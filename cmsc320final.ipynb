{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Historical Prices of Cryptocurrency\n",
    "Ashwin Jeyaseelan, Evan Kerekanich"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "Recently, a cryptocurrency called bitcoin has become a hot topic, but what is it? Bitcoin is the first digital currency which allows the transfer of currency between people without a third party. It was created in 2009 by an unknown person with the alias, Satoshi Nakamoto. It can be used to buy merchandice just like normal currency. Surprisingly, bitcoin has built up a large enough community that markets run competitions where participants are rewarded with bitcoins in exchange of solving complex math puzzles. \n",
    "\n",
    "The purpose of this tutorial is to understand the trend of bitcoin prices to help users decide if it's worth participating with. We will show how to gather, parse, analyze, and conduct hypothesis testing on the data. Finally, we will use machine learning to provide analysis about the bitcoin prices."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting Started \n",
    "First download the bitcoin data from: https://www.kaggle.com/myonin/bitcoin-price-prediction-by-arima/data. Next we will load the bitcoin data file with the library, Pandas. This data contains information about 1-minute bitcoin exchanges from Jan 2012 to October 2017. \n",
    "\n",
    "#### Required Tools:\n",
    "* Python 3.5+\n",
    "* Pandas\n",
    "* numpy \n",
    "* matplotlib \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ashwinjeyaseelan/Documents/anaconda/lib/python3.6/site-packages/statsmodels/compat/pandas.py:56: FutureWarning: The pandas.core.datetools module is deprecated and will be removed in a future version. Please use the pandas.tseries module instead.\n",
      "  from pandas.core import datetools\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_(BTC)</th>\n",
       "      <th>Volume_(Currency)</th>\n",
       "      <th>Weighted_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1325292180</td>\n",
       "      <td>4.247</td>\n",
       "      <td>4.247</td>\n",
       "      <td>4.247</td>\n",
       "      <td>4.247</td>\n",
       "      <td>0.4</td>\n",
       "      <td>1.6988</td>\n",
       "      <td>4.247</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1325292240</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1325292300</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1325292360</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1325292420</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Timestamp   Open   High    Low  Close  Volume_(BTC)  Volume_(Currency)  \\\n",
       "0  1325292180  4.247  4.247  4.247  4.247           0.4             1.6988   \n",
       "1  1325292240    NaN    NaN    NaN    NaN           NaN                NaN   \n",
       "2  1325292300    NaN    NaN    NaN    NaN           NaN                NaN   \n",
       "3  1325292360    NaN    NaN    NaN    NaN           NaN                NaN   \n",
       "4  1325292420    NaN    NaN    NaN    NaN           NaN                NaN   \n",
       "\n",
       "   Weighted_Price  \n",
       "0           4.247  \n",
       "1             NaN  \n",
       "2             NaN  \n",
       "3             NaN  \n",
       "4             NaN  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from scipy import stats\n",
    "import statsmodels.api as sm\n",
    "\n",
    "# Load data:\n",
    "table = pd.read_csv(\"bitcoin-historical-data/btceUSD_1-min_data_2012-01-01_to_2017-05-31.csv\")\n",
    "# Print the first 5 rows of our data:\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looking at our data, we can see the features: Timestamp (unix time), open (opening or starting price of the bitcoin), high (highest price in the minute), low (lowest price in the minute), close (the closing price of the bitcoin), volume and the weighted price."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Tidying Our Data\n",
    "In the head of the table, notice that only one of the rows has succificent data to properly analyze the features. We can save space and time by getting rid of rows that are missing data for features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume_(BTC)</th>\n",
       "      <th>Volume_(Currency)</th>\n",
       "      <th>Weighted_Price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1325292180</td>\n",
       "      <td>4.247</td>\n",
       "      <td>4.247</td>\n",
       "      <td>4.247</td>\n",
       "      <td>4.247</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.698800</td>\n",
       "      <td>4.247000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>1325300460</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>0.623628</td>\n",
       "      <td>2.556875</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>1325304900</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>4.100</td>\n",
       "      <td>6.503072</td>\n",
       "      <td>26.662595</td>\n",
       "      <td>4.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>284</th>\n",
       "      <td>1325309220</td>\n",
       "      <td>4.045</td>\n",
       "      <td>4.045</td>\n",
       "      <td>4.044</td>\n",
       "      <td>4.044</td>\n",
       "      <td>2.379300</td>\n",
       "      <td>9.624254</td>\n",
       "      <td>4.044994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>1325310840</td>\n",
       "      <td>4.044</td>\n",
       "      <td>4.044</td>\n",
       "      <td>4.011</td>\n",
       "      <td>4.011</td>\n",
       "      <td>0.896400</td>\n",
       "      <td>3.607223</td>\n",
       "      <td>4.024122</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Timestamp   Open   High    Low  Close  Volume_(BTC)  Volume_(Currency)  \\\n",
       "0    1325292180  4.247  4.247  4.247  4.247      0.400000           1.698800   \n",
       "138  1325300460  4.100  4.100  4.100  4.100      0.623628           2.556875   \n",
       "212  1325304900  4.100  4.100  4.100  4.100      6.503072          26.662595   \n",
       "284  1325309220  4.045  4.045  4.044  4.044      2.379300           9.624254   \n",
       "311  1325310840  4.044  4.044  4.011  4.011      0.896400           3.607223   \n",
       "\n",
       "     Weighted_Price  \n",
       "0          4.247000  \n",
       "138        4.100000  \n",
       "212        4.100000  \n",
       "284        4.044994  \n",
       "311        4.024122  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop rows with NaN for any of their features\n",
    "table = table.dropna()\n",
    "# view the first 5 rows of the tidy table:\n",
    "table.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Analysis\n",
    "Now that we've prepared our data, we can analyze it. Let's prepare plots to view the prices by days, months, and years.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA3AAAAHNCAYAAABfIZlVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x16035c828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=[15,7])\n",
    "plt.suptitle('Bitcoin exchanges, mean USD', fontsize=22)\n",
    "\n",
    "# minute plot:\n",
    "plt.subplot(221)\n",
    "plt.plot(table.Weighted_Price, label='By Minute')\n",
    "plt.legend()\n",
    "\n",
    "table.Timestamp = pd.to_datetime(table.Timestamp, unit='s')\n",
    "table.index = table.Timestamp\n",
    "\n",
    "# Day plot:\n",
    "table_day = table.resample('D').mean()\n",
    "plt.subplot(222)\n",
    "plt.plot(table_day.Weighted_Price, label='By Days')\n",
    "plt.legend()\n",
    "\n",
    "# month plot:\n",
    "plt.subplot(223)\n",
    "table_month = table.resample('M').mean()\n",
    "plt.plot(table_month.Weighted_Price, label='By Months')\n",
    "plt.legend()\n",
    "\n",
    "# year plot:\n",
    "plt.subplot(224)\n",
    "table_year = table.resample('A-DEC').mean()\n",
    "plt.plot(table_year.Weighted_Price, label='By Year')\n",
    "plt.legend()\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From looking at the data, we can see that that the price has its first peak around 2015, and rapidly increases after 2016. In the day minute plot, you can see more oscillations in the line. This makes sense, because in the smallest unit of time, the fluctuations reflect how rapidly it changes at every minute. After 2017, the prices of bitcoins increase much faster than in any previous year. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Machine Learning\n",
    "Looking back at our bitcoin exchanges subplots, we can clearly see that the prices aren't increasing linearly over time. The bitcoin prices can be modeled better as a polynomial function of our features. \n",
    "\n",
    "#### Neural Network\n",
    "We will use a neural network to model prices as a function of our seven features. A neural network can model can be used to model non convex functions. As you can see our prices are neither a perfect polynomial function of time nor are they a linear function, which makes a neural network a good choice for our objective. \n",
    "\n",
    "A neural network is composed of layers of units, each of which compute a weighted sum of incoming inputs. After applying a function to this weighted sum, known as the activation function, the unit passes its output to the outputs in the next layer. The last unit to receive the outputs of the units in the last layer returns the output. Our goal is to fine tune the weights of the network so our final output is more accurate. \n",
    "\n",
    "Think of a neural network as a model that learns from examples. When you initially feed data into the network, it doesn't know anything so it returns random output. Hence, we train the network after it makes a prediction. This is done by comparing the output of the network with the label or correct answer (in our case this will be the price). In order to decrease the loss of the function, we find the weights that minimize our loss. Neural networks train through backpropagation, in which the slope of the loss function with respect to the weights multiplied by the learning rate parameter is subtracted from the weights. The slope is subtracted from the weights so they can travel in the direction opposite of the increasing slope, i.e. down the slope and hopefully towards the minimum point of the funtion. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.autograd import Variable\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# create a network with three layers. The first two layers will have 100 units.\n",
    "class NeuralNet(nn.Module):\n",
    "    def __init__(self, num_features):\n",
    "        super(NeuralNet, self).__init__()\n",
    "        self.n1 = nn.BatchNorm1d(num_features)\n",
    "        self.fc1 = nn.Linear(num_features, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(100, 100)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(100, 1)\n",
    "        self.relu = nn.ReLU()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.fc1(self.n1(x))\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc3(out)\n",
    "        return out \n",
    "\n",
    "# since we have 7 features (excluding our label which is Weighted_price), our input size is 7\n",
    "net = NeuralNet(7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we've created our neural network, we can train it on our data. We will use 20% of the data for testing, and 80% for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [100/6235], Loss: 0.0780\n",
      "Epoch [1/100], Step [200/6235], Loss: 0.0324\n",
      "Epoch [1/100], Step [300/6235], Loss: 0.0090\n",
      "Epoch [1/100], Step [400/6235], Loss: 0.0028\n",
      "Epoch [1/100], Step [500/6235], Loss: 0.0059\n",
      "Epoch [1/100], Step [600/6235], Loss: 0.0309\n",
      "Epoch [1/100], Step [700/6235], Loss: 0.1533\n",
      "Epoch [1/100], Step [800/6235], Loss: 0.4071\n",
      "Epoch [1/100], Step [900/6235], Loss: 0.0015\n",
      "Epoch [1/100], Step [1000/6235], Loss: 0.0015\n",
      "Epoch [1/100], Step [1100/6235], Loss: 0.0524\n",
      "Epoch [1/100], Step [1200/6235], Loss: 0.0278\n",
      "Epoch [1/100], Step [1300/6235], Loss: 0.0042\n",
      "Epoch [1/100], Step [1400/6235], Loss: 0.0853\n",
      "Epoch [1/100], Step [1500/6235], Loss: 0.0091\n",
      "Epoch [1/100], Step [1600/6235], Loss: 0.0618\n",
      "Epoch [1/100], Step [1700/6235], Loss: 0.0641\n",
      "Epoch [1/100], Step [1800/6235], Loss: 0.2715\n",
      "Epoch [1/100], Step [1900/6235], Loss: 0.0556\n",
      "Epoch [1/100], Step [2000/6235], Loss: 0.7953\n",
      "Epoch [1/100], Step [2100/6235], Loss: 0.3588\n",
      "Epoch [1/100], Step [2200/6235], Loss: 0.4881\n",
      "Epoch [1/100], Step [2300/6235], Loss: 2.9214\n",
      "Epoch [1/100], Step [2400/6235], Loss: 1.3041\n",
      "Epoch [1/100], Step [2500/6235], Loss: 6.0296\n",
      "Epoch [1/100], Step [2600/6235], Loss: 0.1851\n",
      "Epoch [1/100], Step [2700/6235], Loss: 7.0772\n",
      "Epoch [1/100], Step [2800/6235], Loss: 45.8525\n",
      "Epoch [1/100], Step [2900/6235], Loss: 4.2936\n",
      "Epoch [1/100], Step [3000/6235], Loss: 14.6848\n",
      "Epoch [1/100], Step [3100/6235], Loss: 62.3192\n",
      "Epoch [1/100], Step [3200/6235], Loss: 0.9476\n",
      "Epoch [1/100], Step [3300/6235], Loss: 2.5518\n",
      "Epoch [1/100], Step [3400/6235], Loss: 4.5477\n",
      "Epoch [1/100], Step [3500/6235], Loss: 0.4387\n",
      "Epoch [1/100], Step [3600/6235], Loss: 6.3788\n",
      "Epoch [1/100], Step [3700/6235], Loss: 0.3656\n",
      "Epoch [1/100], Step [3800/6235], Loss: 0.0106\n",
      "Epoch [1/100], Step [3900/6235], Loss: 0.0518\n",
      "Epoch [1/100], Step [4000/6235], Loss: 0.1071\n",
      "Epoch [1/100], Step [4100/6235], Loss: 0.1403\n",
      "Epoch [1/100], Step [4200/6235], Loss: 2.1414\n",
      "Epoch [1/100], Step [4300/6235], Loss: 0.7443\n",
      "Epoch [1/100], Step [4400/6235], Loss: 0.0520\n",
      "Epoch [1/100], Step [4500/6235], Loss: 21.9873\n",
      "Epoch [1/100], Step [4600/6235], Loss: 9.8915\n",
      "Epoch [1/100], Step [4700/6235], Loss: 0.3639\n",
      "Epoch [1/100], Step [4800/6235], Loss: 3.6978\n",
      "Epoch [1/100], Step [4900/6235], Loss: 0.1614\n",
      "Epoch [1/100], Step [5000/6235], Loss: 0.2339\n",
      "Epoch [1/100], Step [5100/6235], Loss: 0.0540\n",
      "Epoch [1/100], Step [5200/6235], Loss: 0.6920\n",
      "Epoch [1/100], Step [5300/6235], Loss: 5.9514\n",
      "Epoch [1/100], Step [5400/6235], Loss: 2.7985\n",
      "Epoch [1/100], Step [5500/6235], Loss: 0.7730\n",
      "Epoch [1/100], Step [5600/6235], Loss: 0.5731\n",
      "Epoch [1/100], Step [5700/6235], Loss: 0.2507\n",
      "Epoch [1/100], Step [5800/6235], Loss: 0.0060\n",
      "Epoch [1/100], Step [5900/6235], Loss: 0.1597\n",
      "Epoch [1/100], Step [6000/6235], Loss: 0.0392\n",
      "Epoch [1/100], Step [6100/6235], Loss: 0.1816\n",
      "Epoch [1/100], Step [6200/6235], Loss: 3.7008\n",
      "Epoch [1/100], Step [6300/6235], Loss: 0.0189\n",
      "Epoch [1/100], Step [6400/6235], Loss: 0.0131\n",
      "Epoch [1/100], Step [6500/6235], Loss: 2.4403\n",
      "Epoch [1/100], Step [6600/6235], Loss: 3.6310\n",
      "Epoch [1/100], Step [6700/6235], Loss: 0.4846\n",
      "Epoch [1/100], Step [6800/6235], Loss: 3.1624\n",
      "Epoch [1/100], Step [6900/6235], Loss: 5.9814\n",
      "Epoch [1/100], Step [7000/6235], Loss: 0.1588\n",
      "Epoch [1/100], Step [7100/6235], Loss: 0.0425\n",
      "Epoch [1/100], Step [7200/6235], Loss: 0.0223\n",
      "Epoch [1/100], Step [7300/6235], Loss: 0.0197\n",
      "Epoch [1/100], Step [7400/6235], Loss: 0.2575\n",
      "Epoch [1/100], Step [7500/6235], Loss: 0.8540\n",
      "Epoch [1/100], Step [7600/6235], Loss: 7.2694\n",
      "Epoch [1/100], Step [7700/6235], Loss: 10.1626\n",
      "Epoch [1/100], Step [7800/6235], Loss: 0.1028\n",
      "Epoch [1/100], Step [7900/6235], Loss: 0.5858\n",
      "Epoch [1/100], Step [8000/6235], Loss: 5.0696\n",
      "Epoch [1/100], Step [8100/6235], Loss: 0.0393\n",
      "Epoch [1/100], Step [8200/6235], Loss: 0.3204\n",
      "Epoch [1/100], Step [8300/6235], Loss: 12.4841\n",
      "Epoch [1/100], Step [8400/6235], Loss: 220.3686\n",
      "Epoch [1/100], Step [8500/6235], Loss: 3.7875\n",
      "Epoch [1/100], Step [8600/6235], Loss: 116.2963\n",
      "Epoch [1/100], Step [8700/6235], Loss: 13.5973\n",
      "Epoch [1/100], Step [8800/6235], Loss: 302.8797\n",
      "Epoch [1/100], Step [8900/6235], Loss: 2.3100\n",
      "Epoch [1/100], Step [9000/6235], Loss: 91.0415\n",
      "Epoch [1/100], Step [9100/6235], Loss: 230.0509\n",
      "Epoch [1/100], Step [9200/6235], Loss: 458.5834\n",
      "Epoch [1/100], Step [9300/6235], Loss: 527.8150\n",
      "Epoch [1/100], Step [9400/6235], Loss: 115.4242\n",
      "Epoch [1/100], Step [9500/6235], Loss: 18.4656\n",
      "Epoch [1/100], Step [9600/6235], Loss: 2236.3540\n",
      "Epoch [1/100], Step [9700/6235], Loss: 92.4096\n",
      "Epoch [1/100], Step [9800/6235], Loss: 28.1548\n",
      "Epoch [1/100], Step [9900/6235], Loss: 1406.1826\n",
      "Epoch [1/100], Step [10000/6235], Loss: 437.8419\n",
      "Epoch [1/100], Step [10100/6235], Loss: 34.7067\n",
      "Epoch [1/100], Step [10200/6235], Loss: 113.1482\n",
      "Epoch [1/100], Step [10300/6235], Loss: 33.0364\n",
      "Epoch [1/100], Step [10400/6235], Loss: 1.4907\n",
      "Epoch [1/100], Step [10500/6235], Loss: 7.5373\n",
      "Epoch [1/100], Step [10600/6235], Loss: 55.0839\n",
      "Epoch [1/100], Step [10700/6235], Loss: 523.7336\n",
      "Epoch [1/100], Step [10800/6235], Loss: 219.4446\n",
      "Epoch [1/100], Step [10900/6235], Loss: 120.5045\n",
      "Epoch [1/100], Step [11000/6235], Loss: 4.4366\n",
      "Epoch [1/100], Step [11100/6235], Loss: 22.1922\n",
      "Epoch [1/100], Step [11200/6235], Loss: 0.2999\n",
      "Epoch [1/100], Step [11300/6235], Loss: 16.6262\n",
      "Epoch [1/100], Step [11400/6235], Loss: 6.2941\n",
      "Epoch [1/100], Step [11500/6235], Loss: 0.8218\n",
      "Epoch [1/100], Step [11600/6235], Loss: 3.2434\n",
      "Epoch [1/100], Step [11700/6235], Loss: 2.3432\n",
      "Epoch [1/100], Step [11800/6235], Loss: 31.5100\n",
      "Epoch [1/100], Step [11900/6235], Loss: 34.0739\n",
      "Epoch [1/100], Step [12000/6235], Loss: 32.2446\n",
      "Epoch [1/100], Step [12100/6235], Loss: 130.5512\n",
      "Epoch [1/100], Step [12200/6235], Loss: 122.3970\n",
      "Epoch [1/100], Step [12300/6235], Loss: 86.6980\n",
      "Epoch [1/100], Step [12400/6235], Loss: 708.4540\n",
      "Epoch [1/100], Step [12500/6235], Loss: 116.1641\n",
      "Epoch [1/100], Step [12600/6235], Loss: 40.8789\n",
      "Epoch [1/100], Step [12700/6235], Loss: 11.5750\n",
      "Epoch [1/100], Step [12800/6235], Loss: 129.7918\n",
      "Epoch [1/100], Step [12900/6235], Loss: 13.1829\n",
      "Epoch [1/100], Step [13000/6235], Loss: 2.7611\n",
      "Epoch [1/100], Step [13100/6235], Loss: 30.9991\n",
      "Epoch [1/100], Step [13200/6235], Loss: 13.6328\n",
      "Epoch [1/100], Step [13300/6235], Loss: 31.4121\n",
      "Epoch [1/100], Step [13400/6235], Loss: 4.5065\n",
      "Epoch [1/100], Step [13500/6235], Loss: 5.3901\n",
      "Epoch [1/100], Step [13600/6235], Loss: 13.0479\n",
      "Epoch [1/100], Step [13700/6235], Loss: 186.6862\n",
      "Epoch [1/100], Step [13800/6235], Loss: 110.9209\n",
      "Epoch [1/100], Step [13900/6235], Loss: 31.7041\n",
      "Epoch [1/100], Step [14000/6235], Loss: 31.8054\n",
      "Epoch [1/100], Step [14100/6235], Loss: 31.4492\n",
      "Epoch [1/100], Step [14200/6235], Loss: 4.6439\n",
      "Epoch [1/100], Step [14300/6235], Loss: 7.7489\n",
      "Epoch [1/100], Step [14400/6235], Loss: 9.4694\n",
      "Epoch [1/100], Step [14500/6235], Loss: 18.7191\n",
      "Epoch [1/100], Step [14600/6235], Loss: 4.0876\n",
      "Epoch [1/100], Step [14700/6235], Loss: 1.1375\n",
      "Epoch [1/100], Step [14800/6235], Loss: 41.1376\n",
      "Epoch [1/100], Step [14900/6235], Loss: 8.2248\n",
      "Epoch [1/100], Step [15000/6235], Loss: 0.3155\n",
      "Epoch [1/100], Step [15100/6235], Loss: 0.8506\n",
      "Epoch [1/100], Step [15200/6235], Loss: 311.6234\n",
      "Epoch [1/100], Step [15300/6235], Loss: 46.5030\n",
      "Epoch [1/100], Step [15400/6235], Loss: 0.8347\n",
      "Epoch [1/100], Step [15500/6235], Loss: 3.5908\n",
      "Epoch [1/100], Step [15600/6235], Loss: 214.0310\n",
      "Epoch [1/100], Step [15700/6235], Loss: 1.0550\n",
      "Epoch [1/100], Step [15800/6235], Loss: 3.9636\n",
      "Epoch [1/100], Step [15900/6235], Loss: 5.8245\n",
      "Epoch [1/100], Step [16000/6235], Loss: 1.2133\n",
      "Epoch [1/100], Step [16100/6235], Loss: 80.8525\n",
      "Epoch [1/100], Step [16200/6235], Loss: 2.1966\n",
      "Epoch [1/100], Step [16300/6235], Loss: 0.7956\n",
      "Epoch [1/100], Step [16400/6235], Loss: 18.9681\n",
      "Epoch [1/100], Step [16500/6235], Loss: 104.3424\n",
      "Epoch [1/100], Step [16600/6235], Loss: 0.6950\n",
      "Epoch [1/100], Step [16700/6235], Loss: 0.6809\n",
      "Epoch [1/100], Step [16800/6235], Loss: 6.1619\n",
      "Epoch [1/100], Step [16900/6235], Loss: 18.0617\n",
      "Epoch [1/100], Step [17000/6235], Loss: 0.1360\n",
      "Epoch [1/100], Step [17100/6235], Loss: 7.7931\n",
      "Epoch [1/100], Step [17200/6235], Loss: 4.1732\n",
      "Epoch [1/100], Step [17300/6235], Loss: 47.0600\n",
      "Epoch [1/100], Step [17400/6235], Loss: 69.1913\n",
      "Epoch [1/100], Step [17500/6235], Loss: 1.3695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [17600/6235], Loss: 0.2907\n",
      "Epoch [1/100], Step [17700/6235], Loss: 118.0996\n",
      "Epoch [1/100], Step [17800/6235], Loss: 129.4409\n",
      "Epoch [1/100], Step [17900/6235], Loss: 7.8929\n",
      "Epoch [1/100], Step [18000/6235], Loss: 12.2196\n",
      "Epoch [1/100], Step [18100/6235], Loss: 6.7899\n",
      "Epoch [1/100], Step [18200/6235], Loss: 5.8394\n",
      "Epoch [1/100], Step [18300/6235], Loss: 32.9528\n",
      "Epoch [1/100], Step [18400/6235], Loss: 1.4162\n",
      "Epoch [1/100], Step [18500/6235], Loss: 4.0618\n",
      "Epoch [1/100], Step [18600/6235], Loss: 2.4343\n",
      "Epoch [1/100], Step [18700/6235], Loss: 2.0049\n",
      "Epoch [1/100], Step [18800/6235], Loss: 59.6816\n",
      "Epoch [1/100], Step [18900/6235], Loss: 22.0218\n",
      "Epoch [1/100], Step [19000/6235], Loss: 0.5886\n",
      "Epoch [1/100], Step [19100/6235], Loss: 3.4150\n",
      "Epoch [1/100], Step [19200/6235], Loss: 4.2665\n",
      "Epoch [1/100], Step [19300/6235], Loss: 1.2758\n",
      "Epoch [1/100], Step [19400/6235], Loss: 88.4231\n",
      "Epoch [1/100], Step [19500/6235], Loss: 194.7514\n",
      "Epoch [1/100], Step [19600/6235], Loss: 36.0546\n",
      "Epoch [1/100], Step [19700/6235], Loss: 37.7721\n",
      "Epoch [1/100], Step [19800/6235], Loss: 14.3992\n",
      "Epoch [1/100], Step [19900/6235], Loss: 4.1658\n",
      "Epoch [1/100], Step [20000/6235], Loss: 10.7653\n",
      "Epoch [1/100], Step [20100/6235], Loss: 5.9849\n",
      "Epoch [1/100], Step [20200/6235], Loss: 0.7717\n",
      "Epoch [1/100], Step [20300/6235], Loss: 8.8762\n",
      "Epoch [1/100], Step [20400/6235], Loss: 1.5572\n",
      "Epoch [1/100], Step [20500/6235], Loss: 1.0089\n",
      "Epoch [1/100], Step [20600/6235], Loss: 9.2539\n",
      "Epoch [1/100], Step [20700/6235], Loss: 15.7739\n",
      "Epoch [1/100], Step [20800/6235], Loss: 61.9781\n",
      "Epoch [1/100], Step [20900/6235], Loss: 37.0227\n",
      "Epoch [1/100], Step [21000/6235], Loss: 0.2963\n",
      "Epoch [1/100], Step [21100/6235], Loss: 3.7645\n",
      "Epoch [1/100], Step [21200/6235], Loss: 8.0184\n",
      "Epoch [1/100], Step [21300/6235], Loss: 0.8529\n",
      "Epoch [1/100], Step [21400/6235], Loss: 10.3785\n",
      "Epoch [1/100], Step [21500/6235], Loss: 2.8790\n",
      "Epoch [1/100], Step [21600/6235], Loss: 0.2032\n",
      "Epoch [1/100], Step [21700/6235], Loss: 14.7583\n",
      "Epoch [1/100], Step [21800/6235], Loss: 18.7266\n",
      "Epoch [1/100], Step [21900/6235], Loss: 3.0801\n",
      "Epoch [1/100], Step [22000/6235], Loss: 4.0363\n",
      "Epoch [1/100], Step [22100/6235], Loss: 0.6168\n",
      "Epoch [1/100], Step [22200/6235], Loss: 0.5840\n",
      "Epoch [1/100], Step [22300/6235], Loss: 6.4077\n",
      "Epoch [1/100], Step [22400/6235], Loss: 4.2259\n",
      "Epoch [1/100], Step [22500/6235], Loss: 90.7340\n",
      "Epoch [1/100], Step [22600/6235], Loss: 12.4671\n",
      "Epoch [1/100], Step [22700/6235], Loss: 1.4876\n",
      "Epoch [1/100], Step [22800/6235], Loss: 12.5503\n",
      "Epoch [1/100], Step [22900/6235], Loss: 37.1784\n",
      "Epoch [1/100], Step [23000/6235], Loss: 16.6274\n",
      "Epoch [1/100], Step [23100/6235], Loss: 4.4382\n",
      "Epoch [1/100], Step [23200/6235], Loss: 54.6394\n",
      "Epoch [1/100], Step [23300/6235], Loss: 0.2706\n",
      "Epoch [1/100], Step [23400/6235], Loss: 9.6828\n",
      "Epoch [1/100], Step [23500/6235], Loss: 6.9343\n",
      "Epoch [1/100], Step [23600/6235], Loss: 20.0677\n",
      "Epoch [1/100], Step [23700/6235], Loss: 1.4033\n",
      "Epoch [1/100], Step [23800/6235], Loss: 0.2092\n",
      "Epoch [1/100], Step [23900/6235], Loss: 0.6415\n",
      "Epoch [1/100], Step [24000/6235], Loss: 79.4781\n",
      "Epoch [1/100], Step [24100/6235], Loss: 16.4124\n",
      "Epoch [1/100], Step [24200/6235], Loss: 17.3615\n",
      "Epoch [1/100], Step [24300/6235], Loss: 0.0578\n",
      "Epoch [1/100], Step [24400/6235], Loss: 6.1184\n",
      "Epoch [1/100], Step [24500/6235], Loss: 17.7074\n",
      "Epoch [1/100], Step [24600/6235], Loss: 0.0196\n",
      "Epoch [1/100], Step [24700/6235], Loss: 9.8559\n",
      "Epoch [1/100], Step [24800/6235], Loss: 0.1991\n",
      "Epoch [1/100], Step [24900/6235], Loss: 2.4948\n",
      "Epoch [1/100], Step [25000/6235], Loss: 0.6830\n",
      "Epoch [1/100], Step [25100/6235], Loss: 16.6425\n",
      "Epoch [1/100], Step [25200/6235], Loss: 0.1843\n",
      "Epoch [1/100], Step [25300/6235], Loss: 10.8048\n",
      "Epoch [1/100], Step [25400/6235], Loss: 1.0292\n",
      "Epoch [1/100], Step [25500/6235], Loss: 38.3816\n",
      "Epoch [1/100], Step [25600/6235], Loss: 0.0460\n",
      "Epoch [1/100], Step [25700/6235], Loss: 3.2248\n",
      "Epoch [1/100], Step [25800/6235], Loss: 0.7789\n",
      "Epoch [1/100], Step [25900/6235], Loss: 0.1707\n",
      "Epoch [1/100], Step [26000/6235], Loss: 1.9005\n",
      "Epoch [1/100], Step [26100/6235], Loss: 15.9015\n",
      "Epoch [1/100], Step [26200/6235], Loss: 0.2603\n",
      "Epoch [1/100], Step [26300/6235], Loss: 0.0739\n",
      "Epoch [1/100], Step [26400/6235], Loss: 6.8374\n",
      "Epoch [1/100], Step [26500/6235], Loss: 1.8408\n",
      "Epoch [1/100], Step [26600/6235], Loss: 1.9825\n",
      "Epoch [1/100], Step [26700/6235], Loss: 0.6914\n",
      "Epoch [1/100], Step [26800/6235], Loss: 0.5120\n",
      "Epoch [1/100], Step [26900/6235], Loss: 0.2258\n",
      "Epoch [1/100], Step [27000/6235], Loss: 5.4190\n",
      "Epoch [1/100], Step [27100/6235], Loss: 1.4394\n",
      "Epoch [1/100], Step [27200/6235], Loss: 3.1605\n",
      "Epoch [1/100], Step [27300/6235], Loss: 0.2579\n",
      "Epoch [1/100], Step [27400/6235], Loss: 0.1839\n",
      "Epoch [1/100], Step [27500/6235], Loss: 11.1252\n",
      "Epoch [1/100], Step [27600/6235], Loss: 0.0937\n",
      "Epoch [1/100], Step [27700/6235], Loss: 3.9179\n",
      "Epoch [1/100], Step [27800/6235], Loss: 0.1664\n",
      "Epoch [1/100], Step [27900/6235], Loss: 6.5552\n",
      "Epoch [1/100], Step [28000/6235], Loss: 13.0629\n",
      "Epoch [1/100], Step [28100/6235], Loss: 5.1769\n",
      "Epoch [1/100], Step [28200/6235], Loss: 17.2061\n",
      "Epoch [1/100], Step [28300/6235], Loss: 0.5662\n",
      "Epoch [1/100], Step [28400/6235], Loss: 4.8536\n",
      "Epoch [1/100], Step [28500/6235], Loss: 0.1046\n",
      "Epoch [1/100], Step [28600/6235], Loss: 0.2135\n",
      "Epoch [1/100], Step [28700/6235], Loss: 4.6073\n",
      "Epoch [1/100], Step [28800/6235], Loss: 6.3872\n",
      "Epoch [1/100], Step [28900/6235], Loss: 2.3537\n",
      "Epoch [1/100], Step [29000/6235], Loss: 1.9676\n",
      "Epoch [1/100], Step [29100/6235], Loss: 1.0490\n",
      "Epoch [1/100], Step [29200/6235], Loss: 1.7287\n",
      "Epoch [1/100], Step [29300/6235], Loss: 0.2082\n",
      "Epoch [1/100], Step [29400/6235], Loss: 8.0733\n",
      "Epoch [1/100], Step [29500/6235], Loss: 3.6972\n",
      "Epoch [1/100], Step [29600/6235], Loss: 0.9284\n",
      "Epoch [1/100], Step [29700/6235], Loss: 0.5334\n",
      "Epoch [1/100], Step [29800/6235], Loss: 0.0479\n",
      "Epoch [1/100], Step [29900/6235], Loss: 0.5740\n",
      "Epoch [1/100], Step [30000/6235], Loss: 3.8980\n",
      "Epoch [1/100], Step [30100/6235], Loss: 7.2383\n",
      "Epoch [1/100], Step [30200/6235], Loss: 0.9346\n",
      "Epoch [1/100], Step [30300/6235], Loss: 0.1740\n",
      "Epoch [1/100], Step [30400/6235], Loss: 13.6714\n",
      "Epoch [1/100], Step [30500/6235], Loss: 0.1738\n",
      "Epoch [1/100], Step [30600/6235], Loss: 3.0477\n",
      "Epoch [1/100], Step [30700/6235], Loss: 0.2305\n",
      "Epoch [1/100], Step [30800/6235], Loss: 0.2680\n",
      "Epoch [1/100], Step [30900/6235], Loss: 0.9378\n",
      "Epoch [1/100], Step [31000/6235], Loss: 0.0631\n",
      "Epoch [1/100], Step [31100/6235], Loss: 1.2236\n",
      "Epoch [1/100], Step [31200/6235], Loss: 5.8290\n",
      "Epoch [1/100], Step [31300/6235], Loss: 7.9152\n",
      "Epoch [1/100], Step [31400/6235], Loss: 10.7778\n",
      "Epoch [1/100], Step [31500/6235], Loss: 1.1503\n",
      "Epoch [1/100], Step [31600/6235], Loss: 0.3289\n",
      "Epoch [1/100], Step [31700/6235], Loss: 49.8969\n",
      "Epoch [1/100], Step [31800/6235], Loss: 0.1713\n",
      "Epoch [1/100], Step [31900/6235], Loss: 1943.3215\n",
      "Epoch [1/100], Step [32000/6235], Loss: 185.6730\n",
      "Epoch [1/100], Step [32100/6235], Loss: 8.0846\n",
      "Epoch [1/100], Step [32200/6235], Loss: 0.6649\n",
      "Epoch [1/100], Step [32300/6235], Loss: 30.1389\n",
      "Epoch [1/100], Step [32400/6235], Loss: 1.2920\n",
      "Epoch [1/100], Step [32500/6235], Loss: 2.8652\n",
      "Epoch [1/100], Step [32600/6235], Loss: 1.0552\n",
      "Epoch [1/100], Step [32700/6235], Loss: 196.0014\n",
      "Epoch [1/100], Step [32800/6235], Loss: 35.6959\n",
      "Epoch [1/100], Step [32900/6235], Loss: 61.4032\n",
      "Epoch [1/100], Step [33000/6235], Loss: 25.3598\n",
      "Epoch [1/100], Step [33100/6235], Loss: 2.1400\n",
      "Epoch [1/100], Step [33200/6235], Loss: 0.8175\n",
      "Epoch [1/100], Step [33300/6235], Loss: 0.3746\n",
      "Epoch [1/100], Step [33400/6235], Loss: 195.6240\n",
      "Epoch [1/100], Step [33500/6235], Loss: 0.5219\n",
      "Epoch [1/100], Step [33600/6235], Loss: 9.3764\n",
      "Epoch [1/100], Step [33700/6235], Loss: 5.1346\n",
      "Epoch [1/100], Step [33800/6235], Loss: 16.5361\n",
      "Epoch [1/100], Step [33900/6235], Loss: 1.1129\n",
      "Epoch [1/100], Step [34000/6235], Loss: 0.0271\n",
      "Epoch [1/100], Step [34100/6235], Loss: 0.0688\n",
      "Epoch [1/100], Step [34200/6235], Loss: 35.3457\n",
      "Epoch [1/100], Step [34300/6235], Loss: 0.1078\n",
      "Epoch [1/100], Step [34400/6235], Loss: 4.9929\n",
      "Epoch [1/100], Step [34500/6235], Loss: 93.1110\n",
      "Epoch [1/100], Step [34600/6235], Loss: 18.4005\n",
      "Epoch [1/100], Step [34700/6235], Loss: 13.1676\n",
      "Epoch [1/100], Step [34800/6235], Loss: 6.1357\n",
      "Epoch [1/100], Step [34900/6235], Loss: 8.9295\n",
      "Epoch [1/100], Step [35000/6235], Loss: 0.3806\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Step [35100/6235], Loss: 1.8346\n",
      "Epoch [1/100], Step [35200/6235], Loss: 0.4792\n",
      "Epoch [1/100], Step [35300/6235], Loss: 0.0598\n",
      "Epoch [1/100], Step [35400/6235], Loss: 16.4021\n",
      "Epoch [1/100], Step [35500/6235], Loss: 15.4232\n",
      "Epoch [1/100], Step [35600/6235], Loss: 0.7056\n",
      "Epoch [1/100], Step [35700/6235], Loss: 0.0223\n",
      "Epoch [1/100], Step [35800/6235], Loss: 1.6569\n",
      "Epoch [1/100], Step [35900/6235], Loss: 18.1127\n",
      "Epoch [1/100], Step [36000/6235], Loss: 12.4237\n",
      "Epoch [1/100], Step [36100/6235], Loss: 4.6593\n",
      "Epoch [1/100], Step [36200/6235], Loss: 1.6781\n",
      "Epoch [1/100], Step [36300/6235], Loss: 7.0382\n",
      "Epoch [1/100], Step [36400/6235], Loss: 9.9184\n",
      "Epoch [1/100], Step [36500/6235], Loss: 24.6607\n",
      "Epoch [1/100], Step [36600/6235], Loss: 0.1067\n",
      "Epoch [1/100], Step [36700/6235], Loss: 0.0609\n",
      "Epoch [1/100], Step [36800/6235], Loss: 28.2056\n",
      "Epoch [1/100], Step [36900/6235], Loss: 0.0607\n",
      "Epoch [1/100], Step [37000/6235], Loss: 0.2514\n",
      "Epoch [1/100], Step [37100/6235], Loss: 0.7460\n",
      "Epoch [1/100], Step [37200/6235], Loss: 0.0651\n",
      "Epoch [1/100], Step [37300/6235], Loss: 1.1496\n",
      "Epoch [1/100], Step [37400/6235], Loss: 1.3396\n",
      "Epoch [1/100], Step [37500/6235], Loss: 4.8296\n",
      "Epoch [1/100], Step [37600/6235], Loss: 3.4141\n",
      "Epoch [1/100], Step [37700/6235], Loss: 5.8855\n",
      "Epoch [1/100], Step [37800/6235], Loss: 18.0240\n",
      "Epoch [1/100], Step [37900/6235], Loss: 2.2657\n",
      "Epoch [1/100], Step [38000/6235], Loss: 0.1717\n",
      "Epoch [1/100], Step [38100/6235], Loss: 0.4858\n",
      "Epoch [1/100], Step [38200/6235], Loss: 2.7697\n",
      "Epoch [1/100], Step [38300/6235], Loss: 6.5644\n",
      "Epoch [1/100], Step [38400/6235], Loss: 0.4068\n",
      "Epoch [1/100], Step [38500/6235], Loss: 5.8781\n",
      "Epoch [1/100], Step [38600/6235], Loss: 13.7028\n",
      "Epoch [1/100], Step [38700/6235], Loss: 0.2420\n",
      "Epoch [1/100], Step [38800/6235], Loss: 1.5480\n",
      "Epoch [1/100], Step [38900/6235], Loss: 105.8709\n",
      "Epoch [1/100], Step [39000/6235], Loss: 33.6301\n",
      "Epoch [1/100], Step [39100/6235], Loss: 20.4581\n",
      "Epoch [1/100], Step [39200/6235], Loss: 0.3626\n",
      "Epoch [1/100], Step [39300/6235], Loss: 9.6520\n",
      "Epoch [1/100], Step [39400/6235], Loss: 101.9902\n",
      "Epoch [1/100], Step [39500/6235], Loss: 382.5111\n",
      "Epoch [1/100], Step [39600/6235], Loss: 0.2660\n",
      "Epoch [1/100], Step [39700/6235], Loss: 867.6497\n",
      "Epoch [1/100], Step [39800/6235], Loss: 4.0347\n",
      "Epoch [1/100], Step [39900/6235], Loss: 74.1382\n",
      "Epoch [1/100], Step [40000/6235], Loss: 145.9220\n",
      "Epoch [1/100], Step [40100/6235], Loss: 26.0130\n",
      "Epoch [1/100], Step [40200/6235], Loss: 175.6553\n",
      "Epoch [1/100], Step [40300/6235], Loss: 80.2935\n",
      "Epoch [1/100], Step [40400/6235], Loss: 59.5351\n",
      "Epoch [1/100], Step [40500/6235], Loss: 3.2660\n",
      "Epoch [1/100], Step [40600/6235], Loss: 23.7703\n",
      "Epoch [1/100], Step [40700/6235], Loss: 10.1014\n",
      "Epoch [1/100], Step [40800/6235], Loss: 2.0587\n",
      "Epoch [1/100], Step [40900/6235], Loss: 0.2316\n",
      "Epoch [1/100], Step [41000/6235], Loss: 47.9135\n",
      "Epoch [1/100], Step [41100/6235], Loss: 5.0079\n",
      "Epoch [1/100], Step [41200/6235], Loss: 17.3425\n",
      "Epoch [1/100], Step [41300/6235], Loss: 4.1168\n",
      "Epoch [1/100], Step [41400/6235], Loss: 4.6211\n",
      "Epoch [1/100], Step [41500/6235], Loss: 8.9248\n",
      "Epoch [1/100], Step [41600/6235], Loss: 0.0788\n",
      "Epoch [1/100], Step [41700/6235], Loss: 1.5107\n",
      "Epoch [1/100], Step [41800/6235], Loss: 0.3916\n",
      "Epoch [1/100], Step [41900/6235], Loss: 8.8116\n",
      "Epoch [1/100], Step [42000/6235], Loss: 2.1014\n",
      "Epoch [1/100], Step [42100/6235], Loss: 0.4901\n",
      "Epoch [1/100], Step [42200/6235], Loss: 14.8049\n",
      "Epoch [1/100], Step [42300/6235], Loss: 8.6858\n",
      "Epoch [1/100], Step [42400/6235], Loss: 0.2323\n",
      "Epoch [1/100], Step [42500/6235], Loss: 3.4241\n",
      "Epoch [1/100], Step [42600/6235], Loss: 0.0016\n",
      "Epoch [1/100], Step [42700/6235], Loss: 0.8198\n",
      "Epoch [1/100], Step [42800/6235], Loss: 0.0902\n",
      "Epoch [1/100], Step [42900/6235], Loss: 0.5446\n",
      "Epoch [1/100], Step [43000/6235], Loss: 2.7306\n",
      "Epoch [1/100], Step [43100/6235], Loss: 1.8980\n",
      "Epoch [1/100], Step [43200/6235], Loss: 1.1168\n",
      "Epoch [1/100], Step [43300/6235], Loss: 0.5023\n",
      "Epoch [1/100], Step [43400/6235], Loss: 2.9122\n",
      "Epoch [1/100], Step [43500/6235], Loss: 10.2868\n",
      "Epoch [1/100], Step [43600/6235], Loss: 0.4062\n",
      "Epoch [1/100], Step [43700/6235], Loss: 16.3398\n",
      "Epoch [1/100], Step [43800/6235], Loss: 0.2156\n",
      "Epoch [1/100], Step [43900/6235], Loss: 7.4021\n",
      "Epoch [1/100], Step [44000/6235], Loss: 91.5290\n",
      "Epoch [1/100], Step [44100/6235], Loss: 21.9538\n",
      "Epoch [1/100], Step [44200/6235], Loss: 12.7875\n",
      "Epoch [1/100], Step [44300/6235], Loss: 21.1038\n",
      "Epoch [1/100], Step [44400/6235], Loss: 0.5119\n",
      "Epoch [1/100], Step [44500/6235], Loss: 24.7789\n",
      "Epoch [1/100], Step [44600/6235], Loss: 1.4009\n",
      "Epoch [1/100], Step [44700/6235], Loss: 0.9983\n",
      "Epoch [1/100], Step [44800/6235], Loss: 0.3313\n",
      "Epoch [1/100], Step [44900/6235], Loss: 0.9574\n",
      "Epoch [1/100], Step [45000/6235], Loss: 0.1906\n",
      "Epoch [1/100], Step [45100/6235], Loss: 1.3638\n",
      "Epoch [1/100], Step [45200/6235], Loss: 2.5066\n",
      "Epoch [1/100], Step [45300/6235], Loss: 3.2185\n",
      "Epoch [1/100], Step [45400/6235], Loss: 8.0465\n",
      "Epoch [1/100], Step [45500/6235], Loss: 0.1866\n",
      "Epoch [1/100], Step [45600/6235], Loss: 6.2432\n",
      "Epoch [1/100], Step [45700/6235], Loss: 24.0029\n",
      "Epoch [1/100], Step [45800/6235], Loss: 479.5422\n",
      "Epoch [1/100], Step [45900/6235], Loss: 14.6686\n",
      "Epoch [1/100], Step [46000/6235], Loss: 383.5445\n",
      "Epoch [1/100], Step [46100/6235], Loss: 90.4026\n",
      "Epoch [1/100], Step [46200/6235], Loss: 547.2188\n",
      "Epoch [1/100], Step [46300/6235], Loss: 3.3541\n",
      "Epoch [1/100], Step [46400/6235], Loss: 12.4875\n",
      "Epoch [1/100], Step [46500/6235], Loss: 0.7593\n",
      "Epoch [1/100], Step [46600/6235], Loss: 13.1502\n",
      "Epoch [1/100], Step [46700/6235], Loss: 56.9451\n",
      "Epoch [1/100], Step [46800/6235], Loss: 43.6019\n",
      "Epoch [1/100], Step [46900/6235], Loss: 13.3034\n",
      "Epoch [1/100], Step [47000/6235], Loss: 0.1048\n",
      "Epoch [1/100], Step [47100/6235], Loss: 130.4920\n",
      "Epoch [1/100], Step [47200/6235], Loss: 6.3212\n",
      "Epoch [1/100], Step [47300/6235], Loss: 18.7937\n",
      "Epoch [1/100], Step [47400/6235], Loss: 384.5598\n",
      "Epoch [1/100], Step [47500/6235], Loss: 0.9856\n",
      "Epoch [1/100], Step [47600/6235], Loss: 0.9555\n",
      "Epoch [1/100], Step [47700/6235], Loss: 18.1344\n",
      "Epoch [1/100], Step [47800/6235], Loss: 10.6984\n",
      "Epoch [1/100], Step [47900/6235], Loss: 0.2906\n",
      "Epoch [1/100], Step [48000/6235], Loss: 51.1297\n",
      "Epoch [1/100], Step [48100/6235], Loss: 7.2851\n",
      "Epoch [1/100], Step [48200/6235], Loss: 0.9973\n",
      "Epoch [1/100], Step [48300/6235], Loss: 997.0729\n",
      "Epoch [1/100], Step [48400/6235], Loss: 5.0895\n",
      "Epoch [1/100], Step [48500/6235], Loss: 9.8520\n",
      "Epoch [1/100], Step [48600/6235], Loss: 20.2825\n",
      "Epoch [1/100], Step [48700/6235], Loss: 2.9070\n",
      "Epoch [1/100], Step [48800/6235], Loss: 886.7908\n",
      "Epoch [1/100], Step [48900/6235], Loss: 57.3442\n",
      "Epoch [1/100], Step [49000/6235], Loss: 171.5110\n",
      "Epoch [1/100], Step [49100/6235], Loss: 3037.9314\n",
      "Epoch [1/100], Step [49200/6235], Loss: 700.8494\n",
      "Epoch [1/100], Step [49300/6235], Loss: 288.6634\n",
      "Epoch [1/100], Step [49400/6235], Loss: 8.3514\n",
      "Epoch [1/100], Step [49500/6235], Loss: 23.8387\n",
      "Epoch [1/100], Step [49600/6235], Loss: 222.8619\n",
      "Epoch [1/100], Step [49700/6235], Loss: 724.5791\n",
      "Epoch [1/100], Step [49800/6235], Loss: 1762.7048\n",
      "Epoch [2/100], Step [100/6235], Loss: 6.1613\n",
      "Epoch [2/100], Step [200/6235], Loss: 0.0800\n",
      "Epoch [2/100], Step [300/6235], Loss: 0.0057\n",
      "Epoch [2/100], Step [400/6235], Loss: 0.0039\n",
      "Epoch [2/100], Step [500/6235], Loss: 0.2876\n",
      "Epoch [2/100], Step [600/6235], Loss: 0.0862\n",
      "Epoch [2/100], Step [700/6235], Loss: 0.1164\n",
      "Epoch [2/100], Step [800/6235], Loss: 0.0567\n",
      "Epoch [2/100], Step [900/6235], Loss: 0.0082\n",
      "Epoch [2/100], Step [1000/6235], Loss: 0.0109\n",
      "Epoch [2/100], Step [1100/6235], Loss: 0.0682\n",
      "Epoch [2/100], Step [1200/6235], Loss: 0.4605\n",
      "Epoch [2/100], Step [1300/6235], Loss: 0.0600\n",
      "Epoch [2/100], Step [1400/6235], Loss: 0.0217\n",
      "Epoch [2/100], Step [1500/6235], Loss: 0.0017\n",
      "Epoch [2/100], Step [1600/6235], Loss: 0.4061\n",
      "Epoch [2/100], Step [1700/6235], Loss: 0.0915\n",
      "Epoch [2/100], Step [1800/6235], Loss: 0.0270\n",
      "Epoch [2/100], Step [1900/6235], Loss: 0.1192\n",
      "Epoch [2/100], Step [2000/6235], Loss: 0.7289\n",
      "Epoch [2/100], Step [2100/6235], Loss: 0.2871\n",
      "Epoch [2/100], Step [2200/6235], Loss: 0.1964\n",
      "Epoch [2/100], Step [2300/6235], Loss: 8.7681\n",
      "Epoch [2/100], Step [2400/6235], Loss: 9.9493\n",
      "Epoch [2/100], Step [2500/6235], Loss: 37.8466\n",
      "Epoch [2/100], Step [2600/6235], Loss: 2.7295\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Step [2700/6235], Loss: 52.1671\n",
      "Epoch [2/100], Step [2800/6235], Loss: 105.7661\n",
      "Epoch [2/100], Step [2900/6235], Loss: 8.2305\n",
      "Epoch [2/100], Step [3000/6235], Loss: 7.4818\n",
      "Epoch [2/100], Step [3100/6235], Loss: 44.2616\n",
      "Epoch [2/100], Step [3200/6235], Loss: 19.5237\n",
      "Epoch [2/100], Step [3300/6235], Loss: 1.0932\n",
      "Epoch [2/100], Step [3400/6235], Loss: 2.5474\n",
      "Epoch [2/100], Step [3500/6235], Loss: 2.1452\n",
      "Epoch [2/100], Step [3600/6235], Loss: 13.4662\n",
      "Epoch [2/100], Step [3700/6235], Loss: 0.3592\n",
      "Epoch [2/100], Step [3800/6235], Loss: 0.0099\n",
      "Epoch [2/100], Step [3900/6235], Loss: 0.0340\n",
      "Epoch [2/100], Step [4000/6235], Loss: 0.0396\n",
      "Epoch [2/100], Step [4100/6235], Loss: 0.1954\n",
      "Epoch [2/100], Step [4200/6235], Loss: 1.2354\n",
      "Epoch [2/100], Step [4300/6235], Loss: 0.8732\n",
      "Epoch [2/100], Step [4400/6235], Loss: 0.6032\n",
      "Epoch [2/100], Step [4500/6235], Loss: 11.7346\n",
      "Epoch [2/100], Step [4600/6235], Loss: 13.3322\n",
      "Epoch [2/100], Step [4700/6235], Loss: 0.5139\n",
      "Epoch [2/100], Step [4800/6235], Loss: 2.2562\n",
      "Epoch [2/100], Step [4900/6235], Loss: 0.1494\n",
      "Epoch [2/100], Step [5000/6235], Loss: 1.3514\n",
      "Epoch [2/100], Step [5100/6235], Loss: 27.0102\n",
      "Epoch [2/100], Step [5200/6235], Loss: 0.1785\n",
      "Epoch [2/100], Step [5300/6235], Loss: 0.3989\n",
      "Epoch [2/100], Step [5400/6235], Loss: 0.1775\n",
      "Epoch [2/100], Step [5500/6235], Loss: 1.0666\n",
      "Epoch [2/100], Step [5600/6235], Loss: 0.1480\n",
      "Epoch [2/100], Step [5700/6235], Loss: 0.7883\n",
      "Epoch [2/100], Step [5800/6235], Loss: 0.5193\n",
      "Epoch [2/100], Step [5900/6235], Loss: 0.0333\n",
      "Epoch [2/100], Step [6000/6235], Loss: 0.2282\n",
      "Epoch [2/100], Step [6100/6235], Loss: 0.0086\n",
      "Epoch [2/100], Step [6200/6235], Loss: 0.0581\n",
      "Epoch [2/100], Step [6300/6235], Loss: 0.0741\n",
      "Epoch [2/100], Step [6400/6235], Loss: 0.0613\n",
      "Epoch [2/100], Step [6500/6235], Loss: 2.3029\n",
      "Epoch [2/100], Step [6600/6235], Loss: 0.3907\n",
      "Epoch [2/100], Step [6700/6235], Loss: 0.2733\n",
      "Epoch [2/100], Step [6800/6235], Loss: 2.5891\n",
      "Epoch [2/100], Step [6900/6235], Loss: 5.7122\n",
      "Epoch [2/100], Step [7000/6235], Loss: 0.0925\n",
      "Epoch [2/100], Step [7100/6235], Loss: 0.1598\n",
      "Epoch [2/100], Step [7200/6235], Loss: 0.1529\n",
      "Epoch [2/100], Step [7300/6235], Loss: 0.4352\n",
      "Epoch [2/100], Step [7400/6235], Loss: 0.0504\n",
      "Epoch [2/100], Step [7500/6235], Loss: 18.3126\n",
      "Epoch [2/100], Step [7600/6235], Loss: 9.0059\n",
      "Epoch [2/100], Step [7700/6235], Loss: 0.9007\n",
      "Epoch [2/100], Step [7800/6235], Loss: 0.9961\n",
      "Epoch [2/100], Step [7900/6235], Loss: 1.1885\n",
      "Epoch [2/100], Step [8000/6235], Loss: 0.7278\n",
      "Epoch [2/100], Step [8100/6235], Loss: 1.3002\n",
      "Epoch [2/100], Step [8200/6235], Loss: 7.2482\n",
      "Epoch [2/100], Step [8300/6235], Loss: 18.8586\n",
      "Epoch [2/100], Step [8400/6235], Loss: 23.5666\n",
      "Epoch [2/100], Step [8500/6235], Loss: 48.8262\n",
      "Epoch [2/100], Step [8600/6235], Loss: 1.4117\n",
      "Epoch [2/100], Step [8700/6235], Loss: 98.4535\n",
      "Epoch [2/100], Step [8800/6235], Loss: 4558.2905\n",
      "Epoch [2/100], Step [8900/6235], Loss: 33.6179\n",
      "Epoch [2/100], Step [9000/6235], Loss: 497.8450\n",
      "Epoch [2/100], Step [9100/6235], Loss: 1272.1512\n",
      "Epoch [2/100], Step [9200/6235], Loss: 425.4047\n",
      "Epoch [2/100], Step [9300/6235], Loss: 16.6117\n",
      "Epoch [2/100], Step [9400/6235], Loss: 19.5078\n",
      "Epoch [2/100], Step [9500/6235], Loss: 618.6461\n",
      "Epoch [2/100], Step [9600/6235], Loss: 586.9937\n",
      "Epoch [2/100], Step [9700/6235], Loss: 6.2488\n",
      "Epoch [2/100], Step [9800/6235], Loss: 149.6749\n",
      "Epoch [2/100], Step [9900/6235], Loss: 5.1680\n",
      "Epoch [2/100], Step [10000/6235], Loss: 18.0587\n",
      "Epoch [2/100], Step [10100/6235], Loss: 84.4886\n",
      "Epoch [2/100], Step [10200/6235], Loss: 1107.6338\n",
      "Epoch [2/100], Step [10300/6235], Loss: 47.9432\n",
      "Epoch [2/100], Step [10400/6235], Loss: 8.4340\n",
      "Epoch [2/100], Step [10500/6235], Loss: 11.4673\n",
      "Epoch [2/100], Step [10600/6235], Loss: 285.0704\n",
      "Epoch [2/100], Step [10700/6235], Loss: 36.1434\n",
      "Epoch [2/100], Step [10800/6235], Loss: 570.9977\n",
      "Epoch [2/100], Step [10900/6235], Loss: 24.3451\n",
      "Epoch [2/100], Step [11000/6235], Loss: 32.7909\n",
      "Epoch [2/100], Step [11100/6235], Loss: 111.7230\n",
      "Epoch [2/100], Step [11200/6235], Loss: 40.4849\n",
      "Epoch [2/100], Step [11300/6235], Loss: 2.2416\n",
      "Epoch [2/100], Step [11400/6235], Loss: 81.3942\n",
      "Epoch [2/100], Step [11500/6235], Loss: 11.5463\n",
      "Epoch [2/100], Step [11600/6235], Loss: 0.6799\n",
      "Epoch [2/100], Step [11700/6235], Loss: 60.1436\n",
      "Epoch [2/100], Step [11800/6235], Loss: 224.2466\n",
      "Epoch [2/100], Step [11900/6235], Loss: 992.6388\n",
      "Epoch [2/100], Step [12000/6235], Loss: 91.0399\n",
      "Epoch [2/100], Step [12100/6235], Loss: 599.2827\n",
      "Epoch [2/100], Step [12200/6235], Loss: 104.0963\n",
      "Epoch [2/100], Step [12300/6235], Loss: 38.9877\n",
      "Epoch [2/100], Step [12400/6235], Loss: 238.0968\n",
      "Epoch [2/100], Step [12500/6235], Loss: 200.3896\n",
      "Epoch [2/100], Step [12600/6235], Loss: 54.9532\n",
      "Epoch [2/100], Step [12700/6235], Loss: 16.8043\n",
      "Epoch [2/100], Step [12800/6235], Loss: 1.1036\n",
      "Epoch [2/100], Step [12900/6235], Loss: 18.4351\n",
      "Epoch [2/100], Step [13000/6235], Loss: 9.3251\n",
      "Epoch [2/100], Step [13100/6235], Loss: 8.8834\n",
      "Epoch [2/100], Step [13200/6235], Loss: 36.2754\n",
      "Epoch [2/100], Step [13300/6235], Loss: 17.0606\n",
      "Epoch [2/100], Step [13400/6235], Loss: 1.9428\n",
      "Epoch [2/100], Step [13500/6235], Loss: 0.3374\n",
      "Epoch [2/100], Step [13600/6235], Loss: 50.7350\n",
      "Epoch [2/100], Step [13700/6235], Loss: 195.6129\n",
      "Epoch [2/100], Step [13800/6235], Loss: 124.1330\n",
      "Epoch [2/100], Step [13900/6235], Loss: 34.2855\n",
      "Epoch [2/100], Step [14000/6235], Loss: 0.3238\n",
      "Epoch [2/100], Step [14100/6235], Loss: 370.8246\n",
      "Epoch [2/100], Step [14200/6235], Loss: 0.4670\n",
      "Epoch [2/100], Step [14300/6235], Loss: 1.5412\n",
      "Epoch [2/100], Step [14400/6235], Loss: 3.6228\n",
      "Epoch [2/100], Step [14500/6235], Loss: 23.5093\n",
      "Epoch [2/100], Step [14600/6235], Loss: 10.6376\n",
      "Epoch [2/100], Step [14700/6235], Loss: 5.7376\n",
      "Epoch [2/100], Step [14800/6235], Loss: 14.7003\n",
      "Epoch [2/100], Step [14900/6235], Loss: 1.1018\n",
      "Epoch [2/100], Step [15000/6235], Loss: 0.2380\n",
      "Epoch [2/100], Step [15100/6235], Loss: 0.1580\n",
      "Epoch [2/100], Step [15200/6235], Loss: 65.1608\n",
      "Epoch [2/100], Step [15300/6235], Loss: 166.0695\n",
      "Epoch [2/100], Step [15400/6235], Loss: 31.6899\n",
      "Epoch [2/100], Step [15500/6235], Loss: 3.3393\n",
      "Epoch [2/100], Step [15600/6235], Loss: 170.1868\n",
      "Epoch [2/100], Step [15700/6235], Loss: 76.2768\n",
      "Epoch [2/100], Step [15800/6235], Loss: 1.7411\n",
      "Epoch [2/100], Step [15900/6235], Loss: 6.4706\n",
      "Epoch [2/100], Step [16000/6235], Loss: 1.3409\n",
      "Epoch [2/100], Step [16100/6235], Loss: 19.9824\n",
      "Epoch [2/100], Step [16200/6235], Loss: 26.2590\n",
      "Epoch [2/100], Step [16300/6235], Loss: 0.6781\n",
      "Epoch [2/100], Step [16400/6235], Loss: 5.8918\n",
      "Epoch [2/100], Step [16500/6235], Loss: 6.2939\n",
      "Epoch [2/100], Step [16600/6235], Loss: 0.8049\n",
      "Epoch [2/100], Step [16700/6235], Loss: 0.9381\n",
      "Epoch [2/100], Step [16800/6235], Loss: 13.0196\n",
      "Epoch [2/100], Step [16900/6235], Loss: 37.3498\n",
      "Epoch [2/100], Step [17000/6235], Loss: 0.5655\n",
      "Epoch [2/100], Step [17100/6235], Loss: 1.4060\n",
      "Epoch [2/100], Step [17200/6235], Loss: 6.8679\n",
      "Epoch [2/100], Step [17300/6235], Loss: 0.2574\n",
      "Epoch [2/100], Step [17400/6235], Loss: 71.2263\n",
      "Epoch [2/100], Step [17500/6235], Loss: 4.8063\n",
      "Epoch [2/100], Step [17600/6235], Loss: 1.2549\n",
      "Epoch [2/100], Step [17700/6235], Loss: 5.0507\n",
      "Epoch [2/100], Step [17800/6235], Loss: 42.1245\n",
      "Epoch [2/100], Step [17900/6235], Loss: 36.1796\n",
      "Epoch [2/100], Step [18000/6235], Loss: 17.4545\n",
      "Epoch [2/100], Step [18100/6235], Loss: 0.1906\n",
      "Epoch [2/100], Step [18200/6235], Loss: 2.3187\n",
      "Epoch [2/100], Step [18300/6235], Loss: 0.7792\n",
      "Epoch [2/100], Step [18400/6235], Loss: 0.3270\n",
      "Epoch [2/100], Step [18500/6235], Loss: 6.4799\n",
      "Epoch [2/100], Step [18600/6235], Loss: 5.6224\n",
      "Epoch [2/100], Step [18700/6235], Loss: 3.7585\n",
      "Epoch [2/100], Step [18800/6235], Loss: 102.7188\n",
      "Epoch [2/100], Step [18900/6235], Loss: 5.9118\n",
      "Epoch [2/100], Step [19000/6235], Loss: 1.9378\n",
      "Epoch [2/100], Step [19100/6235], Loss: 1.6509\n",
      "Epoch [2/100], Step [19200/6235], Loss: 4.8044\n",
      "Epoch [2/100], Step [19300/6235], Loss: 0.1970\n",
      "Epoch [2/100], Step [19400/6235], Loss: 158.2251\n",
      "Epoch [2/100], Step [19500/6235], Loss: 208.7378\n",
      "Epoch [2/100], Step [19600/6235], Loss: 121.1269\n",
      "Epoch [2/100], Step [19700/6235], Loss: 20.3568\n",
      "Epoch [2/100], Step [19800/6235], Loss: 25.0580\n",
      "Epoch [2/100], Step [19900/6235], Loss: 14.1687\n",
      "Epoch [2/100], Step [20000/6235], Loss: 75.7017\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Step [20100/6235], Loss: 0.2320\n",
      "Epoch [2/100], Step [20200/6235], Loss: 5.8935\n",
      "Epoch [2/100], Step [20300/6235], Loss: 0.1472\n",
      "Epoch [2/100], Step [20400/6235], Loss: 16.1445\n",
      "Epoch [2/100], Step [20500/6235], Loss: 8.6337\n",
      "Epoch [2/100], Step [20600/6235], Loss: 117.0963\n",
      "Epoch [2/100], Step [20700/6235], Loss: 6.4112\n",
      "Epoch [2/100], Step [20800/6235], Loss: 18.4003\n",
      "Epoch [2/100], Step [20900/6235], Loss: 22.5424\n",
      "Epoch [2/100], Step [21000/6235], Loss: 1.4978\n",
      "Epoch [2/100], Step [21100/6235], Loss: 0.2525\n",
      "Epoch [2/100], Step [21200/6235], Loss: 40.8741\n",
      "Epoch [2/100], Step [21300/6235], Loss: 0.3746\n",
      "Epoch [2/100], Step [21400/6235], Loss: 0.4735\n",
      "Epoch [2/100], Step [21500/6235], Loss: 0.0785\n",
      "Epoch [2/100], Step [21600/6235], Loss: 18.5154\n",
      "Epoch [2/100], Step [21700/6235], Loss: 1.0322\n",
      "Epoch [2/100], Step [21800/6235], Loss: 45.4503\n",
      "Epoch [2/100], Step [21900/6235], Loss: 9.0990\n",
      "Epoch [2/100], Step [22000/6235], Loss: 3.8240\n",
      "Epoch [2/100], Step [22100/6235], Loss: 6.1347\n",
      "Epoch [2/100], Step [22200/6235], Loss: 7.2961\n",
      "Epoch [2/100], Step [22300/6235], Loss: 9.2489\n",
      "Epoch [2/100], Step [22400/6235], Loss: 0.1111\n",
      "Epoch [2/100], Step [22500/6235], Loss: 149.8815\n",
      "Epoch [2/100], Step [22600/6235], Loss: 24.8867\n",
      "Epoch [2/100], Step [22700/6235], Loss: 2.3308\n",
      "Epoch [2/100], Step [22800/6235], Loss: 2.5097\n",
      "Epoch [2/100], Step [22900/6235], Loss: 21.4091\n",
      "Epoch [2/100], Step [23000/6235], Loss: 0.4115\n",
      "Epoch [2/100], Step [23100/6235], Loss: 6.8216\n",
      "Epoch [2/100], Step [23200/6235], Loss: 48.5066\n",
      "Epoch [2/100], Step [23300/6235], Loss: 13.5053\n",
      "Epoch [2/100], Step [23400/6235], Loss: 0.0608\n",
      "Epoch [2/100], Step [23500/6235], Loss: 0.4961\n",
      "Epoch [2/100], Step [23600/6235], Loss: 7.4102\n",
      "Epoch [2/100], Step [23700/6235], Loss: 7.5296\n",
      "Epoch [2/100], Step [23800/6235], Loss: 1.1111\n",
      "Epoch [2/100], Step [23900/6235], Loss: 1.2761\n",
      "Epoch [2/100], Step [24000/6235], Loss: 22.1458\n",
      "Epoch [2/100], Step [24100/6235], Loss: 0.1425\n",
      "Epoch [2/100], Step [24200/6235], Loss: 0.5657\n",
      "Epoch [2/100], Step [24300/6235], Loss: 3.4157\n",
      "Epoch [2/100], Step [24400/6235], Loss: 1.7724\n",
      "Epoch [2/100], Step [24500/6235], Loss: 5.1895\n",
      "Epoch [2/100], Step [24600/6235], Loss: 1.8443\n",
      "Epoch [2/100], Step [24700/6235], Loss: 22.5012\n",
      "Epoch [2/100], Step [24800/6235], Loss: 4.2437\n",
      "Epoch [2/100], Step [24900/6235], Loss: 9.6313\n",
      "Epoch [2/100], Step [25000/6235], Loss: 5.7890\n",
      "Epoch [2/100], Step [25100/6235], Loss: 10.1223\n",
      "Epoch [2/100], Step [25200/6235], Loss: 0.0085\n",
      "Epoch [2/100], Step [25300/6235], Loss: 2.6282\n",
      "Epoch [2/100], Step [25400/6235], Loss: 1.2628\n",
      "Epoch [2/100], Step [25500/6235], Loss: 1.6243\n",
      "Epoch [2/100], Step [25600/6235], Loss: 0.6146\n",
      "Epoch [2/100], Step [25700/6235], Loss: 0.1478\n",
      "Epoch [2/100], Step [25800/6235], Loss: 0.2513\n",
      "Epoch [2/100], Step [25900/6235], Loss: 4.9032\n",
      "Epoch [2/100], Step [26000/6235], Loss: 5.2649\n",
      "Epoch [2/100], Step [26100/6235], Loss: 0.7412\n",
      "Epoch [2/100], Step [26200/6235], Loss: 2.1296\n",
      "Epoch [2/100], Step [26300/6235], Loss: 6.6249\n",
      "Epoch [2/100], Step [26400/6235], Loss: 0.0772\n",
      "Epoch [2/100], Step [26500/6235], Loss: 1.8452\n",
      "Epoch [2/100], Step [26600/6235], Loss: 1.6683\n",
      "Epoch [2/100], Step [26700/6235], Loss: 0.8369\n",
      "Epoch [2/100], Step [26800/6235], Loss: 5.5462\n",
      "Epoch [2/100], Step [26900/6235], Loss: 0.1149\n",
      "Epoch [2/100], Step [27000/6235], Loss: 1.9417\n",
      "Epoch [2/100], Step [27100/6235], Loss: 0.7374\n",
      "Epoch [2/100], Step [27200/6235], Loss: 0.1839\n",
      "Epoch [2/100], Step [27300/6235], Loss: 0.3132\n",
      "Epoch [2/100], Step [27400/6235], Loss: 0.5884\n",
      "Epoch [2/100], Step [27500/6235], Loss: 24.6465\n",
      "Epoch [2/100], Step [27600/6235], Loss: 1.1515\n",
      "Epoch [2/100], Step [27700/6235], Loss: 0.0422\n",
      "Epoch [2/100], Step [27800/6235], Loss: 1.2124\n",
      "Epoch [2/100], Step [27900/6235], Loss: 0.3950\n",
      "Epoch [2/100], Step [28000/6235], Loss: 207.9249\n",
      "Epoch [2/100], Step [28100/6235], Loss: 2.7304\n",
      "Epoch [2/100], Step [28200/6235], Loss: 37.0162\n",
      "Epoch [2/100], Step [28300/6235], Loss: 0.1150\n",
      "Epoch [2/100], Step [28400/6235], Loss: 0.2376\n",
      "Epoch [2/100], Step [28500/6235], Loss: 0.2536\n",
      "Epoch [2/100], Step [28600/6235], Loss: 1.1870\n",
      "Epoch [2/100], Step [28700/6235], Loss: 0.9974\n",
      "Epoch [2/100], Step [28800/6235], Loss: 0.0628\n",
      "Epoch [2/100], Step [28900/6235], Loss: 3.5282\n",
      "Epoch [2/100], Step [29000/6235], Loss: 0.1253\n",
      "Epoch [2/100], Step [29100/6235], Loss: 4.5616\n",
      "Epoch [2/100], Step [29200/6235], Loss: 0.6675\n",
      "Epoch [2/100], Step [29300/6235], Loss: 2.8044\n",
      "Epoch [2/100], Step [29400/6235], Loss: 2.1565\n",
      "Epoch [2/100], Step [29500/6235], Loss: 4.0194\n",
      "Epoch [2/100], Step [29600/6235], Loss: 0.7807\n",
      "Epoch [2/100], Step [29700/6235], Loss: 0.0556\n",
      "Epoch [2/100], Step [29800/6235], Loss: 0.2847\n",
      "Epoch [2/100], Step [29900/6235], Loss: 2.5198\n",
      "Epoch [2/100], Step [30000/6235], Loss: 0.0133\n",
      "Epoch [2/100], Step [30100/6235], Loss: 1.2802\n",
      "Epoch [2/100], Step [30200/6235], Loss: 1.6166\n",
      "Epoch [2/100], Step [30300/6235], Loss: 2.2581\n",
      "Epoch [2/100], Step [30400/6235], Loss: 0.0881\n",
      "Epoch [2/100], Step [30500/6235], Loss: 0.6931\n",
      "Epoch [2/100], Step [30600/6235], Loss: 0.7432\n",
      "Epoch [2/100], Step [30700/6235], Loss: 0.1997\n",
      "Epoch [2/100], Step [30800/6235], Loss: 0.0826\n",
      "Epoch [2/100], Step [30900/6235], Loss: 0.6931\n",
      "Epoch [2/100], Step [31000/6235], Loss: 0.0609\n",
      "Epoch [2/100], Step [31100/6235], Loss: 10.2415\n",
      "Epoch [2/100], Step [31200/6235], Loss: 1.7775\n",
      "Epoch [2/100], Step [31300/6235], Loss: 0.0564\n",
      "Epoch [2/100], Step [31400/6235], Loss: 3.1417\n",
      "Epoch [2/100], Step [31500/6235], Loss: 0.6278\n",
      "Epoch [2/100], Step [31600/6235], Loss: 0.6147\n",
      "Epoch [2/100], Step [31700/6235], Loss: 55.5412\n",
      "Epoch [2/100], Step [31800/6235], Loss: 0.6702\n",
      "Epoch [2/100], Step [31900/6235], Loss: 987.3790\n",
      "Epoch [2/100], Step [32000/6235], Loss: 162.3243\n",
      "Epoch [2/100], Step [32100/6235], Loss: 0.8109\n",
      "Epoch [2/100], Step [32200/6235], Loss: 1.8661\n",
      "Epoch [2/100], Step [32300/6235], Loss: 9.2014\n",
      "Epoch [2/100], Step [32400/6235], Loss: 2.0304\n",
      "Epoch [2/100], Step [32500/6235], Loss: 0.0752\n",
      "Epoch [2/100], Step [32600/6235], Loss: 0.0050\n",
      "Epoch [2/100], Step [32700/6235], Loss: 374.0507\n",
      "Epoch [2/100], Step [32800/6235], Loss: 38.2127\n",
      "Epoch [2/100], Step [32900/6235], Loss: 54.6375\n",
      "Epoch [2/100], Step [33000/6235], Loss: 1.6850\n",
      "Epoch [2/100], Step [33100/6235], Loss: 1.5551\n",
      "Epoch [2/100], Step [33200/6235], Loss: 0.4572\n",
      "Epoch [2/100], Step [33300/6235], Loss: 0.7717\n",
      "Epoch [2/100], Step [33400/6235], Loss: 87.8215\n",
      "Epoch [2/100], Step [33500/6235], Loss: 2.3702\n",
      "Epoch [2/100], Step [33600/6235], Loss: 5.0446\n",
      "Epoch [2/100], Step [33700/6235], Loss: 15.6688\n",
      "Epoch [2/100], Step [33800/6235], Loss: 16.2909\n",
      "Epoch [2/100], Step [33900/6235], Loss: 4.3639\n",
      "Epoch [2/100], Step [34000/6235], Loss: 0.2583\n",
      "Epoch [2/100], Step [34100/6235], Loss: 0.2355\n",
      "Epoch [2/100], Step [34200/6235], Loss: 52.6115\n",
      "Epoch [2/100], Step [34300/6235], Loss: 8.1015\n",
      "Epoch [2/100], Step [34400/6235], Loss: 0.2055\n",
      "Epoch [2/100], Step [34500/6235], Loss: 86.5396\n",
      "Epoch [2/100], Step [34600/6235], Loss: 8.4967\n",
      "Epoch [2/100], Step [34700/6235], Loss: 52.1157\n",
      "Epoch [2/100], Step [34800/6235], Loss: 1.5317\n",
      "Epoch [2/100], Step [34900/6235], Loss: 0.0183\n",
      "Epoch [2/100], Step [35000/6235], Loss: 0.2198\n",
      "Epoch [2/100], Step [35100/6235], Loss: 0.8440\n",
      "Epoch [2/100], Step [35200/6235], Loss: 7.3714\n",
      "Epoch [2/100], Step [35300/6235], Loss: 0.1167\n",
      "Epoch [2/100], Step [35400/6235], Loss: 2.4621\n",
      "Epoch [2/100], Step [35500/6235], Loss: 9.0852\n",
      "Epoch [2/100], Step [35600/6235], Loss: 5.7214\n",
      "Epoch [2/100], Step [35700/6235], Loss: 2.1064\n",
      "Epoch [2/100], Step [35800/6235], Loss: 19.8039\n",
      "Epoch [2/100], Step [35900/6235], Loss: 17.5419\n",
      "Epoch [2/100], Step [36000/6235], Loss: 10.4346\n",
      "Epoch [2/100], Step [36100/6235], Loss: 0.5588\n",
      "Epoch [2/100], Step [36200/6235], Loss: 2.5415\n",
      "Epoch [2/100], Step [36300/6235], Loss: 1.9040\n",
      "Epoch [2/100], Step [36400/6235], Loss: 0.3668\n",
      "Epoch [2/100], Step [36500/6235], Loss: 6.0307\n",
      "Epoch [2/100], Step [36600/6235], Loss: 0.4982\n",
      "Epoch [2/100], Step [36700/6235], Loss: 0.1639\n",
      "Epoch [2/100], Step [36800/6235], Loss: 16.8227\n",
      "Epoch [2/100], Step [36900/6235], Loss: 3.1726\n",
      "Epoch [2/100], Step [37000/6235], Loss: 0.2041\n",
      "Epoch [2/100], Step [37100/6235], Loss: 1.6784\n",
      "Epoch [2/100], Step [37200/6235], Loss: 0.0638\n",
      "Epoch [2/100], Step [37300/6235], Loss: 0.2938\n",
      "Epoch [2/100], Step [37400/6235], Loss: 0.5554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/100], Step [37500/6235], Loss: 2.7063\n",
      "Epoch [2/100], Step [37600/6235], Loss: 1.0668\n",
      "Epoch [2/100], Step [37700/6235], Loss: 4.6281\n",
      "Epoch [2/100], Step [37800/6235], Loss: 8.1385\n",
      "Epoch [2/100], Step [37900/6235], Loss: 0.3218\n",
      "Epoch [2/100], Step [38000/6235], Loss: 1.4517\n",
      "Epoch [2/100], Step [38100/6235], Loss: 3.3171\n",
      "Epoch [2/100], Step [38200/6235], Loss: 0.2285\n",
      "Epoch [2/100], Step [38300/6235], Loss: 5.9507\n",
      "Epoch [2/100], Step [38400/6235], Loss: 0.2003\n",
      "Epoch [2/100], Step [38500/6235], Loss: 0.5963\n",
      "Epoch [2/100], Step [38600/6235], Loss: 0.2050\n",
      "Epoch [2/100], Step [38700/6235], Loss: 0.0386\n",
      "Epoch [2/100], Step [38800/6235], Loss: 4.3470\n",
      "Epoch [2/100], Step [38900/6235], Loss: 122.4939\n",
      "Epoch [2/100], Step [39000/6235], Loss: 16.0020\n",
      "Epoch [2/100], Step [39100/6235], Loss: 12.8287\n",
      "Epoch [2/100], Step [39200/6235], Loss: 0.5479\n",
      "Epoch [2/100], Step [39300/6235], Loss: 14.4049\n",
      "Epoch [2/100], Step [39400/6235], Loss: 146.0231\n",
      "Epoch [2/100], Step [39500/6235], Loss: 46.6554\n",
      "Epoch [2/100], Step [39600/6235], Loss: 28.2177\n",
      "Epoch [2/100], Step [39700/6235], Loss: 323.9442\n",
      "Epoch [2/100], Step [39800/6235], Loss: 80.1970\n",
      "Epoch [2/100], Step [39900/6235], Loss: 69.2816\n",
      "Epoch [2/100], Step [40000/6235], Loss: 234.7038\n",
      "Epoch [2/100], Step [40100/6235], Loss: 1.8930\n",
      "Epoch [2/100], Step [40200/6235], Loss: 168.7317\n",
      "Epoch [2/100], Step [40300/6235], Loss: 5.3472\n",
      "Epoch [2/100], Step [40400/6235], Loss: 126.7298\n",
      "Epoch [2/100], Step [40500/6235], Loss: 0.3866\n",
      "Epoch [2/100], Step [40600/6235], Loss: 17.4989\n",
      "Epoch [2/100], Step [40700/6235], Loss: 1.7645\n",
      "Epoch [2/100], Step [40800/6235], Loss: 4.7241\n",
      "Epoch [2/100], Step [40900/6235], Loss: 0.1005\n",
      "Epoch [2/100], Step [41000/6235], Loss: 14.0907\n",
      "Epoch [2/100], Step [41100/6235], Loss: 16.7300\n",
      "Epoch [2/100], Step [41200/6235], Loss: 28.2155\n",
      "Epoch [2/100], Step [41300/6235], Loss: 3.5749\n",
      "Epoch [2/100], Step [41400/6235], Loss: 1.0077\n",
      "Epoch [2/100], Step [41500/6235], Loss: 0.4850\n",
      "Epoch [2/100], Step [41600/6235], Loss: 4.3611\n",
      "Epoch [2/100], Step [41700/6235], Loss: 4.2083\n",
      "Epoch [2/100], Step [41800/6235], Loss: 20.0406\n",
      "Epoch [2/100], Step [41900/6235], Loss: 2.3640\n",
      "Epoch [2/100], Step [42000/6235], Loss: 11.8459\n",
      "Epoch [2/100], Step [42100/6235], Loss: 0.2073\n",
      "Epoch [2/100], Step [42200/6235], Loss: 108.7193\n",
      "Epoch [2/100], Step [42300/6235], Loss: 5.1348\n",
      "Epoch [2/100], Step [42400/6235], Loss: 1.4466\n",
      "Epoch [2/100], Step [42500/6235], Loss: 0.5372\n",
      "Epoch [2/100], Step [42600/6235], Loss: 0.5951\n",
      "Epoch [2/100], Step [42700/6235], Loss: 3.6243\n",
      "Epoch [2/100], Step [42800/6235], Loss: 0.1640\n",
      "Epoch [2/100], Step [42900/6235], Loss: 3.3333\n",
      "Epoch [2/100], Step [43000/6235], Loss: 2.7077\n",
      "Epoch [2/100], Step [43100/6235], Loss: 1.9764\n",
      "Epoch [2/100], Step [43200/6235], Loss: 0.2583\n",
      "Epoch [2/100], Step [43300/6235], Loss: 0.9693\n",
      "Epoch [2/100], Step [43400/6235], Loss: 7.3622\n",
      "Epoch [2/100], Step [43500/6235], Loss: 1.5106\n",
      "Epoch [2/100], Step [43600/6235], Loss: 4.4760\n",
      "Epoch [2/100], Step [43700/6235], Loss: 42.8189\n",
      "Epoch [2/100], Step [43800/6235], Loss: 0.1730\n",
      "Epoch [2/100], Step [43900/6235], Loss: 4.4470\n",
      "Epoch [2/100], Step [44000/6235], Loss: 29.4682\n",
      "Epoch [2/100], Step [44100/6235], Loss: 0.9441\n",
      "Epoch [2/100], Step [44200/6235], Loss: 10.8517\n",
      "Epoch [2/100], Step [44300/6235], Loss: 61.7947\n",
      "Epoch [2/100], Step [44400/6235], Loss: 0.7797\n",
      "Epoch [2/100], Step [44500/6235], Loss: 3.1713\n",
      "Epoch [2/100], Step [44600/6235], Loss: 0.2610\n",
      "Epoch [2/100], Step [44700/6235], Loss: 0.6026\n",
      "Epoch [2/100], Step [44800/6235], Loss: 0.2316\n",
      "Epoch [2/100], Step [44900/6235], Loss: 3.0593\n",
      "Epoch [2/100], Step [45000/6235], Loss: 0.1812\n",
      "Epoch [2/100], Step [45100/6235], Loss: 8.0437\n",
      "Epoch [2/100], Step [45200/6235], Loss: 0.1935\n",
      "Epoch [2/100], Step [45300/6235], Loss: 12.4580\n",
      "Epoch [2/100], Step [45400/6235], Loss: 34.1705\n",
      "Epoch [2/100], Step [45500/6235], Loss: 0.1877\n",
      "Epoch [2/100], Step [45600/6235], Loss: 1.8940\n",
      "Epoch [2/100], Step [45700/6235], Loss: 123.7804\n",
      "Epoch [2/100], Step [45800/6235], Loss: 697.3820\n",
      "Epoch [2/100], Step [45900/6235], Loss: 29.7182\n",
      "Epoch [2/100], Step [46000/6235], Loss: 217.6847\n",
      "Epoch [2/100], Step [46100/6235], Loss: 182.2890\n",
      "Epoch [2/100], Step [46200/6235], Loss: 42.1367\n",
      "Epoch [2/100], Step [46300/6235], Loss: 73.3781\n",
      "Epoch [2/100], Step [46400/6235], Loss: 1.7536\n",
      "Epoch [2/100], Step [46500/6235], Loss: 1.6485\n",
      "Epoch [2/100], Step [46600/6235], Loss: 13.1889\n",
      "Epoch [2/100], Step [46700/6235], Loss: 55.4887\n",
      "Epoch [2/100], Step [46800/6235], Loss: 83.3482\n",
      "Epoch [2/100], Step [46900/6235], Loss: 43.1669\n",
      "Epoch [2/100], Step [47000/6235], Loss: 5.0492\n",
      "Epoch [2/100], Step [47100/6235], Loss: 113.9948\n",
      "Epoch [2/100], Step [47200/6235], Loss: 16.4592\n",
      "Epoch [2/100], Step [47300/6235], Loss: 2.5985\n",
      "Epoch [2/100], Step [47400/6235], Loss: 327.4347\n",
      "Epoch [2/100], Step [47500/6235], Loss: 10.8252\n",
      "Epoch [2/100], Step [47600/6235], Loss: 7.1460\n",
      "Epoch [2/100], Step [47700/6235], Loss: 97.5246\n",
      "Epoch [2/100], Step [47800/6235], Loss: 25.4532\n",
      "Epoch [2/100], Step [47900/6235], Loss: 21.9130\n",
      "Epoch [2/100], Step [48000/6235], Loss: 65.8118\n",
      "Epoch [2/100], Step [48100/6235], Loss: 62.5322\n",
      "Epoch [2/100], Step [48200/6235], Loss: 100.0098\n",
      "Epoch [2/100], Step [48300/6235], Loss: 906.1252\n",
      "Epoch [2/100], Step [48400/6235], Loss: 30.4606\n",
      "Epoch [2/100], Step [48500/6235], Loss: 13.0424\n",
      "Epoch [2/100], Step [48600/6235], Loss: 36.8592\n",
      "Epoch [2/100], Step [48700/6235], Loss: 22.5722\n",
      "Epoch [2/100], Step [48800/6235], Loss: 961.9247\n",
      "Epoch [2/100], Step [48900/6235], Loss: 668.7856\n",
      "Epoch [2/100], Step [49000/6235], Loss: 196.1511\n",
      "Epoch [2/100], Step [49100/6235], Loss: 587.8217\n",
      "Epoch [2/100], Step [49200/6235], Loss: 666.5807\n",
      "Epoch [2/100], Step [49300/6235], Loss: 728.1010\n",
      "Epoch [2/100], Step [49400/6235], Loss: 9.4872\n",
      "Epoch [2/100], Step [49500/6235], Loss: 18.9026\n",
      "Epoch [2/100], Step [49600/6235], Loss: 68.8545\n",
      "Epoch [2/100], Step [49700/6235], Loss: 195.0267\n",
      "Epoch [2/100], Step [49800/6235], Loss: 22.6087\n",
      "Epoch [3/100], Step [100/6235], Loss: 10.8352\n",
      "Epoch [3/100], Step [200/6235], Loss: 0.1519\n",
      "Epoch [3/100], Step [300/6235], Loss: 0.0049\n",
      "Epoch [3/100], Step [400/6235], Loss: 0.0020\n",
      "Epoch [3/100], Step [500/6235], Loss: 1.8428\n",
      "Epoch [3/100], Step [600/6235], Loss: 0.0761\n",
      "Epoch [3/100], Step [700/6235], Loss: 0.1323\n",
      "Epoch [3/100], Step [800/6235], Loss: 0.0324\n",
      "Epoch [3/100], Step [900/6235], Loss: 0.0125\n",
      "Epoch [3/100], Step [1000/6235], Loss: 0.0071\n",
      "Epoch [3/100], Step [1100/6235], Loss: 0.0503\n",
      "Epoch [3/100], Step [1200/6235], Loss: 0.1894\n",
      "Epoch [3/100], Step [1300/6235], Loss: 0.0216\n",
      "Epoch [3/100], Step [1400/6235], Loss: 0.0494\n",
      "Epoch [3/100], Step [1500/6235], Loss: 0.0013\n",
      "Epoch [3/100], Step [1600/6235], Loss: 0.3725\n",
      "Epoch [3/100], Step [1700/6235], Loss: 0.0170\n",
      "Epoch [3/100], Step [1800/6235], Loss: 0.0675\n",
      "Epoch [3/100], Step [1900/6235], Loss: 0.0084\n",
      "Epoch [3/100], Step [2000/6235], Loss: 1.4662\n",
      "Epoch [3/100], Step [2100/6235], Loss: 1.6978\n",
      "Epoch [3/100], Step [2200/6235], Loss: 0.2573\n",
      "Epoch [3/100], Step [2300/6235], Loss: 1.2442\n",
      "Epoch [3/100], Step [2400/6235], Loss: 35.1637\n",
      "Epoch [3/100], Step [2500/6235], Loss: 46.5051\n",
      "Epoch [3/100], Step [2600/6235], Loss: 2.5670\n",
      "Epoch [3/100], Step [2700/6235], Loss: 14.0865\n",
      "Epoch [3/100], Step [2800/6235], Loss: 61.4732\n",
      "Epoch [3/100], Step [2900/6235], Loss: 12.0193\n",
      "Epoch [3/100], Step [3000/6235], Loss: 10.1884\n",
      "Epoch [3/100], Step [3100/6235], Loss: 71.7773\n",
      "Epoch [3/100], Step [3200/6235], Loss: 1.0186\n",
      "Epoch [3/100], Step [3300/6235], Loss: 9.0616\n",
      "Epoch [3/100], Step [3400/6235], Loss: 17.5293\n",
      "Epoch [3/100], Step [3500/6235], Loss: 123.5140\n",
      "Epoch [3/100], Step [3600/6235], Loss: 5.1317\n",
      "Epoch [3/100], Step [3700/6235], Loss: 0.8700\n",
      "Epoch [3/100], Step [3800/6235], Loss: 0.7212\n",
      "Epoch [3/100], Step [3900/6235], Loss: 2.8098\n",
      "Epoch [3/100], Step [4000/6235], Loss: 0.2172\n",
      "Epoch [3/100], Step [4100/6235], Loss: 3.0846\n",
      "Epoch [3/100], Step [4200/6235], Loss: 0.1864\n",
      "Epoch [3/100], Step [4300/6235], Loss: 2.3813\n",
      "Epoch [3/100], Step [4400/6235], Loss: 0.1295\n",
      "Epoch [3/100], Step [4500/6235], Loss: 29.5313\n",
      "Epoch [3/100], Step [4600/6235], Loss: 7.9719\n",
      "Epoch [3/100], Step [4700/6235], Loss: 2.7165\n",
      "Epoch [3/100], Step [4800/6235], Loss: 2.2153\n",
      "Epoch [3/100], Step [4900/6235], Loss: 1.1272\n",
      "Epoch [3/100], Step [5000/6235], Loss: 0.0300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Step [5100/6235], Loss: 2.5681\n",
      "Epoch [3/100], Step [5200/6235], Loss: 4.3853\n",
      "Epoch [3/100], Step [5300/6235], Loss: 0.1673\n",
      "Epoch [3/100], Step [5400/6235], Loss: 0.0967\n",
      "Epoch [3/100], Step [5500/6235], Loss: 0.6217\n",
      "Epoch [3/100], Step [5600/6235], Loss: 0.4521\n",
      "Epoch [3/100], Step [5700/6235], Loss: 0.2736\n",
      "Epoch [3/100], Step [5800/6235], Loss: 0.7133\n",
      "Epoch [3/100], Step [5900/6235], Loss: 0.1345\n",
      "Epoch [3/100], Step [6000/6235], Loss: 0.1767\n",
      "Epoch [3/100], Step [6100/6235], Loss: 0.6540\n",
      "Epoch [3/100], Step [6200/6235], Loss: 3.0591\n",
      "Epoch [3/100], Step [6300/6235], Loss: 0.1553\n",
      "Epoch [3/100], Step [6400/6235], Loss: 0.3516\n",
      "Epoch [3/100], Step [6500/6235], Loss: 0.0413\n",
      "Epoch [3/100], Step [6600/6235], Loss: 3.9403\n",
      "Epoch [3/100], Step [6700/6235], Loss: 0.1795\n",
      "Epoch [3/100], Step [6800/6235], Loss: 2.0934\n",
      "Epoch [3/100], Step [6900/6235], Loss: 1.2029\n",
      "Epoch [3/100], Step [7000/6235], Loss: 0.8544\n",
      "Epoch [3/100], Step [7100/6235], Loss: 0.4098\n",
      "Epoch [3/100], Step [7200/6235], Loss: 0.8207\n",
      "Epoch [3/100], Step [7300/6235], Loss: 0.9292\n",
      "Epoch [3/100], Step [7400/6235], Loss: 0.0279\n",
      "Epoch [3/100], Step [7500/6235], Loss: 1.4811\n",
      "Epoch [3/100], Step [7600/6235], Loss: 2.4941\n",
      "Epoch [3/100], Step [7700/6235], Loss: 1.0648\n",
      "Epoch [3/100], Step [7800/6235], Loss: 1.4188\n",
      "Epoch [3/100], Step [7900/6235], Loss: 30.6216\n",
      "Epoch [3/100], Step [8000/6235], Loss: 2.9038\n",
      "Epoch [3/100], Step [8100/6235], Loss: 0.6378\n",
      "Epoch [3/100], Step [8200/6235], Loss: 9.6038\n",
      "Epoch [3/100], Step [8300/6235], Loss: 4.9996\n",
      "Epoch [3/100], Step [8400/6235], Loss: 183.8517\n",
      "Epoch [3/100], Step [8500/6235], Loss: 4.4887\n",
      "Epoch [3/100], Step [8600/6235], Loss: 0.8238\n",
      "Epoch [3/100], Step [8700/6235], Loss: 108.3983\n",
      "Epoch [3/100], Step [8800/6235], Loss: 3534.2729\n",
      "Epoch [3/100], Step [8900/6235], Loss: 8.1245\n",
      "Epoch [3/100], Step [9000/6235], Loss: 249.9152\n",
      "Epoch [3/100], Step [9100/6235], Loss: 8.8175\n",
      "Epoch [3/100], Step [9200/6235], Loss: 2306.4182\n",
      "Epoch [3/100], Step [9300/6235], Loss: 238.4918\n",
      "Epoch [3/100], Step [9400/6235], Loss: 224.7563\n",
      "Epoch [3/100], Step [9500/6235], Loss: 4.9752\n",
      "Epoch [3/100], Step [9600/6235], Loss: 478.1309\n",
      "Epoch [3/100], Step [9700/6235], Loss: 95.1930\n",
      "Epoch [3/100], Step [9800/6235], Loss: 217.5579\n",
      "Epoch [3/100], Step [9900/6235], Loss: 96.9486\n",
      "Epoch [3/100], Step [10000/6235], Loss: 41.5615\n",
      "Epoch [3/100], Step [10100/6235], Loss: 20.8015\n",
      "Epoch [3/100], Step [10200/6235], Loss: 898.4973\n",
      "Epoch [3/100], Step [10300/6235], Loss: 9.6688\n",
      "Epoch [3/100], Step [10400/6235], Loss: 16.1410\n",
      "Epoch [3/100], Step [10500/6235], Loss: 0.5436\n",
      "Epoch [3/100], Step [10600/6235], Loss: 63.8867\n",
      "Epoch [3/100], Step [10700/6235], Loss: 179.6219\n",
      "Epoch [3/100], Step [10800/6235], Loss: 165.0695\n",
      "Epoch [3/100], Step [10900/6235], Loss: 16.5147\n",
      "Epoch [3/100], Step [11000/6235], Loss: 8.1131\n",
      "Epoch [3/100], Step [11100/6235], Loss: 44.4870\n",
      "Epoch [3/100], Step [11200/6235], Loss: 77.7762\n",
      "Epoch [3/100], Step [11300/6235], Loss: 97.1863\n",
      "Epoch [3/100], Step [11400/6235], Loss: 330.7245\n",
      "Epoch [3/100], Step [11500/6235], Loss: 1.9843\n",
      "Epoch [3/100], Step [11600/6235], Loss: 4.3689\n",
      "Epoch [3/100], Step [11700/6235], Loss: 103.8322\n",
      "Epoch [3/100], Step [11800/6235], Loss: 91.2077\n",
      "Epoch [3/100], Step [11900/6235], Loss: 720.8745\n",
      "Epoch [3/100], Step [12000/6235], Loss: 27.4985\n",
      "Epoch [3/100], Step [12100/6235], Loss: 512.6569\n",
      "Epoch [3/100], Step [12200/6235], Loss: 62.5761\n",
      "Epoch [3/100], Step [12300/6235], Loss: 6.5941\n",
      "Epoch [3/100], Step [12400/6235], Loss: 13.7438\n",
      "Epoch [3/100], Step [12500/6235], Loss: 221.1199\n",
      "Epoch [3/100], Step [12600/6235], Loss: 51.7124\n",
      "Epoch [3/100], Step [12700/6235], Loss: 17.4560\n",
      "Epoch [3/100], Step [12800/6235], Loss: 5.1916\n",
      "Epoch [3/100], Step [12900/6235], Loss: 23.4917\n",
      "Epoch [3/100], Step [13000/6235], Loss: 5.6363\n",
      "Epoch [3/100], Step [13100/6235], Loss: 66.5676\n",
      "Epoch [3/100], Step [13200/6235], Loss: 45.7985\n",
      "Epoch [3/100], Step [13300/6235], Loss: 0.2403\n",
      "Epoch [3/100], Step [13400/6235], Loss: 0.9314\n",
      "Epoch [3/100], Step [13500/6235], Loss: 4.3736\n",
      "Epoch [3/100], Step [13600/6235], Loss: 10.9351\n",
      "Epoch [3/100], Step [13700/6235], Loss: 72.6628\n",
      "Epoch [3/100], Step [13800/6235], Loss: 74.1398\n",
      "Epoch [3/100], Step [13900/6235], Loss: 82.9795\n",
      "Epoch [3/100], Step [14000/6235], Loss: 4.8569\n",
      "Epoch [3/100], Step [14100/6235], Loss: 326.7739\n",
      "Epoch [3/100], Step [14200/6235], Loss: 3.5067\n",
      "Epoch [3/100], Step [14300/6235], Loss: 0.8363\n",
      "Epoch [3/100], Step [14400/6235], Loss: 0.8955\n",
      "Epoch [3/100], Step [14500/6235], Loss: 5.5856\n",
      "Epoch [3/100], Step [14600/6235], Loss: 1.5929\n",
      "Epoch [3/100], Step [14700/6235], Loss: 11.5547\n",
      "Epoch [3/100], Step [14800/6235], Loss: 12.9438\n",
      "Epoch [3/100], Step [14900/6235], Loss: 0.0784\n",
      "Epoch [3/100], Step [15000/6235], Loss: 0.0839\n",
      "Epoch [3/100], Step [15100/6235], Loss: 0.1443\n",
      "Epoch [3/100], Step [15200/6235], Loss: 6.4054\n",
      "Epoch [3/100], Step [15300/6235], Loss: 159.0961\n",
      "Epoch [3/100], Step [15400/6235], Loss: 28.4854\n",
      "Epoch [3/100], Step [15500/6235], Loss: 4.7502\n",
      "Epoch [3/100], Step [15600/6235], Loss: 26.9593\n",
      "Epoch [3/100], Step [15700/6235], Loss: 4.0598\n",
      "Epoch [3/100], Step [15800/6235], Loss: 1.5291\n",
      "Epoch [3/100], Step [15900/6235], Loss: 2.5151\n",
      "Epoch [3/100], Step [16000/6235], Loss: 2.1106\n",
      "Epoch [3/100], Step [16100/6235], Loss: 2.6188\n",
      "Epoch [3/100], Step [16200/6235], Loss: 27.6341\n",
      "Epoch [3/100], Step [16300/6235], Loss: 1.4880\n",
      "Epoch [3/100], Step [16400/6235], Loss: 28.5187\n",
      "Epoch [3/100], Step [16500/6235], Loss: 121.9998\n",
      "Epoch [3/100], Step [16600/6235], Loss: 4.3776\n",
      "Epoch [3/100], Step [16700/6235], Loss: 1.0060\n",
      "Epoch [3/100], Step [16800/6235], Loss: 1.3745\n",
      "Epoch [3/100], Step [16900/6235], Loss: 5.5833\n",
      "Epoch [3/100], Step [17000/6235], Loss: 2.9770\n",
      "Epoch [3/100], Step [17100/6235], Loss: 0.7897\n",
      "Epoch [3/100], Step [17200/6235], Loss: 1.0117\n",
      "Epoch [3/100], Step [17300/6235], Loss: 2.6757\n",
      "Epoch [3/100], Step [17400/6235], Loss: 178.2863\n",
      "Epoch [3/100], Step [17500/6235], Loss: 3.0359\n",
      "Epoch [3/100], Step [17600/6235], Loss: 3.6005\n",
      "Epoch [3/100], Step [17700/6235], Loss: 8.1644\n",
      "Epoch [3/100], Step [17800/6235], Loss: 1.0198\n",
      "Epoch [3/100], Step [17900/6235], Loss: 178.2794\n",
      "Epoch [3/100], Step [18000/6235], Loss: 6.2166\n",
      "Epoch [3/100], Step [18100/6235], Loss: 4.2281\n",
      "Epoch [3/100], Step [18200/6235], Loss: 4.4513\n",
      "Epoch [3/100], Step [18300/6235], Loss: 1.0320\n",
      "Epoch [3/100], Step [18400/6235], Loss: 19.0019\n",
      "Epoch [3/100], Step [18500/6235], Loss: 41.2316\n",
      "Epoch [3/100], Step [18600/6235], Loss: 2.3297\n",
      "Epoch [3/100], Step [18700/6235], Loss: 1.3610\n",
      "Epoch [3/100], Step [18800/6235], Loss: 81.8528\n",
      "Epoch [3/100], Step [18900/6235], Loss: 1.2639\n",
      "Epoch [3/100], Step [19000/6235], Loss: 11.3315\n",
      "Epoch [3/100], Step [19100/6235], Loss: 0.5708\n",
      "Epoch [3/100], Step [19200/6235], Loss: 3.9188\n",
      "Epoch [3/100], Step [19300/6235], Loss: 25.6213\n",
      "Epoch [3/100], Step [19400/6235], Loss: 94.5615\n",
      "Epoch [3/100], Step [19500/6235], Loss: 195.9874\n",
      "Epoch [3/100], Step [19600/6235], Loss: 149.9174\n",
      "Epoch [3/100], Step [19700/6235], Loss: 25.1538\n",
      "Epoch [3/100], Step [19800/6235], Loss: 33.0739\n",
      "Epoch [3/100], Step [19900/6235], Loss: 2.6842\n",
      "Epoch [3/100], Step [20000/6235], Loss: 115.6393\n",
      "Epoch [3/100], Step [20100/6235], Loss: 17.0912\n",
      "Epoch [3/100], Step [20200/6235], Loss: 0.6343\n",
      "Epoch [3/100], Step [20300/6235], Loss: 0.6463\n",
      "Epoch [3/100], Step [20400/6235], Loss: 35.0826\n",
      "Epoch [3/100], Step [20500/6235], Loss: 19.8001\n",
      "Epoch [3/100], Step [20600/6235], Loss: 305.5595\n",
      "Epoch [3/100], Step [20700/6235], Loss: 22.2910\n",
      "Epoch [3/100], Step [20800/6235], Loss: 7.9402\n",
      "Epoch [3/100], Step [20900/6235], Loss: 16.4793\n",
      "Epoch [3/100], Step [21000/6235], Loss: 2.3259\n",
      "Epoch [3/100], Step [21100/6235], Loss: 8.4448\n",
      "Epoch [3/100], Step [21200/6235], Loss: 6.3422\n",
      "Epoch [3/100], Step [21300/6235], Loss: 8.4115\n",
      "Epoch [3/100], Step [21400/6235], Loss: 1.8117\n",
      "Epoch [3/100], Step [21500/6235], Loss: 6.8463\n",
      "Epoch [3/100], Step [21600/6235], Loss: 30.1975\n",
      "Epoch [3/100], Step [21700/6235], Loss: 0.1561\n",
      "Epoch [3/100], Step [21800/6235], Loss: 22.5873\n",
      "Epoch [3/100], Step [21900/6235], Loss: 0.9814\n",
      "Epoch [3/100], Step [22000/6235], Loss: 0.0679\n",
      "Epoch [3/100], Step [22100/6235], Loss: 3.6672\n",
      "Epoch [3/100], Step [22200/6235], Loss: 10.7655\n",
      "Epoch [3/100], Step [22300/6235], Loss: 0.2450\n",
      "Epoch [3/100], Step [22400/6235], Loss: 6.9886\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Step [22500/6235], Loss: 176.0634\n",
      "Epoch [3/100], Step [22600/6235], Loss: 20.8013\n",
      "Epoch [3/100], Step [22700/6235], Loss: 2.1561\n",
      "Epoch [3/100], Step [22800/6235], Loss: 2.6071\n",
      "Epoch [3/100], Step [22900/6235], Loss: 12.1384\n",
      "Epoch [3/100], Step [23000/6235], Loss: 7.0434\n",
      "Epoch [3/100], Step [23100/6235], Loss: 0.4064\n",
      "Epoch [3/100], Step [23200/6235], Loss: 25.2203\n",
      "Epoch [3/100], Step [23300/6235], Loss: 20.1176\n",
      "Epoch [3/100], Step [23400/6235], Loss: 0.5409\n",
      "Epoch [3/100], Step [23500/6235], Loss: 0.2797\n",
      "Epoch [3/100], Step [23600/6235], Loss: 43.2667\n",
      "Epoch [3/100], Step [23700/6235], Loss: 0.7441\n",
      "Epoch [3/100], Step [23800/6235], Loss: 0.0363\n",
      "Epoch [3/100], Step [23900/6235], Loss: 6.8923\n",
      "Epoch [3/100], Step [24000/6235], Loss: 5.1035\n",
      "Epoch [3/100], Step [24100/6235], Loss: 3.6811\n",
      "Epoch [3/100], Step [24200/6235], Loss: 8.6087\n",
      "Epoch [3/100], Step [24300/6235], Loss: 4.3192\n",
      "Epoch [3/100], Step [24400/6235], Loss: 0.4678\n",
      "Epoch [3/100], Step [24500/6235], Loss: 2.7430\n",
      "Epoch [3/100], Step [24600/6235], Loss: 1.5007\n",
      "Epoch [3/100], Step [24700/6235], Loss: 7.8077\n",
      "Epoch [3/100], Step [24800/6235], Loss: 11.1260\n",
      "Epoch [3/100], Step [24900/6235], Loss: 19.5090\n",
      "Epoch [3/100], Step [25000/6235], Loss: 13.9587\n",
      "Epoch [3/100], Step [25100/6235], Loss: 9.5621\n",
      "Epoch [3/100], Step [25200/6235], Loss: 0.3835\n",
      "Epoch [3/100], Step [25300/6235], Loss: 1.3896\n",
      "Epoch [3/100], Step [25400/6235], Loss: 7.9527\n",
      "Epoch [3/100], Step [25500/6235], Loss: 3.0579\n",
      "Epoch [3/100], Step [25600/6235], Loss: 0.2870\n",
      "Epoch [3/100], Step [25700/6235], Loss: 0.1079\n",
      "Epoch [3/100], Step [25800/6235], Loss: 0.1981\n",
      "Epoch [3/100], Step [25900/6235], Loss: 8.6075\n",
      "Epoch [3/100], Step [26000/6235], Loss: 4.3105\n",
      "Epoch [3/100], Step [26100/6235], Loss: 0.1898\n",
      "Epoch [3/100], Step [26200/6235], Loss: 0.5900\n",
      "Epoch [3/100], Step [26300/6235], Loss: 6.4589\n",
      "Epoch [3/100], Step [26400/6235], Loss: 0.1057\n",
      "Epoch [3/100], Step [26500/6235], Loss: 3.0233\n",
      "Epoch [3/100], Step [26600/6235], Loss: 6.4090\n",
      "Epoch [3/100], Step [26700/6235], Loss: 1.9287\n",
      "Epoch [3/100], Step [26800/6235], Loss: 6.3187\n",
      "Epoch [3/100], Step [26900/6235], Loss: 0.6483\n",
      "Epoch [3/100], Step [27000/6235], Loss: 4.4122\n",
      "Epoch [3/100], Step [27100/6235], Loss: 0.6752\n",
      "Epoch [3/100], Step [27200/6235], Loss: 0.2938\n",
      "Epoch [3/100], Step [27300/6235], Loss: 0.0386\n",
      "Epoch [3/100], Step [27400/6235], Loss: 1.9370\n",
      "Epoch [3/100], Step [27500/6235], Loss: 19.0463\n",
      "Epoch [3/100], Step [27600/6235], Loss: 0.5382\n",
      "Epoch [3/100], Step [27700/6235], Loss: 0.0399\n",
      "Epoch [3/100], Step [27800/6235], Loss: 1.0477\n",
      "Epoch [3/100], Step [27900/6235], Loss: 2.7068\n",
      "Epoch [3/100], Step [28000/6235], Loss: 226.7083\n",
      "Epoch [3/100], Step [28100/6235], Loss: 0.7461\n",
      "Epoch [3/100], Step [28200/6235], Loss: 25.6263\n",
      "Epoch [3/100], Step [28300/6235], Loss: 3.5350\n",
      "Epoch [3/100], Step [28400/6235], Loss: 2.2753\n",
      "Epoch [3/100], Step [28500/6235], Loss: 0.1490\n",
      "Epoch [3/100], Step [28600/6235], Loss: 0.2365\n",
      "Epoch [3/100], Step [28700/6235], Loss: 3.8851\n",
      "Epoch [3/100], Step [28800/6235], Loss: 0.3654\n",
      "Epoch [3/100], Step [28900/6235], Loss: 36.8139\n",
      "Epoch [3/100], Step [29000/6235], Loss: 1.2909\n",
      "Epoch [3/100], Step [29100/6235], Loss: 6.4727\n",
      "Epoch [3/100], Step [29200/6235], Loss: 0.7905\n",
      "Epoch [3/100], Step [29300/6235], Loss: 0.2902\n",
      "Epoch [3/100], Step [29400/6235], Loss: 1.0946\n",
      "Epoch [3/100], Step [29500/6235], Loss: 0.8436\n",
      "Epoch [3/100], Step [29600/6235], Loss: 0.2744\n",
      "Epoch [3/100], Step [29700/6235], Loss: 0.1206\n",
      "Epoch [3/100], Step [29800/6235], Loss: 1.1031\n",
      "Epoch [3/100], Step [29900/6235], Loss: 0.0299\n",
      "Epoch [3/100], Step [30000/6235], Loss: 1.8653\n",
      "Epoch [3/100], Step [30100/6235], Loss: 2.7714\n",
      "Epoch [3/100], Step [30200/6235], Loss: 1.6567\n",
      "Epoch [3/100], Step [30300/6235], Loss: 1.3371\n",
      "Epoch [3/100], Step [30400/6235], Loss: 0.0635\n",
      "Epoch [3/100], Step [30500/6235], Loss: 0.1358\n",
      "Epoch [3/100], Step [30600/6235], Loss: 0.6465\n",
      "Epoch [3/100], Step [30700/6235], Loss: 0.6052\n",
      "Epoch [3/100], Step [30800/6235], Loss: 0.0423\n",
      "Epoch [3/100], Step [30900/6235], Loss: 1.0305\n",
      "Epoch [3/100], Step [31000/6235], Loss: 0.1496\n",
      "Epoch [3/100], Step [31100/6235], Loss: 2.6496\n",
      "Epoch [3/100], Step [31200/6235], Loss: 7.8859\n",
      "Epoch [3/100], Step [31300/6235], Loss: 1.2414\n",
      "Epoch [3/100], Step [31400/6235], Loss: 2.9891\n",
      "Epoch [3/100], Step [31500/6235], Loss: 2.0823\n",
      "Epoch [3/100], Step [31600/6235], Loss: 2.5082\n",
      "Epoch [3/100], Step [31700/6235], Loss: 1.3695\n",
      "Epoch [3/100], Step [31800/6235], Loss: 0.6190\n",
      "Epoch [3/100], Step [31900/6235], Loss: 1578.6981\n",
      "Epoch [3/100], Step [32000/6235], Loss: 80.1427\n",
      "Epoch [3/100], Step [32100/6235], Loss: 5.3236\n",
      "Epoch [3/100], Step [32200/6235], Loss: 6.0728\n",
      "Epoch [3/100], Step [32300/6235], Loss: 1.1804\n",
      "Epoch [3/100], Step [32400/6235], Loss: 1.4014\n",
      "Epoch [3/100], Step [32500/6235], Loss: 0.6539\n",
      "Epoch [3/100], Step [32600/6235], Loss: 0.5523\n",
      "Epoch [3/100], Step [32700/6235], Loss: 299.5998\n",
      "Epoch [3/100], Step [32800/6235], Loss: 21.9425\n",
      "Epoch [3/100], Step [32900/6235], Loss: 6.2463\n",
      "Epoch [3/100], Step [33000/6235], Loss: 4.2042\n",
      "Epoch [3/100], Step [33100/6235], Loss: 0.3862\n",
      "Epoch [3/100], Step [33200/6235], Loss: 0.5323\n",
      "Epoch [3/100], Step [33300/6235], Loss: 0.6089\n",
      "Epoch [3/100], Step [33400/6235], Loss: 4.0399\n",
      "Epoch [3/100], Step [33500/6235], Loss: 0.4920\n",
      "Epoch [3/100], Step [33600/6235], Loss: 2.9862\n",
      "Epoch [3/100], Step [33700/6235], Loss: 3.2584\n",
      "Epoch [3/100], Step [33800/6235], Loss: 45.6189\n",
      "Epoch [3/100], Step [33900/6235], Loss: 1.4719\n",
      "Epoch [3/100], Step [34000/6235], Loss: 1.8344\n",
      "Epoch [3/100], Step [34100/6235], Loss: 0.0706\n",
      "Epoch [3/100], Step [34200/6235], Loss: 38.4137\n",
      "Epoch [3/100], Step [34300/6235], Loss: 7.0210\n",
      "Epoch [3/100], Step [34400/6235], Loss: 4.7812\n",
      "Epoch [3/100], Step [34500/6235], Loss: 16.2352\n",
      "Epoch [3/100], Step [34600/6235], Loss: 10.2666\n",
      "Epoch [3/100], Step [34700/6235], Loss: 2.7398\n",
      "Epoch [3/100], Step [34800/6235], Loss: 11.1777\n",
      "Epoch [3/100], Step [34900/6235], Loss: 3.0551\n",
      "Epoch [3/100], Step [35000/6235], Loss: 0.1165\n",
      "Epoch [3/100], Step [35100/6235], Loss: 4.0353\n",
      "Epoch [3/100], Step [35200/6235], Loss: 19.4879\n",
      "Epoch [3/100], Step [35300/6235], Loss: 2.2712\n",
      "Epoch [3/100], Step [35400/6235], Loss: 10.7200\n",
      "Epoch [3/100], Step [35500/6235], Loss: 0.1633\n",
      "Epoch [3/100], Step [35600/6235], Loss: 4.8992\n",
      "Epoch [3/100], Step [35700/6235], Loss: 1.8564\n",
      "Epoch [3/100], Step [35800/6235], Loss: 0.4562\n",
      "Epoch [3/100], Step [35900/6235], Loss: 13.0809\n",
      "Epoch [3/100], Step [36000/6235], Loss: 6.2776\n",
      "Epoch [3/100], Step [36100/6235], Loss: 7.1462\n",
      "Epoch [3/100], Step [36200/6235], Loss: 1.8379\n",
      "Epoch [3/100], Step [36300/6235], Loss: 6.0073\n",
      "Epoch [3/100], Step [36400/6235], Loss: 3.7284\n",
      "Epoch [3/100], Step [36500/6235], Loss: 3.0338\n",
      "Epoch [3/100], Step [36600/6235], Loss: 0.4168\n",
      "Epoch [3/100], Step [36700/6235], Loss: 5.1247\n",
      "Epoch [3/100], Step [36800/6235], Loss: 0.2864\n",
      "Epoch [3/100], Step [36900/6235], Loss: 17.4472\n",
      "Epoch [3/100], Step [37000/6235], Loss: 0.2572\n",
      "Epoch [3/100], Step [37100/6235], Loss: 4.5151\n",
      "Epoch [3/100], Step [37200/6235], Loss: 0.8667\n",
      "Epoch [3/100], Step [37300/6235], Loss: 1.9879\n",
      "Epoch [3/100], Step [37400/6235], Loss: 0.1066\n",
      "Epoch [3/100], Step [37500/6235], Loss: 0.3720\n",
      "Epoch [3/100], Step [37600/6235], Loss: 1.5963\n",
      "Epoch [3/100], Step [37700/6235], Loss: 20.3949\n",
      "Epoch [3/100], Step [37800/6235], Loss: 0.8153\n",
      "Epoch [3/100], Step [37900/6235], Loss: 9.8555\n",
      "Epoch [3/100], Step [38000/6235], Loss: 0.2188\n",
      "Epoch [3/100], Step [38100/6235], Loss: 1.2000\n",
      "Epoch [3/100], Step [38200/6235], Loss: 1.5344\n",
      "Epoch [3/100], Step [38300/6235], Loss: 3.0485\n",
      "Epoch [3/100], Step [38400/6235], Loss: 0.0646\n",
      "Epoch [3/100], Step [38500/6235], Loss: 1.0677\n",
      "Epoch [3/100], Step [38600/6235], Loss: 3.3357\n",
      "Epoch [3/100], Step [38700/6235], Loss: 0.0759\n",
      "Epoch [3/100], Step [38800/6235], Loss: 1.0666\n",
      "Epoch [3/100], Step [38900/6235], Loss: 24.1670\n",
      "Epoch [3/100], Step [39000/6235], Loss: 11.8443\n",
      "Epoch [3/100], Step [39100/6235], Loss: 12.7204\n",
      "Epoch [3/100], Step [39200/6235], Loss: 0.3929\n",
      "Epoch [3/100], Step [39300/6235], Loss: 15.2464\n",
      "Epoch [3/100], Step [39400/6235], Loss: 161.7125\n",
      "Epoch [3/100], Step [39500/6235], Loss: 57.1638\n",
      "Epoch [3/100], Step [39600/6235], Loss: 28.5592\n",
      "Epoch [3/100], Step [39700/6235], Loss: 63.4199\n",
      "Epoch [3/100], Step [39800/6235], Loss: 133.8686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/100], Step [39900/6235], Loss: 53.9378\n",
      "Epoch [3/100], Step [40000/6235], Loss: 176.9703\n",
      "Epoch [3/100], Step [40100/6235], Loss: 1.9940\n",
      "Epoch [3/100], Step [40200/6235], Loss: 199.7476\n",
      "Epoch [3/100], Step [40300/6235], Loss: 4.0644\n",
      "Epoch [3/100], Step [40400/6235], Loss: 103.6044\n",
      "Epoch [3/100], Step [40500/6235], Loss: 1.0375\n",
      "Epoch [3/100], Step [40600/6235], Loss: 21.6851\n",
      "Epoch [3/100], Step [40700/6235], Loss: 10.4663\n",
      "Epoch [3/100], Step [40800/6235], Loss: 5.7488\n",
      "Epoch [3/100], Step [40900/6235], Loss: 0.7574\n",
      "Epoch [3/100], Step [41000/6235], Loss: 26.0604\n",
      "Epoch [3/100], Step [41100/6235], Loss: 22.9056\n",
      "Epoch [3/100], Step [41200/6235], Loss: 14.7689\n",
      "Epoch [3/100], Step [41300/6235], Loss: 1.5459\n",
      "Epoch [3/100], Step [41400/6235], Loss: 0.4563\n",
      "Epoch [3/100], Step [41500/6235], Loss: 0.2326\n",
      "Epoch [3/100], Step [41600/6235], Loss: 2.8448\n",
      "Epoch [3/100], Step [41700/6235], Loss: 1.8799\n",
      "Epoch [3/100], Step [41800/6235], Loss: 1.5874\n",
      "Epoch [3/100], Step [41900/6235], Loss: 0.1766\n",
      "Epoch [3/100], Step [42000/6235], Loss: 24.5524\n",
      "Epoch [3/100], Step [42100/6235], Loss: 0.5292\n",
      "Epoch [3/100], Step [42200/6235], Loss: 160.7260\n",
      "Epoch [3/100], Step [42300/6235], Loss: 0.5882\n",
      "Epoch [3/100], Step [42400/6235], Loss: 3.6607\n",
      "Epoch [3/100], Step [42500/6235], Loss: 2.2080\n",
      "Epoch [3/100], Step [42600/6235], Loss: 0.8941\n",
      "Epoch [3/100], Step [42700/6235], Loss: 1.2789\n",
      "Epoch [3/100], Step [42800/6235], Loss: 0.8231\n",
      "Epoch [3/100], Step [42900/6235], Loss: 6.5194\n",
      "Epoch [3/100], Step [43000/6235], Loss: 0.8964\n",
      "Epoch [3/100], Step [43100/6235], Loss: 0.4856\n",
      "Epoch [3/100], Step [43200/6235], Loss: 0.5882\n",
      "Epoch [3/100], Step [43300/6235], Loss: 3.9031\n",
      "Epoch [3/100], Step [43400/6235], Loss: 0.7361\n",
      "Epoch [3/100], Step [43500/6235], Loss: 0.1061\n",
      "Epoch [3/100], Step [43600/6235], Loss: 20.8989\n",
      "Epoch [3/100], Step [43700/6235], Loss: 33.6791\n",
      "Epoch [3/100], Step [43800/6235], Loss: 5.3234\n",
      "Epoch [3/100], Step [43900/6235], Loss: 19.2279\n",
      "Epoch [3/100], Step [44000/6235], Loss: 38.7045\n",
      "Epoch [3/100], Step [44100/6235], Loss: 0.1467\n",
      "Epoch [3/100], Step [44200/6235], Loss: 12.4949\n",
      "Epoch [3/100], Step [44300/6235], Loss: 25.8972\n",
      "Epoch [3/100], Step [44400/6235], Loss: 0.3647\n",
      "Epoch [3/100], Step [44500/6235], Loss: 1.0860\n",
      "Epoch [3/100], Step [44600/6235], Loss: 6.7478\n",
      "Epoch [3/100], Step [44700/6235], Loss: 0.6620\n",
      "Epoch [3/100], Step [44800/6235], Loss: 0.2896\n",
      "Epoch [3/100], Step [44900/6235], Loss: 1.4541\n",
      "Epoch [3/100], Step [45000/6235], Loss: 1.1136\n",
      "Epoch [3/100], Step [45100/6235], Loss: 20.4886\n",
      "Epoch [3/100], Step [45200/6235], Loss: 1.0836\n",
      "Epoch [3/100], Step [45300/6235], Loss: 2.4428\n",
      "Epoch [3/100], Step [45400/6235], Loss: 6.3336\n",
      "Epoch [3/100], Step [45500/6235], Loss: 22.2757\n",
      "Epoch [3/100], Step [45600/6235], Loss: 1.1899\n",
      "Epoch [3/100], Step [45700/6235], Loss: 38.2680\n",
      "Epoch [3/100], Step [45800/6235], Loss: 625.8686\n",
      "Epoch [3/100], Step [45900/6235], Loss: 12.1305\n",
      "Epoch [3/100], Step [46000/6235], Loss: 32.6706\n",
      "Epoch [3/100], Step [46100/6235], Loss: 13.3442\n",
      "Epoch [3/100], Step [46200/6235], Loss: 16.0828\n",
      "Epoch [3/100], Step [46300/6235], Loss: 15.7997\n",
      "Epoch [3/100], Step [46400/6235], Loss: 2.6047\n",
      "Epoch [3/100], Step [46500/6235], Loss: 0.4326\n",
      "Epoch [3/100], Step [46600/6235], Loss: 1.3746\n",
      "Epoch [3/100], Step [46700/6235], Loss: 101.9524\n",
      "Epoch [3/100], Step [46800/6235], Loss: 58.1252\n",
      "Epoch [3/100], Step [46900/6235], Loss: 64.7557\n",
      "Epoch [3/100], Step [47000/6235], Loss: 0.0708\n",
      "Epoch [3/100], Step [47100/6235], Loss: 112.9765\n",
      "Epoch [3/100], Step [47200/6235], Loss: 85.9750\n",
      "Epoch [3/100], Step [47300/6235], Loss: 8.3876\n",
      "Epoch [3/100], Step [47400/6235], Loss: 546.9529\n",
      "Epoch [3/100], Step [47500/6235], Loss: 7.0419\n",
      "Epoch [3/100], Step [47600/6235], Loss: 4.6954\n",
      "Epoch [3/100], Step [47700/6235], Loss: 0.5282\n",
      "Epoch [3/100], Step [47800/6235], Loss: 68.6674\n",
      "Epoch [3/100], Step [47900/6235], Loss: 5.8177\n",
      "Epoch [3/100], Step [48000/6235], Loss: 98.7922\n",
      "Epoch [3/100], Step [48100/6235], Loss: 27.2798\n",
      "Epoch [3/100], Step [48200/6235], Loss: 50.3530\n",
      "Epoch [3/100], Step [48300/6235], Loss: 748.7881\n",
      "Epoch [3/100], Step [48400/6235], Loss: 2.9336\n",
      "Epoch [3/100], Step [48500/6235], Loss: 20.7496\n",
      "Epoch [3/100], Step [48600/6235], Loss: 29.1664\n",
      "Epoch [3/100], Step [48700/6235], Loss: 17.7679\n",
      "Epoch [3/100], Step [48800/6235], Loss: 361.0200\n",
      "Epoch [3/100], Step [48900/6235], Loss: 177.4322\n",
      "Epoch [3/100], Step [49000/6235], Loss: 171.0943\n",
      "Epoch [3/100], Step [49100/6235], Loss: 2293.1455\n",
      "Epoch [3/100], Step [49200/6235], Loss: 1125.0367\n",
      "Epoch [3/100], Step [49300/6235], Loss: 1153.3317\n",
      "Epoch [3/100], Step [49400/6235], Loss: 228.7196\n",
      "Epoch [3/100], Step [49500/6235], Loss: 16.5658\n",
      "Epoch [3/100], Step [49600/6235], Loss: 207.5743\n",
      "Epoch [3/100], Step [49700/6235], Loss: 4841.0737\n",
      "Epoch [3/100], Step [49800/6235], Loss: 1170.6989\n",
      "Epoch [4/100], Step [100/6235], Loss: 34.0860\n",
      "Epoch [4/100], Step [200/6235], Loss: 0.1432\n",
      "Epoch [4/100], Step [300/6235], Loss: 0.0592\n",
      "Epoch [4/100], Step [400/6235], Loss: 0.0200\n",
      "Epoch [4/100], Step [500/6235], Loss: 23.9458\n",
      "Epoch [4/100], Step [600/6235], Loss: 0.1241\n",
      "Epoch [4/100], Step [700/6235], Loss: 0.4188\n",
      "Epoch [4/100], Step [800/6235], Loss: 0.0356\n",
      "Epoch [4/100], Step [900/6235], Loss: 0.0274\n",
      "Epoch [4/100], Step [1000/6235], Loss: 0.0199\n",
      "Epoch [4/100], Step [1100/6235], Loss: 0.0254\n",
      "Epoch [4/100], Step [1200/6235], Loss: 0.1136\n",
      "Epoch [4/100], Step [1300/6235], Loss: 0.0168\n",
      "Epoch [4/100], Step [1400/6235], Loss: 0.0396\n",
      "Epoch [4/100], Step [1500/6235], Loss: 0.0019\n",
      "Epoch [4/100], Step [1600/6235], Loss: 0.2984\n",
      "Epoch [4/100], Step [1700/6235], Loss: 0.0506\n",
      "Epoch [4/100], Step [1800/6235], Loss: 0.2943\n",
      "Epoch [4/100], Step [1900/6235], Loss: 0.0382\n",
      "Epoch [4/100], Step [2000/6235], Loss: 2.1279\n",
      "Epoch [4/100], Step [2100/6235], Loss: 2.6604\n",
      "Epoch [4/100], Step [2200/6235], Loss: 1.1859\n",
      "Epoch [4/100], Step [2300/6235], Loss: 0.5524\n",
      "Epoch [4/100], Step [2400/6235], Loss: 28.3148\n",
      "Epoch [4/100], Step [2500/6235], Loss: 16.5174\n",
      "Epoch [4/100], Step [2600/6235], Loss: 7.1796\n",
      "Epoch [4/100], Step [2700/6235], Loss: 20.0568\n",
      "Epoch [4/100], Step [2800/6235], Loss: 305.5905\n",
      "Epoch [4/100], Step [2900/6235], Loss: 14.6063\n",
      "Epoch [4/100], Step [3000/6235], Loss: 14.9778\n",
      "Epoch [4/100], Step [3100/6235], Loss: 93.6818\n",
      "Epoch [4/100], Step [3200/6235], Loss: 0.8272\n",
      "Epoch [4/100], Step [3300/6235], Loss: 1.6074\n",
      "Epoch [4/100], Step [3400/6235], Loss: 6.4922\n",
      "Epoch [4/100], Step [3500/6235], Loss: 99.1339\n",
      "Epoch [4/100], Step [3600/6235], Loss: 5.2694\n",
      "Epoch [4/100], Step [3700/6235], Loss: 3.8484\n",
      "Epoch [4/100], Step [3800/6235], Loss: 0.4070\n",
      "Epoch [4/100], Step [3900/6235], Loss: 1.7213\n",
      "Epoch [4/100], Step [4000/6235], Loss: 0.9555\n",
      "Epoch [4/100], Step [4100/6235], Loss: 1.2510\n",
      "Epoch [4/100], Step [4200/6235], Loss: 2.7752\n",
      "Epoch [4/100], Step [4300/6235], Loss: 2.1501\n",
      "Epoch [4/100], Step [4400/6235], Loss: 0.1456\n",
      "Epoch [4/100], Step [4500/6235], Loss: 65.6656\n",
      "Epoch [4/100], Step [4600/6235], Loss: 24.4735\n",
      "Epoch [4/100], Step [4700/6235], Loss: 7.6420\n",
      "Epoch [4/100], Step [4800/6235], Loss: 1.3961\n",
      "Epoch [4/100], Step [4900/6235], Loss: 1.1384\n",
      "Epoch [4/100], Step [5000/6235], Loss: 0.2111\n",
      "Epoch [4/100], Step [5100/6235], Loss: 7.8860\n",
      "Epoch [4/100], Step [5200/6235], Loss: 6.0241\n",
      "Epoch [4/100], Step [5300/6235], Loss: 3.2605\n",
      "Epoch [4/100], Step [5400/6235], Loss: 0.0361\n",
      "Epoch [4/100], Step [5500/6235], Loss: 0.1784\n",
      "Epoch [4/100], Step [5600/6235], Loss: 0.1498\n",
      "Epoch [4/100], Step [5700/6235], Loss: 1.8789\n",
      "Epoch [4/100], Step [5800/6235], Loss: 0.0546\n",
      "Epoch [4/100], Step [5900/6235], Loss: 0.0684\n",
      "Epoch [4/100], Step [6000/6235], Loss: 0.0985\n",
      "Epoch [4/100], Step [6100/6235], Loss: 0.3555\n",
      "Epoch [4/100], Step [6200/6235], Loss: 1.4652\n",
      "Epoch [4/100], Step [6300/6235], Loss: 0.7646\n",
      "Epoch [4/100], Step [6400/6235], Loss: 0.0404\n",
      "Epoch [4/100], Step [6500/6235], Loss: 0.1078\n",
      "Epoch [4/100], Step [6600/6235], Loss: 8.2138\n",
      "Epoch [4/100], Step [6700/6235], Loss: 0.3154\n",
      "Epoch [4/100], Step [6800/6235], Loss: 3.0947\n",
      "Epoch [4/100], Step [6900/6235], Loss: 1.2695\n",
      "Epoch [4/100], Step [7000/6235], Loss: 0.1622\n",
      "Epoch [4/100], Step [7100/6235], Loss: 0.7524\n",
      "Epoch [4/100], Step [7200/6235], Loss: 0.4277\n",
      "Epoch [4/100], Step [7300/6235], Loss: 0.6628\n",
      "Epoch [4/100], Step [7400/6235], Loss: 0.5779\n",
      "Epoch [4/100], Step [7500/6235], Loss: 0.6964\n",
      "Epoch [4/100], Step [7600/6235], Loss: 1.2408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Step [7700/6235], Loss: 2.6547\n",
      "Epoch [4/100], Step [7800/6235], Loss: 3.6712\n",
      "Epoch [4/100], Step [7900/6235], Loss: 15.3085\n",
      "Epoch [4/100], Step [8000/6235], Loss: 0.1199\n",
      "Epoch [4/100], Step [8100/6235], Loss: 0.3394\n",
      "Epoch [4/100], Step [8200/6235], Loss: 9.8889\n",
      "Epoch [4/100], Step [8300/6235], Loss: 9.5283\n",
      "Epoch [4/100], Step [8400/6235], Loss: 525.9316\n",
      "Epoch [4/100], Step [8500/6235], Loss: 0.5801\n",
      "Epoch [4/100], Step [8600/6235], Loss: 81.7127\n",
      "Epoch [4/100], Step [8700/6235], Loss: 52.5004\n",
      "Epoch [4/100], Step [8800/6235], Loss: 530.5094\n",
      "Epoch [4/100], Step [8900/6235], Loss: 5.2317\n",
      "Epoch [4/100], Step [9000/6235], Loss: 321.8019\n",
      "Epoch [4/100], Step [9100/6235], Loss: 375.1885\n",
      "Epoch [4/100], Step [9200/6235], Loss: 2263.1011\n",
      "Epoch [4/100], Step [9300/6235], Loss: 350.6490\n",
      "Epoch [4/100], Step [9400/6235], Loss: 695.6512\n",
      "Epoch [4/100], Step [9500/6235], Loss: 409.4035\n",
      "Epoch [4/100], Step [9600/6235], Loss: 307.9930\n",
      "Epoch [4/100], Step [9700/6235], Loss: 183.9959\n",
      "Epoch [4/100], Step [9800/6235], Loss: 96.8018\n",
      "Epoch [4/100], Step [9900/6235], Loss: 1195.6932\n",
      "Epoch [4/100], Step [10000/6235], Loss: 117.8937\n",
      "Epoch [4/100], Step [10100/6235], Loss: 1.9236\n",
      "Epoch [4/100], Step [10200/6235], Loss: 608.1405\n",
      "Epoch [4/100], Step [10300/6235], Loss: 0.7808\n",
      "Epoch [4/100], Step [10400/6235], Loss: 6.0000\n",
      "Epoch [4/100], Step [10500/6235], Loss: 5.5606\n",
      "Epoch [4/100], Step [10600/6235], Loss: 254.4470\n",
      "Epoch [4/100], Step [10700/6235], Loss: 318.6423\n",
      "Epoch [4/100], Step [10800/6235], Loss: 13.9768\n",
      "Epoch [4/100], Step [10900/6235], Loss: 6.2158\n",
      "Epoch [4/100], Step [11000/6235], Loss: 15.2526\n",
      "Epoch [4/100], Step [11100/6235], Loss: 5.8501\n",
      "Epoch [4/100], Step [11200/6235], Loss: 112.1405\n",
      "Epoch [4/100], Step [11300/6235], Loss: 186.0380\n",
      "Epoch [4/100], Step [11400/6235], Loss: 356.5788\n",
      "Epoch [4/100], Step [11500/6235], Loss: 3.9831\n",
      "Epoch [4/100], Step [11600/6235], Loss: 2.0986\n",
      "Epoch [4/100], Step [11700/6235], Loss: 146.6641\n",
      "Epoch [4/100], Step [11800/6235], Loss: 44.3704\n",
      "Epoch [4/100], Step [11900/6235], Loss: 1040.8572\n",
      "Epoch [4/100], Step [12000/6235], Loss: 45.4133\n",
      "Epoch [4/100], Step [12100/6235], Loss: 515.6576\n",
      "Epoch [4/100], Step [12200/6235], Loss: 22.7541\n",
      "Epoch [4/100], Step [12300/6235], Loss: 7.4273\n",
      "Epoch [4/100], Step [12400/6235], Loss: 23.4984\n",
      "Epoch [4/100], Step [12500/6235], Loss: 237.4787\n",
      "Epoch [4/100], Step [12600/6235], Loss: 18.4678\n",
      "Epoch [4/100], Step [12700/6235], Loss: 44.3825\n",
      "Epoch [4/100], Step [12800/6235], Loss: 11.0855\n",
      "Epoch [4/100], Step [12900/6235], Loss: 51.2828\n",
      "Epoch [4/100], Step [13000/6235], Loss: 1.8637\n",
      "Epoch [4/100], Step [13100/6235], Loss: 117.5884\n",
      "Epoch [4/100], Step [13200/6235], Loss: 40.7889\n",
      "Epoch [4/100], Step [13300/6235], Loss: 14.2510\n",
      "Epoch [4/100], Step [13400/6235], Loss: 6.8327\n",
      "Epoch [4/100], Step [13500/6235], Loss: 5.4220\n",
      "Epoch [4/100], Step [13600/6235], Loss: 2.3392\n",
      "Epoch [4/100], Step [13700/6235], Loss: 11.8303\n",
      "Epoch [4/100], Step [13800/6235], Loss: 97.3528\n",
      "Epoch [4/100], Step [13900/6235], Loss: 58.4394\n",
      "Epoch [4/100], Step [14000/6235], Loss: 12.5416\n",
      "Epoch [4/100], Step [14100/6235], Loss: 227.1408\n",
      "Epoch [4/100], Step [14200/6235], Loss: 80.6138\n",
      "Epoch [4/100], Step [14300/6235], Loss: 28.9279\n",
      "Epoch [4/100], Step [14400/6235], Loss: 6.6343\n",
      "Epoch [4/100], Step [14500/6235], Loss: 24.9606\n",
      "Epoch [4/100], Step [14600/6235], Loss: 2.7780\n",
      "Epoch [4/100], Step [14700/6235], Loss: 14.7712\n",
      "Epoch [4/100], Step [14800/6235], Loss: 25.3412\n",
      "Epoch [4/100], Step [14900/6235], Loss: 0.7539\n",
      "Epoch [4/100], Step [15000/6235], Loss: 0.3466\n",
      "Epoch [4/100], Step [15100/6235], Loss: 0.0337\n",
      "Epoch [4/100], Step [15200/6235], Loss: 58.9494\n",
      "Epoch [4/100], Step [15300/6235], Loss: 33.3285\n",
      "Epoch [4/100], Step [15400/6235], Loss: 1.6823\n",
      "Epoch [4/100], Step [15500/6235], Loss: 45.0825\n",
      "Epoch [4/100], Step [15600/6235], Loss: 86.6315\n",
      "Epoch [4/100], Step [15700/6235], Loss: 0.4186\n",
      "Epoch [4/100], Step [15800/6235], Loss: 0.9691\n",
      "Epoch [4/100], Step [15900/6235], Loss: 1.5946\n",
      "Epoch [4/100], Step [16000/6235], Loss: 7.1801\n",
      "Epoch [4/100], Step [16100/6235], Loss: 19.5573\n",
      "Epoch [4/100], Step [16200/6235], Loss: 3.7196\n",
      "Epoch [4/100], Step [16300/6235], Loss: 15.4565\n",
      "Epoch [4/100], Step [16400/6235], Loss: 71.2120\n",
      "Epoch [4/100], Step [16500/6235], Loss: 457.1997\n",
      "Epoch [4/100], Step [16600/6235], Loss: 0.3671\n",
      "Epoch [4/100], Step [16700/6235], Loss: 5.8345\n",
      "Epoch [4/100], Step [16800/6235], Loss: 1.4661\n",
      "Epoch [4/100], Step [16900/6235], Loss: 0.1606\n",
      "Epoch [4/100], Step [17000/6235], Loss: 6.7598\n",
      "Epoch [4/100], Step [17100/6235], Loss: 3.6412\n",
      "Epoch [4/100], Step [17200/6235], Loss: 5.6815\n",
      "Epoch [4/100], Step [17300/6235], Loss: 12.4733\n",
      "Epoch [4/100], Step [17400/6235], Loss: 79.4218\n",
      "Epoch [4/100], Step [17500/6235], Loss: 16.0819\n",
      "Epoch [4/100], Step [17600/6235], Loss: 0.4832\n",
      "Epoch [4/100], Step [17700/6235], Loss: 40.3095\n",
      "Epoch [4/100], Step [17800/6235], Loss: 27.8476\n",
      "Epoch [4/100], Step [17900/6235], Loss: 24.8915\n",
      "Epoch [4/100], Step [18000/6235], Loss: 3.2364\n",
      "Epoch [4/100], Step [18100/6235], Loss: 0.5361\n",
      "Epoch [4/100], Step [18200/6235], Loss: 16.7198\n",
      "Epoch [4/100], Step [18300/6235], Loss: 2.2083\n",
      "Epoch [4/100], Step [18400/6235], Loss: 28.2165\n",
      "Epoch [4/100], Step [18500/6235], Loss: 27.8940\n",
      "Epoch [4/100], Step [18600/6235], Loss: 5.2213\n",
      "Epoch [4/100], Step [18700/6235], Loss: 0.2570\n",
      "Epoch [4/100], Step [18800/6235], Loss: 145.1078\n",
      "Epoch [4/100], Step [18900/6235], Loss: 78.8611\n",
      "Epoch [4/100], Step [19000/6235], Loss: 7.4065\n",
      "Epoch [4/100], Step [19100/6235], Loss: 3.3455\n",
      "Epoch [4/100], Step [19200/6235], Loss: 5.9061\n",
      "Epoch [4/100], Step [19300/6235], Loss: 2.7518\n",
      "Epoch [4/100], Step [19400/6235], Loss: 114.6723\n",
      "Epoch [4/100], Step [19500/6235], Loss: 153.9169\n",
      "Epoch [4/100], Step [19600/6235], Loss: 148.0878\n",
      "Epoch [4/100], Step [19700/6235], Loss: 21.6822\n",
      "Epoch [4/100], Step [19800/6235], Loss: 14.1728\n",
      "Epoch [4/100], Step [19900/6235], Loss: 0.2636\n",
      "Epoch [4/100], Step [20000/6235], Loss: 103.1786\n",
      "Epoch [4/100], Step [20100/6235], Loss: 13.8098\n",
      "Epoch [4/100], Step [20200/6235], Loss: 3.6942\n",
      "Epoch [4/100], Step [20300/6235], Loss: 1.8124\n",
      "Epoch [4/100], Step [20400/6235], Loss: 32.9655\n",
      "Epoch [4/100], Step [20500/6235], Loss: 19.8435\n",
      "Epoch [4/100], Step [20600/6235], Loss: 312.6976\n",
      "Epoch [4/100], Step [20700/6235], Loss: 12.8721\n",
      "Epoch [4/100], Step [20800/6235], Loss: 1.1629\n",
      "Epoch [4/100], Step [20900/6235], Loss: 20.4683\n",
      "Epoch [4/100], Step [21000/6235], Loss: 16.5680\n",
      "Epoch [4/100], Step [21100/6235], Loss: 27.1865\n",
      "Epoch [4/100], Step [21200/6235], Loss: 0.2770\n",
      "Epoch [4/100], Step [21300/6235], Loss: 4.2036\n",
      "Epoch [4/100], Step [21400/6235], Loss: 2.5579\n",
      "Epoch [4/100], Step [21500/6235], Loss: 6.0051\n",
      "Epoch [4/100], Step [21600/6235], Loss: 32.1218\n",
      "Epoch [4/100], Step [21700/6235], Loss: 0.2836\n",
      "Epoch [4/100], Step [21800/6235], Loss: 10.8118\n",
      "Epoch [4/100], Step [21900/6235], Loss: 0.0474\n",
      "Epoch [4/100], Step [22000/6235], Loss: 0.2153\n",
      "Epoch [4/100], Step [22100/6235], Loss: 5.5770\n",
      "Epoch [4/100], Step [22200/6235], Loss: 4.4225\n",
      "Epoch [4/100], Step [22300/6235], Loss: 4.7025\n",
      "Epoch [4/100], Step [22400/6235], Loss: 18.8529\n",
      "Epoch [4/100], Step [22500/6235], Loss: 57.2047\n",
      "Epoch [4/100], Step [22600/6235], Loss: 17.6530\n",
      "Epoch [4/100], Step [22700/6235], Loss: 3.4944\n",
      "Epoch [4/100], Step [22800/6235], Loss: 3.0376\n",
      "Epoch [4/100], Step [22900/6235], Loss: 0.5575\n",
      "Epoch [4/100], Step [23000/6235], Loss: 6.3119\n",
      "Epoch [4/100], Step [23100/6235], Loss: 7.9178\n",
      "Epoch [4/100], Step [23200/6235], Loss: 8.0951\n",
      "Epoch [4/100], Step [23300/6235], Loss: 20.5536\n",
      "Epoch [4/100], Step [23400/6235], Loss: 2.1433\n",
      "Epoch [4/100], Step [23500/6235], Loss: 0.0578\n",
      "Epoch [4/100], Step [23600/6235], Loss: 87.0005\n",
      "Epoch [4/100], Step [23700/6235], Loss: 8.5308\n",
      "Epoch [4/100], Step [23800/6235], Loss: 0.7588\n",
      "Epoch [4/100], Step [23900/6235], Loss: 8.1986\n",
      "Epoch [4/100], Step [24000/6235], Loss: 1.1187\n",
      "Epoch [4/100], Step [24100/6235], Loss: 4.1177\n",
      "Epoch [4/100], Step [24200/6235], Loss: 14.1974\n",
      "Epoch [4/100], Step [24300/6235], Loss: 4.5055\n",
      "Epoch [4/100], Step [24400/6235], Loss: 7.9590\n",
      "Epoch [4/100], Step [24500/6235], Loss: 3.1875\n",
      "Epoch [4/100], Step [24600/6235], Loss: 0.0474\n",
      "Epoch [4/100], Step [24700/6235], Loss: 1.0520\n",
      "Epoch [4/100], Step [24800/6235], Loss: 2.4611\n",
      "Epoch [4/100], Step [24900/6235], Loss: 8.4935\n",
      "Epoch [4/100], Step [25000/6235], Loss: 18.5898\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Step [25100/6235], Loss: 8.2754\n",
      "Epoch [4/100], Step [25200/6235], Loss: 1.6981\n",
      "Epoch [4/100], Step [25300/6235], Loss: 2.1768\n",
      "Epoch [4/100], Step [25400/6235], Loss: 10.0417\n",
      "Epoch [4/100], Step [25500/6235], Loss: 6.7528\n",
      "Epoch [4/100], Step [25600/6235], Loss: 2.5078\n",
      "Epoch [4/100], Step [25700/6235], Loss: 0.3427\n",
      "Epoch [4/100], Step [25800/6235], Loss: 0.1949\n",
      "Epoch [4/100], Step [25900/6235], Loss: 8.9231\n",
      "Epoch [4/100], Step [26000/6235], Loss: 2.2449\n",
      "Epoch [4/100], Step [26100/6235], Loss: 0.1050\n",
      "Epoch [4/100], Step [26200/6235], Loss: 0.1065\n",
      "Epoch [4/100], Step [26300/6235], Loss: 4.6150\n",
      "Epoch [4/100], Step [26400/6235], Loss: 0.0997\n",
      "Epoch [4/100], Step [26500/6235], Loss: 0.9690\n",
      "Epoch [4/100], Step [26600/6235], Loss: 5.2470\n",
      "Epoch [4/100], Step [26700/6235], Loss: 1.1205\n",
      "Epoch [4/100], Step [26800/6235], Loss: 2.5545\n",
      "Epoch [4/100], Step [26900/6235], Loss: 0.3399\n",
      "Epoch [4/100], Step [27000/6235], Loss: 9.4391\n",
      "Epoch [4/100], Step [27100/6235], Loss: 0.3699\n",
      "Epoch [4/100], Step [27200/6235], Loss: 0.1269\n",
      "Epoch [4/100], Step [27300/6235], Loss: 0.0925\n",
      "Epoch [4/100], Step [27400/6235], Loss: 1.3542\n",
      "Epoch [4/100], Step [27500/6235], Loss: 8.4496\n",
      "Epoch [4/100], Step [27600/6235], Loss: 0.0266\n",
      "Epoch [4/100], Step [27700/6235], Loss: 0.0429\n",
      "Epoch [4/100], Step [27800/6235], Loss: 3.2707\n",
      "Epoch [4/100], Step [27900/6235], Loss: 0.3267\n",
      "Epoch [4/100], Step [28000/6235], Loss: 201.5806\n",
      "Epoch [4/100], Step [28100/6235], Loss: 3.1203\n",
      "Epoch [4/100], Step [28200/6235], Loss: 29.7435\n",
      "Epoch [4/100], Step [28300/6235], Loss: 4.9271\n",
      "Epoch [4/100], Step [28400/6235], Loss: 5.0370\n",
      "Epoch [4/100], Step [28500/6235], Loss: 0.1999\n",
      "Epoch [4/100], Step [28600/6235], Loss: 0.7492\n",
      "Epoch [4/100], Step [28700/6235], Loss: 3.6429\n",
      "Epoch [4/100], Step [28800/6235], Loss: 0.2031\n",
      "Epoch [4/100], Step [28900/6235], Loss: 53.0561\n",
      "Epoch [4/100], Step [29000/6235], Loss: 0.6537\n",
      "Epoch [4/100], Step [29100/6235], Loss: 3.6071\n",
      "Epoch [4/100], Step [29200/6235], Loss: 0.4810\n",
      "Epoch [4/100], Step [29300/6235], Loss: 0.0140\n",
      "Epoch [4/100], Step [29400/6235], Loss: 0.7468\n",
      "Epoch [4/100], Step [29500/6235], Loss: 0.4035\n",
      "Epoch [4/100], Step [29600/6235], Loss: 1.4716\n",
      "Epoch [4/100], Step [29700/6235], Loss: 0.0557\n",
      "Epoch [4/100], Step [29800/6235], Loss: 1.4111\n",
      "Epoch [4/100], Step [29900/6235], Loss: 0.0191\n",
      "Epoch [4/100], Step [30000/6235], Loss: 8.1788\n",
      "Epoch [4/100], Step [30100/6235], Loss: 2.8596\n",
      "Epoch [4/100], Step [30200/6235], Loss: 0.5068\n",
      "Epoch [4/100], Step [30300/6235], Loss: 1.3163\n",
      "Epoch [4/100], Step [30400/6235], Loss: 0.0213\n",
      "Epoch [4/100], Step [30500/6235], Loss: 0.0905\n",
      "Epoch [4/100], Step [30600/6235], Loss: 0.3286\n",
      "Epoch [4/100], Step [30700/6235], Loss: 0.6245\n",
      "Epoch [4/100], Step [30800/6235], Loss: 0.0791\n",
      "Epoch [4/100], Step [30900/6235], Loss: 1.7567\n",
      "Epoch [4/100], Step [31000/6235], Loss: 0.2802\n",
      "Epoch [4/100], Step [31100/6235], Loss: 0.5046\n",
      "Epoch [4/100], Step [31200/6235], Loss: 11.6326\n",
      "Epoch [4/100], Step [31300/6235], Loss: 1.3654\n",
      "Epoch [4/100], Step [31400/6235], Loss: 3.4624\n",
      "Epoch [4/100], Step [31500/6235], Loss: 1.9789\n",
      "Epoch [4/100], Step [31600/6235], Loss: 4.3217\n",
      "Epoch [4/100], Step [31700/6235], Loss: 1.1560\n",
      "Epoch [4/100], Step [31800/6235], Loss: 0.2736\n",
      "Epoch [4/100], Step [31900/6235], Loss: 42.0104\n",
      "Epoch [4/100], Step [32000/6235], Loss: 106.0515\n",
      "Epoch [4/100], Step [32100/6235], Loss: 5.6949\n",
      "Epoch [4/100], Step [32200/6235], Loss: 9.1602\n",
      "Epoch [4/100], Step [32300/6235], Loss: 0.4114\n",
      "Epoch [4/100], Step [32400/6235], Loss: 1.1899\n",
      "Epoch [4/100], Step [32500/6235], Loss: 1.8870\n",
      "Epoch [4/100], Step [32600/6235], Loss: 0.8023\n",
      "Epoch [4/100], Step [32700/6235], Loss: 213.9187\n",
      "Epoch [4/100], Step [32800/6235], Loss: 12.7624\n",
      "Epoch [4/100], Step [32900/6235], Loss: 2.8706\n",
      "Epoch [4/100], Step [33000/6235], Loss: 6.9972\n",
      "Epoch [4/100], Step [33100/6235], Loss: 0.4839\n",
      "Epoch [4/100], Step [33200/6235], Loss: 2.7279\n",
      "Epoch [4/100], Step [33300/6235], Loss: 4.1323\n",
      "Epoch [4/100], Step [33400/6235], Loss: 0.3382\n",
      "Epoch [4/100], Step [33500/6235], Loss: 1.4993\n",
      "Epoch [4/100], Step [33600/6235], Loss: 4.9667\n",
      "Epoch [4/100], Step [33700/6235], Loss: 0.5251\n",
      "Epoch [4/100], Step [33800/6235], Loss: 53.9114\n",
      "Epoch [4/100], Step [33900/6235], Loss: 2.6390\n",
      "Epoch [4/100], Step [34000/6235], Loss: 1.6402\n",
      "Epoch [4/100], Step [34100/6235], Loss: 0.0137\n",
      "Epoch [4/100], Step [34200/6235], Loss: 26.6366\n",
      "Epoch [4/100], Step [34300/6235], Loss: 1.7164\n",
      "Epoch [4/100], Step [34400/6235], Loss: 1.0827\n",
      "Epoch [4/100], Step [34500/6235], Loss: 6.8857\n",
      "Epoch [4/100], Step [34600/6235], Loss: 3.1484\n",
      "Epoch [4/100], Step [34700/6235], Loss: 7.9476\n",
      "Epoch [4/100], Step [34800/6235], Loss: 13.7042\n",
      "Epoch [4/100], Step [34900/6235], Loss: 6.9318\n",
      "Epoch [4/100], Step [35000/6235], Loss: 0.2661\n",
      "Epoch [4/100], Step [35100/6235], Loss: 4.8730\n",
      "Epoch [4/100], Step [35200/6235], Loss: 12.0176\n",
      "Epoch [4/100], Step [35300/6235], Loss: 4.1245\n",
      "Epoch [4/100], Step [35400/6235], Loss: 10.8415\n",
      "Epoch [4/100], Step [35500/6235], Loss: 0.0792\n",
      "Epoch [4/100], Step [35600/6235], Loss: 1.3323\n",
      "Epoch [4/100], Step [35700/6235], Loss: 6.0495\n",
      "Epoch [4/100], Step [35800/6235], Loss: 1.8262\n",
      "Epoch [4/100], Step [35900/6235], Loss: 4.9724\n",
      "Epoch [4/100], Step [36000/6235], Loss: 3.7270\n",
      "Epoch [4/100], Step [36100/6235], Loss: 18.3491\n",
      "Epoch [4/100], Step [36200/6235], Loss: 0.6054\n",
      "Epoch [4/100], Step [36300/6235], Loss: 6.5282\n",
      "Epoch [4/100], Step [36400/6235], Loss: 5.4792\n",
      "Epoch [4/100], Step [36500/6235], Loss: 2.0962\n",
      "Epoch [4/100], Step [36600/6235], Loss: 0.1240\n",
      "Epoch [4/100], Step [36700/6235], Loss: 8.4999\n",
      "Epoch [4/100], Step [36800/6235], Loss: 1.1476\n",
      "Epoch [4/100], Step [36900/6235], Loss: 11.8833\n",
      "Epoch [4/100], Step [37000/6235], Loss: 0.7189\n",
      "Epoch [4/100], Step [37100/6235], Loss: 2.0194\n",
      "Epoch [4/100], Step [37200/6235], Loss: 1.0988\n",
      "Epoch [4/100], Step [37300/6235], Loss: 2.0381\n",
      "Epoch [4/100], Step [37400/6235], Loss: 0.0844\n",
      "Epoch [4/100], Step [37500/6235], Loss: 1.5506\n",
      "Epoch [4/100], Step [37600/6235], Loss: 4.9212\n",
      "Epoch [4/100], Step [37700/6235], Loss: 12.5536\n",
      "Epoch [4/100], Step [37800/6235], Loss: 6.3755\n",
      "Epoch [4/100], Step [37900/6235], Loss: 12.3966\n",
      "Epoch [4/100], Step [38000/6235], Loss: 0.5889\n",
      "Epoch [4/100], Step [38100/6235], Loss: 0.3253\n",
      "Epoch [4/100], Step [38200/6235], Loss: 6.5203\n",
      "Epoch [4/100], Step [38300/6235], Loss: 0.5645\n",
      "Epoch [4/100], Step [38400/6235], Loss: 1.1979\n",
      "Epoch [4/100], Step [38500/6235], Loss: 0.5972\n",
      "Epoch [4/100], Step [38600/6235], Loss: 6.2432\n",
      "Epoch [4/100], Step [38700/6235], Loss: 0.3515\n",
      "Epoch [4/100], Step [38800/6235], Loss: 0.5508\n",
      "Epoch [4/100], Step [38900/6235], Loss: 65.7680\n",
      "Epoch [4/100], Step [39000/6235], Loss: 16.3979\n",
      "Epoch [4/100], Step [39100/6235], Loss: 3.0528\n",
      "Epoch [4/100], Step [39200/6235], Loss: 0.6741\n",
      "Epoch [4/100], Step [39300/6235], Loss: 36.5348\n",
      "Epoch [4/100], Step [39400/6235], Loss: 267.4443\n",
      "Epoch [4/100], Step [39500/6235], Loss: 253.2222\n",
      "Epoch [4/100], Step [39600/6235], Loss: 19.6849\n",
      "Epoch [4/100], Step [39700/6235], Loss: 731.9287\n",
      "Epoch [4/100], Step [39800/6235], Loss: 24.6182\n",
      "Epoch [4/100], Step [39900/6235], Loss: 12.3333\n",
      "Epoch [4/100], Step [40000/6235], Loss: 10.9157\n",
      "Epoch [4/100], Step [40100/6235], Loss: 20.7755\n",
      "Epoch [4/100], Step [40200/6235], Loss: 193.6922\n",
      "Epoch [4/100], Step [40300/6235], Loss: 9.9283\n",
      "Epoch [4/100], Step [40400/6235], Loss: 37.5374\n",
      "Epoch [4/100], Step [40500/6235], Loss: 0.2363\n",
      "Epoch [4/100], Step [40600/6235], Loss: 14.2738\n",
      "Epoch [4/100], Step [40700/6235], Loss: 7.3126\n",
      "Epoch [4/100], Step [40800/6235], Loss: 4.8282\n",
      "Epoch [4/100], Step [40900/6235], Loss: 1.0137\n",
      "Epoch [4/100], Step [41000/6235], Loss: 28.3228\n",
      "Epoch [4/100], Step [41100/6235], Loss: 11.8707\n",
      "Epoch [4/100], Step [41200/6235], Loss: 12.3475\n",
      "Epoch [4/100], Step [41300/6235], Loss: 0.2074\n",
      "Epoch [4/100], Step [41400/6235], Loss: 0.0202\n",
      "Epoch [4/100], Step [41500/6235], Loss: 0.7118\n",
      "Epoch [4/100], Step [41600/6235], Loss: 0.0538\n",
      "Epoch [4/100], Step [41700/6235], Loss: 1.9603\n",
      "Epoch [4/100], Step [41800/6235], Loss: 0.5739\n",
      "Epoch [4/100], Step [41900/6235], Loss: 0.4257\n",
      "Epoch [4/100], Step [42000/6235], Loss: 24.3862\n",
      "Epoch [4/100], Step [42100/6235], Loss: 0.3223\n",
      "Epoch [4/100], Step [42200/6235], Loss: 99.7306\n",
      "Epoch [4/100], Step [42300/6235], Loss: 0.7522\n",
      "Epoch [4/100], Step [42400/6235], Loss: 2.5631\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/100], Step [42500/6235], Loss: 0.5802\n",
      "Epoch [4/100], Step [42600/6235], Loss: 0.5642\n",
      "Epoch [4/100], Step [42700/6235], Loss: 1.5476\n",
      "Epoch [4/100], Step [42800/6235], Loss: 1.7938\n",
      "Epoch [4/100], Step [42900/6235], Loss: 1.8596\n",
      "Epoch [4/100], Step [43000/6235], Loss: 0.2527\n",
      "Epoch [4/100], Step [43100/6235], Loss: 0.5722\n",
      "Epoch [4/100], Step [43200/6235], Loss: 0.0852\n",
      "Epoch [4/100], Step [43300/6235], Loss: 7.6962\n",
      "Epoch [4/100], Step [43400/6235], Loss: 0.2126\n",
      "Epoch [4/100], Step [43500/6235], Loss: 0.0755\n",
      "Epoch [4/100], Step [43600/6235], Loss: 24.5079\n",
      "Epoch [4/100], Step [43700/6235], Loss: 14.9927\n",
      "Epoch [4/100], Step [43800/6235], Loss: 11.4543\n",
      "Epoch [4/100], Step [43900/6235], Loss: 0.6136\n",
      "Epoch [4/100], Step [44000/6235], Loss: 23.7524\n",
      "Epoch [4/100], Step [44100/6235], Loss: 0.6942\n",
      "Epoch [4/100], Step [44200/6235], Loss: 28.0330\n",
      "Epoch [4/100], Step [44300/6235], Loss: 13.2264\n",
      "Epoch [4/100], Step [44400/6235], Loss: 0.9698\n",
      "Epoch [4/100], Step [44500/6235], Loss: 1.4225\n",
      "Epoch [4/100], Step [44600/6235], Loss: 15.8682\n",
      "Epoch [4/100], Step [44700/6235], Loss: 1.3593\n",
      "Epoch [4/100], Step [44800/6235], Loss: 1.2839\n",
      "Epoch [4/100], Step [44900/6235], Loss: 2.5006\n",
      "Epoch [4/100], Step [45000/6235], Loss: 0.8164\n",
      "Epoch [4/100], Step [45100/6235], Loss: 1.2629\n",
      "Epoch [4/100], Step [45200/6235], Loss: 0.1681\n",
      "Epoch [4/100], Step [45300/6235], Loss: 1.3346\n",
      "Epoch [4/100], Step [45400/6235], Loss: 0.2307\n",
      "Epoch [4/100], Step [45500/6235], Loss: 6.7123\n",
      "Epoch [4/100], Step [45600/6235], Loss: 3.0712\n",
      "Epoch [4/100], Step [45700/6235], Loss: 5.5267\n",
      "Epoch [4/100], Step [45800/6235], Loss: 281.7395\n",
      "Epoch [4/100], Step [45900/6235], Loss: 0.4517\n",
      "Epoch [4/100], Step [46000/6235], Loss: 31.4443\n",
      "Epoch [4/100], Step [46100/6235], Loss: 24.5887\n",
      "Epoch [4/100], Step [46200/6235], Loss: 85.0600\n",
      "Epoch [4/100], Step [46300/6235], Loss: 3.8226\n",
      "Epoch [4/100], Step [46400/6235], Loss: 2.2669\n",
      "Epoch [4/100], Step [46500/6235], Loss: 2.4583\n",
      "Epoch [4/100], Step [46600/6235], Loss: 4.7000\n",
      "Epoch [4/100], Step [46700/6235], Loss: 0.5601\n",
      "Epoch [4/100], Step [46800/6235], Loss: 26.1551\n",
      "Epoch [4/100], Step [46900/6235], Loss: 44.3498\n",
      "Epoch [4/100], Step [47000/6235], Loss: 1.2583\n",
      "Epoch [4/100], Step [47100/6235], Loss: 102.6019\n",
      "Epoch [4/100], Step [47200/6235], Loss: 99.7572\n",
      "Epoch [4/100], Step [47300/6235], Loss: 2.7471\n",
      "Epoch [4/100], Step [47400/6235], Loss: 365.9024\n",
      "Epoch [4/100], Step [47500/6235], Loss: 27.2448\n",
      "Epoch [4/100], Step [47600/6235], Loss: 0.4711\n",
      "Epoch [4/100], Step [47700/6235], Loss: 18.1116\n",
      "Epoch [4/100], Step [47800/6235], Loss: 62.9481\n",
      "Epoch [4/100], Step [47900/6235], Loss: 17.1051\n",
      "Epoch [4/100], Step [48000/6235], Loss: 97.2133\n",
      "Epoch [4/100], Step [48100/6235], Loss: 8.5232\n",
      "Epoch [4/100], Step [48200/6235], Loss: 14.2126\n",
      "Epoch [4/100], Step [48300/6235], Loss: 575.3452\n",
      "Epoch [4/100], Step [48400/6235], Loss: 8.0915\n",
      "Epoch [4/100], Step [48500/6235], Loss: 47.1230\n",
      "Epoch [4/100], Step [48600/6235], Loss: 100.0955\n",
      "Epoch [4/100], Step [48700/6235], Loss: 0.6881\n",
      "Epoch [4/100], Step [48800/6235], Loss: 298.6904\n",
      "Epoch [4/100], Step [48900/6235], Loss: 529.2092\n",
      "Epoch [4/100], Step [49000/6235], Loss: 218.2519\n",
      "Epoch [4/100], Step [49100/6235], Loss: 1416.5178\n",
      "Epoch [4/100], Step [49200/6235], Loss: 805.6130\n",
      "Epoch [4/100], Step [49300/6235], Loss: 1286.2456\n",
      "Epoch [4/100], Step [49400/6235], Loss: 162.1467\n",
      "Epoch [4/100], Step [49500/6235], Loss: 27.5613\n",
      "Epoch [4/100], Step [49600/6235], Loss: 157.8528\n",
      "Epoch [4/100], Step [49700/6235], Loss: 2434.8428\n",
      "Epoch [4/100], Step [49800/6235], Loss: 51.7133\n",
      "Epoch [5/100], Step [100/6235], Loss: 3.0488\n",
      "Epoch [5/100], Step [200/6235], Loss: 0.1900\n",
      "Epoch [5/100], Step [300/6235], Loss: 0.0264\n",
      "Epoch [5/100], Step [400/6235], Loss: 0.0012\n",
      "Epoch [5/100], Step [500/6235], Loss: 0.8000\n",
      "Epoch [5/100], Step [600/6235], Loss: 0.0475\n",
      "Epoch [5/100], Step [700/6235], Loss: 0.5020\n",
      "Epoch [5/100], Step [800/6235], Loss: 0.0136\n",
      "Epoch [5/100], Step [900/6235], Loss: 0.0444\n",
      "Epoch [5/100], Step [1000/6235], Loss: 0.0177\n",
      "Epoch [5/100], Step [1100/6235], Loss: 0.0195\n",
      "Epoch [5/100], Step [1200/6235], Loss: 0.1351\n",
      "Epoch [5/100], Step [1300/6235], Loss: 0.0035\n",
      "Epoch [5/100], Step [1400/6235], Loss: 0.0532\n",
      "Epoch [5/100], Step [1500/6235], Loss: 0.0037\n",
      "Epoch [5/100], Step [1600/6235], Loss: 0.2404\n",
      "Epoch [5/100], Step [1700/6235], Loss: 0.2837\n",
      "Epoch [5/100], Step [1800/6235], Loss: 0.3826\n",
      "Epoch [5/100], Step [1900/6235], Loss: 0.2702\n",
      "Epoch [5/100], Step [2000/6235], Loss: 1.8985\n",
      "Epoch [5/100], Step [2100/6235], Loss: 4.4447\n",
      "Epoch [5/100], Step [2200/6235], Loss: 3.1082\n",
      "Epoch [5/100], Step [2300/6235], Loss: 4.1568\n",
      "Epoch [5/100], Step [2400/6235], Loss: 7.2769\n",
      "Epoch [5/100], Step [2500/6235], Loss: 6.9224\n",
      "Epoch [5/100], Step [2600/6235], Loss: 17.7153\n",
      "Epoch [5/100], Step [2700/6235], Loss: 15.2264\n",
      "Epoch [5/100], Step [2800/6235], Loss: 40.7415\n",
      "Epoch [5/100], Step [2900/6235], Loss: 6.1062\n",
      "Epoch [5/100], Step [3000/6235], Loss: 2.8046\n",
      "Epoch [5/100], Step [3100/6235], Loss: 99.8481\n",
      "Epoch [5/100], Step [3200/6235], Loss: 11.7384\n",
      "Epoch [5/100], Step [3300/6235], Loss: 1.2952\n",
      "Epoch [5/100], Step [3400/6235], Loss: 7.7419\n",
      "Epoch [5/100], Step [3500/6235], Loss: 68.6648\n",
      "Epoch [5/100], Step [3600/6235], Loss: 1.6739\n",
      "Epoch [5/100], Step [3700/6235], Loss: 0.1468\n",
      "Epoch [5/100], Step [3800/6235], Loss: 0.2124\n",
      "Epoch [5/100], Step [3900/6235], Loss: 0.1679\n",
      "Epoch [5/100], Step [4000/6235], Loss: 0.4074\n",
      "Epoch [5/100], Step [4100/6235], Loss: 7.6056\n",
      "Epoch [5/100], Step [4200/6235], Loss: 3.2500\n",
      "Epoch [5/100], Step [4300/6235], Loss: 4.3173\n",
      "Epoch [5/100], Step [4400/6235], Loss: 0.0142\n",
      "Epoch [5/100], Step [4500/6235], Loss: 73.2054\n",
      "Epoch [5/100], Step [4600/6235], Loss: 14.1204\n",
      "Epoch [5/100], Step [4700/6235], Loss: 0.7452\n",
      "Epoch [5/100], Step [4800/6235], Loss: 2.0727\n",
      "Epoch [5/100], Step [4900/6235], Loss: 2.5485\n",
      "Epoch [5/100], Step [5000/6235], Loss: 0.0754\n",
      "Epoch [5/100], Step [5100/6235], Loss: 6.4550\n",
      "Epoch [5/100], Step [5200/6235], Loss: 2.5997\n",
      "Epoch [5/100], Step [5300/6235], Loss: 13.1962\n",
      "Epoch [5/100], Step [5400/6235], Loss: 5.1920\n",
      "Epoch [5/100], Step [5500/6235], Loss: 1.4271\n",
      "Epoch [5/100], Step [5600/6235], Loss: 0.3522\n",
      "Epoch [5/100], Step [5700/6235], Loss: 0.2093\n",
      "Epoch [5/100], Step [5800/6235], Loss: 2.7834\n",
      "Epoch [5/100], Step [5900/6235], Loss: 0.0079\n",
      "Epoch [5/100], Step [6000/6235], Loss: 1.5287\n",
      "Epoch [5/100], Step [6100/6235], Loss: 0.1589\n",
      "Epoch [5/100], Step [6200/6235], Loss: 6.2429\n",
      "Epoch [5/100], Step [6300/6235], Loss: 1.0111\n",
      "Epoch [5/100], Step [6400/6235], Loss: 0.1013\n",
      "Epoch [5/100], Step [6500/6235], Loss: 1.7558\n",
      "Epoch [5/100], Step [6600/6235], Loss: 0.7956\n",
      "Epoch [5/100], Step [6700/6235], Loss: 0.1144\n",
      "Epoch [5/100], Step [6800/6235], Loss: 0.2266\n",
      "Epoch [5/100], Step [6900/6235], Loss: 0.5140\n",
      "Epoch [5/100], Step [7000/6235], Loss: 0.0303\n",
      "Epoch [5/100], Step [7100/6235], Loss: 0.8490\n",
      "Epoch [5/100], Step [7200/6235], Loss: 7.5562\n",
      "Epoch [5/100], Step [7300/6235], Loss: 1.3560\n",
      "Epoch [5/100], Step [7400/6235], Loss: 0.0330\n",
      "Epoch [5/100], Step [7500/6235], Loss: 0.1733\n",
      "Epoch [5/100], Step [7600/6235], Loss: 5.9296\n",
      "Epoch [5/100], Step [7700/6235], Loss: 9.2657\n",
      "Epoch [5/100], Step [7800/6235], Loss: 1.6294\n",
      "Epoch [5/100], Step [7900/6235], Loss: 2.9122\n",
      "Epoch [5/100], Step [8000/6235], Loss: 0.5206\n",
      "Epoch [5/100], Step [8100/6235], Loss: 0.8767\n",
      "Epoch [5/100], Step [8200/6235], Loss: 10.7115\n",
      "Epoch [5/100], Step [8300/6235], Loss: 13.5480\n",
      "Epoch [5/100], Step [8400/6235], Loss: 510.2781\n",
      "Epoch [5/100], Step [8500/6235], Loss: 19.2607\n",
      "Epoch [5/100], Step [8600/6235], Loss: 37.6348\n",
      "Epoch [5/100], Step [8700/6235], Loss: 20.3048\n",
      "Epoch [5/100], Step [8800/6235], Loss: 21.3384\n",
      "Epoch [5/100], Step [8900/6235], Loss: 1.6268\n",
      "Epoch [5/100], Step [9000/6235], Loss: 445.7475\n",
      "Epoch [5/100], Step [9100/6235], Loss: 673.7307\n",
      "Epoch [5/100], Step [9200/6235], Loss: 2534.6885\n",
      "Epoch [5/100], Step [9300/6235], Loss: 416.4941\n",
      "Epoch [5/100], Step [9400/6235], Loss: 1137.9230\n",
      "Epoch [5/100], Step [9500/6235], Loss: 193.5341\n",
      "Epoch [5/100], Step [9600/6235], Loss: 161.0025\n",
      "Epoch [5/100], Step [9700/6235], Loss: 189.8716\n",
      "Epoch [5/100], Step [9800/6235], Loss: 12.4845\n",
      "Epoch [5/100], Step [9900/6235], Loss: 143.0183\n",
      "Epoch [5/100], Step [10000/6235], Loss: 109.9166\n",
      "Epoch [5/100], Step [10100/6235], Loss: 2.2988\n",
      "Epoch [5/100], Step [10200/6235], Loss: 483.0657\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Step [10300/6235], Loss: 0.4635\n",
      "Epoch [5/100], Step [10400/6235], Loss: 1.4720\n",
      "Epoch [5/100], Step [10500/6235], Loss: 14.4442\n",
      "Epoch [5/100], Step [10600/6235], Loss: 552.2311\n",
      "Epoch [5/100], Step [10700/6235], Loss: 175.8895\n",
      "Epoch [5/100], Step [10800/6235], Loss: 2.0202\n",
      "Epoch [5/100], Step [10900/6235], Loss: 5.8198\n",
      "Epoch [5/100], Step [11000/6235], Loss: 52.7598\n",
      "Epoch [5/100], Step [11100/6235], Loss: 0.5744\n",
      "Epoch [5/100], Step [11200/6235], Loss: 124.1073\n",
      "Epoch [5/100], Step [11300/6235], Loss: 215.4717\n",
      "Epoch [5/100], Step [11400/6235], Loss: 327.2175\n",
      "Epoch [5/100], Step [11500/6235], Loss: 11.4367\n",
      "Epoch [5/100], Step [11600/6235], Loss: 1.8084\n",
      "Epoch [5/100], Step [11700/6235], Loss: 166.3050\n",
      "Epoch [5/100], Step [11800/6235], Loss: 5.2121\n",
      "Epoch [5/100], Step [11900/6235], Loss: 1005.1871\n",
      "Epoch [5/100], Step [12000/6235], Loss: 433.0671\n",
      "Epoch [5/100], Step [12100/6235], Loss: 351.4935\n",
      "Epoch [5/100], Step [12200/6235], Loss: 14.8079\n",
      "Epoch [5/100], Step [12300/6235], Loss: 6.6850\n",
      "Epoch [5/100], Step [12400/6235], Loss: 55.5046\n",
      "Epoch [5/100], Step [12500/6235], Loss: 196.8001\n",
      "Epoch [5/100], Step [12600/6235], Loss: 9.3451\n",
      "Epoch [5/100], Step [12700/6235], Loss: 40.0911\n",
      "Epoch [5/100], Step [12800/6235], Loss: 16.9457\n",
      "Epoch [5/100], Step [12900/6235], Loss: 65.6241\n",
      "Epoch [5/100], Step [13000/6235], Loss: 1.1961\n",
      "Epoch [5/100], Step [13100/6235], Loss: 119.3313\n",
      "Epoch [5/100], Step [13200/6235], Loss: 34.7103\n",
      "Epoch [5/100], Step [13300/6235], Loss: 18.1327\n",
      "Epoch [5/100], Step [13400/6235], Loss: 26.6544\n",
      "Epoch [5/100], Step [13500/6235], Loss: 5.5590\n",
      "Epoch [5/100], Step [13600/6235], Loss: 11.0530\n",
      "Epoch [5/100], Step [13700/6235], Loss: 2.8707\n",
      "Epoch [5/100], Step [13800/6235], Loss: 101.7573\n",
      "Epoch [5/100], Step [13900/6235], Loss: 42.5790\n",
      "Epoch [5/100], Step [14000/6235], Loss: 10.6802\n",
      "Epoch [5/100], Step [14100/6235], Loss: 50.4649\n",
      "Epoch [5/100], Step [14200/6235], Loss: 96.0026\n",
      "Epoch [5/100], Step [14300/6235], Loss: 16.9387\n",
      "Epoch [5/100], Step [14400/6235], Loss: 12.9708\n",
      "Epoch [5/100], Step [14500/6235], Loss: 28.8092\n",
      "Epoch [5/100], Step [14600/6235], Loss: 3.5428\n",
      "Epoch [5/100], Step [14700/6235], Loss: 20.8765\n",
      "Epoch [5/100], Step [14800/6235], Loss: 29.7217\n",
      "Epoch [5/100], Step [14900/6235], Loss: 0.8148\n",
      "Epoch [5/100], Step [15000/6235], Loss: 0.7054\n",
      "Epoch [5/100], Step [15100/6235], Loss: 0.0836\n",
      "Epoch [5/100], Step [15200/6235], Loss: 67.6439\n",
      "Epoch [5/100], Step [15300/6235], Loss: 14.1925\n",
      "Epoch [5/100], Step [15400/6235], Loss: 1.4855\n",
      "Epoch [5/100], Step [15500/6235], Loss: 40.0125\n",
      "Epoch [5/100], Step [15600/6235], Loss: 74.1068\n",
      "Epoch [5/100], Step [15700/6235], Loss: 2.2809\n",
      "Epoch [5/100], Step [15800/6235], Loss: 0.1635\n",
      "Epoch [5/100], Step [15900/6235], Loss: 0.5812\n",
      "Epoch [5/100], Step [16000/6235], Loss: 46.1266\n",
      "Epoch [5/100], Step [16100/6235], Loss: 0.2764\n",
      "Epoch [5/100], Step [16200/6235], Loss: 0.2564\n",
      "Epoch [5/100], Step [16300/6235], Loss: 35.3251\n",
      "Epoch [5/100], Step [16400/6235], Loss: 77.4167\n",
      "Epoch [5/100], Step [16500/6235], Loss: 568.4014\n",
      "Epoch [5/100], Step [16600/6235], Loss: 3.4857\n",
      "Epoch [5/100], Step [16700/6235], Loss: 7.8136\n",
      "Epoch [5/100], Step [16800/6235], Loss: 1.6371\n",
      "Epoch [5/100], Step [16900/6235], Loss: 1.3089\n",
      "Epoch [5/100], Step [17000/6235], Loss: 5.8408\n",
      "Epoch [5/100], Step [17100/6235], Loss: 3.4811\n",
      "Epoch [5/100], Step [17200/6235], Loss: 16.1457\n",
      "Epoch [5/100], Step [17300/6235], Loss: 16.8096\n",
      "Epoch [5/100], Step [17400/6235], Loss: 48.8960\n",
      "Epoch [5/100], Step [17500/6235], Loss: 12.0587\n",
      "Epoch [5/100], Step [17600/6235], Loss: 0.3134\n",
      "Epoch [5/100], Step [17700/6235], Loss: 102.8486\n",
      "Epoch [5/100], Step [17800/6235], Loss: 39.2247\n",
      "Epoch [5/100], Step [17900/6235], Loss: 25.0903\n",
      "Epoch [5/100], Step [18000/6235], Loss: 0.9595\n",
      "Epoch [5/100], Step [18100/6235], Loss: 15.3537\n",
      "Epoch [5/100], Step [18200/6235], Loss: 19.4370\n",
      "Epoch [5/100], Step [18300/6235], Loss: 4.6504\n",
      "Epoch [5/100], Step [18400/6235], Loss: 19.0263\n",
      "Epoch [5/100], Step [18500/6235], Loss: 13.8167\n",
      "Epoch [5/100], Step [18600/6235], Loss: 5.2306\n",
      "Epoch [5/100], Step [18700/6235], Loss: 0.2223\n",
      "Epoch [5/100], Step [18800/6235], Loss: 443.0692\n",
      "Epoch [5/100], Step [18900/6235], Loss: 17.2270\n",
      "Epoch [5/100], Step [19000/6235], Loss: 12.5955\n",
      "Epoch [5/100], Step [19100/6235], Loss: 31.8047\n",
      "Epoch [5/100], Step [19200/6235], Loss: 1.3318\n",
      "Epoch [5/100], Step [19300/6235], Loss: 3.5951\n",
      "Epoch [5/100], Step [19400/6235], Loss: 42.7321\n",
      "Epoch [5/100], Step [19500/6235], Loss: 102.3329\n",
      "Epoch [5/100], Step [19600/6235], Loss: 141.4818\n",
      "Epoch [5/100], Step [19700/6235], Loss: 20.6860\n",
      "Epoch [5/100], Step [19800/6235], Loss: 5.9846\n",
      "Epoch [5/100], Step [19900/6235], Loss: 0.2584\n",
      "Epoch [5/100], Step [20000/6235], Loss: 81.6925\n",
      "Epoch [5/100], Step [20100/6235], Loss: 6.7029\n",
      "Epoch [5/100], Step [20200/6235], Loss: 5.7265\n",
      "Epoch [5/100], Step [20300/6235], Loss: 2.3880\n",
      "Epoch [5/100], Step [20400/6235], Loss: 29.4426\n",
      "Epoch [5/100], Step [20500/6235], Loss: 21.3147\n",
      "Epoch [5/100], Step [20600/6235], Loss: 301.6773\n",
      "Epoch [5/100], Step [20700/6235], Loss: 3.5868\n",
      "Epoch [5/100], Step [20800/6235], Loss: 4.9153\n",
      "Epoch [5/100], Step [20900/6235], Loss: 16.8578\n",
      "Epoch [5/100], Step [21000/6235], Loss: 6.6048\n",
      "Epoch [5/100], Step [21100/6235], Loss: 25.5943\n",
      "Epoch [5/100], Step [21200/6235], Loss: 0.7973\n",
      "Epoch [5/100], Step [21300/6235], Loss: 2.7506\n",
      "Epoch [5/100], Step [21400/6235], Loss: 2.7595\n",
      "Epoch [5/100], Step [21500/6235], Loss: 4.2258\n",
      "Epoch [5/100], Step [21600/6235], Loss: 32.7436\n",
      "Epoch [5/100], Step [21700/6235], Loss: 0.1940\n",
      "Epoch [5/100], Step [21800/6235], Loss: 5.1414\n",
      "Epoch [5/100], Step [21900/6235], Loss: 0.0170\n",
      "Epoch [5/100], Step [22000/6235], Loss: 1.3122\n",
      "Epoch [5/100], Step [22100/6235], Loss: 4.7705\n",
      "Epoch [5/100], Step [22200/6235], Loss: 2.6812\n",
      "Epoch [5/100], Step [22300/6235], Loss: 3.1496\n",
      "Epoch [5/100], Step [22400/6235], Loss: 13.1338\n",
      "Epoch [5/100], Step [22500/6235], Loss: 132.4360\n",
      "Epoch [5/100], Step [22600/6235], Loss: 19.1114\n",
      "Epoch [5/100], Step [22700/6235], Loss: 1.9354\n",
      "Epoch [5/100], Step [22800/6235], Loss: 4.8974\n",
      "Epoch [5/100], Step [22900/6235], Loss: 6.6619\n",
      "Epoch [5/100], Step [23000/6235], Loss: 10.2133\n",
      "Epoch [5/100], Step [23100/6235], Loss: 5.8999\n",
      "Epoch [5/100], Step [23200/6235], Loss: 4.7910\n",
      "Epoch [5/100], Step [23300/6235], Loss: 20.4685\n",
      "Epoch [5/100], Step [23400/6235], Loss: 2.5936\n",
      "Epoch [5/100], Step [23500/6235], Loss: 0.1238\n",
      "Epoch [5/100], Step [23600/6235], Loss: 102.8122\n",
      "Epoch [5/100], Step [23700/6235], Loss: 8.4520\n",
      "Epoch [5/100], Step [23800/6235], Loss: 0.9419\n",
      "Epoch [5/100], Step [23900/6235], Loss: 5.7185\n",
      "Epoch [5/100], Step [24000/6235], Loss: 0.6876\n",
      "Epoch [5/100], Step [24100/6235], Loss: 1.9075\n",
      "Epoch [5/100], Step [24200/6235], Loss: 2.2895\n",
      "Epoch [5/100], Step [24300/6235], Loss: 4.3644\n",
      "Epoch [5/100], Step [24400/6235], Loss: 8.6334\n",
      "Epoch [5/100], Step [24500/6235], Loss: 3.3822\n",
      "Epoch [5/100], Step [24600/6235], Loss: 0.1021\n",
      "Epoch [5/100], Step [24700/6235], Loss: 0.8870\n",
      "Epoch [5/100], Step [24800/6235], Loss: 1.1706\n",
      "Epoch [5/100], Step [24900/6235], Loss: 16.3250\n",
      "Epoch [5/100], Step [25000/6235], Loss: 20.0418\n",
      "Epoch [5/100], Step [25100/6235], Loss: 7.7543\n",
      "Epoch [5/100], Step [25200/6235], Loss: 1.8310\n",
      "Epoch [5/100], Step [25300/6235], Loss: 2.4288\n",
      "Epoch [5/100], Step [25400/6235], Loss: 9.3148\n",
      "Epoch [5/100], Step [25500/6235], Loss: 7.9550\n",
      "Epoch [5/100], Step [25600/6235], Loss: 3.1539\n",
      "Epoch [5/100], Step [25700/6235], Loss: 0.3065\n",
      "Epoch [5/100], Step [25800/6235], Loss: 0.1702\n",
      "Epoch [5/100], Step [25900/6235], Loss: 7.3100\n",
      "Epoch [5/100], Step [26000/6235], Loss: 4.0024\n",
      "Epoch [5/100], Step [26100/6235], Loss: 0.3409\n",
      "Epoch [5/100], Step [26200/6235], Loss: 0.1107\n",
      "Epoch [5/100], Step [26300/6235], Loss: 5.0286\n",
      "Epoch [5/100], Step [26400/6235], Loss: 0.1041\n",
      "Epoch [5/100], Step [26500/6235], Loss: 0.4675\n",
      "Epoch [5/100], Step [26600/6235], Loss: 3.9193\n",
      "Epoch [5/100], Step [26700/6235], Loss: 0.8602\n",
      "Epoch [5/100], Step [26800/6235], Loss: 1.5211\n",
      "Epoch [5/100], Step [26900/6235], Loss: 0.1741\n",
      "Epoch [5/100], Step [27000/6235], Loss: 11.7083\n",
      "Epoch [5/100], Step [27100/6235], Loss: 0.1504\n",
      "Epoch [5/100], Step [27200/6235], Loss: 0.0525\n",
      "Epoch [5/100], Step [27300/6235], Loss: 0.1751\n",
      "Epoch [5/100], Step [27400/6235], Loss: 1.0931\n",
      "Epoch [5/100], Step [27500/6235], Loss: 14.7450\n",
      "Epoch [5/100], Step [27600/6235], Loss: 0.2297\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Step [27700/6235], Loss: 0.0698\n",
      "Epoch [5/100], Step [27800/6235], Loss: 1.3337\n",
      "Epoch [5/100], Step [27900/6235], Loss: 0.7230\n",
      "Epoch [5/100], Step [28000/6235], Loss: 213.3529\n",
      "Epoch [5/100], Step [28100/6235], Loss: 9.6589\n",
      "Epoch [5/100], Step [28200/6235], Loss: 18.0738\n",
      "Epoch [5/100], Step [28300/6235], Loss: 5.2602\n",
      "Epoch [5/100], Step [28400/6235], Loss: 6.8187\n",
      "Epoch [5/100], Step [28500/6235], Loss: 0.1918\n",
      "Epoch [5/100], Step [28600/6235], Loss: 0.8757\n",
      "Epoch [5/100], Step [28700/6235], Loss: 3.5868\n",
      "Epoch [5/100], Step [28800/6235], Loss: 0.1827\n",
      "Epoch [5/100], Step [28900/6235], Loss: 56.8096\n",
      "Epoch [5/100], Step [29000/6235], Loss: 0.3921\n",
      "Epoch [5/100], Step [29100/6235], Loss: 2.7461\n",
      "Epoch [5/100], Step [29200/6235], Loss: 0.3621\n",
      "Epoch [5/100], Step [29300/6235], Loss: 12.9171\n",
      "Epoch [5/100], Step [29400/6235], Loss: 0.1445\n",
      "Epoch [5/100], Step [29500/6235], Loss: 11.8645\n",
      "Epoch [5/100], Step [29600/6235], Loss: 0.7394\n",
      "Epoch [5/100], Step [29700/6235], Loss: 0.5402\n",
      "Epoch [5/100], Step [29800/6235], Loss: 1.7471\n",
      "Epoch [5/100], Step [29900/6235], Loss: 0.0736\n",
      "Epoch [5/100], Step [30000/6235], Loss: 8.8582\n",
      "Epoch [5/100], Step [30100/6235], Loss: 11.3287\n",
      "Epoch [5/100], Step [30200/6235], Loss: 0.0599\n",
      "Epoch [5/100], Step [30300/6235], Loss: 0.8247\n",
      "Epoch [5/100], Step [30400/6235], Loss: 0.1476\n",
      "Epoch [5/100], Step [30500/6235], Loss: 0.8321\n",
      "Epoch [5/100], Step [30600/6235], Loss: 0.0105\n",
      "Epoch [5/100], Step [30700/6235], Loss: 0.5951\n",
      "Epoch [5/100], Step [30800/6235], Loss: 0.1289\n",
      "Epoch [5/100], Step [30900/6235], Loss: 1.4367\n",
      "Epoch [5/100], Step [31000/6235], Loss: 0.2055\n",
      "Epoch [5/100], Step [31100/6235], Loss: 0.0991\n",
      "Epoch [5/100], Step [31200/6235], Loss: 12.3782\n",
      "Epoch [5/100], Step [31300/6235], Loss: 1.6404\n",
      "Epoch [5/100], Step [31400/6235], Loss: 7.7536\n",
      "Epoch [5/100], Step [31500/6235], Loss: 1.3279\n",
      "Epoch [5/100], Step [31600/6235], Loss: 2.7461\n",
      "Epoch [5/100], Step [31700/6235], Loss: 0.3836\n",
      "Epoch [5/100], Step [31800/6235], Loss: 0.8901\n",
      "Epoch [5/100], Step [31900/6235], Loss: 1576.1257\n",
      "Epoch [5/100], Step [32000/6235], Loss: 58.0257\n",
      "Epoch [5/100], Step [32100/6235], Loss: 6.3696\n",
      "Epoch [5/100], Step [32200/6235], Loss: 13.3000\n",
      "Epoch [5/100], Step [32300/6235], Loss: 0.1188\n",
      "Epoch [5/100], Step [32400/6235], Loss: 0.8468\n",
      "Epoch [5/100], Step [32500/6235], Loss: 7.8052\n",
      "Epoch [5/100], Step [32600/6235], Loss: 1.3721\n",
      "Epoch [5/100], Step [32700/6235], Loss: 115.0319\n",
      "Epoch [5/100], Step [32800/6235], Loss: 7.8562\n",
      "Epoch [5/100], Step [32900/6235], Loss: 2.2747\n",
      "Epoch [5/100], Step [33000/6235], Loss: 9.0363\n",
      "Epoch [5/100], Step [33100/6235], Loss: 0.5312\n",
      "Epoch [5/100], Step [33200/6235], Loss: 4.7953\n",
      "Epoch [5/100], Step [33300/6235], Loss: 8.7919\n",
      "Epoch [5/100], Step [33400/6235], Loss: 0.1831\n",
      "Epoch [5/100], Step [33500/6235], Loss: 1.8784\n",
      "Epoch [5/100], Step [33600/6235], Loss: 4.6269\n",
      "Epoch [5/100], Step [33700/6235], Loss: 1.2360\n",
      "Epoch [5/100], Step [33800/6235], Loss: 53.7437\n",
      "Epoch [5/100], Step [33900/6235], Loss: 4.7694\n",
      "Epoch [5/100], Step [34000/6235], Loss: 1.2159\n",
      "Epoch [5/100], Step [34100/6235], Loss: 0.0066\n",
      "Epoch [5/100], Step [34200/6235], Loss: 24.9859\n",
      "Epoch [5/100], Step [34300/6235], Loss: 0.9705\n",
      "Epoch [5/100], Step [34400/6235], Loss: 0.6494\n",
      "Epoch [5/100], Step [34500/6235], Loss: 55.5551\n",
      "Epoch [5/100], Step [34600/6235], Loss: 2.3403\n",
      "Epoch [5/100], Step [34700/6235], Loss: 3.1635\n",
      "Epoch [5/100], Step [34800/6235], Loss: 13.3009\n",
      "Epoch [5/100], Step [34900/6235], Loss: 10.1534\n",
      "Epoch [5/100], Step [35000/6235], Loss: 0.0373\n",
      "Epoch [5/100], Step [35100/6235], Loss: 5.8213\n",
      "Epoch [5/100], Step [35200/6235], Loss: 8.8576\n",
      "Epoch [5/100], Step [35300/6235], Loss: 4.8295\n",
      "Epoch [5/100], Step [35400/6235], Loss: 9.1569\n",
      "Epoch [5/100], Step [35500/6235], Loss: 0.0326\n",
      "Epoch [5/100], Step [35600/6235], Loss: 0.7260\n",
      "Epoch [5/100], Step [35700/6235], Loss: 8.4804\n",
      "Epoch [5/100], Step [35800/6235], Loss: 3.1774\n",
      "Epoch [5/100], Step [35900/6235], Loss: 10.7828\n",
      "Epoch [5/100], Step [36000/6235], Loss: 3.0896\n",
      "Epoch [5/100], Step [36100/6235], Loss: 22.7541\n",
      "Epoch [5/100], Step [36200/6235], Loss: 0.1119\n",
      "Epoch [5/100], Step [36300/6235], Loss: 5.6475\n",
      "Epoch [5/100], Step [36400/6235], Loss: 4.5499\n",
      "Epoch [5/100], Step [36500/6235], Loss: 1.2972\n",
      "Epoch [5/100], Step [36600/6235], Loss: 0.0394\n",
      "Epoch [5/100], Step [36700/6235], Loss: 8.1453\n",
      "Epoch [5/100], Step [36800/6235], Loss: 3.6718\n",
      "Epoch [5/100], Step [36900/6235], Loss: 9.1430\n",
      "Epoch [5/100], Step [37000/6235], Loss: 0.5786\n",
      "Epoch [5/100], Step [37100/6235], Loss: 0.9817\n",
      "Epoch [5/100], Step [37200/6235], Loss: 0.5439\n",
      "Epoch [5/100], Step [37300/6235], Loss: 1.8144\n",
      "Epoch [5/100], Step [37400/6235], Loss: 0.2446\n",
      "Epoch [5/100], Step [37500/6235], Loss: 1.8110\n",
      "Epoch [5/100], Step [37600/6235], Loss: 6.8609\n",
      "Epoch [5/100], Step [37700/6235], Loss: 7.9260\n",
      "Epoch [5/100], Step [37800/6235], Loss: 8.8353\n",
      "Epoch [5/100], Step [37900/6235], Loss: 13.6165\n",
      "Epoch [5/100], Step [38000/6235], Loss: 0.5519\n",
      "Epoch [5/100], Step [38100/6235], Loss: 0.0195\n",
      "Epoch [5/100], Step [38200/6235], Loss: 8.8341\n",
      "Epoch [5/100], Step [38300/6235], Loss: 0.0989\n",
      "Epoch [5/100], Step [38400/6235], Loss: 1.4834\n",
      "Epoch [5/100], Step [38500/6235], Loss: 0.3172\n",
      "Epoch [5/100], Step [38600/6235], Loss: 7.2143\n",
      "Epoch [5/100], Step [38700/6235], Loss: 0.3819\n",
      "Epoch [5/100], Step [38800/6235], Loss: 1.1658\n",
      "Epoch [5/100], Step [38900/6235], Loss: 4.6795\n",
      "Epoch [5/100], Step [39000/6235], Loss: 7.2171\n",
      "Epoch [5/100], Step [39100/6235], Loss: 25.4773\n",
      "Epoch [5/100], Step [39200/6235], Loss: 0.3944\n",
      "Epoch [5/100], Step [39300/6235], Loss: 78.7431\n",
      "Epoch [5/100], Step [39400/6235], Loss: 71.0055\n",
      "Epoch [5/100], Step [39500/6235], Loss: 369.5749\n",
      "Epoch [5/100], Step [39600/6235], Loss: 37.2080\n",
      "Epoch [5/100], Step [39700/6235], Loss: 150.8795\n",
      "Epoch [5/100], Step [39800/6235], Loss: 23.6913\n",
      "Epoch [5/100], Step [39900/6235], Loss: 18.5933\n",
      "Epoch [5/100], Step [40000/6235], Loss: 17.5167\n",
      "Epoch [5/100], Step [40100/6235], Loss: 20.5697\n",
      "Epoch [5/100], Step [40200/6235], Loss: 194.9757\n",
      "Epoch [5/100], Step [40300/6235], Loss: 12.6054\n",
      "Epoch [5/100], Step [40400/6235], Loss: 33.9850\n",
      "Epoch [5/100], Step [40500/6235], Loss: 0.2336\n",
      "Epoch [5/100], Step [40600/6235], Loss: 13.4285\n",
      "Epoch [5/100], Step [40700/6235], Loss: 6.7943\n",
      "Epoch [5/100], Step [40800/6235], Loss: 4.6446\n",
      "Epoch [5/100], Step [40900/6235], Loss: 0.9805\n",
      "Epoch [5/100], Step [41000/6235], Loss: 27.1758\n",
      "Epoch [5/100], Step [41100/6235], Loss: 8.9434\n",
      "Epoch [5/100], Step [41200/6235], Loss: 12.5464\n",
      "Epoch [5/100], Step [41300/6235], Loss: 0.1643\n",
      "Epoch [5/100], Step [41400/6235], Loss: 0.1300\n",
      "Epoch [5/100], Step [41500/6235], Loss: 0.8876\n",
      "Epoch [5/100], Step [41600/6235], Loss: 0.4435\n",
      "Epoch [5/100], Step [41700/6235], Loss: 2.1894\n",
      "Epoch [5/100], Step [41800/6235], Loss: 0.4694\n",
      "Epoch [5/100], Step [41900/6235], Loss: 0.5447\n",
      "Epoch [5/100], Step [42000/6235], Loss: 21.8252\n",
      "Epoch [5/100], Step [42100/6235], Loss: 0.2820\n",
      "Epoch [5/100], Step [42200/6235], Loss: 80.5745\n",
      "Epoch [5/100], Step [42300/6235], Loss: 0.6341\n",
      "Epoch [5/100], Step [42400/6235], Loss: 2.1546\n",
      "Epoch [5/100], Step [42500/6235], Loss: 1.4074\n",
      "Epoch [5/100], Step [42600/6235], Loss: 0.5636\n",
      "Epoch [5/100], Step [42700/6235], Loss: 1.5829\n",
      "Epoch [5/100], Step [42800/6235], Loss: 2.1597\n",
      "Epoch [5/100], Step [42900/6235], Loss: 0.5609\n",
      "Epoch [5/100], Step [43000/6235], Loss: 0.1263\n",
      "Epoch [5/100], Step [43100/6235], Loss: 1.1507\n",
      "Epoch [5/100], Step [43200/6235], Loss: 0.0235\n",
      "Epoch [5/100], Step [43300/6235], Loss: 9.0393\n",
      "Epoch [5/100], Step [43400/6235], Loss: 0.1393\n",
      "Epoch [5/100], Step [43500/6235], Loss: 0.1471\n",
      "Epoch [5/100], Step [43600/6235], Loss: 25.3303\n",
      "Epoch [5/100], Step [43700/6235], Loss: 8.0575\n",
      "Epoch [5/100], Step [43800/6235], Loss: 10.7151\n",
      "Epoch [5/100], Step [43900/6235], Loss: 0.8265\n",
      "Epoch [5/100], Step [44000/6235], Loss: 108.9102\n",
      "Epoch [5/100], Step [44100/6235], Loss: 0.0972\n",
      "Epoch [5/100], Step [44200/6235], Loss: 18.7817\n",
      "Epoch [5/100], Step [44300/6235], Loss: 16.1862\n",
      "Epoch [5/100], Step [44400/6235], Loss: 0.8025\n",
      "Epoch [5/100], Step [44500/6235], Loss: 3.7457\n",
      "Epoch [5/100], Step [44600/6235], Loss: 20.1999\n",
      "Epoch [5/100], Step [44700/6235], Loss: 1.5489\n",
      "Epoch [5/100], Step [44800/6235], Loss: 2.9369\n",
      "Epoch [5/100], Step [44900/6235], Loss: 2.8380\n",
      "Epoch [5/100], Step [45000/6235], Loss: 0.7728\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/100], Step [45100/6235], Loss: 3.3045\n",
      "Epoch [5/100], Step [45200/6235], Loss: 3.3854\n",
      "Epoch [5/100], Step [45300/6235], Loss: 0.8071\n",
      "Epoch [5/100], Step [45400/6235], Loss: 0.0703\n",
      "Epoch [5/100], Step [45500/6235], Loss: 3.3383\n",
      "Epoch [5/100], Step [45600/6235], Loss: 3.1693\n",
      "Epoch [5/100], Step [45700/6235], Loss: 1.1875\n",
      "Epoch [5/100], Step [45800/6235], Loss: 323.6961\n",
      "Epoch [5/100], Step [45900/6235], Loss: 7.9300\n",
      "Epoch [5/100], Step [46000/6235], Loss: 5.9735\n",
      "Epoch [5/100], Step [46100/6235], Loss: 8.3657\n",
      "Epoch [5/100], Step [46200/6235], Loss: 83.6181\n",
      "Epoch [5/100], Step [46300/6235], Loss: 6.1695\n",
      "Epoch [5/100], Step [46400/6235], Loss: 2.9634\n",
      "Epoch [5/100], Step [46500/6235], Loss: 6.7990\n",
      "Epoch [5/100], Step [46600/6235], Loss: 0.2330\n",
      "Epoch [5/100], Step [46700/6235], Loss: 3.7394\n",
      "Epoch [5/100], Step [46800/6235], Loss: 28.3217\n",
      "Epoch [5/100], Step [46900/6235], Loss: 35.6077\n",
      "Epoch [5/100], Step [47000/6235], Loss: 2.4092\n",
      "Epoch [5/100], Step [47100/6235], Loss: 98.0809\n",
      "Epoch [5/100], Step [47200/6235], Loss: 98.6573\n",
      "Epoch [5/100], Step [47300/6235], Loss: 1.5330\n",
      "Epoch [5/100], Step [47400/6235], Loss: 277.2380\n",
      "Epoch [5/100], Step [47500/6235], Loss: 22.1246\n",
      "Epoch [5/100], Step [47600/6235], Loss: 1.2912\n",
      "Epoch [5/100], Step [47700/6235], Loss: 24.8303\n",
      "Epoch [5/100], Step [47800/6235], Loss: 54.3205\n",
      "Epoch [5/100], Step [47900/6235], Loss: 16.5760\n",
      "Epoch [5/100], Step [48000/6235], Loss: 53.6329\n",
      "Epoch [5/100], Step [48100/6235], Loss: 5.6745\n",
      "Epoch [5/100], Step [48200/6235], Loss: 5.1119\n",
      "Epoch [5/100], Step [48300/6235], Loss: 472.4106\n",
      "Epoch [5/100], Step [48400/6235], Loss: 10.0777\n",
      "Epoch [5/100], Step [48500/6235], Loss: 47.0636\n",
      "Epoch [5/100], Step [48600/6235], Loss: 115.3012\n",
      "Epoch [5/100], Step [48700/6235], Loss: 0.4330\n",
      "Epoch [5/100], Step [48800/6235], Loss: 202.6457\n",
      "Epoch [5/100], Step [48900/6235], Loss: 295.5604\n",
      "Epoch [5/100], Step [49000/6235], Loss: 222.6075\n",
      "Epoch [5/100], Step [49100/6235], Loss: 2448.1938\n",
      "Epoch [5/100], Step [49200/6235], Loss: 536.6490\n",
      "Epoch [5/100], Step [49300/6235], Loss: 967.4700\n",
      "Epoch [5/100], Step [49400/6235], Loss: 15.0979\n",
      "Epoch [5/100], Step [49500/6235], Loss: 6.7785\n",
      "Epoch [5/100], Step [49600/6235], Loss: 216.6885\n",
      "Epoch [5/100], Step [49700/6235], Loss: 8459.9268\n",
      "Epoch [5/100], Step [49800/6235], Loss: 2658.0396\n",
      "Epoch [6/100], Step [100/6235], Loss: 36.1172\n",
      "Epoch [6/100], Step [200/6235], Loss: 0.3017\n",
      "Epoch [6/100], Step [300/6235], Loss: 0.0568\n",
      "Epoch [6/100], Step [400/6235], Loss: 0.0173\n",
      "Epoch [6/100], Step [500/6235], Loss: 1.3231\n",
      "Epoch [6/100], Step [600/6235], Loss: 0.0427\n",
      "Epoch [6/100], Step [700/6235], Loss: 0.3166\n",
      "Epoch [6/100], Step [800/6235], Loss: 0.0156\n",
      "Epoch [6/100], Step [900/6235], Loss: 0.0327\n",
      "Epoch [6/100], Step [1000/6235], Loss: 0.0157\n",
      "Epoch [6/100], Step [1100/6235], Loss: 0.0848\n",
      "Epoch [6/100], Step [1200/6235], Loss: 0.1269\n",
      "Epoch [6/100], Step [1300/6235], Loss: 0.0173\n",
      "Epoch [6/100], Step [1400/6235], Loss: 0.1908\n",
      "Epoch [6/100], Step [1500/6235], Loss: 0.0025\n",
      "Epoch [6/100], Step [1600/6235], Loss: 0.2702\n",
      "Epoch [6/100], Step [1700/6235], Loss: 0.1730\n",
      "Epoch [6/100], Step [1800/6235], Loss: 0.3818\n",
      "Epoch [6/100], Step [1900/6235], Loss: 0.1644\n",
      "Epoch [6/100], Step [2000/6235], Loss: 2.1062\n",
      "Epoch [6/100], Step [2100/6235], Loss: 3.5977\n",
      "Epoch [6/100], Step [2200/6235], Loss: 1.9570\n",
      "Epoch [6/100], Step [2300/6235], Loss: 1.6584\n",
      "Epoch [6/100], Step [2400/6235], Loss: 13.6740\n",
      "Epoch [6/100], Step [2500/6235], Loss: 2.8017\n",
      "Epoch [6/100], Step [2600/6235], Loss: 14.1291\n",
      "Epoch [6/100], Step [2700/6235], Loss: 21.9340\n",
      "Epoch [6/100], Step [2800/6235], Loss: 21.6741\n",
      "Epoch [6/100], Step [2900/6235], Loss: 12.3551\n",
      "Epoch [6/100], Step [3000/6235], Loss: 11.0503\n",
      "Epoch [6/100], Step [3100/6235], Loss: 96.5920\n",
      "Epoch [6/100], Step [3200/6235], Loss: 1.8365\n",
      "Epoch [6/100], Step [3300/6235], Loss: 1.4879\n",
      "Epoch [6/100], Step [3400/6235], Loss: 5.9506\n",
      "Epoch [6/100], Step [3500/6235], Loss: 92.5062\n",
      "Epoch [6/100], Step [3600/6235], Loss: 5.2992\n",
      "Epoch [6/100], Step [3700/6235], Loss: 2.5211\n",
      "Epoch [6/100], Step [3800/6235], Loss: 0.5975\n",
      "Epoch [6/100], Step [3900/6235], Loss: 0.9585\n",
      "Epoch [6/100], Step [4000/6235], Loss: 0.9461\n",
      "Epoch [6/100], Step [4100/6235], Loss: 2.4154\n",
      "Epoch [6/100], Step [4200/6235], Loss: 1.2166\n",
      "Epoch [6/100], Step [4300/6235], Loss: 2.5358\n",
      "Epoch [6/100], Step [4400/6235], Loss: 0.1428\n",
      "Epoch [6/100], Step [4500/6235], Loss: 70.4289\n",
      "Epoch [6/100], Step [4600/6235], Loss: 21.5535\n",
      "Epoch [6/100], Step [4700/6235], Loss: 7.2193\n",
      "Epoch [6/100], Step [4800/6235], Loss: 1.3251\n",
      "Epoch [6/100], Step [4900/6235], Loss: 1.1916\n",
      "Epoch [6/100], Step [5000/6235], Loss: 0.6127\n",
      "Epoch [6/100], Step [5100/6235], Loss: 8.7956\n",
      "Epoch [6/100], Step [5200/6235], Loss: 0.9150\n",
      "Epoch [6/100], Step [5300/6235], Loss: 5.9595\n",
      "Epoch [6/100], Step [5400/6235], Loss: 0.3180\n",
      "Epoch [6/100], Step [5500/6235], Loss: 0.1101\n",
      "Epoch [6/100], Step [5600/6235], Loss: 0.2259\n",
      "Epoch [6/100], Step [5700/6235], Loss: 1.7958\n",
      "Epoch [6/100], Step [5800/6235], Loss: 0.3169\n",
      "Epoch [6/100], Step [5900/6235], Loss: 0.0780\n",
      "Epoch [6/100], Step [6000/6235], Loss: 0.0502\n",
      "Epoch [6/100], Step [6100/6235], Loss: 0.3124\n",
      "Epoch [6/100], Step [6200/6235], Loss: 1.7311\n",
      "Epoch [6/100], Step [6300/6235], Loss: 0.6466\n",
      "Epoch [6/100], Step [6400/6235], Loss: 0.0563\n",
      "Epoch [6/100], Step [6500/6235], Loss: 0.3510\n",
      "Epoch [6/100], Step [6600/6235], Loss: 1.1481\n",
      "Epoch [6/100], Step [6700/6235], Loss: 0.3401\n",
      "Epoch [6/100], Step [6800/6235], Loss: 1.7981\n",
      "Epoch [6/100], Step [6900/6235], Loss: 1.5112\n",
      "Epoch [6/100], Step [7000/6235], Loss: 0.0667\n",
      "Epoch [6/100], Step [7100/6235], Loss: 0.8013\n",
      "Epoch [6/100], Step [7200/6235], Loss: 0.0848\n",
      "Epoch [6/100], Step [7300/6235], Loss: 0.1103\n",
      "Epoch [6/100], Step [7400/6235], Loss: 0.9003\n",
      "Epoch [6/100], Step [7500/6235], Loss: 0.9127\n",
      "Epoch [6/100], Step [7600/6235], Loss: 2.5321\n",
      "Epoch [6/100], Step [7700/6235], Loss: 1.5167\n",
      "Epoch [6/100], Step [7800/6235], Loss: 0.3635\n",
      "Epoch [6/100], Step [7900/6235], Loss: 5.1838\n",
      "Epoch [6/100], Step [8000/6235], Loss: 0.0542\n",
      "Epoch [6/100], Step [8100/6235], Loss: 2.2691\n",
      "Epoch [6/100], Step [8200/6235], Loss: 7.1084\n",
      "Epoch [6/100], Step [8300/6235], Loss: 10.6855\n",
      "Epoch [6/100], Step [8400/6235], Loss: 440.4832\n",
      "Epoch [6/100], Step [8500/6235], Loss: 0.5796\n",
      "Epoch [6/100], Step [8600/6235], Loss: 124.2996\n",
      "Epoch [6/100], Step [8700/6235], Loss: 78.0180\n",
      "Epoch [6/100], Step [8800/6235], Loss: 318.3060\n",
      "Epoch [6/100], Step [8900/6235], Loss: 2.5108\n",
      "Epoch [6/100], Step [9000/6235], Loss: 296.9239\n",
      "Epoch [6/100], Step [9100/6235], Loss: 354.9940\n",
      "Epoch [6/100], Step [9200/6235], Loss: 2261.2322\n",
      "Epoch [6/100], Step [9300/6235], Loss: 81.5901\n",
      "Epoch [6/100], Step [9400/6235], Loss: 1232.3285\n",
      "Epoch [6/100], Step [9500/6235], Loss: 299.8868\n",
      "Epoch [6/100], Step [9600/6235], Loss: 143.1583\n",
      "Epoch [6/100], Step [9700/6235], Loss: 216.5017\n",
      "Epoch [6/100], Step [9800/6235], Loss: 91.0380\n",
      "Epoch [6/100], Step [9900/6235], Loss: 53.3532\n",
      "Epoch [6/100], Step [10000/6235], Loss: 145.8185\n",
      "Epoch [6/100], Step [10100/6235], Loss: 1.2369\n",
      "Epoch [6/100], Step [10200/6235], Loss: 516.2622\n",
      "Epoch [6/100], Step [10300/6235], Loss: 0.3011\n",
      "Epoch [6/100], Step [10400/6235], Loss: 3.0024\n",
      "Epoch [6/100], Step [10500/6235], Loss: 11.7152\n",
      "Epoch [6/100], Step [10600/6235], Loss: 534.2643\n",
      "Epoch [6/100], Step [10700/6235], Loss: 240.8805\n",
      "Epoch [6/100], Step [10800/6235], Loss: 0.7232\n",
      "Epoch [6/100], Step [10900/6235], Loss: 5.1414\n",
      "Epoch [6/100], Step [11000/6235], Loss: 46.4149\n",
      "Epoch [6/100], Step [11100/6235], Loss: 0.6365\n",
      "Epoch [6/100], Step [11200/6235], Loss: 123.5181\n",
      "Epoch [6/100], Step [11300/6235], Loss: 212.9944\n",
      "Epoch [6/100], Step [11400/6235], Loss: 327.4835\n",
      "Epoch [6/100], Step [11500/6235], Loss: 11.1607\n",
      "Epoch [6/100], Step [11600/6235], Loss: 1.6841\n",
      "Epoch [6/100], Step [11700/6235], Loss: 165.9516\n",
      "Epoch [6/100], Step [11800/6235], Loss: 24.0667\n",
      "Epoch [6/100], Step [11900/6235], Loss: 883.2521\n",
      "Epoch [6/100], Step [12000/6235], Loss: 587.0889\n",
      "Epoch [6/100], Step [12100/6235], Loss: 389.0371\n",
      "Epoch [6/100], Step [12200/6235], Loss: 12.5968\n",
      "Epoch [6/100], Step [12300/6235], Loss: 7.6487\n",
      "Epoch [6/100], Step [12400/6235], Loss: 41.2340\n",
      "Epoch [6/100], Step [12500/6235], Loss: 212.2114\n",
      "Epoch [6/100], Step [12600/6235], Loss: 10.5973\n",
      "Epoch [6/100], Step [12700/6235], Loss: 34.3476\n",
      "Epoch [6/100], Step [12800/6235], Loss: 14.9096\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Step [12900/6235], Loss: 68.0055\n",
      "Epoch [6/100], Step [13000/6235], Loss: 1.1503\n",
      "Epoch [6/100], Step [13100/6235], Loss: 117.8159\n",
      "Epoch [6/100], Step [13200/6235], Loss: 32.8024\n",
      "Epoch [6/100], Step [13300/6235], Loss: 18.3512\n",
      "Epoch [6/100], Step [13400/6235], Loss: 34.1119\n",
      "Epoch [6/100], Step [13500/6235], Loss: 7.6226\n",
      "Epoch [6/100], Step [13600/6235], Loss: 1.4993\n",
      "Epoch [6/100], Step [13700/6235], Loss: 14.7954\n",
      "Epoch [6/100], Step [13800/6235], Loss: 134.5361\n",
      "Epoch [6/100], Step [13900/6235], Loss: 44.0357\n",
      "Epoch [6/100], Step [14000/6235], Loss: 10.5650\n",
      "Epoch [6/100], Step [14100/6235], Loss: 11.0037\n",
      "Epoch [6/100], Step [14200/6235], Loss: 105.3059\n",
      "Epoch [6/100], Step [14300/6235], Loss: 10.5442\n",
      "Epoch [6/100], Step [14400/6235], Loss: 16.4637\n",
      "Epoch [6/100], Step [14500/6235], Loss: 26.8028\n",
      "Epoch [6/100], Step [14600/6235], Loss: 3.0706\n",
      "Epoch [6/100], Step [14700/6235], Loss: 25.4150\n",
      "Epoch [6/100], Step [14800/6235], Loss: 31.7179\n",
      "Epoch [6/100], Step [14900/6235], Loss: 0.7594\n",
      "Epoch [6/100], Step [15000/6235], Loss: 0.9661\n",
      "Epoch [6/100], Step [15100/6235], Loss: 0.1923\n",
      "Epoch [6/100], Step [15200/6235], Loss: 66.4838\n",
      "Epoch [6/100], Step [15300/6235], Loss: 7.3696\n",
      "Epoch [6/100], Step [15400/6235], Loss: 8.7139\n",
      "Epoch [6/100], Step [15500/6235], Loss: 33.4836\n",
      "Epoch [6/100], Step [15600/6235], Loss: 106.6012\n",
      "Epoch [6/100], Step [15700/6235], Loss: 8.5246\n",
      "Epoch [6/100], Step [15800/6235], Loss: 0.2374\n",
      "Epoch [6/100], Step [15900/6235], Loss: 1.1187\n",
      "Epoch [6/100], Step [16000/6235], Loss: 17.4151\n",
      "Epoch [6/100], Step [16100/6235], Loss: 0.6773\n",
      "Epoch [6/100], Step [16200/6235], Loss: 0.8864\n",
      "Epoch [6/100], Step [16300/6235], Loss: 44.5501\n",
      "Epoch [6/100], Step [16400/6235], Loss: 75.4152\n",
      "Epoch [6/100], Step [16500/6235], Loss: 598.0695\n",
      "Epoch [6/100], Step [16600/6235], Loss: 5.9766\n",
      "Epoch [6/100], Step [16700/6235], Loss: 7.2203\n",
      "Epoch [6/100], Step [16800/6235], Loss: 1.5160\n",
      "Epoch [6/100], Step [16900/6235], Loss: 4.3197\n",
      "Epoch [6/100], Step [17000/6235], Loss: 4.5376\n",
      "Epoch [6/100], Step [17100/6235], Loss: 1.9735\n",
      "Epoch [6/100], Step [17200/6235], Loss: 26.3976\n",
      "Epoch [6/100], Step [17300/6235], Loss: 19.2223\n",
      "Epoch [6/100], Step [17400/6235], Loss: 38.7258\n",
      "Epoch [6/100], Step [17500/6235], Loss: 6.7564\n",
      "Epoch [6/100], Step [17600/6235], Loss: 0.4644\n",
      "Epoch [6/100], Step [17700/6235], Loss: 19.7472\n",
      "Epoch [6/100], Step [17800/6235], Loss: 32.3294\n",
      "Epoch [6/100], Step [17900/6235], Loss: 131.1982\n",
      "Epoch [6/100], Step [18000/6235], Loss: 0.9741\n",
      "Epoch [6/100], Step [18100/6235], Loss: 6.8868\n",
      "Epoch [6/100], Step [18200/6235], Loss: 19.8035\n",
      "Epoch [6/100], Step [18300/6235], Loss: 6.7415\n",
      "Epoch [6/100], Step [18400/6235], Loss: 10.8130\n",
      "Epoch [6/100], Step [18500/6235], Loss: 5.3623\n",
      "Epoch [6/100], Step [18600/6235], Loss: 4.0565\n",
      "Epoch [6/100], Step [18700/6235], Loss: 0.2063\n",
      "Epoch [6/100], Step [18800/6235], Loss: 132.0912\n",
      "Epoch [6/100], Step [18900/6235], Loss: 34.3999\n",
      "Epoch [6/100], Step [19000/6235], Loss: 6.3526\n",
      "Epoch [6/100], Step [19100/6235], Loss: 33.6698\n",
      "Epoch [6/100], Step [19200/6235], Loss: 1.4318\n",
      "Epoch [6/100], Step [19300/6235], Loss: 5.5962\n",
      "Epoch [6/100], Step [19400/6235], Loss: 60.6859\n",
      "Epoch [6/100], Step [19500/6235], Loss: 64.2247\n",
      "Epoch [6/100], Step [19600/6235], Loss: 130.2822\n",
      "Epoch [6/100], Step [19700/6235], Loss: 8.2766\n",
      "Epoch [6/100], Step [19800/6235], Loss: 0.8499\n",
      "Epoch [6/100], Step [19900/6235], Loss: 1.6019\n",
      "Epoch [6/100], Step [20000/6235], Loss: 65.3534\n",
      "Epoch [6/100], Step [20100/6235], Loss: 0.9494\n",
      "Epoch [6/100], Step [20200/6235], Loss: 4.1424\n",
      "Epoch [6/100], Step [20300/6235], Loss: 1.6789\n",
      "Epoch [6/100], Step [20400/6235], Loss: 24.1477\n",
      "Epoch [6/100], Step [20500/6235], Loss: 27.9293\n",
      "Epoch [6/100], Step [20600/6235], Loss: 255.7661\n",
      "Epoch [6/100], Step [20700/6235], Loss: 30.9110\n",
      "Epoch [6/100], Step [20800/6235], Loss: 36.6366\n",
      "Epoch [6/100], Step [20900/6235], Loss: 20.1698\n",
      "Epoch [6/100], Step [21000/6235], Loss: 21.5352\n",
      "Epoch [6/100], Step [21100/6235], Loss: 15.6439\n",
      "Epoch [6/100], Step [21200/6235], Loss: 0.8203\n",
      "Epoch [6/100], Step [21300/6235], Loss: 1.0835\n",
      "Epoch [6/100], Step [21400/6235], Loss: 3.7407\n",
      "Epoch [6/100], Step [21500/6235], Loss: 1.9405\n",
      "Epoch [6/100], Step [21600/6235], Loss: 31.5149\n",
      "Epoch [6/100], Step [21700/6235], Loss: 0.1855\n",
      "Epoch [6/100], Step [21800/6235], Loss: 0.0664\n",
      "Epoch [6/100], Step [21900/6235], Loss: 0.3027\n",
      "Epoch [6/100], Step [22000/6235], Loss: 4.4475\n",
      "Epoch [6/100], Step [22100/6235], Loss: 2.0131\n",
      "Epoch [6/100], Step [22200/6235], Loss: 1.7270\n",
      "Epoch [6/100], Step [22300/6235], Loss: 0.4896\n",
      "Epoch [6/100], Step [22400/6235], Loss: 23.1595\n",
      "Epoch [6/100], Step [22500/6235], Loss: 25.2546\n",
      "Epoch [6/100], Step [22600/6235], Loss: 21.5603\n",
      "Epoch [6/100], Step [22700/6235], Loss: 1.1404\n",
      "Epoch [6/100], Step [22800/6235], Loss: 5.1764\n",
      "Epoch [6/100], Step [22900/6235], Loss: 15.0402\n",
      "Epoch [6/100], Step [23000/6235], Loss: 10.7196\n",
      "Epoch [6/100], Step [23100/6235], Loss: 8.9887\n",
      "Epoch [6/100], Step [23200/6235], Loss: 2.2844\n",
      "Epoch [6/100], Step [23300/6235], Loss: 19.9904\n",
      "Epoch [6/100], Step [23400/6235], Loss: 2.6646\n",
      "Epoch [6/100], Step [23500/6235], Loss: 0.5081\n",
      "Epoch [6/100], Step [23600/6235], Loss: 131.3111\n",
      "Epoch [6/100], Step [23700/6235], Loss: 6.7790\n",
      "Epoch [6/100], Step [23800/6235], Loss: 0.8041\n",
      "Epoch [6/100], Step [23900/6235], Loss: 0.9489\n",
      "Epoch [6/100], Step [24000/6235], Loss: 1.0214\n",
      "Epoch [6/100], Step [24100/6235], Loss: 0.4807\n",
      "Epoch [6/100], Step [24200/6235], Loss: 0.7711\n",
      "Epoch [6/100], Step [24300/6235], Loss: 2.0089\n",
      "Epoch [6/100], Step [24400/6235], Loss: 10.2197\n",
      "Epoch [6/100], Step [24500/6235], Loss: 3.2958\n",
      "Epoch [6/100], Step [24600/6235], Loss: 0.3504\n",
      "Epoch [6/100], Step [24700/6235], Loss: 7.0197\n",
      "Epoch [6/100], Step [24800/6235], Loss: 0.0861\n",
      "Epoch [6/100], Step [24900/6235], Loss: 10.2786\n",
      "Epoch [6/100], Step [25000/6235], Loss: 18.3597\n",
      "Epoch [6/100], Step [25100/6235], Loss: 6.8000\n",
      "Epoch [6/100], Step [25200/6235], Loss: 1.4670\n",
      "Epoch [6/100], Step [25300/6235], Loss: 0.6175\n",
      "Epoch [6/100], Step [25400/6235], Loss: 6.8867\n",
      "Epoch [6/100], Step [25500/6235], Loss: 9.4837\n",
      "Epoch [6/100], Step [25600/6235], Loss: 5.9510\n",
      "Epoch [6/100], Step [25700/6235], Loss: 0.0398\n",
      "Epoch [6/100], Step [25800/6235], Loss: 0.1369\n",
      "Epoch [6/100], Step [25900/6235], Loss: 2.5614\n",
      "Epoch [6/100], Step [26000/6235], Loss: 1.6575\n",
      "Epoch [6/100], Step [26100/6235], Loss: 0.0384\n",
      "Epoch [6/100], Step [26200/6235], Loss: 0.9526\n",
      "Epoch [6/100], Step [26300/6235], Loss: 5.4556\n",
      "Epoch [6/100], Step [26400/6235], Loss: 0.1189\n",
      "Epoch [6/100], Step [26500/6235], Loss: 0.0400\n",
      "Epoch [6/100], Step [26600/6235], Loss: 1.3675\n",
      "Epoch [6/100], Step [26700/6235], Loss: 0.4072\n",
      "Epoch [6/100], Step [26800/6235], Loss: 0.2800\n",
      "Epoch [6/100], Step [26900/6235], Loss: 0.0048\n",
      "Epoch [6/100], Step [27000/6235], Loss: 15.3297\n",
      "Epoch [6/100], Step [27100/6235], Loss: 0.0496\n",
      "Epoch [6/100], Step [27200/6235], Loss: 0.0114\n",
      "Epoch [6/100], Step [27300/6235], Loss: 0.1872\n",
      "Epoch [6/100], Step [27400/6235], Loss: 0.8089\n",
      "Epoch [6/100], Step [27500/6235], Loss: 21.0184\n",
      "Epoch [6/100], Step [27600/6235], Loss: 1.4040\n",
      "Epoch [6/100], Step [27700/6235], Loss: 1.5726\n",
      "Epoch [6/100], Step [27800/6235], Loss: 5.4544\n",
      "Epoch [6/100], Step [27900/6235], Loss: 1.9697\n",
      "Epoch [6/100], Step [28000/6235], Loss: 175.6645\n",
      "Epoch [6/100], Step [28100/6235], Loss: 0.4190\n",
      "Epoch [6/100], Step [28200/6235], Loss: 26.4077\n",
      "Epoch [6/100], Step [28300/6235], Loss: 4.3691\n",
      "Epoch [6/100], Step [28400/6235], Loss: 15.3170\n",
      "Epoch [6/100], Step [28500/6235], Loss: 0.7454\n",
      "Epoch [6/100], Step [28600/6235], Loss: 1.3737\n",
      "Epoch [6/100], Step [28700/6235], Loss: 3.5975\n",
      "Epoch [6/100], Step [28800/6235], Loss: 0.1850\n",
      "Epoch [6/100], Step [28900/6235], Loss: 72.1415\n",
      "Epoch [6/100], Step [29000/6235], Loss: 9.7370\n",
      "Epoch [6/100], Step [29100/6235], Loss: 0.0500\n",
      "Epoch [6/100], Step [29200/6235], Loss: 0.2949\n",
      "Epoch [6/100], Step [29300/6235], Loss: 7.1613\n",
      "Epoch [6/100], Step [29400/6235], Loss: 0.0519\n",
      "Epoch [6/100], Step [29500/6235], Loss: 1.6044\n",
      "Epoch [6/100], Step [29600/6235], Loss: 0.4851\n",
      "Epoch [6/100], Step [29700/6235], Loss: 1.9357\n",
      "Epoch [6/100], Step [29800/6235], Loss: 1.3813\n",
      "Epoch [6/100], Step [29900/6235], Loss: 0.6102\n",
      "Epoch [6/100], Step [30000/6235], Loss: 5.6166\n",
      "Epoch [6/100], Step [30100/6235], Loss: 10.8889\n",
      "Epoch [6/100], Step [30200/6235], Loss: 1.1784\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Step [30300/6235], Loss: 0.0038\n",
      "Epoch [6/100], Step [30400/6235], Loss: 1.0540\n",
      "Epoch [6/100], Step [30500/6235], Loss: 3.1956\n",
      "Epoch [6/100], Step [30600/6235], Loss: 1.2044\n",
      "Epoch [6/100], Step [30700/6235], Loss: 0.0268\n",
      "Epoch [6/100], Step [30800/6235], Loss: 0.3448\n",
      "Epoch [6/100], Step [30900/6235], Loss: 3.0501\n",
      "Epoch [6/100], Step [31000/6235], Loss: 0.0321\n",
      "Epoch [6/100], Step [31100/6235], Loss: 0.0871\n",
      "Epoch [6/100], Step [31200/6235], Loss: 7.3377\n",
      "Epoch [6/100], Step [31300/6235], Loss: 5.8822\n",
      "Epoch [6/100], Step [31400/6235], Loss: 2.7518\n",
      "Epoch [6/100], Step [31500/6235], Loss: 1.6528\n",
      "Epoch [6/100], Step [31600/6235], Loss: 5.6818\n",
      "Epoch [6/100], Step [31700/6235], Loss: 2.7867\n",
      "Epoch [6/100], Step [31800/6235], Loss: 1.7263\n",
      "Epoch [6/100], Step [31900/6235], Loss: 1522.7795\n",
      "Epoch [6/100], Step [32000/6235], Loss: 18.6421\n",
      "Epoch [6/100], Step [32100/6235], Loss: 9.5768\n",
      "Epoch [6/100], Step [32200/6235], Loss: 13.2427\n",
      "Epoch [6/100], Step [32300/6235], Loss: 0.3480\n",
      "Epoch [6/100], Step [32400/6235], Loss: 0.2765\n",
      "Epoch [6/100], Step [32500/6235], Loss: 18.9148\n",
      "Epoch [6/100], Step [32600/6235], Loss: 1.3057\n",
      "Epoch [6/100], Step [32700/6235], Loss: 38.7159\n",
      "Epoch [6/100], Step [32800/6235], Loss: 1.4316\n",
      "Epoch [6/100], Step [32900/6235], Loss: 6.6014\n",
      "Epoch [6/100], Step [33000/6235], Loss: 5.3065\n",
      "Epoch [6/100], Step [33100/6235], Loss: 0.2756\n",
      "Epoch [6/100], Step [33200/6235], Loss: 5.1905\n",
      "Epoch [6/100], Step [33300/6235], Loss: 3.8464\n",
      "Epoch [6/100], Step [33400/6235], Loss: 1.2721\n",
      "Epoch [6/100], Step [33500/6235], Loss: 1.5540\n",
      "Epoch [6/100], Step [33600/6235], Loss: 0.6522\n",
      "Epoch [6/100], Step [33700/6235], Loss: 3.4203\n",
      "Epoch [6/100], Step [33800/6235], Loss: 36.5731\n",
      "Epoch [6/100], Step [33900/6235], Loss: 18.6230\n",
      "Epoch [6/100], Step [34000/6235], Loss: 0.4027\n",
      "Epoch [6/100], Step [34100/6235], Loss: 0.1918\n",
      "Epoch [6/100], Step [34200/6235], Loss: 29.3672\n",
      "Epoch [6/100], Step [34300/6235], Loss: 0.0682\n",
      "Epoch [6/100], Step [34400/6235], Loss: 2.3495\n",
      "Epoch [6/100], Step [34500/6235], Loss: 129.4253\n",
      "Epoch [6/100], Step [34600/6235], Loss: 1.6074\n",
      "Epoch [6/100], Step [34700/6235], Loss: 0.7251\n",
      "Epoch [6/100], Step [34800/6235], Loss: 9.7573\n",
      "Epoch [6/100], Step [34900/6235], Loss: 26.4498\n",
      "Epoch [6/100], Step [35000/6235], Loss: 0.3329\n",
      "Epoch [6/100], Step [35100/6235], Loss: 7.9782\n",
      "Epoch [6/100], Step [35200/6235], Loss: 5.5202\n",
      "Epoch [6/100], Step [35300/6235], Loss: 5.1967\n",
      "Epoch [6/100], Step [35400/6235], Loss: 2.6802\n",
      "Epoch [6/100], Step [35500/6235], Loss: 0.0394\n",
      "Epoch [6/100], Step [35600/6235], Loss: 7.3090\n",
      "Epoch [6/100], Step [35700/6235], Loss: 16.2624\n",
      "Epoch [6/100], Step [35800/6235], Loss: 1.2478\n",
      "Epoch [6/100], Step [35900/6235], Loss: 0.6466\n",
      "Epoch [6/100], Step [36000/6235], Loss: 1.7924\n",
      "Epoch [6/100], Step [36100/6235], Loss: 18.6848\n",
      "Epoch [6/100], Step [36200/6235], Loss: 2.9040\n",
      "Epoch [6/100], Step [36300/6235], Loss: 4.9941\n",
      "Epoch [6/100], Step [36400/6235], Loss: 0.6102\n",
      "Epoch [6/100], Step [36500/6235], Loss: 1.3768\n",
      "Epoch [6/100], Step [36600/6235], Loss: 0.0832\n",
      "Epoch [6/100], Step [36700/6235], Loss: 3.4750\n",
      "Epoch [6/100], Step [36800/6235], Loss: 11.7513\n",
      "Epoch [6/100], Step [36900/6235], Loss: 7.4772\n",
      "Epoch [6/100], Step [37000/6235], Loss: 0.0870\n",
      "Epoch [6/100], Step [37100/6235], Loss: 0.0774\n",
      "Epoch [6/100], Step [37200/6235], Loss: 0.0615\n",
      "Epoch [6/100], Step [37300/6235], Loss: 0.7709\n",
      "Epoch [6/100], Step [37400/6235], Loss: 0.6105\n",
      "Epoch [6/100], Step [37500/6235], Loss: 0.6302\n",
      "Epoch [6/100], Step [37600/6235], Loss: 10.9536\n",
      "Epoch [6/100], Step [37700/6235], Loss: 0.1404\n",
      "Epoch [6/100], Step [37800/6235], Loss: 4.9218\n",
      "Epoch [6/100], Step [37900/6235], Loss: 5.8701\n",
      "Epoch [6/100], Step [38000/6235], Loss: 0.0480\n",
      "Epoch [6/100], Step [38100/6235], Loss: 5.8596\n",
      "Epoch [6/100], Step [38200/6235], Loss: 11.3592\n",
      "Epoch [6/100], Step [38300/6235], Loss: 0.9381\n",
      "Epoch [6/100], Step [38400/6235], Loss: 0.7534\n",
      "Epoch [6/100], Step [38500/6235], Loss: 0.2615\n",
      "Epoch [6/100], Step [38600/6235], Loss: 8.7676\n",
      "Epoch [6/100], Step [38700/6235], Loss: 0.2145\n",
      "Epoch [6/100], Step [38800/6235], Loss: 2.2279\n",
      "Epoch [6/100], Step [38900/6235], Loss: 8.6519\n",
      "Epoch [6/100], Step [39000/6235], Loss: 5.5514\n",
      "Epoch [6/100], Step [39100/6235], Loss: 7.9210\n",
      "Epoch [6/100], Step [39200/6235], Loss: 1.4085\n",
      "Epoch [6/100], Step [39300/6235], Loss: 30.7391\n",
      "Epoch [6/100], Step [39400/6235], Loss: 260.4542\n",
      "Epoch [6/100], Step [39500/6235], Loss: 171.8149\n",
      "Epoch [6/100], Step [39600/6235], Loss: 12.4043\n",
      "Epoch [6/100], Step [39700/6235], Loss: 126.5652\n",
      "Epoch [6/100], Step [39800/6235], Loss: 148.3324\n",
      "Epoch [6/100], Step [39900/6235], Loss: 1.0621\n",
      "Epoch [6/100], Step [40000/6235], Loss: 2.4801\n",
      "Epoch [6/100], Step [40100/6235], Loss: 27.1513\n",
      "Epoch [6/100], Step [40200/6235], Loss: 118.2355\n",
      "Epoch [6/100], Step [40300/6235], Loss: 4.5773\n",
      "Epoch [6/100], Step [40400/6235], Loss: 5.0081\n",
      "Epoch [6/100], Step [40500/6235], Loss: 0.1247\n",
      "Epoch [6/100], Step [40600/6235], Loss: 7.5899\n",
      "Epoch [6/100], Step [40700/6235], Loss: 5.6892\n",
      "Epoch [6/100], Step [40800/6235], Loss: 3.9947\n",
      "Epoch [6/100], Step [40900/6235], Loss: 0.8886\n",
      "Epoch [6/100], Step [41000/6235], Loss: 15.7537\n",
      "Epoch [6/100], Step [41100/6235], Loss: 22.0442\n",
      "Epoch [6/100], Step [41200/6235], Loss: 19.0864\n",
      "Epoch [6/100], Step [41300/6235], Loss: 0.2035\n",
      "Epoch [6/100], Step [41400/6235], Loss: 1.2650\n",
      "Epoch [6/100], Step [41500/6235], Loss: 0.7037\n",
      "Epoch [6/100], Step [41600/6235], Loss: 2.2349\n",
      "Epoch [6/100], Step [41700/6235], Loss: 4.3604\n",
      "Epoch [6/100], Step [41800/6235], Loss: 0.6975\n",
      "Epoch [6/100], Step [41900/6235], Loss: 0.1944\n",
      "Epoch [6/100], Step [42000/6235], Loss: 9.9410\n",
      "Epoch [6/100], Step [42100/6235], Loss: 0.2443\n",
      "Epoch [6/100], Step [42200/6235], Loss: 12.4628\n",
      "Epoch [6/100], Step [42300/6235], Loss: 0.4691\n",
      "Epoch [6/100], Step [42400/6235], Loss: 2.3989\n",
      "Epoch [6/100], Step [42500/6235], Loss: 0.3675\n",
      "Epoch [6/100], Step [42600/6235], Loss: 0.4463\n",
      "Epoch [6/100], Step [42700/6235], Loss: 0.9408\n",
      "Epoch [6/100], Step [42800/6235], Loss: 3.9726\n",
      "Epoch [6/100], Step [42900/6235], Loss: 1.1626\n",
      "Epoch [6/100], Step [43000/6235], Loss: 1.8919\n",
      "Epoch [6/100], Step [43100/6235], Loss: 4.2176\n",
      "Epoch [6/100], Step [43200/6235], Loss: 0.6626\n",
      "Epoch [6/100], Step [43300/6235], Loss: 13.1224\n",
      "Epoch [6/100], Step [43400/6235], Loss: 2.3666\n",
      "Epoch [6/100], Step [43500/6235], Loss: 2.4644\n",
      "Epoch [6/100], Step [43600/6235], Loss: 38.1735\n",
      "Epoch [6/100], Step [43700/6235], Loss: 9.0119\n",
      "Epoch [6/100], Step [43800/6235], Loss: 3.9081\n",
      "Epoch [6/100], Step [43900/6235], Loss: 0.9736\n",
      "Epoch [6/100], Step [44000/6235], Loss: 17.9268\n",
      "Epoch [6/100], Step [44100/6235], Loss: 5.3924\n",
      "Epoch [6/100], Step [44200/6235], Loss: 34.0143\n",
      "Epoch [6/100], Step [44300/6235], Loss: 10.2768\n",
      "Epoch [6/100], Step [44400/6235], Loss: 0.5250\n",
      "Epoch [6/100], Step [44500/6235], Loss: 8.8258\n",
      "Epoch [6/100], Step [44600/6235], Loss: 9.7614\n",
      "Epoch [6/100], Step [44700/6235], Loss: 2.5824\n",
      "Epoch [6/100], Step [44800/6235], Loss: 7.2224\n",
      "Epoch [6/100], Step [44900/6235], Loss: 0.9310\n",
      "Epoch [6/100], Step [45000/6235], Loss: 0.1865\n",
      "Epoch [6/100], Step [45100/6235], Loss: 17.9838\n",
      "Epoch [6/100], Step [45200/6235], Loss: 6.0690\n",
      "Epoch [6/100], Step [45300/6235], Loss: 5.7969\n",
      "Epoch [6/100], Step [45400/6235], Loss: 1.8282\n",
      "Epoch [6/100], Step [45500/6235], Loss: 0.1537\n",
      "Epoch [6/100], Step [45600/6235], Loss: 1.7510\n",
      "Epoch [6/100], Step [45700/6235], Loss: 19.1871\n",
      "Epoch [6/100], Step [45800/6235], Loss: 273.6054\n",
      "Epoch [6/100], Step [45900/6235], Loss: 5.1194\n",
      "Epoch [6/100], Step [46000/6235], Loss: 0.9876\n",
      "Epoch [6/100], Step [46100/6235], Loss: 8.7887\n",
      "Epoch [6/100], Step [46200/6235], Loss: 64.2001\n",
      "Epoch [6/100], Step [46300/6235], Loss: 37.1115\n",
      "Epoch [6/100], Step [46400/6235], Loss: 3.1232\n",
      "Epoch [6/100], Step [46500/6235], Loss: 39.5964\n",
      "Epoch [6/100], Step [46600/6235], Loss: 20.2737\n",
      "Epoch [6/100], Step [46700/6235], Loss: 2.1031\n",
      "Epoch [6/100], Step [46800/6235], Loss: 32.0030\n",
      "Epoch [6/100], Step [46900/6235], Loss: 22.8255\n",
      "Epoch [6/100], Step [47000/6235], Loss: 1.8975\n",
      "Epoch [6/100], Step [47100/6235], Loss: 69.4938\n",
      "Epoch [6/100], Step [47200/6235], Loss: 51.4279\n",
      "Epoch [6/100], Step [47300/6235], Loss: 0.6787\n",
      "Epoch [6/100], Step [47400/6235], Loss: 48.9217\n",
      "Epoch [6/100], Step [47500/6235], Loss: 4.9272\n",
      "Epoch [6/100], Step [47600/6235], Loss: 16.9279\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [6/100], Step [47700/6235], Loss: 12.3826\n",
      "Epoch [6/100], Step [47800/6235], Loss: 14.7726\n",
      "Epoch [6/100], Step [47900/6235], Loss: 26.0014\n",
      "Epoch [6/100], Step [48000/6235], Loss: 28.1584\n",
      "Epoch [6/100], Step [48100/6235], Loss: 3.8390\n",
      "Epoch [6/100], Step [48200/6235], Loss: 23.2417\n",
      "Epoch [6/100], Step [48300/6235], Loss: 328.3732\n",
      "Epoch [6/100], Step [48400/6235], Loss: 19.9899\n",
      "Epoch [6/100], Step [48500/6235], Loss: 20.7143\n",
      "Epoch [6/100], Step [48600/6235], Loss: 166.7761\n",
      "Epoch [6/100], Step [48700/6235], Loss: 29.6112\n",
      "Epoch [6/100], Step [48800/6235], Loss: 266.2052\n",
      "Epoch [6/100], Step [48900/6235], Loss: 136.8878\n",
      "Epoch [6/100], Step [49000/6235], Loss: 156.8651\n",
      "Epoch [6/100], Step [49100/6235], Loss: 2467.1958\n",
      "Epoch [6/100], Step [49200/6235], Loss: 714.3342\n",
      "Epoch [6/100], Step [49300/6235], Loss: 1162.3781\n",
      "Epoch [6/100], Step [49400/6235], Loss: 12.6401\n",
      "Epoch [6/100], Step [49500/6235], Loss: 8.0489\n",
      "Epoch [6/100], Step [49600/6235], Loss: 26.4750\n",
      "Epoch [6/100], Step [49700/6235], Loss: 10149.8926\n",
      "Epoch [6/100], Step [49800/6235], Loss: 673.9905\n",
      "Epoch [7/100], Step [100/6235], Loss: 34.6455\n",
      "Epoch [7/100], Step [200/6235], Loss: 1.7494\n",
      "Epoch [7/100], Step [300/6235], Loss: 0.2683\n",
      "Epoch [7/100], Step [400/6235], Loss: 0.1469\n",
      "Epoch [7/100], Step [500/6235], Loss: 2.0841\n",
      "Epoch [7/100], Step [600/6235], Loss: 1.2980\n",
      "Epoch [7/100], Step [700/6235], Loss: 0.7009\n",
      "Epoch [7/100], Step [800/6235], Loss: 0.0576\n",
      "Epoch [7/100], Step [900/6235], Loss: 0.0685\n",
      "Epoch [7/100], Step [1000/6235], Loss: 0.0226\n",
      "Epoch [7/100], Step [1100/6235], Loss: 0.0311\n",
      "Epoch [7/100], Step [1200/6235], Loss: 0.1754\n",
      "Epoch [7/100], Step [1300/6235], Loss: 0.0034\n",
      "Epoch [7/100], Step [1400/6235], Loss: 0.0536\n",
      "Epoch [7/100], Step [1500/6235], Loss: 0.0091\n",
      "Epoch [7/100], Step [1600/6235], Loss: 0.2352\n",
      "Epoch [7/100], Step [1700/6235], Loss: 0.1705\n",
      "Epoch [7/100], Step [1800/6235], Loss: 0.2603\n",
      "Epoch [7/100], Step [1900/6235], Loss: 0.2967\n",
      "Epoch [7/100], Step [2000/6235], Loss: 2.1571\n",
      "Epoch [7/100], Step [2100/6235], Loss: 3.3103\n",
      "Epoch [7/100], Step [2200/6235], Loss: 5.5963\n",
      "Epoch [7/100], Step [2300/6235], Loss: 5.9116\n",
      "Epoch [7/100], Step [2400/6235], Loss: 0.7486\n",
      "Epoch [7/100], Step [2500/6235], Loss: 41.0419\n",
      "Epoch [7/100], Step [2600/6235], Loss: 13.8429\n",
      "Epoch [7/100], Step [2700/6235], Loss: 4.5543\n",
      "Epoch [7/100], Step [2800/6235], Loss: 33.7872\n",
      "Epoch [7/100], Step [2900/6235], Loss: 13.7406\n",
      "Epoch [7/100], Step [3000/6235], Loss: 0.1604\n",
      "Epoch [7/100], Step [3100/6235], Loss: 74.8682\n",
      "Epoch [7/100], Step [3200/6235], Loss: 32.6585\n",
      "Epoch [7/100], Step [3300/6235], Loss: 6.6561\n",
      "Epoch [7/100], Step [3400/6235], Loss: 5.3848\n",
      "Epoch [7/100], Step [3500/6235], Loss: 59.4639\n",
      "Epoch [7/100], Step [3600/6235], Loss: 0.3220\n",
      "Epoch [7/100], Step [3700/6235], Loss: 0.1311\n",
      "Epoch [7/100], Step [3800/6235], Loss: 0.1357\n",
      "Epoch [7/100], Step [3900/6235], Loss: 0.1552\n",
      "Epoch [7/100], Step [4000/6235], Loss: 0.1435\n",
      "Epoch [7/100], Step [4100/6235], Loss: 9.8522\n",
      "Epoch [7/100], Step [4200/6235], Loss: 5.4384\n",
      "Epoch [7/100], Step [4300/6235], Loss: 3.4537\n",
      "Epoch [7/100], Step [4400/6235], Loss: 0.3744\n",
      "Epoch [7/100], Step [4500/6235], Loss: 43.2480\n",
      "Epoch [7/100], Step [4600/6235], Loss: 4.0859\n",
      "Epoch [7/100], Step [4700/6235], Loss: 0.1497\n",
      "Epoch [7/100], Step [4800/6235], Loss: 4.7181\n",
      "Epoch [7/100], Step [4900/6235], Loss: 4.1161\n",
      "Epoch [7/100], Step [5000/6235], Loss: 0.3320\n",
      "Epoch [7/100], Step [5100/6235], Loss: 0.8894\n",
      "Epoch [7/100], Step [5200/6235], Loss: 6.3514\n",
      "Epoch [7/100], Step [5300/6235], Loss: 14.8233\n",
      "Epoch [7/100], Step [5400/6235], Loss: 3.6100\n",
      "Epoch [7/100], Step [5500/6235], Loss: 0.0422\n",
      "Epoch [7/100], Step [5600/6235], Loss: 0.2278\n",
      "Epoch [7/100], Step [5700/6235], Loss: 0.0487\n",
      "Epoch [7/100], Step [5800/6235], Loss: 0.2309\n",
      "Epoch [7/100], Step [5900/6235], Loss: 0.0444\n",
      "Epoch [7/100], Step [6000/6235], Loss: 1.1864\n",
      "Epoch [7/100], Step [6100/6235], Loss: 0.0653\n",
      "Epoch [7/100], Step [6200/6235], Loss: 7.8801\n",
      "Epoch [7/100], Step [6300/6235], Loss: 1.0315\n",
      "Epoch [7/100], Step [6400/6235], Loss: 0.1491\n",
      "Epoch [7/100], Step [6500/6235], Loss: 0.6903\n",
      "Epoch [7/100], Step [6600/6235], Loss: 10.5665\n",
      "Epoch [7/100], Step [6700/6235], Loss: 1.2898\n",
      "Epoch [7/100], Step [6800/6235], Loss: 0.6008\n",
      "Epoch [7/100], Step [6900/6235], Loss: 0.4154\n",
      "Epoch [7/100], Step [7000/6235], Loss: 0.1882\n",
      "Epoch [7/100], Step [7100/6235], Loss: 0.3570\n",
      "Epoch [7/100], Step [7200/6235], Loss: 0.7183\n",
      "Epoch [7/100], Step [7300/6235], Loss: 0.1307\n",
      "Epoch [7/100], Step [7400/6235], Loss: 0.1800\n",
      "Epoch [7/100], Step [7500/6235], Loss: 0.1125\n",
      "Epoch [7/100], Step [7600/6235], Loss: 2.2401\n",
      "Epoch [7/100], Step [7700/6235], Loss: 18.6140\n",
      "Epoch [7/100], Step [7800/6235], Loss: 1.4140\n",
      "Epoch [7/100], Step [7900/6235], Loss: 2.3453\n",
      "Epoch [7/100], Step [8000/6235], Loss: 0.4792\n",
      "Epoch [7/100], Step [8100/6235], Loss: 1.1037\n",
      "Epoch [7/100], Step [8200/6235], Loss: 10.5205\n",
      "Epoch [7/100], Step [8300/6235], Loss: 17.3325\n",
      "Epoch [7/100], Step [8400/6235], Loss: 463.5183\n",
      "Epoch [7/100], Step [8500/6235], Loss: 15.3068\n",
      "Epoch [7/100], Step [8600/6235], Loss: 54.1214\n",
      "Epoch [7/100], Step [8700/6235], Loss: 23.0337\n",
      "Epoch [7/100], Step [8800/6235], Loss: 113.2641\n",
      "Epoch [7/100], Step [8900/6235], Loss: 3.3536\n",
      "Epoch [7/100], Step [9000/6235], Loss: 302.9008\n",
      "Epoch [7/100], Step [9100/6235], Loss: 641.1088\n",
      "Epoch [7/100], Step [9200/6235], Loss: 2766.5903\n",
      "Epoch [7/100], Step [9300/6235], Loss: 27.8668\n",
      "Epoch [7/100], Step [9400/6235], Loss: 663.7891\n",
      "Epoch [7/100], Step [9500/6235], Loss: 0.9694\n",
      "Epoch [7/100], Step [9600/6235], Loss: 217.3790\n",
      "Epoch [7/100], Step [9700/6235], Loss: 146.7034\n",
      "Epoch [7/100], Step [9800/6235], Loss: 40.6411\n",
      "Epoch [7/100], Step [9900/6235], Loss: 64.2119\n",
      "Epoch [7/100], Step [10000/6235], Loss: 113.4218\n",
      "Epoch [7/100], Step [10100/6235], Loss: 2.9301\n",
      "Epoch [7/100], Step [10200/6235], Loss: 472.0337\n",
      "Epoch [7/100], Step [10300/6235], Loss: 1.0336\n",
      "Epoch [7/100], Step [10400/6235], Loss: 0.2448\n",
      "Epoch [7/100], Step [10500/6235], Loss: 14.1399\n",
      "Epoch [7/100], Step [10600/6235], Loss: 978.5033\n",
      "Epoch [7/100], Step [10700/6235], Loss: 87.2601\n",
      "Epoch [7/100], Step [10800/6235], Loss: 17.3900\n",
      "Epoch [7/100], Step [10900/6235], Loss: 5.9178\n",
      "Epoch [7/100], Step [11000/6235], Loss: 115.1426\n",
      "Epoch [7/100], Step [11100/6235], Loss: 3.4722\n",
      "Epoch [7/100], Step [11200/6235], Loss: 122.1589\n",
      "Epoch [7/100], Step [11300/6235], Loss: 239.8344\n",
      "Epoch [7/100], Step [11400/6235], Loss: 244.3949\n",
      "Epoch [7/100], Step [11500/6235], Loss: 18.2355\n",
      "Epoch [7/100], Step [11600/6235], Loss: 3.6867\n",
      "Epoch [7/100], Step [11700/6235], Loss: 166.1277\n",
      "Epoch [7/100], Step [11800/6235], Loss: 11.9741\n",
      "Epoch [7/100], Step [11900/6235], Loss: 541.5557\n",
      "Epoch [7/100], Step [12000/6235], Loss: 330.5273\n",
      "Epoch [7/100], Step [12100/6235], Loss: 599.3698\n",
      "Epoch [7/100], Step [12200/6235], Loss: 10.4199\n",
      "Epoch [7/100], Step [12300/6235], Loss: 6.6797\n",
      "Epoch [7/100], Step [12400/6235], Loss: 82.5951\n",
      "Epoch [7/100], Step [12500/6235], Loss: 134.2617\n",
      "Epoch [7/100], Step [12600/6235], Loss: 2.4015\n",
      "Epoch [7/100], Step [12700/6235], Loss: 25.4827\n",
      "Epoch [7/100], Step [12800/6235], Loss: 22.0208\n",
      "Epoch [7/100], Step [12900/6235], Loss: 72.0067\n",
      "Epoch [7/100], Step [13000/6235], Loss: 0.4534\n",
      "Epoch [7/100], Step [13100/6235], Loss: 99.4014\n",
      "Epoch [7/100], Step [13200/6235], Loss: 20.0273\n",
      "Epoch [7/100], Step [13300/6235], Loss: 17.4124\n",
      "Epoch [7/100], Step [13400/6235], Loss: 80.8059\n",
      "Epoch [7/100], Step [13500/6235], Loss: 2.5796\n",
      "Epoch [7/100], Step [13600/6235], Loss: 28.8736\n",
      "Epoch [7/100], Step [13700/6235], Loss: 0.5846\n",
      "Epoch [7/100], Step [13800/6235], Loss: 142.6736\n",
      "Epoch [7/100], Step [13900/6235], Loss: 33.6536\n",
      "Epoch [7/100], Step [14000/6235], Loss: 6.9223\n",
      "Epoch [7/100], Step [14100/6235], Loss: 13.6423\n",
      "Epoch [7/100], Step [14200/6235], Loss: 45.4542\n",
      "Epoch [7/100], Step [14300/6235], Loss: 2.5696\n",
      "Epoch [7/100], Step [14400/6235], Loss: 25.5904\n",
      "Epoch [7/100], Step [14500/6235], Loss: 36.2834\n",
      "Epoch [7/100], Step [14600/6235], Loss: 1.1634\n",
      "Epoch [7/100], Step [14700/6235], Loss: 37.3559\n",
      "Epoch [7/100], Step [14800/6235], Loss: 33.7645\n",
      "Epoch [7/100], Step [14900/6235], Loss: 0.5410\n",
      "Epoch [7/100], Step [15000/6235], Loss: 1.4280\n",
      "Epoch [7/100], Step [15100/6235], Loss: 0.4753\n",
      "Epoch [7/100], Step [15200/6235], Loss: 53.3541\n",
      "Epoch [7/100], Step [15300/6235], Loss: 0.9002\n",
      "Epoch [7/100], Step [15400/6235], Loss: 6.5696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Step [15500/6235], Loss: 4.3660\n",
      "Epoch [7/100], Step [15600/6235], Loss: 166.8727\n",
      "Epoch [7/100], Step [15700/6235], Loss: 107.9282\n",
      "Epoch [7/100], Step [15800/6235], Loss: 5.4529\n",
      "Epoch [7/100], Step [15900/6235], Loss: 3.4496\n",
      "Epoch [7/100], Step [16000/6235], Loss: 1.0460\n",
      "Epoch [7/100], Step [16100/6235], Loss: 0.3896\n",
      "Epoch [7/100], Step [16200/6235], Loss: 8.7633\n",
      "Epoch [7/100], Step [16300/6235], Loss: 37.2719\n",
      "Epoch [7/100], Step [16400/6235], Loss: 53.5189\n",
      "Epoch [7/100], Step [16500/6235], Loss: 638.9676\n",
      "Epoch [7/100], Step [16600/6235], Loss: 15.8611\n",
      "Epoch [7/100], Step [16700/6235], Loss: 3.1522\n",
      "Epoch [7/100], Step [16800/6235], Loss: 0.9863\n",
      "Epoch [7/100], Step [16900/6235], Loss: 9.8458\n",
      "Epoch [7/100], Step [17000/6235], Loss: 1.6935\n",
      "Epoch [7/100], Step [17100/6235], Loss: 0.1653\n",
      "Epoch [7/100], Step [17200/6235], Loss: 59.7918\n",
      "Epoch [7/100], Step [17300/6235], Loss: 24.0060\n",
      "Epoch [7/100], Step [17400/6235], Loss: 30.1652\n",
      "Epoch [7/100], Step [17500/6235], Loss: 2.4053\n",
      "Epoch [7/100], Step [17600/6235], Loss: 0.3970\n",
      "Epoch [7/100], Step [17700/6235], Loss: 15.3135\n",
      "Epoch [7/100], Step [17800/6235], Loss: 46.2646\n",
      "Epoch [7/100], Step [17900/6235], Loss: 49.1797\n",
      "Epoch [7/100], Step [18000/6235], Loss: 3.5646\n",
      "Epoch [7/100], Step [18100/6235], Loss: 6.5959\n",
      "Epoch [7/100], Step [18200/6235], Loss: 10.9498\n",
      "Epoch [7/100], Step [18300/6235], Loss: 11.1380\n",
      "Epoch [7/100], Step [18400/6235], Loss: 1.5495\n",
      "Epoch [7/100], Step [18500/6235], Loss: 0.3837\n",
      "Epoch [7/100], Step [18600/6235], Loss: 1.1488\n",
      "Epoch [7/100], Step [18700/6235], Loss: 0.3069\n",
      "Epoch [7/100], Step [18800/6235], Loss: 127.3694\n",
      "Epoch [7/100], Step [18900/6235], Loss: 84.2773\n",
      "Epoch [7/100], Step [19000/6235], Loss: 0.9836\n",
      "Epoch [7/100], Step [19100/6235], Loss: 41.7631\n",
      "Epoch [7/100], Step [19200/6235], Loss: 1.7116\n",
      "Epoch [7/100], Step [19300/6235], Loss: 71.4427\n",
      "Epoch [7/100], Step [19400/6235], Loss: 49.5831\n",
      "Epoch [7/100], Step [19500/6235], Loss: 37.3905\n",
      "Epoch [7/100], Step [19600/6235], Loss: 103.1231\n",
      "Epoch [7/100], Step [19700/6235], Loss: 6.1357\n",
      "Epoch [7/100], Step [19800/6235], Loss: 1.1896\n",
      "Epoch [7/100], Step [19900/6235], Loss: 1.1961\n",
      "Epoch [7/100], Step [20000/6235], Loss: 61.0688\n",
      "Epoch [7/100], Step [20100/6235], Loss: 0.8302\n",
      "Epoch [7/100], Step [20200/6235], Loss: 0.5312\n",
      "Epoch [7/100], Step [20300/6235], Loss: 0.3803\n",
      "Epoch [7/100], Step [20400/6235], Loss: 15.3856\n",
      "Epoch [7/100], Step [20500/6235], Loss: 38.3434\n",
      "Epoch [7/100], Step [20600/6235], Loss: 114.4368\n",
      "Epoch [7/100], Step [20700/6235], Loss: 1.6713\n",
      "Epoch [7/100], Step [20800/6235], Loss: 0.7642\n",
      "Epoch [7/100], Step [20900/6235], Loss: 49.1236\n",
      "Epoch [7/100], Step [21000/6235], Loss: 18.1592\n",
      "Epoch [7/100], Step [21100/6235], Loss: 0.0565\n",
      "Epoch [7/100], Step [21200/6235], Loss: 0.4189\n",
      "Epoch [7/100], Step [21300/6235], Loss: 0.0471\n",
      "Epoch [7/100], Step [21400/6235], Loss: 6.3092\n",
      "Epoch [7/100], Step [21500/6235], Loss: 1.5556\n",
      "Epoch [7/100], Step [21600/6235], Loss: 28.5416\n",
      "Epoch [7/100], Step [21700/6235], Loss: 0.2024\n",
      "Epoch [7/100], Step [21800/6235], Loss: 4.9671\n",
      "Epoch [7/100], Step [21900/6235], Loss: 1.6498\n",
      "Epoch [7/100], Step [22000/6235], Loss: 8.6570\n",
      "Epoch [7/100], Step [22100/6235], Loss: 0.0806\n",
      "Epoch [7/100], Step [22200/6235], Loss: 7.0205\n",
      "Epoch [7/100], Step [22300/6235], Loss: 3.9169\n",
      "Epoch [7/100], Step [22400/6235], Loss: 28.3321\n",
      "Epoch [7/100], Step [22500/6235], Loss: 68.9988\n",
      "Epoch [7/100], Step [22600/6235], Loss: 13.9320\n",
      "Epoch [7/100], Step [22700/6235], Loss: 2.7014\n",
      "Epoch [7/100], Step [22800/6235], Loss: 9.7580\n",
      "Epoch [7/100], Step [22900/6235], Loss: 12.3843\n",
      "Epoch [7/100], Step [23000/6235], Loss: 9.8986\n",
      "Epoch [7/100], Step [23100/6235], Loss: 9.0469\n",
      "Epoch [7/100], Step [23200/6235], Loss: 5.9509\n",
      "Epoch [7/100], Step [23300/6235], Loss: 18.3847\n",
      "Epoch [7/100], Step [23400/6235], Loss: 2.6682\n",
      "Epoch [7/100], Step [23500/6235], Loss: 0.5240\n",
      "Epoch [7/100], Step [23600/6235], Loss: 138.6067\n",
      "Epoch [7/100], Step [23700/6235], Loss: 2.0290\n",
      "Epoch [7/100], Step [23800/6235], Loss: 0.6223\n",
      "Epoch [7/100], Step [23900/6235], Loss: 0.1183\n",
      "Epoch [7/100], Step [24000/6235], Loss: 3.3761\n",
      "Epoch [7/100], Step [24100/6235], Loss: 2.7413\n",
      "Epoch [7/100], Step [24200/6235], Loss: 23.0995\n",
      "Epoch [7/100], Step [24300/6235], Loss: 1.6035\n",
      "Epoch [7/100], Step [24400/6235], Loss: 6.8133\n",
      "Epoch [7/100], Step [24500/6235], Loss: 2.6069\n",
      "Epoch [7/100], Step [24600/6235], Loss: 0.2197\n",
      "Epoch [7/100], Step [24700/6235], Loss: 0.9352\n",
      "Epoch [7/100], Step [24800/6235], Loss: 0.1253\n",
      "Epoch [7/100], Step [24900/6235], Loss: 8.0510\n",
      "Epoch [7/100], Step [25000/6235], Loss: 19.1267\n",
      "Epoch [7/100], Step [25100/6235], Loss: 7.3638\n",
      "Epoch [7/100], Step [25200/6235], Loss: 0.7593\n",
      "Epoch [7/100], Step [25300/6235], Loss: 0.7541\n",
      "Epoch [7/100], Step [25400/6235], Loss: 10.3801\n",
      "Epoch [7/100], Step [25500/6235], Loss: 9.2360\n",
      "Epoch [7/100], Step [25600/6235], Loss: 7.9156\n",
      "Epoch [7/100], Step [25700/6235], Loss: 0.5664\n",
      "Epoch [7/100], Step [25800/6235], Loss: 0.9447\n",
      "Epoch [7/100], Step [25900/6235], Loss: 0.4188\n",
      "Epoch [7/100], Step [26000/6235], Loss: 0.1358\n",
      "Epoch [7/100], Step [26100/6235], Loss: 0.0473\n",
      "Epoch [7/100], Step [26200/6235], Loss: 1.4089\n",
      "Epoch [7/100], Step [26300/6235], Loss: 3.3876\n",
      "Epoch [7/100], Step [26400/6235], Loss: 0.2110\n",
      "Epoch [7/100], Step [26500/6235], Loss: 0.0335\n",
      "Epoch [7/100], Step [26600/6235], Loss: 0.2772\n",
      "Epoch [7/100], Step [26700/6235], Loss: 0.1867\n",
      "Epoch [7/100], Step [26800/6235], Loss: 0.0884\n",
      "Epoch [7/100], Step [26900/6235], Loss: 0.0209\n",
      "Epoch [7/100], Step [27000/6235], Loss: 16.2104\n",
      "Epoch [7/100], Step [27100/6235], Loss: 0.0928\n",
      "Epoch [7/100], Step [27200/6235], Loss: 0.0217\n",
      "Epoch [7/100], Step [27300/6235], Loss: 0.0289\n",
      "Epoch [7/100], Step [27400/6235], Loss: 0.6651\n",
      "Epoch [7/100], Step [27500/6235], Loss: 8.5672\n",
      "Epoch [7/100], Step [27600/6235], Loss: 0.2293\n",
      "Epoch [7/100], Step [27700/6235], Loss: 1.3217\n",
      "Epoch [7/100], Step [27800/6235], Loss: 7.6835\n",
      "Epoch [7/100], Step [27900/6235], Loss: 2.2230\n",
      "Epoch [7/100], Step [28000/6235], Loss: 186.9240\n",
      "Epoch [7/100], Step [28100/6235], Loss: 2.0073\n",
      "Epoch [7/100], Step [28200/6235], Loss: 30.1927\n",
      "Epoch [7/100], Step [28300/6235], Loss: 3.9080\n",
      "Epoch [7/100], Step [28400/6235], Loss: 23.8617\n",
      "Epoch [7/100], Step [28500/6235], Loss: 3.2793\n",
      "Epoch [7/100], Step [28600/6235], Loss: 0.8318\n",
      "Epoch [7/100], Step [28700/6235], Loss: 4.5233\n",
      "Epoch [7/100], Step [28800/6235], Loss: 0.3497\n",
      "Epoch [7/100], Step [28900/6235], Loss: 72.8603\n",
      "Epoch [7/100], Step [29000/6235], Loss: 10.4997\n",
      "Epoch [7/100], Step [29100/6235], Loss: 0.1433\n",
      "Epoch [7/100], Step [29200/6235], Loss: 1.7451\n",
      "Epoch [7/100], Step [29300/6235], Loss: 5.0257\n",
      "Epoch [7/100], Step [29400/6235], Loss: 0.1173\n",
      "Epoch [7/100], Step [29500/6235], Loss: 5.4167\n",
      "Epoch [7/100], Step [29600/6235], Loss: 0.2274\n",
      "Epoch [7/100], Step [29700/6235], Loss: 2.4904\n",
      "Epoch [7/100], Step [29800/6235], Loss: 1.1093\n",
      "Epoch [7/100], Step [29900/6235], Loss: 0.8584\n",
      "Epoch [7/100], Step [30000/6235], Loss: 5.2212\n",
      "Epoch [7/100], Step [30100/6235], Loss: 9.8186\n",
      "Epoch [7/100], Step [30200/6235], Loss: 1.6376\n",
      "Epoch [7/100], Step [30300/6235], Loss: 0.0712\n",
      "Epoch [7/100], Step [30400/6235], Loss: 1.5565\n",
      "Epoch [7/100], Step [30500/6235], Loss: 2.9208\n",
      "Epoch [7/100], Step [30600/6235], Loss: 1.7505\n",
      "Epoch [7/100], Step [30700/6235], Loss: 0.5242\n",
      "Epoch [7/100], Step [30800/6235], Loss: 0.5001\n",
      "Epoch [7/100], Step [30900/6235], Loss: 3.8696\n",
      "Epoch [7/100], Step [31000/6235], Loss: 0.0528\n",
      "Epoch [7/100], Step [31100/6235], Loss: 0.0898\n",
      "Epoch [7/100], Step [31200/6235], Loss: 6.2370\n",
      "Epoch [7/100], Step [31300/6235], Loss: 1.8913\n",
      "Epoch [7/100], Step [31400/6235], Loss: 3.6349\n",
      "Epoch [7/100], Step [31500/6235], Loss: 0.8682\n",
      "Epoch [7/100], Step [31600/6235], Loss: 6.6238\n",
      "Epoch [7/100], Step [31700/6235], Loss: 4.8056\n",
      "Epoch [7/100], Step [31800/6235], Loss: 1.7627\n",
      "Epoch [7/100], Step [31900/6235], Loss: 756.6567\n",
      "Epoch [7/100], Step [32000/6235], Loss: 112.1080\n",
      "Epoch [7/100], Step [32100/6235], Loss: 8.7934\n",
      "Epoch [7/100], Step [32200/6235], Loss: 28.6811\n",
      "Epoch [7/100], Step [32300/6235], Loss: 0.4754\n",
      "Epoch [7/100], Step [32400/6235], Loss: 0.1796\n",
      "Epoch [7/100], Step [32500/6235], Loss: 20.3033\n",
      "Epoch [7/100], Step [32600/6235], Loss: 1.1702\n",
      "Epoch [7/100], Step [32700/6235], Loss: 48.7125\n",
      "Epoch [7/100], Step [32800/6235], Loss: 2.4457\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [7/100], Step [32900/6235], Loss: 8.8939\n",
      "Epoch [7/100], Step [33000/6235], Loss: 3.3997\n",
      "Epoch [7/100], Step [33100/6235], Loss: 0.1569\n",
      "Epoch [7/100], Step [33200/6235], Loss: 4.7214\n",
      "Epoch [7/100], Step [33300/6235], Loss: 7.5045\n",
      "Epoch [7/100], Step [33400/6235], Loss: 2.5751\n",
      "Epoch [7/100], Step [33500/6235], Loss: 1.0256\n",
      "Epoch [7/100], Step [33600/6235], Loss: 0.0977\n",
      "Epoch [7/100], Step [33700/6235], Loss: 3.0361\n",
      "Epoch [7/100], Step [33800/6235], Loss: 28.8206\n",
      "Epoch [7/100], Step [33900/6235], Loss: 23.6529\n",
      "Epoch [7/100], Step [34000/6235], Loss: 0.1686\n",
      "Epoch [7/100], Step [34100/6235], Loss: 0.3248\n",
      "Epoch [7/100], Step [34200/6235], Loss: 30.8964\n",
      "Epoch [7/100], Step [34300/6235], Loss: 0.0063\n",
      "Epoch [7/100], Step [34400/6235], Loss: 3.1690\n",
      "Epoch [7/100], Step [34500/6235], Loss: 72.0615\n",
      "Epoch [7/100], Step [34600/6235], Loss: 1.3115\n",
      "Epoch [7/100], Step [34700/6235], Loss: 0.9009\n",
      "Epoch [7/100], Step [34800/6235], Loss: 8.2948\n",
      "Epoch [7/100], Step [34900/6235], Loss: 30.6008\n",
      "Epoch [7/100], Step [35000/6235], Loss: 0.0650\n",
      "Epoch [7/100], Step [35100/6235], Loss: 6.1328\n",
      "Epoch [7/100], Step [35200/6235], Loss: 5.7832\n",
      "Epoch [7/100], Step [35300/6235], Loss: 4.6984\n",
      "Epoch [7/100], Step [35400/6235], Loss: 1.1759\n",
      "Epoch [7/100], Step [35500/6235], Loss: 0.0649\n",
      "Epoch [7/100], Step [35600/6235], Loss: 9.8681\n",
      "Epoch [7/100], Step [35700/6235], Loss: 13.6426\n",
      "Epoch [7/100], Step [35800/6235], Loss: 6.9915\n",
      "Epoch [7/100], Step [35900/6235], Loss: 3.2688\n",
      "Epoch [7/100], Step [36000/6235], Loss: 0.8589\n",
      "Epoch [7/100], Step [36100/6235], Loss: 15.1454\n",
      "Epoch [7/100], Step [36200/6235], Loss: 7.1283\n",
      "Epoch [7/100], Step [36300/6235], Loss: 2.1555\n",
      "Epoch [7/100], Step [36400/6235], Loss: 0.1350\n",
      "Epoch [7/100], Step [36500/6235], Loss: 5.0233\n",
      "Epoch [7/100], Step [36600/6235], Loss: 0.1460\n",
      "Epoch [7/100], Step [36700/6235], Loss: 2.0105\n",
      "Epoch [7/100], Step [36800/6235], Loss: 15.2872\n",
      "Epoch [7/100], Step [36900/6235], Loss: 8.3918\n",
      "Epoch [7/100], Step [37000/6235], Loss: 0.5759\n",
      "Epoch [7/100], Step [37100/6235], Loss: 0.5650\n",
      "Epoch [7/100], Step [37200/6235], Loss: 0.1374\n",
      "Epoch [7/100], Step [37300/6235], Loss: 0.6281\n",
      "Epoch [7/100], Step [37400/6235], Loss: 0.7510\n",
      "Epoch [7/100], Step [37500/6235], Loss: 0.3768\n",
      "Epoch [7/100], Step [37600/6235], Loss: 9.7426\n",
      "Epoch [7/100], Step [37700/6235], Loss: 0.7310\n",
      "Epoch [7/100], Step [37800/6235], Loss: 3.3572\n",
      "Epoch [7/100], Step [37900/6235], Loss: 7.2650\n",
      "Epoch [7/100], Step [38000/6235], Loss: 0.0817\n",
      "Epoch [7/100], Step [38100/6235], Loss: 6.7359\n",
      "Epoch [7/100], Step [38200/6235], Loss: 9.6414\n",
      "Epoch [7/100], Step [38300/6235], Loss: 1.9143\n",
      "Epoch [7/100], Step [38400/6235], Loss: 0.4505\n",
      "Epoch [7/100], Step [38500/6235], Loss: 0.1724\n",
      "Epoch [7/100], Step [38600/6235], Loss: 8.7448\n",
      "Epoch [7/100], Step [38700/6235], Loss: 0.1960\n",
      "Epoch [7/100], Step [38800/6235], Loss: 1.6023\n",
      "Epoch [7/100], Step [38900/6235], Loss: 4.2950\n",
      "Epoch [7/100], Step [39000/6235], Loss: 1.5190\n",
      "Epoch [7/100], Step [39100/6235], Loss: 9.6252\n",
      "Epoch [7/100], Step [39200/6235], Loss: 0.6904\n",
      "Epoch [7/100], Step [39300/6235], Loss: 41.1318\n",
      "Epoch [7/100], Step [39400/6235], Loss: 151.9370\n",
      "Epoch [7/100], Step [39500/6235], Loss: 19.9897\n",
      "Epoch [7/100], Step [39600/6235], Loss: 15.5891\n",
      "Epoch [7/100], Step [39700/6235], Loss: 406.4935\n",
      "Epoch [7/100], Step [39800/6235], Loss: 79.9634\n",
      "Epoch [7/100], Step [39900/6235], Loss: 0.1880\n",
      "Epoch [7/100], Step [40000/6235], Loss: 9.2996\n",
      "Epoch [7/100], Step [40100/6235], Loss: 24.9454\n",
      "Epoch [7/100], Step [40200/6235], Loss: 84.9689\n",
      "Epoch [7/100], Step [40300/6235], Loss: 2.6954\n",
      "Epoch [7/100], Step [40400/6235], Loss: 0.6819\n",
      "Epoch [7/100], Step [40500/6235], Loss: 0.1822\n",
      "Epoch [7/100], Step [40600/6235], Loss: 5.1044\n",
      "Epoch [7/100], Step [40700/6235], Loss: 5.9145\n",
      "Epoch [7/100], Step [40800/6235], Loss: 3.9559\n",
      "Epoch [7/100], Step [40900/6235], Loss: 0.8624\n",
      "Epoch [7/100], Step [41000/6235], Loss: 9.7922\n",
      "Epoch [7/100], Step [41100/6235], Loss: 21.2739\n",
      "Epoch [7/100], Step [41200/6235], Loss: 25.3189\n",
      "Epoch [7/100], Step [41300/6235], Loss: 0.4918\n",
      "Epoch [7/100], Step [41400/6235], Loss: 1.2701\n",
      "Epoch [7/100], Step [41500/6235], Loss: 0.3359\n",
      "Epoch [7/100], Step [41600/6235], Loss: 1.1808\n",
      "Epoch [7/100], Step [41700/6235], Loss: 4.8476\n",
      "Epoch [7/100], Step [41800/6235], Loss: 1.9503\n",
      "Epoch [7/100], Step [41900/6235], Loss: 0.0463\n",
      "Epoch [7/100], Step [42000/6235], Loss: 6.7601\n",
      "Epoch [7/100], Step [42100/6235], Loss: 0.6282\n",
      "Epoch [7/100], Step [42200/6235], Loss: 3.5148\n",
      "Epoch [7/100], Step [42300/6235], Loss: 0.6568\n",
      "Epoch [7/100], Step [42400/6235], Loss: 2.7542\n",
      "Epoch [7/100], Step [42500/6235], Loss: 1.2186\n",
      "Epoch [7/100], Step [42600/6235], Loss: 0.4553\n",
      "Epoch [7/100], Step [42700/6235], Loss: 0.5520\n",
      "Epoch [7/100], Step [42800/6235], Loss: 4.6959\n",
      "Epoch [7/100], Step [42900/6235], Loss: 2.3686\n",
      "Epoch [7/100], Step [43000/6235], Loss: 2.2574\n",
      "Epoch [7/100], Step [43100/6235], Loss: 3.8754\n",
      "Epoch [7/100], Step [43200/6235], Loss: 0.5786\n",
      "Epoch [7/100], Step [43300/6235], Loss: 13.7941\n",
      "Epoch [7/100], Step [43400/6235], Loss: 4.4523\n",
      "Epoch [7/100], Step [43500/6235], Loss: 3.6474\n",
      "Epoch [7/100], Step [43600/6235], Loss: 43.7212\n",
      "Epoch [7/100], Step [43700/6235], Loss: 20.5554\n",
      "Epoch [7/100], Step [43800/6235], Loss: 1.9539\n",
      "Epoch [7/100], Step [43900/6235], Loss: 1.1430\n",
      "Epoch [7/100], Step [44000/6235], Loss: 33.3897\n",
      "Epoch [7/100], Step [44100/6235], Loss: 4.4127\n",
      "Epoch [7/100], Step [44200/6235], Loss: 37.4893\n",
      "Epoch [7/100], Step [44300/6235], Loss: 67.6846\n",
      "Epoch [7/100], Step [44400/6235], Loss: 0.8434\n",
      "Epoch [7/100], Step [44500/6235], Loss: 8.1548\n",
      "Epoch [7/100], Step [44600/6235], Loss: 12.4716\n",
      "Epoch [7/100], Step [44700/6235], Loss: 4.9753\n",
      "Epoch [7/100], Step [44800/6235], Loss: 3.1708\n",
      "Epoch [7/100], Step [44900/6235], Loss: 0.3274\n",
      "Epoch [7/100], Step [45000/6235], Loss: 0.1908\n",
      "Epoch [7/100], Step [45100/6235], Loss: 29.1019\n",
      "Epoch [7/100], Step [45200/6235], Loss: 0.9795\n",
      "Epoch [7/100], Step [45300/6235], Loss: 15.3010\n",
      "Epoch [7/100], Step [45400/6235], Loss: 3.5087\n",
      "Epoch [7/100], Step [45500/6235], Loss: 0.1478\n",
      "Epoch [7/100], Step [45600/6235], Loss: 1.2171\n",
      "Epoch [7/100], Step [45700/6235], Loss: 31.5375\n",
      "Epoch [7/100], Step [45800/6235], Loss: 390.6622\n",
      "Epoch [7/100], Step [45900/6235], Loss: 1.4738\n",
      "Epoch [7/100], Step [46000/6235], Loss: 2.9660\n",
      "Epoch [7/100], Step [46100/6235], Loss: 11.3204\n",
      "Epoch [7/100], Step [46200/6235], Loss: 19.8447\n",
      "Epoch [7/100], Step [46300/6235], Loss: 8.2507\n",
      "Epoch [7/100], Step [46400/6235], Loss: 7.1263\n",
      "Epoch [7/100], Step [46500/6235], Loss: 27.5791\n",
      "Epoch [7/100], Step [46600/6235], Loss: 1.3425\n",
      "Epoch [7/100], Step [46700/6235], Loss: 2.0684\n",
      "Epoch [7/100], Step [46800/6235], Loss: 20.5946\n",
      "Epoch [7/100], Step [46900/6235], Loss: 24.8345\n",
      "Epoch [7/100], Step [47000/6235], Loss: 0.7476\n",
      "Epoch [7/100], Step [47100/6235], Loss: 49.5572\n",
      "Epoch [7/100], Step [47200/6235], Loss: 23.6381\n",
      "Epoch [7/100], Step [47300/6235], Loss: 0.9207\n",
      "Epoch [7/100], Step [47400/6235], Loss: 17.4102\n",
      "Epoch [7/100], Step [47500/6235], Loss: 2.9255\n",
      "Epoch [7/100], Step [47600/6235], Loss: 13.4446\n",
      "Epoch [7/100], Step [47700/6235], Loss: 6.4453\n",
      "Epoch [7/100], Step [47800/6235], Loss: 7.3686\n",
      "Epoch [7/100], Step [47900/6235], Loss: 33.4954\n",
      "Epoch [7/100], Step [48000/6235], Loss: 19.1149\n",
      "Epoch [7/100], Step [48100/6235], Loss: 3.2573\n",
      "Epoch [7/100], Step [48200/6235], Loss: 21.9693\n",
      "Epoch [7/100], Step [48300/6235], Loss: 274.9856\n",
      "Epoch [7/100], Step [48400/6235], Loss: 24.3100\n",
      "Epoch [7/100], Step [48500/6235], Loss: 14.9959\n",
      "Epoch [7/100], Step [48600/6235], Loss: 160.3501\n",
      "Epoch [7/100], Step [48700/6235], Loss: 43.9402\n",
      "Epoch [7/100], Step [48800/6235], Loss: 364.5440\n",
      "Epoch [7/100], Step [48900/6235], Loss: 19.9343\n",
      "Epoch [7/100], Step [49000/6235], Loss: 201.6007\n",
      "Epoch [7/100], Step [49100/6235], Loss: 2763.6648\n",
      "Epoch [7/100], Step [49200/6235], Loss: 546.6498\n",
      "Epoch [7/100], Step [49300/6235], Loss: 1201.3008\n",
      "Epoch [7/100], Step [49400/6235], Loss: 2.5193\n",
      "Epoch [7/100], Step [49500/6235], Loss: 38.2305\n",
      "Epoch [7/100], Step [49600/6235], Loss: 189.7112\n",
      "Epoch [7/100], Step [49700/6235], Loss: 2549.4431\n",
      "Epoch [7/100], Step [49800/6235], Loss: 3058.4077\n",
      "Epoch [8/100], Step [100/6235], Loss: 48.9333\n",
      "Epoch [8/100], Step [200/6235], Loss: 0.7485\n",
      "Epoch [8/100], Step [300/6235], Loss: 0.2384\n",
      "Epoch [8/100], Step [400/6235], Loss: 0.0352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Step [500/6235], Loss: 6.0765\n",
      "Epoch [8/100], Step [600/6235], Loss: 0.0448\n",
      "Epoch [8/100], Step [700/6235], Loss: 0.6160\n",
      "Epoch [8/100], Step [800/6235], Loss: 0.0635\n",
      "Epoch [8/100], Step [900/6235], Loss: 0.1485\n",
      "Epoch [8/100], Step [1000/6235], Loss: 0.0664\n",
      "Epoch [8/100], Step [1100/6235], Loss: 0.6093\n",
      "Epoch [8/100], Step [1200/6235], Loss: 0.1938\n",
      "Epoch [8/100], Step [1300/6235], Loss: 0.0166\n",
      "Epoch [8/100], Step [1400/6235], Loss: 0.5904\n",
      "Epoch [8/100], Step [1500/6235], Loss: 0.0243\n",
      "Epoch [8/100], Step [1600/6235], Loss: 0.2402\n",
      "Epoch [8/100], Step [1700/6235], Loss: 0.2497\n",
      "Epoch [8/100], Step [1800/6235], Loss: 0.4359\n",
      "Epoch [8/100], Step [1900/6235], Loss: 0.2922\n",
      "Epoch [8/100], Step [2000/6235], Loss: 2.9981\n",
      "Epoch [8/100], Step [2100/6235], Loss: 2.9708\n",
      "Epoch [8/100], Step [2200/6235], Loss: 6.4895\n",
      "Epoch [8/100], Step [2300/6235], Loss: 0.4994\n",
      "Epoch [8/100], Step [2400/6235], Loss: 0.5134\n",
      "Epoch [8/100], Step [2500/6235], Loss: 56.6580\n",
      "Epoch [8/100], Step [2600/6235], Loss: 13.2347\n",
      "Epoch [8/100], Step [2700/6235], Loss: 5.1898\n",
      "Epoch [8/100], Step [2800/6235], Loss: 387.3914\n",
      "Epoch [8/100], Step [2900/6235], Loss: 18.6429\n",
      "Epoch [8/100], Step [3000/6235], Loss: 1.5858\n",
      "Epoch [8/100], Step [3100/6235], Loss: 65.2085\n",
      "Epoch [8/100], Step [3200/6235], Loss: 63.5442\n",
      "Epoch [8/100], Step [3300/6235], Loss: 11.7115\n",
      "Epoch [8/100], Step [3400/6235], Loss: 1.8818\n",
      "Epoch [8/100], Step [3500/6235], Loss: 46.7165\n",
      "Epoch [8/100], Step [3600/6235], Loss: 4.8757\n",
      "Epoch [8/100], Step [3700/6235], Loss: 0.0564\n",
      "Epoch [8/100], Step [3800/6235], Loss: 0.0450\n",
      "Epoch [8/100], Step [3900/6235], Loss: 0.1193\n",
      "Epoch [8/100], Step [4000/6235], Loss: 0.0648\n",
      "Epoch [8/100], Step [4100/6235], Loss: 8.4717\n",
      "Epoch [8/100], Step [4200/6235], Loss: 1.5345\n",
      "Epoch [8/100], Step [4300/6235], Loss: 5.8602\n",
      "Epoch [8/100], Step [4400/6235], Loss: 1.4226\n",
      "Epoch [8/100], Step [4500/6235], Loss: 35.7588\n",
      "Epoch [8/100], Step [4600/6235], Loss: 4.0383\n",
      "Epoch [8/100], Step [4700/6235], Loss: 0.6664\n",
      "Epoch [8/100], Step [4800/6235], Loss: 11.3790\n",
      "Epoch [8/100], Step [4900/6235], Loss: 0.1419\n",
      "Epoch [8/100], Step [5000/6235], Loss: 0.2073\n",
      "Epoch [8/100], Step [5100/6235], Loss: 1.1437\n",
      "Epoch [8/100], Step [5200/6235], Loss: 1.8834\n",
      "Epoch [8/100], Step [5300/6235], Loss: 39.6455\n",
      "Epoch [8/100], Step [5400/6235], Loss: 0.6863\n",
      "Epoch [8/100], Step [5500/6235], Loss: 0.4016\n",
      "Epoch [8/100], Step [5600/6235], Loss: 0.2798\n",
      "Epoch [8/100], Step [5700/6235], Loss: 0.1334\n",
      "Epoch [8/100], Step [5800/6235], Loss: 1.0257\n",
      "Epoch [8/100], Step [5900/6235], Loss: 0.0404\n",
      "Epoch [8/100], Step [6000/6235], Loss: 1.8858\n",
      "Epoch [8/100], Step [6100/6235], Loss: 0.0698\n",
      "Epoch [8/100], Step [6200/6235], Loss: 3.3467\n",
      "Epoch [8/100], Step [6300/6235], Loss: 0.1267\n",
      "Epoch [8/100], Step [6400/6235], Loss: 0.0446\n",
      "Epoch [8/100], Step [6500/6235], Loss: 4.6731\n",
      "Epoch [8/100], Step [6600/6235], Loss: 11.5207\n",
      "Epoch [8/100], Step [6700/6235], Loss: 2.5856\n",
      "Epoch [8/100], Step [6800/6235], Loss: 1.2298\n",
      "Epoch [8/100], Step [6900/6235], Loss: 1.4864\n",
      "Epoch [8/100], Step [7000/6235], Loss: 0.0317\n",
      "Epoch [8/100], Step [7100/6235], Loss: 0.1695\n",
      "Epoch [8/100], Step [7200/6235], Loss: 0.2526\n",
      "Epoch [8/100], Step [7300/6235], Loss: 1.4418\n",
      "Epoch [8/100], Step [7400/6235], Loss: 0.2413\n",
      "Epoch [8/100], Step [7500/6235], Loss: 0.2415\n",
      "Epoch [8/100], Step [7600/6235], Loss: 0.2924\n",
      "Epoch [8/100], Step [7700/6235], Loss: 18.5594\n",
      "Epoch [8/100], Step [7800/6235], Loss: 4.0008\n",
      "Epoch [8/100], Step [7900/6235], Loss: 0.0181\n",
      "Epoch [8/100], Step [8000/6235], Loss: 0.0405\n",
      "Epoch [8/100], Step [8100/6235], Loss: 3.9016\n",
      "Epoch [8/100], Step [8200/6235], Loss: 11.4641\n",
      "Epoch [8/100], Step [8300/6235], Loss: 28.6053\n",
      "Epoch [8/100], Step [8400/6235], Loss: 235.0939\n",
      "Epoch [8/100], Step [8500/6235], Loss: 1.2046\n",
      "Epoch [8/100], Step [8600/6235], Loss: 142.9048\n",
      "Epoch [8/100], Step [8700/6235], Loss: 76.9657\n",
      "Epoch [8/100], Step [8800/6235], Loss: 212.1607\n",
      "Epoch [8/100], Step [8900/6235], Loss: 21.6359\n",
      "Epoch [8/100], Step [9000/6235], Loss: 266.2633\n",
      "Epoch [8/100], Step [9100/6235], Loss: 597.5486\n",
      "Epoch [8/100], Step [9200/6235], Loss: 2668.9548\n",
      "Epoch [8/100], Step [9300/6235], Loss: 4.5310\n",
      "Epoch [8/100], Step [9400/6235], Loss: 80.2081\n",
      "Epoch [8/100], Step [9500/6235], Loss: 683.7778\n",
      "Epoch [8/100], Step [9600/6235], Loss: 64.9314\n",
      "Epoch [8/100], Step [9700/6235], Loss: 81.6696\n",
      "Epoch [8/100], Step [9800/6235], Loss: 15.9859\n",
      "Epoch [8/100], Step [9900/6235], Loss: 73.6456\n",
      "Epoch [8/100], Step [10000/6235], Loss: 113.2047\n",
      "Epoch [8/100], Step [10100/6235], Loss: 3.3591\n",
      "Epoch [8/100], Step [10200/6235], Loss: 566.9827\n",
      "Epoch [8/100], Step [10300/6235], Loss: 1.6917\n",
      "Epoch [8/100], Step [10400/6235], Loss: 0.5938\n",
      "Epoch [8/100], Step [10500/6235], Loss: 17.0447\n",
      "Epoch [8/100], Step [10600/6235], Loss: 563.1672\n",
      "Epoch [8/100], Step [10700/6235], Loss: 110.4608\n",
      "Epoch [8/100], Step [10800/6235], Loss: 41.3367\n",
      "Epoch [8/100], Step [10900/6235], Loss: 3.9700\n",
      "Epoch [8/100], Step [11000/6235], Loss: 168.0527\n",
      "Epoch [8/100], Step [11100/6235], Loss: 10.3724\n",
      "Epoch [8/100], Step [11200/6235], Loss: 104.2376\n",
      "Epoch [8/100], Step [11300/6235], Loss: 239.5438\n",
      "Epoch [8/100], Step [11400/6235], Loss: 145.8285\n",
      "Epoch [8/100], Step [11500/6235], Loss: 13.5865\n",
      "Epoch [8/100], Step [11600/6235], Loss: 5.4325\n",
      "Epoch [8/100], Step [11700/6235], Loss: 144.8992\n",
      "Epoch [8/100], Step [11800/6235], Loss: 168.0814\n",
      "Epoch [8/100], Step [11900/6235], Loss: 481.6922\n",
      "Epoch [8/100], Step [12000/6235], Loss: 650.7684\n",
      "Epoch [8/100], Step [12100/6235], Loss: 494.1536\n",
      "Epoch [8/100], Step [12200/6235], Loss: 21.7407\n",
      "Epoch [8/100], Step [12300/6235], Loss: 4.1873\n",
      "Epoch [8/100], Step [12400/6235], Loss: 219.1008\n",
      "Epoch [8/100], Step [12500/6235], Loss: 77.7204\n",
      "Epoch [8/100], Step [12600/6235], Loss: 2.6267\n",
      "Epoch [8/100], Step [12700/6235], Loss: 16.1604\n",
      "Epoch [8/100], Step [12800/6235], Loss: 27.7266\n",
      "Epoch [8/100], Step [12900/6235], Loss: 62.2058\n",
      "Epoch [8/100], Step [13000/6235], Loss: 0.1625\n",
      "Epoch [8/100], Step [13100/6235], Loss: 80.1837\n",
      "Epoch [8/100], Step [13200/6235], Loss: 11.2994\n",
      "Epoch [8/100], Step [13300/6235], Loss: 17.2998\n",
      "Epoch [8/100], Step [13400/6235], Loss: 121.9886\n",
      "Epoch [8/100], Step [13500/6235], Loss: 8.6378\n",
      "Epoch [8/100], Step [13600/6235], Loss: 38.9340\n",
      "Epoch [8/100], Step [13700/6235], Loss: 5.2370\n",
      "Epoch [8/100], Step [13800/6235], Loss: 169.9524\n",
      "Epoch [8/100], Step [13900/6235], Loss: 16.6454\n",
      "Epoch [8/100], Step [14000/6235], Loss: 4.7591\n",
      "Epoch [8/100], Step [14100/6235], Loss: 10.7495\n",
      "Epoch [8/100], Step [14200/6235], Loss: 10.0242\n",
      "Epoch [8/100], Step [14300/6235], Loss: 2.7558\n",
      "Epoch [8/100], Step [14400/6235], Loss: 32.6141\n",
      "Epoch [8/100], Step [14500/6235], Loss: 46.9661\n",
      "Epoch [8/100], Step [14600/6235], Loss: 0.1040\n",
      "Epoch [8/100], Step [14700/6235], Loss: 45.2092\n",
      "Epoch [8/100], Step [14800/6235], Loss: 31.7499\n",
      "Epoch [8/100], Step [14900/6235], Loss: 0.6322\n",
      "Epoch [8/100], Step [15000/6235], Loss: 1.8624\n",
      "Epoch [8/100], Step [15100/6235], Loss: 0.5338\n",
      "Epoch [8/100], Step [15200/6235], Loss: 34.3904\n",
      "Epoch [8/100], Step [15300/6235], Loss: 0.1977\n",
      "Epoch [8/100], Step [15400/6235], Loss: 71.7166\n",
      "Epoch [8/100], Step [15500/6235], Loss: 0.6157\n",
      "Epoch [8/100], Step [15600/6235], Loss: 240.0365\n",
      "Epoch [8/100], Step [15700/6235], Loss: 57.7143\n",
      "Epoch [8/100], Step [15800/6235], Loss: 4.6753\n",
      "Epoch [8/100], Step [15900/6235], Loss: 3.2312\n",
      "Epoch [8/100], Step [16000/6235], Loss: 83.1300\n",
      "Epoch [8/100], Step [16100/6235], Loss: 0.5323\n",
      "Epoch [8/100], Step [16200/6235], Loss: 14.6988\n",
      "Epoch [8/100], Step [16300/6235], Loss: 26.0378\n",
      "Epoch [8/100], Step [16400/6235], Loss: 38.2880\n",
      "Epoch [8/100], Step [16500/6235], Loss: 614.3716\n",
      "Epoch [8/100], Step [16600/6235], Loss: 29.9528\n",
      "Epoch [8/100], Step [16700/6235], Loss: 2.2842\n",
      "Epoch [8/100], Step [16800/6235], Loss: 1.0850\n",
      "Epoch [8/100], Step [16900/6235], Loss: 7.3860\n",
      "Epoch [8/100], Step [17000/6235], Loss: 0.8040\n",
      "Epoch [8/100], Step [17100/6235], Loss: 0.2723\n",
      "Epoch [8/100], Step [17200/6235], Loss: 78.4464\n",
      "Epoch [8/100], Step [17300/6235], Loss: 37.8933\n",
      "Epoch [8/100], Step [17400/6235], Loss: 27.2040\n",
      "Epoch [8/100], Step [17500/6235], Loss: 5.7479\n",
      "Epoch [8/100], Step [17600/6235], Loss: 0.2932\n",
      "Epoch [8/100], Step [17700/6235], Loss: 165.6124\n",
      "Epoch [8/100], Step [17800/6235], Loss: 37.2545\n",
      "Epoch [8/100], Step [17900/6235], Loss: 94.3386\n",
      "Epoch [8/100], Step [18000/6235], Loss: 5.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Step [18100/6235], Loss: 7.5458\n",
      "Epoch [8/100], Step [18200/6235], Loss: 5.2915\n",
      "Epoch [8/100], Step [18300/6235], Loss: 11.3894\n",
      "Epoch [8/100], Step [18400/6235], Loss: 0.4366\n",
      "Epoch [8/100], Step [18500/6235], Loss: 3.4860\n",
      "Epoch [8/100], Step [18600/6235], Loss: 0.3647\n",
      "Epoch [8/100], Step [18700/6235], Loss: 0.2401\n",
      "Epoch [8/100], Step [18800/6235], Loss: 160.6614\n",
      "Epoch [8/100], Step [18900/6235], Loss: 51.5314\n",
      "Epoch [8/100], Step [19000/6235], Loss: 1.6346\n",
      "Epoch [8/100], Step [19100/6235], Loss: 7.2753\n",
      "Epoch [8/100], Step [19200/6235], Loss: 3.1348\n",
      "Epoch [8/100], Step [19300/6235], Loss: 2.0291\n",
      "Epoch [8/100], Step [19400/6235], Loss: 188.0046\n",
      "Epoch [8/100], Step [19500/6235], Loss: 171.4441\n",
      "Epoch [8/100], Step [19600/6235], Loss: 143.6117\n",
      "Epoch [8/100], Step [19700/6235], Loss: 25.3374\n",
      "Epoch [8/100], Step [19800/6235], Loss: 1.7906\n",
      "Epoch [8/100], Step [19900/6235], Loss: 1.3720\n",
      "Epoch [8/100], Step [20000/6235], Loss: 82.9638\n",
      "Epoch [8/100], Step [20100/6235], Loss: 4.5902\n",
      "Epoch [8/100], Step [20200/6235], Loss: 6.2162\n",
      "Epoch [8/100], Step [20300/6235], Loss: 2.3627\n",
      "Epoch [8/100], Step [20400/6235], Loss: 25.9163\n",
      "Epoch [8/100], Step [20500/6235], Loss: 27.9623\n",
      "Epoch [8/100], Step [20600/6235], Loss: 190.2465\n",
      "Epoch [8/100], Step [20700/6235], Loss: 20.9122\n",
      "Epoch [8/100], Step [20800/6235], Loss: 0.3737\n",
      "Epoch [8/100], Step [20900/6235], Loss: 29.8398\n",
      "Epoch [8/100], Step [21000/6235], Loss: 16.5556\n",
      "Epoch [8/100], Step [21100/6235], Loss: 1.5981\n",
      "Epoch [8/100], Step [21200/6235], Loss: 0.2728\n",
      "Epoch [8/100], Step [21300/6235], Loss: 0.0856\n",
      "Epoch [8/100], Step [21400/6235], Loss: 6.4322\n",
      "Epoch [8/100], Step [21500/6235], Loss: 1.7326\n",
      "Epoch [8/100], Step [21600/6235], Loss: 28.4349\n",
      "Epoch [8/100], Step [21700/6235], Loss: 0.2066\n",
      "Epoch [8/100], Step [21800/6235], Loss: 4.9483\n",
      "Epoch [8/100], Step [21900/6235], Loss: 1.7950\n",
      "Epoch [8/100], Step [22000/6235], Loss: 9.4016\n",
      "Epoch [8/100], Step [22100/6235], Loss: 0.0279\n",
      "Epoch [8/100], Step [22200/6235], Loss: 2.4988\n",
      "Epoch [8/100], Step [22300/6235], Loss: 0.4555\n",
      "Epoch [8/100], Step [22400/6235], Loss: 7.3780\n",
      "Epoch [8/100], Step [22500/6235], Loss: 111.7730\n",
      "Epoch [8/100], Step [22600/6235], Loss: 15.0425\n",
      "Epoch [8/100], Step [22700/6235], Loss: 1.5105\n",
      "Epoch [8/100], Step [22800/6235], Loss: 12.6437\n",
      "Epoch [8/100], Step [22900/6235], Loss: 22.4498\n",
      "Epoch [8/100], Step [23000/6235], Loss: 15.0931\n",
      "Epoch [8/100], Step [23100/6235], Loss: 2.9699\n",
      "Epoch [8/100], Step [23200/6235], Loss: 4.6232\n",
      "Epoch [8/100], Step [23300/6235], Loss: 16.5135\n",
      "Epoch [8/100], Step [23400/6235], Loss: 2.3960\n",
      "Epoch [8/100], Step [23500/6235], Loss: 0.2900\n",
      "Epoch [8/100], Step [23600/6235], Loss: 126.9921\n",
      "Epoch [8/100], Step [23700/6235], Loss: 3.2631\n",
      "Epoch [8/100], Step [23800/6235], Loss: 0.6530\n",
      "Epoch [8/100], Step [23900/6235], Loss: 1.3605\n",
      "Epoch [8/100], Step [24000/6235], Loss: 5.6271\n",
      "Epoch [8/100], Step [24100/6235], Loss: 6.8905\n",
      "Epoch [8/100], Step [24200/6235], Loss: 0.4851\n",
      "Epoch [8/100], Step [24300/6235], Loss: 1.3894\n",
      "Epoch [8/100], Step [24400/6235], Loss: 5.1494\n",
      "Epoch [8/100], Step [24500/6235], Loss: 1.2223\n",
      "Epoch [8/100], Step [24600/6235], Loss: 1.3204\n",
      "Epoch [8/100], Step [24700/6235], Loss: 0.4298\n",
      "Epoch [8/100], Step [24800/6235], Loss: 0.7186\n",
      "Epoch [8/100], Step [24900/6235], Loss: 9.5254\n",
      "Epoch [8/100], Step [25000/6235], Loss: 6.8162\n",
      "Epoch [8/100], Step [25100/6235], Loss: 9.9078\n",
      "Epoch [8/100], Step [25200/6235], Loss: 0.6723\n",
      "Epoch [8/100], Step [25300/6235], Loss: 1.7196\n",
      "Epoch [8/100], Step [25400/6235], Loss: 2.8157\n",
      "Epoch [8/100], Step [25500/6235], Loss: 7.9294\n",
      "Epoch [8/100], Step [25600/6235], Loss: 10.5693\n",
      "Epoch [8/100], Step [25700/6235], Loss: 2.0538\n",
      "Epoch [8/100], Step [25800/6235], Loss: 4.0020\n",
      "Epoch [8/100], Step [25900/6235], Loss: 0.3545\n",
      "Epoch [8/100], Step [26000/6235], Loss: 0.0211\n",
      "Epoch [8/100], Step [26100/6235], Loss: 0.4555\n",
      "Epoch [8/100], Step [26200/6235], Loss: 0.9620\n",
      "Epoch [8/100], Step [26300/6235], Loss: 0.4184\n",
      "Epoch [8/100], Step [26400/6235], Loss: 1.2965\n",
      "Epoch [8/100], Step [26500/6235], Loss: 0.0211\n",
      "Epoch [8/100], Step [26600/6235], Loss: 0.1208\n",
      "Epoch [8/100], Step [26700/6235], Loss: 0.0292\n",
      "Epoch [8/100], Step [26800/6235], Loss: 0.0563\n",
      "Epoch [8/100], Step [26900/6235], Loss: 0.1432\n",
      "Epoch [8/100], Step [27000/6235], Loss: 14.0624\n",
      "Epoch [8/100], Step [27100/6235], Loss: 0.1282\n",
      "Epoch [8/100], Step [27200/6235], Loss: 0.2184\n",
      "Epoch [8/100], Step [27300/6235], Loss: 0.0189\n",
      "Epoch [8/100], Step [27400/6235], Loss: 0.3931\n",
      "Epoch [8/100], Step [27500/6235], Loss: 0.8243\n",
      "Epoch [8/100], Step [27600/6235], Loss: 0.5645\n",
      "Epoch [8/100], Step [27700/6235], Loss: 0.8936\n",
      "Epoch [8/100], Step [27800/6235], Loss: 6.4085\n",
      "Epoch [8/100], Step [27900/6235], Loss: 1.1745\n",
      "Epoch [8/100], Step [28000/6235], Loss: 165.2339\n",
      "Epoch [8/100], Step [28100/6235], Loss: 1.7218\n",
      "Epoch [8/100], Step [28200/6235], Loss: 27.6215\n",
      "Epoch [8/100], Step [28300/6235], Loss: 3.0767\n",
      "Epoch [8/100], Step [28400/6235], Loss: 26.2293\n",
      "Epoch [8/100], Step [28500/6235], Loss: 3.8847\n",
      "Epoch [8/100], Step [28600/6235], Loss: 0.1658\n",
      "Epoch [8/100], Step [28700/6235], Loss: 5.5445\n",
      "Epoch [8/100], Step [28800/6235], Loss: 0.6071\n",
      "Epoch [8/100], Step [28900/6235], Loss: 61.1600\n",
      "Epoch [8/100], Step [29000/6235], Loss: 12.1427\n",
      "Epoch [8/100], Step [29100/6235], Loss: 0.4924\n",
      "Epoch [8/100], Step [29200/6235], Loss: 4.9236\n",
      "Epoch [8/100], Step [29300/6235], Loss: 8.2830\n",
      "Epoch [8/100], Step [29400/6235], Loss: 1.1460\n",
      "Epoch [8/100], Step [29500/6235], Loss: 4.9128\n",
      "Epoch [8/100], Step [29600/6235], Loss: 0.3751\n",
      "Epoch [8/100], Step [29700/6235], Loss: 2.9444\n",
      "Epoch [8/100], Step [29800/6235], Loss: 0.4604\n",
      "Epoch [8/100], Step [29900/6235], Loss: 0.7541\n",
      "Epoch [8/100], Step [30000/6235], Loss: 6.4968\n",
      "Epoch [8/100], Step [30100/6235], Loss: 6.8171\n",
      "Epoch [8/100], Step [30200/6235], Loss: 1.8580\n",
      "Epoch [8/100], Step [30300/6235], Loss: 0.0766\n",
      "Epoch [8/100], Step [30400/6235], Loss: 2.5343\n",
      "Epoch [8/100], Step [30500/6235], Loss: 0.5401\n",
      "Epoch [8/100], Step [30600/6235], Loss: 1.5230\n",
      "Epoch [8/100], Step [30700/6235], Loss: 2.0509\n",
      "Epoch [8/100], Step [30800/6235], Loss: 0.5464\n",
      "Epoch [8/100], Step [30900/6235], Loss: 2.7164\n",
      "Epoch [8/100], Step [31000/6235], Loss: 0.3138\n",
      "Epoch [8/100], Step [31100/6235], Loss: 0.0782\n",
      "Epoch [8/100], Step [31200/6235], Loss: 6.4531\n",
      "Epoch [8/100], Step [31300/6235], Loss: 0.8087\n",
      "Epoch [8/100], Step [31400/6235], Loss: 0.0423\n",
      "Epoch [8/100], Step [31500/6235], Loss: 0.5074\n",
      "Epoch [8/100], Step [31600/6235], Loss: 6.2934\n",
      "Epoch [8/100], Step [31700/6235], Loss: 23.7385\n",
      "Epoch [8/100], Step [31800/6235], Loss: 2.6216\n",
      "Epoch [8/100], Step [31900/6235], Loss: 1618.0701\n",
      "Epoch [8/100], Step [32000/6235], Loss: 15.9208\n",
      "Epoch [8/100], Step [32100/6235], Loss: 7.6398\n",
      "Epoch [8/100], Step [32200/6235], Loss: 87.4255\n",
      "Epoch [8/100], Step [32300/6235], Loss: 1.2284\n",
      "Epoch [8/100], Step [32400/6235], Loss: 0.6816\n",
      "Epoch [8/100], Step [32500/6235], Loss: 19.6201\n",
      "Epoch [8/100], Step [32600/6235], Loss: 0.6358\n",
      "Epoch [8/100], Step [32700/6235], Loss: 42.2511\n",
      "Epoch [8/100], Step [32800/6235], Loss: 0.3025\n",
      "Epoch [8/100], Step [32900/6235], Loss: 14.5139\n",
      "Epoch [8/100], Step [33000/6235], Loss: 0.0904\n",
      "Epoch [8/100], Step [33100/6235], Loss: 0.4187\n",
      "Epoch [8/100], Step [33200/6235], Loss: 3.2265\n",
      "Epoch [8/100], Step [33300/6235], Loss: 0.4240\n",
      "Epoch [8/100], Step [33400/6235], Loss: 1.0619\n",
      "Epoch [8/100], Step [33500/6235], Loss: 0.2270\n",
      "Epoch [8/100], Step [33600/6235], Loss: 1.0339\n",
      "Epoch [8/100], Step [33700/6235], Loss: 0.9512\n",
      "Epoch [8/100], Step [33800/6235], Loss: 9.7332\n",
      "Epoch [8/100], Step [33900/6235], Loss: 27.7408\n",
      "Epoch [8/100], Step [34000/6235], Loss: 0.0139\n",
      "Epoch [8/100], Step [34100/6235], Loss: 0.1996\n",
      "Epoch [8/100], Step [34200/6235], Loss: 23.0131\n",
      "Epoch [8/100], Step [34300/6235], Loss: 1.0948\n",
      "Epoch [8/100], Step [34400/6235], Loss: 0.2362\n",
      "Epoch [8/100], Step [34500/6235], Loss: 146.7049\n",
      "Epoch [8/100], Step [34600/6235], Loss: 1.9623\n",
      "Epoch [8/100], Step [34700/6235], Loss: 15.2038\n",
      "Epoch [8/100], Step [34800/6235], Loss: 8.8339\n",
      "Epoch [8/100], Step [34900/6235], Loss: 47.7070\n",
      "Epoch [8/100], Step [35000/6235], Loss: 0.0843\n",
      "Epoch [8/100], Step [35100/6235], Loss: 3.8471\n",
      "Epoch [8/100], Step [35200/6235], Loss: 6.4419\n",
      "Epoch [8/100], Step [35300/6235], Loss: 1.9517\n",
      "Epoch [8/100], Step [35400/6235], Loss: 0.4964\n",
      "Epoch [8/100], Step [35500/6235], Loss: 0.3302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [8/100], Step [35600/6235], Loss: 11.8092\n",
      "Epoch [8/100], Step [35700/6235], Loss: 17.2963\n",
      "Epoch [8/100], Step [35800/6235], Loss: 0.6841\n",
      "Epoch [8/100], Step [35900/6235], Loss: 1.4517\n",
      "Epoch [8/100], Step [36000/6235], Loss: 0.5541\n",
      "Epoch [8/100], Step [36100/6235], Loss: 9.0079\n",
      "Epoch [8/100], Step [36200/6235], Loss: 19.3971\n",
      "Epoch [8/100], Step [36300/6235], Loss: 0.2677\n",
      "Epoch [8/100], Step [36400/6235], Loss: 0.0220\n",
      "Epoch [8/100], Step [36500/6235], Loss: 11.5715\n",
      "Epoch [8/100], Step [36600/6235], Loss: 0.7472\n",
      "Epoch [8/100], Step [36700/6235], Loss: 0.9837\n",
      "Epoch [8/100], Step [36800/6235], Loss: 26.1262\n",
      "Epoch [8/100], Step [36900/6235], Loss: 4.6802\n",
      "Epoch [8/100], Step [37000/6235], Loss: 1.1164\n",
      "Epoch [8/100], Step [37100/6235], Loss: 1.4935\n",
      "Epoch [8/100], Step [37200/6235], Loss: 0.0878\n",
      "Epoch [8/100], Step [37300/6235], Loss: 0.6983\n",
      "Epoch [8/100], Step [37400/6235], Loss: 1.0723\n",
      "Epoch [8/100], Step [37500/6235], Loss: 1.2412\n",
      "Epoch [8/100], Step [37600/6235], Loss: 5.6558\n",
      "Epoch [8/100], Step [37700/6235], Loss: 0.5786\n",
      "Epoch [8/100], Step [37800/6235], Loss: 0.2690\n",
      "Epoch [8/100], Step [37900/6235], Loss: 3.6803\n",
      "Epoch [8/100], Step [38000/6235], Loss: 0.2506\n",
      "Epoch [8/100], Step [38100/6235], Loss: 8.6544\n",
      "Epoch [8/100], Step [38200/6235], Loss: 3.7134\n",
      "Epoch [8/100], Step [38300/6235], Loss: 4.2410\n",
      "Epoch [8/100], Step [38400/6235], Loss: 0.0810\n",
      "Epoch [8/100], Step [38500/6235], Loss: 0.5177\n",
      "Epoch [8/100], Step [38600/6235], Loss: 9.3231\n",
      "Epoch [8/100], Step [38700/6235], Loss: 0.0409\n",
      "Epoch [8/100], Step [38800/6235], Loss: 1.0528\n",
      "Epoch [8/100], Step [38900/6235], Loss: 7.2332\n",
      "Epoch [8/100], Step [39000/6235], Loss: 8.1862\n",
      "Epoch [8/100], Step [39100/6235], Loss: 19.4897\n",
      "Epoch [8/100], Step [39200/6235], Loss: 0.2950\n",
      "Epoch [8/100], Step [39300/6235], Loss: 9.9733\n",
      "Epoch [8/100], Step [39400/6235], Loss: 67.8450\n",
      "Epoch [8/100], Step [39500/6235], Loss: 254.8469\n",
      "Epoch [8/100], Step [39600/6235], Loss: 13.3032\n",
      "Epoch [8/100], Step [39700/6235], Loss: 114.8224\n",
      "Epoch [8/100], Step [39800/6235], Loss: 171.2974\n",
      "Epoch [8/100], Step [39900/6235], Loss: 0.6297\n",
      "Epoch [8/100], Step [40000/6235], Loss: 13.4548\n",
      "Epoch [8/100], Step [40100/6235], Loss: 33.5477\n",
      "Epoch [8/100], Step [40200/6235], Loss: 31.9764\n",
      "Epoch [8/100], Step [40300/6235], Loss: 0.2063\n",
      "Epoch [8/100], Step [40400/6235], Loss: 1.8124\n",
      "Epoch [8/100], Step [40500/6235], Loss: 1.0014\n",
      "Epoch [8/100], Step [40600/6235], Loss: 1.2164\n",
      "Epoch [8/100], Step [40700/6235], Loss: 7.1619\n",
      "Epoch [8/100], Step [40800/6235], Loss: 3.8256\n",
      "Epoch [8/100], Step [40900/6235], Loss: 0.7122\n",
      "Epoch [8/100], Step [41000/6235], Loss: 0.1777\n",
      "Epoch [8/100], Step [41100/6235], Loss: 34.0792\n",
      "Epoch [8/100], Step [41200/6235], Loss: 40.2882\n",
      "Epoch [8/100], Step [41300/6235], Loss: 1.9340\n",
      "Epoch [8/100], Step [41400/6235], Loss: 0.7039\n",
      "Epoch [8/100], Step [41500/6235], Loss: 0.2106\n",
      "Epoch [8/100], Step [41600/6235], Loss: 0.0710\n",
      "Epoch [8/100], Step [41700/6235], Loss: 3.6009\n",
      "Epoch [8/100], Step [41800/6235], Loss: 3.1617\n",
      "Epoch [8/100], Step [41900/6235], Loss: 0.6580\n",
      "Epoch [8/100], Step [42000/6235], Loss: 2.8270\n",
      "Epoch [8/100], Step [42100/6235], Loss: 2.4877\n",
      "Epoch [8/100], Step [42200/6235], Loss: 12.7237\n",
      "Epoch [8/100], Step [42300/6235], Loss: 0.6733\n",
      "Epoch [8/100], Step [42400/6235], Loss: 4.5958\n",
      "Epoch [8/100], Step [42500/6235], Loss: 2.9820\n",
      "Epoch [8/100], Step [42600/6235], Loss: 0.4654\n",
      "Epoch [8/100], Step [42700/6235], Loss: 0.1750\n",
      "Epoch [8/100], Step [42800/6235], Loss: 2.8449\n",
      "Epoch [8/100], Step [42900/6235], Loss: 4.3437\n",
      "Epoch [8/100], Step [43000/6235], Loss: 1.5649\n",
      "Epoch [8/100], Step [43100/6235], Loss: 2.9799\n",
      "Epoch [8/100], Step [43200/6235], Loss: 0.1694\n",
      "Epoch [8/100], Step [43300/6235], Loss: 12.6673\n",
      "Epoch [8/100], Step [43400/6235], Loss: 5.4586\n",
      "Epoch [8/100], Step [43500/6235], Loss: 6.6612\n",
      "Epoch [8/100], Step [43600/6235], Loss: 43.3657\n",
      "Epoch [8/100], Step [43700/6235], Loss: 42.6580\n",
      "Epoch [8/100], Step [43800/6235], Loss: 0.3177\n",
      "Epoch [8/100], Step [43900/6235], Loss: 1.5320\n",
      "Epoch [8/100], Step [44000/6235], Loss: 52.6378\n",
      "Epoch [8/100], Step [44100/6235], Loss: 2.4716\n",
      "Epoch [8/100], Step [44200/6235], Loss: 26.3669\n",
      "Epoch [8/100], Step [44300/6235], Loss: 4.0504\n",
      "Epoch [8/100], Step [44400/6235], Loss: 0.4074\n",
      "Epoch [8/100], Step [44500/6235], Loss: 2.5189\n",
      "Epoch [8/100], Step [44600/6235], Loss: 12.2817\n",
      "Epoch [8/100], Step [44700/6235], Loss: 2.9590\n",
      "Epoch [8/100], Step [44800/6235], Loss: 1.0238\n",
      "Epoch [8/100], Step [44900/6235], Loss: 0.8737\n",
      "Epoch [8/100], Step [45000/6235], Loss: 2.6621\n",
      "Epoch [8/100], Step [45100/6235], Loss: 48.2589\n",
      "Epoch [8/100], Step [45200/6235], Loss: 0.3733\n",
      "Epoch [8/100], Step [45300/6235], Loss: 41.6265\n",
      "Epoch [8/100], Step [45400/6235], Loss: 5.5263\n",
      "Epoch [8/100], Step [45500/6235], Loss: 0.1582\n",
      "Epoch [8/100], Step [45600/6235], Loss: 0.1309\n",
      "Epoch [8/100], Step [45700/6235], Loss: 76.4159\n",
      "Epoch [8/100], Step [45800/6235], Loss: 586.7211\n",
      "Epoch [8/100], Step [45900/6235], Loss: 0.8947\n",
      "Epoch [8/100], Step [46000/6235], Loss: 11.3634\n",
      "Epoch [8/100], Step [46100/6235], Loss: 22.2808\n",
      "Epoch [8/100], Step [46200/6235], Loss: 19.5338\n",
      "Epoch [8/100], Step [46300/6235], Loss: 50.1948\n",
      "Epoch [8/100], Step [46400/6235], Loss: 9.0315\n",
      "Epoch [8/100], Step [46500/6235], Loss: 10.0835\n",
      "Epoch [8/100], Step [46600/6235], Loss: 4.5089\n",
      "Epoch [8/100], Step [46700/6235], Loss: 1.4489\n",
      "Epoch [8/100], Step [46800/6235], Loss: 28.9423\n",
      "Epoch [8/100], Step [46900/6235], Loss: 20.0878\n",
      "Epoch [8/100], Step [47000/6235], Loss: 0.6879\n",
      "Epoch [8/100], Step [47100/6235], Loss: 66.7684\n",
      "Epoch [8/100], Step [47200/6235], Loss: 82.9649\n",
      "Epoch [8/100], Step [47300/6235], Loss: 0.6825\n",
      "Epoch [8/100], Step [47400/6235], Loss: 70.4041\n",
      "Epoch [8/100], Step [47500/6235], Loss: 3.1233\n",
      "Epoch [8/100], Step [47600/6235], Loss: 10.1002\n",
      "Epoch [8/100], Step [47700/6235], Loss: 6.1953\n",
      "Epoch [8/100], Step [47800/6235], Loss: 6.5164\n",
      "Epoch [8/100], Step [47900/6235], Loss: 24.0792\n",
      "Epoch [8/100], Step [48000/6235], Loss: 6.8556\n",
      "Epoch [8/100], Step [48100/6235], Loss: 2.1903\n",
      "Epoch [8/100], Step [48200/6235], Loss: 35.2033\n",
      "Epoch [8/100], Step [48300/6235], Loss: 249.1899\n",
      "Epoch [8/100], Step [48400/6235], Loss: 30.8140\n",
      "Epoch [8/100], Step [48500/6235], Loss: 10.2140\n",
      "Epoch [8/100], Step [48600/6235], Loss: 142.8674\n",
      "Epoch [8/100], Step [48700/6235], Loss: 77.1917\n",
      "Epoch [8/100], Step [48800/6235], Loss: 142.7630\n",
      "Epoch [8/100], Step [48900/6235], Loss: 115.9249\n",
      "Epoch [8/100], Step [49000/6235], Loss: 294.0392\n",
      "Epoch [8/100], Step [49100/6235], Loss: 1634.0249\n",
      "Epoch [8/100], Step [49200/6235], Loss: 542.6301\n",
      "Epoch [8/100], Step [49300/6235], Loss: 1176.2496\n",
      "Epoch [8/100], Step [49400/6235], Loss: 32.5502\n",
      "Epoch [8/100], Step [49500/6235], Loss: 6.3251\n",
      "Epoch [8/100], Step [49600/6235], Loss: 106.9798\n",
      "Epoch [8/100], Step [49700/6235], Loss: 18124.4863\n",
      "Epoch [8/100], Step [49800/6235], Loss: 2920.1509\n",
      "Epoch [9/100], Step [100/6235], Loss: 44.0187\n",
      "Epoch [9/100], Step [200/6235], Loss: 0.2966\n",
      "Epoch [9/100], Step [300/6235], Loss: 0.0323\n",
      "Epoch [9/100], Step [400/6235], Loss: 0.0110\n",
      "Epoch [9/100], Step [500/6235], Loss: 14.2907\n",
      "Epoch [9/100], Step [600/6235], Loss: 0.1159\n",
      "Epoch [9/100], Step [700/6235], Loss: 0.9919\n",
      "Epoch [9/100], Step [800/6235], Loss: 0.4494\n",
      "Epoch [9/100], Step [900/6235], Loss: 0.4830\n",
      "Epoch [9/100], Step [1000/6235], Loss: 0.0420\n",
      "Epoch [9/100], Step [1100/6235], Loss: 0.5609\n",
      "Epoch [9/100], Step [1200/6235], Loss: 0.2748\n",
      "Epoch [9/100], Step [1300/6235], Loss: 0.1941\n",
      "Epoch [9/100], Step [1400/6235], Loss: 1.3312\n",
      "Epoch [9/100], Step [1500/6235], Loss: 0.0584\n",
      "Epoch [9/100], Step [1600/6235], Loss: 0.6283\n",
      "Epoch [9/100], Step [1700/6235], Loss: 0.1954\n",
      "Epoch [9/100], Step [1800/6235], Loss: 0.4437\n",
      "Epoch [9/100], Step [1900/6235], Loss: 0.3923\n",
      "Epoch [9/100], Step [2000/6235], Loss: 2.6909\n",
      "Epoch [9/100], Step [2100/6235], Loss: 1.7267\n",
      "Epoch [9/100], Step [2200/6235], Loss: 7.1731\n",
      "Epoch [9/100], Step [2300/6235], Loss: 5.3271\n",
      "Epoch [9/100], Step [2400/6235], Loss: 3.5885\n",
      "Epoch [9/100], Step [2500/6235], Loss: 37.8253\n",
      "Epoch [9/100], Step [2600/6235], Loss: 13.2169\n",
      "Epoch [9/100], Step [2700/6235], Loss: 5.5475\n",
      "Epoch [9/100], Step [2800/6235], Loss: 128.2262\n",
      "Epoch [9/100], Step [2900/6235], Loss: 13.1692\n",
      "Epoch [9/100], Step [3000/6235], Loss: 1.0788\n",
      "Epoch [9/100], Step [3100/6235], Loss: 69.1878\n",
      "Epoch [9/100], Step [3200/6235], Loss: 81.0347\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Step [3300/6235], Loss: 6.5147\n",
      "Epoch [9/100], Step [3400/6235], Loss: 1.7815\n",
      "Epoch [9/100], Step [3500/6235], Loss: 34.5477\n",
      "Epoch [9/100], Step [3600/6235], Loss: 8.7767\n",
      "Epoch [9/100], Step [3700/6235], Loss: 0.0783\n",
      "Epoch [9/100], Step [3800/6235], Loss: 0.2648\n",
      "Epoch [9/100], Step [3900/6235], Loss: 0.7638\n",
      "Epoch [9/100], Step [4000/6235], Loss: 0.0201\n",
      "Epoch [9/100], Step [4100/6235], Loss: 6.6654\n",
      "Epoch [9/100], Step [4200/6235], Loss: 0.5916\n",
      "Epoch [9/100], Step [4300/6235], Loss: 6.6666\n",
      "Epoch [9/100], Step [4400/6235], Loss: 3.4989\n",
      "Epoch [9/100], Step [4500/6235], Loss: 42.4503\n",
      "Epoch [9/100], Step [4600/6235], Loss: 1.4279\n",
      "Epoch [9/100], Step [4700/6235], Loss: 0.2884\n",
      "Epoch [9/100], Step [4800/6235], Loss: 9.3659\n",
      "Epoch [9/100], Step [4900/6235], Loss: 0.2330\n",
      "Epoch [9/100], Step [5000/6235], Loss: 0.1095\n",
      "Epoch [9/100], Step [5100/6235], Loss: 2.1935\n",
      "Epoch [9/100], Step [5200/6235], Loss: 1.3421\n",
      "Epoch [9/100], Step [5300/6235], Loss: 41.8853\n",
      "Epoch [9/100], Step [5400/6235], Loss: 1.0957\n",
      "Epoch [9/100], Step [5500/6235], Loss: 0.0145\n",
      "Epoch [9/100], Step [5600/6235], Loss: 0.3253\n",
      "Epoch [9/100], Step [5700/6235], Loss: 0.1905\n",
      "Epoch [9/100], Step [5800/6235], Loss: 0.1786\n",
      "Epoch [9/100], Step [5900/6235], Loss: 0.1789\n",
      "Epoch [9/100], Step [6000/6235], Loss: 3.1437\n",
      "Epoch [9/100], Step [6100/6235], Loss: 0.0912\n",
      "Epoch [9/100], Step [6200/6235], Loss: 2.0500\n",
      "Epoch [9/100], Step [6300/6235], Loss: 1.5921\n",
      "Epoch [9/100], Step [6400/6235], Loss: 0.0500\n",
      "Epoch [9/100], Step [6500/6235], Loss: 3.0819\n",
      "Epoch [9/100], Step [6600/6235], Loss: 5.8675\n",
      "Epoch [9/100], Step [6700/6235], Loss: 3.9768\n",
      "Epoch [9/100], Step [6800/6235], Loss: 0.0939\n",
      "Epoch [9/100], Step [6900/6235], Loss: 0.8090\n",
      "Epoch [9/100], Step [7000/6235], Loss: 0.2842\n",
      "Epoch [9/100], Step [7100/6235], Loss: 0.2387\n",
      "Epoch [9/100], Step [7200/6235], Loss: 0.1173\n",
      "Epoch [9/100], Step [7300/6235], Loss: 0.2285\n",
      "Epoch [9/100], Step [7400/6235], Loss: 0.2751\n",
      "Epoch [9/100], Step [7500/6235], Loss: 0.2979\n",
      "Epoch [9/100], Step [7600/6235], Loss: 2.5317\n",
      "Epoch [9/100], Step [7700/6235], Loss: 23.0931\n",
      "Epoch [9/100], Step [7800/6235], Loss: 11.3019\n",
      "Epoch [9/100], Step [7900/6235], Loss: 10.1766\n",
      "Epoch [9/100], Step [8000/6235], Loss: 0.1698\n",
      "Epoch [9/100], Step [8100/6235], Loss: 4.2365\n",
      "Epoch [9/100], Step [8200/6235], Loss: 20.0733\n",
      "Epoch [9/100], Step [8300/6235], Loss: 82.3556\n",
      "Epoch [9/100], Step [8400/6235], Loss: 42.7394\n",
      "Epoch [9/100], Step [8500/6235], Loss: 68.9019\n",
      "Epoch [9/100], Step [8600/6235], Loss: 17.2592\n",
      "Epoch [9/100], Step [8700/6235], Loss: 70.1993\n",
      "Epoch [9/100], Step [8800/6235], Loss: 79.8545\n",
      "Epoch [9/100], Step [8900/6235], Loss: 6.6641\n",
      "Epoch [9/100], Step [9000/6235], Loss: 251.8271\n",
      "Epoch [9/100], Step [9100/6235], Loss: 875.6651\n",
      "Epoch [9/100], Step [9200/6235], Loss: 4056.7788\n",
      "Epoch [9/100], Step [9300/6235], Loss: 50.3657\n",
      "Epoch [9/100], Step [9400/6235], Loss: 491.4605\n",
      "Epoch [9/100], Step [9500/6235], Loss: 11.0396\n",
      "Epoch [9/100], Step [9600/6235], Loss: 277.9792\n",
      "Epoch [9/100], Step [9700/6235], Loss: 93.1152\n",
      "Epoch [9/100], Step [9800/6235], Loss: 197.0230\n",
      "Epoch [9/100], Step [9900/6235], Loss: 13.5593\n",
      "Epoch [9/100], Step [10000/6235], Loss: 80.2970\n",
      "Epoch [9/100], Step [10100/6235], Loss: 2.3135\n",
      "Epoch [9/100], Step [10200/6235], Loss: 453.7081\n",
      "Epoch [9/100], Step [10300/6235], Loss: 1.5683\n",
      "Epoch [9/100], Step [10400/6235], Loss: 0.9232\n",
      "Epoch [9/100], Step [10500/6235], Loss: 4.9315\n",
      "Epoch [9/100], Step [10600/6235], Loss: 1258.8497\n",
      "Epoch [9/100], Step [10700/6235], Loss: 56.8930\n",
      "Epoch [9/100], Step [10800/6235], Loss: 45.2896\n",
      "Epoch [9/100], Step [10900/6235], Loss: 2.8752\n",
      "Epoch [9/100], Step [11000/6235], Loss: 170.7239\n",
      "Epoch [9/100], Step [11100/6235], Loss: 12.8088\n",
      "Epoch [9/100], Step [11200/6235], Loss: 98.6399\n",
      "Epoch [9/100], Step [11300/6235], Loss: 236.7612\n",
      "Epoch [9/100], Step [11400/6235], Loss: 140.4388\n",
      "Epoch [9/100], Step [11500/6235], Loss: 12.5424\n",
      "Epoch [9/100], Step [11600/6235], Loss: 5.6324\n",
      "Epoch [9/100], Step [11700/6235], Loss: 143.7677\n",
      "Epoch [9/100], Step [11800/6235], Loss: 97.4306\n",
      "Epoch [9/100], Step [11900/6235], Loss: 822.2059\n",
      "Epoch [9/100], Step [12000/6235], Loss: 184.8278\n",
      "Epoch [9/100], Step [12100/6235], Loss: 442.3775\n",
      "Epoch [9/100], Step [12200/6235], Loss: 22.1620\n",
      "Epoch [9/100], Step [12300/6235], Loss: 6.6874\n",
      "Epoch [9/100], Step [12400/6235], Loss: 28.2305\n",
      "Epoch [9/100], Step [12500/6235], Loss: 179.3040\n",
      "Epoch [9/100], Step [12600/6235], Loss: 2.0047\n",
      "Epoch [9/100], Step [12700/6235], Loss: 19.0315\n",
      "Epoch [9/100], Step [12800/6235], Loss: 24.5067\n",
      "Epoch [9/100], Step [12900/6235], Loss: 65.4186\n",
      "Epoch [9/100], Step [13000/6235], Loss: 0.2515\n",
      "Epoch [9/100], Step [13100/6235], Loss: 85.0181\n",
      "Epoch [9/100], Step [13200/6235], Loss: 14.4620\n",
      "Epoch [9/100], Step [13300/6235], Loss: 17.0937\n",
      "Epoch [9/100], Step [13400/6235], Loss: 102.5563\n",
      "Epoch [9/100], Step [13500/6235], Loss: 6.8629\n",
      "Epoch [9/100], Step [13600/6235], Loss: 16.2958\n",
      "Epoch [9/100], Step [13700/6235], Loss: 7.7420\n",
      "Epoch [9/100], Step [13800/6235], Loss: 130.2507\n",
      "Epoch [9/100], Step [13900/6235], Loss: 60.4796\n",
      "Epoch [9/100], Step [14000/6235], Loss: 11.3352\n",
      "Epoch [9/100], Step [14100/6235], Loss: 29.2833\n",
      "Epoch [9/100], Step [14200/6235], Loss: 37.8182\n",
      "Epoch [9/100], Step [14300/6235], Loss: 1.1820\n",
      "Epoch [9/100], Step [14400/6235], Loss: 25.9132\n",
      "Epoch [9/100], Step [14500/6235], Loss: 25.7425\n",
      "Epoch [9/100], Step [14600/6235], Loss: 2.2217\n",
      "Epoch [9/100], Step [14700/6235], Loss: 31.8198\n",
      "Epoch [9/100], Step [14800/6235], Loss: 33.0573\n",
      "Epoch [9/100], Step [14900/6235], Loss: 0.6145\n",
      "Epoch [9/100], Step [15000/6235], Loss: 1.3048\n",
      "Epoch [9/100], Step [15100/6235], Loss: 0.4135\n",
      "Epoch [9/100], Step [15200/6235], Loss: 49.0420\n",
      "Epoch [9/100], Step [15300/6235], Loss: 1.0839\n",
      "Epoch [9/100], Step [15400/6235], Loss: 29.2720\n",
      "Epoch [9/100], Step [15500/6235], Loss: 0.5157\n",
      "Epoch [9/100], Step [15600/6235], Loss: 185.7675\n",
      "Epoch [9/100], Step [15700/6235], Loss: 42.5271\n",
      "Epoch [9/100], Step [15800/6235], Loss: 9.2377\n",
      "Epoch [9/100], Step [15900/6235], Loss: 0.8292\n",
      "Epoch [9/100], Step [16000/6235], Loss: 54.6164\n",
      "Epoch [9/100], Step [16100/6235], Loss: 0.6993\n",
      "Epoch [9/100], Step [16200/6235], Loss: 14.8402\n",
      "Epoch [9/100], Step [16300/6235], Loss: 21.3288\n",
      "Epoch [9/100], Step [16400/6235], Loss: 33.2563\n",
      "Epoch [9/100], Step [16500/6235], Loss: 567.6912\n",
      "Epoch [9/100], Step [16600/6235], Loss: 27.9848\n",
      "Epoch [9/100], Step [16700/6235], Loss: 1.7790\n",
      "Epoch [9/100], Step [16800/6235], Loss: 1.9953\n",
      "Epoch [9/100], Step [16900/6235], Loss: 5.1815\n",
      "Epoch [9/100], Step [17000/6235], Loss: 0.5228\n",
      "Epoch [9/100], Step [17100/6235], Loss: 0.5208\n",
      "Epoch [9/100], Step [17200/6235], Loss: 92.6876\n",
      "Epoch [9/100], Step [17300/6235], Loss: 47.9327\n",
      "Epoch [9/100], Step [17400/6235], Loss: 28.8966\n",
      "Epoch [9/100], Step [17500/6235], Loss: 8.9891\n",
      "Epoch [9/100], Step [17600/6235], Loss: 0.4257\n",
      "Epoch [9/100], Step [17700/6235], Loss: 5.3495\n",
      "Epoch [9/100], Step [17800/6235], Loss: 39.5678\n",
      "Epoch [9/100], Step [17900/6235], Loss: 0.7996\n",
      "Epoch [9/100], Step [18000/6235], Loss: 6.7575\n",
      "Epoch [9/100], Step [18100/6235], Loss: 13.8742\n",
      "Epoch [9/100], Step [18200/6235], Loss: 3.4293\n",
      "Epoch [9/100], Step [18300/6235], Loss: 10.4111\n",
      "Epoch [9/100], Step [18400/6235], Loss: 1.1952\n",
      "Epoch [9/100], Step [18500/6235], Loss: 2.7654\n",
      "Epoch [9/100], Step [18600/6235], Loss: 0.1712\n",
      "Epoch [9/100], Step [18700/6235], Loss: 0.2924\n",
      "Epoch [9/100], Step [18800/6235], Loss: 49.4843\n",
      "Epoch [9/100], Step [18900/6235], Loss: 35.2531\n",
      "Epoch [9/100], Step [19000/6235], Loss: 3.3322\n",
      "Epoch [9/100], Step [19100/6235], Loss: 47.3167\n",
      "Epoch [9/100], Step [19200/6235], Loss: 0.9441\n",
      "Epoch [9/100], Step [19300/6235], Loss: 18.0873\n",
      "Epoch [9/100], Step [19400/6235], Loss: 0.5297\n",
      "Epoch [9/100], Step [19500/6235], Loss: 79.2318\n",
      "Epoch [9/100], Step [19600/6235], Loss: 91.0981\n",
      "Epoch [9/100], Step [19700/6235], Loss: 6.6200\n",
      "Epoch [9/100], Step [19800/6235], Loss: 2.4773\n",
      "Epoch [9/100], Step [19900/6235], Loss: 0.1410\n",
      "Epoch [9/100], Step [20000/6235], Loss: 55.5909\n",
      "Epoch [9/100], Step [20100/6235], Loss: 3.9984\n",
      "Epoch [9/100], Step [20200/6235], Loss: 0.7774\n",
      "Epoch [9/100], Step [20300/6235], Loss: 0.3951\n",
      "Epoch [9/100], Step [20400/6235], Loss: 11.4633\n",
      "Epoch [9/100], Step [20500/6235], Loss: 47.1576\n",
      "Epoch [9/100], Step [20600/6235], Loss: 70.9842\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Step [20700/6235], Loss: 20.6898\n",
      "Epoch [9/100], Step [20800/6235], Loss: 1.7381\n",
      "Epoch [9/100], Step [20900/6235], Loss: 0.4986\n",
      "Epoch [9/100], Step [21000/6235], Loss: 15.1308\n",
      "Epoch [9/100], Step [21100/6235], Loss: 5.3134\n",
      "Epoch [9/100], Step [21200/6235], Loss: 0.1749\n",
      "Epoch [9/100], Step [21300/6235], Loss: 0.2176\n",
      "Epoch [9/100], Step [21400/6235], Loss: 5.0430\n",
      "Epoch [9/100], Step [21500/6235], Loss: 0.9707\n",
      "Epoch [9/100], Step [21600/6235], Loss: 30.5889\n",
      "Epoch [9/100], Step [21700/6235], Loss: 1.0870\n",
      "Epoch [9/100], Step [21800/6235], Loss: 4.4364\n",
      "Epoch [9/100], Step [21900/6235], Loss: 1.8806\n",
      "Epoch [9/100], Step [22000/6235], Loss: 11.6935\n",
      "Epoch [9/100], Step [22100/6235], Loss: 0.5543\n",
      "Epoch [9/100], Step [22200/6235], Loss: 0.2004\n",
      "Epoch [9/100], Step [22300/6235], Loss: 0.2064\n",
      "Epoch [9/100], Step [22400/6235], Loss: 0.6292\n",
      "Epoch [9/100], Step [22500/6235], Loss: 127.8397\n",
      "Epoch [9/100], Step [22600/6235], Loss: 17.6530\n",
      "Epoch [9/100], Step [22700/6235], Loss: 1.4133\n",
      "Epoch [9/100], Step [22800/6235], Loss: 27.3487\n",
      "Epoch [9/100], Step [22900/6235], Loss: 20.6188\n",
      "Epoch [9/100], Step [23000/6235], Loss: 24.1532\n",
      "Epoch [9/100], Step [23100/6235], Loss: 4.4839\n",
      "Epoch [9/100], Step [23200/6235], Loss: 34.0490\n",
      "Epoch [9/100], Step [23300/6235], Loss: 13.4265\n",
      "Epoch [9/100], Step [23400/6235], Loss: 2.3113\n",
      "Epoch [9/100], Step [23500/6235], Loss: 0.1555\n",
      "Epoch [9/100], Step [23600/6235], Loss: 112.3215\n",
      "Epoch [9/100], Step [23700/6235], Loss: 2.5718\n",
      "Epoch [9/100], Step [23800/6235], Loss: 1.0310\n",
      "Epoch [9/100], Step [23900/6235], Loss: 3.6082\n",
      "Epoch [9/100], Step [24000/6235], Loss: 8.7087\n",
      "Epoch [9/100], Step [24100/6235], Loss: 8.3918\n",
      "Epoch [9/100], Step [24200/6235], Loss: 0.8613\n",
      "Epoch [9/100], Step [24300/6235], Loss: 4.3458\n",
      "Epoch [9/100], Step [24400/6235], Loss: 8.5776\n",
      "Epoch [9/100], Step [24500/6235], Loss: 0.2931\n",
      "Epoch [9/100], Step [24600/6235], Loss: 0.1815\n",
      "Epoch [9/100], Step [24700/6235], Loss: 1.4611\n",
      "Epoch [9/100], Step [24800/6235], Loss: 0.4617\n",
      "Epoch [9/100], Step [24900/6235], Loss: 7.7990\n",
      "Epoch [9/100], Step [25000/6235], Loss: 2.9076\n",
      "Epoch [9/100], Step [25100/6235], Loss: 14.9645\n",
      "Epoch [9/100], Step [25200/6235], Loss: 0.3212\n",
      "Epoch [9/100], Step [25300/6235], Loss: 4.5927\n",
      "Epoch [9/100], Step [25400/6235], Loss: 1.2618\n",
      "Epoch [9/100], Step [25500/6235], Loss: 5.4301\n",
      "Epoch [9/100], Step [25600/6235], Loss: 8.7099\n",
      "Epoch [9/100], Step [25700/6235], Loss: 3.1449\n",
      "Epoch [9/100], Step [25800/6235], Loss: 7.6685\n",
      "Epoch [9/100], Step [25900/6235], Loss: 1.1808\n",
      "Epoch [9/100], Step [26000/6235], Loss: 0.0564\n",
      "Epoch [9/100], Step [26100/6235], Loss: 0.8120\n",
      "Epoch [9/100], Step [26200/6235], Loss: 0.2837\n",
      "Epoch [9/100], Step [26300/6235], Loss: 0.2203\n",
      "Epoch [9/100], Step [26400/6235], Loss: 2.9795\n",
      "Epoch [9/100], Step [26500/6235], Loss: 0.0662\n",
      "Epoch [9/100], Step [26600/6235], Loss: 0.9700\n",
      "Epoch [9/100], Step [26700/6235], Loss: 0.1028\n",
      "Epoch [9/100], Step [26800/6235], Loss: 0.2827\n",
      "Epoch [9/100], Step [26900/6235], Loss: 0.1488\n",
      "Epoch [9/100], Step [27000/6235], Loss: 11.3494\n",
      "Epoch [9/100], Step [27100/6235], Loss: 0.0770\n",
      "Epoch [9/100], Step [27200/6235], Loss: 0.4461\n",
      "Epoch [9/100], Step [27300/6235], Loss: 0.0172\n",
      "Epoch [9/100], Step [27400/6235], Loss: 0.2582\n",
      "Epoch [9/100], Step [27500/6235], Loss: 0.0671\n",
      "Epoch [9/100], Step [27600/6235], Loss: 0.0080\n",
      "Epoch [9/100], Step [27700/6235], Loss: 0.8736\n",
      "Epoch [9/100], Step [27800/6235], Loss: 5.3362\n",
      "Epoch [9/100], Step [27900/6235], Loss: 1.5920\n",
      "Epoch [9/100], Step [28000/6235], Loss: 64.3580\n",
      "Epoch [9/100], Step [28100/6235], Loss: 0.7034\n",
      "Epoch [9/100], Step [28200/6235], Loss: 33.9670\n",
      "Epoch [9/100], Step [28300/6235], Loss: 2.8467\n",
      "Epoch [9/100], Step [28400/6235], Loss: 26.2430\n",
      "Epoch [9/100], Step [28500/6235], Loss: 4.6880\n",
      "Epoch [9/100], Step [28600/6235], Loss: 0.4188\n",
      "Epoch [9/100], Step [28700/6235], Loss: 4.2572\n",
      "Epoch [9/100], Step [28800/6235], Loss: 0.6874\n",
      "Epoch [9/100], Step [28900/6235], Loss: 44.8054\n",
      "Epoch [9/100], Step [29000/6235], Loss: 1.3284\n",
      "Epoch [9/100], Step [29100/6235], Loss: 0.1728\n",
      "Epoch [9/100], Step [29200/6235], Loss: 6.3507\n",
      "Epoch [9/100], Step [29300/6235], Loss: 0.3155\n",
      "Epoch [9/100], Step [29400/6235], Loss: 0.4094\n",
      "Epoch [9/100], Step [29500/6235], Loss: 3.2014\n",
      "Epoch [9/100], Step [29600/6235], Loss: 0.5647\n",
      "Epoch [9/100], Step [29700/6235], Loss: 3.0619\n",
      "Epoch [9/100], Step [29800/6235], Loss: 0.2093\n",
      "Epoch [9/100], Step [29900/6235], Loss: 4.5229\n",
      "Epoch [9/100], Step [30000/6235], Loss: 4.1075\n",
      "Epoch [9/100], Step [30100/6235], Loss: 8.1092\n",
      "Epoch [9/100], Step [30200/6235], Loss: 0.8745\n",
      "Epoch [9/100], Step [30300/6235], Loss: 0.2728\n",
      "Epoch [9/100], Step [30400/6235], Loss: 4.9336\n",
      "Epoch [9/100], Step [30500/6235], Loss: 0.1979\n",
      "Epoch [9/100], Step [30600/6235], Loss: 0.4419\n",
      "Epoch [9/100], Step [30700/6235], Loss: 3.0813\n",
      "Epoch [9/100], Step [30800/6235], Loss: 0.4247\n",
      "Epoch [9/100], Step [30900/6235], Loss: 0.9901\n",
      "Epoch [9/100], Step [31000/6235], Loss: 0.2107\n",
      "Epoch [9/100], Step [31100/6235], Loss: 0.9313\n",
      "Epoch [9/100], Step [31200/6235], Loss: 4.5609\n",
      "Epoch [9/100], Step [31300/6235], Loss: 4.3697\n",
      "Epoch [9/100], Step [31400/6235], Loss: 6.5472\n",
      "Epoch [9/100], Step [31500/6235], Loss: 0.6858\n",
      "Epoch [9/100], Step [31600/6235], Loss: 1.5682\n",
      "Epoch [9/100], Step [31700/6235], Loss: 14.8350\n",
      "Epoch [9/100], Step [31800/6235], Loss: 3.3952\n",
      "Epoch [9/100], Step [31900/6235], Loss: 126.9966\n",
      "Epoch [9/100], Step [32000/6235], Loss: 26.0448\n",
      "Epoch [9/100], Step [32100/6235], Loss: 5.3251\n",
      "Epoch [9/100], Step [32200/6235], Loss: 54.5419\n",
      "Epoch [9/100], Step [32300/6235], Loss: 1.2372\n",
      "Epoch [9/100], Step [32400/6235], Loss: 0.9668\n",
      "Epoch [9/100], Step [32500/6235], Loss: 19.0957\n",
      "Epoch [9/100], Step [32600/6235], Loss: 0.6103\n",
      "Epoch [9/100], Step [32700/6235], Loss: 72.2417\n",
      "Epoch [9/100], Step [32800/6235], Loss: 1.6695\n",
      "Epoch [9/100], Step [32900/6235], Loss: 21.2860\n",
      "Epoch [9/100], Step [33000/6235], Loss: 0.2522\n",
      "Epoch [9/100], Step [33100/6235], Loss: 0.6889\n",
      "Epoch [9/100], Step [33200/6235], Loss: 1.5835\n",
      "Epoch [9/100], Step [33300/6235], Loss: 7.8116\n",
      "Epoch [9/100], Step [33400/6235], Loss: 26.0617\n",
      "Epoch [9/100], Step [33500/6235], Loss: 0.4120\n",
      "Epoch [9/100], Step [33600/6235], Loss: 3.3476\n",
      "Epoch [9/100], Step [33700/6235], Loss: 5.1550\n",
      "Epoch [9/100], Step [33800/6235], Loss: 5.3316\n",
      "Epoch [9/100], Step [33900/6235], Loss: 26.1455\n",
      "Epoch [9/100], Step [34000/6235], Loss: 0.0052\n",
      "Epoch [9/100], Step [34100/6235], Loss: 0.0313\n",
      "Epoch [9/100], Step [34200/6235], Loss: 9.0449\n",
      "Epoch [9/100], Step [34300/6235], Loss: 4.0345\n",
      "Epoch [9/100], Step [34400/6235], Loss: 1.1412\n",
      "Epoch [9/100], Step [34500/6235], Loss: 108.6129\n",
      "Epoch [9/100], Step [34600/6235], Loss: 1.7388\n",
      "Epoch [9/100], Step [34700/6235], Loss: 10.6042\n",
      "Epoch [9/100], Step [34800/6235], Loss: 12.5921\n",
      "Epoch [9/100], Step [34900/6235], Loss: 64.1674\n",
      "Epoch [9/100], Step [35000/6235], Loss: 0.1166\n",
      "Epoch [9/100], Step [35100/6235], Loss: 3.0886\n",
      "Epoch [9/100], Step [35200/6235], Loss: 3.1771\n",
      "Epoch [9/100], Step [35300/6235], Loss: 0.1922\n",
      "Epoch [9/100], Step [35400/6235], Loss: 0.8825\n",
      "Epoch [9/100], Step [35500/6235], Loss: 1.8368\n",
      "Epoch [9/100], Step [35600/6235], Loss: 5.9328\n",
      "Epoch [9/100], Step [35700/6235], Loss: 5.5730\n",
      "Epoch [9/100], Step [35800/6235], Loss: 0.6593\n",
      "Epoch [9/100], Step [35900/6235], Loss: 0.1268\n",
      "Epoch [9/100], Step [36000/6235], Loss: 3.1200\n",
      "Epoch [9/100], Step [36100/6235], Loss: 2.6699\n",
      "Epoch [9/100], Step [36200/6235], Loss: 27.9815\n",
      "Epoch [9/100], Step [36300/6235], Loss: 0.2602\n",
      "Epoch [9/100], Step [36400/6235], Loss: 0.0547\n",
      "Epoch [9/100], Step [36500/6235], Loss: 10.8376\n",
      "Epoch [9/100], Step [36600/6235], Loss: 0.2248\n",
      "Epoch [9/100], Step [36700/6235], Loss: 0.5393\n",
      "Epoch [9/100], Step [36800/6235], Loss: 36.7215\n",
      "Epoch [9/100], Step [36900/6235], Loss: 3.0998\n",
      "Epoch [9/100], Step [37000/6235], Loss: 0.8051\n",
      "Epoch [9/100], Step [37100/6235], Loss: 0.5890\n",
      "Epoch [9/100], Step [37200/6235], Loss: 0.0239\n",
      "Epoch [9/100], Step [37300/6235], Loss: 0.6797\n",
      "Epoch [9/100], Step [37400/6235], Loss: 0.3979\n",
      "Epoch [9/100], Step [37500/6235], Loss: 3.2287\n",
      "Epoch [9/100], Step [37600/6235], Loss: 6.7002\n",
      "Epoch [9/100], Step [37700/6235], Loss: 0.5107\n",
      "Epoch [9/100], Step [37800/6235], Loss: 3.0933\n",
      "Epoch [9/100], Step [37900/6235], Loss: 5.6259\n",
      "Epoch [9/100], Step [38000/6235], Loss: 0.1671\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [9/100], Step [38100/6235], Loss: 6.7771\n",
      "Epoch [9/100], Step [38200/6235], Loss: 1.2688\n",
      "Epoch [9/100], Step [38300/6235], Loss: 2.4214\n",
      "Epoch [9/100], Step [38400/6235], Loss: 0.0787\n",
      "Epoch [9/100], Step [38500/6235], Loss: 2.4451\n",
      "Epoch [9/100], Step [38600/6235], Loss: 4.4874\n",
      "Epoch [9/100], Step [38700/6235], Loss: 0.0465\n",
      "Epoch [9/100], Step [38800/6235], Loss: 1.3214\n",
      "Epoch [9/100], Step [38900/6235], Loss: 58.6648\n",
      "Epoch [9/100], Step [39000/6235], Loss: 13.1051\n",
      "Epoch [9/100], Step [39100/6235], Loss: 7.3400\n",
      "Epoch [9/100], Step [39200/6235], Loss: 6.3392\n",
      "Epoch [9/100], Step [39300/6235], Loss: 144.8092\n",
      "Epoch [9/100], Step [39400/6235], Loss: 28.3078\n",
      "Epoch [9/100], Step [39500/6235], Loss: 224.8890\n",
      "Epoch [9/100], Step [39600/6235], Loss: 13.5035\n",
      "Epoch [9/100], Step [39700/6235], Loss: 283.3502\n",
      "Epoch [9/100], Step [39800/6235], Loss: 10.1309\n",
      "Epoch [9/100], Step [39900/6235], Loss: 0.2722\n",
      "Epoch [9/100], Step [40000/6235], Loss: 23.7136\n",
      "Epoch [9/100], Step [40100/6235], Loss: 28.5676\n",
      "Epoch [9/100], Step [40200/6235], Loss: 1.5861\n",
      "Epoch [9/100], Step [40300/6235], Loss: 0.5475\n",
      "Epoch [9/100], Step [40400/6235], Loss: 2.6864\n",
      "Epoch [9/100], Step [40500/6235], Loss: 2.3070\n",
      "Epoch [9/100], Step [40600/6235], Loss: 0.2182\n",
      "Epoch [9/100], Step [40700/6235], Loss: 7.9042\n",
      "Epoch [9/100], Step [40800/6235], Loss: 2.2395\n",
      "Epoch [9/100], Step [40900/6235], Loss: 0.0736\n",
      "Epoch [9/100], Step [41000/6235], Loss: 16.7950\n",
      "Epoch [9/100], Step [41100/6235], Loss: 37.8444\n",
      "Epoch [9/100], Step [41200/6235], Loss: 45.4561\n",
      "Epoch [9/100], Step [41300/6235], Loss: 3.8671\n",
      "Epoch [9/100], Step [41400/6235], Loss: 0.0065\n",
      "Epoch [9/100], Step [41500/6235], Loss: 1.3232\n",
      "Epoch [9/100], Step [41600/6235], Loss: 0.0311\n",
      "Epoch [9/100], Step [41700/6235], Loss: 0.4629\n",
      "Epoch [9/100], Step [41800/6235], Loss: 1.3160\n",
      "Epoch [9/100], Step [41900/6235], Loss: 3.2909\n",
      "Epoch [9/100], Step [42000/6235], Loss: 1.9207\n",
      "Epoch [9/100], Step [42100/6235], Loss: 5.0225\n",
      "Epoch [9/100], Step [42200/6235], Loss: 57.9818\n",
      "Epoch [9/100], Step [42300/6235], Loss: 2.9135\n",
      "Epoch [9/100], Step [42400/6235], Loss: 5.1498\n",
      "Epoch [9/100], Step [42500/6235], Loss: 2.8547\n",
      "Epoch [9/100], Step [42600/6235], Loss: 0.4832\n",
      "Epoch [9/100], Step [42700/6235], Loss: 0.2421\n",
      "Epoch [9/100], Step [42800/6235], Loss: 0.5562\n",
      "Epoch [9/100], Step [42900/6235], Loss: 4.1178\n",
      "Epoch [9/100], Step [43000/6235], Loss: 0.4783\n",
      "Epoch [9/100], Step [43100/6235], Loss: 2.1951\n",
      "Epoch [9/100], Step [43200/6235], Loss: 0.3637\n",
      "Epoch [9/100], Step [43300/6235], Loss: 10.7220\n",
      "Epoch [9/100], Step [43400/6235], Loss: 9.1647\n",
      "Epoch [9/100], Step [43500/6235], Loss: 9.0114\n",
      "Epoch [9/100], Step [43600/6235], Loss: 29.7120\n",
      "Epoch [9/100], Step [43700/6235], Loss: 45.8972\n",
      "Epoch [9/100], Step [43800/6235], Loss: 0.6959\n",
      "Epoch [9/100], Step [43900/6235], Loss: 0.4919\n",
      "Epoch [9/100], Step [44000/6235], Loss: 54.1448\n",
      "Epoch [9/100], Step [44100/6235], Loss: 1.4415\n",
      "Epoch [9/100], Step [44200/6235], Loss: 2.4862\n",
      "Epoch [9/100], Step [44300/6235], Loss: 3.3731\n",
      "Epoch [9/100], Step [44400/6235], Loss: 3.8400\n",
      "Epoch [9/100], Step [44500/6235], Loss: 2.4790\n",
      "Epoch [9/100], Step [44600/6235], Loss: 36.8091\n",
      "Epoch [9/100], Step [44700/6235], Loss: 2.7584\n",
      "Epoch [9/100], Step [44800/6235], Loss: 3.4880\n",
      "Epoch [9/100], Step [44900/6235], Loss: 3.3609\n",
      "Epoch [9/100], Step [45000/6235], Loss: 5.0349\n",
      "Epoch [9/100], Step [45100/6235], Loss: 20.1501\n",
      "Epoch [9/100], Step [45200/6235], Loss: 0.5813\n",
      "Epoch [9/100], Step [45300/6235], Loss: 31.0641\n",
      "Epoch [9/100], Step [45400/6235], Loss: 12.8686\n",
      "Epoch [9/100], Step [45500/6235], Loss: 0.3520\n",
      "Epoch [9/100], Step [45600/6235], Loss: 0.1489\n",
      "Epoch [9/100], Step [45700/6235], Loss: 112.5407\n",
      "Epoch [9/100], Step [45800/6235], Loss: 421.9476\n",
      "Epoch [9/100], Step [45900/6235], Loss: 53.8503\n",
      "Epoch [9/100], Step [46000/6235], Loss: 20.8459\n",
      "Epoch [9/100], Step [46100/6235], Loss: 58.9787\n",
      "Epoch [9/100], Step [46200/6235], Loss: 89.9435\n",
      "Epoch [9/100], Step [46300/6235], Loss: 44.8794\n",
      "Epoch [9/100], Step [46400/6235], Loss: 7.4416\n",
      "Epoch [9/100], Step [46500/6235], Loss: 61.1511\n",
      "Epoch [9/100], Step [46600/6235], Loss: 22.8477\n",
      "Epoch [9/100], Step [46700/6235], Loss: 4.2155\n",
      "Epoch [9/100], Step [46800/6235], Loss: 0.9365\n",
      "Epoch [9/100], Step [46900/6235], Loss: 6.7575\n",
      "Epoch [9/100], Step [47000/6235], Loss: 4.1208\n",
      "Epoch [9/100], Step [47100/6235], Loss: 1.0931\n",
      "Epoch [9/100], Step [47200/6235], Loss: 4.4762\n",
      "Epoch [9/100], Step [47300/6235], Loss: 0.2427\n",
      "Epoch [9/100], Step [47400/6235], Loss: 35.8332\n",
      "Epoch [9/100], Step [47500/6235], Loss: 0.4675\n",
      "Epoch [9/100], Step [47600/6235], Loss: 1.6519\n",
      "Epoch [9/100], Step [47700/6235], Loss: 5.3643\n",
      "Epoch [9/100], Step [47800/6235], Loss: 0.9389\n",
      "Epoch [9/100], Step [47900/6235], Loss: 31.8940\n",
      "Epoch [9/100], Step [48000/6235], Loss: 91.1444\n",
      "Epoch [9/100], Step [48100/6235], Loss: 2.4418\n",
      "Epoch [9/100], Step [48200/6235], Loss: 13.1669\n",
      "Epoch [9/100], Step [48300/6235], Loss: 247.6583\n",
      "Epoch [9/100], Step [48400/6235], Loss: 43.7883\n",
      "Epoch [9/100], Step [48500/6235], Loss: 5.3146\n",
      "Epoch [9/100], Step [48600/6235], Loss: 105.2571\n",
      "Epoch [9/100], Step [48700/6235], Loss: 103.2125\n",
      "Epoch [9/100], Step [48800/6235], Loss: 112.4092\n",
      "Epoch [9/100], Step [48900/6235], Loss: 72.6041\n",
      "Epoch [9/100], Step [49000/6235], Loss: 285.6943\n",
      "Epoch [9/100], Step [49100/6235], Loss: 1507.7690\n",
      "Epoch [9/100], Step [49200/6235], Loss: 607.9459\n",
      "Epoch [9/100], Step [49300/6235], Loss: 1225.3816\n",
      "Epoch [9/100], Step [49400/6235], Loss: 1.8891\n",
      "Epoch [9/100], Step [49500/6235], Loss: 23.5748\n",
      "Epoch [9/100], Step [49600/6235], Loss: 174.6430\n",
      "Epoch [9/100], Step [49700/6235], Loss: 12997.3965\n",
      "Epoch [9/100], Step [49800/6235], Loss: 1459.6595\n",
      "Epoch [10/100], Step [100/6235], Loss: 34.7804\n",
      "Epoch [10/100], Step [200/6235], Loss: 0.1458\n",
      "Epoch [10/100], Step [300/6235], Loss: 0.0694\n",
      "Epoch [10/100], Step [400/6235], Loss: 0.0260\n",
      "Epoch [10/100], Step [500/6235], Loss: 42.1514\n",
      "Epoch [10/100], Step [600/6235], Loss: 0.1195\n",
      "Epoch [10/100], Step [700/6235], Loss: 0.4889\n",
      "Epoch [10/100], Step [800/6235], Loss: 0.2366\n",
      "Epoch [10/100], Step [900/6235], Loss: 0.3739\n",
      "Epoch [10/100], Step [1000/6235], Loss: 0.0981\n",
      "Epoch [10/100], Step [1100/6235], Loss: 2.2019\n",
      "Epoch [10/100], Step [1200/6235], Loss: 0.1828\n",
      "Epoch [10/100], Step [1300/6235], Loss: 0.1364\n",
      "Epoch [10/100], Step [1400/6235], Loss: 2.1618\n",
      "Epoch [10/100], Step [1500/6235], Loss: 0.0080\n",
      "Epoch [10/100], Step [1600/6235], Loss: 0.2205\n",
      "Epoch [10/100], Step [1700/6235], Loss: 0.1069\n",
      "Epoch [10/100], Step [1800/6235], Loss: 0.2462\n",
      "Epoch [10/100], Step [1900/6235], Loss: 0.5315\n",
      "Epoch [10/100], Step [2000/6235], Loss: 2.2452\n",
      "Epoch [10/100], Step [2100/6235], Loss: 1.6377\n",
      "Epoch [10/100], Step [2200/6235], Loss: 9.5038\n",
      "Epoch [10/100], Step [2300/6235], Loss: 13.0910\n",
      "Epoch [10/100], Step [2400/6235], Loss: 5.0811\n",
      "Epoch [10/100], Step [2500/6235], Loss: 42.9333\n",
      "Epoch [10/100], Step [2600/6235], Loss: 9.8715\n",
      "Epoch [10/100], Step [2700/6235], Loss: 20.2134\n",
      "Epoch [10/100], Step [2800/6235], Loss: 121.3114\n",
      "Epoch [10/100], Step [2900/6235], Loss: 6.0990\n",
      "Epoch [10/100], Step [3000/6235], Loss: 0.3295\n",
      "Epoch [10/100], Step [3100/6235], Loss: 63.2733\n",
      "Epoch [10/100], Step [3200/6235], Loss: 78.8404\n",
      "Epoch [10/100], Step [3300/6235], Loss: 0.5409\n",
      "Epoch [10/100], Step [3400/6235], Loss: 2.7888\n",
      "Epoch [10/100], Step [3500/6235], Loss: 28.2691\n",
      "Epoch [10/100], Step [3600/6235], Loss: 9.7102\n",
      "Epoch [10/100], Step [3700/6235], Loss: 1.2550\n",
      "Epoch [10/100], Step [3800/6235], Loss: 0.5506\n",
      "Epoch [10/100], Step [3900/6235], Loss: 1.3238\n",
      "Epoch [10/100], Step [4000/6235], Loss: 0.1345\n",
      "Epoch [10/100], Step [4100/6235], Loss: 3.8688\n",
      "Epoch [10/100], Step [4200/6235], Loss: 0.2008\n",
      "Epoch [10/100], Step [4300/6235], Loss: 9.6961\n",
      "Epoch [10/100], Step [4400/6235], Loss: 3.0224\n",
      "Epoch [10/100], Step [4500/6235], Loss: 60.4857\n",
      "Epoch [10/100], Step [4600/6235], Loss: 12.0893\n",
      "Epoch [10/100], Step [4700/6235], Loss: 1.9357\n",
      "Epoch [10/100], Step [4800/6235], Loss: 0.0616\n",
      "Epoch [10/100], Step [4900/6235], Loss: 0.0630\n",
      "Epoch [10/100], Step [5000/6235], Loss: 0.5197\n",
      "Epoch [10/100], Step [5100/6235], Loss: 1.2718\n",
      "Epoch [10/100], Step [5200/6235], Loss: 1.2588\n",
      "Epoch [10/100], Step [5300/6235], Loss: 30.9887\n",
      "Epoch [10/100], Step [5400/6235], Loss: 1.1373\n",
      "Epoch [10/100], Step [5500/6235], Loss: 0.0330\n",
      "Epoch [10/100], Step [5600/6235], Loss: 0.2561\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Step [5700/6235], Loss: 1.7181\n",
      "Epoch [10/100], Step [5800/6235], Loss: 1.0726\n",
      "Epoch [10/100], Step [5900/6235], Loss: 0.1479\n",
      "Epoch [10/100], Step [6000/6235], Loss: 0.0567\n",
      "Epoch [10/100], Step [6100/6235], Loss: 0.0956\n",
      "Epoch [10/100], Step [6200/6235], Loss: 0.4160\n",
      "Epoch [10/100], Step [6300/6235], Loss: 0.2744\n",
      "Epoch [10/100], Step [6400/6235], Loss: 0.1350\n",
      "Epoch [10/100], Step [6500/6235], Loss: 1.2384\n",
      "Epoch [10/100], Step [6600/6235], Loss: 0.2262\n",
      "Epoch [10/100], Step [6700/6235], Loss: 0.4532\n",
      "Epoch [10/100], Step [6800/6235], Loss: 0.2256\n",
      "Epoch [10/100], Step [6900/6235], Loss: 2.4134\n",
      "Epoch [10/100], Step [7000/6235], Loss: 0.0455\n",
      "Epoch [10/100], Step [7100/6235], Loss: 0.2463\n",
      "Epoch [10/100], Step [7200/6235], Loss: 1.5526\n",
      "Epoch [10/100], Step [7300/6235], Loss: 1.1306\n",
      "Epoch [10/100], Step [7400/6235], Loss: 0.0134\n",
      "Epoch [10/100], Step [7500/6235], Loss: 9.0524\n",
      "Epoch [10/100], Step [7600/6235], Loss: 1.1505\n",
      "Epoch [10/100], Step [7700/6235], Loss: 0.7322\n",
      "Epoch [10/100], Step [7800/6235], Loss: 6.9529\n",
      "Epoch [10/100], Step [7900/6235], Loss: 8.2418\n",
      "Epoch [10/100], Step [8000/6235], Loss: 0.1511\n",
      "Epoch [10/100], Step [8100/6235], Loss: 4.1936\n",
      "Epoch [10/100], Step [8200/6235], Loss: 20.9840\n",
      "Epoch [10/100], Step [8300/6235], Loss: 55.0534\n",
      "Epoch [10/100], Step [8400/6235], Loss: 25.4898\n",
      "Epoch [10/100], Step [8500/6235], Loss: 31.5989\n",
      "Epoch [10/100], Step [8600/6235], Loss: 7.0855\n",
      "Epoch [10/100], Step [8700/6235], Loss: 6.3411\n",
      "Epoch [10/100], Step [8800/6235], Loss: 559.2987\n",
      "Epoch [10/100], Step [8900/6235], Loss: 1.4924\n",
      "Epoch [10/100], Step [9000/6235], Loss: 280.3741\n",
      "Epoch [10/100], Step [9100/6235], Loss: 3.4331\n",
      "Epoch [10/100], Step [9200/6235], Loss: 2061.9695\n",
      "Epoch [10/100], Step [9300/6235], Loss: 125.2590\n",
      "Epoch [10/100], Step [9400/6235], Loss: 1462.6281\n",
      "Epoch [10/100], Step [9500/6235], Loss: 436.7756\n",
      "Epoch [10/100], Step [9600/6235], Loss: 506.5789\n",
      "Epoch [10/100], Step [9700/6235], Loss: 53.7344\n",
      "Epoch [10/100], Step [9800/6235], Loss: 171.2798\n",
      "Epoch [10/100], Step [9900/6235], Loss: 10.6066\n",
      "Epoch [10/100], Step [10000/6235], Loss: 64.4367\n",
      "Epoch [10/100], Step [10100/6235], Loss: 70.4446\n",
      "Epoch [10/100], Step [10200/6235], Loss: 950.8430\n",
      "Epoch [10/100], Step [10300/6235], Loss: 16.1794\n",
      "Epoch [10/100], Step [10400/6235], Loss: 15.6659\n",
      "Epoch [10/100], Step [10500/6235], Loss: 3.1694\n",
      "Epoch [10/100], Step [10600/6235], Loss: 1178.0070\n",
      "Epoch [10/100], Step [10700/6235], Loss: 293.0033\n",
      "Epoch [10/100], Step [10800/6235], Loss: 2.7356\n",
      "Epoch [10/100], Step [10900/6235], Loss: 4.7955\n",
      "Epoch [10/100], Step [11000/6235], Loss: 20.0612\n",
      "Epoch [10/100], Step [11100/6235], Loss: 1.1293\n",
      "Epoch [10/100], Step [11200/6235], Loss: 121.7806\n",
      "Epoch [10/100], Step [11300/6235], Loss: 203.7314\n",
      "Epoch [10/100], Step [11400/6235], Loss: 336.3571\n",
      "Epoch [10/100], Step [11500/6235], Loss: 6.5725\n",
      "Epoch [10/100], Step [11600/6235], Loss: 1.6691\n",
      "Epoch [10/100], Step [11700/6235], Loss: 153.4970\n",
      "Epoch [10/100], Step [11800/6235], Loss: 79.5264\n",
      "Epoch [10/100], Step [11900/6235], Loss: 419.0620\n",
      "Epoch [10/100], Step [12000/6235], Loss: 20.5942\n",
      "Epoch [10/100], Step [12100/6235], Loss: 572.7830\n",
      "Epoch [10/100], Step [12200/6235], Loss: 91.3886\n",
      "Epoch [10/100], Step [12300/6235], Loss: 32.2859\n",
      "Epoch [10/100], Step [12400/6235], Loss: 166.8848\n",
      "Epoch [10/100], Step [12500/6235], Loss: 216.9231\n",
      "Epoch [10/100], Step [12600/6235], Loss: 48.5380\n",
      "Epoch [10/100], Step [12700/6235], Loss: 32.9540\n",
      "Epoch [10/100], Step [12800/6235], Loss: 7.1064\n",
      "Epoch [10/100], Step [12900/6235], Loss: 43.6036\n",
      "Epoch [10/100], Step [13000/6235], Loss: 2.1835\n",
      "Epoch [10/100], Step [13100/6235], Loss: 110.0279\n",
      "Epoch [10/100], Step [13200/6235], Loss: 46.0724\n",
      "Epoch [10/100], Step [13300/6235], Loss: 1.7431\n",
      "Epoch [10/100], Step [13400/6235], Loss: 0.4579\n",
      "Epoch [10/100], Step [13500/6235], Loss: 1.2272\n",
      "Epoch [10/100], Step [13600/6235], Loss: 12.4889\n",
      "Epoch [10/100], Step [13700/6235], Loss: 169.8073\n",
      "Epoch [10/100], Step [13800/6235], Loss: 92.7990\n",
      "Epoch [10/100], Step [13900/6235], Loss: 16.9014\n",
      "Epoch [10/100], Step [14000/6235], Loss: 0.2210\n",
      "Epoch [10/100], Step [14100/6235], Loss: 287.2242\n",
      "Epoch [10/100], Step [14200/6235], Loss: 3.9777\n",
      "Epoch [10/100], Step [14300/6235], Loss: 25.0846\n",
      "Epoch [10/100], Step [14400/6235], Loss: 1.3347\n",
      "Epoch [10/100], Step [14500/6235], Loss: 5.1549\n",
      "Epoch [10/100], Step [14600/6235], Loss: 1.7061\n",
      "Epoch [10/100], Step [14700/6235], Loss: 10.8832\n",
      "Epoch [10/100], Step [14800/6235], Loss: 11.6712\n",
      "Epoch [10/100], Step [14900/6235], Loss: 0.1340\n",
      "Epoch [10/100], Step [15000/6235], Loss: 0.1026\n",
      "Epoch [10/100], Step [15100/6235], Loss: 0.1436\n",
      "Epoch [10/100], Step [15200/6235], Loss: 35.9449\n",
      "Epoch [10/100], Step [15300/6235], Loss: 25.8326\n",
      "Epoch [10/100], Step [15400/6235], Loss: 0.9721\n",
      "Epoch [10/100], Step [15500/6235], Loss: 40.9578\n",
      "Epoch [10/100], Step [15600/6235], Loss: 136.9506\n",
      "Epoch [10/100], Step [15700/6235], Loss: 55.8973\n",
      "Epoch [10/100], Step [15800/6235], Loss: 2.6244\n",
      "Epoch [10/100], Step [15900/6235], Loss: 3.5248\n",
      "Epoch [10/100], Step [16000/6235], Loss: 3.5407\n",
      "Epoch [10/100], Step [16100/6235], Loss: 4.1755\n",
      "Epoch [10/100], Step [16200/6235], Loss: 1.2962\n",
      "Epoch [10/100], Step [16300/6235], Loss: 45.1438\n",
      "Epoch [10/100], Step [16400/6235], Loss: 75.8915\n",
      "Epoch [10/100], Step [16500/6235], Loss: 612.0735\n",
      "Epoch [10/100], Step [16600/6235], Loss: 13.8195\n",
      "Epoch [10/100], Step [16700/6235], Loss: 4.4889\n",
      "Epoch [10/100], Step [16800/6235], Loss: 1.4686\n",
      "Epoch [10/100], Step [16900/6235], Loss: 9.1868\n",
      "Epoch [10/100], Step [17000/6235], Loss: 3.0993\n",
      "Epoch [10/100], Step [17100/6235], Loss: 0.4991\n",
      "Epoch [10/100], Step [17200/6235], Loss: 37.6688\n",
      "Epoch [10/100], Step [17300/6235], Loss: 18.9371\n",
      "Epoch [10/100], Step [17400/6235], Loss: 43.6372\n",
      "Epoch [10/100], Step [17500/6235], Loss: 4.2637\n",
      "Epoch [10/100], Step [17600/6235], Loss: 0.5124\n",
      "Epoch [10/100], Step [17700/6235], Loss: 41.6522\n",
      "Epoch [10/100], Step [17800/6235], Loss: 4.6602\n",
      "Epoch [10/100], Step [17900/6235], Loss: 23.7153\n",
      "Epoch [10/100], Step [18000/6235], Loss: 2.4052\n",
      "Epoch [10/100], Step [18100/6235], Loss: 13.7734\n",
      "Epoch [10/100], Step [18200/6235], Loss: 20.1881\n",
      "Epoch [10/100], Step [18300/6235], Loss: 3.7386\n",
      "Epoch [10/100], Step [18400/6235], Loss: 19.9039\n",
      "Epoch [10/100], Step [18500/6235], Loss: 18.8578\n",
      "Epoch [10/100], Step [18600/6235], Loss: 5.4739\n",
      "Epoch [10/100], Step [18700/6235], Loss: 0.2458\n",
      "Epoch [10/100], Step [18800/6235], Loss: 100.5796\n",
      "Epoch [10/100], Step [18900/6235], Loss: 0.7642\n",
      "Epoch [10/100], Step [19000/6235], Loss: 17.1581\n",
      "Epoch [10/100], Step [19100/6235], Loss: 23.6081\n",
      "Epoch [10/100], Step [19200/6235], Loss: 2.3330\n",
      "Epoch [10/100], Step [19300/6235], Loss: 16.6619\n",
      "Epoch [10/100], Step [19400/6235], Loss: 110.0858\n",
      "Epoch [10/100], Step [19500/6235], Loss: 129.7176\n",
      "Epoch [10/100], Step [19600/6235], Loss: 146.6228\n",
      "Epoch [10/100], Step [19700/6235], Loss: 19.6515\n",
      "Epoch [10/100], Step [19800/6235], Loss: 9.4910\n",
      "Epoch [10/100], Step [19900/6235], Loss: 0.1683\n",
      "Epoch [10/100], Step [20000/6235], Loss: 103.3369\n",
      "Epoch [10/100], Step [20100/6235], Loss: 12.9914\n",
      "Epoch [10/100], Step [20200/6235], Loss: 0.8367\n",
      "Epoch [10/100], Step [20300/6235], Loss: 1.6743\n",
      "Epoch [10/100], Step [20400/6235], Loss: 33.0353\n",
      "Epoch [10/100], Step [20500/6235], Loss: 20.9256\n",
      "Epoch [10/100], Step [20600/6235], Loss: 255.8462\n",
      "Epoch [10/100], Step [20700/6235], Loss: 23.6267\n",
      "Epoch [10/100], Step [20800/6235], Loss: 9.8481\n",
      "Epoch [10/100], Step [20900/6235], Loss: 19.0608\n",
      "Epoch [10/100], Step [21000/6235], Loss: 21.2268\n",
      "Epoch [10/100], Step [21100/6235], Loss: 25.9808\n",
      "Epoch [10/100], Step [21200/6235], Loss: 0.8005\n",
      "Epoch [10/100], Step [21300/6235], Loss: 2.6512\n",
      "Epoch [10/100], Step [21400/6235], Loss: 2.5934\n",
      "Epoch [10/100], Step [21500/6235], Loss: 5.3470\n",
      "Epoch [10/100], Step [21600/6235], Loss: 32.3227\n",
      "Epoch [10/100], Step [21700/6235], Loss: 4.8013\n",
      "Epoch [10/100], Step [21800/6235], Loss: 16.7920\n",
      "Epoch [10/100], Step [21900/6235], Loss: 0.0557\n",
      "Epoch [10/100], Step [22000/6235], Loss: 0.1794\n",
      "Epoch [10/100], Step [22100/6235], Loss: 5.8021\n",
      "Epoch [10/100], Step [22200/6235], Loss: 1.0332\n",
      "Epoch [10/100], Step [22300/6235], Loss: 9.0635\n",
      "Epoch [10/100], Step [22400/6235], Loss: 10.9065\n",
      "Epoch [10/100], Step [22500/6235], Loss: 45.7802\n",
      "Epoch [10/100], Step [22600/6235], Loss: 4.8652\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Step [22700/6235], Loss: 0.0279\n",
      "Epoch [10/100], Step [22800/6235], Loss: 3.9990\n",
      "Epoch [10/100], Step [22900/6235], Loss: 20.2346\n",
      "Epoch [10/100], Step [23000/6235], Loss: 10.3345\n",
      "Epoch [10/100], Step [23100/6235], Loss: 1.4128\n",
      "Epoch [10/100], Step [23200/6235], Loss: 5.0574\n",
      "Epoch [10/100], Step [23300/6235], Loss: 19.3728\n",
      "Epoch [10/100], Step [23400/6235], Loss: 2.1930\n",
      "Epoch [10/100], Step [23500/6235], Loss: 0.0470\n",
      "Epoch [10/100], Step [23600/6235], Loss: 96.7445\n",
      "Epoch [10/100], Step [23700/6235], Loss: 2.8358\n",
      "Epoch [10/100], Step [23800/6235], Loss: 0.9068\n",
      "Epoch [10/100], Step [23900/6235], Loss: 5.4787\n",
      "Epoch [10/100], Step [24000/6235], Loss: 0.2027\n",
      "Epoch [10/100], Step [24100/6235], Loss: 3.0597\n",
      "Epoch [10/100], Step [24200/6235], Loss: 37.5687\n",
      "Epoch [10/100], Step [24300/6235], Loss: 2.5120\n",
      "Epoch [10/100], Step [24400/6235], Loss: 10.1952\n",
      "Epoch [10/100], Step [24500/6235], Loss: 3.6660\n",
      "Epoch [10/100], Step [24600/6235], Loss: 0.2671\n",
      "Epoch [10/100], Step [24700/6235], Loss: 2.2010\n",
      "Epoch [10/100], Step [24800/6235], Loss: 0.3782\n",
      "Epoch [10/100], Step [24900/6235], Loss: 0.1092\n",
      "Epoch [10/100], Step [25000/6235], Loss: 2.9046\n",
      "Epoch [10/100], Step [25100/6235], Loss: 9.2545\n",
      "Epoch [10/100], Step [25200/6235], Loss: 1.2545\n",
      "Epoch [10/100], Step [25300/6235], Loss: 1.9356\n",
      "Epoch [10/100], Step [25400/6235], Loss: 9.4068\n",
      "Epoch [10/100], Step [25500/6235], Loss: 7.0802\n",
      "Epoch [10/100], Step [25600/6235], Loss: 1.8031\n",
      "Epoch [10/100], Step [25700/6235], Loss: 0.3371\n",
      "Epoch [10/100], Step [25800/6235], Loss: 0.1359\n",
      "Epoch [10/100], Step [25900/6235], Loss: 7.9295\n",
      "Epoch [10/100], Step [26000/6235], Loss: 6.8700\n",
      "Epoch [10/100], Step [26100/6235], Loss: 0.0424\n",
      "Epoch [10/100], Step [26200/6235], Loss: 0.1986\n",
      "Epoch [10/100], Step [26300/6235], Loss: 5.0304\n",
      "Epoch [10/100], Step [26400/6235], Loss: 0.1391\n",
      "Epoch [10/100], Step [26500/6235], Loss: 0.3819\n",
      "Epoch [10/100], Step [26600/6235], Loss: 3.5633\n",
      "Epoch [10/100], Step [26700/6235], Loss: 0.7795\n",
      "Epoch [10/100], Step [26800/6235], Loss: 1.6537\n",
      "Epoch [10/100], Step [26900/6235], Loss: 0.1166\n",
      "Epoch [10/100], Step [27000/6235], Loss: 12.4130\n",
      "Epoch [10/100], Step [27100/6235], Loss: 0.1058\n",
      "Epoch [10/100], Step [27200/6235], Loss: 0.0432\n",
      "Epoch [10/100], Step [27300/6235], Loss: 0.2049\n",
      "Epoch [10/100], Step [27400/6235], Loss: 1.0016\n",
      "Epoch [10/100], Step [27500/6235], Loss: 12.0222\n",
      "Epoch [10/100], Step [27600/6235], Loss: 0.6929\n",
      "Epoch [10/100], Step [27700/6235], Loss: 1.0516\n",
      "Epoch [10/100], Step [27800/6235], Loss: 5.1476\n",
      "Epoch [10/100], Step [27900/6235], Loss: 1.7243\n",
      "Epoch [10/100], Step [28000/6235], Loss: 106.1165\n",
      "Epoch [10/100], Step [28100/6235], Loss: 5.0012\n",
      "Epoch [10/100], Step [28200/6235], Loss: 26.0809\n",
      "Epoch [10/100], Step [28300/6235], Loss: 6.2686\n",
      "Epoch [10/100], Step [28400/6235], Loss: 13.7632\n",
      "Epoch [10/100], Step [28500/6235], Loss: 0.7211\n",
      "Epoch [10/100], Step [28600/6235], Loss: 1.3670\n",
      "Epoch [10/100], Step [28700/6235], Loss: 3.4354\n",
      "Epoch [10/100], Step [28800/6235], Loss: 0.1598\n",
      "Epoch [10/100], Step [28900/6235], Loss: 66.4644\n",
      "Epoch [10/100], Step [29000/6235], Loss: 0.7932\n",
      "Epoch [10/100], Step [29100/6235], Loss: 2.0397\n",
      "Epoch [10/100], Step [29200/6235], Loss: 0.0538\n",
      "Epoch [10/100], Step [29300/6235], Loss: 7.8822\n",
      "Epoch [10/100], Step [29400/6235], Loss: 1.1904\n",
      "Epoch [10/100], Step [29500/6235], Loss: 0.5954\n",
      "Epoch [10/100], Step [29600/6235], Loss: 0.3315\n",
      "Epoch [10/100], Step [29700/6235], Loss: 0.1018\n",
      "Epoch [10/100], Step [29800/6235], Loss: 1.7376\n",
      "Epoch [10/100], Step [29900/6235], Loss: 0.0576\n",
      "Epoch [10/100], Step [30000/6235], Loss: 0.2015\n",
      "Epoch [10/100], Step [30100/6235], Loss: 0.1315\n",
      "Epoch [10/100], Step [30200/6235], Loss: 0.4564\n",
      "Epoch [10/100], Step [30300/6235], Loss: 1.5366\n",
      "Epoch [10/100], Step [30400/6235], Loss: 0.5471\n",
      "Epoch [10/100], Step [30500/6235], Loss: 0.0731\n",
      "Epoch [10/100], Step [30600/6235], Loss: 0.1639\n",
      "Epoch [10/100], Step [30700/6235], Loss: 0.1361\n",
      "Epoch [10/100], Step [30800/6235], Loss: 0.2514\n",
      "Epoch [10/100], Step [30900/6235], Loss: 1.7006\n",
      "Epoch [10/100], Step [31000/6235], Loss: 0.0770\n",
      "Epoch [10/100], Step [31100/6235], Loss: 0.0636\n",
      "Epoch [10/100], Step [31200/6235], Loss: 16.0362\n",
      "Epoch [10/100], Step [31300/6235], Loss: 1.3007\n",
      "Epoch [10/100], Step [31400/6235], Loss: 3.5790\n",
      "Epoch [10/100], Step [31500/6235], Loss: 1.6559\n",
      "Epoch [10/100], Step [31600/6235], Loss: 0.1358\n",
      "Epoch [10/100], Step [31700/6235], Loss: 33.3465\n",
      "Epoch [10/100], Step [31800/6235], Loss: 0.4561\n",
      "Epoch [10/100], Step [31900/6235], Loss: 139.9151\n",
      "Epoch [10/100], Step [32000/6235], Loss: 14.1982\n",
      "Epoch [10/100], Step [32100/6235], Loss: 7.3445\n",
      "Epoch [10/100], Step [32200/6235], Loss: 58.2022\n",
      "Epoch [10/100], Step [32300/6235], Loss: 0.7146\n",
      "Epoch [10/100], Step [32400/6235], Loss: 0.1416\n",
      "Epoch [10/100], Step [32500/6235], Loss: 20.3918\n",
      "Epoch [10/100], Step [32600/6235], Loss: 1.0578\n",
      "Epoch [10/100], Step [32700/6235], Loss: 48.6464\n",
      "Epoch [10/100], Step [32800/6235], Loss: 0.4421\n",
      "Epoch [10/100], Step [32900/6235], Loss: 11.0187\n",
      "Epoch [10/100], Step [33000/6235], Loss: 1.5883\n",
      "Epoch [10/100], Step [33100/6235], Loss: 0.1493\n",
      "Epoch [10/100], Step [33200/6235], Loss: 4.5167\n",
      "Epoch [10/100], Step [33300/6235], Loss: 2.1676\n",
      "Epoch [10/100], Step [33400/6235], Loss: 122.5463\n",
      "Epoch [10/100], Step [33500/6235], Loss: 1.0402\n",
      "Epoch [10/100], Step [33600/6235], Loss: 0.4108\n",
      "Epoch [10/100], Step [33700/6235], Loss: 0.7937\n",
      "Epoch [10/100], Step [33800/6235], Loss: 16.1835\n",
      "Epoch [10/100], Step [33900/6235], Loss: 27.5408\n",
      "Epoch [10/100], Step [34000/6235], Loss: 0.0228\n",
      "Epoch [10/100], Step [34100/6235], Loss: 0.3361\n",
      "Epoch [10/100], Step [34200/6235], Loss: 27.6744\n",
      "Epoch [10/100], Step [34300/6235], Loss: 0.3516\n",
      "Epoch [10/100], Step [34400/6235], Loss: 1.6955\n",
      "Epoch [10/100], Step [34500/6235], Loss: 95.5193\n",
      "Epoch [10/100], Step [34600/6235], Loss: 1.3768\n",
      "Epoch [10/100], Step [34700/6235], Loss: 18.0160\n",
      "Epoch [10/100], Step [34800/6235], Loss: 8.7616\n",
      "Epoch [10/100], Step [34900/6235], Loss: 21.3996\n",
      "Epoch [10/100], Step [35000/6235], Loss: 0.0363\n",
      "Epoch [10/100], Step [35100/6235], Loss: 6.0040\n",
      "Epoch [10/100], Step [35200/6235], Loss: 6.0768\n",
      "Epoch [10/100], Step [35300/6235], Loss: 4.3114\n",
      "Epoch [10/100], Step [35400/6235], Loss: 0.7036\n",
      "Epoch [10/100], Step [35500/6235], Loss: 0.1041\n",
      "Epoch [10/100], Step [35600/6235], Loss: 13.5365\n",
      "Epoch [10/100], Step [35700/6235], Loss: 17.1820\n",
      "Epoch [10/100], Step [35800/6235], Loss: 14.8791\n",
      "Epoch [10/100], Step [35900/6235], Loss: 6.0105\n",
      "Epoch [10/100], Step [36000/6235], Loss: 0.0202\n",
      "Epoch [10/100], Step [36100/6235], Loss: 11.3166\n",
      "Epoch [10/100], Step [36200/6235], Loss: 13.2549\n",
      "Epoch [10/100], Step [36300/6235], Loss: 0.0941\n",
      "Epoch [10/100], Step [36400/6235], Loss: 0.0411\n",
      "Epoch [10/100], Step [36500/6235], Loss: 8.9804\n",
      "Epoch [10/100], Step [36600/6235], Loss: 0.4390\n",
      "Epoch [10/100], Step [36700/6235], Loss: 1.2908\n",
      "Epoch [10/100], Step [36800/6235], Loss: 20.5394\n",
      "Epoch [10/100], Step [36900/6235], Loss: 8.0140\n",
      "Epoch [10/100], Step [37000/6235], Loss: 1.0311\n",
      "Epoch [10/100], Step [37100/6235], Loss: 1.2386\n",
      "Epoch [10/100], Step [37200/6235], Loss: 0.1429\n",
      "Epoch [10/100], Step [37300/6235], Loss: 0.6683\n",
      "Epoch [10/100], Step [37400/6235], Loss: 1.0414\n",
      "Epoch [10/100], Step [37500/6235], Loss: 0.6275\n",
      "Epoch [10/100], Step [37600/6235], Loss: 6.6260\n",
      "Epoch [10/100], Step [37700/6235], Loss: 0.7864\n",
      "Epoch [10/100], Step [37800/6235], Loss: 0.5551\n",
      "Epoch [10/100], Step [37900/6235], Loss: 0.9343\n",
      "Epoch [10/100], Step [38000/6235], Loss: 0.2505\n",
      "Epoch [10/100], Step [38100/6235], Loss: 8.3961\n",
      "Epoch [10/100], Step [38200/6235], Loss: 5.2728\n",
      "Epoch [10/100], Step [38300/6235], Loss: 0.2268\n",
      "Epoch [10/100], Step [38400/6235], Loss: 0.1196\n",
      "Epoch [10/100], Step [38500/6235], Loss: 0.2678\n",
      "Epoch [10/100], Step [38600/6235], Loss: 2.7120\n",
      "Epoch [10/100], Step [38700/6235], Loss: 0.0663\n",
      "Epoch [10/100], Step [38800/6235], Loss: 0.9270\n",
      "Epoch [10/100], Step [38900/6235], Loss: 85.8394\n",
      "Epoch [10/100], Step [39000/6235], Loss: 3.5903\n",
      "Epoch [10/100], Step [39100/6235], Loss: 32.4437\n",
      "Epoch [10/100], Step [39200/6235], Loss: 0.7838\n",
      "Epoch [10/100], Step [39300/6235], Loss: 11.8327\n",
      "Epoch [10/100], Step [39400/6235], Loss: 168.8831\n",
      "Epoch [10/100], Step [39500/6235], Loss: 115.0619\n",
      "Epoch [10/100], Step [39600/6235], Loss: 11.6850\n",
      "Epoch [10/100], Step [39700/6235], Loss: 222.3920\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/100], Step [39800/6235], Loss: 103.2692\n",
      "Epoch [10/100], Step [39900/6235], Loss: 0.9269\n",
      "Epoch [10/100], Step [40000/6235], Loss: 9.2191\n",
      "Epoch [10/100], Step [40100/6235], Loss: 28.9748\n",
      "Epoch [10/100], Step [40200/6235], Loss: 1.7474\n",
      "Epoch [10/100], Step [40300/6235], Loss: 0.2624\n",
      "Epoch [10/100], Step [40400/6235], Loss: 2.6571\n",
      "Epoch [10/100], Step [40500/6235], Loss: 2.3095\n",
      "Epoch [10/100], Step [40600/6235], Loss: 0.2618\n",
      "Epoch [10/100], Step [40700/6235], Loss: 7.8407\n",
      "Epoch [10/100], Step [40800/6235], Loss: 2.3073\n",
      "Epoch [10/100], Step [40900/6235], Loss: 0.0764\n",
      "Epoch [10/100], Step [41000/6235], Loss: 13.8612\n",
      "Epoch [10/100], Step [41100/6235], Loss: 2.9311\n",
      "Epoch [10/100], Step [41200/6235], Loss: 13.5632\n",
      "Epoch [10/100], Step [41300/6235], Loss: 1.1129\n",
      "Epoch [10/100], Step [41400/6235], Loss: 0.0682\n",
      "Epoch [10/100], Step [41500/6235], Loss: 0.7617\n",
      "Epoch [10/100], Step [41600/6235], Loss: 0.0179\n",
      "Epoch [10/100], Step [41700/6235], Loss: 0.7709\n",
      "Epoch [10/100], Step [41800/6235], Loss: 1.5704\n",
      "Epoch [10/100], Step [41900/6235], Loss: 3.0152\n",
      "Epoch [10/100], Step [42000/6235], Loss: 1.9368\n",
      "Epoch [10/100], Step [42100/6235], Loss: 4.7041\n",
      "Epoch [10/100], Step [42200/6235], Loss: 44.5070\n",
      "Epoch [10/100], Step [42300/6235], Loss: 2.9113\n",
      "Epoch [10/100], Step [42400/6235], Loss: 4.2972\n",
      "Epoch [10/100], Step [42500/6235], Loss: 0.5329\n",
      "Epoch [10/100], Step [42600/6235], Loss: 0.4302\n",
      "Epoch [10/100], Step [42700/6235], Loss: 0.1391\n",
      "Epoch [10/100], Step [42800/6235], Loss: 0.6073\n",
      "Epoch [10/100], Step [42900/6235], Loss: 4.0897\n",
      "Epoch [10/100], Step [43000/6235], Loss: 0.4927\n",
      "Epoch [10/100], Step [43100/6235], Loss: 2.1920\n",
      "Epoch [10/100], Step [43200/6235], Loss: 0.3576\n",
      "Epoch [10/100], Step [43300/6235], Loss: 10.6495\n",
      "Epoch [10/100], Step [43400/6235], Loss: 9.3553\n",
      "Epoch [10/100], Step [43500/6235], Loss: 9.1308\n",
      "Epoch [10/100], Step [43600/6235], Loss: 28.3772\n",
      "Epoch [10/100], Step [43700/6235], Loss: 47.3171\n",
      "Epoch [10/100], Step [43800/6235], Loss: 0.7365\n",
      "Epoch [10/100], Step [43900/6235], Loss: 3.0081\n",
      "Epoch [10/100], Step [44000/6235], Loss: 58.4410\n",
      "Epoch [10/100], Step [44100/6235], Loss: 1.7679\n",
      "Epoch [10/100], Step [44200/6235], Loss: 11.6356\n",
      "Epoch [10/100], Step [44300/6235], Loss: 1.3160\n",
      "Epoch [10/100], Step [44400/6235], Loss: 0.7845\n",
      "Epoch [10/100], Step [44500/6235], Loss: 0.4861\n",
      "Epoch [10/100], Step [44600/6235], Loss: 27.5307\n",
      "Epoch [10/100], Step [44700/6235], Loss: 0.9550\n",
      "Epoch [10/100], Step [44800/6235], Loss: 5.5538\n",
      "Epoch [10/100], Step [44900/6235], Loss: 6.0458\n",
      "Epoch [10/100], Step [45000/6235], Loss: 4.8642\n",
      "Epoch [10/100], Step [45100/6235], Loss: 44.8671\n",
      "Epoch [10/100], Step [45200/6235], Loss: 0.7520\n",
      "Epoch [10/100], Step [45300/6235], Loss: 25.9564\n",
      "Epoch [10/100], Step [45400/6235], Loss: 10.8145\n",
      "Epoch [10/100], Step [45500/6235], Loss: 1.1367\n",
      "Epoch [10/100], Step [45600/6235], Loss: 0.4992\n",
      "Epoch [10/100], Step [45700/6235], Loss: 135.5760\n",
      "Epoch [10/100], Step [45800/6235], Loss: 255.6005\n",
      "Epoch [10/100], Step [45900/6235], Loss: 13.2142\n",
      "Epoch [10/100], Step [46000/6235], Loss: 23.5239\n",
      "Epoch [10/100], Step [46100/6235], Loss: 56.4943\n",
      "Epoch [10/100], Step [46200/6235], Loss: 69.0847\n",
      "Epoch [10/100], Step [46300/6235], Loss: 3.7339\n",
      "Epoch [10/100], Step [46400/6235], Loss: 7.1559\n",
      "Epoch [10/100], Step [46500/6235], Loss: 14.9622\n",
      "Epoch [10/100], Step [46600/6235], Loss: 28.7559\n",
      "Epoch [10/100], Step [46700/6235], Loss: 7.7979\n",
      "Epoch [10/100], Step [46800/6235], Loss: 4.2808\n",
      "Epoch [10/100], Step [46900/6235], Loss: 2.9770\n",
      "Epoch [10/100], Step [47000/6235], Loss: 6.9393\n",
      "Epoch [10/100], Step [47100/6235], Loss: 3.3491\n",
      "Epoch [10/100], Step [47200/6235], Loss: 4.9119\n",
      "Epoch [10/100], Step [47300/6235], Loss: 1.0852\n",
      "Epoch [10/100], Step [47400/6235], Loss: 76.1986\n",
      "Epoch [10/100], Step [47500/6235], Loss: 4.4009\n",
      "Epoch [10/100], Step [47600/6235], Loss: 1.2184\n",
      "Epoch [10/100], Step [47700/6235], Loss: 7.9234\n",
      "Epoch [10/100], Step [47800/6235], Loss: 0.6563\n",
      "Epoch [10/100], Step [47900/6235], Loss: 26.7377\n",
      "Epoch [10/100], Step [48000/6235], Loss: 133.9814\n",
      "Epoch [10/100], Step [48100/6235], Loss: 3.5722\n",
      "Epoch [10/100], Step [48200/6235], Loss: 5.4646\n",
      "Epoch [10/100], Step [48300/6235], Loss: 112.3035\n",
      "Epoch [10/100], Step [48400/6235], Loss: 60.2651\n",
      "Epoch [10/100], Step [48500/6235], Loss: 5.0660\n",
      "Epoch [10/100], Step [48600/6235], Loss: 112.2326\n",
      "Epoch [10/100], Step [48700/6235], Loss: 105.1145\n",
      "Epoch [10/100], Step [48800/6235], Loss: 127.5838\n",
      "Epoch [10/100], Step [48900/6235], Loss: 64.1908\n",
      "Epoch [10/100], Step [49000/6235], Loss: 299.5079\n",
      "Epoch [10/100], Step [49100/6235], Loss: 2199.2866\n",
      "Epoch [10/100], Step [49200/6235], Loss: 540.5602\n",
      "Epoch [10/100], Step [49300/6235], Loss: 1143.7883\n",
      "Epoch [10/100], Step [49400/6235], Loss: 1.8523\n",
      "Epoch [10/100], Step [49500/6235], Loss: 50.2769\n",
      "Epoch [10/100], Step [49600/6235], Loss: 88.4875\n",
      "Epoch [10/100], Step [49700/6235], Loss: 884.0941\n",
      "Epoch [10/100], Step [49800/6235], Loss: 12.4178\n",
      "Epoch [11/100], Step [100/6235], Loss: 50.9936\n",
      "Epoch [11/100], Step [200/6235], Loss: 0.5974\n",
      "Epoch [11/100], Step [300/6235], Loss: 0.2361\n",
      "Epoch [11/100], Step [400/6235], Loss: 0.1593\n",
      "Epoch [11/100], Step [500/6235], Loss: 0.5628\n",
      "Epoch [11/100], Step [600/6235], Loss: 0.1558\n",
      "Epoch [11/100], Step [700/6235], Loss: 0.4398\n",
      "Epoch [11/100], Step [800/6235], Loss: 0.2469\n",
      "Epoch [11/100], Step [900/6235], Loss: 0.0714\n",
      "Epoch [11/100], Step [1000/6235], Loss: 0.0382\n",
      "Epoch [11/100], Step [1100/6235], Loss: 0.1502\n",
      "Epoch [11/100], Step [1200/6235], Loss: 0.1541\n",
      "Epoch [11/100], Step [1300/6235], Loss: 0.0917\n",
      "Epoch [11/100], Step [1400/6235], Loss: 0.3141\n",
      "Epoch [11/100], Step [1500/6235], Loss: 0.0117\n",
      "Epoch [11/100], Step [1600/6235], Loss: 0.2238\n",
      "Epoch [11/100], Step [1700/6235], Loss: 0.1129\n",
      "Epoch [11/100], Step [1800/6235], Loss: 0.2484\n",
      "Epoch [11/100], Step [1900/6235], Loss: 0.8806\n",
      "Epoch [11/100], Step [2000/6235], Loss: 2.8303\n",
      "Epoch [11/100], Step [2100/6235], Loss: 1.7996\n",
      "Epoch [11/100], Step [2200/6235], Loss: 11.1202\n",
      "Epoch [11/100], Step [2300/6235], Loss: 25.7149\n",
      "Epoch [11/100], Step [2400/6235], Loss: 14.7458\n",
      "Epoch [11/100], Step [2500/6235], Loss: 34.5627\n",
      "Epoch [11/100], Step [2600/6235], Loss: 7.5233\n",
      "Epoch [11/100], Step [2700/6235], Loss: 32.5213\n",
      "Epoch [11/100], Step [2800/6235], Loss: 2.1356\n",
      "Epoch [11/100], Step [2900/6235], Loss: 6.2469\n",
      "Epoch [11/100], Step [3000/6235], Loss: 0.7401\n",
      "Epoch [11/100], Step [3100/6235], Loss: 45.6160\n",
      "Epoch [11/100], Step [3200/6235], Loss: 65.9415\n",
      "Epoch [11/100], Step [3300/6235], Loss: 0.6071\n",
      "Epoch [11/100], Step [3400/6235], Loss: 2.6867\n",
      "Epoch [11/100], Step [3500/6235], Loss: 34.2489\n",
      "Epoch [11/100], Step [3600/6235], Loss: 10.2432\n",
      "Epoch [11/100], Step [3700/6235], Loss: 1.4783\n",
      "Epoch [11/100], Step [3800/6235], Loss: 0.5163\n",
      "Epoch [11/100], Step [3900/6235], Loss: 0.6825\n",
      "Epoch [11/100], Step [4000/6235], Loss: 0.1925\n",
      "Epoch [11/100], Step [4100/6235], Loss: 2.9238\n",
      "Epoch [11/100], Step [4200/6235], Loss: 0.2347\n",
      "Epoch [11/100], Step [4300/6235], Loss: 9.1524\n",
      "Epoch [11/100], Step [4400/6235], Loss: 0.6258\n",
      "Epoch [11/100], Step [4500/6235], Loss: 72.4013\n",
      "Epoch [11/100], Step [4600/6235], Loss: 14.1616\n",
      "Epoch [11/100], Step [4700/6235], Loss: 2.3550\n",
      "Epoch [11/100], Step [4800/6235], Loss: 1.6346\n",
      "Epoch [11/100], Step [4900/6235], Loss: 0.0880\n",
      "Epoch [11/100], Step [5000/6235], Loss: 0.9072\n",
      "Epoch [11/100], Step [5100/6235], Loss: 2.1496\n",
      "Epoch [11/100], Step [5200/6235], Loss: 4.2845\n",
      "Epoch [11/100], Step [5300/6235], Loss: 34.6640\n",
      "Epoch [11/100], Step [5400/6235], Loss: 2.0773\n",
      "Epoch [11/100], Step [5500/6235], Loss: 0.4450\n",
      "Epoch [11/100], Step [5600/6235], Loss: 0.0667\n",
      "Epoch [11/100], Step [5700/6235], Loss: 0.1883\n",
      "Epoch [11/100], Step [5800/6235], Loss: 1.1420\n",
      "Epoch [11/100], Step [5900/6235], Loss: 1.0061\n",
      "Epoch [11/100], Step [6000/6235], Loss: 0.5048\n",
      "Epoch [11/100], Step [6100/6235], Loss: 0.2258\n",
      "Epoch [11/100], Step [6200/6235], Loss: 0.0663\n",
      "Epoch [11/100], Step [6300/6235], Loss: 0.0543\n",
      "Epoch [11/100], Step [6400/6235], Loss: 0.0930\n",
      "Epoch [11/100], Step [6500/6235], Loss: 0.0710\n",
      "Epoch [11/100], Step [6600/6235], Loss: 0.1868\n",
      "Epoch [11/100], Step [6700/6235], Loss: 0.8246\n",
      "Epoch [11/100], Step [6800/6235], Loss: 0.8645\n",
      "Epoch [11/100], Step [6900/6235], Loss: 1.1120\n",
      "Epoch [11/100], Step [7000/6235], Loss: 0.0284\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Step [7100/6235], Loss: 0.6900\n",
      "Epoch [11/100], Step [7200/6235], Loss: 0.6603\n",
      "Epoch [11/100], Step [7300/6235], Loss: 1.4477\n",
      "Epoch [11/100], Step [7400/6235], Loss: 0.0249\n",
      "Epoch [11/100], Step [7500/6235], Loss: 14.9455\n",
      "Epoch [11/100], Step [7600/6235], Loss: 11.6605\n",
      "Epoch [11/100], Step [7700/6235], Loss: 3.9972\n",
      "Epoch [11/100], Step [7800/6235], Loss: 0.5002\n",
      "Epoch [11/100], Step [7900/6235], Loss: 11.6825\n",
      "Epoch [11/100], Step [8000/6235], Loss: 0.2445\n",
      "Epoch [11/100], Step [8100/6235], Loss: 3.8621\n",
      "Epoch [11/100], Step [8200/6235], Loss: 22.2529\n",
      "Epoch [11/100], Step [8300/6235], Loss: 55.9165\n",
      "Epoch [11/100], Step [8400/6235], Loss: 23.3825\n",
      "Epoch [11/100], Step [8500/6235], Loss: 22.8726\n",
      "Epoch [11/100], Step [8600/6235], Loss: 7.7497\n",
      "Epoch [11/100], Step [8700/6235], Loss: 7.1980\n",
      "Epoch [11/100], Step [8800/6235], Loss: 591.1176\n",
      "Epoch [11/100], Step [8900/6235], Loss: 0.8743\n",
      "Epoch [11/100], Step [9000/6235], Loss: 407.4820\n",
      "Epoch [11/100], Step [9100/6235], Loss: 100.5335\n",
      "Epoch [11/100], Step [9200/6235], Loss: 3111.0308\n",
      "Epoch [11/100], Step [9300/6235], Loss: 170.5607\n",
      "Epoch [11/100], Step [9400/6235], Loss: 272.2777\n",
      "Epoch [11/100], Step [9500/6235], Loss: 299.7069\n",
      "Epoch [11/100], Step [9600/6235], Loss: 56.2024\n",
      "Epoch [11/100], Step [9700/6235], Loss: 206.3946\n",
      "Epoch [11/100], Step [9800/6235], Loss: 363.8808\n",
      "Epoch [11/100], Step [9900/6235], Loss: 18.0523\n",
      "Epoch [11/100], Step [10000/6235], Loss: 13.0322\n",
      "Epoch [11/100], Step [10100/6235], Loss: 61.7999\n",
      "Epoch [11/100], Step [10200/6235], Loss: 551.1022\n",
      "Epoch [11/100], Step [10300/6235], Loss: 0.9707\n",
      "Epoch [11/100], Step [10400/6235], Loss: 4.3887\n",
      "Epoch [11/100], Step [10500/6235], Loss: 11.6710\n",
      "Epoch [11/100], Step [10600/6235], Loss: 1828.5687\n",
      "Epoch [11/100], Step [10700/6235], Loss: 109.9545\n",
      "Epoch [11/100], Step [10800/6235], Loss: 52.1065\n",
      "Epoch [11/100], Step [10900/6235], Loss: 4.8599\n",
      "Epoch [11/100], Step [11000/6235], Loss: 90.1266\n",
      "Epoch [11/100], Step [11100/6235], Loss: 4.2386\n",
      "Epoch [11/100], Step [11200/6235], Loss: 123.4442\n",
      "Epoch [11/100], Step [11300/6235], Loss: 232.9057\n",
      "Epoch [11/100], Step [11400/6235], Loss: 270.0865\n",
      "Epoch [11/100], Step [11500/6235], Loss: 17.5684\n",
      "Epoch [11/100], Step [11600/6235], Loss: 3.1682\n",
      "Epoch [11/100], Step [11700/6235], Loss: 174.5875\n",
      "Epoch [11/100], Step [11800/6235], Loss: 31.9255\n",
      "Epoch [11/100], Step [11900/6235], Loss: 950.7980\n",
      "Epoch [11/100], Step [12000/6235], Loss: 10.6137\n",
      "Epoch [11/100], Step [12100/6235], Loss: 488.0190\n",
      "Epoch [11/100], Step [12200/6235], Loss: 89.3663\n",
      "Epoch [11/100], Step [12300/6235], Loss: 24.7921\n",
      "Epoch [11/100], Step [12400/6235], Loss: 115.0185\n",
      "Epoch [11/100], Step [12500/6235], Loss: 240.1528\n",
      "Epoch [11/100], Step [12600/6235], Loss: 43.1557\n",
      "Epoch [11/100], Step [12700/6235], Loss: 27.0409\n",
      "Epoch [11/100], Step [12800/6235], Loss: 5.9454\n",
      "Epoch [11/100], Step [12900/6235], Loss: 54.4860\n",
      "Epoch [11/100], Step [13000/6235], Loss: 1.7685\n",
      "Epoch [11/100], Step [13100/6235], Loss: 117.7195\n",
      "Epoch [11/100], Step [13200/6235], Loss: 46.6287\n",
      "Epoch [11/100], Step [13300/6235], Loss: 1.8337\n",
      "Epoch [11/100], Step [13400/6235], Loss: 0.5212\n",
      "Epoch [11/100], Step [13500/6235], Loss: 0.3278\n",
      "Epoch [11/100], Step [13600/6235], Loss: 38.4212\n",
      "Epoch [11/100], Step [13700/6235], Loss: 183.1718\n",
      "Epoch [11/100], Step [13800/6235], Loss: 135.1174\n",
      "Epoch [11/100], Step [13900/6235], Loss: 16.2872\n",
      "Epoch [11/100], Step [14000/6235], Loss: 0.2127\n",
      "Epoch [11/100], Step [14100/6235], Loss: 78.4819\n",
      "Epoch [11/100], Step [14200/6235], Loss: 44.9473\n",
      "Epoch [11/100], Step [14300/6235], Loss: 23.3015\n",
      "Epoch [11/100], Step [14400/6235], Loss: 0.1980\n",
      "Epoch [11/100], Step [14500/6235], Loss: 12.4873\n",
      "Epoch [11/100], Step [14600/6235], Loss: 5.4952\n",
      "Epoch [11/100], Step [14700/6235], Loss: 8.3773\n",
      "Epoch [11/100], Step [14800/6235], Loss: 13.1216\n",
      "Epoch [11/100], Step [14900/6235], Loss: 0.1052\n",
      "Epoch [11/100], Step [15000/6235], Loss: 0.0394\n",
      "Epoch [11/100], Step [15100/6235], Loss: 0.1346\n",
      "Epoch [11/100], Step [15200/6235], Loss: 14.3186\n",
      "Epoch [11/100], Step [15300/6235], Loss: 22.9831\n",
      "Epoch [11/100], Step [15400/6235], Loss: 3.1890\n",
      "Epoch [11/100], Step [15500/6235], Loss: 39.3211\n",
      "Epoch [11/100], Step [15600/6235], Loss: 77.7568\n",
      "Epoch [11/100], Step [15700/6235], Loss: 16.2101\n",
      "Epoch [11/100], Step [15800/6235], Loss: 4.8509\n",
      "Epoch [11/100], Step [15900/6235], Loss: 3.2570\n",
      "Epoch [11/100], Step [16000/6235], Loss: 1.4935\n",
      "Epoch [11/100], Step [16100/6235], Loss: 0.9805\n",
      "Epoch [11/100], Step [16200/6235], Loss: 5.0473\n",
      "Epoch [11/100], Step [16300/6235], Loss: 46.0549\n",
      "Epoch [11/100], Step [16400/6235], Loss: 71.5178\n",
      "Epoch [11/100], Step [16500/6235], Loss: 625.2167\n",
      "Epoch [11/100], Step [16600/6235], Loss: 12.0887\n",
      "Epoch [11/100], Step [16700/6235], Loss: 2.9521\n",
      "Epoch [11/100], Step [16800/6235], Loss: 0.9909\n",
      "Epoch [11/100], Step [16900/6235], Loss: 9.8438\n",
      "Epoch [11/100], Step [17000/6235], Loss: 1.9405\n",
      "Epoch [11/100], Step [17100/6235], Loss: 0.1692\n",
      "Epoch [11/100], Step [17200/6235], Loss: 51.4039\n",
      "Epoch [11/100], Step [17300/6235], Loss: 20.9377\n",
      "Epoch [11/100], Step [17400/6235], Loss: 36.7600\n",
      "Epoch [11/100], Step [17500/6235], Loss: 1.9345\n",
      "Epoch [11/100], Step [17600/6235], Loss: 0.5585\n",
      "Epoch [11/100], Step [17700/6235], Loss: 92.9067\n",
      "Epoch [11/100], Step [17800/6235], Loss: 22.5987\n",
      "Epoch [11/100], Step [17900/6235], Loss: 20.8088\n",
      "Epoch [11/100], Step [18000/6235], Loss: 2.3782\n",
      "Epoch [11/100], Step [18100/6235], Loss: 13.3416\n",
      "Epoch [11/100], Step [18200/6235], Loss: 20.4537\n",
      "Epoch [11/100], Step [18300/6235], Loss: 3.4852\n",
      "Epoch [11/100], Step [18400/6235], Loss: 19.6479\n",
      "Epoch [11/100], Step [18500/6235], Loss: 21.9030\n",
      "Epoch [11/100], Step [18600/6235], Loss: 5.5305\n",
      "Epoch [11/100], Step [18700/6235], Loss: 0.2905\n",
      "Epoch [11/100], Step [18800/6235], Loss: 148.0585\n",
      "Epoch [11/100], Step [18900/6235], Loss: 2.0331\n",
      "Epoch [11/100], Step [19000/6235], Loss: 2.1492\n",
      "Epoch [11/100], Step [19100/6235], Loss: 11.8314\n",
      "Epoch [11/100], Step [19200/6235], Loss: 1.2779\n",
      "Epoch [11/100], Step [19300/6235], Loss: 2.4491\n",
      "Epoch [11/100], Step [19400/6235], Loss: 142.4582\n",
      "Epoch [11/100], Step [19500/6235], Loss: 206.7849\n",
      "Epoch [11/100], Step [19600/6235], Loss: 122.3433\n",
      "Epoch [11/100], Step [19700/6235], Loss: 14.1214\n",
      "Epoch [11/100], Step [19800/6235], Loss: 9.3373\n",
      "Epoch [11/100], Step [19900/6235], Loss: 0.1205\n",
      "Epoch [11/100], Step [20000/6235], Loss: 112.8845\n",
      "Epoch [11/100], Step [20100/6235], Loss: 17.6257\n",
      "Epoch [11/100], Step [20200/6235], Loss: 0.9043\n",
      "Epoch [11/100], Step [20300/6235], Loss: 0.3742\n",
      "Epoch [11/100], Step [20400/6235], Loss: 34.7578\n",
      "Epoch [11/100], Step [20500/6235], Loss: 21.8170\n",
      "Epoch [11/100], Step [20600/6235], Loss: 254.3247\n",
      "Epoch [11/100], Step [20700/6235], Loss: 5.9067\n",
      "Epoch [11/100], Step [20800/6235], Loss: 34.5083\n",
      "Epoch [11/100], Step [20900/6235], Loss: 26.2135\n",
      "Epoch [11/100], Step [21000/6235], Loss: 18.7585\n",
      "Epoch [11/100], Step [21100/6235], Loss: 25.1848\n",
      "Epoch [11/100], Step [21200/6235], Loss: 0.7393\n",
      "Epoch [11/100], Step [21300/6235], Loss: 2.9779\n",
      "Epoch [11/100], Step [21400/6235], Loss: 2.5512\n",
      "Epoch [11/100], Step [21500/6235], Loss: 6.5220\n",
      "Epoch [11/100], Step [21600/6235], Loss: 30.1697\n",
      "Epoch [11/100], Step [21700/6235], Loss: 0.2435\n",
      "Epoch [11/100], Step [21800/6235], Loss: 15.0649\n",
      "Epoch [11/100], Step [21900/6235], Loss: 0.0457\n",
      "Epoch [11/100], Step [22000/6235], Loss: 0.2221\n",
      "Epoch [11/100], Step [22100/6235], Loss: 5.0772\n",
      "Epoch [11/100], Step [22200/6235], Loss: 0.5843\n",
      "Epoch [11/100], Step [22300/6235], Loss: 0.3410\n",
      "Epoch [11/100], Step [22400/6235], Loss: 1.7700\n",
      "Epoch [11/100], Step [22500/6235], Loss: 46.0094\n",
      "Epoch [11/100], Step [22600/6235], Loss: 13.6051\n",
      "Epoch [11/100], Step [22700/6235], Loss: 0.6479\n",
      "Epoch [11/100], Step [22800/6235], Loss: 2.1164\n",
      "Epoch [11/100], Step [22900/6235], Loss: 0.4483\n",
      "Epoch [11/100], Step [23000/6235], Loss: 2.7726\n",
      "Epoch [11/100], Step [23100/6235], Loss: 8.7663\n",
      "Epoch [11/100], Step [23200/6235], Loss: 26.0385\n",
      "Epoch [11/100], Step [23300/6235], Loss: 17.2640\n",
      "Epoch [11/100], Step [23400/6235], Loss: 0.2306\n",
      "Epoch [11/100], Step [23500/6235], Loss: 0.3469\n",
      "Epoch [11/100], Step [23600/6235], Loss: 65.2210\n",
      "Epoch [11/100], Step [23700/6235], Loss: 10.7018\n",
      "Epoch [11/100], Step [23800/6235], Loss: 0.0881\n",
      "Epoch [11/100], Step [23900/6235], Loss: 6.6899\n",
      "Epoch [11/100], Step [24000/6235], Loss: 3.4778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Step [24100/6235], Loss: 3.1706\n",
      "Epoch [11/100], Step [24200/6235], Loss: 42.7851\n",
      "Epoch [11/100], Step [24300/6235], Loss: 3.3928\n",
      "Epoch [11/100], Step [24400/6235], Loss: 9.7834\n",
      "Epoch [11/100], Step [24500/6235], Loss: 4.0728\n",
      "Epoch [11/100], Step [24600/6235], Loss: 0.2738\n",
      "Epoch [11/100], Step [24700/6235], Loss: 6.0771\n",
      "Epoch [11/100], Step [24800/6235], Loss: 1.7364\n",
      "Epoch [11/100], Step [24900/6235], Loss: 0.0823\n",
      "Epoch [11/100], Step [25000/6235], Loss: 18.0684\n",
      "Epoch [11/100], Step [25100/6235], Loss: 8.0909\n",
      "Epoch [11/100], Step [25200/6235], Loss: 1.5594\n",
      "Epoch [11/100], Step [25300/6235], Loss: 2.8106\n",
      "Epoch [11/100], Step [25400/6235], Loss: 10.0065\n",
      "Epoch [11/100], Step [25500/6235], Loss: 2.7291\n",
      "Epoch [11/100], Step [25600/6235], Loss: 0.4348\n",
      "Epoch [11/100], Step [25700/6235], Loss: 0.1188\n",
      "Epoch [11/100], Step [25800/6235], Loss: 0.1427\n",
      "Epoch [11/100], Step [25900/6235], Loss: 9.5046\n",
      "Epoch [11/100], Step [26000/6235], Loss: 2.2737\n",
      "Epoch [11/100], Step [26100/6235], Loss: 0.3237\n",
      "Epoch [11/100], Step [26200/6235], Loss: 0.0606\n",
      "Epoch [11/100], Step [26300/6235], Loss: 4.5083\n",
      "Epoch [11/100], Step [26400/6235], Loss: 0.0789\n",
      "Epoch [11/100], Step [26500/6235], Loss: 0.9839\n",
      "Epoch [11/100], Step [26600/6235], Loss: 5.6531\n",
      "Epoch [11/100], Step [26700/6235], Loss: 1.1701\n",
      "Epoch [11/100], Step [26800/6235], Loss: 2.4406\n",
      "Epoch [11/100], Step [26900/6235], Loss: 0.3264\n",
      "Epoch [11/100], Step [27000/6235], Loss: 8.3459\n",
      "Epoch [11/100], Step [27100/6235], Loss: 0.5533\n",
      "Epoch [11/100], Step [27200/6235], Loss: 0.2231\n",
      "Epoch [11/100], Step [27300/6235], Loss: 0.0676\n",
      "Epoch [11/100], Step [27400/6235], Loss: 1.4033\n",
      "Epoch [11/100], Step [27500/6235], Loss: 6.9275\n",
      "Epoch [11/100], Step [27600/6235], Loss: 0.2594\n",
      "Epoch [11/100], Step [27700/6235], Loss: 0.0833\n",
      "Epoch [11/100], Step [27800/6235], Loss: 2.1389\n",
      "Epoch [11/100], Step [27900/6235], Loss: 0.3055\n",
      "Epoch [11/100], Step [28000/6235], Loss: 144.2632\n",
      "Epoch [11/100], Step [28100/6235], Loss: 9.6311\n",
      "Epoch [11/100], Step [28200/6235], Loss: 25.3915\n",
      "Epoch [11/100], Step [28300/6235], Loss: 6.3695\n",
      "Epoch [11/100], Step [28400/6235], Loss: 10.6797\n",
      "Epoch [11/100], Step [28500/6235], Loss: 0.2607\n",
      "Epoch [11/100], Step [28600/6235], Loss: 1.4254\n",
      "Epoch [11/100], Step [28700/6235], Loss: 3.4008\n",
      "Epoch [11/100], Step [28800/6235], Loss: 0.1542\n",
      "Epoch [11/100], Step [28900/6235], Loss: 55.9728\n",
      "Epoch [11/100], Step [29000/6235], Loss: 3.6819\n",
      "Epoch [11/100], Step [29100/6235], Loss: 1.5478\n",
      "Epoch [11/100], Step [29200/6235], Loss: 0.3375\n",
      "Epoch [11/100], Step [29300/6235], Loss: 5.5759\n",
      "Epoch [11/100], Step [29400/6235], Loss: 0.4051\n",
      "Epoch [11/100], Step [29500/6235], Loss: 2.8679\n",
      "Epoch [11/100], Step [29600/6235], Loss: 2.1531\n",
      "Epoch [11/100], Step [29700/6235], Loss: 0.0404\n",
      "Epoch [11/100], Step [29800/6235], Loss: 1.4469\n",
      "Epoch [11/100], Step [29900/6235], Loss: 0.9700\n",
      "Epoch [11/100], Step [30000/6235], Loss: 4.5157\n",
      "Epoch [11/100], Step [30100/6235], Loss: 1.4408\n",
      "Epoch [11/100], Step [30200/6235], Loss: 0.2527\n",
      "Epoch [11/100], Step [30300/6235], Loss: 1.2132\n",
      "Epoch [11/100], Step [30400/6235], Loss: 0.0433\n",
      "Epoch [11/100], Step [30500/6235], Loss: 0.5982\n",
      "Epoch [11/100], Step [30600/6235], Loss: 0.0091\n",
      "Epoch [11/100], Step [30700/6235], Loss: 0.5588\n",
      "Epoch [11/100], Step [30800/6235], Loss: 0.1277\n",
      "Epoch [11/100], Step [30900/6235], Loss: 1.3120\n",
      "Epoch [11/100], Step [31000/6235], Loss: 0.1701\n",
      "Epoch [11/100], Step [31100/6235], Loss: 0.0568\n",
      "Epoch [11/100], Step [31200/6235], Loss: 10.0815\n",
      "Epoch [11/100], Step [31300/6235], Loss: 0.9246\n",
      "Epoch [11/100], Step [31400/6235], Loss: 0.7458\n",
      "Epoch [11/100], Step [31500/6235], Loss: 1.6578\n",
      "Epoch [11/100], Step [31600/6235], Loss: 3.5083\n",
      "Epoch [11/100], Step [31700/6235], Loss: 18.4383\n",
      "Epoch [11/100], Step [31800/6235], Loss: 0.4043\n",
      "Epoch [11/100], Step [31900/6235], Loss: 1622.9158\n",
      "Epoch [11/100], Step [32000/6235], Loss: 1.5611\n",
      "Epoch [11/100], Step [32100/6235], Loss: 8.0884\n",
      "Epoch [11/100], Step [32200/6235], Loss: 89.5352\n",
      "Epoch [11/100], Step [32300/6235], Loss: 1.2187\n",
      "Epoch [11/100], Step [32400/6235], Loss: 0.6824\n",
      "Epoch [11/100], Step [32500/6235], Loss: 20.3314\n",
      "Epoch [11/100], Step [32600/6235], Loss: 0.6796\n",
      "Epoch [11/100], Step [32700/6235], Loss: 44.1293\n",
      "Epoch [11/100], Step [32800/6235], Loss: 8.1984\n",
      "Epoch [11/100], Step [32900/6235], Loss: 12.1162\n",
      "Epoch [11/100], Step [33000/6235], Loss: 0.1385\n",
      "Epoch [11/100], Step [33100/6235], Loss: 0.8652\n",
      "Epoch [11/100], Step [33200/6235], Loss: 2.4294\n",
      "Epoch [11/100], Step [33300/6235], Loss: 8.8389\n",
      "Epoch [11/100], Step [33400/6235], Loss: 87.5907\n",
      "Epoch [11/100], Step [33500/6235], Loss: 1.0652\n",
      "Epoch [11/100], Step [33600/6235], Loss: 2.9774\n",
      "Epoch [11/100], Step [33700/6235], Loss: 0.6929\n",
      "Epoch [11/100], Step [33800/6235], Loss: 8.7891\n",
      "Epoch [11/100], Step [33900/6235], Loss: 27.1584\n",
      "Epoch [11/100], Step [34000/6235], Loss: 0.0083\n",
      "Epoch [11/100], Step [34100/6235], Loss: 0.0760\n",
      "Epoch [11/100], Step [34200/6235], Loss: 11.9342\n",
      "Epoch [11/100], Step [34300/6235], Loss: 2.9059\n",
      "Epoch [11/100], Step [34400/6235], Loss: 0.0875\n",
      "Epoch [11/100], Step [34500/6235], Loss: 124.4259\n",
      "Epoch [11/100], Step [34600/6235], Loss: 1.0526\n",
      "Epoch [11/100], Step [34700/6235], Loss: 6.6036\n",
      "Epoch [11/100], Step [34800/6235], Loss: 9.7663\n",
      "Epoch [11/100], Step [34900/6235], Loss: 51.6218\n",
      "Epoch [11/100], Step [35000/6235], Loss: 0.0808\n",
      "Epoch [11/100], Step [35100/6235], Loss: 3.6728\n",
      "Epoch [11/100], Step [35200/6235], Loss: 6.2354\n",
      "Epoch [11/100], Step [35300/6235], Loss: 1.2731\n",
      "Epoch [11/100], Step [35400/6235], Loss: 0.7148\n",
      "Epoch [11/100], Step [35500/6235], Loss: 0.7494\n",
      "Epoch [11/100], Step [35600/6235], Loss: 9.1772\n",
      "Epoch [11/100], Step [35700/6235], Loss: 9.2399\n",
      "Epoch [11/100], Step [35800/6235], Loss: 0.3298\n",
      "Epoch [11/100], Step [35900/6235], Loss: 4.2164\n",
      "Epoch [11/100], Step [36000/6235], Loss: 2.0407\n",
      "Epoch [11/100], Step [36100/6235], Loss: 4.6605\n",
      "Epoch [11/100], Step [36200/6235], Loss: 24.0668\n",
      "Epoch [11/100], Step [36300/6235], Loss: 3.3488\n",
      "Epoch [11/100], Step [36400/6235], Loss: 0.0256\n",
      "Epoch [11/100], Step [36500/6235], Loss: 11.8235\n",
      "Epoch [11/100], Step [36600/6235], Loss: 0.6251\n",
      "Epoch [11/100], Step [36700/6235], Loss: 0.7499\n",
      "Epoch [11/100], Step [36800/6235], Loss: 33.7701\n",
      "Epoch [11/100], Step [36900/6235], Loss: 2.9991\n",
      "Epoch [11/100], Step [37000/6235], Loss: 0.9914\n",
      "Epoch [11/100], Step [37100/6235], Loss: 1.0937\n",
      "Epoch [11/100], Step [37200/6235], Loss: 0.0279\n",
      "Epoch [11/100], Step [37300/6235], Loss: 0.6853\n",
      "Epoch [11/100], Step [37400/6235], Loss: 0.6404\n",
      "Epoch [11/100], Step [37500/6235], Loss: 2.8475\n",
      "Epoch [11/100], Step [37600/6235], Loss: 6.0720\n",
      "Epoch [11/100], Step [37700/6235], Loss: 0.4284\n",
      "Epoch [11/100], Step [37800/6235], Loss: 2.3020\n",
      "Epoch [11/100], Step [37900/6235], Loss: 0.6178\n",
      "Epoch [11/100], Step [38000/6235], Loss: 0.6198\n",
      "Epoch [11/100], Step [38100/6235], Loss: 7.3510\n",
      "Epoch [11/100], Step [38200/6235], Loss: 1.3786\n",
      "Epoch [11/100], Step [38300/6235], Loss: 2.9233\n",
      "Epoch [11/100], Step [38400/6235], Loss: 0.0602\n",
      "Epoch [11/100], Step [38500/6235], Loss: 2.1099\n",
      "Epoch [11/100], Step [38600/6235], Loss: 3.6529\n",
      "Epoch [11/100], Step [38700/6235], Loss: 0.0559\n",
      "Epoch [11/100], Step [38800/6235], Loss: 1.3970\n",
      "Epoch [11/100], Step [38900/6235], Loss: 2.6704\n",
      "Epoch [11/100], Step [39000/6235], Loss: 15.7057\n",
      "Epoch [11/100], Step [39100/6235], Loss: 10.9939\n",
      "Epoch [11/100], Step [39200/6235], Loss: 3.5534\n",
      "Epoch [11/100], Step [39300/6235], Loss: 18.6888\n",
      "Epoch [11/100], Step [39400/6235], Loss: 51.4686\n",
      "Epoch [11/100], Step [39500/6235], Loss: 323.7215\n",
      "Epoch [11/100], Step [39600/6235], Loss: 27.4261\n",
      "Epoch [11/100], Step [39700/6235], Loss: 42.3019\n",
      "Epoch [11/100], Step [39800/6235], Loss: 241.8382\n",
      "Epoch [11/100], Step [39900/6235], Loss: 2.1407\n",
      "Epoch [11/100], Step [40000/6235], Loss: 4.9854\n",
      "Epoch [11/100], Step [40100/6235], Loss: 21.4317\n",
      "Epoch [11/100], Step [40200/6235], Loss: 1.3381\n",
      "Epoch [11/100], Step [40300/6235], Loss: 0.5605\n",
      "Epoch [11/100], Step [40400/6235], Loss: 1.3975\n",
      "Epoch [11/100], Step [40500/6235], Loss: 2.6121\n",
      "Epoch [11/100], Step [40600/6235], Loss: 0.2311\n",
      "Epoch [11/100], Step [40700/6235], Loss: 7.5243\n",
      "Epoch [11/100], Step [40800/6235], Loss: 1.2541\n",
      "Epoch [11/100], Step [40900/6235], Loss: 0.1387\n",
      "Epoch [11/100], Step [41000/6235], Loss: 28.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [11/100], Step [41100/6235], Loss: 26.8480\n",
      "Epoch [11/100], Step [41200/6235], Loss: 35.8784\n",
      "Epoch [11/100], Step [41300/6235], Loss: 3.9222\n",
      "Epoch [11/100], Step [41400/6235], Loss: 0.2768\n",
      "Epoch [11/100], Step [41500/6235], Loss: 2.8557\n",
      "Epoch [11/100], Step [41600/6235], Loss: 0.0657\n",
      "Epoch [11/100], Step [41700/6235], Loss: 0.1209\n",
      "Epoch [11/100], Step [41800/6235], Loss: 1.0227\n",
      "Epoch [11/100], Step [41900/6235], Loss: 4.1881\n",
      "Epoch [11/100], Step [42000/6235], Loss: 2.2063\n",
      "Epoch [11/100], Step [42100/6235], Loss: 6.2785\n",
      "Epoch [11/100], Step [42200/6235], Loss: 69.6834\n",
      "Epoch [11/100], Step [42300/6235], Loss: 2.6745\n",
      "Epoch [11/100], Step [42400/6235], Loss: 4.2976\n",
      "Epoch [11/100], Step [42500/6235], Loss: 0.4901\n",
      "Epoch [11/100], Step [42600/6235], Loss: 0.7072\n",
      "Epoch [11/100], Step [42700/6235], Loss: 0.3482\n",
      "Epoch [11/100], Step [42800/6235], Loss: 0.2691\n",
      "Epoch [11/100], Step [42900/6235], Loss: 4.0439\n",
      "Epoch [11/100], Step [43000/6235], Loss: 0.1841\n",
      "Epoch [11/100], Step [43100/6235], Loss: 1.7113\n",
      "Epoch [11/100], Step [43200/6235], Loss: 0.4707\n",
      "Epoch [11/100], Step [43300/6235], Loss: 10.0530\n",
      "Epoch [11/100], Step [43400/6235], Loss: 12.1536\n",
      "Epoch [11/100], Step [43500/6235], Loss: 9.2918\n",
      "Epoch [11/100], Step [43600/6235], Loss: 24.1253\n",
      "Epoch [11/100], Step [43700/6235], Loss: 47.1129\n",
      "Epoch [11/100], Step [43800/6235], Loss: 0.7959\n",
      "Epoch [11/100], Step [43900/6235], Loss: 3.2032\n",
      "Epoch [11/100], Step [44000/6235], Loss: 30.7277\n",
      "Epoch [11/100], Step [44100/6235], Loss: 5.0127\n",
      "Epoch [11/100], Step [44200/6235], Loss: 4.3934\n",
      "Epoch [11/100], Step [44300/6235], Loss: 83.4637\n",
      "Epoch [11/100], Step [44400/6235], Loss: 0.7696\n",
      "Epoch [11/100], Step [44500/6235], Loss: 2.3602\n",
      "Epoch [11/100], Step [44600/6235], Loss: 19.4417\n",
      "Epoch [11/100], Step [44700/6235], Loss: 3.3902\n",
      "Epoch [11/100], Step [44800/6235], Loss: 3.9106\n",
      "Epoch [11/100], Step [44900/6235], Loss: 5.8456\n",
      "Epoch [11/100], Step [45000/6235], Loss: 4.8822\n",
      "Epoch [11/100], Step [45100/6235], Loss: 53.5863\n",
      "Epoch [11/100], Step [45200/6235], Loss: 1.2405\n",
      "Epoch [11/100], Step [45300/6235], Loss: 26.2360\n",
      "Epoch [11/100], Step [45400/6235], Loss: 11.1299\n",
      "Epoch [11/100], Step [45500/6235], Loss: 1.1227\n",
      "Epoch [11/100], Step [45600/6235], Loss: 0.3755\n",
      "Epoch [11/100], Step [45700/6235], Loss: 144.8332\n",
      "Epoch [11/100], Step [45800/6235], Loss: 329.6246\n",
      "Epoch [11/100], Step [45900/6235], Loss: 0.7213\n",
      "Epoch [11/100], Step [46000/6235], Loss: 16.9881\n",
      "Epoch [11/100], Step [46100/6235], Loss: 23.0100\n",
      "Epoch [11/100], Step [46200/6235], Loss: 77.7150\n",
      "Epoch [11/100], Step [46300/6235], Loss: 20.2388\n",
      "Epoch [11/100], Step [46400/6235], Loss: 8.1062\n",
      "Epoch [11/100], Step [46500/6235], Loss: 272.3842\n",
      "Epoch [11/100], Step [46600/6235], Loss: 13.7598\n",
      "Epoch [11/100], Step [46700/6235], Loss: 14.0664\n",
      "Epoch [11/100], Step [46800/6235], Loss: 8.2264\n",
      "Epoch [11/100], Step [46900/6235], Loss: 2.0543\n",
      "Epoch [11/100], Step [47000/6235], Loss: 7.5378\n",
      "Epoch [11/100], Step [47100/6235], Loss: 4.9263\n",
      "Epoch [11/100], Step [47200/6235], Loss: 4.6619\n",
      "Epoch [11/100], Step [47300/6235], Loss: 0.8289\n",
      "Epoch [11/100], Step [47400/6235], Loss: 58.9136\n",
      "Epoch [11/100], Step [47500/6235], Loss: 6.1724\n",
      "Epoch [11/100], Step [47600/6235], Loss: 1.4147\n",
      "Epoch [11/100], Step [47700/6235], Loss: 16.8677\n",
      "Epoch [11/100], Step [47800/6235], Loss: 0.8754\n",
      "Epoch [11/100], Step [47900/6235], Loss: 40.5879\n",
      "Epoch [11/100], Step [48000/6235], Loss: 109.7988\n",
      "Epoch [11/100], Step [48100/6235], Loss: 1.7515\n",
      "Epoch [11/100], Step [48200/6235], Loss: 13.4743\n",
      "Epoch [11/100], Step [48300/6235], Loss: 52.6022\n",
      "Epoch [11/100], Step [48400/6235], Loss: 65.6711\n",
      "Epoch [11/100], Step [48500/6235], Loss: 4.3346\n",
      "Epoch [11/100], Step [48600/6235], Loss: 104.3722\n",
      "Epoch [11/100], Step [48700/6235], Loss: 97.6864\n",
      "Epoch [11/100], Step [48800/6235], Loss: 84.5838\n",
      "Epoch [11/100], Step [48900/6235], Loss: 21.0742\n",
      "Epoch [11/100], Step [49000/6235], Loss: 275.9872\n",
      "Epoch [11/100], Step [49100/6235], Loss: 1649.9514\n",
      "Epoch [11/100], Step [49200/6235], Loss: 936.0615\n",
      "Epoch [11/100], Step [49300/6235], Loss: 1204.4043\n",
      "Epoch [11/100], Step [49400/6235], Loss: 334.3820\n",
      "Epoch [11/100], Step [49500/6235], Loss: 3.7122\n",
      "Epoch [11/100], Step [49600/6235], Loss: 68.4351\n",
      "Epoch [11/100], Step [49700/6235], Loss: 3987.4478\n",
      "Epoch [11/100], Step [49800/6235], Loss: 58.4006\n",
      "Epoch [12/100], Step [100/6235], Loss: 17.9999\n",
      "Epoch [12/100], Step [200/6235], Loss: 0.1483\n",
      "Epoch [12/100], Step [300/6235], Loss: 0.0241\n",
      "Epoch [12/100], Step [400/6235], Loss: 0.0061\n",
      "Epoch [12/100], Step [500/6235], Loss: 11.0996\n",
      "Epoch [12/100], Step [600/6235], Loss: 0.0655\n",
      "Epoch [12/100], Step [700/6235], Loss: 0.6865\n",
      "Epoch [12/100], Step [800/6235], Loss: 0.1991\n",
      "Epoch [12/100], Step [900/6235], Loss: 0.5596\n",
      "Epoch [12/100], Step [1000/6235], Loss: 0.0627\n",
      "Epoch [12/100], Step [1100/6235], Loss: 0.3314\n",
      "Epoch [12/100], Step [1200/6235], Loss: 0.1758\n",
      "Epoch [12/100], Step [1300/6235], Loss: 0.1405\n",
      "Epoch [12/100], Step [1400/6235], Loss: 1.2275\n",
      "Epoch [12/100], Step [1500/6235], Loss: 0.0143\n",
      "Epoch [12/100], Step [1600/6235], Loss: 0.3787\n",
      "Epoch [12/100], Step [1700/6235], Loss: 0.4603\n",
      "Epoch [12/100], Step [1800/6235], Loss: 0.2851\n",
      "Epoch [12/100], Step [1900/6235], Loss: 0.6178\n",
      "Epoch [12/100], Step [2000/6235], Loss: 3.2550\n",
      "Epoch [12/100], Step [2100/6235], Loss: 1.1645\n",
      "Epoch [12/100], Step [2200/6235], Loss: 9.6723\n",
      "Epoch [12/100], Step [2300/6235], Loss: 12.1447\n",
      "Epoch [12/100], Step [2400/6235], Loss: 4.6988\n",
      "Epoch [12/100], Step [2500/6235], Loss: 36.4494\n",
      "Epoch [12/100], Step [2600/6235], Loss: 10.1565\n",
      "Epoch [12/100], Step [2700/6235], Loss: 20.0542\n",
      "Epoch [12/100], Step [2800/6235], Loss: 111.2790\n",
      "Epoch [12/100], Step [2900/6235], Loss: 6.5949\n",
      "Epoch [12/100], Step [3000/6235], Loss: 1.5157\n",
      "Epoch [12/100], Step [3100/6235], Loss: 62.8200\n",
      "Epoch [12/100], Step [3200/6235], Loss: 84.2230\n",
      "Epoch [12/100], Step [3300/6235], Loss: 1.0978\n",
      "Epoch [12/100], Step [3400/6235], Loss: 3.2885\n",
      "Epoch [12/100], Step [3500/6235], Loss: 29.5650\n",
      "Epoch [12/100], Step [3600/6235], Loss: 10.3290\n",
      "Epoch [12/100], Step [3700/6235], Loss: 1.0564\n",
      "Epoch [12/100], Step [3800/6235], Loss: 0.5656\n",
      "Epoch [12/100], Step [3900/6235], Loss: 1.6096\n",
      "Epoch [12/100], Step [4000/6235], Loss: 0.1269\n",
      "Epoch [12/100], Step [4100/6235], Loss: 4.2563\n",
      "Epoch [12/100], Step [4200/6235], Loss: 0.5243\n",
      "Epoch [12/100], Step [4300/6235], Loss: 9.1410\n",
      "Epoch [12/100], Step [4400/6235], Loss: 3.8056\n",
      "Epoch [12/100], Step [4500/6235], Loss: 54.5792\n",
      "Epoch [12/100], Step [4600/6235], Loss: 8.4499\n",
      "Epoch [12/100], Step [4700/6235], Loss: 1.3834\n",
      "Epoch [12/100], Step [4800/6235], Loss: 0.9430\n",
      "Epoch [12/100], Step [4900/6235], Loss: 0.0647\n",
      "Epoch [12/100], Step [5000/6235], Loss: 0.4437\n",
      "Epoch [12/100], Step [5100/6235], Loss: 2.0535\n",
      "Epoch [12/100], Step [5200/6235], Loss: 1.3098\n",
      "Epoch [12/100], Step [5300/6235], Loss: 32.2921\n",
      "Epoch [12/100], Step [5400/6235], Loss: 0.0852\n",
      "Epoch [12/100], Step [5500/6235], Loss: 0.1980\n",
      "Epoch [12/100], Step [5600/6235], Loss: 0.3677\n",
      "Epoch [12/100], Step [5700/6235], Loss: 2.0392\n",
      "Epoch [12/100], Step [5800/6235], Loss: 1.3876\n",
      "Epoch [12/100], Step [5900/6235], Loss: 0.1260\n",
      "Epoch [12/100], Step [6000/6235], Loss: 2.8150\n",
      "Epoch [12/100], Step [6100/6235], Loss: 0.0968\n",
      "Epoch [12/100], Step [6200/6235], Loss: 0.5646\n",
      "Epoch [12/100], Step [6300/6235], Loss: 1.1663\n",
      "Epoch [12/100], Step [6400/6235], Loss: 0.1441\n",
      "Epoch [12/100], Step [6500/6235], Loss: 1.1798\n",
      "Epoch [12/100], Step [6600/6235], Loss: 0.6506\n",
      "Epoch [12/100], Step [6700/6235], Loss: 0.6123\n",
      "Epoch [12/100], Step [6800/6235], Loss: 1.0425\n",
      "Epoch [12/100], Step [6900/6235], Loss: 3.1855\n",
      "Epoch [12/100], Step [7000/6235], Loss: 0.4069\n",
      "Epoch [12/100], Step [7100/6235], Loss: 0.2893\n",
      "Epoch [12/100], Step [7200/6235], Loss: 0.3259\n",
      "Epoch [12/100], Step [7300/6235], Loss: 1.0000\n",
      "Epoch [12/100], Step [7400/6235], Loss: 0.0573\n",
      "Epoch [12/100], Step [7500/6235], Loss: 3.1541\n",
      "Epoch [12/100], Step [7600/6235], Loss: 15.2426\n",
      "Epoch [12/100], Step [7700/6235], Loss: 1.3225\n",
      "Epoch [12/100], Step [7800/6235], Loss: 8.9078\n",
      "Epoch [12/100], Step [7900/6235], Loss: 14.0079\n",
      "Epoch [12/100], Step [8000/6235], Loss: 0.6381\n",
      "Epoch [12/100], Step [8100/6235], Loss: 3.3148\n",
      "Epoch [12/100], Step [8200/6235], Loss: 24.8908\n",
      "Epoch [12/100], Step [8300/6235], Loss: 39.7613\n",
      "Epoch [12/100], Step [8400/6235], Loss: 28.8250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Step [8500/6235], Loss: 49.0285\n",
      "Epoch [12/100], Step [8600/6235], Loss: 11.3587\n",
      "Epoch [12/100], Step [8700/6235], Loss: 4.4744\n",
      "Epoch [12/100], Step [8800/6235], Loss: 1687.5292\n",
      "Epoch [12/100], Step [8900/6235], Loss: 28.0979\n",
      "Epoch [12/100], Step [9000/6235], Loss: 497.6372\n",
      "Epoch [12/100], Step [9100/6235], Loss: 128.1785\n",
      "Epoch [12/100], Step [9200/6235], Loss: 2186.8540\n",
      "Epoch [12/100], Step [9300/6235], Loss: 66.2992\n",
      "Epoch [12/100], Step [9400/6235], Loss: 142.0087\n",
      "Epoch [12/100], Step [9500/6235], Loss: 299.0917\n",
      "Epoch [12/100], Step [9600/6235], Loss: 310.2659\n",
      "Epoch [12/100], Step [9700/6235], Loss: 213.7044\n",
      "Epoch [12/100], Step [9800/6235], Loss: 371.4109\n",
      "Epoch [12/100], Step [9900/6235], Loss: 10.9010\n",
      "Epoch [12/100], Step [10000/6235], Loss: 8.3138\n",
      "Epoch [12/100], Step [10100/6235], Loss: 61.9955\n",
      "Epoch [12/100], Step [10200/6235], Loss: 584.9398\n",
      "Epoch [12/100], Step [10300/6235], Loss: 1.4959\n",
      "Epoch [12/100], Step [10400/6235], Loss: 5.3516\n",
      "Epoch [12/100], Step [10500/6235], Loss: 11.5682\n",
      "Epoch [12/100], Step [10600/6235], Loss: 1786.6920\n",
      "Epoch [12/100], Step [10700/6235], Loss: 107.5758\n",
      "Epoch [12/100], Step [10800/6235], Loss: 31.9113\n",
      "Epoch [12/100], Step [10900/6235], Loss: 4.8037\n",
      "Epoch [12/100], Step [11000/6235], Loss: 80.1343\n",
      "Epoch [12/100], Step [11100/6235], Loss: 3.0324\n",
      "Epoch [12/100], Step [11200/6235], Loss: 125.3939\n",
      "Epoch [12/100], Step [11300/6235], Loss: 230.9929\n",
      "Epoch [12/100], Step [11400/6235], Loss: 279.0479\n",
      "Epoch [12/100], Step [11500/6235], Loss: 16.9083\n",
      "Epoch [12/100], Step [11600/6235], Loss: 2.8039\n",
      "Epoch [12/100], Step [11700/6235], Loss: 174.0993\n",
      "Epoch [12/100], Step [11800/6235], Loss: 27.7466\n",
      "Epoch [12/100], Step [11900/6235], Loss: 832.2121\n",
      "Epoch [12/100], Step [12000/6235], Loss: 276.1523\n",
      "Epoch [12/100], Step [12100/6235], Loss: 368.3717\n",
      "Epoch [12/100], Step [12200/6235], Loss: 77.1769\n",
      "Epoch [12/100], Step [12300/6235], Loss: 11.8305\n",
      "Epoch [12/100], Step [12400/6235], Loss: 67.3793\n",
      "Epoch [12/100], Step [12500/6235], Loss: 246.3406\n",
      "Epoch [12/100], Step [12600/6235], Loss: 40.4531\n",
      "Epoch [12/100], Step [12700/6235], Loss: 19.8458\n",
      "Epoch [12/100], Step [12800/6235], Loss: 11.2580\n",
      "Epoch [12/100], Step [12900/6235], Loss: 57.8165\n",
      "Epoch [12/100], Step [13000/6235], Loss: 1.5445\n",
      "Epoch [12/100], Step [13100/6235], Loss: 119.0480\n",
      "Epoch [12/100], Step [13200/6235], Loss: 45.1776\n",
      "Epoch [12/100], Step [13300/6235], Loss: 4.4163\n",
      "Epoch [12/100], Step [13400/6235], Loss: 0.9591\n",
      "Epoch [12/100], Step [13500/6235], Loss: 0.6133\n",
      "Epoch [12/100], Step [13600/6235], Loss: 28.6105\n",
      "Epoch [12/100], Step [13700/6235], Loss: 200.9006\n",
      "Epoch [12/100], Step [13800/6235], Loss: 117.7038\n",
      "Epoch [12/100], Step [13900/6235], Loss: 0.7564\n",
      "Epoch [12/100], Step [14000/6235], Loss: 0.1954\n",
      "Epoch [12/100], Step [14100/6235], Loss: 13.9669\n",
      "Epoch [12/100], Step [14200/6235], Loss: 63.1103\n",
      "Epoch [12/100], Step [14300/6235], Loss: 28.1078\n",
      "Epoch [12/100], Step [14400/6235], Loss: 0.4032\n",
      "Epoch [12/100], Step [14500/6235], Loss: 6.6197\n",
      "Epoch [12/100], Step [14600/6235], Loss: 3.4306\n",
      "Epoch [12/100], Step [14700/6235], Loss: 10.2985\n",
      "Epoch [12/100], Step [14800/6235], Loss: 10.4665\n",
      "Epoch [12/100], Step [14900/6235], Loss: 0.0722\n",
      "Epoch [12/100], Step [15000/6235], Loss: 0.0244\n",
      "Epoch [12/100], Step [15100/6235], Loss: 0.1341\n",
      "Epoch [12/100], Step [15200/6235], Loss: 24.6303\n",
      "Epoch [12/100], Step [15300/6235], Loss: 21.1564\n",
      "Epoch [12/100], Step [15400/6235], Loss: 2.4808\n",
      "Epoch [12/100], Step [15500/6235], Loss: 36.2579\n",
      "Epoch [12/100], Step [15600/6235], Loss: 136.1421\n",
      "Epoch [12/100], Step [15700/6235], Loss: 82.7336\n",
      "Epoch [12/100], Step [15800/6235], Loss: 6.4928\n",
      "Epoch [12/100], Step [15900/6235], Loss: 2.9014\n",
      "Epoch [12/100], Step [16000/6235], Loss: 14.5019\n",
      "Epoch [12/100], Step [16100/6235], Loss: 0.4778\n",
      "Epoch [12/100], Step [16200/6235], Loss: 5.6047\n",
      "Epoch [12/100], Step [16300/6235], Loss: 45.6921\n",
      "Epoch [12/100], Step [16400/6235], Loss: 69.5370\n",
      "Epoch [12/100], Step [16500/6235], Loss: 625.1765\n",
      "Epoch [12/100], Step [16600/6235], Loss: 8.1821\n",
      "Epoch [12/100], Step [16700/6235], Loss: 2.7376\n",
      "Epoch [12/100], Step [16800/6235], Loss: 0.9499\n",
      "Epoch [12/100], Step [16900/6235], Loss: 9.5056\n",
      "Epoch [12/100], Step [17000/6235], Loss: 1.6802\n",
      "Epoch [12/100], Step [17100/6235], Loss: 0.1585\n",
      "Epoch [12/100], Step [17200/6235], Loss: 56.3765\n",
      "Epoch [12/100], Step [17300/6235], Loss: 20.4055\n",
      "Epoch [12/100], Step [17400/6235], Loss: 32.8967\n",
      "Epoch [12/100], Step [17500/6235], Loss: 0.4321\n",
      "Epoch [12/100], Step [17600/6235], Loss: 0.5354\n",
      "Epoch [12/100], Step [17700/6235], Loss: 6.3678\n",
      "Epoch [12/100], Step [17800/6235], Loss: 57.2270\n",
      "Epoch [12/100], Step [17900/6235], Loss: 0.3099\n",
      "Epoch [12/100], Step [18000/6235], Loss: 0.3489\n",
      "Epoch [12/100], Step [18100/6235], Loss: 15.3800\n",
      "Epoch [12/100], Step [18200/6235], Loss: 20.0862\n",
      "Epoch [12/100], Step [18300/6235], Loss: 4.0849\n",
      "Epoch [12/100], Step [18400/6235], Loss: 17.0894\n",
      "Epoch [12/100], Step [18500/6235], Loss: 17.8362\n",
      "Epoch [12/100], Step [18600/6235], Loss: 5.4549\n",
      "Epoch [12/100], Step [18700/6235], Loss: 0.2261\n",
      "Epoch [12/100], Step [18800/6235], Loss: 88.9922\n",
      "Epoch [12/100], Step [18900/6235], Loss: 0.2903\n",
      "Epoch [12/100], Step [19000/6235], Loss: 7.2921\n",
      "Epoch [12/100], Step [19100/6235], Loss: 1.8867\n",
      "Epoch [12/100], Step [19200/6235], Loss: 1.6908\n",
      "Epoch [12/100], Step [19300/6235], Loss: 1.5358\n",
      "Epoch [12/100], Step [19400/6235], Loss: 127.9235\n",
      "Epoch [12/100], Step [19500/6235], Loss: 133.9865\n",
      "Epoch [12/100], Step [19600/6235], Loss: 120.2195\n",
      "Epoch [12/100], Step [19700/6235], Loss: 18.2047\n",
      "Epoch [12/100], Step [19800/6235], Loss: 9.1855\n",
      "Epoch [12/100], Step [19900/6235], Loss: 0.1119\n",
      "Epoch [12/100], Step [20000/6235], Loss: 108.8127\n",
      "Epoch [12/100], Step [20100/6235], Loss: 15.4049\n",
      "Epoch [12/100], Step [20200/6235], Loss: 1.4368\n",
      "Epoch [12/100], Step [20300/6235], Loss: 0.7582\n",
      "Epoch [12/100], Step [20400/6235], Loss: 33.6652\n",
      "Epoch [12/100], Step [20500/6235], Loss: 21.4761\n",
      "Epoch [12/100], Step [20600/6235], Loss: 240.0279\n",
      "Epoch [12/100], Step [20700/6235], Loss: 3.7417\n",
      "Epoch [12/100], Step [20800/6235], Loss: 3.6110\n",
      "Epoch [12/100], Step [20900/6235], Loss: 29.1894\n",
      "Epoch [12/100], Step [21000/6235], Loss: 10.4330\n",
      "Epoch [12/100], Step [21100/6235], Loss: 5.1896\n",
      "Epoch [12/100], Step [21200/6235], Loss: 0.1292\n",
      "Epoch [12/100], Step [21300/6235], Loss: 2.8007\n",
      "Epoch [12/100], Step [21400/6235], Loss: 2.7169\n",
      "Epoch [12/100], Step [21500/6235], Loss: 6.4280\n",
      "Epoch [12/100], Step [21600/6235], Loss: 30.9346\n",
      "Epoch [12/100], Step [21700/6235], Loss: 1.2702\n",
      "Epoch [12/100], Step [21800/6235], Loss: 14.2493\n",
      "Epoch [12/100], Step [21900/6235], Loss: 0.0058\n",
      "Epoch [12/100], Step [22000/6235], Loss: 0.1323\n",
      "Epoch [12/100], Step [22100/6235], Loss: 5.6842\n",
      "Epoch [12/100], Step [22200/6235], Loss: 10.1894\n",
      "Epoch [12/100], Step [22300/6235], Loss: 0.5085\n",
      "Epoch [12/100], Step [22400/6235], Loss: 2.4808\n",
      "Epoch [12/100], Step [22500/6235], Loss: 92.7904\n",
      "Epoch [12/100], Step [22600/6235], Loss: 14.9458\n",
      "Epoch [12/100], Step [22700/6235], Loss: 0.2719\n",
      "Epoch [12/100], Step [22800/6235], Loss: 2.2873\n",
      "Epoch [12/100], Step [22900/6235], Loss: 22.5961\n",
      "Epoch [12/100], Step [23000/6235], Loss: 1.1736\n",
      "Epoch [12/100], Step [23100/6235], Loss: 8.3920\n",
      "Epoch [12/100], Step [23200/6235], Loss: 16.7088\n",
      "Epoch [12/100], Step [23300/6235], Loss: 16.9690\n",
      "Epoch [12/100], Step [23400/6235], Loss: 0.3579\n",
      "Epoch [12/100], Step [23500/6235], Loss: 0.3093\n",
      "Epoch [12/100], Step [23600/6235], Loss: 66.6463\n",
      "Epoch [12/100], Step [23700/6235], Loss: 1.5658\n",
      "Epoch [12/100], Step [23800/6235], Loss: 0.2181\n",
      "Epoch [12/100], Step [23900/6235], Loss: 7.4862\n",
      "Epoch [12/100], Step [24000/6235], Loss: 2.7467\n",
      "Epoch [12/100], Step [24100/6235], Loss: 4.2976\n",
      "Epoch [12/100], Step [24200/6235], Loss: 12.4849\n",
      "Epoch [12/100], Step [24300/6235], Loss: 2.4290\n",
      "Epoch [12/100], Step [24400/6235], Loss: 9.7491\n",
      "Epoch [12/100], Step [24500/6235], Loss: 3.9066\n",
      "Epoch [12/100], Step [24600/6235], Loss: 0.2329\n",
      "Epoch [12/100], Step [24700/6235], Loss: 0.2837\n",
      "Epoch [12/100], Step [24800/6235], Loss: 1.0461\n",
      "Epoch [12/100], Step [24900/6235], Loss: 8.1678\n",
      "Epoch [12/100], Step [25000/6235], Loss: 18.1536\n",
      "Epoch [12/100], Step [25100/6235], Loss: 8.5146\n",
      "Epoch [12/100], Step [25200/6235], Loss: 1.6276\n",
      "Epoch [12/100], Step [25300/6235], Loss: 2.2698\n",
      "Epoch [12/100], Step [25400/6235], Loss: 10.0303\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Step [25500/6235], Loss: 3.6819\n",
      "Epoch [12/100], Step [25600/6235], Loss: 0.7726\n",
      "Epoch [12/100], Step [25700/6235], Loss: 0.1849\n",
      "Epoch [12/100], Step [25800/6235], Loss: 0.1701\n",
      "Epoch [12/100], Step [25900/6235], Loss: 9.5539\n",
      "Epoch [12/100], Step [26000/6235], Loss: 1.5637\n",
      "Epoch [12/100], Step [26100/6235], Loss: 0.7261\n",
      "Epoch [12/100], Step [26200/6235], Loss: 0.0555\n",
      "Epoch [12/100], Step [26300/6235], Loss: 4.8772\n",
      "Epoch [12/100], Step [26400/6235], Loss: 0.0576\n",
      "Epoch [12/100], Step [26500/6235], Loss: 1.0006\n",
      "Epoch [12/100], Step [26600/6235], Loss: 5.6776\n",
      "Epoch [12/100], Step [26700/6235], Loss: 1.1871\n",
      "Epoch [12/100], Step [26800/6235], Loss: 2.5453\n",
      "Epoch [12/100], Step [26900/6235], Loss: 0.3435\n",
      "Epoch [12/100], Step [27000/6235], Loss: 8.2778\n",
      "Epoch [12/100], Step [27100/6235], Loss: 0.5419\n",
      "Epoch [12/100], Step [27200/6235], Loss: 0.2176\n",
      "Epoch [12/100], Step [27300/6235], Loss: 0.0675\n",
      "Epoch [12/100], Step [27400/6235], Loss: 1.4221\n",
      "Epoch [12/100], Step [27500/6235], Loss: 5.1955\n",
      "Epoch [12/100], Step [27600/6235], Loss: 0.3185\n",
      "Epoch [12/100], Step [27700/6235], Loss: 0.1648\n",
      "Epoch [12/100], Step [27800/6235], Loss: 4.1303\n",
      "Epoch [12/100], Step [27900/6235], Loss: 0.5054\n",
      "Epoch [12/100], Step [28000/6235], Loss: 191.6792\n",
      "Epoch [12/100], Step [28100/6235], Loss: 1.2893\n",
      "Epoch [12/100], Step [28200/6235], Loss: 29.5793\n",
      "Epoch [12/100], Step [28300/6235], Loss: 5.7948\n",
      "Epoch [12/100], Step [28400/6235], Loss: 12.9088\n",
      "Epoch [12/100], Step [28500/6235], Loss: 0.5137\n",
      "Epoch [12/100], Step [28600/6235], Loss: 1.4663\n",
      "Epoch [12/100], Step [28700/6235], Loss: 3.4608\n",
      "Epoch [12/100], Step [28800/6235], Loss: 0.1518\n",
      "Epoch [12/100], Step [28900/6235], Loss: 60.4211\n",
      "Epoch [12/100], Step [29000/6235], Loss: 0.4895\n",
      "Epoch [12/100], Step [29100/6235], Loss: 1.5167\n",
      "Epoch [12/100], Step [29200/6235], Loss: 0.3095\n",
      "Epoch [12/100], Step [29300/6235], Loss: 11.8992\n",
      "Epoch [12/100], Step [29400/6235], Loss: 0.3485\n",
      "Epoch [12/100], Step [29500/6235], Loss: 8.7178\n",
      "Epoch [12/100], Step [29600/6235], Loss: 0.7727\n",
      "Epoch [12/100], Step [29700/6235], Loss: 0.2929\n",
      "Epoch [12/100], Step [29800/6235], Loss: 1.6744\n",
      "Epoch [12/100], Step [29900/6235], Loss: 0.1103\n",
      "Epoch [12/100], Step [30000/6235], Loss: 7.9369\n",
      "Epoch [12/100], Step [30100/6235], Loss: 3.8906\n",
      "Epoch [12/100], Step [30200/6235], Loss: 0.0580\n",
      "Epoch [12/100], Step [30300/6235], Loss: 1.0432\n",
      "Epoch [12/100], Step [30400/6235], Loss: 0.0888\n",
      "Epoch [12/100], Step [30500/6235], Loss: 0.8653\n",
      "Epoch [12/100], Step [30600/6235], Loss: 0.0541\n",
      "Epoch [12/100], Step [30700/6235], Loss: 0.5185\n",
      "Epoch [12/100], Step [30800/6235], Loss: 0.1521\n",
      "Epoch [12/100], Step [30900/6235], Loss: 1.4676\n",
      "Epoch [12/100], Step [31000/6235], Loss: 0.1522\n",
      "Epoch [12/100], Step [31100/6235], Loss: 0.0693\n",
      "Epoch [12/100], Step [31200/6235], Loss: 9.7560\n",
      "Epoch [12/100], Step [31300/6235], Loss: 1.4894\n",
      "Epoch [12/100], Step [31400/6235], Loss: 8.1897\n",
      "Epoch [12/100], Step [31500/6235], Loss: 0.2296\n",
      "Epoch [12/100], Step [31600/6235], Loss: 0.7441\n",
      "Epoch [12/100], Step [31700/6235], Loss: 2.3641\n",
      "Epoch [12/100], Step [31800/6235], Loss: 1.1182\n",
      "Epoch [12/100], Step [31900/6235], Loss: 2029.5488\n",
      "Epoch [12/100], Step [32000/6235], Loss: 18.0505\n",
      "Epoch [12/100], Step [32100/6235], Loss: 8.6463\n",
      "Epoch [12/100], Step [32200/6235], Loss: 102.8351\n",
      "Epoch [12/100], Step [32300/6235], Loss: 0.5876\n",
      "Epoch [12/100], Step [32400/6235], Loss: 0.1669\n",
      "Epoch [12/100], Step [32500/6235], Loss: 21.7744\n",
      "Epoch [12/100], Step [32600/6235], Loss: 0.8812\n",
      "Epoch [12/100], Step [32700/6235], Loss: 32.8277\n",
      "Epoch [12/100], Step [32800/6235], Loss: 0.1602\n",
      "Epoch [12/100], Step [32900/6235], Loss: 15.5657\n",
      "Epoch [12/100], Step [33000/6235], Loss: 0.2267\n",
      "Epoch [12/100], Step [33100/6235], Loss: 0.3368\n",
      "Epoch [12/100], Step [33200/6235], Loss: 4.3489\n",
      "Epoch [12/100], Step [33300/6235], Loss: 4.3050\n",
      "Epoch [12/100], Step [33400/6235], Loss: 124.6452\n",
      "Epoch [12/100], Step [33500/6235], Loss: 0.2682\n",
      "Epoch [12/100], Step [33600/6235], Loss: 0.8995\n",
      "Epoch [12/100], Step [33700/6235], Loss: 0.4321\n",
      "Epoch [12/100], Step [33800/6235], Loss: 8.2132\n",
      "Epoch [12/100], Step [33900/6235], Loss: 27.7422\n",
      "Epoch [12/100], Step [34000/6235], Loss: 0.0116\n",
      "Epoch [12/100], Step [34100/6235], Loss: 0.1409\n",
      "Epoch [12/100], Step [34200/6235], Loss: 16.5642\n",
      "Epoch [12/100], Step [34300/6235], Loss: 1.6729\n",
      "Epoch [12/100], Step [34400/6235], Loss: 0.0884\n",
      "Epoch [12/100], Step [34500/6235], Loss: 126.3929\n",
      "Epoch [12/100], Step [34600/6235], Loss: 1.5225\n",
      "Epoch [12/100], Step [34700/6235], Loss: 40.6059\n",
      "Epoch [12/100], Step [34800/6235], Loss: 12.6953\n",
      "Epoch [12/100], Step [34900/6235], Loss: 38.8489\n",
      "Epoch [12/100], Step [35000/6235], Loss: 0.7549\n",
      "Epoch [12/100], Step [35100/6235], Loss: 3.7380\n",
      "Epoch [12/100], Step [35200/6235], Loss: 6.3480\n",
      "Epoch [12/100], Step [35300/6235], Loss: 2.1705\n",
      "Epoch [12/100], Step [35400/6235], Loss: 0.5076\n",
      "Epoch [12/100], Step [35500/6235], Loss: 0.3968\n",
      "Epoch [12/100], Step [35600/6235], Loss: 11.3078\n",
      "Epoch [12/100], Step [35700/6235], Loss: 9.2089\n",
      "Epoch [12/100], Step [35800/6235], Loss: 0.9067\n",
      "Epoch [12/100], Step [35900/6235], Loss: 0.3131\n",
      "Epoch [12/100], Step [36000/6235], Loss: 1.8882\n",
      "Epoch [12/100], Step [36100/6235], Loss: 6.1707\n",
      "Epoch [12/100], Step [36200/6235], Loss: 23.5981\n",
      "Epoch [12/100], Step [36300/6235], Loss: 0.1807\n",
      "Epoch [12/100], Step [36400/6235], Loss: 0.0256\n",
      "Epoch [12/100], Step [36500/6235], Loss: 12.0404\n",
      "Epoch [12/100], Step [36600/6235], Loss: 0.7513\n",
      "Epoch [12/100], Step [36700/6235], Loss: 0.8580\n",
      "Epoch [12/100], Step [36800/6235], Loss: 30.9278\n",
      "Epoch [12/100], Step [36900/6235], Loss: 3.5859\n",
      "Epoch [12/100], Step [37000/6235], Loss: 1.0654\n",
      "Epoch [12/100], Step [37100/6235], Loss: 1.3615\n",
      "Epoch [12/100], Step [37200/6235], Loss: 0.0452\n",
      "Epoch [12/100], Step [37300/6235], Loss: 0.6942\n",
      "Epoch [12/100], Step [37400/6235], Loss: 0.8497\n",
      "Epoch [12/100], Step [37500/6235], Loss: 2.2815\n",
      "Epoch [12/100], Step [37600/6235], Loss: 5.6218\n",
      "Epoch [12/100], Step [37700/6235], Loss: 0.3886\n",
      "Epoch [12/100], Step [37800/6235], Loss: 1.0358\n",
      "Epoch [12/100], Step [37900/6235], Loss: 2.8889\n",
      "Epoch [12/100], Step [38000/6235], Loss: 0.4231\n",
      "Epoch [12/100], Step [38100/6235], Loss: 8.5742\n",
      "Epoch [12/100], Step [38200/6235], Loss: 1.5825\n",
      "Epoch [12/100], Step [38300/6235], Loss: 5.8790\n",
      "Epoch [12/100], Step [38400/6235], Loss: 0.0739\n",
      "Epoch [12/100], Step [38500/6235], Loss: 1.4751\n",
      "Epoch [12/100], Step [38600/6235], Loss: 8.7585\n",
      "Epoch [12/100], Step [38700/6235], Loss: 0.2109\n",
      "Epoch [12/100], Step [38800/6235], Loss: 1.4841\n",
      "Epoch [12/100], Step [38900/6235], Loss: 28.4660\n",
      "Epoch [12/100], Step [39000/6235], Loss: 9.5471\n",
      "Epoch [12/100], Step [39100/6235], Loss: 10.1400\n",
      "Epoch [12/100], Step [39200/6235], Loss: 7.5591\n",
      "Epoch [12/100], Step [39300/6235], Loss: 74.3574\n",
      "Epoch [12/100], Step [39400/6235], Loss: 20.8485\n",
      "Epoch [12/100], Step [39500/6235], Loss: 358.8151\n",
      "Epoch [12/100], Step [39600/6235], Loss: 5.0154\n",
      "Epoch [12/100], Step [39700/6235], Loss: 79.8879\n",
      "Epoch [12/100], Step [39800/6235], Loss: 100.7812\n",
      "Epoch [12/100], Step [39900/6235], Loss: 0.2249\n",
      "Epoch [12/100], Step [40000/6235], Loss: 21.2233\n",
      "Epoch [12/100], Step [40100/6235], Loss: 28.4247\n",
      "Epoch [12/100], Step [40200/6235], Loss: 1.6098\n",
      "Epoch [12/100], Step [40300/6235], Loss: 0.7162\n",
      "Epoch [12/100], Step [40400/6235], Loss: 2.2136\n",
      "Epoch [12/100], Step [40500/6235], Loss: 2.4347\n",
      "Epoch [12/100], Step [40600/6235], Loss: 0.2482\n",
      "Epoch [12/100], Step [40700/6235], Loss: 7.7761\n",
      "Epoch [12/100], Step [40800/6235], Loss: 1.8326\n",
      "Epoch [12/100], Step [40900/6235], Loss: 0.0623\n",
      "Epoch [12/100], Step [41000/6235], Loss: 19.5746\n",
      "Epoch [12/100], Step [41100/6235], Loss: 31.4984\n",
      "Epoch [12/100], Step [41200/6235], Loss: 43.3419\n",
      "Epoch [12/100], Step [41300/6235], Loss: 4.1322\n",
      "Epoch [12/100], Step [41400/6235], Loss: 0.0503\n",
      "Epoch [12/100], Step [41500/6235], Loss: 1.2641\n",
      "Epoch [12/100], Step [41600/6235], Loss: 0.0215\n",
      "Epoch [12/100], Step [41700/6235], Loss: 0.4206\n",
      "Epoch [12/100], Step [41800/6235], Loss: 1.3311\n",
      "Epoch [12/100], Step [41900/6235], Loss: 3.4510\n",
      "Epoch [12/100], Step [42000/6235], Loss: 1.9872\n",
      "Epoch [12/100], Step [42100/6235], Loss: 5.2345\n",
      "Epoch [12/100], Step [42200/6235], Loss: 51.8252\n",
      "Epoch [12/100], Step [42300/6235], Loss: 3.2256\n",
      "Epoch [12/100], Step [42400/6235], Loss: 3.5845\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [12/100], Step [42500/6235], Loss: 1.7881\n",
      "Epoch [12/100], Step [42600/6235], Loss: 0.4532\n",
      "Epoch [12/100], Step [42700/6235], Loss: 0.1877\n",
      "Epoch [12/100], Step [42800/6235], Loss: 0.5286\n",
      "Epoch [12/100], Step [42900/6235], Loss: 4.0824\n",
      "Epoch [12/100], Step [43000/6235], Loss: 0.4054\n",
      "Epoch [12/100], Step [43100/6235], Loss: 2.0975\n",
      "Epoch [12/100], Step [43200/6235], Loss: 0.3877\n",
      "Epoch [12/100], Step [43300/6235], Loss: 10.5275\n",
      "Epoch [12/100], Step [43400/6235], Loss: 10.4366\n",
      "Epoch [12/100], Step [43500/6235], Loss: 9.1942\n",
      "Epoch [12/100], Step [43600/6235], Loss: 27.4717\n",
      "Epoch [12/100], Step [43700/6235], Loss: 48.0741\n",
      "Epoch [12/100], Step [43800/6235], Loss: 0.9773\n",
      "Epoch [12/100], Step [43900/6235], Loss: 2.8443\n",
      "Epoch [12/100], Step [44000/6235], Loss: 47.3084\n",
      "Epoch [12/100], Step [44100/6235], Loss: 1.6051\n",
      "Epoch [12/100], Step [44200/6235], Loss: 27.3800\n",
      "Epoch [12/100], Step [44300/6235], Loss: 3.5705\n",
      "Epoch [12/100], Step [44400/6235], Loss: 0.5865\n",
      "Epoch [12/100], Step [44500/6235], Loss: 1.2357\n",
      "Epoch [12/100], Step [44600/6235], Loss: 22.8186\n",
      "Epoch [12/100], Step [44700/6235], Loss: 2.0653\n",
      "Epoch [12/100], Step [44800/6235], Loss: 5.0729\n",
      "Epoch [12/100], Step [44900/6235], Loss: 4.2772\n",
      "Epoch [12/100], Step [45000/6235], Loss: 4.8448\n",
      "Epoch [12/100], Step [45100/6235], Loss: 59.7012\n",
      "Epoch [12/100], Step [45200/6235], Loss: 0.7265\n",
      "Epoch [12/100], Step [45300/6235], Loss: 26.8820\n",
      "Epoch [12/100], Step [45400/6235], Loss: 11.7672\n",
      "Epoch [12/100], Step [45500/6235], Loss: 0.8550\n",
      "Epoch [12/100], Step [45600/6235], Loss: 0.2765\n",
      "Epoch [12/100], Step [45700/6235], Loss: 128.9741\n",
      "Epoch [12/100], Step [45800/6235], Loss: 365.2371\n",
      "Epoch [12/100], Step [45900/6235], Loss: 120.5107\n",
      "Epoch [12/100], Step [46000/6235], Loss: 26.6460\n",
      "Epoch [12/100], Step [46100/6235], Loss: 16.8387\n",
      "Epoch [12/100], Step [46200/6235], Loss: 86.3673\n",
      "Epoch [12/100], Step [46300/6235], Loss: 23.2561\n",
      "Epoch [12/100], Step [46400/6235], Loss: 8.3942\n",
      "Epoch [12/100], Step [46500/6235], Loss: 417.7021\n",
      "Epoch [12/100], Step [46600/6235], Loss: 12.6116\n",
      "Epoch [12/100], Step [46700/6235], Loss: 11.9541\n",
      "Epoch [12/100], Step [46800/6235], Loss: 3.8704\n",
      "Epoch [12/100], Step [46900/6235], Loss: 2.4080\n",
      "Epoch [12/100], Step [47000/6235], Loss: 7.2815\n",
      "Epoch [12/100], Step [47100/6235], Loss: 3.0467\n",
      "Epoch [12/100], Step [47200/6235], Loss: 5.3429\n",
      "Epoch [12/100], Step [47300/6235], Loss: 0.3359\n",
      "Epoch [12/100], Step [47400/6235], Loss: 43.6710\n",
      "Epoch [12/100], Step [47500/6235], Loss: 1.1917\n",
      "Epoch [12/100], Step [47600/6235], Loss: 1.5907\n",
      "Epoch [12/100], Step [47700/6235], Loss: 4.7542\n",
      "Epoch [12/100], Step [47800/6235], Loss: 1.4307\n",
      "Epoch [12/100], Step [47900/6235], Loss: 23.2108\n",
      "Epoch [12/100], Step [48000/6235], Loss: 90.3459\n",
      "Epoch [12/100], Step [48100/6235], Loss: 3.0145\n",
      "Epoch [12/100], Step [48200/6235], Loss: 10.8939\n",
      "Epoch [12/100], Step [48300/6235], Loss: 111.5894\n",
      "Epoch [12/100], Step [48400/6235], Loss: 46.3914\n",
      "Epoch [12/100], Step [48500/6235], Loss: 6.3118\n",
      "Epoch [12/100], Step [48600/6235], Loss: 123.2900\n",
      "Epoch [12/100], Step [48700/6235], Loss: 98.0970\n",
      "Epoch [12/100], Step [48800/6235], Loss: 253.6094\n",
      "Epoch [12/100], Step [48900/6235], Loss: 16.5185\n",
      "Epoch [12/100], Step [49000/6235], Loss: 278.2067\n",
      "Epoch [12/100], Step [49100/6235], Loss: 1054.6941\n",
      "Epoch [12/100], Step [49200/6235], Loss: 546.0777\n",
      "Epoch [12/100], Step [49300/6235], Loss: 1291.0818\n",
      "Epoch [12/100], Step [49400/6235], Loss: 2.2829\n",
      "Epoch [12/100], Step [49500/6235], Loss: 28.3732\n",
      "Epoch [12/100], Step [49600/6235], Loss: 58.5589\n",
      "Epoch [12/100], Step [49700/6235], Loss: 661.7796\n",
      "Epoch [12/100], Step [49800/6235], Loss: 707.4912\n",
      "Epoch [13/100], Step [100/6235], Loss: 45.0178\n",
      "Epoch [13/100], Step [200/6235], Loss: 0.0939\n",
      "Epoch [13/100], Step [300/6235], Loss: 0.0492\n",
      "Epoch [13/100], Step [400/6235], Loss: 0.0057\n",
      "Epoch [13/100], Step [500/6235], Loss: 6.8941\n",
      "Epoch [13/100], Step [600/6235], Loss: 0.0459\n",
      "Epoch [13/100], Step [700/6235], Loss: 0.2721\n",
      "Epoch [13/100], Step [800/6235], Loss: 0.0706\n",
      "Epoch [13/100], Step [900/6235], Loss: 0.0297\n",
      "Epoch [13/100], Step [1000/6235], Loss: 0.0232\n",
      "Epoch [13/100], Step [1100/6235], Loss: 0.0095\n",
      "Epoch [13/100], Step [1200/6235], Loss: 0.1323\n",
      "Epoch [13/100], Step [1300/6235], Loss: 0.0624\n",
      "Epoch [13/100], Step [1400/6235], Loss: 0.0333\n",
      "Epoch [13/100], Step [1500/6235], Loss: 0.0020\n",
      "Epoch [13/100], Step [1600/6235], Loss: 0.2040\n",
      "Epoch [13/100], Step [1700/6235], Loss: 0.0380\n",
      "Epoch [13/100], Step [1800/6235], Loss: 0.2211\n",
      "Epoch [13/100], Step [1900/6235], Loss: 0.8401\n",
      "Epoch [13/100], Step [2000/6235], Loss: 2.1513\n",
      "Epoch [13/100], Step [2100/6235], Loss: 1.0743\n",
      "Epoch [13/100], Step [2200/6235], Loss: 11.6140\n",
      "Epoch [13/100], Step [2300/6235], Loss: 30.5413\n",
      "Epoch [13/100], Step [2400/6235], Loss: 15.8688\n",
      "Epoch [13/100], Step [2500/6235], Loss: 40.8339\n",
      "Epoch [13/100], Step [2600/6235], Loss: 6.4941\n",
      "Epoch [13/100], Step [2700/6235], Loss: 50.5578\n",
      "Epoch [13/100], Step [2800/6235], Loss: 296.0764\n",
      "Epoch [13/100], Step [2900/6235], Loss: 6.9619\n",
      "Epoch [13/100], Step [3000/6235], Loss: 0.9633\n",
      "Epoch [13/100], Step [3100/6235], Loss: 45.2819\n",
      "Epoch [13/100], Step [3200/6235], Loss: 64.9587\n",
      "Epoch [13/100], Step [3300/6235], Loss: 0.2091\n",
      "Epoch [13/100], Step [3400/6235], Loss: 2.7616\n",
      "Epoch [13/100], Step [3500/6235], Loss: 37.1155\n",
      "Epoch [13/100], Step [3600/6235], Loss: 10.4171\n",
      "Epoch [13/100], Step [3700/6235], Loss: 1.4677\n",
      "Epoch [13/100], Step [3800/6235], Loss: 0.4632\n",
      "Epoch [13/100], Step [3900/6235], Loss: 0.5930\n",
      "Epoch [13/100], Step [4000/6235], Loss: 0.1538\n",
      "Epoch [13/100], Step [4100/6235], Loss: 2.8157\n",
      "Epoch [13/100], Step [4200/6235], Loss: 0.4602\n",
      "Epoch [13/100], Step [4300/6235], Loss: 9.8771\n",
      "Epoch [13/100], Step [4400/6235], Loss: 0.5197\n",
      "Epoch [13/100], Step [4500/6235], Loss: 76.7805\n",
      "Epoch [13/100], Step [4600/6235], Loss: 18.8189\n",
      "Epoch [13/100], Step [4700/6235], Loss: 2.4128\n",
      "Epoch [13/100], Step [4800/6235], Loss: 2.6107\n",
      "Epoch [13/100], Step [4900/6235], Loss: 0.0799\n",
      "Epoch [13/100], Step [5000/6235], Loss: 0.8949\n",
      "Epoch [13/100], Step [5100/6235], Loss: 5.1169\n",
      "Epoch [13/100], Step [5200/6235], Loss: 5.4324\n",
      "Epoch [13/100], Step [5300/6235], Loss: 33.8789\n",
      "Epoch [13/100], Step [5400/6235], Loss: 2.5038\n",
      "Epoch [13/100], Step [5500/6235], Loss: 0.4631\n",
      "Epoch [13/100], Step [5600/6235], Loss: 0.0486\n",
      "Epoch [13/100], Step [5700/6235], Loss: 0.1136\n",
      "Epoch [13/100], Step [5800/6235], Loss: 2.1149\n",
      "Epoch [13/100], Step [5900/6235], Loss: 1.0680\n",
      "Epoch [13/100], Step [6000/6235], Loss: 0.3675\n",
      "Epoch [13/100], Step [6100/6235], Loss: 0.1961\n",
      "Epoch [13/100], Step [6200/6235], Loss: 0.1461\n",
      "Epoch [13/100], Step [6300/6235], Loss: 0.2337\n",
      "Epoch [13/100], Step [6400/6235], Loss: 0.1295\n",
      "Epoch [13/100], Step [6500/6235], Loss: 0.3632\n",
      "Epoch [13/100], Step [6600/6235], Loss: 0.9116\n",
      "Epoch [13/100], Step [6700/6235], Loss: 0.9661\n",
      "Epoch [13/100], Step [6800/6235], Loss: 2.4267\n",
      "Epoch [13/100], Step [6900/6235], Loss: 1.6372\n",
      "Epoch [13/100], Step [7000/6235], Loss: 0.0493\n",
      "Epoch [13/100], Step [7100/6235], Loss: 0.2636\n",
      "Epoch [13/100], Step [7200/6235], Loss: 1.0051\n",
      "Epoch [13/100], Step [7300/6235], Loss: 2.3161\n",
      "Epoch [13/100], Step [7400/6235], Loss: 0.0234\n",
      "Epoch [13/100], Step [7500/6235], Loss: 13.9338\n",
      "Epoch [13/100], Step [7600/6235], Loss: 6.9415\n",
      "Epoch [13/100], Step [7700/6235], Loss: 3.9294\n",
      "Epoch [13/100], Step [7800/6235], Loss: 2.8198\n",
      "Epoch [13/100], Step [7900/6235], Loss: 13.8964\n",
      "Epoch [13/100], Step [8000/6235], Loss: 0.2840\n",
      "Epoch [13/100], Step [8100/6235], Loss: 4.5242\n",
      "Epoch [13/100], Step [8200/6235], Loss: 14.7412\n",
      "Epoch [13/100], Step [8300/6235], Loss: 58.2152\n",
      "Epoch [13/100], Step [8400/6235], Loss: 49.7260\n",
      "Epoch [13/100], Step [8500/6235], Loss: 71.4447\n",
      "Epoch [13/100], Step [8600/6235], Loss: 3.3604\n",
      "Epoch [13/100], Step [8700/6235], Loss: 36.2855\n",
      "Epoch [13/100], Step [8800/6235], Loss: 350.7828\n",
      "Epoch [13/100], Step [8900/6235], Loss: 129.2782\n",
      "Epoch [13/100], Step [9000/6235], Loss: 430.6779\n",
      "Epoch [13/100], Step [9100/6235], Loss: 594.4718\n",
      "Epoch [13/100], Step [9200/6235], Loss: 3573.6191\n",
      "Epoch [13/100], Step [9300/6235], Loss: 149.8607\n",
      "Epoch [13/100], Step [9400/6235], Loss: 35.2304\n",
      "Epoch [13/100], Step [9500/6235], Loss: 9.5796\n",
      "Epoch [13/100], Step [9600/6235], Loss: 54.2916\n",
      "Epoch [13/100], Step [9700/6235], Loss: 102.6215\n",
      "Epoch [13/100], Step [9800/6235], Loss: 364.9402\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Step [9900/6235], Loss: 3.4514\n",
      "Epoch [13/100], Step [10000/6235], Loss: 34.3291\n",
      "Epoch [13/100], Step [10100/6235], Loss: 13.3124\n",
      "Epoch [13/100], Step [10200/6235], Loss: 444.8066\n",
      "Epoch [13/100], Step [10300/6235], Loss: 0.5521\n",
      "Epoch [13/100], Step [10400/6235], Loss: 0.7035\n",
      "Epoch [13/100], Step [10500/6235], Loss: 5.8727\n",
      "Epoch [13/100], Step [10600/6235], Loss: 2025.4603\n",
      "Epoch [13/100], Step [10700/6235], Loss: 39.0701\n",
      "Epoch [13/100], Step [10800/6235], Loss: 107.7721\n",
      "Epoch [13/100], Step [10900/6235], Loss: 2.0914\n",
      "Epoch [13/100], Step [11000/6235], Loss: 160.2610\n",
      "Epoch [13/100], Step [11100/6235], Loss: 14.0303\n",
      "Epoch [13/100], Step [11200/6235], Loss: 98.0774\n",
      "Epoch [13/100], Step [11300/6235], Loss: 236.3024\n",
      "Epoch [13/100], Step [11400/6235], Loss: 166.0518\n",
      "Epoch [13/100], Step [11500/6235], Loss: 14.1236\n",
      "Epoch [13/100], Step [11600/6235], Loss: 5.5627\n",
      "Epoch [13/100], Step [11700/6235], Loss: 155.2575\n",
      "Epoch [13/100], Step [11800/6235], Loss: 3.4000\n",
      "Epoch [13/100], Step [11900/6235], Loss: 876.9415\n",
      "Epoch [13/100], Step [12000/6235], Loss: 211.7542\n",
      "Epoch [13/100], Step [12100/6235], Loss: 408.6452\n",
      "Epoch [13/100], Step [12200/6235], Loss: 33.7449\n",
      "Epoch [13/100], Step [12300/6235], Loss: 4.8842\n",
      "Epoch [13/100], Step [12400/6235], Loss: 83.2845\n",
      "Epoch [13/100], Step [12500/6235], Loss: 253.7636\n",
      "Epoch [13/100], Step [12600/6235], Loss: 15.4247\n",
      "Epoch [13/100], Step [12700/6235], Loss: 13.3024\n",
      "Epoch [13/100], Step [12800/6235], Loss: 23.2771\n",
      "Epoch [13/100], Step [12900/6235], Loss: 71.6724\n",
      "Epoch [13/100], Step [13000/6235], Loss: 0.6523\n",
      "Epoch [13/100], Step [13100/6235], Loss: 106.3503\n",
      "Epoch [13/100], Step [13200/6235], Loss: 30.9699\n",
      "Epoch [13/100], Step [13300/6235], Loss: 17.3805\n",
      "Epoch [13/100], Step [13400/6235], Loss: 33.1458\n",
      "Epoch [13/100], Step [13500/6235], Loss: 4.5217\n",
      "Epoch [13/100], Step [13600/6235], Loss: 9.1612\n",
      "Epoch [13/100], Step [13700/6235], Loss: 145.1438\n",
      "Epoch [13/100], Step [13800/6235], Loss: 73.1400\n",
      "Epoch [13/100], Step [13900/6235], Loss: 37.9859\n",
      "Epoch [13/100], Step [14000/6235], Loss: 1.8609\n",
      "Epoch [13/100], Step [14100/6235], Loss: 2.5697\n",
      "Epoch [13/100], Step [14200/6235], Loss: 52.7212\n",
      "Epoch [13/100], Step [14300/6235], Loss: 37.5488\n",
      "Epoch [13/100], Step [14400/6235], Loss: 8.7049\n",
      "Epoch [13/100], Step [14500/6235], Loss: 14.1785\n",
      "Epoch [13/100], Step [14600/6235], Loss: 1.9600\n",
      "Epoch [13/100], Step [14700/6235], Loss: 10.6726\n",
      "Epoch [13/100], Step [14800/6235], Loss: 17.3422\n",
      "Epoch [13/100], Step [14900/6235], Loss: 0.5532\n",
      "Epoch [13/100], Step [15000/6235], Loss: 0.1811\n",
      "Epoch [13/100], Step [15100/6235], Loss: 0.0740\n",
      "Epoch [13/100], Step [15200/6235], Loss: 65.5370\n",
      "Epoch [13/100], Step [15300/6235], Loss: 1.7860\n",
      "Epoch [13/100], Step [15400/6235], Loss: 32.8763\n",
      "Epoch [13/100], Step [15500/6235], Loss: 22.2524\n",
      "Epoch [13/100], Step [15600/6235], Loss: 269.0040\n",
      "Epoch [13/100], Step [15700/6235], Loss: 14.7830\n",
      "Epoch [13/100], Step [15800/6235], Loss: 7.7370\n",
      "Epoch [13/100], Step [15900/6235], Loss: 2.2293\n",
      "Epoch [13/100], Step [16000/6235], Loss: 48.4657\n",
      "Epoch [13/100], Step [16100/6235], Loss: 1.4398\n",
      "Epoch [13/100], Step [16200/6235], Loss: 12.0545\n",
      "Epoch [13/100], Step [16300/6235], Loss: 29.2270\n",
      "Epoch [13/100], Step [16400/6235], Loss: 45.2123\n",
      "Epoch [13/100], Step [16500/6235], Loss: 573.8013\n",
      "Epoch [13/100], Step [16600/6235], Loss: 9.8494\n",
      "Epoch [13/100], Step [16700/6235], Loss: 2.1926\n",
      "Epoch [13/100], Step [16800/6235], Loss: 1.5084\n",
      "Epoch [13/100], Step [16900/6235], Loss: 6.2126\n",
      "Epoch [13/100], Step [17000/6235], Loss: 0.7736\n",
      "Epoch [13/100], Step [17100/6235], Loss: 0.3145\n",
      "Epoch [13/100], Step [17200/6235], Loss: 81.1231\n",
      "Epoch [13/100], Step [17300/6235], Loss: 33.1968\n",
      "Epoch [13/100], Step [17400/6235], Loss: 30.2080\n",
      "Epoch [13/100], Step [17500/6235], Loss: 0.5235\n",
      "Epoch [13/100], Step [17600/6235], Loss: 0.2831\n",
      "Epoch [13/100], Step [17700/6235], Loss: 65.2681\n",
      "Epoch [13/100], Step [17800/6235], Loss: 52.5824\n",
      "Epoch [13/100], Step [17900/6235], Loss: 6.3000\n",
      "Epoch [13/100], Step [18000/6235], Loss: 0.7043\n",
      "Epoch [13/100], Step [18100/6235], Loss: 5.9071\n",
      "Epoch [13/100], Step [18200/6235], Loss: 12.8925\n",
      "Epoch [13/100], Step [18300/6235], Loss: 9.0943\n",
      "Epoch [13/100], Step [18400/6235], Loss: 2.6087\n",
      "Epoch [13/100], Step [18500/6235], Loss: 1.4619\n",
      "Epoch [13/100], Step [18600/6235], Loss: 2.3955\n",
      "Epoch [13/100], Step [18700/6235], Loss: 0.2055\n",
      "Epoch [13/100], Step [18800/6235], Loss: 115.1390\n",
      "Epoch [13/100], Step [18900/6235], Loss: 72.6072\n",
      "Epoch [13/100], Step [19000/6235], Loss: 3.0693\n",
      "Epoch [13/100], Step [19100/6235], Loss: 1.5293\n",
      "Epoch [13/100], Step [19200/6235], Loss: 2.4689\n",
      "Epoch [13/100], Step [19300/6235], Loss: 1.1154\n",
      "Epoch [13/100], Step [19400/6235], Loss: 129.0627\n",
      "Epoch [13/100], Step [19500/6235], Loss: 205.7223\n",
      "Epoch [13/100], Step [19600/6235], Loss: 61.9203\n",
      "Epoch [13/100], Step [19700/6235], Loss: 13.0442\n",
      "Epoch [13/100], Step [19800/6235], Loss: 0.9957\n",
      "Epoch [13/100], Step [19900/6235], Loss: 1.4759\n",
      "Epoch [13/100], Step [20000/6235], Loss: 83.9822\n",
      "Epoch [13/100], Step [20100/6235], Loss: 5.9938\n",
      "Epoch [13/100], Step [20200/6235], Loss: 5.6923\n",
      "Epoch [13/100], Step [20300/6235], Loss: 1.9111\n",
      "Epoch [13/100], Step [20400/6235], Loss: 28.1471\n",
      "Epoch [13/100], Step [20500/6235], Loss: 25.8493\n",
      "Epoch [13/100], Step [20600/6235], Loss: 133.0271\n",
      "Epoch [13/100], Step [20700/6235], Loss: 5.5741\n",
      "Epoch [13/100], Step [20800/6235], Loss: 2.8509\n",
      "Epoch [13/100], Step [20900/6235], Loss: 19.3079\n",
      "Epoch [13/100], Step [21000/6235], Loss: 8.6680\n",
      "Epoch [13/100], Step [21100/6235], Loss: 1.7060\n",
      "Epoch [13/100], Step [21200/6235], Loss: 0.6128\n",
      "Epoch [13/100], Step [21300/6235], Loss: 0.2140\n",
      "Epoch [13/100], Step [21400/6235], Loss: 3.8595\n",
      "Epoch [13/100], Step [21500/6235], Loss: 1.8984\n",
      "Epoch [13/100], Step [21600/6235], Loss: 32.3292\n",
      "Epoch [13/100], Step [21700/6235], Loss: 0.2420\n",
      "Epoch [13/100], Step [21800/6235], Loss: 0.1916\n",
      "Epoch [13/100], Step [21900/6235], Loss: 0.1268\n",
      "Epoch [13/100], Step [22000/6235], Loss: 3.0149\n",
      "Epoch [13/100], Step [22100/6235], Loss: 3.6789\n",
      "Epoch [13/100], Step [22200/6235], Loss: 3.1832\n",
      "Epoch [13/100], Step [22300/6235], Loss: 4.5553\n",
      "Epoch [13/100], Step [22400/6235], Loss: 18.9632\n",
      "Epoch [13/100], Step [22500/6235], Loss: 201.5272\n",
      "Epoch [13/100], Step [22600/6235], Loss: 30.3294\n",
      "Epoch [13/100], Step [22700/6235], Loss: 1.8620\n",
      "Epoch [13/100], Step [22800/6235], Loss: 10.9124\n",
      "Epoch [13/100], Step [22900/6235], Loss: 21.9471\n",
      "Epoch [13/100], Step [23000/6235], Loss: 10.3809\n",
      "Epoch [13/100], Step [23100/6235], Loss: 4.8998\n",
      "Epoch [13/100], Step [23200/6235], Loss: 9.6958\n",
      "Epoch [13/100], Step [23300/6235], Loss: 20.2201\n",
      "Epoch [13/100], Step [23400/6235], Loss: 2.4823\n",
      "Epoch [13/100], Step [23500/6235], Loss: 0.0837\n",
      "Epoch [13/100], Step [23600/6235], Loss: 120.4380\n",
      "Epoch [13/100], Step [23700/6235], Loss: 7.0224\n",
      "Epoch [13/100], Step [23800/6235], Loss: 0.9601\n",
      "Epoch [13/100], Step [23900/6235], Loss: 4.0521\n",
      "Epoch [13/100], Step [24000/6235], Loss: 0.3807\n",
      "Epoch [13/100], Step [24100/6235], Loss: 0.1360\n",
      "Epoch [13/100], Step [24200/6235], Loss: 7.2716\n",
      "Epoch [13/100], Step [24300/6235], Loss: 1.6151\n",
      "Epoch [13/100], Step [24400/6235], Loss: 7.2492\n",
      "Epoch [13/100], Step [24500/6235], Loss: 3.1201\n",
      "Epoch [13/100], Step [24600/6235], Loss: 0.2565\n",
      "Epoch [13/100], Step [24700/6235], Loss: 4.3990\n",
      "Epoch [13/100], Step [24800/6235], Loss: 0.0828\n",
      "Epoch [13/100], Step [24900/6235], Loss: 10.1226\n",
      "Epoch [13/100], Step [25000/6235], Loss: 18.6418\n",
      "Epoch [13/100], Step [25100/6235], Loss: 8.8465\n",
      "Epoch [13/100], Step [25200/6235], Loss: 1.4807\n",
      "Epoch [13/100], Step [25300/6235], Loss: 0.5772\n",
      "Epoch [13/100], Step [25400/6235], Loss: 9.0251\n",
      "Epoch [13/100], Step [25500/6235], Loss: 8.7956\n",
      "Epoch [13/100], Step [25600/6235], Loss: 5.5776\n",
      "Epoch [13/100], Step [25700/6235], Loss: 0.1453\n",
      "Epoch [13/100], Step [25800/6235], Loss: 0.1018\n",
      "Epoch [13/100], Step [25900/6235], Loss: 5.2416\n",
      "Epoch [13/100], Step [26000/6235], Loss: 1.4715\n",
      "Epoch [13/100], Step [26100/6235], Loss: 0.1296\n",
      "Epoch [13/100], Step [26200/6235], Loss: 0.6680\n",
      "Epoch [13/100], Step [26300/6235], Loss: 5.0815\n",
      "Epoch [13/100], Step [26400/6235], Loss: 0.0982\n",
      "Epoch [13/100], Step [26500/6235], Loss: 0.0384\n",
      "Epoch [13/100], Step [26600/6235], Loss: 1.5888\n",
      "Epoch [13/100], Step [26700/6235], Loss: 0.4139\n",
      "Epoch [13/100], Step [26800/6235], Loss: 0.2520\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Step [26900/6235], Loss: 0.0027\n",
      "Epoch [13/100], Step [27000/6235], Loss: 15.0370\n",
      "Epoch [13/100], Step [27100/6235], Loss: 0.0441\n",
      "Epoch [13/100], Step [27200/6235], Loss: 0.0181\n",
      "Epoch [13/100], Step [27300/6235], Loss: 0.2151\n",
      "Epoch [13/100], Step [27400/6235], Loss: 0.8013\n",
      "Epoch [13/100], Step [27500/6235], Loss: 12.9788\n",
      "Epoch [13/100], Step [27600/6235], Loss: 0.2234\n",
      "Epoch [13/100], Step [27700/6235], Loss: 1.6250\n",
      "Epoch [13/100], Step [27800/6235], Loss: 5.1702\n",
      "Epoch [13/100], Step [27900/6235], Loss: 0.4836\n",
      "Epoch [13/100], Step [28000/6235], Loss: 162.2817\n",
      "Epoch [13/100], Step [28100/6235], Loss: 1.6592\n",
      "Epoch [13/100], Step [28200/6235], Loss: 32.7861\n",
      "Epoch [13/100], Step [28300/6235], Loss: 3.1222\n",
      "Epoch [13/100], Step [28400/6235], Loss: 24.3206\n",
      "Epoch [13/100], Step [28500/6235], Loss: 2.3074\n",
      "Epoch [13/100], Step [28600/6235], Loss: 0.5942\n",
      "Epoch [13/100], Step [28700/6235], Loss: 4.7211\n",
      "Epoch [13/100], Step [28800/6235], Loss: 0.4015\n",
      "Epoch [13/100], Step [28900/6235], Loss: 73.6167\n",
      "Epoch [13/100], Step [29000/6235], Loss: 10.5543\n",
      "Epoch [13/100], Step [29100/6235], Loss: 0.0298\n",
      "Epoch [13/100], Step [29200/6235], Loss: 0.9480\n",
      "Epoch [13/100], Step [29300/6235], Loss: 11.8299\n",
      "Epoch [13/100], Step [29400/6235], Loss: 0.4415\n",
      "Epoch [13/100], Step [29500/6235], Loss: 6.8312\n",
      "Epoch [13/100], Step [29600/6235], Loss: 0.0977\n",
      "Epoch [13/100], Step [29700/6235], Loss: 2.3434\n",
      "Epoch [13/100], Step [29800/6235], Loss: 1.1657\n",
      "Epoch [13/100], Step [29900/6235], Loss: 1.1411\n",
      "Epoch [13/100], Step [30000/6235], Loss: 5.4851\n",
      "Epoch [13/100], Step [30100/6235], Loss: 12.0350\n",
      "Epoch [13/100], Step [30200/6235], Loss: 1.5452\n",
      "Epoch [13/100], Step [30300/6235], Loss: 0.0559\n",
      "Epoch [13/100], Step [30400/6235], Loss: 1.4758\n",
      "Epoch [13/100], Step [30500/6235], Loss: 2.9474\n",
      "Epoch [13/100], Step [30600/6235], Loss: 1.7918\n",
      "Epoch [13/100], Step [30700/6235], Loss: 0.6027\n",
      "Epoch [13/100], Step [30800/6235], Loss: 0.5123\n",
      "Epoch [13/100], Step [30900/6235], Loss: 3.9630\n",
      "Epoch [13/100], Step [31000/6235], Loss: 0.1010\n",
      "Epoch [13/100], Step [31100/6235], Loss: 0.0783\n",
      "Epoch [13/100], Step [31200/6235], Loss: 9.6464\n",
      "Epoch [13/100], Step [31300/6235], Loss: 0.0817\n",
      "Epoch [13/100], Step [31400/6235], Loss: 11.9838\n",
      "Epoch [13/100], Step [31500/6235], Loss: 2.4876\n",
      "Epoch [13/100], Step [31600/6235], Loss: 5.8198\n",
      "Epoch [13/100], Step [31700/6235], Loss: 2.9556\n",
      "Epoch [13/100], Step [31800/6235], Loss: 2.3181\n",
      "Epoch [13/100], Step [31900/6235], Loss: 1158.5699\n",
      "Epoch [13/100], Step [32000/6235], Loss: 37.6755\n",
      "Epoch [13/100], Step [32100/6235], Loss: 8.0542\n",
      "Epoch [13/100], Step [32200/6235], Loss: 116.3983\n",
      "Epoch [13/100], Step [32300/6235], Loss: 1.6157\n",
      "Epoch [13/100], Step [32400/6235], Loss: 1.2528\n",
      "Epoch [13/100], Step [32500/6235], Loss: 16.4765\n",
      "Epoch [13/100], Step [32600/6235], Loss: 0.5301\n",
      "Epoch [13/100], Step [32700/6235], Loss: 57.4873\n",
      "Epoch [13/100], Step [32800/6235], Loss: 0.7913\n",
      "Epoch [13/100], Step [32900/6235], Loss: 13.9986\n",
      "Epoch [13/100], Step [33000/6235], Loss: 0.1294\n",
      "Epoch [13/100], Step [33100/6235], Loss: 1.1854\n",
      "Epoch [13/100], Step [33200/6235], Loss: 1.6777\n",
      "Epoch [13/100], Step [33300/6235], Loss: 10.6825\n",
      "Epoch [13/100], Step [33400/6235], Loss: 98.9541\n",
      "Epoch [13/100], Step [33500/6235], Loss: 2.3929\n",
      "Epoch [13/100], Step [33600/6235], Loss: 2.4231\n",
      "Epoch [13/100], Step [33700/6235], Loss: 1.1182\n",
      "Epoch [13/100], Step [33800/6235], Loss: 6.9571\n",
      "Epoch [13/100], Step [33900/6235], Loss: 27.3888\n",
      "Epoch [13/100], Step [34000/6235], Loss: 0.0096\n",
      "Epoch [13/100], Step [34100/6235], Loss: 0.0879\n",
      "Epoch [13/100], Step [34200/6235], Loss: 14.7816\n",
      "Epoch [13/100], Step [34300/6235], Loss: 3.0306\n",
      "Epoch [13/100], Step [34400/6235], Loss: 0.5246\n",
      "Epoch [13/100], Step [34500/6235], Loss: 96.7262\n",
      "Epoch [13/100], Step [34600/6235], Loss: 2.2099\n",
      "Epoch [13/100], Step [34700/6235], Loss: 23.8898\n",
      "Epoch [13/100], Step [34800/6235], Loss: 13.9558\n",
      "Epoch [13/100], Step [34900/6235], Loss: 58.8345\n",
      "Epoch [13/100], Step [35000/6235], Loss: 0.1017\n",
      "Epoch [13/100], Step [35100/6235], Loss: 3.3495\n",
      "Epoch [13/100], Step [35200/6235], Loss: 5.2451\n",
      "Epoch [13/100], Step [35300/6235], Loss: 0.4376\n",
      "Epoch [13/100], Step [35400/6235], Loss: 0.8582\n",
      "Epoch [13/100], Step [35500/6235], Loss: 0.9804\n",
      "Epoch [13/100], Step [35600/6235], Loss: 8.3230\n",
      "Epoch [13/100], Step [35700/6235], Loss: 6.2781\n",
      "Epoch [13/100], Step [35800/6235], Loss: 2.2819\n",
      "Epoch [13/100], Step [35900/6235], Loss: 5.7427\n",
      "Epoch [13/100], Step [36000/6235], Loss: 3.5815\n",
      "Epoch [13/100], Step [36100/6235], Loss: 3.7782\n",
      "Epoch [13/100], Step [36200/6235], Loss: 16.0635\n",
      "Epoch [13/100], Step [36300/6235], Loss: 0.0821\n",
      "Epoch [13/100], Step [36400/6235], Loss: 0.0257\n",
      "Epoch [13/100], Step [36500/6235], Loss: 11.5723\n",
      "Epoch [13/100], Step [36600/6235], Loss: 0.5212\n",
      "Epoch [13/100], Step [36700/6235], Loss: 0.6902\n",
      "Epoch [13/100], Step [36800/6235], Loss: 34.9589\n",
      "Epoch [13/100], Step [36900/6235], Loss: 2.9511\n",
      "Epoch [13/100], Step [37000/6235], Loss: 0.9526\n",
      "Epoch [13/100], Step [37100/6235], Loss: 0.9677\n",
      "Epoch [13/100], Step [37200/6235], Loss: 0.0251\n",
      "Epoch [13/100], Step [37300/6235], Loss: 0.6826\n",
      "Epoch [13/100], Step [37400/6235], Loss: 0.5707\n",
      "Epoch [13/100], Step [37500/6235], Loss: 2.9816\n",
      "Epoch [13/100], Step [37600/6235], Loss: 6.2013\n",
      "Epoch [13/100], Step [37700/6235], Loss: 0.4254\n",
      "Epoch [13/100], Step [37800/6235], Loss: 2.3481\n",
      "Epoch [13/100], Step [37900/6235], Loss: 2.0287\n",
      "Epoch [13/100], Step [38000/6235], Loss: 0.6696\n",
      "Epoch [13/100], Step [38100/6235], Loss: 7.0611\n",
      "Epoch [13/100], Step [38200/6235], Loss: 1.3325\n",
      "Epoch [13/100], Step [38300/6235], Loss: 1.9249\n",
      "Epoch [13/100], Step [38400/6235], Loss: 0.0450\n",
      "Epoch [13/100], Step [38500/6235], Loss: 2.0368\n",
      "Epoch [13/100], Step [38600/6235], Loss: 7.9208\n",
      "Epoch [13/100], Step [38700/6235], Loss: 0.1222\n",
      "Epoch [13/100], Step [38800/6235], Loss: 1.4508\n",
      "Epoch [13/100], Step [38900/6235], Loss: 2.0442\n",
      "Epoch [13/100], Step [39000/6235], Loss: 6.1573\n",
      "Epoch [13/100], Step [39100/6235], Loss: 26.6982\n",
      "Epoch [13/100], Step [39200/6235], Loss: 0.3451\n",
      "Epoch [13/100], Step [39300/6235], Loss: 6.1666\n",
      "Epoch [13/100], Step [39400/6235], Loss: 313.7119\n",
      "Epoch [13/100], Step [39500/6235], Loss: 372.8808\n",
      "Epoch [13/100], Step [39600/6235], Loss: 19.7682\n",
      "Epoch [13/100], Step [39700/6235], Loss: 41.8212\n",
      "Epoch [13/100], Step [39800/6235], Loss: 200.0607\n",
      "Epoch [13/100], Step [39900/6235], Loss: 1.7096\n",
      "Epoch [13/100], Step [40000/6235], Loss: 10.5005\n",
      "Epoch [13/100], Step [40100/6235], Loss: 23.6384\n",
      "Epoch [13/100], Step [40200/6235], Loss: 0.9148\n",
      "Epoch [13/100], Step [40300/6235], Loss: 0.4351\n",
      "Epoch [13/100], Step [40400/6235], Loss: 1.7601\n",
      "Epoch [13/100], Step [40500/6235], Loss: 2.5267\n",
      "Epoch [13/100], Step [40600/6235], Loss: 0.2287\n",
      "Epoch [13/100], Step [40700/6235], Loss: 7.6779\n",
      "Epoch [13/100], Step [40800/6235], Loss: 1.5854\n",
      "Epoch [13/100], Step [40900/6235], Loss: 0.0769\n",
      "Epoch [13/100], Step [41000/6235], Loss: 22.5247\n",
      "Epoch [13/100], Step [41100/6235], Loss: 15.4296\n",
      "Epoch [13/100], Step [41200/6235], Loss: 29.5019\n",
      "Epoch [13/100], Step [41300/6235], Loss: 3.5164\n",
      "Epoch [13/100], Step [41400/6235], Loss: 0.0674\n",
      "Epoch [13/100], Step [41500/6235], Loss: 1.4430\n",
      "Epoch [13/100], Step [41600/6235], Loss: 0.0467\n",
      "Epoch [13/100], Step [41700/6235], Loss: 0.3397\n",
      "Epoch [13/100], Step [41800/6235], Loss: 1.2983\n",
      "Epoch [13/100], Step [41900/6235], Loss: 3.5302\n",
      "Epoch [13/100], Step [42000/6235], Loss: 1.9856\n",
      "Epoch [13/100], Step [42100/6235], Loss: 5.3247\n",
      "Epoch [13/100], Step [42200/6235], Loss: 43.6370\n",
      "Epoch [13/100], Step [42300/6235], Loss: 2.6525\n",
      "Epoch [13/100], Step [42400/6235], Loss: 4.7569\n",
      "Epoch [13/100], Step [42500/6235], Loss: 0.3474\n",
      "Epoch [13/100], Step [42600/6235], Loss: 0.5663\n",
      "Epoch [13/100], Step [42700/6235], Loss: 0.2745\n",
      "Epoch [13/100], Step [42800/6235], Loss: 0.4092\n",
      "Epoch [13/100], Step [42900/6235], Loss: 4.0610\n",
      "Epoch [13/100], Step [43000/6235], Loss: 0.3445\n",
      "Epoch [13/100], Step [43100/6235], Loss: 2.0258\n",
      "Epoch [13/100], Step [43200/6235], Loss: 0.3951\n",
      "Epoch [13/100], Step [43300/6235], Loss: 10.4223\n",
      "Epoch [13/100], Step [43400/6235], Loss: 11.7022\n",
      "Epoch [13/100], Step [43500/6235], Loss: 9.2112\n",
      "Epoch [13/100], Step [43600/6235], Loss: 26.8328\n",
      "Epoch [13/100], Step [43700/6235], Loss: 48.7543\n",
      "Epoch [13/100], Step [43800/6235], Loss: 0.9375\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [13/100], Step [43900/6235], Loss: 3.3148\n",
      "Epoch [13/100], Step [44000/6235], Loss: 59.0639\n",
      "Epoch [13/100], Step [44100/6235], Loss: 1.2966\n",
      "Epoch [13/100], Step [44200/6235], Loss: 25.9076\n",
      "Epoch [13/100], Step [44300/6235], Loss: 30.5064\n",
      "Epoch [13/100], Step [44400/6235], Loss: 3.0683\n",
      "Epoch [13/100], Step [44500/6235], Loss: 2.0992\n",
      "Epoch [13/100], Step [44600/6235], Loss: 33.4388\n",
      "Epoch [13/100], Step [44700/6235], Loss: 10.2328\n",
      "Epoch [13/100], Step [44800/6235], Loss: 3.3285\n",
      "Epoch [13/100], Step [44900/6235], Loss: 4.3987\n",
      "Epoch [13/100], Step [45000/6235], Loss: 4.8390\n",
      "Epoch [13/100], Step [45100/6235], Loss: 81.4642\n",
      "Epoch [13/100], Step [45200/6235], Loss: 2.1365\n",
      "Epoch [13/100], Step [45300/6235], Loss: 27.3642\n",
      "Epoch [13/100], Step [45400/6235], Loss: 12.2553\n",
      "Epoch [13/100], Step [45500/6235], Loss: 0.9421\n",
      "Epoch [13/100], Step [45600/6235], Loss: 0.3069\n",
      "Epoch [13/100], Step [45700/6235], Loss: 147.9805\n",
      "Epoch [13/100], Step [45800/6235], Loss: 270.2097\n",
      "Epoch [13/100], Step [45900/6235], Loss: 28.2691\n",
      "Epoch [13/100], Step [46000/6235], Loss: 16.6609\n",
      "Epoch [13/100], Step [46100/6235], Loss: 76.0524\n",
      "Epoch [13/100], Step [46200/6235], Loss: 41.6530\n",
      "Epoch [13/100], Step [46300/6235], Loss: 82.0731\n",
      "Epoch [13/100], Step [46400/6235], Loss: 11.1339\n",
      "Epoch [13/100], Step [46500/6235], Loss: 230.1795\n",
      "Epoch [13/100], Step [46600/6235], Loss: 12.9798\n",
      "Epoch [13/100], Step [46700/6235], Loss: 14.4335\n",
      "Epoch [13/100], Step [46800/6235], Loss: 4.5302\n",
      "Epoch [13/100], Step [46900/6235], Loss: 1.8095\n",
      "Epoch [13/100], Step [47000/6235], Loss: 7.7331\n",
      "Epoch [13/100], Step [47100/6235], Loss: 4.9357\n",
      "Epoch [13/100], Step [47200/6235], Loss: 5.1342\n",
      "Epoch [13/100], Step [47300/6235], Loss: 0.3501\n",
      "Epoch [13/100], Step [47400/6235], Loss: 42.4733\n",
      "Epoch [13/100], Step [47500/6235], Loss: 2.3046\n",
      "Epoch [13/100], Step [47600/6235], Loss: 1.0201\n",
      "Epoch [13/100], Step [47700/6235], Loss: 6.2566\n",
      "Epoch [13/100], Step [47800/6235], Loss: 0.7330\n",
      "Epoch [13/100], Step [47900/6235], Loss: 24.0889\n",
      "Epoch [13/100], Step [48000/6235], Loss: 118.2369\n",
      "Epoch [13/100], Step [48100/6235], Loss: 3.9878\n",
      "Epoch [13/100], Step [48200/6235], Loss: 5.2096\n",
      "Epoch [13/100], Step [48300/6235], Loss: 117.8668\n",
      "Epoch [13/100], Step [48400/6235], Loss: 50.6253\n",
      "Epoch [13/100], Step [48500/6235], Loss: 6.0535\n",
      "Epoch [13/100], Step [48600/6235], Loss: 126.3150\n",
      "Epoch [13/100], Step [48700/6235], Loss: 98.2582\n",
      "Epoch [13/100], Step [48800/6235], Loss: 205.6767\n",
      "Epoch [13/100], Step [48900/6235], Loss: 55.2079\n",
      "Epoch [13/100], Step [49000/6235], Loss: 281.6863\n",
      "Epoch [13/100], Step [49100/6235], Loss: 2423.0835\n",
      "Epoch [13/100], Step [49200/6235], Loss: 596.2342\n",
      "Epoch [13/100], Step [49300/6235], Loss: 1212.9904\n",
      "Epoch [13/100], Step [49400/6235], Loss: 3.3901\n",
      "Epoch [13/100], Step [49500/6235], Loss: 44.4513\n",
      "Epoch [13/100], Step [49600/6235], Loss: 39.1579\n",
      "Epoch [13/100], Step [49700/6235], Loss: 11360.7217\n",
      "Epoch [13/100], Step [49800/6235], Loss: 828.4061\n",
      "Epoch [14/100], Step [100/6235], Loss: 3.0729\n",
      "Epoch [14/100], Step [200/6235], Loss: 0.4765\n",
      "Epoch [14/100], Step [300/6235], Loss: 0.8282\n",
      "Epoch [14/100], Step [400/6235], Loss: 0.6193\n",
      "Epoch [14/100], Step [500/6235], Loss: 1.1032\n",
      "Epoch [14/100], Step [600/6235], Loss: 0.0568\n",
      "Epoch [14/100], Step [700/6235], Loss: 0.4629\n",
      "Epoch [14/100], Step [800/6235], Loss: 0.1642\n",
      "Epoch [14/100], Step [900/6235], Loss: 0.0785\n",
      "Epoch [14/100], Step [1000/6235], Loss: 0.0267\n",
      "Epoch [14/100], Step [1100/6235], Loss: 0.0318\n",
      "Epoch [14/100], Step [1200/6235], Loss: 0.1688\n",
      "Epoch [14/100], Step [1300/6235], Loss: 0.0439\n",
      "Epoch [14/100], Step [1400/6235], Loss: 0.0933\n",
      "Epoch [14/100], Step [1500/6235], Loss: 0.0098\n",
      "Epoch [14/100], Step [1600/6235], Loss: 0.2331\n",
      "Epoch [14/100], Step [1700/6235], Loss: 0.0181\n",
      "Epoch [14/100], Step [1800/6235], Loss: 0.1939\n",
      "Epoch [14/100], Step [1900/6235], Loss: 0.5868\n",
      "Epoch [14/100], Step [2000/6235], Loss: 2.1604\n",
      "Epoch [14/100], Step [2100/6235], Loss: 1.6152\n",
      "Epoch [14/100], Step [2200/6235], Loss: 9.8198\n",
      "Epoch [14/100], Step [2300/6235], Loss: 14.3835\n",
      "Epoch [14/100], Step [2400/6235], Loss: 5.8579\n",
      "Epoch [14/100], Step [2500/6235], Loss: 38.1301\n",
      "Epoch [14/100], Step [2600/6235], Loss: 9.7496\n",
      "Epoch [14/100], Step [2700/6235], Loss: 21.9309\n",
      "Epoch [14/100], Step [2800/6235], Loss: 84.9313\n",
      "Epoch [14/100], Step [2900/6235], Loss: 6.8209\n",
      "Epoch [14/100], Step [3000/6235], Loss: 0.4015\n",
      "Epoch [14/100], Step [3100/6235], Loss: 61.8981\n",
      "Epoch [14/100], Step [3200/6235], Loss: 82.3424\n",
      "Epoch [14/100], Step [3300/6235], Loss: 1.5967\n",
      "Epoch [14/100], Step [3400/6235], Loss: 2.8127\n",
      "Epoch [14/100], Step [3500/6235], Loss: 28.4635\n",
      "Epoch [14/100], Step [3600/6235], Loss: 10.0625\n",
      "Epoch [14/100], Step [3700/6235], Loss: 1.0692\n",
      "Epoch [14/100], Step [3800/6235], Loss: 0.5883\n",
      "Epoch [14/100], Step [3900/6235], Loss: 1.6872\n",
      "Epoch [14/100], Step [4000/6235], Loss: 0.0710\n",
      "Epoch [14/100], Step [4100/6235], Loss: 4.4779\n",
      "Epoch [14/100], Step [4200/6235], Loss: 0.2311\n",
      "Epoch [14/100], Step [4300/6235], Loss: 10.7226\n",
      "Epoch [14/100], Step [4400/6235], Loss: 3.8634\n",
      "Epoch [14/100], Step [4500/6235], Loss: 53.9004\n",
      "Epoch [14/100], Step [4600/6235], Loss: 8.3570\n",
      "Epoch [14/100], Step [4700/6235], Loss: 1.4806\n",
      "Epoch [14/100], Step [4800/6235], Loss: 1.0053\n",
      "Epoch [14/100], Step [4900/6235], Loss: 0.0683\n",
      "Epoch [14/100], Step [5000/6235], Loss: 0.2789\n",
      "Epoch [14/100], Step [5100/6235], Loss: 2.2695\n",
      "Epoch [14/100], Step [5200/6235], Loss: 1.2257\n",
      "Epoch [14/100], Step [5300/6235], Loss: 31.1318\n",
      "Epoch [14/100], Step [5400/6235], Loss: 0.1208\n",
      "Epoch [14/100], Step [5500/6235], Loss: 0.2951\n",
      "Epoch [14/100], Step [5600/6235], Loss: 0.3153\n",
      "Epoch [14/100], Step [5700/6235], Loss: 1.9854\n",
      "Epoch [14/100], Step [5800/6235], Loss: 0.9983\n",
      "Epoch [14/100], Step [5900/6235], Loss: 0.0142\n",
      "Epoch [14/100], Step [6000/6235], Loss: 0.1289\n",
      "Epoch [14/100], Step [6100/6235], Loss: 0.1922\n",
      "Epoch [14/100], Step [6200/6235], Loss: 0.5443\n",
      "Epoch [14/100], Step [6300/6235], Loss: 0.9201\n",
      "Epoch [14/100], Step [6400/6235], Loss: 0.0394\n",
      "Epoch [14/100], Step [6500/6235], Loss: 0.6582\n",
      "Epoch [14/100], Step [6600/6235], Loss: 1.4798\n",
      "Epoch [14/100], Step [6700/6235], Loss: 0.6376\n",
      "Epoch [14/100], Step [6800/6235], Loss: 0.8172\n",
      "Epoch [14/100], Step [6900/6235], Loss: 3.3324\n",
      "Epoch [14/100], Step [7000/6235], Loss: 0.5300\n",
      "Epoch [14/100], Step [7100/6235], Loss: 0.2503\n",
      "Epoch [14/100], Step [7200/6235], Loss: 0.2045\n",
      "Epoch [14/100], Step [7300/6235], Loss: 1.3998\n",
      "Epoch [14/100], Step [7400/6235], Loss: 0.1829\n",
      "Epoch [14/100], Step [7500/6235], Loss: 1.8671\n",
      "Epoch [14/100], Step [7600/6235], Loss: 19.2922\n",
      "Epoch [14/100], Step [7700/6235], Loss: 9.8676\n",
      "Epoch [14/100], Step [7800/6235], Loss: 14.3304\n",
      "Epoch [14/100], Step [7900/6235], Loss: 13.7399\n",
      "Epoch [14/100], Step [8000/6235], Loss: 0.5515\n",
      "Epoch [14/100], Step [8100/6235], Loss: 3.4046\n",
      "Epoch [14/100], Step [8200/6235], Loss: 24.3134\n",
      "Epoch [14/100], Step [8300/6235], Loss: 49.7553\n",
      "Epoch [14/100], Step [8400/6235], Loss: 17.2482\n",
      "Epoch [14/100], Step [8500/6235], Loss: 56.5729\n",
      "Epoch [14/100], Step [8600/6235], Loss: 11.5791\n",
      "Epoch [14/100], Step [8700/6235], Loss: 13.3539\n",
      "Epoch [14/100], Step [8800/6235], Loss: 589.1471\n",
      "Epoch [14/100], Step [8900/6235], Loss: 9.5880\n",
      "Epoch [14/100], Step [9000/6235], Loss: 469.4138\n",
      "Epoch [14/100], Step [9100/6235], Loss: 161.8327\n",
      "Epoch [14/100], Step [9200/6235], Loss: 3036.2244\n",
      "Epoch [14/100], Step [9300/6235], Loss: 33.5134\n",
      "Epoch [14/100], Step [9400/6235], Loss: 988.3270\n",
      "Epoch [14/100], Step [9500/6235], Loss: 205.2361\n",
      "Epoch [14/100], Step [9600/6235], Loss: 139.5006\n",
      "Epoch [14/100], Step [9700/6235], Loss: 204.0921\n",
      "Epoch [14/100], Step [9800/6235], Loss: 370.4820\n",
      "Epoch [14/100], Step [9900/6235], Loss: 16.7085\n",
      "Epoch [14/100], Step [10000/6235], Loss: 11.1108\n",
      "Epoch [14/100], Step [10100/6235], Loss: 58.2464\n",
      "Epoch [14/100], Step [10200/6235], Loss: 529.7120\n",
      "Epoch [14/100], Step [10300/6235], Loss: 1.0622\n",
      "Epoch [14/100], Step [10400/6235], Loss: 3.5884\n",
      "Epoch [14/100], Step [10500/6235], Loss: 11.4035\n",
      "Epoch [14/100], Step [10600/6235], Loss: 1901.5997\n",
      "Epoch [14/100], Step [10700/6235], Loss: 158.2033\n",
      "Epoch [14/100], Step [10800/6235], Loss: 12.1450\n",
      "Epoch [14/100], Step [10900/6235], Loss: 4.0500\n",
      "Epoch [14/100], Step [11000/6235], Loss: 105.8180\n",
      "Epoch [14/100], Step [11100/6235], Loss: 6.2949\n",
      "Epoch [14/100], Step [11200/6235], Loss: 118.8145\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Step [11300/6235], Loss: 236.3282\n",
      "Epoch [14/100], Step [11400/6235], Loss: 245.5575\n",
      "Epoch [14/100], Step [11500/6235], Loss: 18.2242\n",
      "Epoch [14/100], Step [11600/6235], Loss: 4.0220\n",
      "Epoch [14/100], Step [11700/6235], Loss: 173.2467\n",
      "Epoch [14/100], Step [11800/6235], Loss: 37.3879\n",
      "Epoch [14/100], Step [11900/6235], Loss: 959.9539\n",
      "Epoch [14/100], Step [12000/6235], Loss: 206.1195\n",
      "Epoch [14/100], Step [12100/6235], Loss: 365.1873\n",
      "Epoch [14/100], Step [12200/6235], Loss: 66.9871\n",
      "Epoch [14/100], Step [12300/6235], Loss: 8.5155\n",
      "Epoch [14/100], Step [12400/6235], Loss: 118.9475\n",
      "Epoch [14/100], Step [12500/6235], Loss: 266.5510\n",
      "Epoch [14/100], Step [12600/6235], Loss: 31.3382\n",
      "Epoch [14/100], Step [12700/6235], Loss: 11.1100\n",
      "Epoch [14/100], Step [12800/6235], Loss: 17.5652\n",
      "Epoch [14/100], Step [12900/6235], Loss: 67.7109\n",
      "Epoch [14/100], Step [13000/6235], Loss: 1.0536\n",
      "Epoch [14/100], Step [13100/6235], Loss: 117.5876\n",
      "Epoch [14/100], Step [13200/6235], Loss: 41.1389\n",
      "Epoch [14/100], Step [13300/6235], Loss: 10.3925\n",
      "Epoch [14/100], Step [13400/6235], Loss: 7.1187\n",
      "Epoch [14/100], Step [13500/6235], Loss: 2.1277\n",
      "Epoch [14/100], Step [13600/6235], Loss: 41.7821\n",
      "Epoch [14/100], Step [13700/6235], Loss: 182.4242\n",
      "Epoch [14/100], Step [13800/6235], Loss: 100.6473\n",
      "Epoch [14/100], Step [13900/6235], Loss: 0.8534\n",
      "Epoch [14/100], Step [14000/6235], Loss: 0.6962\n",
      "Epoch [14/100], Step [14100/6235], Loss: 9.8151\n",
      "Epoch [14/100], Step [14200/6235], Loss: 40.8144\n",
      "Epoch [14/100], Step [14300/6235], Loss: 33.1889\n",
      "Epoch [14/100], Step [14400/6235], Loss: 2.7568\n",
      "Epoch [14/100], Step [14500/6235], Loss: 5.9811\n",
      "Epoch [14/100], Step [14600/6235], Loss: 1.8218\n",
      "Epoch [14/100], Step [14700/6235], Loss: 10.5718\n",
      "Epoch [14/100], Step [14800/6235], Loss: 10.7232\n",
      "Epoch [14/100], Step [14900/6235], Loss: 0.1426\n",
      "Epoch [14/100], Step [15000/6235], Loss: 0.1035\n",
      "Epoch [14/100], Step [15100/6235], Loss: 0.1429\n",
      "Epoch [14/100], Step [15200/6235], Loss: 46.6284\n",
      "Epoch [14/100], Step [15300/6235], Loss: 5.9208\n",
      "Epoch [14/100], Step [15400/6235], Loss: 0.6847\n",
      "Epoch [14/100], Step [15500/6235], Loss: 23.0627\n",
      "Epoch [14/100], Step [15600/6235], Loss: 8.3002\n",
      "Epoch [14/100], Step [15700/6235], Loss: 167.1805\n",
      "Epoch [14/100], Step [15800/6235], Loss: 8.0669\n",
      "Epoch [14/100], Step [15900/6235], Loss: 1.8281\n",
      "Epoch [14/100], Step [16000/6235], Loss: 4.1582\n",
      "Epoch [14/100], Step [16100/6235], Loss: 0.4272\n",
      "Epoch [14/100], Step [16200/6235], Loss: 11.8978\n",
      "Epoch [14/100], Step [16300/6235], Loss: 35.4232\n",
      "Epoch [14/100], Step [16400/6235], Loss: 54.0999\n",
      "Epoch [14/100], Step [16500/6235], Loss: 600.3984\n",
      "Epoch [14/100], Step [16600/6235], Loss: 6.6406\n",
      "Epoch [14/100], Step [16700/6235], Loss: 2.4824\n",
      "Epoch [14/100], Step [16800/6235], Loss: 0.9617\n",
      "Epoch [14/100], Step [16900/6235], Loss: 7.6715\n",
      "Epoch [14/100], Step [17000/6235], Loss: 0.9611\n",
      "Epoch [14/100], Step [17100/6235], Loss: 0.2349\n",
      "Epoch [14/100], Step [17200/6235], Loss: 70.4544\n",
      "Epoch [14/100], Step [17300/6235], Loss: 25.5701\n",
      "Epoch [14/100], Step [17400/6235], Loss: 29.5525\n",
      "Epoch [14/100], Step [17500/6235], Loss: 4.2075\n",
      "Epoch [14/100], Step [17600/6235], Loss: 0.3482\n",
      "Epoch [14/100], Step [17700/6235], Loss: 5.8756\n",
      "Epoch [14/100], Step [17800/6235], Loss: 54.4092\n",
      "Epoch [14/100], Step [17900/6235], Loss: 20.1305\n",
      "Epoch [14/100], Step [18000/6235], Loss: 0.2983\n",
      "Epoch [14/100], Step [18100/6235], Loss: 16.4430\n",
      "Epoch [14/100], Step [18200/6235], Loss: 19.2204\n",
      "Epoch [14/100], Step [18300/6235], Loss: 4.7867\n",
      "Epoch [14/100], Step [18400/6235], Loss: 11.6466\n",
      "Epoch [14/100], Step [18500/6235], Loss: 10.5227\n",
      "Epoch [14/100], Step [18600/6235], Loss: 4.7585\n",
      "Epoch [14/100], Step [18700/6235], Loss: 0.2241\n",
      "Epoch [14/100], Step [18800/6235], Loss: 103.1873\n",
      "Epoch [14/100], Step [18900/6235], Loss: 1.9884\n",
      "Epoch [14/100], Step [19000/6235], Loss: 4.8455\n",
      "Epoch [14/100], Step [19100/6235], Loss: 26.3157\n",
      "Epoch [14/100], Step [19200/6235], Loss: 1.5976\n",
      "Epoch [14/100], Step [19300/6235], Loss: 0.8041\n",
      "Epoch [14/100], Step [19400/6235], Loss: 82.5507\n",
      "Epoch [14/100], Step [19500/6235], Loss: 241.6104\n",
      "Epoch [14/100], Step [19600/6235], Loss: 129.2454\n",
      "Epoch [14/100], Step [19700/6235], Loss: 14.3570\n",
      "Epoch [14/100], Step [19800/6235], Loss: 1.4237\n",
      "Epoch [14/100], Step [19900/6235], Loss: 1.4287\n",
      "Epoch [14/100], Step [20000/6235], Loss: 81.7696\n",
      "Epoch [14/100], Step [20100/6235], Loss: 5.6620\n",
      "Epoch [14/100], Step [20200/6235], Loss: 5.7942\n",
      "Epoch [14/100], Step [20300/6235], Loss: 2.0429\n",
      "Epoch [14/100], Step [20400/6235], Loss: 28.3050\n",
      "Epoch [14/100], Step [20500/6235], Loss: 25.1832\n",
      "Epoch [14/100], Step [20600/6235], Loss: 50.0894\n",
      "Epoch [14/100], Step [20700/6235], Loss: 7.1615\n",
      "Epoch [14/100], Step [20800/6235], Loss: 19.0182\n",
      "Epoch [14/100], Step [20900/6235], Loss: 27.1181\n",
      "Epoch [14/100], Step [21000/6235], Loss: 23.2058\n",
      "Epoch [14/100], Step [21100/6235], Loss: 7.8082\n",
      "Epoch [14/100], Step [21200/6235], Loss: 1.0279\n",
      "Epoch [14/100], Step [21300/6235], Loss: 0.9902\n",
      "Epoch [14/100], Step [21400/6235], Loss: 2.9024\n",
      "Epoch [14/100], Step [21500/6235], Loss: 3.0650\n",
      "Epoch [14/100], Step [21600/6235], Loss: 33.0151\n",
      "Epoch [14/100], Step [21700/6235], Loss: 0.3770\n",
      "Epoch [14/100], Step [21800/6235], Loss: 5.5995\n",
      "Epoch [14/100], Step [21900/6235], Loss: 0.0191\n",
      "Epoch [14/100], Step [22000/6235], Loss: 0.9882\n",
      "Epoch [14/100], Step [22100/6235], Loss: 5.5220\n",
      "Epoch [14/100], Step [22200/6235], Loss: 9.8669\n",
      "Epoch [14/100], Step [22300/6235], Loss: 5.5131\n",
      "Epoch [14/100], Step [22400/6235], Loss: 5.2609\n",
      "Epoch [14/100], Step [22500/6235], Loss: 124.4993\n",
      "Epoch [14/100], Step [22600/6235], Loss: 16.2721\n",
      "Epoch [14/100], Step [22700/6235], Loss: 3.1750\n",
      "Epoch [14/100], Step [22800/6235], Loss: 4.5358\n",
      "Epoch [14/100], Step [22900/6235], Loss: 4.1409\n",
      "Epoch [14/100], Step [23000/6235], Loss: 3.8216\n",
      "Epoch [14/100], Step [23100/6235], Loss: 9.1771\n",
      "Epoch [14/100], Step [23200/6235], Loss: 16.6949\n",
      "Epoch [14/100], Step [23300/6235], Loss: 19.7822\n",
      "Epoch [14/100], Step [23400/6235], Loss: 2.0650\n",
      "Epoch [14/100], Step [23500/6235], Loss: 0.0441\n",
      "Epoch [14/100], Step [23600/6235], Loss: 110.3518\n",
      "Epoch [14/100], Step [23700/6235], Loss: 5.1813\n",
      "Epoch [14/100], Step [23800/6235], Loss: 1.0241\n",
      "Epoch [14/100], Step [23900/6235], Loss: 6.1231\n",
      "Epoch [14/100], Step [24000/6235], Loss: 0.1034\n",
      "Epoch [14/100], Step [24100/6235], Loss: 0.4961\n",
      "Epoch [14/100], Step [24200/6235], Loss: 11.2023\n",
      "Epoch [14/100], Step [24300/6235], Loss: 3.3049\n",
      "Epoch [14/100], Step [24400/6235], Loss: 11.4076\n",
      "Epoch [14/100], Step [24500/6235], Loss: 3.3485\n",
      "Epoch [14/100], Step [24600/6235], Loss: 0.2799\n",
      "Epoch [14/100], Step [24700/6235], Loss: 7.3547\n",
      "Epoch [14/100], Step [24800/6235], Loss: 0.0758\n",
      "Epoch [14/100], Step [24900/6235], Loss: 17.9478\n",
      "Epoch [14/100], Step [25000/6235], Loss: 20.2759\n",
      "Epoch [14/100], Step [25100/6235], Loss: 8.8906\n",
      "Epoch [14/100], Step [25200/6235], Loss: 1.7050\n",
      "Epoch [14/100], Step [25300/6235], Loss: 0.7002\n",
      "Epoch [14/100], Step [25400/6235], Loss: 7.2396\n",
      "Epoch [14/100], Step [25500/6235], Loss: 8.0233\n",
      "Epoch [14/100], Step [25600/6235], Loss: 4.1894\n",
      "Epoch [14/100], Step [25700/6235], Loss: 0.3127\n",
      "Epoch [14/100], Step [25800/6235], Loss: 0.1221\n",
      "Epoch [14/100], Step [25900/6235], Loss: 7.2192\n",
      "Epoch [14/100], Step [26000/6235], Loss: 3.3456\n",
      "Epoch [14/100], Step [26100/6235], Loss: 0.5495\n",
      "Epoch [14/100], Step [26200/6235], Loss: 0.0500\n",
      "Epoch [14/100], Step [26300/6235], Loss: 5.2447\n",
      "Epoch [14/100], Step [26400/6235], Loss: 0.1394\n",
      "Epoch [14/100], Step [26500/6235], Loss: 0.1120\n",
      "Epoch [14/100], Step [26600/6235], Loss: 2.2787\n",
      "Epoch [14/100], Step [26700/6235], Loss: 0.5318\n",
      "Epoch [14/100], Step [26800/6235], Loss: 0.4367\n",
      "Epoch [14/100], Step [26900/6235], Loss: 0.0198\n",
      "Epoch [14/100], Step [27000/6235], Loss: 14.0676\n",
      "Epoch [14/100], Step [27100/6235], Loss: 0.0570\n",
      "Epoch [14/100], Step [27200/6235], Loss: 0.0267\n",
      "Epoch [14/100], Step [27300/6235], Loss: 0.2436\n",
      "Epoch [14/100], Step [27400/6235], Loss: 0.8527\n",
      "Epoch [14/100], Step [27500/6235], Loss: 19.5010\n",
      "Epoch [14/100], Step [27600/6235], Loss: 1.1597\n",
      "Epoch [14/100], Step [27700/6235], Loss: 1.5620\n",
      "Epoch [14/100], Step [27800/6235], Loss: 5.3245\n",
      "Epoch [14/100], Step [27900/6235], Loss: 0.7973\n",
      "Epoch [14/100], Step [28000/6235], Loss: 163.3829\n",
      "Epoch [14/100], Step [28100/6235], Loss: 0.5666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Step [28200/6235], Loss: 23.2807\n",
      "Epoch [14/100], Step [28300/6235], Loss: 5.1338\n",
      "Epoch [14/100], Step [28400/6235], Loss: 20.1733\n",
      "Epoch [14/100], Step [28500/6235], Loss: 1.4640\n",
      "Epoch [14/100], Step [28600/6235], Loss: 1.0276\n",
      "Epoch [14/100], Step [28700/6235], Loss: 3.8667\n",
      "Epoch [14/100], Step [28800/6235], Loss: 0.2725\n",
      "Epoch [14/100], Step [28900/6235], Loss: 72.5926\n",
      "Epoch [14/100], Step [29000/6235], Loss: 4.9535\n",
      "Epoch [14/100], Step [29100/6235], Loss: 0.0743\n",
      "Epoch [14/100], Step [29200/6235], Loss: 0.3226\n",
      "Epoch [14/100], Step [29300/6235], Loss: 2.7581\n",
      "Epoch [14/100], Step [29400/6235], Loss: 0.2229\n",
      "Epoch [14/100], Step [29500/6235], Loss: 5.0012\n",
      "Epoch [14/100], Step [29600/6235], Loss: 0.3230\n",
      "Epoch [14/100], Step [29700/6235], Loss: 0.1876\n",
      "Epoch [14/100], Step [29800/6235], Loss: 1.6515\n",
      "Epoch [14/100], Step [29900/6235], Loss: 0.1752\n",
      "Epoch [14/100], Step [30000/6235], Loss: 7.5063\n",
      "Epoch [14/100], Step [30100/6235], Loss: 11.8990\n",
      "Epoch [14/100], Step [30200/6235], Loss: 0.8774\n",
      "Epoch [14/100], Step [30300/6235], Loss: 1.2428\n",
      "Epoch [14/100], Step [30400/6235], Loss: 0.8417\n",
      "Epoch [14/100], Step [30500/6235], Loss: 2.2336\n",
      "Epoch [14/100], Step [30600/6235], Loss: 1.2024\n",
      "Epoch [14/100], Step [30700/6235], Loss: 0.0269\n",
      "Epoch [14/100], Step [30800/6235], Loss: 0.3491\n",
      "Epoch [14/100], Step [30900/6235], Loss: 3.3405\n",
      "Epoch [14/100], Step [31000/6235], Loss: 0.0148\n",
      "Epoch [14/100], Step [31100/6235], Loss: 0.0714\n",
      "Epoch [14/100], Step [31200/6235], Loss: 8.6928\n",
      "Epoch [14/100], Step [31300/6235], Loss: 3.4593\n",
      "Epoch [14/100], Step [31400/6235], Loss: 9.9054\n",
      "Epoch [14/100], Step [31500/6235], Loss: 0.4368\n",
      "Epoch [14/100], Step [31600/6235], Loss: 1.9819\n",
      "Epoch [14/100], Step [31700/6235], Loss: 7.7348\n",
      "Epoch [14/100], Step [31800/6235], Loss: 0.6656\n",
      "Epoch [14/100], Step [31900/6235], Loss: 1162.8434\n",
      "Epoch [14/100], Step [32000/6235], Loss: 21.6786\n",
      "Epoch [14/100], Step [32100/6235], Loss: 6.7787\n",
      "Epoch [14/100], Step [32200/6235], Loss: 103.1760\n",
      "Epoch [14/100], Step [32300/6235], Loss: 1.3872\n",
      "Epoch [14/100], Step [32400/6235], Loss: 0.9910\n",
      "Epoch [14/100], Step [32500/6235], Loss: 18.4115\n",
      "Epoch [14/100], Step [32600/6235], Loss: 0.5983\n",
      "Epoch [14/100], Step [32700/6235], Loss: 48.2658\n",
      "Epoch [14/100], Step [32800/6235], Loss: 0.1007\n",
      "Epoch [14/100], Step [32900/6235], Loss: 13.9697\n",
      "Epoch [14/100], Step [33000/6235], Loss: 0.1151\n",
      "Epoch [14/100], Step [33100/6235], Loss: 0.8357\n",
      "Epoch [14/100], Step [33200/6235], Loss: 3.0240\n",
      "Epoch [14/100], Step [33300/6235], Loss: 9.7569\n",
      "Epoch [14/100], Step [33400/6235], Loss: 54.6647\n",
      "Epoch [14/100], Step [33500/6235], Loss: 0.3114\n",
      "Epoch [14/100], Step [33600/6235], Loss: 3.1761\n",
      "Epoch [14/100], Step [33700/6235], Loss: 0.6847\n",
      "Epoch [14/100], Step [33800/6235], Loss: 11.1113\n",
      "Epoch [14/100], Step [33900/6235], Loss: 29.2092\n",
      "Epoch [14/100], Step [34000/6235], Loss: 0.0130\n",
      "Epoch [14/100], Step [34100/6235], Loss: 0.0904\n",
      "Epoch [14/100], Step [34200/6235], Loss: 13.0973\n",
      "Epoch [14/100], Step [34300/6235], Loss: 2.3518\n",
      "Epoch [14/100], Step [34400/6235], Loss: 0.2059\n",
      "Epoch [14/100], Step [34500/6235], Loss: 104.9601\n",
      "Epoch [14/100], Step [34600/6235], Loss: 1.6260\n",
      "Epoch [14/100], Step [34700/6235], Loss: 5.4744\n",
      "Epoch [14/100], Step [34800/6235], Loss: 10.0690\n",
      "Epoch [14/100], Step [34900/6235], Loss: 54.1776\n",
      "Epoch [14/100], Step [35000/6235], Loss: 0.0743\n",
      "Epoch [14/100], Step [35100/6235], Loss: 3.7316\n",
      "Epoch [14/100], Step [35200/6235], Loss: 5.9190\n",
      "Epoch [14/100], Step [35300/6235], Loss: 1.2395\n",
      "Epoch [14/100], Step [35400/6235], Loss: 0.6456\n",
      "Epoch [14/100], Step [35500/6235], Loss: 0.6136\n",
      "Epoch [14/100], Step [35600/6235], Loss: 10.0041\n",
      "Epoch [14/100], Step [35700/6235], Loss: 8.3550\n",
      "Epoch [14/100], Step [35800/6235], Loss: 0.2330\n",
      "Epoch [14/100], Step [35900/6235], Loss: 4.5425\n",
      "Epoch [14/100], Step [36000/6235], Loss: 2.0624\n",
      "Epoch [14/100], Step [36100/6235], Loss: 5.6253\n",
      "Epoch [14/100], Step [36200/6235], Loss: 22.9580\n",
      "Epoch [14/100], Step [36300/6235], Loss: 0.2833\n",
      "Epoch [14/100], Step [36400/6235], Loss: 0.0229\n",
      "Epoch [14/100], Step [36500/6235], Loss: 12.0134\n",
      "Epoch [14/100], Step [36600/6235], Loss: 0.7119\n",
      "Epoch [14/100], Step [36700/6235], Loss: 0.8098\n",
      "Epoch [14/100], Step [36800/6235], Loss: 32.0242\n",
      "Epoch [14/100], Step [36900/6235], Loss: 3.7462\n",
      "Epoch [14/100], Step [37000/6235], Loss: 1.0402\n",
      "Epoch [14/100], Step [37100/6235], Loss: 1.2787\n",
      "Epoch [14/100], Step [37200/6235], Loss: 0.0384\n",
      "Epoch [14/100], Step [37300/6235], Loss: 0.6895\n",
      "Epoch [14/100], Step [37400/6235], Loss: 0.7810\n",
      "Epoch [14/100], Step [37500/6235], Loss: 2.4574\n",
      "Epoch [14/100], Step [37600/6235], Loss: 5.7231\n",
      "Epoch [14/100], Step [37700/6235], Loss: 0.3948\n",
      "Epoch [14/100], Step [37800/6235], Loss: 1.2031\n",
      "Epoch [14/100], Step [37900/6235], Loss: 3.8416\n",
      "Epoch [14/100], Step [38000/6235], Loss: 0.6576\n",
      "Epoch [14/100], Step [38100/6235], Loss: 7.1805\n",
      "Epoch [14/100], Step [38200/6235], Loss: 1.5662\n",
      "Epoch [14/100], Step [38300/6235], Loss: 2.1399\n",
      "Epoch [14/100], Step [38400/6235], Loss: 0.0925\n",
      "Epoch [14/100], Step [38500/6235], Loss: 1.5555\n",
      "Epoch [14/100], Step [38600/6235], Loss: 9.3974\n",
      "Epoch [14/100], Step [38700/6235], Loss: 0.0568\n",
      "Epoch [14/100], Step [38800/6235], Loss: 1.4851\n",
      "Epoch [14/100], Step [38900/6235], Loss: 7.4114\n",
      "Epoch [14/100], Step [39000/6235], Loss: 19.0093\n",
      "Epoch [14/100], Step [39100/6235], Loss: 14.4187\n",
      "Epoch [14/100], Step [39200/6235], Loss: 1.0578\n",
      "Epoch [14/100], Step [39300/6235], Loss: 6.4924\n",
      "Epoch [14/100], Step [39400/6235], Loss: 24.0979\n",
      "Epoch [14/100], Step [39500/6235], Loss: 260.4614\n",
      "Epoch [14/100], Step [39600/6235], Loss: 14.1106\n",
      "Epoch [14/100], Step [39700/6235], Loss: 39.0488\n",
      "Epoch [14/100], Step [39800/6235], Loss: 117.1991\n",
      "Epoch [14/100], Step [39900/6235], Loss: 0.2078\n",
      "Epoch [14/100], Step [40000/6235], Loss: 11.4003\n",
      "Epoch [14/100], Step [40100/6235], Loss: 34.0244\n",
      "Epoch [14/100], Step [40200/6235], Loss: 3.8465\n",
      "Epoch [14/100], Step [40300/6235], Loss: 0.1221\n",
      "Epoch [14/100], Step [40400/6235], Loss: 2.4919\n",
      "Epoch [14/100], Step [40500/6235], Loss: 2.3243\n",
      "Epoch [14/100], Step [40600/6235], Loss: 0.2173\n",
      "Epoch [14/100], Step [40700/6235], Loss: 7.8725\n",
      "Epoch [14/100], Step [40800/6235], Loss: 2.2184\n",
      "Epoch [14/100], Step [40900/6235], Loss: 0.0822\n",
      "Epoch [14/100], Step [41000/6235], Loss: 13.7877\n",
      "Epoch [14/100], Step [41100/6235], Loss: 7.9225\n",
      "Epoch [14/100], Step [41200/6235], Loss: 17.1787\n",
      "Epoch [14/100], Step [41300/6235], Loss: 1.4763\n",
      "Epoch [14/100], Step [41400/6235], Loss: 0.1246\n",
      "Epoch [14/100], Step [41500/6235], Loss: 0.2928\n",
      "Epoch [14/100], Step [41600/6235], Loss: 0.0921\n",
      "Epoch [14/100], Step [41700/6235], Loss: 0.7924\n",
      "Epoch [14/100], Step [41800/6235], Loss: 1.5490\n",
      "Epoch [14/100], Step [41900/6235], Loss: 2.8519\n",
      "Epoch [14/100], Step [42000/6235], Loss: 1.8334\n",
      "Epoch [14/100], Step [42100/6235], Loss: 4.5635\n",
      "Epoch [14/100], Step [42200/6235], Loss: 44.9179\n",
      "Epoch [14/100], Step [42300/6235], Loss: 0.7315\n",
      "Epoch [14/100], Step [42400/6235], Loss: 4.2319\n",
      "Epoch [14/100], Step [42500/6235], Loss: 2.2567\n",
      "Epoch [14/100], Step [42600/6235], Loss: 0.4306\n",
      "Epoch [14/100], Step [42700/6235], Loss: 0.1678\n",
      "Epoch [14/100], Step [42800/6235], Loss: 0.6130\n",
      "Epoch [14/100], Step [42900/6235], Loss: 4.1270\n",
      "Epoch [14/100], Step [43000/6235], Loss: 0.5762\n",
      "Epoch [14/100], Step [43100/6235], Loss: 2.2859\n",
      "Epoch [14/100], Step [43200/6235], Loss: 0.3334\n",
      "Epoch [14/100], Step [43300/6235], Loss: 10.8270\n",
      "Epoch [14/100], Step [43400/6235], Loss: 10.3098\n",
      "Epoch [14/100], Step [43500/6235], Loss: 9.0329\n",
      "Epoch [14/100], Step [43600/6235], Loss: 29.7029\n",
      "Epoch [14/100], Step [43700/6235], Loss: 48.6192\n",
      "Epoch [14/100], Step [43800/6235], Loss: 0.9666\n",
      "Epoch [14/100], Step [43900/6235], Loss: 0.7395\n",
      "Epoch [14/100], Step [44000/6235], Loss: 60.9042\n",
      "Epoch [14/100], Step [44100/6235], Loss: 0.8711\n",
      "Epoch [14/100], Step [44200/6235], Loss: 2.4003\n",
      "Epoch [14/100], Step [44300/6235], Loss: 41.5181\n",
      "Epoch [14/100], Step [44400/6235], Loss: 4.7573\n",
      "Epoch [14/100], Step [44500/6235], Loss: 1.8636\n",
      "Epoch [14/100], Step [44600/6235], Loss: 34.1373\n",
      "Epoch [14/100], Step [44700/6235], Loss: 1.2627\n",
      "Epoch [14/100], Step [44800/6235], Loss: 3.4184\n",
      "Epoch [14/100], Step [44900/6235], Loss: 5.0597\n",
      "Epoch [14/100], Step [45000/6235], Loss: 4.8929\n",
      "Epoch [14/100], Step [45100/6235], Loss: 54.0984\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [14/100], Step [45200/6235], Loss: 0.4330\n",
      "Epoch [14/100], Step [45300/6235], Loss: 27.1001\n",
      "Epoch [14/100], Step [45400/6235], Loss: 12.5217\n",
      "Epoch [14/100], Step [45500/6235], Loss: 0.8401\n",
      "Epoch [14/100], Step [45600/6235], Loss: 0.2926\n",
      "Epoch [14/100], Step [45700/6235], Loss: 122.9527\n",
      "Epoch [14/100], Step [45800/6235], Loss: 386.7878\n",
      "Epoch [14/100], Step [45900/6235], Loss: 73.1198\n",
      "Epoch [14/100], Step [46000/6235], Loss: 24.7498\n",
      "Epoch [14/100], Step [46100/6235], Loss: 10.7365\n",
      "Epoch [14/100], Step [46200/6235], Loss: 93.1606\n",
      "Epoch [14/100], Step [46300/6235], Loss: 15.3504\n",
      "Epoch [14/100], Step [46400/6235], Loss: 8.1541\n",
      "Epoch [14/100], Step [46500/6235], Loss: 10.2372\n",
      "Epoch [14/100], Step [46600/6235], Loss: 21.4024\n",
      "Epoch [14/100], Step [46700/6235], Loss: 6.6687\n",
      "Epoch [14/100], Step [46800/6235], Loss: 5.9544\n",
      "Epoch [14/100], Step [46900/6235], Loss: 2.8215\n",
      "Epoch [14/100], Step [47000/6235], Loss: 6.8145\n",
      "Epoch [14/100], Step [47100/6235], Loss: 2.4544\n",
      "Epoch [14/100], Step [47200/6235], Loss: 4.8522\n",
      "Epoch [14/100], Step [47300/6235], Loss: 0.8163\n",
      "Epoch [14/100], Step [47400/6235], Loss: 68.2376\n",
      "Epoch [14/100], Step [47500/6235], Loss: 10.5282\n",
      "Epoch [14/100], Step [47600/6235], Loss: 1.0395\n",
      "Epoch [14/100], Step [47700/6235], Loss: 11.5333\n",
      "Epoch [14/100], Step [47800/6235], Loss: 0.5650\n",
      "Epoch [14/100], Step [47900/6235], Loss: 37.6766\n",
      "Epoch [14/100], Step [48000/6235], Loss: 112.2740\n",
      "Epoch [14/100], Step [48100/6235], Loss: 2.8586\n",
      "Epoch [14/100], Step [48200/6235], Loss: 2.4544\n",
      "Epoch [14/100], Step [48300/6235], Loss: 112.5238\n",
      "Epoch [14/100], Step [48400/6235], Loss: 68.1932\n",
      "Epoch [14/100], Step [48500/6235], Loss: 3.8462\n",
      "Epoch [14/100], Step [48600/6235], Loss: 95.7946\n",
      "Epoch [14/100], Step [48700/6235], Loss: 82.0536\n",
      "Epoch [14/100], Step [48800/6235], Loss: 28.7807\n",
      "Epoch [14/100], Step [48900/6235], Loss: 163.5448\n",
      "Epoch [14/100], Step [49000/6235], Loss: 360.7421\n",
      "Epoch [14/100], Step [49100/6235], Loss: 1409.1011\n",
      "Epoch [14/100], Step [49200/6235], Loss: 581.8303\n",
      "Epoch [14/100], Step [49300/6235], Loss: 932.5722\n",
      "Epoch [14/100], Step [49400/6235], Loss: 104.2054\n",
      "Epoch [14/100], Step [49500/6235], Loss: 4.8381\n",
      "Epoch [14/100], Step [49600/6235], Loss: 364.2671\n",
      "Epoch [14/100], Step [49700/6235], Loss: 9171.6914\n",
      "Epoch [14/100], Step [49800/6235], Loss: 1289.5767\n",
      "Epoch [15/100], Step [100/6235], Loss: 47.2697\n",
      "Epoch [15/100], Step [200/6235], Loss: 0.1162\n",
      "Epoch [15/100], Step [300/6235], Loss: 0.0230\n",
      "Epoch [15/100], Step [400/6235], Loss: 0.0030\n",
      "Epoch [15/100], Step [500/6235], Loss: 10.4477\n",
      "Epoch [15/100], Step [600/6235], Loss: 0.0495\n",
      "Epoch [15/100], Step [700/6235], Loss: 0.3103\n",
      "Epoch [15/100], Step [800/6235], Loss: 0.1156\n",
      "Epoch [15/100], Step [900/6235], Loss: 0.0705\n",
      "Epoch [15/100], Step [1000/6235], Loss: 0.0307\n",
      "Epoch [15/100], Step [1100/6235], Loss: 0.1592\n",
      "Epoch [15/100], Step [1200/6235], Loss: 0.1549\n",
      "Epoch [15/100], Step [1300/6235], Loss: 0.0527\n",
      "Epoch [15/100], Step [1400/6235], Loss: 0.0847\n",
      "Epoch [15/100], Step [1500/6235], Loss: 0.0022\n",
      "Epoch [15/100], Step [1600/6235], Loss: 0.2058\n",
      "Epoch [15/100], Step [1700/6235], Loss: 0.0231\n",
      "Epoch [15/100], Step [1800/6235], Loss: 0.1999\n",
      "Epoch [15/100], Step [1900/6235], Loss: 0.8635\n",
      "Epoch [15/100], Step [2000/6235], Loss: 2.0302\n",
      "Epoch [15/100], Step [2100/6235], Loss: 1.5265\n",
      "Epoch [15/100], Step [2200/6235], Loss: 11.1746\n",
      "Epoch [15/100], Step [2300/6235], Loss: 23.8699\n",
      "Epoch [15/100], Step [2400/6235], Loss: 14.3376\n",
      "Epoch [15/100], Step [2500/6235], Loss: 32.8342\n",
      "Epoch [15/100], Step [2600/6235], Loss: 7.2115\n",
      "Epoch [15/100], Step [2700/6235], Loss: 38.6413\n",
      "Epoch [15/100], Step [2800/6235], Loss: 500.0977\n",
      "Epoch [15/100], Step [2900/6235], Loss: 6.4043\n",
      "Epoch [15/100], Step [3000/6235], Loss: 0.3820\n",
      "Epoch [15/100], Step [3100/6235], Loss: 37.8462\n",
      "Epoch [15/100], Step [3200/6235], Loss: 50.0814\n",
      "Epoch [15/100], Step [3300/6235], Loss: 0.0972\n",
      "Epoch [15/100], Step [3400/6235], Loss: 2.1865\n",
      "Epoch [15/100], Step [3500/6235], Loss: 32.0779\n",
      "Epoch [15/100], Step [3600/6235], Loss: 12.2226\n",
      "Epoch [15/100], Step [3700/6235], Loss: 1.9088\n",
      "Epoch [15/100], Step [3800/6235], Loss: 0.3885\n",
      "Epoch [15/100], Step [3900/6235], Loss: 0.6124\n",
      "Epoch [15/100], Step [4000/6235], Loss: 0.1542\n",
      "Epoch [15/100], Step [4100/6235], Loss: 1.5075\n",
      "Epoch [15/100], Step [4200/6235], Loss: 0.6483\n",
      "Epoch [15/100], Step [4300/6235], Loss: 9.3006\n",
      "Epoch [15/100], Step [4400/6235], Loss: 0.2002\n",
      "Epoch [15/100], Step [4500/6235], Loss: 66.0954\n",
      "Epoch [15/100], Step [4600/6235], Loss: 16.5094\n",
      "Epoch [15/100], Step [4700/6235], Loss: 2.0648\n",
      "Epoch [15/100], Step [4800/6235], Loss: 3.3354\n",
      "Epoch [15/100], Step [4900/6235], Loss: 0.0621\n",
      "Epoch [15/100], Step [5000/6235], Loss: 1.3715\n",
      "Epoch [15/100], Step [5100/6235], Loss: 4.7621\n",
      "Epoch [15/100], Step [5200/6235], Loss: 75.6961\n",
      "Epoch [15/100], Step [5300/6235], Loss: 34.5520\n",
      "Epoch [15/100], Step [5400/6235], Loss: 1.3297\n",
      "Epoch [15/100], Step [5500/6235], Loss: 0.3282\n",
      "Epoch [15/100], Step [5600/6235], Loss: 0.3600\n",
      "Epoch [15/100], Step [5700/6235], Loss: 1.3101\n",
      "Epoch [15/100], Step [5800/6235], Loss: 0.5512\n",
      "Epoch [15/100], Step [5900/6235], Loss: 2.3651\n",
      "Epoch [15/100], Step [6000/6235], Loss: 0.9257\n",
      "Epoch [15/100], Step [6100/6235], Loss: 0.0958\n",
      "Epoch [15/100], Step [6200/6235], Loss: 0.7007\n",
      "Epoch [15/100], Step [6300/6235], Loss: 0.5221\n",
      "Epoch [15/100], Step [6400/6235], Loss: 0.2766\n",
      "Epoch [15/100], Step [6500/6235], Loss: 0.1669\n",
      "Epoch [15/100], Step [6600/6235], Loss: 3.9800\n",
      "Epoch [15/100], Step [6700/6235], Loss: 0.1595\n",
      "Epoch [15/100], Step [6800/6235], Loss: 1.7464\n",
      "Epoch [15/100], Step [6900/6235], Loss: 0.9311\n",
      "Epoch [15/100], Step [7000/6235], Loss: 0.0724\n",
      "Epoch [15/100], Step [7100/6235], Loss: 1.3767\n",
      "Epoch [15/100], Step [7200/6235], Loss: 0.2514\n",
      "Epoch [15/100], Step [7300/6235], Loss: 0.4729\n",
      "Epoch [15/100], Step [7400/6235], Loss: 0.5591\n",
      "Epoch [15/100], Step [7500/6235], Loss: 34.2588\n",
      "Epoch [15/100], Step [7600/6235], Loss: 10.6998\n",
      "Epoch [15/100], Step [7700/6235], Loss: 6.9504\n",
      "Epoch [15/100], Step [7800/6235], Loss: 1.8829\n",
      "Epoch [15/100], Step [7900/6235], Loss: 5.3457\n",
      "Epoch [15/100], Step [8000/6235], Loss: 0.2782\n",
      "Epoch [15/100], Step [8100/6235], Loss: 2.0777\n",
      "Epoch [15/100], Step [8200/6235], Loss: 6.4946\n",
      "Epoch [15/100], Step [8300/6235], Loss: 15.8107\n",
      "Epoch [15/100], Step [8400/6235], Loss: 10.4290\n",
      "Epoch [15/100], Step [8500/6235], Loss: 1.8058\n",
      "Epoch [15/100], Step [8600/6235], Loss: 3.2422\n",
      "Epoch [15/100], Step [8700/6235], Loss: 0.7632\n",
      "Epoch [15/100], Step [8800/6235], Loss: 782.1862\n",
      "Epoch [15/100], Step [8900/6235], Loss: 1.2374\n",
      "Epoch [15/100], Step [9000/6235], Loss: 133.2351\n",
      "Epoch [15/100], Step [9100/6235], Loss: 25.9556\n",
      "Epoch [15/100], Step [9200/6235], Loss: 1798.0144\n",
      "Epoch [15/100], Step [9300/6235], Loss: 179.6748\n",
      "Epoch [15/100], Step [9400/6235], Loss: 1158.5216\n",
      "Epoch [15/100], Step [9500/6235], Loss: 226.9232\n",
      "Epoch [15/100], Step [9600/6235], Loss: 103.3479\n",
      "Epoch [15/100], Step [9700/6235], Loss: 215.4996\n",
      "Epoch [15/100], Step [9800/6235], Loss: 245.4744\n",
      "Epoch [15/100], Step [9900/6235], Loss: 202.5187\n",
      "Epoch [15/100], Step [10000/6235], Loss: 314.8559\n",
      "Epoch [15/100], Step [10100/6235], Loss: 82.0411\n",
      "Epoch [15/100], Step [10200/6235], Loss: 791.7994\n",
      "Epoch [15/100], Step [10300/6235], Loss: 7.5867\n",
      "Epoch [15/100], Step [10400/6235], Loss: 11.7511\n",
      "Epoch [15/100], Step [10500/6235], Loss: 6.7910\n",
      "Epoch [15/100], Step [10600/6235], Loss: 1410.3124\n",
      "Epoch [15/100], Step [10700/6235], Loss: 246.9523\n",
      "Epoch [15/100], Step [10800/6235], Loss: 3.4391\n",
      "Epoch [15/100], Step [10900/6235], Loss: 5.1093\n",
      "Epoch [15/100], Step [11000/6235], Loss: 27.1401\n",
      "Epoch [15/100], Step [11100/6235], Loss: 0.6363\n",
      "Epoch [15/100], Step [11200/6235], Loss: 124.0599\n",
      "Epoch [15/100], Step [11300/6235], Loss: 207.0181\n",
      "Epoch [15/100], Step [11400/6235], Loss: 335.9903\n",
      "Epoch [15/100], Step [11500/6235], Loss: 7.2135\n",
      "Epoch [15/100], Step [11600/6235], Loss: 1.2726\n",
      "Epoch [15/100], Step [11700/6235], Loss: 154.4364\n",
      "Epoch [15/100], Step [11800/6235], Loss: 45.8477\n",
      "Epoch [15/100], Step [11900/6235], Loss: 835.8665\n",
      "Epoch [15/100], Step [12000/6235], Loss: 61.7734\n",
      "Epoch [15/100], Step [12100/6235], Loss: 507.1175\n",
      "Epoch [15/100], Step [12200/6235], Loss: 104.9296\n",
      "Epoch [15/100], Step [12300/6235], Loss: 31.5441\n",
      "Epoch [15/100], Step [12400/6235], Loss: 376.1432\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Step [12500/6235], Loss: 199.7847\n",
      "Epoch [15/100], Step [12600/6235], Loss: 52.2377\n",
      "Epoch [15/100], Step [12700/6235], Loss: 31.5607\n",
      "Epoch [15/100], Step [12800/6235], Loss: 3.7021\n",
      "Epoch [15/100], Step [12900/6235], Loss: 28.5851\n",
      "Epoch [15/100], Step [13000/6235], Loss: 3.5457\n",
      "Epoch [15/100], Step [13100/6235], Loss: 84.3616\n",
      "Epoch [15/100], Step [13200/6235], Loss: 46.2609\n",
      "Epoch [15/100], Step [13300/6235], Loss: 2.8948\n",
      "Epoch [15/100], Step [13400/6235], Loss: 1.0177\n",
      "Epoch [15/100], Step [13500/6235], Loss: 1.3321\n",
      "Epoch [15/100], Step [13600/6235], Loss: 4.1758\n",
      "Epoch [15/100], Step [13700/6235], Loss: 189.9244\n",
      "Epoch [15/100], Step [13800/6235], Loss: 144.4945\n",
      "Epoch [15/100], Step [13900/6235], Loss: 4.7681\n",
      "Epoch [15/100], Step [14000/6235], Loss: 27.2311\n",
      "Epoch [15/100], Step [14100/6235], Loss: 308.8785\n",
      "Epoch [15/100], Step [14200/6235], Loss: 0.5373\n",
      "Epoch [15/100], Step [14300/6235], Loss: 3.3983\n",
      "Epoch [15/100], Step [14400/6235], Loss: 3.2711\n",
      "Epoch [15/100], Step [14500/6235], Loss: 19.3605\n",
      "Epoch [15/100], Step [14600/6235], Loss: 10.5461\n",
      "Epoch [15/100], Step [14700/6235], Loss: 5.3169\n",
      "Epoch [15/100], Step [14800/6235], Loss: 17.5974\n",
      "Epoch [15/100], Step [14900/6235], Loss: 0.6444\n",
      "Epoch [15/100], Step [15000/6235], Loss: 0.2329\n",
      "Epoch [15/100], Step [15100/6235], Loss: 0.2022\n",
      "Epoch [15/100], Step [15200/6235], Loss: 3.1835\n",
      "Epoch [15/100], Step [15300/6235], Loss: 143.4797\n",
      "Epoch [15/100], Step [15400/6235], Loss: 9.9003\n",
      "Epoch [15/100], Step [15500/6235], Loss: 34.7739\n",
      "Epoch [15/100], Step [15600/6235], Loss: 234.3773\n",
      "Epoch [15/100], Step [15700/6235], Loss: 12.5976\n",
      "Epoch [15/100], Step [15800/6235], Loss: 0.2624\n",
      "Epoch [15/100], Step [15900/6235], Loss: 0.8990\n",
      "Epoch [15/100], Step [16000/6235], Loss: 43.7330\n",
      "Epoch [15/100], Step [16100/6235], Loss: 0.4923\n",
      "Epoch [15/100], Step [16200/6235], Loss: 4.2019\n",
      "Epoch [15/100], Step [16300/6235], Loss: 15.4700\n",
      "Epoch [15/100], Step [16400/6235], Loss: 67.2015\n",
      "Epoch [15/100], Step [16500/6235], Loss: 571.8051\n",
      "Epoch [15/100], Step [16600/6235], Loss: 5.5976\n",
      "Epoch [15/100], Step [16700/6235], Loss: 7.7492\n",
      "Epoch [15/100], Step [16800/6235], Loss: 2.0201\n",
      "Epoch [15/100], Step [16900/6235], Loss: 1.9105\n",
      "Epoch [15/100], Step [17000/6235], Loss: 6.0171\n",
      "Epoch [15/100], Step [17100/6235], Loss: 3.3496\n",
      "Epoch [15/100], Step [17200/6235], Loss: 13.3095\n",
      "Epoch [15/100], Step [17300/6235], Loss: 12.6592\n",
      "Epoch [15/100], Step [17400/6235], Loss: 86.2219\n",
      "Epoch [15/100], Step [17500/6235], Loss: 13.7842\n",
      "Epoch [15/100], Step [17600/6235], Loss: 0.3797\n",
      "Epoch [15/100], Step [17700/6235], Loss: 45.6798\n",
      "Epoch [15/100], Step [17800/6235], Loss: 20.8635\n",
      "Epoch [15/100], Step [17900/6235], Loss: 124.1978\n",
      "Epoch [15/100], Step [18000/6235], Loss: 1.8739\n",
      "Epoch [15/100], Step [18100/6235], Loss: 7.7977\n",
      "Epoch [15/100], Step [18200/6235], Loss: 10.3403\n",
      "Epoch [15/100], Step [18300/6235], Loss: 0.9709\n",
      "Epoch [15/100], Step [18400/6235], Loss: 27.5907\n",
      "Epoch [15/100], Step [18500/6235], Loss: 43.0222\n",
      "Epoch [15/100], Step [18600/6235], Loss: 2.5753\n",
      "Epoch [15/100], Step [18700/6235], Loss: 1.3062\n",
      "Epoch [15/100], Step [18800/6235], Loss: 39.1300\n",
      "Epoch [15/100], Step [18900/6235], Loss: 8.1994\n",
      "Epoch [15/100], Step [19000/6235], Loss: 25.6329\n",
      "Epoch [15/100], Step [19100/6235], Loss: 1.3275\n",
      "Epoch [15/100], Step [19200/6235], Loss: 1.2287\n",
      "Epoch [15/100], Step [19300/6235], Loss: 7.7132\n",
      "Epoch [15/100], Step [19400/6235], Loss: 56.2324\n",
      "Epoch [15/100], Step [19500/6235], Loss: 202.8131\n",
      "Epoch [15/100], Step [19600/6235], Loss: 147.5984\n",
      "Epoch [15/100], Step [19700/6235], Loss: 12.0576\n",
      "Epoch [15/100], Step [19800/6235], Loss: 31.6176\n",
      "Epoch [15/100], Step [19900/6235], Loss: 2.6457\n",
      "Epoch [15/100], Step [20000/6235], Loss: 109.4823\n",
      "Epoch [15/100], Step [20100/6235], Loss: 4.2001\n",
      "Epoch [15/100], Step [20200/6235], Loss: 0.3878\n",
      "Epoch [15/100], Step [20300/6235], Loss: 0.1283\n",
      "Epoch [15/100], Step [20400/6235], Loss: 34.2479\n",
      "Epoch [15/100], Step [20500/6235], Loss: 19.4788\n",
      "Epoch [15/100], Step [20600/6235], Loss: 273.1884\n",
      "Epoch [15/100], Step [20700/6235], Loss: 14.6020\n",
      "Epoch [15/100], Step [20800/6235], Loss: 21.1661\n",
      "Epoch [15/100], Step [20900/6235], Loss: 26.0351\n",
      "Epoch [15/100], Step [21000/6235], Loss: 4.7690\n",
      "Epoch [15/100], Step [21100/6235], Loss: 10.8316\n",
      "Epoch [15/100], Step [21200/6235], Loss: 0.5196\n",
      "Epoch [15/100], Step [21300/6235], Loss: 6.5177\n",
      "Epoch [15/100], Step [21400/6235], Loss: 2.1164\n",
      "Epoch [15/100], Step [21500/6235], Loss: 7.0166\n",
      "Epoch [15/100], Step [21600/6235], Loss: 29.2468\n",
      "Epoch [15/100], Step [21700/6235], Loss: 1.3999\n",
      "Epoch [15/100], Step [21800/6235], Loss: 31.4206\n",
      "Epoch [15/100], Step [21900/6235], Loss: 2.7598\n",
      "Epoch [15/100], Step [22000/6235], Loss: 0.0622\n",
      "Epoch [15/100], Step [22100/6235], Loss: 3.5849\n",
      "Epoch [15/100], Step [22200/6235], Loss: 7.8260\n",
      "Epoch [15/100], Step [22300/6235], Loss: 1.8298\n",
      "Epoch [15/100], Step [22400/6235], Loss: 3.6768\n",
      "Epoch [15/100], Step [22500/6235], Loss: 95.5950\n",
      "Epoch [15/100], Step [22600/6235], Loss: 21.2289\n",
      "Epoch [15/100], Step [22700/6235], Loss: 0.6348\n",
      "Epoch [15/100], Step [22800/6235], Loss: 1.9428\n",
      "Epoch [15/100], Step [22900/6235], Loss: 0.6821\n",
      "Epoch [15/100], Step [23000/6235], Loss: 22.6448\n",
      "Epoch [15/100], Step [23100/6235], Loss: 0.2643\n",
      "Epoch [15/100], Step [23200/6235], Loss: 18.9529\n",
      "Epoch [15/100], Step [23300/6235], Loss: 17.8382\n",
      "Epoch [15/100], Step [23400/6235], Loss: 0.8708\n",
      "Epoch [15/100], Step [23500/6235], Loss: 0.2195\n",
      "Epoch [15/100], Step [23600/6235], Loss: 59.1900\n",
      "Epoch [15/100], Step [23700/6235], Loss: 13.4234\n",
      "Epoch [15/100], Step [23800/6235], Loss: 0.1154\n",
      "Epoch [15/100], Step [23900/6235], Loss: 8.2891\n",
      "Epoch [15/100], Step [24000/6235], Loss: 3.3800\n",
      "Epoch [15/100], Step [24100/6235], Loss: 2.0509\n",
      "Epoch [15/100], Step [24200/6235], Loss: 38.5070\n",
      "Epoch [15/100], Step [24300/6235], Loss: 4.2421\n",
      "Epoch [15/100], Step [24400/6235], Loss: 6.0945\n",
      "Epoch [15/100], Step [24500/6235], Loss: 2.9811\n",
      "Epoch [15/100], Step [24600/6235], Loss: 0.1100\n",
      "Epoch [15/100], Step [24700/6235], Loss: 4.7273\n",
      "Epoch [15/100], Step [24800/6235], Loss: 5.0240\n",
      "Epoch [15/100], Step [24900/6235], Loss: 3.8083\n",
      "Epoch [15/100], Step [25000/6235], Loss: 5.2796\n",
      "Epoch [15/100], Step [25100/6235], Loss: 9.4021\n",
      "Epoch [15/100], Step [25200/6235], Loss: 0.6133\n",
      "Epoch [15/100], Step [25300/6235], Loss: 1.1723\n",
      "Epoch [15/100], Step [25400/6235], Loss: 8.2138\n",
      "Epoch [15/100], Step [25500/6235], Loss: 5.1537\n",
      "Epoch [15/100], Step [25600/6235], Loss: 0.5993\n",
      "Epoch [15/100], Step [25700/6235], Loss: 0.3105\n",
      "Epoch [15/100], Step [25800/6235], Loss: 0.1435\n",
      "Epoch [15/100], Step [25900/6235], Loss: 8.9337\n",
      "Epoch [15/100], Step [26000/6235], Loss: 0.0647\n",
      "Epoch [15/100], Step [26100/6235], Loss: 3.4872\n",
      "Epoch [15/100], Step [26200/6235], Loss: 2.0398\n",
      "Epoch [15/100], Step [26300/6235], Loss: 7.4608\n",
      "Epoch [15/100], Step [26400/6235], Loss: 0.0826\n",
      "Epoch [15/100], Step [26500/6235], Loss: 1.4775\n",
      "Epoch [15/100], Step [26600/6235], Loss: 6.0665\n",
      "Epoch [15/100], Step [26700/6235], Loss: 1.2398\n",
      "Epoch [15/100], Step [26800/6235], Loss: 2.4550\n",
      "Epoch [15/100], Step [26900/6235], Loss: 0.3448\n",
      "Epoch [15/100], Step [27000/6235], Loss: 9.6889\n",
      "Epoch [15/100], Step [27100/6235], Loss: 0.2991\n",
      "Epoch [15/100], Step [27200/6235], Loss: 0.0942\n",
      "Epoch [15/100], Step [27300/6235], Loss: 0.1353\n",
      "Epoch [15/100], Step [27400/6235], Loss: 1.2376\n",
      "Epoch [15/100], Step [27500/6235], Loss: 3.6877\n",
      "Epoch [15/100], Step [27600/6235], Loss: 0.4824\n",
      "Epoch [15/100], Step [27700/6235], Loss: 0.0341\n",
      "Epoch [15/100], Step [27800/6235], Loss: 1.9201\n",
      "Epoch [15/100], Step [27900/6235], Loss: 5.6012\n",
      "Epoch [15/100], Step [28000/6235], Loss: 199.9832\n",
      "Epoch [15/100], Step [28100/6235], Loss: 0.7093\n",
      "Epoch [15/100], Step [28200/6235], Loss: 32.3978\n",
      "Epoch [15/100], Step [28300/6235], Loss: 5.4139\n",
      "Epoch [15/100], Step [28400/6235], Loss: 10.1026\n",
      "Epoch [15/100], Step [28500/6235], Loss: 0.6295\n",
      "Epoch [15/100], Step [28600/6235], Loss: 1.3191\n",
      "Epoch [15/100], Step [28700/6235], Loss: 3.4571\n",
      "Epoch [15/100], Step [28800/6235], Loss: 0.1619\n",
      "Epoch [15/100], Step [28900/6235], Loss: 62.7128\n",
      "Epoch [15/100], Step [29000/6235], Loss: 1.3403\n",
      "Epoch [15/100], Step [29100/6235], Loss: 0.9278\n",
      "Epoch [15/100], Step [29200/6235], Loss: 0.0865\n",
      "Epoch [15/100], Step [29300/6235], Loss: 0.5255\n",
      "Epoch [15/100], Step [29400/6235], Loss: 0.1758\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Step [29500/6235], Loss: 1.6108\n",
      "Epoch [15/100], Step [29600/6235], Loss: 0.1252\n",
      "Epoch [15/100], Step [29700/6235], Loss: 0.9662\n",
      "Epoch [15/100], Step [29800/6235], Loss: 1.5701\n",
      "Epoch [15/100], Step [29900/6235], Loss: 0.0527\n",
      "Epoch [15/100], Step [30000/6235], Loss: 1.0893\n",
      "Epoch [15/100], Step [30100/6235], Loss: 9.1666\n",
      "Epoch [15/100], Step [30200/6235], Loss: 1.2458\n",
      "Epoch [15/100], Step [30300/6235], Loss: 0.9427\n",
      "Epoch [15/100], Step [30400/6235], Loss: 1.1621\n",
      "Epoch [15/100], Step [30500/6235], Loss: 0.6748\n",
      "Epoch [15/100], Step [30600/6235], Loss: 0.1334\n",
      "Epoch [15/100], Step [30700/6235], Loss: 0.0218\n",
      "Epoch [15/100], Step [30800/6235], Loss: 0.3720\n",
      "Epoch [15/100], Step [30900/6235], Loss: 2.1335\n",
      "Epoch [15/100], Step [31000/6235], Loss: 0.0224\n",
      "Epoch [15/100], Step [31100/6235], Loss: 0.0786\n",
      "Epoch [15/100], Step [31200/6235], Loss: 0.3630\n",
      "Epoch [15/100], Step [31300/6235], Loss: 2.0645\n",
      "Epoch [15/100], Step [31400/6235], Loss: 1.0164\n",
      "Epoch [15/100], Step [31500/6235], Loss: 0.2269\n",
      "Epoch [15/100], Step [31600/6235], Loss: 0.2489\n",
      "Epoch [15/100], Step [31700/6235], Loss: 0.9789\n",
      "Epoch [15/100], Step [31800/6235], Loss: 0.6373\n",
      "Epoch [15/100], Step [31900/6235], Loss: 1407.3201\n",
      "Epoch [15/100], Step [32000/6235], Loss: 69.4797\n",
      "Epoch [15/100], Step [32100/6235], Loss: 8.9903\n",
      "Epoch [15/100], Step [32200/6235], Loss: 17.4989\n",
      "Epoch [15/100], Step [32300/6235], Loss: 0.4194\n",
      "Epoch [15/100], Step [32400/6235], Loss: 0.2240\n",
      "Epoch [15/100], Step [32500/6235], Loss: 19.3657\n",
      "Epoch [15/100], Step [32600/6235], Loss: 1.2699\n",
      "Epoch [15/100], Step [32700/6235], Loss: 310.9604\n",
      "Epoch [15/100], Step [32800/6235], Loss: 15.0856\n",
      "Epoch [15/100], Step [32900/6235], Loss: 5.5916\n",
      "Epoch [15/100], Step [33000/6235], Loss: 4.3091\n",
      "Epoch [15/100], Step [33100/6235], Loss: 0.1711\n",
      "Epoch [15/100], Step [33200/6235], Loss: 4.6303\n",
      "Epoch [15/100], Step [33300/6235], Loss: 6.9650\n",
      "Epoch [15/100], Step [33400/6235], Loss: 1.3166\n",
      "Epoch [15/100], Step [33500/6235], Loss: 0.4243\n",
      "Epoch [15/100], Step [33600/6235], Loss: 0.0466\n",
      "Epoch [15/100], Step [33700/6235], Loss: 1.4960\n",
      "Epoch [15/100], Step [33800/6235], Loss: 26.3829\n",
      "Epoch [15/100], Step [33900/6235], Loss: 24.8207\n",
      "Epoch [15/100], Step [34000/6235], Loss: 0.1341\n",
      "Epoch [15/100], Step [34100/6235], Loss: 0.3466\n",
      "Epoch [15/100], Step [34200/6235], Loss: 31.6173\n",
      "Epoch [15/100], Step [34300/6235], Loss: 0.0381\n",
      "Epoch [15/100], Step [34400/6235], Loss: 3.0032\n",
      "Epoch [15/100], Step [34500/6235], Loss: 12.5323\n",
      "Epoch [15/100], Step [34600/6235], Loss: 2.6517\n",
      "Epoch [15/100], Step [34700/6235], Loss: 40.4091\n",
      "Epoch [15/100], Step [34800/6235], Loss: 10.0658\n",
      "Epoch [15/100], Step [34900/6235], Loss: 27.5605\n",
      "Epoch [15/100], Step [35000/6235], Loss: 1.2315\n",
      "Epoch [15/100], Step [35100/6235], Loss: 8.4076\n",
      "Epoch [15/100], Step [35200/6235], Loss: 5.7929\n",
      "Epoch [15/100], Step [35300/6235], Loss: 4.8801\n",
      "Epoch [15/100], Step [35400/6235], Loss: 1.3809\n",
      "Epoch [15/100], Step [35500/6235], Loss: 0.0769\n",
      "Epoch [15/100], Step [35600/6235], Loss: 11.5631\n",
      "Epoch [15/100], Step [35700/6235], Loss: 17.3573\n",
      "Epoch [15/100], Step [35800/6235], Loss: 1.5044\n",
      "Epoch [15/100], Step [35900/6235], Loss: 2.5079\n",
      "Epoch [15/100], Step [36000/6235], Loss: 0.3390\n",
      "Epoch [15/100], Step [36100/6235], Loss: 13.4195\n",
      "Epoch [15/100], Step [36200/6235], Loss: 8.8891\n",
      "Epoch [15/100], Step [36300/6235], Loss: 3.5023\n",
      "Epoch [15/100], Step [36400/6235], Loss: 0.1918\n",
      "Epoch [15/100], Step [36500/6235], Loss: 5.6823\n",
      "Epoch [15/100], Step [36600/6235], Loss: 0.2090\n",
      "Epoch [15/100], Step [36700/6235], Loss: 1.7367\n",
      "Epoch [15/100], Step [36800/6235], Loss: 17.9787\n",
      "Epoch [15/100], Step [36900/6235], Loss: 8.5011\n",
      "Epoch [15/100], Step [37000/6235], Loss: 0.7296\n",
      "Epoch [15/100], Step [37100/6235], Loss: 0.7872\n",
      "Epoch [15/100], Step [37200/6235], Loss: 0.1511\n",
      "Epoch [15/100], Step [37300/6235], Loss: 0.6296\n",
      "Epoch [15/100], Step [37400/6235], Loss: 0.8428\n",
      "Epoch [15/100], Step [37500/6235], Loss: 0.4146\n",
      "Epoch [15/100], Step [37600/6235], Loss: 8.3407\n",
      "Epoch [15/100], Step [37700/6235], Loss: 0.9399\n",
      "Epoch [15/100], Step [37800/6235], Loss: 1.9301\n",
      "Epoch [15/100], Step [37900/6235], Loss: 4.3383\n",
      "Epoch [15/100], Step [38000/6235], Loss: 0.1025\n",
      "Epoch [15/100], Step [38100/6235], Loss: 1.7709\n",
      "Epoch [15/100], Step [38200/6235], Loss: 7.2325\n",
      "Epoch [15/100], Step [38300/6235], Loss: 0.0919\n",
      "Epoch [15/100], Step [38400/6235], Loss: 0.2509\n",
      "Epoch [15/100], Step [38500/6235], Loss: 0.0451\n",
      "Epoch [15/100], Step [38600/6235], Loss: 8.8799\n",
      "Epoch [15/100], Step [38700/6235], Loss: 0.0336\n",
      "Epoch [15/100], Step [38800/6235], Loss: 1.0177\n",
      "Epoch [15/100], Step [38900/6235], Loss: 3.3202\n",
      "Epoch [15/100], Step [39000/6235], Loss: 2.3855\n",
      "Epoch [15/100], Step [39100/6235], Loss: 31.0677\n",
      "Epoch [15/100], Step [39200/6235], Loss: 0.2290\n",
      "Epoch [15/100], Step [39300/6235], Loss: 25.5704\n",
      "Epoch [15/100], Step [39400/6235], Loss: 82.4172\n",
      "Epoch [15/100], Step [39500/6235], Loss: 31.5441\n",
      "Epoch [15/100], Step [39600/6235], Loss: 3.8929\n",
      "Epoch [15/100], Step [39700/6235], Loss: 182.5058\n",
      "Epoch [15/100], Step [39800/6235], Loss: 193.8546\n",
      "Epoch [15/100], Step [39900/6235], Loss: 1.0149\n",
      "Epoch [15/100], Step [40000/6235], Loss: 14.8928\n",
      "Epoch [15/100], Step [40100/6235], Loss: 28.8274\n",
      "Epoch [15/100], Step [40200/6235], Loss: 5.0804\n",
      "Epoch [15/100], Step [40300/6235], Loss: 0.2124\n",
      "Epoch [15/100], Step [40400/6235], Loss: 3.3952\n",
      "Epoch [15/100], Step [40500/6235], Loss: 2.1255\n",
      "Epoch [15/100], Step [40600/6235], Loss: 0.2748\n",
      "Epoch [15/100], Step [40700/6235], Loss: 8.0321\n",
      "Epoch [15/100], Step [40800/6235], Loss: 2.9305\n",
      "Epoch [15/100], Step [40900/6235], Loss: 0.2095\n",
      "Epoch [15/100], Step [41000/6235], Loss: 6.4334\n",
      "Epoch [15/100], Step [41100/6235], Loss: 24.9774\n",
      "Epoch [15/100], Step [41200/6235], Loss: 18.5477\n",
      "Epoch [15/100], Step [41300/6235], Loss: 0.5795\n",
      "Epoch [15/100], Step [41400/6235], Loss: 0.7378\n",
      "Epoch [15/100], Step [41500/6235], Loss: 0.0708\n",
      "Epoch [15/100], Step [41600/6235], Loss: 0.1744\n",
      "Epoch [15/100], Step [41700/6235], Loss: 2.2672\n",
      "Epoch [15/100], Step [41800/6235], Loss: 2.3521\n",
      "Epoch [15/100], Step [41900/6235], Loss: 1.5477\n",
      "Epoch [15/100], Step [42000/6235], Loss: 2.0632\n",
      "Epoch [15/100], Step [42100/6235], Loss: 3.3993\n",
      "Epoch [15/100], Step [42200/6235], Loss: 41.4024\n",
      "Epoch [15/100], Step [42300/6235], Loss: 2.1966\n",
      "Epoch [15/100], Step [42400/6235], Loss: 5.6858\n",
      "Epoch [15/100], Step [42500/6235], Loss: 0.6531\n",
      "Epoch [15/100], Step [42600/6235], Loss: 0.4249\n",
      "Epoch [15/100], Step [42700/6235], Loss: 0.2127\n",
      "Epoch [15/100], Step [42800/6235], Loss: 0.7985\n",
      "Epoch [15/100], Step [42900/6235], Loss: 4.2509\n",
      "Epoch [15/100], Step [43000/6235], Loss: 0.7832\n",
      "Epoch [15/100], Step [43100/6235], Loss: 2.4336\n",
      "Epoch [15/100], Step [43200/6235], Loss: 0.2945\n",
      "Epoch [15/100], Step [43300/6235], Loss: 11.0265\n",
      "Epoch [15/100], Step [43400/6235], Loss: 9.8835\n",
      "Epoch [15/100], Step [43500/6235], Loss: 8.8854\n",
      "Epoch [15/100], Step [43600/6235], Loss: 30.8853\n",
      "Epoch [15/100], Step [43700/6235], Loss: 49.2776\n",
      "Epoch [15/100], Step [43800/6235], Loss: 0.8946\n",
      "Epoch [15/100], Step [43900/6235], Loss: 1.9962\n",
      "Epoch [15/100], Step [44000/6235], Loss: 56.3228\n",
      "Epoch [15/100], Step [44100/6235], Loss: 1.2841\n",
      "Epoch [15/100], Step [44200/6235], Loss: 12.6690\n",
      "Epoch [15/100], Step [44300/6235], Loss: 0.5281\n",
      "Epoch [15/100], Step [44400/6235], Loss: 0.6173\n",
      "Epoch [15/100], Step [44500/6235], Loss: 0.4557\n",
      "Epoch [15/100], Step [44600/6235], Loss: 30.9530\n",
      "Epoch [15/100], Step [44700/6235], Loss: 7.8233\n",
      "Epoch [15/100], Step [44800/6235], Loss: 3.2189\n",
      "Epoch [15/100], Step [44900/6235], Loss: 5.0364\n",
      "Epoch [15/100], Step [45000/6235], Loss: 4.8377\n",
      "Epoch [15/100], Step [45100/6235], Loss: 81.8110\n",
      "Epoch [15/100], Step [45200/6235], Loss: 1.4115\n",
      "Epoch [15/100], Step [45300/6235], Loss: 26.7379\n",
      "Epoch [15/100], Step [45400/6235], Loss: 10.7078\n",
      "Epoch [15/100], Step [45500/6235], Loss: 1.0889\n",
      "Epoch [15/100], Step [45600/6235], Loss: 0.3552\n",
      "Epoch [15/100], Step [45700/6235], Loss: 150.2071\n",
      "Epoch [15/100], Step [45800/6235], Loss: 389.3068\n",
      "Epoch [15/100], Step [45900/6235], Loss: 93.7278\n",
      "Epoch [15/100], Step [46000/6235], Loss: 20.2135\n",
      "Epoch [15/100], Step [46100/6235], Loss: 86.9012\n",
      "Epoch [15/100], Step [46200/6235], Loss: 21.7741\n",
      "Epoch [15/100], Step [46300/6235], Loss: 77.8461\n",
      "Epoch [15/100], Step [46400/6235], Loss: 11.4637\n",
      "Epoch [15/100], Step [46500/6235], Loss: 15.7607\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [15/100], Step [46600/6235], Loss: 11.3854\n",
      "Epoch [15/100], Step [46700/6235], Loss: 12.2697\n",
      "Epoch [15/100], Step [46800/6235], Loss: 10.3299\n",
      "Epoch [15/100], Step [46900/6235], Loss: 1.5871\n",
      "Epoch [15/100], Step [47000/6235], Loss: 7.8933\n",
      "Epoch [15/100], Step [47100/6235], Loss: 7.0152\n",
      "Epoch [15/100], Step [47200/6235], Loss: 4.5737\n",
      "Epoch [15/100], Step [47300/6235], Loss: 1.6983\n",
      "Epoch [15/100], Step [47400/6235], Loss: 85.8325\n",
      "Epoch [15/100], Step [47500/6235], Loss: 2.6191\n",
      "Epoch [15/100], Step [47600/6235], Loss: 0.6709\n",
      "Epoch [15/100], Step [47700/6235], Loss: 13.3260\n",
      "Epoch [15/100], Step [47800/6235], Loss: 0.5628\n",
      "Epoch [15/100], Step [47900/6235], Loss: 34.4691\n",
      "Epoch [15/100], Step [48000/6235], Loss: 169.0160\n",
      "Epoch [15/100], Step [48100/6235], Loss: 2.8621\n",
      "Epoch [15/100], Step [48200/6235], Loss: 17.4826\n",
      "Epoch [15/100], Step [48300/6235], Loss: 4.2203\n",
      "Epoch [15/100], Step [48400/6235], Loss: 67.3801\n",
      "Epoch [15/100], Step [48500/6235], Loss: 4.1540\n",
      "Epoch [15/100], Step [48600/6235], Loss: 93.4477\n",
      "Epoch [15/100], Step [48700/6235], Loss: 77.4968\n",
      "Epoch [15/100], Step [48800/6235], Loss: 289.0676\n",
      "Epoch [15/100], Step [48900/6235], Loss: 396.1042\n",
      "Epoch [15/100], Step [49000/6235], Loss: 352.7948\n",
      "Epoch [15/100], Step [49100/6235], Loss: 2257.3501\n",
      "Epoch [15/100], Step [49200/6235], Loss: 953.1991\n",
      "Epoch [15/100], Step [49300/6235], Loss: 1043.7234\n",
      "Epoch [15/100], Step [49400/6235], Loss: 270.6432\n",
      "Epoch [15/100], Step [49500/6235], Loss: 11.4948\n",
      "Epoch [15/100], Step [49600/6235], Loss: 67.2933\n",
      "Epoch [15/100], Step [49700/6235], Loss: 14043.9443\n",
      "Epoch [15/100], Step [49800/6235], Loss: 718.4928\n",
      "Epoch [16/100], Step [100/6235], Loss: 44.4280\n",
      "Epoch [16/100], Step [200/6235], Loss: 0.1037\n",
      "Epoch [16/100], Step [300/6235], Loss: 0.0043\n",
      "Epoch [16/100], Step [400/6235], Loss: 0.0008\n",
      "Epoch [16/100], Step [500/6235], Loss: 0.0063\n",
      "Epoch [16/100], Step [600/6235], Loss: 0.0376\n",
      "Epoch [16/100], Step [700/6235], Loss: 0.2502\n",
      "Epoch [16/100], Step [800/6235], Loss: 0.0798\n",
      "Epoch [16/100], Step [900/6235], Loss: 0.0170\n",
      "Epoch [16/100], Step [1000/6235], Loss: 0.0220\n",
      "Epoch [16/100], Step [1100/6235], Loss: 0.0015\n",
      "Epoch [16/100], Step [1200/6235], Loss: 0.1409\n",
      "Epoch [16/100], Step [1300/6235], Loss: 0.0611\n",
      "Epoch [16/100], Step [1400/6235], Loss: 0.0345\n",
      "Epoch [16/100], Step [1500/6235], Loss: 0.0019\n",
      "Epoch [16/100], Step [1600/6235], Loss: 0.2025\n",
      "Epoch [16/100], Step [1700/6235], Loss: 0.0270\n",
      "Epoch [16/100], Step [1800/6235], Loss: 0.2105\n",
      "Epoch [16/100], Step [1900/6235], Loss: 0.8638\n",
      "Epoch [16/100], Step [2000/6235], Loss: 1.9804\n",
      "Epoch [16/100], Step [2100/6235], Loss: 1.3765\n",
      "Epoch [16/100], Step [2200/6235], Loss: 11.6026\n",
      "Epoch [16/100], Step [2300/6235], Loss: 24.9808\n",
      "Epoch [16/100], Step [2400/6235], Loss: 15.7017\n",
      "Epoch [16/100], Step [2500/6235], Loss: 31.1373\n",
      "Epoch [16/100], Step [2600/6235], Loss: 7.0988\n",
      "Epoch [16/100], Step [2700/6235], Loss: 35.3468\n",
      "Epoch [16/100], Step [2800/6235], Loss: 65.9475\n",
      "Epoch [16/100], Step [2900/6235], Loss: 7.0035\n",
      "Epoch [16/100], Step [3000/6235], Loss: 0.8848\n",
      "Epoch [16/100], Step [3100/6235], Loss: 39.1102\n",
      "Epoch [16/100], Step [3200/6235], Loss: 50.1124\n",
      "Epoch [16/100], Step [3300/6235], Loss: 0.1555\n",
      "Epoch [16/100], Step [3400/6235], Loss: 2.2818\n",
      "Epoch [16/100], Step [3500/6235], Loss: 32.3207\n",
      "Epoch [16/100], Step [3600/6235], Loss: 12.2469\n",
      "Epoch [16/100], Step [3700/6235], Loss: 1.8410\n",
      "Epoch [16/100], Step [3800/6235], Loss: 0.3951\n",
      "Epoch [16/100], Step [3900/6235], Loss: 0.5607\n",
      "Epoch [16/100], Step [4000/6235], Loss: 0.1546\n",
      "Epoch [16/100], Step [4100/6235], Loss: 1.7696\n",
      "Epoch [16/100], Step [4200/6235], Loss: 0.4544\n",
      "Epoch [16/100], Step [4300/6235], Loss: 8.3433\n",
      "Epoch [16/100], Step [4400/6235], Loss: 0.0706\n",
      "Epoch [16/100], Step [4500/6235], Loss: 69.8496\n",
      "Epoch [16/100], Step [4600/6235], Loss: 13.6011\n",
      "Epoch [16/100], Step [4700/6235], Loss: 1.9917\n",
      "Epoch [16/100], Step [4800/6235], Loss: 3.0625\n",
      "Epoch [16/100], Step [4900/6235], Loss: 0.0211\n",
      "Epoch [16/100], Step [5000/6235], Loss: 1.3556\n",
      "Epoch [16/100], Step [5100/6235], Loss: 3.6070\n",
      "Epoch [16/100], Step [5200/6235], Loss: 4.6113\n",
      "Epoch [16/100], Step [5300/6235], Loss: 36.3721\n",
      "Epoch [16/100], Step [5400/6235], Loss: 1.1277\n",
      "Epoch [16/100], Step [5500/6235], Loss: 0.3527\n",
      "Epoch [16/100], Step [5600/6235], Loss: 0.3998\n",
      "Epoch [16/100], Step [5700/6235], Loss: 0.9644\n",
      "Epoch [16/100], Step [5800/6235], Loss: 0.5297\n",
      "Epoch [16/100], Step [5900/6235], Loss: 2.2129\n",
      "Epoch [16/100], Step [6000/6235], Loss: 1.4313\n",
      "Epoch [16/100], Step [6100/6235], Loss: 0.0680\n",
      "Epoch [16/100], Step [6200/6235], Loss: 0.4389\n",
      "Epoch [16/100], Step [6300/6235], Loss: 0.4813\n",
      "Epoch [16/100], Step [6400/6235], Loss: 0.0732\n",
      "Epoch [16/100], Step [6500/6235], Loss: 0.5636\n",
      "Epoch [16/100], Step [6600/6235], Loss: 2.4903\n",
      "Epoch [16/100], Step [6700/6235], Loss: 0.2049\n",
      "Epoch [16/100], Step [6800/6235], Loss: 3.5092\n",
      "Epoch [16/100], Step [6900/6235], Loss: 0.9722\n",
      "Epoch [16/100], Step [7000/6235], Loss: 0.0148\n",
      "Epoch [16/100], Step [7100/6235], Loss: 1.6678\n",
      "Epoch [16/100], Step [7200/6235], Loss: 0.3089\n",
      "Epoch [16/100], Step [7300/6235], Loss: 1.7282\n",
      "Epoch [16/100], Step [7400/6235], Loss: 0.3168\n",
      "Epoch [16/100], Step [7500/6235], Loss: 27.6132\n",
      "Epoch [16/100], Step [7600/6235], Loss: 5.1558\n",
      "Epoch [16/100], Step [7700/6235], Loss: 5.1824\n",
      "Epoch [16/100], Step [7800/6235], Loss: 0.9836\n",
      "Epoch [16/100], Step [7900/6235], Loss: 38.0044\n",
      "Epoch [16/100], Step [8000/6235], Loss: 4.0329\n",
      "Epoch [16/100], Step [8100/6235], Loss: 2.0902\n",
      "Epoch [16/100], Step [8200/6235], Loss: 21.3171\n",
      "Epoch [16/100], Step [8300/6235], Loss: 12.7443\n",
      "Epoch [16/100], Step [8400/6235], Loss: 14.8440\n",
      "Epoch [16/100], Step [8500/6235], Loss: 3.0437\n",
      "Epoch [16/100], Step [8600/6235], Loss: 1.6058\n",
      "Epoch [16/100], Step [8700/6235], Loss: 2.3849\n",
      "Epoch [16/100], Step [8800/6235], Loss: 462.4932\n",
      "Epoch [16/100], Step [8900/6235], Loss: 5.0144\n",
      "Epoch [16/100], Step [9000/6235], Loss: 199.6914\n",
      "Epoch [16/100], Step [9100/6235], Loss: 1.9762\n",
      "Epoch [16/100], Step [9200/6235], Loss: 2471.0891\n",
      "Epoch [16/100], Step [9300/6235], Loss: 4.2681\n",
      "Epoch [16/100], Step [9400/6235], Loss: 530.9644\n",
      "Epoch [16/100], Step [9500/6235], Loss: 330.3877\n",
      "Epoch [16/100], Step [9600/6235], Loss: 12.9445\n",
      "Epoch [16/100], Step [9700/6235], Loss: 231.7286\n",
      "Epoch [16/100], Step [9800/6235], Loss: 270.6630\n",
      "Epoch [16/100], Step [9900/6235], Loss: 10.3900\n",
      "Epoch [16/100], Step [10000/6235], Loss: 74.2734\n",
      "Epoch [16/100], Step [10100/6235], Loss: 83.1821\n",
      "Epoch [16/100], Step [10200/6235], Loss: 744.3978\n",
      "Epoch [16/100], Step [10300/6235], Loss: 5.6936\n",
      "Epoch [16/100], Step [10400/6235], Loss: 9.6566\n",
      "Epoch [16/100], Step [10500/6235], Loss: 9.7818\n",
      "Epoch [16/100], Step [10600/6235], Loss: 1843.5627\n",
      "Epoch [16/100], Step [10700/6235], Loss: 136.8495\n",
      "Epoch [16/100], Step [10800/6235], Loss: 35.6978\n",
      "Epoch [16/100], Step [10900/6235], Loss: 4.7920\n",
      "Epoch [16/100], Step [11000/6235], Loss: 64.0246\n",
      "Epoch [16/100], Step [11100/6235], Loss: 2.3029\n",
      "Epoch [16/100], Step [11200/6235], Loss: 127.2027\n",
      "Epoch [16/100], Step [11300/6235], Loss: 225.4355\n",
      "Epoch [16/100], Step [11400/6235], Loss: 296.1639\n",
      "Epoch [16/100], Step [11500/6235], Loss: 15.0107\n",
      "Epoch [16/100], Step [11600/6235], Loss: 2.5572\n",
      "Epoch [16/100], Step [11700/6235], Loss: 172.3326\n",
      "Epoch [16/100], Step [11800/6235], Loss: 33.6743\n",
      "Epoch [16/100], Step [11900/6235], Loss: 676.7073\n",
      "Epoch [16/100], Step [12000/6235], Loss: 40.2004\n",
      "Epoch [16/100], Step [12100/6235], Loss: 438.5795\n",
      "Epoch [16/100], Step [12200/6235], Loss: 104.0105\n",
      "Epoch [16/100], Step [12300/6235], Loss: 63.2029\n",
      "Epoch [16/100], Step [12400/6235], Loss: 247.6395\n",
      "Epoch [16/100], Step [12500/6235], Loss: 209.4354\n",
      "Epoch [16/100], Step [12600/6235], Loss: 48.0571\n",
      "Epoch [16/100], Step [12700/6235], Loss: 14.6858\n",
      "Epoch [16/100], Step [12800/6235], Loss: 6.8604\n",
      "Epoch [16/100], Step [12900/6235], Loss: 47.5645\n",
      "Epoch [16/100], Step [13000/6235], Loss: 1.9597\n",
      "Epoch [16/100], Step [13100/6235], Loss: 113.6557\n",
      "Epoch [16/100], Step [13200/6235], Loss: 47.1956\n",
      "Epoch [16/100], Step [13300/6235], Loss: 0.2411\n",
      "Epoch [16/100], Step [13400/6235], Loss: 0.6709\n",
      "Epoch [16/100], Step [13500/6235], Loss: 1.0015\n",
      "Epoch [16/100], Step [13600/6235], Loss: 15.2718\n",
      "Epoch [16/100], Step [13700/6235], Loss: 171.6673\n",
      "Epoch [16/100], Step [13800/6235], Loss: 151.6440\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Step [13900/6235], Loss: 46.9758\n",
      "Epoch [16/100], Step [14000/6235], Loss: 3.7580\n",
      "Epoch [16/100], Step [14100/6235], Loss: 228.1737\n",
      "Epoch [16/100], Step [14200/6235], Loss: 0.9740\n",
      "Epoch [16/100], Step [14300/6235], Loss: 11.3977\n",
      "Epoch [16/100], Step [14400/6235], Loss: 0.2840\n",
      "Epoch [16/100], Step [14500/6235], Loss: 15.3366\n",
      "Epoch [16/100], Step [14600/6235], Loss: 7.4689\n",
      "Epoch [16/100], Step [14700/6235], Loss: 6.6831\n",
      "Epoch [16/100], Step [14800/6235], Loss: 15.8335\n",
      "Epoch [16/100], Step [14900/6235], Loss: 0.1544\n",
      "Epoch [16/100], Step [15000/6235], Loss: 0.1116\n",
      "Epoch [16/100], Step [15100/6235], Loss: 0.1385\n",
      "Epoch [16/100], Step [15200/6235], Loss: 9.1332\n",
      "Epoch [16/100], Step [15300/6235], Loss: 32.1285\n",
      "Epoch [16/100], Step [15400/6235], Loss: 6.9867\n",
      "Epoch [16/100], Step [15500/6235], Loss: 39.0028\n",
      "Epoch [16/100], Step [15600/6235], Loss: 50.7510\n",
      "Epoch [16/100], Step [15700/6235], Loss: 6.8986\n",
      "Epoch [16/100], Step [15800/6235], Loss: 5.4692\n",
      "Epoch [16/100], Step [15900/6235], Loss: 3.0615\n",
      "Epoch [16/100], Step [16000/6235], Loss: 12.2943\n",
      "Epoch [16/100], Step [16100/6235], Loss: 0.4983\n",
      "Epoch [16/100], Step [16200/6235], Loss: 3.5355\n",
      "Epoch [16/100], Step [16300/6235], Loss: 43.9644\n",
      "Epoch [16/100], Step [16400/6235], Loss: 74.4117\n",
      "Epoch [16/100], Step [16500/6235], Loss: 589.2183\n",
      "Epoch [16/100], Step [16600/6235], Loss: 13.7437\n",
      "Epoch [16/100], Step [16700/6235], Loss: 2.8109\n",
      "Epoch [16/100], Step [16800/6235], Loss: 0.9794\n",
      "Epoch [16/100], Step [16900/6235], Loss: 9.6298\n",
      "Epoch [16/100], Step [17000/6235], Loss: 1.7602\n",
      "Epoch [16/100], Step [17100/6235], Loss: 0.1525\n",
      "Epoch [16/100], Step [17200/6235], Loss: 54.8967\n",
      "Epoch [16/100], Step [17300/6235], Loss: 21.3344\n",
      "Epoch [16/100], Step [17400/6235], Loss: 35.1040\n",
      "Epoch [16/100], Step [17500/6235], Loss: 2.1379\n",
      "Epoch [16/100], Step [17600/6235], Loss: 0.5548\n",
      "Epoch [16/100], Step [17700/6235], Loss: 133.5335\n",
      "Epoch [16/100], Step [17800/6235], Loss: 29.7904\n",
      "Epoch [16/100], Step [17900/6235], Loss: 36.0023\n",
      "Epoch [16/100], Step [18000/6235], Loss: 1.0421\n",
      "Epoch [16/100], Step [18100/6235], Loss: 10.7672\n",
      "Epoch [16/100], Step [18200/6235], Loss: 20.1937\n",
      "Epoch [16/100], Step [18300/6235], Loss: 3.7279\n",
      "Epoch [16/100], Step [18400/6235], Loss: 17.5068\n",
      "Epoch [16/100], Step [18500/6235], Loss: 18.8308\n",
      "Epoch [16/100], Step [18600/6235], Loss: 5.4493\n",
      "Epoch [16/100], Step [18700/6235], Loss: 0.2395\n",
      "Epoch [16/100], Step [18800/6235], Loss: 67.1480\n",
      "Epoch [16/100], Step [18900/6235], Loss: 0.9249\n",
      "Epoch [16/100], Step [19000/6235], Loss: 14.2516\n",
      "Epoch [16/100], Step [19100/6235], Loss: 20.7839\n",
      "Epoch [16/100], Step [19200/6235], Loss: 1.3826\n",
      "Epoch [16/100], Step [19300/6235], Loss: 14.5197\n",
      "Epoch [16/100], Step [19400/6235], Loss: 188.8891\n",
      "Epoch [16/100], Step [19500/6235], Loss: 150.7937\n",
      "Epoch [16/100], Step [19600/6235], Loss: 149.1724\n",
      "Epoch [16/100], Step [19700/6235], Loss: 22.9296\n",
      "Epoch [16/100], Step [19800/6235], Loss: 3.9686\n",
      "Epoch [16/100], Step [19900/6235], Loss: 0.3671\n",
      "Epoch [16/100], Step [20000/6235], Loss: 104.3480\n",
      "Epoch [16/100], Step [20100/6235], Loss: 13.7288\n",
      "Epoch [16/100], Step [20200/6235], Loss: 2.8313\n",
      "Epoch [16/100], Step [20300/6235], Loss: 0.9547\n",
      "Epoch [16/100], Step [20400/6235], Loss: 32.6857\n",
      "Epoch [16/100], Step [20500/6235], Loss: 22.0929\n",
      "Epoch [16/100], Step [20600/6235], Loss: 224.7845\n",
      "Epoch [16/100], Step [20700/6235], Loss: 49.4808\n",
      "Epoch [16/100], Step [20800/6235], Loss: 1.0306\n",
      "Epoch [16/100], Step [20900/6235], Loss: 30.9769\n",
      "Epoch [16/100], Step [21000/6235], Loss: 23.2964\n",
      "Epoch [16/100], Step [21100/6235], Loss: 19.7867\n",
      "Epoch [16/100], Step [21200/6235], Loss: 0.7686\n",
      "Epoch [16/100], Step [21300/6235], Loss: 1.3401\n",
      "Epoch [16/100], Step [21400/6235], Loss: 2.6846\n",
      "Epoch [16/100], Step [21500/6235], Loss: 4.1450\n",
      "Epoch [16/100], Step [21600/6235], Loss: 32.6639\n",
      "Epoch [16/100], Step [21700/6235], Loss: 0.4481\n",
      "Epoch [16/100], Step [21800/6235], Loss: 16.4066\n",
      "Epoch [16/100], Step [21900/6235], Loss: 0.0566\n",
      "Epoch [16/100], Step [22000/6235], Loss: 0.2740\n",
      "Epoch [16/100], Step [22100/6235], Loss: 5.9738\n",
      "Epoch [16/100], Step [22200/6235], Loss: 10.5139\n",
      "Epoch [16/100], Step [22300/6235], Loss: 0.3495\n",
      "Epoch [16/100], Step [22400/6235], Loss: 8.3663\n",
      "Epoch [16/100], Step [22500/6235], Loss: 116.2428\n",
      "Epoch [16/100], Step [22600/6235], Loss: 15.9293\n",
      "Epoch [16/100], Step [22700/6235], Loss: 1.6437\n",
      "Epoch [16/100], Step [22800/6235], Loss: 2.6597\n",
      "Epoch [16/100], Step [22900/6235], Loss: 20.6843\n",
      "Epoch [16/100], Step [23000/6235], Loss: 4.3449\n",
      "Epoch [16/100], Step [23100/6235], Loss: 7.8998\n",
      "Epoch [16/100], Step [23200/6235], Loss: 13.7818\n",
      "Epoch [16/100], Step [23300/6235], Loss: 18.6011\n",
      "Epoch [16/100], Step [23400/6235], Loss: 1.0071\n",
      "Epoch [16/100], Step [23500/6235], Loss: 0.1999\n",
      "Epoch [16/100], Step [23600/6235], Loss: 83.6110\n",
      "Epoch [16/100], Step [23700/6235], Loss: 5.3634\n",
      "Epoch [16/100], Step [23800/6235], Loss: 0.6738\n",
      "Epoch [16/100], Step [23900/6235], Loss: 8.0403\n",
      "Epoch [16/100], Step [24000/6235], Loss: 0.8857\n",
      "Epoch [16/100], Step [24100/6235], Loss: 3.4791\n",
      "Epoch [16/100], Step [24200/6235], Loss: 21.4134\n",
      "Epoch [16/100], Step [24300/6235], Loss: 1.9138\n",
      "Epoch [16/100], Step [24400/6235], Loss: 9.2646\n",
      "Epoch [16/100], Step [24500/6235], Loss: 3.8130\n",
      "Epoch [16/100], Step [24600/6235], Loss: 0.3098\n",
      "Epoch [16/100], Step [24700/6235], Loss: 1.8164\n",
      "Epoch [16/100], Step [24800/6235], Loss: 0.4659\n",
      "Epoch [16/100], Step [24900/6235], Loss: 4.1746\n",
      "Epoch [16/100], Step [25000/6235], Loss: 20.1230\n",
      "Epoch [16/100], Step [25100/6235], Loss: 7.5120\n",
      "Epoch [16/100], Step [25200/6235], Loss: 2.0492\n",
      "Epoch [16/100], Step [25300/6235], Loss: 1.6273\n",
      "Epoch [16/100], Step [25400/6235], Loss: 9.7065\n",
      "Epoch [16/100], Step [25500/6235], Loss: 6.1975\n",
      "Epoch [16/100], Step [25600/6235], Loss: 1.7868\n",
      "Epoch [16/100], Step [25700/6235], Loss: 0.3638\n",
      "Epoch [16/100], Step [25800/6235], Loss: 0.1433\n",
      "Epoch [16/100], Step [25900/6235], Loss: 9.2039\n",
      "Epoch [16/100], Step [26000/6235], Loss: 0.0299\n",
      "Epoch [16/100], Step [26100/6235], Loss: 0.1993\n",
      "Epoch [16/100], Step [26200/6235], Loss: 0.6478\n",
      "Epoch [16/100], Step [26300/6235], Loss: 5.9624\n",
      "Epoch [16/100], Step [26400/6235], Loss: 0.0706\n",
      "Epoch [16/100], Step [26500/6235], Loss: 1.4626\n",
      "Epoch [16/100], Step [26600/6235], Loss: 4.2668\n",
      "Epoch [16/100], Step [26700/6235], Loss: 0.8562\n",
      "Epoch [16/100], Step [26800/6235], Loss: 1.2735\n",
      "Epoch [16/100], Step [26900/6235], Loss: 0.1304\n",
      "Epoch [16/100], Step [27000/6235], Loss: 11.5584\n",
      "Epoch [16/100], Step [27100/6235], Loss: 0.1958\n",
      "Epoch [16/100], Step [27200/6235], Loss: 0.0717\n",
      "Epoch [16/100], Step [27300/6235], Loss: 0.1650\n",
      "Epoch [16/100], Step [27400/6235], Loss: 1.0329\n",
      "Epoch [16/100], Step [27500/6235], Loss: 11.8525\n",
      "Epoch [16/100], Step [27600/6235], Loss: 0.6911\n",
      "Epoch [16/100], Step [27700/6235], Loss: 0.9707\n",
      "Epoch [16/100], Step [27800/6235], Loss: 2.4625\n",
      "Epoch [16/100], Step [27900/6235], Loss: 0.5475\n",
      "Epoch [16/100], Step [28000/6235], Loss: 181.4623\n",
      "Epoch [16/100], Step [28100/6235], Loss: 1.4488\n",
      "Epoch [16/100], Step [28200/6235], Loss: 34.6411\n",
      "Epoch [16/100], Step [28300/6235], Loss: 4.1843\n",
      "Epoch [16/100], Step [28400/6235], Loss: 19.0516\n",
      "Epoch [16/100], Step [28500/6235], Loss: 1.1673\n",
      "Epoch [16/100], Step [28600/6235], Loss: 1.2120\n",
      "Epoch [16/100], Step [28700/6235], Loss: 3.7421\n",
      "Epoch [16/100], Step [28800/6235], Loss: 0.2320\n",
      "Epoch [16/100], Step [28900/6235], Loss: 68.5366\n",
      "Epoch [16/100], Step [29000/6235], Loss: 1.1468\n",
      "Epoch [16/100], Step [29100/6235], Loss: 0.6170\n",
      "Epoch [16/100], Step [29200/6235], Loss: 0.0981\n",
      "Epoch [16/100], Step [29300/6235], Loss: 10.6309\n",
      "Epoch [16/100], Step [29400/6235], Loss: 0.1788\n",
      "Epoch [16/100], Step [29500/6235], Loss: 3.2256\n",
      "Epoch [16/100], Step [29600/6235], Loss: 0.1845\n",
      "Epoch [16/100], Step [29700/6235], Loss: 0.1901\n",
      "Epoch [16/100], Step [29800/6235], Loss: 1.4372\n",
      "Epoch [16/100], Step [29900/6235], Loss: 0.1150\n",
      "Epoch [16/100], Step [30000/6235], Loss: 8.1539\n",
      "Epoch [16/100], Step [30100/6235], Loss: 11.0996\n",
      "Epoch [16/100], Step [30200/6235], Loss: 0.2518\n",
      "Epoch [16/100], Step [30300/6235], Loss: 0.4819\n",
      "Epoch [16/100], Step [30400/6235], Loss: 0.3691\n",
      "Epoch [16/100], Step [30500/6235], Loss: 2.0023\n",
      "Epoch [16/100], Step [30600/6235], Loss: 0.4806\n",
      "Epoch [16/100], Step [30700/6235], Loss: 0.1887\n",
      "Epoch [16/100], Step [30800/6235], Loss: 0.2320\n",
      "Epoch [16/100], Step [30900/6235], Loss: 2.1523\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Step [31000/6235], Loss: 0.0810\n",
      "Epoch [16/100], Step [31100/6235], Loss: 0.0973\n",
      "Epoch [16/100], Step [31200/6235], Loss: 9.4946\n",
      "Epoch [16/100], Step [31300/6235], Loss: 1.4087\n",
      "Epoch [16/100], Step [31400/6235], Loss: 1.1376\n",
      "Epoch [16/100], Step [31500/6235], Loss: 0.3832\n",
      "Epoch [16/100], Step [31600/6235], Loss: 3.8157\n",
      "Epoch [16/100], Step [31700/6235], Loss: 1.6807\n",
      "Epoch [16/100], Step [31800/6235], Loss: 1.8463\n",
      "Epoch [16/100], Step [31900/6235], Loss: 207.0674\n",
      "Epoch [16/100], Step [32000/6235], Loss: 14.3580\n",
      "Epoch [16/100], Step [32100/6235], Loss: 6.9959\n",
      "Epoch [16/100], Step [32200/6235], Loss: 56.9127\n",
      "Epoch [16/100], Step [32300/6235], Loss: 0.9423\n",
      "Epoch [16/100], Step [32400/6235], Loss: 0.3317\n",
      "Epoch [16/100], Step [32500/6235], Loss: 21.9089\n",
      "Epoch [16/100], Step [32600/6235], Loss: 0.8371\n",
      "Epoch [16/100], Step [32700/6235], Loss: 48.4253\n",
      "Epoch [16/100], Step [32800/6235], Loss: 0.4428\n",
      "Epoch [16/100], Step [32900/6235], Loss: 15.6262\n",
      "Epoch [16/100], Step [33000/6235], Loss: 0.1018\n",
      "Epoch [16/100], Step [33100/6235], Loss: 0.9193\n",
      "Epoch [16/100], Step [33200/6235], Loss: 1.8774\n",
      "Epoch [16/100], Step [33300/6235], Loss: 7.9942\n",
      "Epoch [16/100], Step [33400/6235], Loss: 141.1064\n",
      "Epoch [16/100], Step [33500/6235], Loss: 2.3659\n",
      "Epoch [16/100], Step [33600/6235], Loss: 1.4772\n",
      "Epoch [16/100], Step [33700/6235], Loss: 0.1564\n",
      "Epoch [16/100], Step [33800/6235], Loss: 28.6948\n",
      "Epoch [16/100], Step [33900/6235], Loss: 31.1114\n",
      "Epoch [16/100], Step [34000/6235], Loss: 0.0086\n",
      "Epoch [16/100], Step [34100/6235], Loss: 0.0548\n",
      "Epoch [16/100], Step [34200/6235], Loss: 9.0084\n",
      "Epoch [16/100], Step [34300/6235], Loss: 3.4453\n",
      "Epoch [16/100], Step [34400/6235], Loss: 0.4562\n",
      "Epoch [16/100], Step [34500/6235], Loss: 141.1230\n",
      "Epoch [16/100], Step [34600/6235], Loss: 2.9119\n",
      "Epoch [16/100], Step [34700/6235], Loss: 5.3594\n",
      "Epoch [16/100], Step [34800/6235], Loss: 8.7533\n",
      "Epoch [16/100], Step [34900/6235], Loss: 57.1969\n",
      "Epoch [16/100], Step [35000/6235], Loss: 0.2345\n",
      "Epoch [16/100], Step [35100/6235], Loss: 3.7948\n",
      "Epoch [16/100], Step [35200/6235], Loss: 5.4223\n",
      "Epoch [16/100], Step [35300/6235], Loss: 0.6530\n",
      "Epoch [16/100], Step [35400/6235], Loss: 0.7839\n",
      "Epoch [16/100], Step [35500/6235], Loss: 0.9362\n",
      "Epoch [16/100], Step [35600/6235], Loss: 8.4472\n",
      "Epoch [16/100], Step [35700/6235], Loss: 6.4547\n",
      "Epoch [16/100], Step [35800/6235], Loss: 0.4415\n",
      "Epoch [16/100], Step [35900/6235], Loss: 0.7655\n",
      "Epoch [16/100], Step [36000/6235], Loss: 0.7196\n",
      "Epoch [16/100], Step [36100/6235], Loss: 4.5436\n",
      "Epoch [16/100], Step [36200/6235], Loss: 24.5041\n",
      "Epoch [16/100], Step [36300/6235], Loss: 1.5756\n",
      "Epoch [16/100], Step [36400/6235], Loss: 0.0328\n",
      "Epoch [16/100], Step [36500/6235], Loss: 11.9032\n",
      "Epoch [16/100], Step [36600/6235], Loss: 0.6324\n",
      "Epoch [16/100], Step [36700/6235], Loss: 0.7605\n",
      "Epoch [16/100], Step [36800/6235], Loss: 33.3686\n",
      "Epoch [16/100], Step [36900/6235], Loss: 2.9847\n",
      "Epoch [16/100], Step [37000/6235], Loss: 1.0039\n",
      "Epoch [16/100], Step [37100/6235], Loss: 1.1326\n",
      "Epoch [16/100], Step [37200/6235], Loss: 0.0285\n",
      "Epoch [16/100], Step [37300/6235], Loss: 0.6890\n",
      "Epoch [16/100], Step [37400/6235], Loss: 0.6724\n",
      "Epoch [16/100], Step [37500/6235], Loss: 2.7913\n",
      "Epoch [16/100], Step [37600/6235], Loss: 5.9829\n",
      "Epoch [16/100], Step [37700/6235], Loss: 0.4093\n",
      "Epoch [16/100], Step [37800/6235], Loss: 1.9239\n",
      "Epoch [16/100], Step [37900/6235], Loss: 6.0152\n",
      "Epoch [16/100], Step [38000/6235], Loss: 0.2011\n",
      "Epoch [16/100], Step [38100/6235], Loss: 7.9941\n",
      "Epoch [16/100], Step [38200/6235], Loss: 1.3994\n",
      "Epoch [16/100], Step [38300/6235], Loss: 3.9157\n",
      "Epoch [16/100], Step [38400/6235], Loss: 0.0832\n",
      "Epoch [16/100], Step [38500/6235], Loss: 1.9927\n",
      "Epoch [16/100], Step [38600/6235], Loss: 2.7084\n",
      "Epoch [16/100], Step [38700/6235], Loss: 0.1053\n",
      "Epoch [16/100], Step [38800/6235], Loss: 1.4234\n",
      "Epoch [16/100], Step [38900/6235], Loss: 2.4754\n",
      "Epoch [16/100], Step [39000/6235], Loss: 0.9311\n",
      "Epoch [16/100], Step [39100/6235], Loss: 24.3785\n",
      "Epoch [16/100], Step [39200/6235], Loss: 1.3551\n",
      "Epoch [16/100], Step [39300/6235], Loss: 2.7484\n",
      "Epoch [16/100], Step [39400/6235], Loss: 39.2297\n",
      "Epoch [16/100], Step [39500/6235], Loss: 16.4597\n",
      "Epoch [16/100], Step [39600/6235], Loss: 3.9944\n",
      "Epoch [16/100], Step [39700/6235], Loss: 177.9097\n",
      "Epoch [16/100], Step [39800/6235], Loss: 169.9087\n",
      "Epoch [16/100], Step [39900/6235], Loss: 0.4662\n",
      "Epoch [16/100], Step [40000/6235], Loss: 4.5628\n",
      "Epoch [16/100], Step [40100/6235], Loss: 30.5036\n",
      "Epoch [16/100], Step [40200/6235], Loss: 1.0450\n",
      "Epoch [16/100], Step [40300/6235], Loss: 0.3950\n",
      "Epoch [16/100], Step [40400/6235], Loss: 2.1661\n",
      "Epoch [16/100], Step [40500/6235], Loss: 2.4490\n",
      "Epoch [16/100], Step [40600/6235], Loss: 0.2510\n",
      "Epoch [16/100], Step [40700/6235], Loss: 7.7734\n",
      "Epoch [16/100], Step [40800/6235], Loss: 1.8459\n",
      "Epoch [16/100], Step [40900/6235], Loss: 0.0647\n",
      "Epoch [16/100], Step [41000/6235], Loss: 19.2429\n",
      "Epoch [16/100], Step [41100/6235], Loss: 12.4970\n",
      "Epoch [16/100], Step [41200/6235], Loss: 18.0692\n",
      "Epoch [16/100], Step [41300/6235], Loss: 0.1280\n",
      "Epoch [16/100], Step [41400/6235], Loss: 0.2820\n",
      "Epoch [16/100], Step [41500/6235], Loss: 1.0016\n",
      "Epoch [16/100], Step [41600/6235], Loss: 0.0108\n",
      "Epoch [16/100], Step [41700/6235], Loss: 0.4278\n",
      "Epoch [16/100], Step [41800/6235], Loss: 1.3168\n",
      "Epoch [16/100], Step [41900/6235], Loss: 3.4111\n",
      "Epoch [16/100], Step [42000/6235], Loss: 1.9177\n",
      "Epoch [16/100], Step [42100/6235], Loss: 5.1610\n",
      "Epoch [16/100], Step [42200/6235], Loss: 50.6746\n",
      "Epoch [16/100], Step [42300/6235], Loss: 0.8265\n",
      "Epoch [16/100], Step [42400/6235], Loss: 5.3466\n",
      "Epoch [16/100], Step [42500/6235], Loss: 0.6784\n",
      "Epoch [16/100], Step [42600/6235], Loss: 0.4475\n",
      "Epoch [16/100], Step [42700/6235], Loss: 0.2154\n",
      "Epoch [16/100], Step [42800/6235], Loss: 0.5154\n",
      "Epoch [16/100], Step [42900/6235], Loss: 4.0992\n",
      "Epoch [16/100], Step [43000/6235], Loss: 0.4569\n",
      "Epoch [16/100], Step [43100/6235], Loss: 2.1550\n",
      "Epoch [16/100], Step [43200/6235], Loss: 0.3687\n",
      "Epoch [16/100], Step [43300/6235], Loss: 10.5968\n",
      "Epoch [16/100], Step [43400/6235], Loss: 10.4084\n",
      "Epoch [16/100], Step [43500/6235], Loss: 9.1348\n",
      "Epoch [16/100], Step [43600/6235], Loss: 28.3697\n",
      "Epoch [16/100], Step [43700/6235], Loss: 47.2181\n",
      "Epoch [16/100], Step [43800/6235], Loss: 0.8398\n",
      "Epoch [16/100], Step [43900/6235], Loss: 2.6853\n",
      "Epoch [16/100], Step [44000/6235], Loss: 59.3076\n",
      "Epoch [16/100], Step [44100/6235], Loss: 1.4364\n",
      "Epoch [16/100], Step [44200/6235], Loss: 2.0704\n",
      "Epoch [16/100], Step [44300/6235], Loss: 78.3532\n",
      "Epoch [16/100], Step [44400/6235], Loss: 0.7141\n",
      "Epoch [16/100], Step [44500/6235], Loss: 0.8510\n",
      "Epoch [16/100], Step [44600/6235], Loss: 17.9425\n",
      "Epoch [16/100], Step [44700/6235], Loss: 17.6173\n",
      "Epoch [16/100], Step [44800/6235], Loss: 3.0661\n",
      "Epoch [16/100], Step [44900/6235], Loss: 4.8134\n",
      "Epoch [16/100], Step [45000/6235], Loss: 4.8669\n",
      "Epoch [16/100], Step [45100/6235], Loss: 70.3223\n",
      "Epoch [16/100], Step [45200/6235], Loss: 1.0209\n",
      "Epoch [16/100], Step [45300/6235], Loss: 26.6582\n",
      "Epoch [16/100], Step [45400/6235], Loss: 12.0195\n",
      "Epoch [16/100], Step [45500/6235], Loss: 0.7801\n",
      "Epoch [16/100], Step [45600/6235], Loss: 0.2359\n",
      "Epoch [16/100], Step [45700/6235], Loss: 89.9825\n",
      "Epoch [16/100], Step [45800/6235], Loss: 301.2025\n",
      "Epoch [16/100], Step [45900/6235], Loss: 18.7234\n",
      "Epoch [16/100], Step [46000/6235], Loss: 32.1610\n",
      "Epoch [16/100], Step [46100/6235], Loss: 30.0397\n",
      "Epoch [16/100], Step [46200/6235], Loss: 2.7634\n",
      "Epoch [16/100], Step [46300/6235], Loss: 3.1350\n",
      "Epoch [16/100], Step [46400/6235], Loss: 11.8426\n",
      "Epoch [16/100], Step [46500/6235], Loss: 17.7200\n",
      "Epoch [16/100], Step [46600/6235], Loss: 26.3322\n",
      "Epoch [16/100], Step [46700/6235], Loss: 11.1481\n",
      "Epoch [16/100], Step [46800/6235], Loss: 3.6137\n",
      "Epoch [16/100], Step [46900/6235], Loss: 3.1073\n",
      "Epoch [16/100], Step [47000/6235], Loss: 6.6327\n",
      "Epoch [16/100], Step [47100/6235], Loss: 1.5940\n",
      "Epoch [16/100], Step [47200/6235], Loss: 4.6023\n",
      "Epoch [16/100], Step [47300/6235], Loss: 0.3355\n",
      "Epoch [16/100], Step [47400/6235], Loss: 33.3301\n",
      "Epoch [16/100], Step [47500/6235], Loss: 0.4086\n",
      "Epoch [16/100], Step [47600/6235], Loss: 0.8291\n",
      "Epoch [16/100], Step [47700/6235], Loss: 6.8795\n",
      "Epoch [16/100], Step [47800/6235], Loss: 0.6539\n",
      "Epoch [16/100], Step [47900/6235], Loss: 25.2740\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [16/100], Step [48000/6235], Loss: 100.3727\n",
      "Epoch [16/100], Step [48100/6235], Loss: 2.6352\n",
      "Epoch [16/100], Step [48200/6235], Loss: 8.6491\n",
      "Epoch [16/100], Step [48300/6235], Loss: 146.1220\n",
      "Epoch [16/100], Step [48400/6235], Loss: 50.0094\n",
      "Epoch [16/100], Step [48500/6235], Loss: 5.7252\n",
      "Epoch [16/100], Step [48600/6235], Loss: 122.0449\n",
      "Epoch [16/100], Step [48700/6235], Loss: 100.3737\n",
      "Epoch [16/100], Step [48800/6235], Loss: 198.8168\n",
      "Epoch [16/100], Step [48900/6235], Loss: 58.5638\n",
      "Epoch [16/100], Step [49000/6235], Loss: 281.0606\n",
      "Epoch [16/100], Step [49100/6235], Loss: 1058.9677\n",
      "Epoch [16/100], Step [49200/6235], Loss: 660.3394\n",
      "Epoch [16/100], Step [49300/6235], Loss: 1101.9945\n",
      "Epoch [16/100], Step [49400/6235], Loss: 30.6721\n",
      "Epoch [16/100], Step [49500/6235], Loss: 36.9702\n",
      "Epoch [16/100], Step [49600/6235], Loss: 143.1773\n",
      "Epoch [16/100], Step [49700/6235], Loss: 1800.5984\n",
      "Epoch [16/100], Step [49800/6235], Loss: 7.3569\n",
      "Epoch [17/100], Step [100/6235], Loss: 13.2688\n",
      "Epoch [17/100], Step [200/6235], Loss: 1.1594\n",
      "Epoch [17/100], Step [300/6235], Loss: 0.1871\n",
      "Epoch [17/100], Step [400/6235], Loss: 0.1061\n",
      "Epoch [17/100], Step [500/6235], Loss: 0.6125\n",
      "Epoch [17/100], Step [600/6235], Loss: 0.0610\n",
      "Epoch [17/100], Step [700/6235], Loss: 0.4536\n",
      "Epoch [17/100], Step [800/6235], Loss: 0.1491\n",
      "Epoch [17/100], Step [900/6235], Loss: 0.0590\n",
      "Epoch [17/100], Step [1000/6235], Loss: 0.0520\n",
      "Epoch [17/100], Step [1100/6235], Loss: 0.1940\n",
      "Epoch [17/100], Step [1200/6235], Loss: 0.2017\n",
      "Epoch [17/100], Step [1300/6235], Loss: 0.0687\n",
      "Epoch [17/100], Step [1400/6235], Loss: 0.3580\n",
      "Epoch [17/100], Step [1500/6235], Loss: 0.0232\n",
      "Epoch [17/100], Step [1600/6235], Loss: 0.2491\n",
      "Epoch [17/100], Step [1700/6235], Loss: 0.1223\n",
      "Epoch [17/100], Step [1800/6235], Loss: 0.2538\n",
      "Epoch [17/100], Step [1900/6235], Loss: 0.6712\n",
      "Epoch [17/100], Step [2000/6235], Loss: 2.6143\n",
      "Epoch [17/100], Step [2100/6235], Loss: 3.5084\n",
      "Epoch [17/100], Step [2200/6235], Loss: 9.4122\n",
      "Epoch [17/100], Step [2300/6235], Loss: 12.4011\n",
      "Epoch [17/100], Step [2400/6235], Loss: 4.7318\n",
      "Epoch [17/100], Step [2500/6235], Loss: 37.5015\n",
      "Epoch [17/100], Step [2600/6235], Loss: 10.3509\n",
      "Epoch [17/100], Step [2700/6235], Loss: 18.2384\n",
      "Epoch [17/100], Step [2800/6235], Loss: 164.0775\n",
      "Epoch [17/100], Step [2900/6235], Loss: 6.5102\n",
      "Epoch [17/100], Step [3000/6235], Loss: 0.1308\n",
      "Epoch [17/100], Step [3100/6235], Loss: 68.5363\n",
      "Epoch [17/100], Step [3200/6235], Loss: 85.3603\n",
      "Epoch [17/100], Step [3300/6235], Loss: 1.8056\n",
      "Epoch [17/100], Step [3400/6235], Loss: 2.5233\n",
      "Epoch [17/100], Step [3500/6235], Loss: 27.6014\n",
      "Epoch [17/100], Step [3600/6235], Loss: 9.8962\n",
      "Epoch [17/100], Step [3700/6235], Loss: 0.8595\n",
      "Epoch [17/100], Step [3800/6235], Loss: 0.5572\n",
      "Epoch [17/100], Step [3900/6235], Loss: 1.6975\n",
      "Epoch [17/100], Step [4000/6235], Loss: 0.0458\n",
      "Epoch [17/100], Step [4100/6235], Loss: 4.6623\n",
      "Epoch [17/100], Step [4200/6235], Loss: 0.8133\n",
      "Epoch [17/100], Step [4300/6235], Loss: 9.0190\n",
      "Epoch [17/100], Step [4400/6235], Loss: 4.5288\n",
      "Epoch [17/100], Step [4500/6235], Loss: 54.4685\n",
      "Epoch [17/100], Step [4600/6235], Loss: 7.0750\n",
      "Epoch [17/100], Step [4700/6235], Loss: 1.1376\n",
      "Epoch [17/100], Step [4800/6235], Loss: 2.5525\n",
      "Epoch [17/100], Step [4900/6235], Loss: 0.0484\n",
      "Epoch [17/100], Step [5000/6235], Loss: 0.2812\n",
      "Epoch [17/100], Step [5100/6235], Loss: 2.2076\n",
      "Epoch [17/100], Step [5200/6235], Loss: 2.2156\n",
      "Epoch [17/100], Step [5300/6235], Loss: 32.3951\n",
      "Epoch [17/100], Step [5400/6235], Loss: 1.1529\n",
      "Epoch [17/100], Step [5500/6235], Loss: 0.3825\n",
      "Epoch [17/100], Step [5600/6235], Loss: 0.3463\n",
      "Epoch [17/100], Step [5700/6235], Loss: 1.8529\n",
      "Epoch [17/100], Step [5800/6235], Loss: 0.8910\n",
      "Epoch [17/100], Step [5900/6235], Loss: 0.0479\n",
      "Epoch [17/100], Step [6000/6235], Loss: 1.0227\n",
      "Epoch [17/100], Step [6100/6235], Loss: 0.1201\n",
      "Epoch [17/100], Step [6200/6235], Loss: 0.8731\n",
      "Epoch [17/100], Step [6300/6235], Loss: 1.4905\n",
      "Epoch [17/100], Step [6400/6235], Loss: 0.0673\n",
      "Epoch [17/100], Step [6500/6235], Loss: 0.3675\n",
      "Epoch [17/100], Step [6600/6235], Loss: 31.6882\n",
      "Epoch [17/100], Step [6700/6235], Loss: 0.8329\n",
      "Epoch [17/100], Step [6800/6235], Loss: 0.4770\n",
      "Epoch [17/100], Step [6900/6235], Loss: 2.6947\n",
      "Epoch [17/100], Step [7000/6235], Loss: 0.7224\n",
      "Epoch [17/100], Step [7100/6235], Loss: 0.2912\n",
      "Epoch [17/100], Step [7200/6235], Loss: 0.1817\n",
      "Epoch [17/100], Step [7300/6235], Loss: 1.1360\n",
      "Epoch [17/100], Step [7400/6235], Loss: 0.2078\n",
      "Epoch [17/100], Step [7500/6235], Loss: 1.3525\n",
      "Epoch [17/100], Step [7600/6235], Loss: 19.5558\n",
      "Epoch [17/100], Step [7700/6235], Loss: 10.7372\n",
      "Epoch [17/100], Step [7800/6235], Loss: 15.8295\n",
      "Epoch [17/100], Step [7900/6235], Loss: 13.3731\n",
      "Epoch [17/100], Step [8000/6235], Loss: 0.5097\n",
      "Epoch [17/100], Step [8100/6235], Loss: 3.5643\n",
      "Epoch [17/100], Step [8200/6235], Loss: 23.6138\n",
      "Epoch [17/100], Step [8300/6235], Loss: 53.8232\n",
      "Epoch [17/100], Step [8400/6235], Loss: 26.2155\n",
      "Epoch [17/100], Step [8500/6235], Loss: 76.1774\n",
      "Epoch [17/100], Step [8600/6235], Loss: 3.0478\n",
      "Epoch [17/100], Step [8700/6235], Loss: 33.3806\n",
      "Epoch [17/100], Step [8800/6235], Loss: 462.0482\n",
      "Epoch [17/100], Step [8900/6235], Loss: 36.3927\n",
      "Epoch [17/100], Step [9000/6235], Loss: 501.7475\n",
      "Epoch [17/100], Step [9100/6235], Loss: 126.6833\n",
      "Epoch [17/100], Step [9200/6235], Loss: 2464.8538\n",
      "Epoch [17/100], Step [9300/6235], Loss: 17.9568\n",
      "Epoch [17/100], Step [9400/6235], Loss: 1281.9554\n",
      "Epoch [17/100], Step [9500/6235], Loss: 209.1031\n",
      "Epoch [17/100], Step [9600/6235], Loss: 40.6430\n",
      "Epoch [17/100], Step [9700/6235], Loss: 225.9004\n",
      "Epoch [17/100], Step [9800/6235], Loss: 335.3829\n",
      "Epoch [17/100], Step [9900/6235], Loss: 3.7624\n",
      "Epoch [17/100], Step [10000/6235], Loss: 8.1648\n",
      "Epoch [17/100], Step [10100/6235], Loss: 74.9276\n",
      "Epoch [17/100], Step [10200/6235], Loss: 626.4541\n",
      "Epoch [17/100], Step [10300/6235], Loss: 1.8588\n",
      "Epoch [17/100], Step [10400/6235], Loss: 6.3807\n",
      "Epoch [17/100], Step [10500/6235], Loss: 11.1167\n",
      "Epoch [17/100], Step [10600/6235], Loss: 1617.5227\n",
      "Epoch [17/100], Step [10700/6235], Loss: 190.7839\n",
      "Epoch [17/100], Step [10800/6235], Loss: 31.5582\n",
      "Epoch [17/100], Step [10900/6235], Loss: 4.7359\n",
      "Epoch [17/100], Step [11000/6235], Loss: 68.2490\n",
      "Epoch [17/100], Step [11100/6235], Loss: 2.0749\n",
      "Epoch [17/100], Step [11200/6235], Loss: 127.0576\n",
      "Epoch [17/100], Step [11300/6235], Loss: 226.4047\n",
      "Epoch [17/100], Step [11400/6235], Loss: 294.1605\n",
      "Epoch [17/100], Step [11500/6235], Loss: 15.7796\n",
      "Epoch [17/100], Step [11600/6235], Loss: 2.5910\n",
      "Epoch [17/100], Step [11700/6235], Loss: 172.8929\n",
      "Epoch [17/100], Step [11800/6235], Loss: 40.5913\n",
      "Epoch [17/100], Step [11900/6235], Loss: 828.2001\n",
      "Epoch [17/100], Step [12000/6235], Loss: 90.6986\n",
      "Epoch [17/100], Step [12100/6235], Loss: 475.7150\n",
      "Epoch [17/100], Step [12200/6235], Loss: 89.5277\n",
      "Epoch [17/100], Step [12300/6235], Loss: 31.1271\n",
      "Epoch [17/100], Step [12400/6235], Loss: 353.6394\n",
      "Epoch [17/100], Step [12500/6235], Loss: 225.8406\n",
      "Epoch [17/100], Step [12600/6235], Loss: 46.7873\n",
      "Epoch [17/100], Step [12700/6235], Loss: 30.0956\n",
      "Epoch [17/100], Step [12800/6235], Loss: 8.7247\n",
      "Epoch [17/100], Step [12900/6235], Loss: 52.3537\n",
      "Epoch [17/100], Step [13000/6235], Loss: 1.8693\n",
      "Epoch [17/100], Step [13100/6235], Loss: 116.7672\n",
      "Epoch [17/100], Step [13200/6235], Loss: 46.5725\n",
      "Epoch [17/100], Step [13300/6235], Loss: 1.5903\n",
      "Epoch [17/100], Step [13400/6235], Loss: 0.7426\n",
      "Epoch [17/100], Step [13500/6235], Loss: 0.5547\n",
      "Epoch [17/100], Step [13600/6235], Loss: 29.4986\n",
      "Epoch [17/100], Step [13700/6235], Loss: 206.0514\n",
      "Epoch [17/100], Step [13800/6235], Loss: 131.6054\n",
      "Epoch [17/100], Step [13900/6235], Loss: 9.5205\n",
      "Epoch [17/100], Step [14000/6235], Loss: 0.5060\n",
      "Epoch [17/100], Step [14100/6235], Loss: 343.7447\n",
      "Epoch [17/100], Step [14200/6235], Loss: 35.0143\n",
      "Epoch [17/100], Step [14300/6235], Loss: 24.2193\n",
      "Epoch [17/100], Step [14400/6235], Loss: 0.2912\n",
      "Epoch [17/100], Step [14500/6235], Loss: 8.6673\n",
      "Epoch [17/100], Step [14600/6235], Loss: 3.9729\n",
      "Epoch [17/100], Step [14700/6235], Loss: 9.7325\n",
      "Epoch [17/100], Step [14800/6235], Loss: 11.0674\n",
      "Epoch [17/100], Step [14900/6235], Loss: 0.0757\n",
      "Epoch [17/100], Step [15000/6235], Loss: 0.0148\n",
      "Epoch [17/100], Step [15100/6235], Loss: 0.1352\n",
      "Epoch [17/100], Step [15200/6235], Loss: 18.2491\n",
      "Epoch [17/100], Step [15300/6235], Loss: 22.3697\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Step [15400/6235], Loss: 0.8277\n",
      "Epoch [17/100], Step [15500/6235], Loss: 36.5367\n",
      "Epoch [17/100], Step [15600/6235], Loss: 58.1354\n",
      "Epoch [17/100], Step [15700/6235], Loss: 23.3182\n",
      "Epoch [17/100], Step [15800/6235], Loss: 4.3697\n",
      "Epoch [17/100], Step [15900/6235], Loss: 3.4028\n",
      "Epoch [17/100], Step [16000/6235], Loss: 17.2127\n",
      "Epoch [17/100], Step [16100/6235], Loss: 0.5444\n",
      "Epoch [17/100], Step [16200/6235], Loss: 5.1361\n",
      "Epoch [17/100], Step [16300/6235], Loss: 44.6596\n",
      "Epoch [17/100], Step [16400/6235], Loss: 68.2770\n",
      "Epoch [17/100], Step [16500/6235], Loss: 614.4125\n",
      "Epoch [17/100], Step [16600/6235], Loss: 22.7170\n",
      "Epoch [17/100], Step [16700/6235], Loss: 2.7587\n",
      "Epoch [17/100], Step [16800/6235], Loss: 0.9924\n",
      "Epoch [17/100], Step [16900/6235], Loss: 9.3891\n",
      "Epoch [17/100], Step [17000/6235], Loss: 1.6150\n",
      "Epoch [17/100], Step [17100/6235], Loss: 0.1551\n",
      "Epoch [17/100], Step [17200/6235], Loss: 56.7806\n",
      "Epoch [17/100], Step [17300/6235], Loss: 21.6052\n",
      "Epoch [17/100], Step [17400/6235], Loss: 33.6300\n",
      "Epoch [17/100], Step [17500/6235], Loss: 1.4536\n",
      "Epoch [17/100], Step [17600/6235], Loss: 0.5072\n",
      "Epoch [17/100], Step [17700/6235], Loss: 1.1105\n",
      "Epoch [17/100], Step [17800/6235], Loss: 12.9021\n",
      "Epoch [17/100], Step [17900/6235], Loss: 12.3373\n",
      "Epoch [17/100], Step [18000/6235], Loss: 3.5272\n",
      "Epoch [17/100], Step [18100/6235], Loss: 13.7654\n",
      "Epoch [17/100], Step [18200/6235], Loss: 20.0461\n",
      "Epoch [17/100], Step [18300/6235], Loss: 2.9947\n",
      "Epoch [17/100], Step [18400/6235], Loss: 19.5652\n",
      "Epoch [17/100], Step [18500/6235], Loss: 20.9440\n",
      "Epoch [17/100], Step [18600/6235], Loss: 5.5426\n",
      "Epoch [17/100], Step [18700/6235], Loss: 0.2123\n",
      "Epoch [17/100], Step [18800/6235], Loss: 56.8574\n",
      "Epoch [17/100], Step [18900/6235], Loss: 3.6897\n",
      "Epoch [17/100], Step [19000/6235], Loss: 13.4454\n",
      "Epoch [17/100], Step [19100/6235], Loss: 3.6331\n",
      "Epoch [17/100], Step [19200/6235], Loss: 10.3748\n",
      "Epoch [17/100], Step [19300/6235], Loss: 0.9060\n",
      "Epoch [17/100], Step [19400/6235], Loss: 195.1109\n",
      "Epoch [17/100], Step [19500/6235], Loss: 125.0254\n",
      "Epoch [17/100], Step [19600/6235], Loss: 141.6593\n",
      "Epoch [17/100], Step [19700/6235], Loss: 14.4859\n",
      "Epoch [17/100], Step [19800/6235], Loss: 5.0617\n",
      "Epoch [17/100], Step [19900/6235], Loss: 0.2448\n",
      "Epoch [17/100], Step [20000/6235], Loss: 105.0025\n",
      "Epoch [17/100], Step [20100/6235], Loss: 13.8456\n",
      "Epoch [17/100], Step [20200/6235], Loss: 2.8196\n",
      "Epoch [17/100], Step [20300/6235], Loss: 0.9591\n",
      "Epoch [17/100], Step [20400/6235], Loss: 32.7477\n",
      "Epoch [17/100], Step [20500/6235], Loss: 21.6411\n",
      "Epoch [17/100], Step [20600/6235], Loss: 125.0689\n",
      "Epoch [17/100], Step [20700/6235], Loss: 0.8300\n",
      "Epoch [17/100], Step [20800/6235], Loss: 2.8816\n",
      "Epoch [17/100], Step [20900/6235], Loss: 15.8499\n",
      "Epoch [17/100], Step [21000/6235], Loss: 3.5689\n",
      "Epoch [17/100], Step [21100/6235], Loss: 17.7115\n",
      "Epoch [17/100], Step [21200/6235], Loss: 0.7634\n",
      "Epoch [17/100], Step [21300/6235], Loss: 1.7058\n",
      "Epoch [17/100], Step [21400/6235], Loss: 2.6472\n",
      "Epoch [17/100], Step [21500/6235], Loss: 4.5254\n",
      "Epoch [17/100], Step [21600/6235], Loss: 32.4543\n",
      "Epoch [17/100], Step [21700/6235], Loss: 0.2887\n",
      "Epoch [17/100], Step [21800/6235], Loss: 7.1818\n",
      "Epoch [17/100], Step [21900/6235], Loss: 0.0573\n",
      "Epoch [17/100], Step [22000/6235], Loss: 0.1927\n",
      "Epoch [17/100], Step [22100/6235], Loss: 5.9928\n",
      "Epoch [17/100], Step [22200/6235], Loss: 7.2557\n",
      "Epoch [17/100], Step [22300/6235], Loss: 3.2025\n",
      "Epoch [17/100], Step [22400/6235], Loss: 4.1239\n",
      "Epoch [17/100], Step [22500/6235], Loss: 85.1350\n",
      "Epoch [17/100], Step [22600/6235], Loss: 18.4910\n",
      "Epoch [17/100], Step [22700/6235], Loss: 1.1037\n",
      "Epoch [17/100], Step [22800/6235], Loss: 3.4036\n",
      "Epoch [17/100], Step [22900/6235], Loss: 2.5784\n",
      "Epoch [17/100], Step [23000/6235], Loss: 11.9878\n",
      "Epoch [17/100], Step [23100/6235], Loss: 4.3956\n",
      "Epoch [17/100], Step [23200/6235], Loss: 11.2292\n",
      "Epoch [17/100], Step [23300/6235], Loss: 19.5536\n",
      "Epoch [17/100], Step [23400/6235], Loss: 1.5930\n",
      "Epoch [17/100], Step [23500/6235], Loss: 0.1181\n",
      "Epoch [17/100], Step [23600/6235], Loss: 101.1814\n",
      "Epoch [17/100], Step [23700/6235], Loss: 8.0276\n",
      "Epoch [17/100], Step [23800/6235], Loss: 0.9436\n",
      "Epoch [17/100], Step [23900/6235], Loss: 7.5678\n",
      "Epoch [17/100], Step [24000/6235], Loss: 0.3752\n",
      "Epoch [17/100], Step [24100/6235], Loss: 1.8792\n",
      "Epoch [17/100], Step [24200/6235], Loss: 12.1151\n",
      "Epoch [17/100], Step [24300/6235], Loss: 1.6581\n",
      "Epoch [17/100], Step [24400/6235], Loss: 8.3043\n",
      "Epoch [17/100], Step [24500/6235], Loss: 3.5404\n",
      "Epoch [17/100], Step [24600/6235], Loss: 0.3482\n",
      "Epoch [17/100], Step [24700/6235], Loss: 4.7324\n",
      "Epoch [17/100], Step [24800/6235], Loss: 0.1008\n",
      "Epoch [17/100], Step [24900/6235], Loss: 0.3591\n",
      "Epoch [17/100], Step [25000/6235], Loss: 18.6706\n",
      "Epoch [17/100], Step [25100/6235], Loss: 8.3394\n",
      "Epoch [17/100], Step [25200/6235], Loss: 1.8849\n",
      "Epoch [17/100], Step [25300/6235], Loss: 1.0710\n",
      "Epoch [17/100], Step [25400/6235], Loss: 9.3622\n",
      "Epoch [17/100], Step [25500/6235], Loss: 7.6416\n",
      "Epoch [17/100], Step [25600/6235], Loss: 3.6006\n",
      "Epoch [17/100], Step [25700/6235], Loss: 0.3304\n",
      "Epoch [17/100], Step [25800/6235], Loss: 0.1851\n",
      "Epoch [17/100], Step [25900/6235], Loss: 8.1037\n",
      "Epoch [17/100], Step [26000/6235], Loss: 0.4814\n",
      "Epoch [17/100], Step [26100/6235], Loss: 0.4562\n",
      "Epoch [17/100], Step [26200/6235], Loss: 0.0641\n",
      "Epoch [17/100], Step [26300/6235], Loss: 4.7731\n",
      "Epoch [17/100], Step [26400/6235], Loss: 0.1427\n",
      "Epoch [17/100], Step [26500/6235], Loss: 0.2413\n",
      "Epoch [17/100], Step [26600/6235], Loss: 2.9826\n",
      "Epoch [17/100], Step [26700/6235], Loss: 0.6416\n",
      "Epoch [17/100], Step [26800/6235], Loss: 0.7601\n",
      "Epoch [17/100], Step [26900/6235], Loss: 0.0537\n",
      "Epoch [17/100], Step [27000/6235], Loss: 13.1381\n",
      "Epoch [17/100], Step [27100/6235], Loss: 0.0949\n",
      "Epoch [17/100], Step [27200/6235], Loss: 0.0378\n",
      "Epoch [17/100], Step [27300/6235], Loss: 0.2283\n",
      "Epoch [17/100], Step [27400/6235], Loss: 0.9230\n",
      "Epoch [17/100], Step [27500/6235], Loss: 14.7987\n",
      "Epoch [17/100], Step [27600/6235], Loss: 0.4131\n",
      "Epoch [17/100], Step [27700/6235], Loss: 1.3762\n",
      "Epoch [17/100], Step [27800/6235], Loss: 3.9502\n",
      "Epoch [17/100], Step [27900/6235], Loss: 0.1435\n",
      "Epoch [17/100], Step [28000/6235], Loss: 190.7400\n",
      "Epoch [17/100], Step [28100/6235], Loss: 1.3861\n",
      "Epoch [17/100], Step [28200/6235], Loss: 30.1604\n",
      "Epoch [17/100], Step [28300/6235], Loss: 4.0125\n",
      "Epoch [17/100], Step [28400/6235], Loss: 21.0687\n",
      "Epoch [17/100], Step [28500/6235], Loss: 1.2364\n",
      "Epoch [17/100], Step [28600/6235], Loss: 1.2046\n",
      "Epoch [17/100], Step [28700/6235], Loss: 4.0983\n",
      "Epoch [17/100], Step [28800/6235], Loss: 0.2756\n",
      "Epoch [17/100], Step [28900/6235], Loss: 72.8634\n",
      "Epoch [17/100], Step [29000/6235], Loss: 9.8491\n",
      "Epoch [17/100], Step [29100/6235], Loss: 0.0252\n",
      "Epoch [17/100], Step [29200/6235], Loss: 0.2214\n",
      "Epoch [17/100], Step [29300/6235], Loss: 0.4709\n",
      "Epoch [17/100], Step [29400/6235], Loss: 0.3223\n",
      "Epoch [17/100], Step [29500/6235], Loss: 7.7409\n",
      "Epoch [17/100], Step [29600/6235], Loss: 0.0526\n",
      "Epoch [17/100], Step [29700/6235], Loss: 1.4740\n",
      "Epoch [17/100], Step [29800/6235], Loss: 1.5861\n",
      "Epoch [17/100], Step [29900/6235], Loss: 0.4960\n",
      "Epoch [17/100], Step [30000/6235], Loss: 6.3112\n",
      "Epoch [17/100], Step [30100/6235], Loss: 6.5681\n",
      "Epoch [17/100], Step [30200/6235], Loss: 0.8767\n",
      "Epoch [17/100], Step [30300/6235], Loss: 0.0437\n",
      "Epoch [17/100], Step [30400/6235], Loss: 0.8330\n",
      "Epoch [17/100], Step [30500/6235], Loss: 2.9083\n",
      "Epoch [17/100], Step [30600/6235], Loss: 1.2041\n",
      "Epoch [17/100], Step [30700/6235], Loss: 0.0339\n",
      "Epoch [17/100], Step [30800/6235], Loss: 0.3554\n",
      "Epoch [17/100], Step [30900/6235], Loss: 3.2674\n",
      "Epoch [17/100], Step [31000/6235], Loss: 0.0157\n",
      "Epoch [17/100], Step [31100/6235], Loss: 0.0740\n",
      "Epoch [17/100], Step [31200/6235], Loss: 15.4619\n",
      "Epoch [17/100], Step [31300/6235], Loss: 2.3019\n",
      "Epoch [17/100], Step [31400/6235], Loss: 0.3596\n",
      "Epoch [17/100], Step [31500/6235], Loss: 0.4414\n",
      "Epoch [17/100], Step [31600/6235], Loss: 5.9012\n",
      "Epoch [17/100], Step [31700/6235], Loss: 3.5410\n",
      "Epoch [17/100], Step [31800/6235], Loss: 0.1767\n",
      "Epoch [17/100], Step [31900/6235], Loss: 2143.3694\n",
      "Epoch [17/100], Step [32000/6235], Loss: 77.7343\n",
      "Epoch [17/100], Step [32100/6235], Loss: 8.2093\n",
      "Epoch [17/100], Step [32200/6235], Loss: 44.6599\n",
      "Epoch [17/100], Step [32300/6235], Loss: 0.7219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Step [32400/6235], Loss: 0.3313\n",
      "Epoch [17/100], Step [32500/6235], Loss: 21.2558\n",
      "Epoch [17/100], Step [32600/6235], Loss: 0.7482\n",
      "Epoch [17/100], Step [32700/6235], Loss: 39.8653\n",
      "Epoch [17/100], Step [32800/6235], Loss: 0.3352\n",
      "Epoch [17/100], Step [32900/6235], Loss: 12.8431\n",
      "Epoch [17/100], Step [33000/6235], Loss: 0.1228\n",
      "Epoch [17/100], Step [33100/6235], Loss: 0.3148\n",
      "Epoch [17/100], Step [33200/6235], Loss: 2.5273\n",
      "Epoch [17/100], Step [33300/6235], Loss: 5.8006\n",
      "Epoch [17/100], Step [33400/6235], Loss: 106.1689\n",
      "Epoch [17/100], Step [33500/6235], Loss: 2.6716\n",
      "Epoch [17/100], Step [33600/6235], Loss: 1.0273\n",
      "Epoch [17/100], Step [33700/6235], Loss: 2.6872\n",
      "Epoch [17/100], Step [33800/6235], Loss: 8.4895\n",
      "Epoch [17/100], Step [33900/6235], Loss: 27.4605\n",
      "Epoch [17/100], Step [34000/6235], Loss: 0.0137\n",
      "Epoch [17/100], Step [34100/6235], Loss: 0.1106\n",
      "Epoch [17/100], Step [34200/6235], Loss: 15.0109\n",
      "Epoch [17/100], Step [34300/6235], Loss: 2.1825\n",
      "Epoch [17/100], Step [34400/6235], Loss: 1.2551\n",
      "Epoch [17/100], Step [34500/6235], Loss: 48.0442\n",
      "Epoch [17/100], Step [34600/6235], Loss: 2.6216\n",
      "Epoch [17/100], Step [34700/6235], Loss: 8.2522\n",
      "Epoch [17/100], Step [34800/6235], Loss: 9.2371\n",
      "Epoch [17/100], Step [34900/6235], Loss: 48.1093\n",
      "Epoch [17/100], Step [35000/6235], Loss: 0.1527\n",
      "Epoch [17/100], Step [35100/6235], Loss: 4.7928\n",
      "Epoch [17/100], Step [35200/6235], Loss: 6.0871\n",
      "Epoch [17/100], Step [35300/6235], Loss: 1.4120\n",
      "Epoch [17/100], Step [35400/6235], Loss: 0.6355\n",
      "Epoch [17/100], Step [35500/6235], Loss: 0.5663\n",
      "Epoch [17/100], Step [35600/6235], Loss: 10.2514\n",
      "Epoch [17/100], Step [35700/6235], Loss: 9.6025\n",
      "Epoch [17/100], Step [35800/6235], Loss: 1.2186\n",
      "Epoch [17/100], Step [35900/6235], Loss: 0.7264\n",
      "Epoch [17/100], Step [36000/6235], Loss: 0.6158\n",
      "Epoch [17/100], Step [36100/6235], Loss: 5.7221\n",
      "Epoch [17/100], Step [36200/6235], Loss: 18.6610\n",
      "Epoch [17/100], Step [36300/6235], Loss: 0.3791\n",
      "Epoch [17/100], Step [36400/6235], Loss: 0.0310\n",
      "Epoch [17/100], Step [36500/6235], Loss: 12.0727\n",
      "Epoch [17/100], Step [36600/6235], Loss: 0.7085\n",
      "Epoch [17/100], Step [36700/6235], Loss: 0.8070\n",
      "Epoch [17/100], Step [36800/6235], Loss: 31.8195\n",
      "Epoch [17/100], Step [36900/6235], Loss: 3.2208\n",
      "Epoch [17/100], Step [37000/6235], Loss: 1.0306\n",
      "Epoch [17/100], Step [37100/6235], Loss: 1.2582\n",
      "Epoch [17/100], Step [37200/6235], Loss: 0.0363\n",
      "Epoch [17/100], Step [37300/6235], Loss: 0.6893\n",
      "Epoch [17/100], Step [37400/6235], Loss: 0.7499\n",
      "Epoch [17/100], Step [37500/6235], Loss: 2.4850\n",
      "Epoch [17/100], Step [37600/6235], Loss: 5.7992\n",
      "Epoch [17/100], Step [37700/6235], Loss: 0.4333\n",
      "Epoch [17/100], Step [37800/6235], Loss: 1.3157\n",
      "Epoch [17/100], Step [37900/6235], Loss: 0.2405\n",
      "Epoch [17/100], Step [38000/6235], Loss: 0.5814\n",
      "Epoch [17/100], Step [38100/6235], Loss: 7.1976\n",
      "Epoch [17/100], Step [38200/6235], Loss: 1.4645\n",
      "Epoch [17/100], Step [38300/6235], Loss: 4.4829\n",
      "Epoch [17/100], Step [38400/6235], Loss: 0.0686\n",
      "Epoch [17/100], Step [38500/6235], Loss: 1.7876\n",
      "Epoch [17/100], Step [38600/6235], Loss: 3.5580\n",
      "Epoch [17/100], Step [38700/6235], Loss: 0.1769\n",
      "Epoch [17/100], Step [38800/6235], Loss: 1.5006\n",
      "Epoch [17/100], Step [38900/6235], Loss: 7.7094\n",
      "Epoch [17/100], Step [39000/6235], Loss: 3.5635\n",
      "Epoch [17/100], Step [39100/6235], Loss: 30.4060\n",
      "Epoch [17/100], Step [39200/6235], Loss: 0.1908\n",
      "Epoch [17/100], Step [39300/6235], Loss: 2.9429\n",
      "Epoch [17/100], Step [39400/6235], Loss: 191.6539\n",
      "Epoch [17/100], Step [39500/6235], Loss: 367.9099\n",
      "Epoch [17/100], Step [39600/6235], Loss: 12.5936\n",
      "Epoch [17/100], Step [39700/6235], Loss: 456.8458\n",
      "Epoch [17/100], Step [39800/6235], Loss: 58.6260\n",
      "Epoch [17/100], Step [39900/6235], Loss: 0.4601\n",
      "Epoch [17/100], Step [40000/6235], Loss: 16.3975\n",
      "Epoch [17/100], Step [40100/6235], Loss: 35.2048\n",
      "Epoch [17/100], Step [40200/6235], Loss: 3.5560\n",
      "Epoch [17/100], Step [40300/6235], Loss: 0.2716\n",
      "Epoch [17/100], Step [40400/6235], Loss: 2.9043\n",
      "Epoch [17/100], Step [40500/6235], Loss: 2.2182\n",
      "Epoch [17/100], Step [40600/6235], Loss: 0.2689\n",
      "Epoch [17/100], Step [40700/6235], Loss: 7.9350\n",
      "Epoch [17/100], Step [40800/6235], Loss: 2.4929\n",
      "Epoch [17/100], Step [40900/6235], Loss: 0.1305\n",
      "Epoch [17/100], Step [41000/6235], Loss: 13.6249\n",
      "Epoch [17/100], Step [41100/6235], Loss: 20.2950\n",
      "Epoch [17/100], Step [41200/6235], Loss: 57.7103\n",
      "Epoch [17/100], Step [41300/6235], Loss: 4.9213\n",
      "Epoch [17/100], Step [41400/6235], Loss: 0.0122\n",
      "Epoch [17/100], Step [41500/6235], Loss: 0.7708\n",
      "Epoch [17/100], Step [41600/6235], Loss: 0.0254\n",
      "Epoch [17/100], Step [41700/6235], Loss: 0.5204\n",
      "Epoch [17/100], Step [41800/6235], Loss: 1.3214\n",
      "Epoch [17/100], Step [41900/6235], Loss: 3.2232\n",
      "Epoch [17/100], Step [42000/6235], Loss: 1.8663\n",
      "Epoch [17/100], Step [42100/6235], Loss: 4.9254\n",
      "Epoch [17/100], Step [42200/6235], Loss: 55.8652\n",
      "Epoch [17/100], Step [42300/6235], Loss: 2.6125\n",
      "Epoch [17/100], Step [42400/6235], Loss: 5.4137\n",
      "Epoch [17/100], Step [42500/6235], Loss: 1.9473\n",
      "Epoch [17/100], Step [42600/6235], Loss: 0.4470\n",
      "Epoch [17/100], Step [42700/6235], Loss: 0.1689\n",
      "Epoch [17/100], Step [42800/6235], Loss: 0.5757\n",
      "Epoch [17/100], Step [42900/6235], Loss: 4.1235\n",
      "Epoch [17/100], Step [43000/6235], Loss: 0.5463\n",
      "Epoch [17/100], Step [43100/6235], Loss: 2.2111\n",
      "Epoch [17/100], Step [43200/6235], Loss: 0.3548\n",
      "Epoch [17/100], Step [43300/6235], Loss: 10.6536\n",
      "Epoch [17/100], Step [43400/6235], Loss: 10.6756\n",
      "Epoch [17/100], Step [43500/6235], Loss: 9.1014\n",
      "Epoch [17/100], Step [43600/6235], Loss: 28.7185\n",
      "Epoch [17/100], Step [43700/6235], Loss: 48.8635\n",
      "Epoch [17/100], Step [43800/6235], Loss: 0.9279\n",
      "Epoch [17/100], Step [43900/6235], Loss: 2.8684\n",
      "Epoch [17/100], Step [44000/6235], Loss: 63.2616\n",
      "Epoch [17/100], Step [44100/6235], Loss: 0.8738\n",
      "Epoch [17/100], Step [44200/6235], Loss: 33.3445\n",
      "Epoch [17/100], Step [44300/6235], Loss: 2.7833\n",
      "Epoch [17/100], Step [44400/6235], Loss: 3.2891\n",
      "Epoch [17/100], Step [44500/6235], Loss: 1.8249\n",
      "Epoch [17/100], Step [44600/6235], Loss: 17.2569\n",
      "Epoch [17/100], Step [44700/6235], Loss: 2.8389\n",
      "Epoch [17/100], Step [44800/6235], Loss: 5.0731\n",
      "Epoch [17/100], Step [44900/6235], Loss: 5.1828\n",
      "Epoch [17/100], Step [45000/6235], Loss: 4.8612\n",
      "Epoch [17/100], Step [45100/6235], Loss: 14.6923\n",
      "Epoch [17/100], Step [45200/6235], Loss: 0.3537\n",
      "Epoch [17/100], Step [45300/6235], Loss: 27.5718\n",
      "Epoch [17/100], Step [45400/6235], Loss: 12.5371\n",
      "Epoch [17/100], Step [45500/6235], Loss: 0.6803\n",
      "Epoch [17/100], Step [45600/6235], Loss: 0.2713\n",
      "Epoch [17/100], Step [45700/6235], Loss: 113.0516\n",
      "Epoch [17/100], Step [45800/6235], Loss: 251.3430\n",
      "Epoch [17/100], Step [45900/6235], Loss: 29.4438\n",
      "Epoch [17/100], Step [46000/6235], Loss: 25.9686\n",
      "Epoch [17/100], Step [46100/6235], Loss: 27.2515\n",
      "Epoch [17/100], Step [46200/6235], Loss: 6.0347\n",
      "Epoch [17/100], Step [46300/6235], Loss: 42.6203\n",
      "Epoch [17/100], Step [46400/6235], Loss: 1.5479\n",
      "Epoch [17/100], Step [46500/6235], Loss: 36.4481\n",
      "Epoch [17/100], Step [46600/6235], Loss: 23.6520\n",
      "Epoch [17/100], Step [46700/6235], Loss: 6.2618\n",
      "Epoch [17/100], Step [46800/6235], Loss: 3.7403\n",
      "Epoch [17/100], Step [46900/6235], Loss: 4.3949\n",
      "Epoch [17/100], Step [47000/6235], Loss: 5.8268\n",
      "Epoch [17/100], Step [47100/6235], Loss: 0.8074\n",
      "Epoch [17/100], Step [47200/6235], Loss: 4.4732\n",
      "Epoch [17/100], Step [47300/6235], Loss: 0.7542\n",
      "Epoch [17/100], Step [47400/6235], Loss: 65.8363\n",
      "Epoch [17/100], Step [47500/6235], Loss: 2.1014\n",
      "Epoch [17/100], Step [47600/6235], Loss: 0.9365\n",
      "Epoch [17/100], Step [47700/6235], Loss: 6.9366\n",
      "Epoch [17/100], Step [47800/6235], Loss: 0.4523\n",
      "Epoch [17/100], Step [47900/6235], Loss: 32.6724\n",
      "Epoch [17/100], Step [48000/6235], Loss: 41.8028\n",
      "Epoch [17/100], Step [48100/6235], Loss: 1.8156\n",
      "Epoch [17/100], Step [48200/6235], Loss: 22.4201\n",
      "Epoch [17/100], Step [48300/6235], Loss: 532.8564\n",
      "Epoch [17/100], Step [48400/6235], Loss: 52.0722\n",
      "Epoch [17/100], Step [48500/6235], Loss: 5.1403\n",
      "Epoch [17/100], Step [48600/6235], Loss: 105.2154\n",
      "Epoch [17/100], Step [48700/6235], Loss: 97.6397\n",
      "Epoch [17/100], Step [48800/6235], Loss: 253.2591\n",
      "Epoch [17/100], Step [48900/6235], Loss: 91.8097\n",
      "Epoch [17/100], Step [49000/6235], Loss: 301.6068\n",
      "Epoch [17/100], Step [49100/6235], Loss: 2185.5371\n",
      "Epoch [17/100], Step [49200/6235], Loss: 585.4435\n",
      "Epoch [17/100], Step [49300/6235], Loss: 1050.2385\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [17/100], Step [49400/6235], Loss: 360.8548\n",
      "Epoch [17/100], Step [49500/6235], Loss: 4.1376\n",
      "Epoch [17/100], Step [49600/6235], Loss: 36.0883\n",
      "Epoch [17/100], Step [49700/6235], Loss: 1885.2897\n",
      "Epoch [17/100], Step [49800/6235], Loss: 611.2442\n",
      "Epoch [18/100], Step [100/6235], Loss: 61.2744\n",
      "Epoch [18/100], Step [200/6235], Loss: 0.0934\n",
      "Epoch [18/100], Step [300/6235], Loss: 0.0072\n",
      "Epoch [18/100], Step [400/6235], Loss: 0.0007\n",
      "Epoch [18/100], Step [500/6235], Loss: 0.0485\n",
      "Epoch [18/100], Step [600/6235], Loss: 0.0399\n",
      "Epoch [18/100], Step [700/6235], Loss: 0.2095\n",
      "Epoch [18/100], Step [800/6235], Loss: 0.0633\n",
      "Epoch [18/100], Step [900/6235], Loss: 0.0212\n",
      "Epoch [18/100], Step [1000/6235], Loss: 0.0220\n",
      "Epoch [18/100], Step [1100/6235], Loss: 0.0152\n",
      "Epoch [18/100], Step [1200/6235], Loss: 0.1336\n",
      "Epoch [18/100], Step [1300/6235], Loss: 0.0646\n",
      "Epoch [18/100], Step [1400/6235], Loss: 0.0447\n",
      "Epoch [18/100], Step [1500/6235], Loss: 0.0035\n",
      "Epoch [18/100], Step [1600/6235], Loss: 0.2059\n",
      "Epoch [18/100], Step [1700/6235], Loss: 0.0486\n",
      "Epoch [18/100], Step [1800/6235], Loss: 0.2382\n",
      "Epoch [18/100], Step [1900/6235], Loss: 0.8334\n",
      "Epoch [18/100], Step [2000/6235], Loss: 2.4275\n",
      "Epoch [18/100], Step [2100/6235], Loss: 3.4204\n",
      "Epoch [18/100], Step [2200/6235], Loss: 11.9792\n",
      "Epoch [18/100], Step [2300/6235], Loss: 27.5909\n",
      "Epoch [18/100], Step [2400/6235], Loss: 25.6742\n",
      "Epoch [18/100], Step [2500/6235], Loss: 46.6247\n",
      "Epoch [18/100], Step [2600/6235], Loss: 6.5085\n",
      "Epoch [18/100], Step [2700/6235], Loss: 60.5886\n",
      "Epoch [18/100], Step [2800/6235], Loss: 186.4725\n",
      "Epoch [18/100], Step [2900/6235], Loss: 7.4931\n",
      "Epoch [18/100], Step [3000/6235], Loss: 0.1175\n",
      "Epoch [18/100], Step [3100/6235], Loss: 35.8352\n",
      "Epoch [18/100], Step [3200/6235], Loss: 37.9588\n",
      "Epoch [18/100], Step [3300/6235], Loss: 1.5793\n",
      "Epoch [18/100], Step [3400/6235], Loss: 1.8763\n",
      "Epoch [18/100], Step [3500/6235], Loss: 35.6092\n",
      "Epoch [18/100], Step [3600/6235], Loss: 14.2195\n",
      "Epoch [18/100], Step [3700/6235], Loss: 2.2582\n",
      "Epoch [18/100], Step [3800/6235], Loss: 0.3300\n",
      "Epoch [18/100], Step [3900/6235], Loss: 0.9195\n",
      "Epoch [18/100], Step [4000/6235], Loss: 0.2005\n",
      "Epoch [18/100], Step [4100/6235], Loss: 0.8426\n",
      "Epoch [18/100], Step [4200/6235], Loss: 1.5302\n",
      "Epoch [18/100], Step [4300/6235], Loss: 10.3667\n",
      "Epoch [18/100], Step [4400/6235], Loss: 0.3873\n",
      "Epoch [18/100], Step [4500/6235], Loss: 55.8351\n",
      "Epoch [18/100], Step [4600/6235], Loss: 10.8209\n",
      "Epoch [18/100], Step [4700/6235], Loss: 2.0014\n",
      "Epoch [18/100], Step [4800/6235], Loss: 2.7488\n",
      "Epoch [18/100], Step [4900/6235], Loss: 0.2915\n",
      "Epoch [18/100], Step [5000/6235], Loss: 2.0891\n",
      "Epoch [18/100], Step [5100/6235], Loss: 6.2242\n",
      "Epoch [18/100], Step [5200/6235], Loss: 12.6058\n",
      "Epoch [18/100], Step [5300/6235], Loss: 32.5780\n",
      "Epoch [18/100], Step [5400/6235], Loss: 0.9185\n",
      "Epoch [18/100], Step [5500/6235], Loss: 1.3886\n",
      "Epoch [18/100], Step [5600/6235], Loss: 0.3718\n",
      "Epoch [18/100], Step [5700/6235], Loss: 3.2046\n",
      "Epoch [18/100], Step [5800/6235], Loss: 0.0845\n",
      "Epoch [18/100], Step [5900/6235], Loss: 2.3483\n",
      "Epoch [18/100], Step [6000/6235], Loss: 1.5637\n",
      "Epoch [18/100], Step [6100/6235], Loss: 0.1301\n",
      "Epoch [18/100], Step [6200/6235], Loss: 2.6700\n",
      "Epoch [18/100], Step [6300/6235], Loss: 0.5088\n",
      "Epoch [18/100], Step [6400/6235], Loss: 0.0410\n",
      "Epoch [18/100], Step [6500/6235], Loss: 0.4424\n",
      "Epoch [18/100], Step [6600/6235], Loss: 92.5623\n",
      "Epoch [18/100], Step [6700/6235], Loss: 0.7179\n",
      "Epoch [18/100], Step [6800/6235], Loss: 1.7004\n",
      "Epoch [18/100], Step [6900/6235], Loss: 1.7098\n",
      "Epoch [18/100], Step [7000/6235], Loss: 0.0293\n",
      "Epoch [18/100], Step [7100/6235], Loss: 1.5384\n",
      "Epoch [18/100], Step [7200/6235], Loss: 0.0243\n",
      "Epoch [18/100], Step [7300/6235], Loss: 1.3258\n",
      "Epoch [18/100], Step [7400/6235], Loss: 0.3900\n",
      "Epoch [18/100], Step [7500/6235], Loss: 30.4784\n",
      "Epoch [18/100], Step [7600/6235], Loss: 4.7175\n",
      "Epoch [18/100], Step [7700/6235], Loss: 7.5214\n",
      "Epoch [18/100], Step [7800/6235], Loss: 3.5517\n",
      "Epoch [18/100], Step [7900/6235], Loss: 20.5625\n",
      "Epoch [18/100], Step [8000/6235], Loss: 4.2020\n",
      "Epoch [18/100], Step [8100/6235], Loss: 2.1516\n",
      "Epoch [18/100], Step [8200/6235], Loss: 12.5768\n",
      "Epoch [18/100], Step [8300/6235], Loss: 15.8901\n",
      "Epoch [18/100], Step [8400/6235], Loss: 7.8029\n",
      "Epoch [18/100], Step [8500/6235], Loss: 5.7608\n",
      "Epoch [18/100], Step [8600/6235], Loss: 1.4393\n",
      "Epoch [18/100], Step [8700/6235], Loss: 4.5959\n",
      "Epoch [18/100], Step [8800/6235], Loss: 476.8227\n",
      "Epoch [18/100], Step [8900/6235], Loss: 5.7124\n",
      "Epoch [18/100], Step [9000/6235], Loss: 220.8240\n",
      "Epoch [18/100], Step [9100/6235], Loss: 8.5316\n",
      "Epoch [18/100], Step [9200/6235], Loss: 2833.7324\n",
      "Epoch [18/100], Step [9300/6235], Loss: 119.8776\n",
      "Epoch [18/100], Step [9400/6235], Loss: 268.3192\n",
      "Epoch [18/100], Step [9500/6235], Loss: 397.7847\n",
      "Epoch [18/100], Step [9600/6235], Loss: 214.3596\n",
      "Epoch [18/100], Step [9700/6235], Loss: 227.8590\n",
      "Epoch [18/100], Step [9800/6235], Loss: 269.0941\n",
      "Epoch [18/100], Step [9900/6235], Loss: 20.6500\n",
      "Epoch [18/100], Step [10000/6235], Loss: 31.7939\n",
      "Epoch [18/100], Step [10100/6235], Loss: 78.8215\n",
      "Epoch [18/100], Step [10200/6235], Loss: 842.9998\n",
      "Epoch [18/100], Step [10300/6235], Loss: 9.9549\n",
      "Epoch [18/100], Step [10400/6235], Loss: 12.7437\n",
      "Epoch [18/100], Step [10500/6235], Loss: 6.4234\n",
      "Epoch [18/100], Step [10600/6235], Loss: 1581.1855\n",
      "Epoch [18/100], Step [10700/6235], Loss: 224.5118\n",
      "Epoch [18/100], Step [10800/6235], Loss: 9.0361\n",
      "Epoch [18/100], Step [10900/6235], Loss: 4.7709\n",
      "Epoch [18/100], Step [11000/6235], Loss: 32.4952\n",
      "Epoch [18/100], Step [11100/6235], Loss: 0.4169\n",
      "Epoch [18/100], Step [11200/6235], Loss: 126.1682\n",
      "Epoch [18/100], Step [11300/6235], Loss: 210.9206\n",
      "Epoch [18/100], Step [11400/6235], Loss: 328.3222\n",
      "Epoch [18/100], Step [11500/6235], Loss: 8.9432\n",
      "Epoch [18/100], Step [11600/6235], Loss: 1.6953\n",
      "Epoch [18/100], Step [11700/6235], Loss: 159.5968\n",
      "Epoch [18/100], Step [11800/6235], Loss: 41.1061\n",
      "Epoch [18/100], Step [11900/6235], Loss: 1004.2679\n",
      "Epoch [18/100], Step [12000/6235], Loss: 17.1436\n",
      "Epoch [18/100], Step [12100/6235], Loss: 461.9960\n",
      "Epoch [18/100], Step [12200/6235], Loss: 98.9380\n",
      "Epoch [18/100], Step [12300/6235], Loss: 37.0038\n",
      "Epoch [18/100], Step [12400/6235], Loss: 360.1727\n",
      "Epoch [18/100], Step [12500/6235], Loss: 201.8702\n",
      "Epoch [18/100], Step [12600/6235], Loss: 51.6694\n",
      "Epoch [18/100], Step [12700/6235], Loss: 31.9545\n",
      "Epoch [18/100], Step [12800/6235], Loss: 4.8049\n",
      "Epoch [18/100], Step [12900/6235], Loss: 31.8351\n",
      "Epoch [18/100], Step [13000/6235], Loss: 2.9978\n",
      "Epoch [18/100], Step [13100/6235], Loss: 91.1320\n",
      "Epoch [18/100], Step [13200/6235], Loss: 46.7105\n",
      "Epoch [18/100], Step [13300/6235], Loss: 1.7718\n",
      "Epoch [18/100], Step [13400/6235], Loss: 1.0567\n",
      "Epoch [18/100], Step [13500/6235], Loss: 0.7999\n",
      "Epoch [18/100], Step [13600/6235], Loss: 2.6874\n",
      "Epoch [18/100], Step [13700/6235], Loss: 219.8919\n",
      "Epoch [18/100], Step [13800/6235], Loss: 142.6085\n",
      "Epoch [18/100], Step [13900/6235], Loss: 3.0704\n",
      "Epoch [18/100], Step [14000/6235], Loss: 23.4829\n",
      "Epoch [18/100], Step [14100/6235], Loss: 236.2867\n",
      "Epoch [18/100], Step [14200/6235], Loss: 4.2414\n",
      "Epoch [18/100], Step [14300/6235], Loss: 4.1799\n",
      "Epoch [18/100], Step [14400/6235], Loss: 2.0616\n",
      "Epoch [18/100], Step [14500/6235], Loss: 19.4961\n",
      "Epoch [18/100], Step [14600/6235], Loss: 9.7358\n",
      "Epoch [18/100], Step [14700/6235], Loss: 5.4404\n",
      "Epoch [18/100], Step [14800/6235], Loss: 17.0406\n",
      "Epoch [18/100], Step [14900/6235], Loss: 0.5408\n",
      "Epoch [18/100], Step [15000/6235], Loss: 0.2081\n",
      "Epoch [18/100], Step [15100/6235], Loss: 0.1492\n",
      "Epoch [18/100], Step [15200/6235], Loss: 1.6088\n",
      "Epoch [18/100], Step [15300/6235], Loss: 131.6198\n",
      "Epoch [18/100], Step [15400/6235], Loss: 10.6114\n",
      "Epoch [18/100], Step [15500/6235], Loss: 40.5713\n",
      "Epoch [18/100], Step [15600/6235], Loss: 230.3021\n",
      "Epoch [18/100], Step [15700/6235], Loss: 10.4176\n",
      "Epoch [18/100], Step [15800/6235], Loss: 0.9825\n",
      "Epoch [18/100], Step [15900/6235], Loss: 1.6551\n",
      "Epoch [18/100], Step [16000/6235], Loss: 0.9536\n",
      "Epoch [18/100], Step [16100/6235], Loss: 0.9663\n",
      "Epoch [18/100], Step [16200/6235], Loss: 3.2741\n",
      "Epoch [18/100], Step [16300/6235], Loss: 18.5753\n",
      "Epoch [18/100], Step [16400/6235], Loss: 69.5663\n",
      "Epoch [18/100], Step [16500/6235], Loss: 569.8205\n",
      "Epoch [18/100], Step [16600/6235], Loss: 4.9691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Step [16700/6235], Loss: 7.3121\n",
      "Epoch [18/100], Step [16800/6235], Loss: 1.5658\n",
      "Epoch [18/100], Step [16900/6235], Loss: 3.0389\n",
      "Epoch [18/100], Step [17000/6235], Loss: 5.5518\n",
      "Epoch [18/100], Step [17100/6235], Loss: 2.8837\n",
      "Epoch [18/100], Step [17200/6235], Loss: 15.0061\n",
      "Epoch [18/100], Step [17300/6235], Loss: 13.2848\n",
      "Epoch [18/100], Step [17400/6235], Loss: 84.7919\n",
      "Epoch [18/100], Step [17500/6235], Loss: 14.7812\n",
      "Epoch [18/100], Step [17600/6235], Loss: 0.2668\n",
      "Epoch [18/100], Step [17700/6235], Loss: 14.7541\n",
      "Epoch [18/100], Step [17800/6235], Loss: 19.7230\n",
      "Epoch [18/100], Step [17900/6235], Loss: 46.1141\n",
      "Epoch [18/100], Step [18000/6235], Loss: 0.1784\n",
      "Epoch [18/100], Step [18100/6235], Loss: 10.3394\n",
      "Epoch [18/100], Step [18200/6235], Loss: 14.1253\n",
      "Epoch [18/100], Step [18300/6235], Loss: 0.5134\n",
      "Epoch [18/100], Step [18400/6235], Loss: 31.4455\n",
      "Epoch [18/100], Step [18500/6235], Loss: 43.0068\n",
      "Epoch [18/100], Step [18600/6235], Loss: 3.3432\n",
      "Epoch [18/100], Step [18700/6235], Loss: 0.8291\n",
      "Epoch [18/100], Step [18800/6235], Loss: 64.2005\n",
      "Epoch [18/100], Step [18900/6235], Loss: 21.0870\n",
      "Epoch [18/100], Step [19000/6235], Loss: 16.4232\n",
      "Epoch [18/100], Step [19100/6235], Loss: 1.0075\n",
      "Epoch [18/100], Step [19200/6235], Loss: 1.2232\n",
      "Epoch [18/100], Step [19300/6235], Loss: 0.4583\n",
      "Epoch [18/100], Step [19400/6235], Loss: 104.8533\n",
      "Epoch [18/100], Step [19500/6235], Loss: 225.7998\n",
      "Epoch [18/100], Step [19600/6235], Loss: 143.1534\n",
      "Epoch [18/100], Step [19700/6235], Loss: 15.5093\n",
      "Epoch [18/100], Step [19800/6235], Loss: 34.1005\n",
      "Epoch [18/100], Step [19900/6235], Loss: 3.7298\n",
      "Epoch [18/100], Step [20000/6235], Loss: 101.4646\n",
      "Epoch [18/100], Step [20100/6235], Loss: 4.5283\n",
      "Epoch [18/100], Step [20200/6235], Loss: 0.4311\n",
      "Epoch [18/100], Step [20300/6235], Loss: 0.1719\n",
      "Epoch [18/100], Step [20400/6235], Loss: 32.1667\n",
      "Epoch [18/100], Step [20500/6235], Loss: 18.7379\n",
      "Epoch [18/100], Step [20600/6235], Loss: 154.3791\n",
      "Epoch [18/100], Step [20700/6235], Loss: 0.5666\n",
      "Epoch [18/100], Step [20800/6235], Loss: 32.0968\n",
      "Epoch [18/100], Step [20900/6235], Loss: 23.8023\n",
      "Epoch [18/100], Step [21000/6235], Loss: 3.5455\n",
      "Epoch [18/100], Step [21100/6235], Loss: 17.8823\n",
      "Epoch [18/100], Step [21200/6235], Loss: 0.8762\n",
      "Epoch [18/100], Step [21300/6235], Loss: 6.8428\n",
      "Epoch [18/100], Step [21400/6235], Loss: 2.0378\n",
      "Epoch [18/100], Step [21500/6235], Loss: 6.8186\n",
      "Epoch [18/100], Step [21600/6235], Loss: 28.3488\n",
      "Epoch [18/100], Step [21700/6235], Loss: 0.2187\n",
      "Epoch [18/100], Step [21800/6235], Loss: 30.0458\n",
      "Epoch [18/100], Step [21900/6235], Loss: 2.3586\n",
      "Epoch [18/100], Step [22000/6235], Loss: 0.2193\n",
      "Epoch [18/100], Step [22100/6235], Loss: 3.4965\n",
      "Epoch [18/100], Step [22200/6235], Loss: 2.7455\n",
      "Epoch [18/100], Step [22300/6235], Loss: 1.5834\n",
      "Epoch [18/100], Step [22400/6235], Loss: 0.2755\n",
      "Epoch [18/100], Step [22500/6235], Loss: 262.5896\n",
      "Epoch [18/100], Step [22600/6235], Loss: 25.1791\n",
      "Epoch [18/100], Step [22700/6235], Loss: 1.5649\n",
      "Epoch [18/100], Step [22800/6235], Loss: 11.1262\n",
      "Epoch [18/100], Step [22900/6235], Loss: 14.5609\n",
      "Epoch [18/100], Step [23000/6235], Loss: 18.7455\n",
      "Epoch [18/100], Step [23100/6235], Loss: 7.8285\n",
      "Epoch [18/100], Step [23200/6235], Loss: 28.1033\n",
      "Epoch [18/100], Step [23300/6235], Loss: 19.2883\n",
      "Epoch [18/100], Step [23400/6235], Loss: 0.5273\n",
      "Epoch [18/100], Step [23500/6235], Loss: 0.2754\n",
      "Epoch [18/100], Step [23600/6235], Loss: 54.0160\n",
      "Epoch [18/100], Step [23700/6235], Loss: 1.2438\n",
      "Epoch [18/100], Step [23800/6235], Loss: 0.0904\n",
      "Epoch [18/100], Step [23900/6235], Loss: 7.7070\n",
      "Epoch [18/100], Step [24000/6235], Loss: 3.5646\n",
      "Epoch [18/100], Step [24100/6235], Loss: 2.9758\n",
      "Epoch [18/100], Step [24200/6235], Loss: 25.8912\n",
      "Epoch [18/100], Step [24300/6235], Loss: 4.2047\n",
      "Epoch [18/100], Step [24400/6235], Loss: 6.3481\n",
      "Epoch [18/100], Step [24500/6235], Loss: 2.9723\n",
      "Epoch [18/100], Step [24600/6235], Loss: 0.0801\n",
      "Epoch [18/100], Step [24700/6235], Loss: 3.2498\n",
      "Epoch [18/100], Step [24800/6235], Loss: 6.5859\n",
      "Epoch [18/100], Step [24900/6235], Loss: 2.3073\n",
      "Epoch [18/100], Step [25000/6235], Loss: 17.3191\n",
      "Epoch [18/100], Step [25100/6235], Loss: 8.8817\n",
      "Epoch [18/100], Step [25200/6235], Loss: 0.8159\n",
      "Epoch [18/100], Step [25300/6235], Loss: 1.9937\n",
      "Epoch [18/100], Step [25400/6235], Loss: 9.6484\n",
      "Epoch [18/100], Step [25500/6235], Loss: 4.5712\n",
      "Epoch [18/100], Step [25600/6235], Loss: 0.6632\n",
      "Epoch [18/100], Step [25700/6235], Loss: 0.1424\n",
      "Epoch [18/100], Step [25800/6235], Loss: 0.1357\n",
      "Epoch [18/100], Step [25900/6235], Loss: 9.2719\n",
      "Epoch [18/100], Step [26000/6235], Loss: 4.8036\n",
      "Epoch [18/100], Step [26100/6235], Loss: 3.3219\n",
      "Epoch [18/100], Step [26200/6235], Loss: 2.0382\n",
      "Epoch [18/100], Step [26300/6235], Loss: 7.6298\n",
      "Epoch [18/100], Step [26400/6235], Loss: 0.0912\n",
      "Epoch [18/100], Step [26500/6235], Loss: 1.8893\n",
      "Epoch [18/100], Step [26600/6235], Loss: 6.3139\n",
      "Epoch [18/100], Step [26700/6235], Loss: 1.3448\n",
      "Epoch [18/100], Step [26800/6235], Loss: 2.7461\n",
      "Epoch [18/100], Step [26900/6235], Loss: 0.3551\n",
      "Epoch [18/100], Step [27000/6235], Loss: 9.1193\n",
      "Epoch [18/100], Step [27100/6235], Loss: 0.3666\n",
      "Epoch [18/100], Step [27200/6235], Loss: 0.1188\n",
      "Epoch [18/100], Step [27300/6235], Loss: 0.1194\n",
      "Epoch [18/100], Step [27400/6235], Loss: 1.2272\n",
      "Epoch [18/100], Step [27500/6235], Loss: 21.5294\n",
      "Epoch [18/100], Step [27600/6235], Loss: 0.1196\n",
      "Epoch [18/100], Step [27700/6235], Loss: 0.0131\n",
      "Epoch [18/100], Step [27800/6235], Loss: 3.4869\n",
      "Epoch [18/100], Step [27900/6235], Loss: 5.5682\n",
      "Epoch [18/100], Step [28000/6235], Loss: 218.0284\n",
      "Epoch [18/100], Step [28100/6235], Loss: 0.9537\n",
      "Epoch [18/100], Step [28200/6235], Loss: 32.8993\n",
      "Epoch [18/100], Step [28300/6235], Loss: 5.7168\n",
      "Epoch [18/100], Step [28400/6235], Loss: 12.0320\n",
      "Epoch [18/100], Step [28500/6235], Loss: 0.1826\n",
      "Epoch [18/100], Step [28600/6235], Loss: 1.3543\n",
      "Epoch [18/100], Step [28700/6235], Loss: 3.4574\n",
      "Epoch [18/100], Step [28800/6235], Loss: 0.1616\n",
      "Epoch [18/100], Step [28900/6235], Loss: 63.3708\n",
      "Epoch [18/100], Step [29000/6235], Loss: 3.2629\n",
      "Epoch [18/100], Step [29100/6235], Loss: 1.7331\n",
      "Epoch [18/100], Step [29200/6235], Loss: 0.0727\n",
      "Epoch [18/100], Step [29300/6235], Loss: 10.7007\n",
      "Epoch [18/100], Step [29400/6235], Loss: 3.0309\n",
      "Epoch [18/100], Step [29500/6235], Loss: 5.0904\n",
      "Epoch [18/100], Step [29600/6235], Loss: 0.5295\n",
      "Epoch [18/100], Step [29700/6235], Loss: 0.0889\n",
      "Epoch [18/100], Step [29800/6235], Loss: 1.5039\n",
      "Epoch [18/100], Step [29900/6235], Loss: 0.1891\n",
      "Epoch [18/100], Step [30000/6235], Loss: 0.7809\n",
      "Epoch [18/100], Step [30100/6235], Loss: 9.2350\n",
      "Epoch [18/100], Step [30200/6235], Loss: 1.3565\n",
      "Epoch [18/100], Step [30300/6235], Loss: 0.0243\n",
      "Epoch [18/100], Step [30400/6235], Loss: 1.2991\n",
      "Epoch [18/100], Step [30500/6235], Loss: 1.3770\n",
      "Epoch [18/100], Step [30600/6235], Loss: 0.3646\n",
      "Epoch [18/100], Step [30700/6235], Loss: 0.1514\n",
      "Epoch [18/100], Step [30800/6235], Loss: 0.4729\n",
      "Epoch [18/100], Step [30900/6235], Loss: 3.0155\n",
      "Epoch [18/100], Step [31000/6235], Loss: 0.0791\n",
      "Epoch [18/100], Step [31100/6235], Loss: 0.0724\n",
      "Epoch [18/100], Step [31200/6235], Loss: 10.5161\n",
      "Epoch [18/100], Step [31300/6235], Loss: 1.7649\n",
      "Epoch [18/100], Step [31400/6235], Loss: 1.5561\n",
      "Epoch [18/100], Step [31500/6235], Loss: 0.5126\n",
      "Epoch [18/100], Step [31600/6235], Loss: 0.5068\n",
      "Epoch [18/100], Step [31700/6235], Loss: 31.4024\n",
      "Epoch [18/100], Step [31800/6235], Loss: 2.5880\n",
      "Epoch [18/100], Step [31900/6235], Loss: 340.7176\n",
      "Epoch [18/100], Step [32000/6235], Loss: 50.1429\n",
      "Epoch [18/100], Step [32100/6235], Loss: 17.0486\n",
      "Epoch [18/100], Step [32200/6235], Loss: 5.1470\n",
      "Epoch [18/100], Step [32300/6235], Loss: 0.4663\n",
      "Epoch [18/100], Step [32400/6235], Loss: 0.8350\n",
      "Epoch [18/100], Step [32500/6235], Loss: 14.1918\n",
      "Epoch [18/100], Step [32600/6235], Loss: 1.4891\n",
      "Epoch [18/100], Step [32700/6235], Loss: 245.5439\n",
      "Epoch [18/100], Step [32800/6235], Loss: 6.1661\n",
      "Epoch [18/100], Step [32900/6235], Loss: 8.8675\n",
      "Epoch [18/100], Step [33000/6235], Loss: 4.8841\n",
      "Epoch [18/100], Step [33100/6235], Loss: 0.1655\n",
      "Epoch [18/100], Step [33200/6235], Loss: 5.1105\n",
      "Epoch [18/100], Step [33300/6235], Loss: 3.1000\n",
      "Epoch [18/100], Step [33400/6235], Loss: 3.9824\n",
      "Epoch [18/100], Step [33500/6235], Loss: 0.9452\n",
      "Epoch [18/100], Step [33600/6235], Loss: 0.1041\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [18/100], Step [33700/6235], Loss: 2.2423\n",
      "Epoch [18/100], Step [33800/6235], Loss: 26.0748\n",
      "Epoch [18/100], Step [33900/6235], Loss: 24.5926\n",
      "Epoch [18/100], Step [34000/6235], Loss: 0.1264\n",
      "Epoch [18/100], Step [34100/6235], Loss: 0.3492\n",
      "Epoch [18/100], Step [34200/6235], Loss: 31.3038\n",
      "Epoch [18/100], Step [34300/6235], Loss: 0.0419\n",
      "Epoch [18/100], Step [34400/6235], Loss: 3.1516\n",
      "Epoch [18/100], Step [34500/6235], Loss: 13.5948\n",
      "Epoch [18/100], Step [34600/6235], Loss: 1.3206\n",
      "Epoch [18/100], Step [34700/6235], Loss: 2.4096\n",
      "Epoch [18/100], Step [34800/6235], Loss: 9.8118\n",
      "Epoch [18/100], Step [34900/6235], Loss: 29.9265\n",
      "Epoch [18/100], Step [35000/6235], Loss: 1.0016\n",
      "Epoch [18/100], Step [35100/6235], Loss: 5.7630\n",
      "Epoch [18/100], Step [35200/6235], Loss: 6.4000\n",
      "Epoch [18/100], Step [35300/6235], Loss: 4.2531\n",
      "Epoch [18/100], Step [35400/6235], Loss: 0.7182\n",
      "Epoch [18/100], Step [35500/6235], Loss: 0.0888\n",
      "Epoch [18/100], Step [35600/6235], Loss: 13.7256\n",
      "Epoch [18/100], Step [35700/6235], Loss: 18.0992\n",
      "Epoch [18/100], Step [35800/6235], Loss: 1.4516\n",
      "Epoch [18/100], Step [35900/6235], Loss: 2.8433\n",
      "Epoch [18/100], Step [36000/6235], Loss: 0.1458\n",
      "Epoch [18/100], Step [36100/6235], Loss: 12.7522\n",
      "Epoch [18/100], Step [36200/6235], Loss: 11.2340\n",
      "Epoch [18/100], Step [36300/6235], Loss: 0.1155\n",
      "Epoch [18/100], Step [36400/6235], Loss: 0.0579\n",
      "Epoch [18/100], Step [36500/6235], Loss: 8.0375\n",
      "Epoch [18/100], Step [36600/6235], Loss: 0.4656\n",
      "Epoch [18/100], Step [36700/6235], Loss: 1.3866\n",
      "Epoch [18/100], Step [36800/6235], Loss: 20.2032\n",
      "Epoch [18/100], Step [36900/6235], Loss: 9.5334\n",
      "Epoch [18/100], Step [37000/6235], Loss: 0.9694\n",
      "Epoch [18/100], Step [37100/6235], Loss: 1.0903\n",
      "Epoch [18/100], Step [37200/6235], Loss: 0.1516\n",
      "Epoch [18/100], Step [37300/6235], Loss: 0.6498\n",
      "Epoch [18/100], Step [37400/6235], Loss: 0.9749\n",
      "Epoch [18/100], Step [37500/6235], Loss: 0.4886\n",
      "Epoch [18/100], Step [37600/6235], Loss: 7.3762\n",
      "Epoch [18/100], Step [37700/6235], Loss: 0.8933\n",
      "Epoch [18/100], Step [37800/6235], Loss: 1.4053\n",
      "Epoch [18/100], Step [37900/6235], Loss: 3.4032\n",
      "Epoch [18/100], Step [38000/6235], Loss: 0.1807\n",
      "Epoch [18/100], Step [38100/6235], Loss: 8.4888\n",
      "Epoch [18/100], Step [38200/6235], Loss: 5.9884\n",
      "Epoch [18/100], Step [38300/6235], Loss: 1.7209\n",
      "Epoch [18/100], Step [38400/6235], Loss: 0.1850\n",
      "Epoch [18/100], Step [38500/6235], Loss: 0.1159\n",
      "Epoch [18/100], Step [38600/6235], Loss: 4.4604\n",
      "Epoch [18/100], Step [38700/6235], Loss: 0.0305\n",
      "Epoch [18/100], Step [38800/6235], Loss: 0.9531\n",
      "Epoch [18/100], Step [38900/6235], Loss: 12.5184\n",
      "Epoch [18/100], Step [39000/6235], Loss: 1.5050\n",
      "Epoch [18/100], Step [39100/6235], Loss: 12.1413\n",
      "Epoch [18/100], Step [39200/6235], Loss: 1.3962\n",
      "Epoch [18/100], Step [39300/6235], Loss: 169.5448\n",
      "Epoch [18/100], Step [39400/6235], Loss: 110.6261\n",
      "Epoch [18/100], Step [39500/6235], Loss: 341.6242\n",
      "Epoch [18/100], Step [39600/6235], Loss: 11.1860\n",
      "Epoch [18/100], Step [39700/6235], Loss: 205.7801\n",
      "Epoch [18/100], Step [39800/6235], Loss: 162.5027\n",
      "Epoch [18/100], Step [39900/6235], Loss: 0.4454\n",
      "Epoch [18/100], Step [40000/6235], Loss: 2.6113\n",
      "Epoch [18/100], Step [40100/6235], Loss: 32.0932\n",
      "Epoch [18/100], Step [40200/6235], Loss: 3.0856\n",
      "Epoch [18/100], Step [40300/6235], Loss: 0.2542\n",
      "Epoch [18/100], Step [40400/6235], Loss: 2.5698\n",
      "Epoch [18/100], Step [40500/6235], Loss: 2.3445\n",
      "Epoch [18/100], Step [40600/6235], Loss: 0.2306\n",
      "Epoch [18/100], Step [40700/6235], Loss: 7.9372\n",
      "Epoch [18/100], Step [40800/6235], Loss: 2.2731\n",
      "Epoch [18/100], Step [40900/6235], Loss: 0.0974\n",
      "Epoch [18/100], Step [41000/6235], Loss: 12.7135\n",
      "Epoch [18/100], Step [41100/6235], Loss: 18.9683\n",
      "Epoch [18/100], Step [41200/6235], Loss: 47.0985\n",
      "Epoch [18/100], Step [41300/6235], Loss: 4.5624\n",
      "Epoch [18/100], Step [41400/6235], Loss: 0.0096\n",
      "Epoch [18/100], Step [41500/6235], Loss: 0.4623\n",
      "Epoch [18/100], Step [41600/6235], Loss: 0.0436\n",
      "Epoch [18/100], Step [41700/6235], Loss: 0.6537\n",
      "Epoch [18/100], Step [41800/6235], Loss: 1.4007\n",
      "Epoch [18/100], Step [41900/6235], Loss: 2.9874\n",
      "Epoch [18/100], Step [42000/6235], Loss: 1.8463\n",
      "Epoch [18/100], Step [42100/6235], Loss: 4.6760\n",
      "Epoch [18/100], Step [42200/6235], Loss: 61.3442\n",
      "Epoch [18/100], Step [42300/6235], Loss: 2.6782\n",
      "Epoch [18/100], Step [42400/6235], Loss: 5.1707\n",
      "Epoch [18/100], Step [42500/6235], Loss: 2.0366\n",
      "Epoch [18/100], Step [42600/6235], Loss: 0.4739\n",
      "Epoch [18/100], Step [42700/6235], Loss: 0.2320\n",
      "Epoch [18/100], Step [42800/6235], Loss: 0.6041\n",
      "Epoch [18/100], Step [42900/6235], Loss: 4.0545\n",
      "Epoch [18/100], Step [43000/6235], Loss: 0.4495\n",
      "Epoch [18/100], Step [43100/6235], Loss: 2.1612\n",
      "Epoch [18/100], Step [43200/6235], Loss: 0.3791\n",
      "Epoch [18/100], Step [43300/6235], Loss: 10.6206\n",
      "Epoch [18/100], Step [43400/6235], Loss: 9.6781\n",
      "Epoch [18/100], Step [43500/6235], Loss: 9.1470\n",
      "Epoch [18/100], Step [43600/6235], Loss: 28.3354\n",
      "Epoch [18/100], Step [43700/6235], Loss: 46.3220\n",
      "Epoch [18/100], Step [43800/6235], Loss: 0.7361\n",
      "Epoch [18/100], Step [43900/6235], Loss: 0.7056\n",
      "Epoch [18/100], Step [44000/6235], Loss: 60.3682\n",
      "Epoch [18/100], Step [44100/6235], Loss: 2.1740\n",
      "Epoch [18/100], Step [44200/6235], Loss: 4.5144\n",
      "Epoch [18/100], Step [44300/6235], Loss: 41.0267\n",
      "Epoch [18/100], Step [44400/6235], Loss: 4.1260\n",
      "Epoch [18/100], Step [44500/6235], Loss: 2.8593\n",
      "Epoch [18/100], Step [44600/6235], Loss: 21.7350\n",
      "Epoch [18/100], Step [44700/6235], Loss: 8.9903\n",
      "Epoch [18/100], Step [44800/6235], Loss: 2.9216\n",
      "Epoch [18/100], Step [44900/6235], Loss: 5.5373\n",
      "Epoch [18/100], Step [45000/6235], Loss: 4.8419\n",
      "Epoch [18/100], Step [45100/6235], Loss: 48.3909\n",
      "Epoch [18/100], Step [45200/6235], Loss: 1.0953\n",
      "Epoch [18/100], Step [45300/6235], Loss: 26.2764\n",
      "Epoch [18/100], Step [45400/6235], Loss: 12.0056\n",
      "Epoch [18/100], Step [45500/6235], Loss: 0.8640\n",
      "Epoch [18/100], Step [45600/6235], Loss: 0.3447\n",
      "Epoch [18/100], Step [45700/6235], Loss: 112.4329\n",
      "Epoch [18/100], Step [45800/6235], Loss: 270.6774\n",
      "Epoch [18/100], Step [45900/6235], Loss: 17.8373\n",
      "Epoch [18/100], Step [46000/6235], Loss: 29.9808\n",
      "Epoch [18/100], Step [46100/6235], Loss: 39.2676\n",
      "Epoch [18/100], Step [46200/6235], Loss: 10.3659\n",
      "Epoch [18/100], Step [46300/6235], Loss: 63.1930\n",
      "Epoch [18/100], Step [46400/6235], Loss: 11.9470\n",
      "Epoch [18/100], Step [46500/6235], Loss: 252.8942\n",
      "Epoch [18/100], Step [46600/6235], Loss: 12.4025\n",
      "Epoch [18/100], Step [46700/6235], Loss: 7.6459\n",
      "Epoch [18/100], Step [46800/6235], Loss: 4.3766\n",
      "Epoch [18/100], Step [46900/6235], Loss: 2.1668\n",
      "Epoch [18/100], Step [47000/6235], Loss: 7.5606\n",
      "Epoch [18/100], Step [47100/6235], Loss: 5.2505\n",
      "Epoch [18/100], Step [47200/6235], Loss: 4.6183\n",
      "Epoch [18/100], Step [47300/6235], Loss: 1.1462\n",
      "Epoch [18/100], Step [47400/6235], Loss: 77.5133\n",
      "Epoch [18/100], Step [47500/6235], Loss: 3.0998\n",
      "Epoch [18/100], Step [47600/6235], Loss: 1.2668\n",
      "Epoch [18/100], Step [47700/6235], Loss: 6.0943\n",
      "Epoch [18/100], Step [47800/6235], Loss: 1.0524\n",
      "Epoch [18/100], Step [47900/6235], Loss: 23.3119\n",
      "Epoch [18/100], Step [48000/6235], Loss: 84.5424\n",
      "Epoch [18/100], Step [48100/6235], Loss: 4.4812\n",
      "Epoch [18/100], Step [48200/6235], Loss: 11.0548\n",
      "Epoch [18/100], Step [48300/6235], Loss: 105.9274\n",
      "Epoch [18/100], Step [48400/6235], Loss: 57.4644\n",
      "Epoch [18/100], Step [48500/6235], Loss: 4.9268\n",
      "Epoch [18/100], Step [48600/6235], Loss: 115.2557\n",
      "Epoch [18/100], Step [48700/6235], Loss: 104.1525\n",
      "Epoch [18/100], Step [48800/6235], Loss: 121.3347\n",
      "Epoch [18/100], Step [48900/6235], Loss: 52.3717\n",
      "Epoch [18/100], Step [49000/6235], Loss: 271.3731\n",
      "Epoch [18/100], Step [49100/6235], Loss: 2032.0385\n",
      "Epoch [18/100], Step [49200/6235], Loss: 533.1287\n",
      "Epoch [18/100], Step [49300/6235], Loss: 1047.3864\n",
      "Epoch [18/100], Step [49400/6235], Loss: 3.5980\n",
      "Epoch [18/100], Step [49500/6235], Loss: 35.2988\n",
      "Epoch [18/100], Step [49600/6235], Loss: 215.0872\n",
      "Epoch [18/100], Step [49700/6235], Loss: 4606.2178\n",
      "Epoch [18/100], Step [49800/6235], Loss: 32.4882\n",
      "Epoch [19/100], Step [100/6235], Loss: 8.1269\n",
      "Epoch [19/100], Step [200/6235], Loss: 1.3159\n",
      "Epoch [19/100], Step [300/6235], Loss: 0.7134\n",
      "Epoch [19/100], Step [400/6235], Loss: 0.5402\n",
      "Epoch [19/100], Step [500/6235], Loss: 0.2217\n",
      "Epoch [19/100], Step [600/6235], Loss: 0.3520\n",
      "Epoch [19/100], Step [700/6235], Loss: 0.2526\n",
      "Epoch [19/100], Step [800/6235], Loss: 0.2247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Step [900/6235], Loss: 0.1044\n",
      "Epoch [19/100], Step [1000/6235], Loss: 0.0238\n",
      "Epoch [19/100], Step [1100/6235], Loss: 0.0814\n",
      "Epoch [19/100], Step [1200/6235], Loss: 0.0823\n",
      "Epoch [19/100], Step [1300/6235], Loss: 0.0670\n",
      "Epoch [19/100], Step [1400/6235], Loss: 0.1065\n",
      "Epoch [19/100], Step [1500/6235], Loss: 0.0016\n",
      "Epoch [19/100], Step [1600/6235], Loss: 0.1963\n",
      "Epoch [19/100], Step [1700/6235], Loss: 0.0400\n",
      "Epoch [19/100], Step [1800/6235], Loss: 0.3536\n",
      "Epoch [19/100], Step [1900/6235], Loss: 0.4112\n",
      "Epoch [19/100], Step [2000/6235], Loss: 1.4661\n",
      "Epoch [19/100], Step [2100/6235], Loss: 0.7785\n",
      "Epoch [19/100], Step [2200/6235], Loss: 11.0148\n",
      "Epoch [19/100], Step [2300/6235], Loss: 24.0491\n",
      "Epoch [19/100], Step [2400/6235], Loss: 15.8985\n",
      "Epoch [19/100], Step [2500/6235], Loss: 17.9420\n",
      "Epoch [19/100], Step [2600/6235], Loss: 4.2474\n",
      "Epoch [19/100], Step [2700/6235], Loss: 27.1648\n",
      "Epoch [19/100], Step [2800/6235], Loss: 240.5424\n",
      "Epoch [19/100], Step [2900/6235], Loss: 4.4623\n",
      "Epoch [19/100], Step [3000/6235], Loss: 0.5154\n",
      "Epoch [19/100], Step [3100/6235], Loss: 34.7324\n",
      "Epoch [19/100], Step [3200/6235], Loss: 29.3437\n",
      "Epoch [19/100], Step [3300/6235], Loss: 1.1512\n",
      "Epoch [19/100], Step [3400/6235], Loss: 1.9686\n",
      "Epoch [19/100], Step [3500/6235], Loss: 26.9991\n",
      "Epoch [19/100], Step [3600/6235], Loss: 14.9686\n",
      "Epoch [19/100], Step [3700/6235], Loss: 2.2735\n",
      "Epoch [19/100], Step [3800/6235], Loss: 0.3146\n",
      "Epoch [19/100], Step [3900/6235], Loss: 1.4701\n",
      "Epoch [19/100], Step [4000/6235], Loss: 0.2567\n",
      "Epoch [19/100], Step [4100/6235], Loss: 0.5937\n",
      "Epoch [19/100], Step [4200/6235], Loss: 0.7438\n",
      "Epoch [19/100], Step [4300/6235], Loss: 10.8226\n",
      "Epoch [19/100], Step [4400/6235], Loss: 0.5032\n",
      "Epoch [19/100], Step [4500/6235], Loss: 76.2003\n",
      "Epoch [19/100], Step [4600/6235], Loss: 9.8094\n",
      "Epoch [19/100], Step [4700/6235], Loss: 2.0722\n",
      "Epoch [19/100], Step [4800/6235], Loss: 2.8705\n",
      "Epoch [19/100], Step [4900/6235], Loss: 0.4558\n",
      "Epoch [19/100], Step [5000/6235], Loss: 2.6121\n",
      "Epoch [19/100], Step [5100/6235], Loss: 9.5937\n",
      "Epoch [19/100], Step [5200/6235], Loss: 4.0348\n",
      "Epoch [19/100], Step [5300/6235], Loss: 30.8805\n",
      "Epoch [19/100], Step [5400/6235], Loss: 6.2183\n",
      "Epoch [19/100], Step [5500/6235], Loss: 0.0246\n",
      "Epoch [19/100], Step [5600/6235], Loss: 0.3776\n",
      "Epoch [19/100], Step [5700/6235], Loss: 2.9504\n",
      "Epoch [19/100], Step [5800/6235], Loss: 0.4360\n",
      "Epoch [19/100], Step [5900/6235], Loss: 2.5529\n",
      "Epoch [19/100], Step [6000/6235], Loss: 1.7841\n",
      "Epoch [19/100], Step [6100/6235], Loss: 0.2382\n",
      "Epoch [19/100], Step [6200/6235], Loss: 2.8459\n",
      "Epoch [19/100], Step [6300/6235], Loss: 0.7624\n",
      "Epoch [19/100], Step [6400/6235], Loss: 0.0642\n",
      "Epoch [19/100], Step [6500/6235], Loss: 0.1823\n",
      "Epoch [19/100], Step [6600/6235], Loss: 12.6117\n",
      "Epoch [19/100], Step [6700/6235], Loss: 0.5339\n",
      "Epoch [19/100], Step [6800/6235], Loss: 7.5587\n",
      "Epoch [19/100], Step [6900/6235], Loss: 1.0455\n",
      "Epoch [19/100], Step [7000/6235], Loss: 0.0457\n",
      "Epoch [19/100], Step [7100/6235], Loss: 1.3922\n",
      "Epoch [19/100], Step [7200/6235], Loss: 0.1139\n",
      "Epoch [19/100], Step [7300/6235], Loss: 2.4831\n",
      "Epoch [19/100], Step [7400/6235], Loss: 0.3095\n",
      "Epoch [19/100], Step [7500/6235], Loss: 26.4440\n",
      "Epoch [19/100], Step [7600/6235], Loss: 5.2534\n",
      "Epoch [19/100], Step [7700/6235], Loss: 6.1935\n",
      "Epoch [19/100], Step [7800/6235], Loss: 0.3491\n",
      "Epoch [19/100], Step [7900/6235], Loss: 6.9631\n",
      "Epoch [19/100], Step [8000/6235], Loss: 0.8186\n",
      "Epoch [19/100], Step [8100/6235], Loss: 3.0502\n",
      "Epoch [19/100], Step [8200/6235], Loss: 26.0181\n",
      "Epoch [19/100], Step [8300/6235], Loss: 32.8419\n",
      "Epoch [19/100], Step [8400/6235], Loss: 27.5527\n",
      "Epoch [19/100], Step [8500/6235], Loss: 27.9929\n",
      "Epoch [19/100], Step [8600/6235], Loss: 9.7678\n",
      "Epoch [19/100], Step [8700/6235], Loss: 7.8847\n",
      "Epoch [19/100], Step [8800/6235], Loss: 410.7882\n",
      "Epoch [19/100], Step [8900/6235], Loss: 1.3640\n",
      "Epoch [19/100], Step [9000/6235], Loss: 365.6288\n",
      "Epoch [19/100], Step [9100/6235], Loss: 45.9884\n",
      "Epoch [19/100], Step [9200/6235], Loss: 2122.9719\n",
      "Epoch [19/100], Step [9300/6235], Loss: 70.1766\n",
      "Epoch [19/100], Step [9400/6235], Loss: 1105.9882\n",
      "Epoch [19/100], Step [9500/6235], Loss: 170.5673\n",
      "Epoch [19/100], Step [9600/6235], Loss: 1336.6711\n",
      "Epoch [19/100], Step [9700/6235], Loss: 237.3630\n",
      "Epoch [19/100], Step [9800/6235], Loss: 330.4765\n",
      "Epoch [19/100], Step [9900/6235], Loss: 11.4164\n",
      "Epoch [19/100], Step [10000/6235], Loss: 23.9620\n",
      "Epoch [19/100], Step [10100/6235], Loss: 81.5886\n",
      "Epoch [19/100], Step [10200/6235], Loss: 715.3364\n",
      "Epoch [19/100], Step [10300/6235], Loss: 4.6747\n",
      "Epoch [19/100], Step [10400/6235], Loss: 9.7223\n",
      "Epoch [19/100], Step [10500/6235], Loss: 8.7624\n",
      "Epoch [19/100], Step [10600/6235], Loss: 1494.5787\n",
      "Epoch [19/100], Step [10700/6235], Loss: 233.7604\n",
      "Epoch [19/100], Step [10800/6235], Loss: 3.2631\n",
      "Epoch [19/100], Step [10900/6235], Loss: 5.1706\n",
      "Epoch [19/100], Step [11000/6235], Loss: 35.1783\n",
      "Epoch [19/100], Step [11100/6235], Loss: 0.3365\n",
      "Epoch [19/100], Step [11200/6235], Loss: 125.9002\n",
      "Epoch [19/100], Step [11300/6235], Loss: 211.4420\n",
      "Epoch [19/100], Step [11400/6235], Loss: 328.8829\n",
      "Epoch [19/100], Step [11500/6235], Loss: 9.0160\n",
      "Epoch [19/100], Step [11600/6235], Loss: 1.2700\n",
      "Epoch [19/100], Step [11700/6235], Loss: 159.8873\n",
      "Epoch [19/100], Step [11800/6235], Loss: 43.3721\n",
      "Epoch [19/100], Step [11900/6235], Loss: 763.9025\n",
      "Epoch [19/100], Step [12000/6235], Loss: 43.9711\n",
      "Epoch [19/100], Step [12100/6235], Loss: 553.8201\n",
      "Epoch [19/100], Step [12200/6235], Loss: 96.9274\n",
      "Epoch [19/100], Step [12300/6235], Loss: 2.1077\n",
      "Epoch [19/100], Step [12400/6235], Loss: 154.2512\n",
      "Epoch [19/100], Step [12500/6235], Loss: 209.1956\n",
      "Epoch [19/100], Step [12600/6235], Loss: 52.7476\n",
      "Epoch [19/100], Step [12700/6235], Loss: 3.6815\n",
      "Epoch [19/100], Step [12800/6235], Loss: 3.6954\n",
      "Epoch [19/100], Step [12900/6235], Loss: 27.8475\n",
      "Epoch [19/100], Step [13000/6235], Loss: 3.6053\n",
      "Epoch [19/100], Step [13100/6235], Loss: 83.8707\n",
      "Epoch [19/100], Step [13200/6235], Loss: 46.2329\n",
      "Epoch [19/100], Step [13300/6235], Loss: 2.4977\n",
      "Epoch [19/100], Step [13400/6235], Loss: 1.1068\n",
      "Epoch [19/100], Step [13500/6235], Loss: 0.9627\n",
      "Epoch [19/100], Step [13600/6235], Loss: 9.7137\n",
      "Epoch [19/100], Step [13700/6235], Loss: 229.0281\n",
      "Epoch [19/100], Step [13800/6235], Loss: 134.6043\n",
      "Epoch [19/100], Step [13900/6235], Loss: 0.4453\n",
      "Epoch [19/100], Step [14000/6235], Loss: 25.5908\n",
      "Epoch [19/100], Step [14100/6235], Loss: 137.2111\n",
      "Epoch [19/100], Step [14200/6235], Loss: 23.6792\n",
      "Epoch [19/100], Step [14300/6235], Loss: 3.9855\n",
      "Epoch [19/100], Step [14400/6235], Loss: 1.8919\n",
      "Epoch [19/100], Step [14500/6235], Loss: 14.4836\n",
      "Epoch [19/100], Step [14600/6235], Loss: 8.2638\n",
      "Epoch [19/100], Step [14700/6235], Loss: 7.3844\n",
      "Epoch [19/100], Step [14800/6235], Loss: 13.7735\n",
      "Epoch [19/100], Step [14900/6235], Loss: 0.3366\n",
      "Epoch [19/100], Step [15000/6235], Loss: 0.1401\n",
      "Epoch [19/100], Step [15100/6235], Loss: 0.1846\n",
      "Epoch [19/100], Step [15200/6235], Loss: 0.8890\n",
      "Epoch [19/100], Step [15300/6235], Loss: 150.4997\n",
      "Epoch [19/100], Step [15400/6235], Loss: 4.5681\n",
      "Epoch [19/100], Step [15500/6235], Loss: 33.5803\n",
      "Epoch [19/100], Step [15600/6235], Loss: 211.6006\n",
      "Epoch [19/100], Step [15700/6235], Loss: 10.9755\n",
      "Epoch [19/100], Step [15800/6235], Loss: 0.7709\n",
      "Epoch [19/100], Step [15900/6235], Loss: 0.5051\n",
      "Epoch [19/100], Step [16000/6235], Loss: 29.7002\n",
      "Epoch [19/100], Step [16100/6235], Loss: 0.7863\n",
      "Epoch [19/100], Step [16200/6235], Loss: 6.3222\n",
      "Epoch [19/100], Step [16300/6235], Loss: 11.5491\n",
      "Epoch [19/100], Step [16400/6235], Loss: 63.1216\n",
      "Epoch [19/100], Step [16500/6235], Loss: 549.7526\n",
      "Epoch [19/100], Step [16600/6235], Loss: 2.9137\n",
      "Epoch [19/100], Step [16700/6235], Loss: 7.8524\n",
      "Epoch [19/100], Step [16800/6235], Loss: 2.3912\n",
      "Epoch [19/100], Step [16900/6235], Loss: 0.9425\n",
      "Epoch [19/100], Step [17000/6235], Loss: 6.5076\n",
      "Epoch [19/100], Step [17100/6235], Loss: 3.8023\n",
      "Epoch [19/100], Step [17200/6235], Loss: 11.2634\n",
      "Epoch [19/100], Step [17300/6235], Loss: 11.5764\n",
      "Epoch [19/100], Step [17400/6235], Loss: 96.0053\n",
      "Epoch [19/100], Step [17500/6235], Loss: 15.7278\n",
      "Epoch [19/100], Step [17600/6235], Loss: 0.4995\n",
      "Epoch [19/100], Step [17700/6235], Loss: 26.1829\n",
      "Epoch [19/100], Step [17800/6235], Loss: 0.6001\n",
      "Epoch [19/100], Step [17900/6235], Loss: 17.3823\n",
      "Epoch [19/100], Step [18000/6235], Loss: 3.6155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Step [18100/6235], Loss: 2.9415\n",
      "Epoch [19/100], Step [18200/6235], Loss: 4.0738\n",
      "Epoch [19/100], Step [18300/6235], Loss: 1.5828\n",
      "Epoch [19/100], Step [18400/6235], Loss: 15.6656\n",
      "Epoch [19/100], Step [18500/6235], Loss: 32.3367\n",
      "Epoch [19/100], Step [18600/6235], Loss: 2.1538\n",
      "Epoch [19/100], Step [18700/6235], Loss: 2.0190\n",
      "Epoch [19/100], Step [18800/6235], Loss: 60.8296\n",
      "Epoch [19/100], Step [18900/6235], Loss: 11.7291\n",
      "Epoch [19/100], Step [19000/6235], Loss: 0.5554\n",
      "Epoch [19/100], Step [19100/6235], Loss: 0.5662\n",
      "Epoch [19/100], Step [19200/6235], Loss: 7.1595\n",
      "Epoch [19/100], Step [19300/6235], Loss: 1.2875\n",
      "Epoch [19/100], Step [19400/6235], Loss: 153.4373\n",
      "Epoch [19/100], Step [19500/6235], Loss: 222.8194\n",
      "Epoch [19/100], Step [19600/6235], Loss: 17.7568\n",
      "Epoch [19/100], Step [19700/6235], Loss: 25.6408\n",
      "Epoch [19/100], Step [19800/6235], Loss: 34.8855\n",
      "Epoch [19/100], Step [19900/6235], Loss: 4.2329\n",
      "Epoch [19/100], Step [20000/6235], Loss: 107.6875\n",
      "Epoch [19/100], Step [20100/6235], Loss: 3.4316\n",
      "Epoch [19/100], Step [20200/6235], Loss: 0.3121\n",
      "Epoch [19/100], Step [20300/6235], Loss: 0.1287\n",
      "Epoch [19/100], Step [20400/6235], Loss: 33.4440\n",
      "Epoch [19/100], Step [20500/6235], Loss: 18.6301\n",
      "Epoch [19/100], Step [20600/6235], Loss: 66.0111\n",
      "Epoch [19/100], Step [20700/6235], Loss: 18.3446\n",
      "Epoch [19/100], Step [20800/6235], Loss: 5.3801\n",
      "Epoch [19/100], Step [20900/6235], Loss: 29.5138\n",
      "Epoch [19/100], Step [21000/6235], Loss: 2.4692\n",
      "Epoch [19/100], Step [21100/6235], Loss: 8.4078\n",
      "Epoch [19/100], Step [21200/6235], Loss: 4.1086\n",
      "Epoch [19/100], Step [21300/6235], Loss: 8.1749\n",
      "Epoch [19/100], Step [21400/6235], Loss: 1.8011\n",
      "Epoch [19/100], Step [21500/6235], Loss: 6.9470\n",
      "Epoch [19/100], Step [21600/6235], Loss: 29.0806\n",
      "Epoch [19/100], Step [21700/6235], Loss: 6.3792\n",
      "Epoch [19/100], Step [21800/6235], Loss: 32.6443\n",
      "Epoch [19/100], Step [21900/6235], Loss: 2.5278\n",
      "Epoch [19/100], Step [22000/6235], Loss: 0.1130\n",
      "Epoch [19/100], Step [22100/6235], Loss: 3.5564\n",
      "Epoch [19/100], Step [22200/6235], Loss: 0.6758\n",
      "Epoch [19/100], Step [22300/6235], Loss: 4.2702\n",
      "Epoch [19/100], Step [22400/6235], Loss: 0.3822\n",
      "Epoch [19/100], Step [22500/6235], Loss: 184.8007\n",
      "Epoch [19/100], Step [22600/6235], Loss: 21.1667\n",
      "Epoch [19/100], Step [22700/6235], Loss: 0.0689\n",
      "Epoch [19/100], Step [22800/6235], Loss: 4.9495\n",
      "Epoch [19/100], Step [22900/6235], Loss: 17.9285\n",
      "Epoch [19/100], Step [23000/6235], Loss: 8.4850\n",
      "Epoch [19/100], Step [23100/6235], Loss: 1.4383\n",
      "Epoch [19/100], Step [23200/6235], Loss: 8.5030\n",
      "Epoch [19/100], Step [23300/6235], Loss: 11.0651\n",
      "Epoch [19/100], Step [23400/6235], Loss: 2.2323\n",
      "Epoch [19/100], Step [23500/6235], Loss: 0.0755\n",
      "Epoch [19/100], Step [23600/6235], Loss: 72.7704\n",
      "Epoch [19/100], Step [23700/6235], Loss: 4.0290\n",
      "Epoch [19/100], Step [23800/6235], Loss: 0.6380\n",
      "Epoch [19/100], Step [23900/6235], Loss: 5.4139\n",
      "Epoch [19/100], Step [24000/6235], Loss: 1.4412\n",
      "Epoch [19/100], Step [24100/6235], Loss: 0.5280\n",
      "Epoch [19/100], Step [24200/6235], Loss: 19.1124\n",
      "Epoch [19/100], Step [24300/6235], Loss: 4.0133\n",
      "Epoch [19/100], Step [24400/6235], Loss: 9.1648\n",
      "Epoch [19/100], Step [24500/6235], Loss: 2.9967\n",
      "Epoch [19/100], Step [24600/6235], Loss: 0.0887\n",
      "Epoch [19/100], Step [24700/6235], Loss: 2.8778\n",
      "Epoch [19/100], Step [24800/6235], Loss: 1.8979\n",
      "Epoch [19/100], Step [24900/6235], Loss: 15.9504\n",
      "Epoch [19/100], Step [25000/6235], Loss: 17.8981\n",
      "Epoch [19/100], Step [25100/6235], Loss: 7.4615\n",
      "Epoch [19/100], Step [25200/6235], Loss: 1.0886\n",
      "Epoch [19/100], Step [25300/6235], Loss: 0.7536\n",
      "Epoch [19/100], Step [25400/6235], Loss: 1.0381\n",
      "Epoch [19/100], Step [25500/6235], Loss: 6.7177\n",
      "Epoch [19/100], Step [25600/6235], Loss: 4.0812\n",
      "Epoch [19/100], Step [25700/6235], Loss: 0.0435\n",
      "Epoch [19/100], Step [25800/6235], Loss: 0.3825\n",
      "Epoch [19/100], Step [25900/6235], Loss: 2.1036\n",
      "Epoch [19/100], Step [26000/6235], Loss: 0.2527\n",
      "Epoch [19/100], Step [26100/6235], Loss: 1.4435\n",
      "Epoch [19/100], Step [26200/6235], Loss: 0.1388\n",
      "Epoch [19/100], Step [26300/6235], Loss: 4.3236\n",
      "Epoch [19/100], Step [26400/6235], Loss: 0.0664\n",
      "Epoch [19/100], Step [26500/6235], Loss: 0.0117\n",
      "Epoch [19/100], Step [26600/6235], Loss: 0.2772\n",
      "Epoch [19/100], Step [26700/6235], Loss: 0.1599\n",
      "Epoch [19/100], Step [26800/6235], Loss: 0.6953\n",
      "Epoch [19/100], Step [26900/6235], Loss: 0.0183\n",
      "Epoch [19/100], Step [27000/6235], Loss: 16.0437\n",
      "Epoch [19/100], Step [27100/6235], Loss: 0.1030\n",
      "Epoch [19/100], Step [27200/6235], Loss: 0.0352\n",
      "Epoch [19/100], Step [27300/6235], Loss: 0.0173\n",
      "Epoch [19/100], Step [27400/6235], Loss: 0.5844\n",
      "Epoch [19/100], Step [27500/6235], Loss: 3.8879\n",
      "Epoch [19/100], Step [27600/6235], Loss: 0.1332\n",
      "Epoch [19/100], Step [27700/6235], Loss: 1.6425\n",
      "Epoch [19/100], Step [27800/6235], Loss: 5.9520\n",
      "Epoch [19/100], Step [27900/6235], Loss: 0.1415\n",
      "Epoch [19/100], Step [28000/6235], Loss: 7.5860\n",
      "Epoch [19/100], Step [28100/6235], Loss: 9.8630\n",
      "Epoch [19/100], Step [28200/6235], Loss: 27.7409\n",
      "Epoch [19/100], Step [28300/6235], Loss: 2.5975\n",
      "Epoch [19/100], Step [28400/6235], Loss: 26.9589\n",
      "Epoch [19/100], Step [28500/6235], Loss: 3.1753\n",
      "Epoch [19/100], Step [28600/6235], Loss: 0.0669\n",
      "Epoch [19/100], Step [28700/6235], Loss: 4.9482\n",
      "Epoch [19/100], Step [28800/6235], Loss: 0.6438\n",
      "Epoch [19/100], Step [28900/6235], Loss: 52.4677\n",
      "Epoch [19/100], Step [29000/6235], Loss: 1.5465\n",
      "Epoch [19/100], Step [29100/6235], Loss: 0.5873\n",
      "Epoch [19/100], Step [29200/6235], Loss: 4.9381\n",
      "Epoch [19/100], Step [29300/6235], Loss: 4.8320\n",
      "Epoch [19/100], Step [29400/6235], Loss: 0.3457\n",
      "Epoch [19/100], Step [29500/6235], Loss: 4.7366\n",
      "Epoch [19/100], Step [29600/6235], Loss: 0.4090\n",
      "Epoch [19/100], Step [29700/6235], Loss: 3.0590\n",
      "Epoch [19/100], Step [29800/6235], Loss: 0.5169\n",
      "Epoch [19/100], Step [29900/6235], Loss: 2.9634\n",
      "Epoch [19/100], Step [30000/6235], Loss: 4.2594\n",
      "Epoch [19/100], Step [30100/6235], Loss: 9.8534\n",
      "Epoch [19/100], Step [30200/6235], Loss: 1.8700\n",
      "Epoch [19/100], Step [30300/6235], Loss: 0.0519\n",
      "Epoch [19/100], Step [30400/6235], Loss: 2.3763\n",
      "Epoch [19/100], Step [30500/6235], Loss: 0.9449\n",
      "Epoch [19/100], Step [30600/6235], Loss: 0.0055\n",
      "Epoch [19/100], Step [30700/6235], Loss: 2.0488\n",
      "Epoch [19/100], Step [30800/6235], Loss: 0.5553\n",
      "Epoch [19/100], Step [30900/6235], Loss: 2.3838\n",
      "Epoch [19/100], Step [31000/6235], Loss: 0.3570\n",
      "Epoch [19/100], Step [31100/6235], Loss: 0.1746\n",
      "Epoch [19/100], Step [31200/6235], Loss: 1.7009\n",
      "Epoch [19/100], Step [31300/6235], Loss: 1.2834\n",
      "Epoch [19/100], Step [31400/6235], Loss: 5.9430\n",
      "Epoch [19/100], Step [31500/6235], Loss: 0.6992\n",
      "Epoch [19/100], Step [31600/6235], Loss: 8.8960\n",
      "Epoch [19/100], Step [31700/6235], Loss: 21.8458\n",
      "Epoch [19/100], Step [31800/6235], Loss: 0.0712\n",
      "Epoch [19/100], Step [31900/6235], Loss: 1027.3097\n",
      "Epoch [19/100], Step [32000/6235], Loss: 21.2466\n",
      "Epoch [19/100], Step [32100/6235], Loss: 8.8538\n",
      "Epoch [19/100], Step [32200/6235], Loss: 82.5617\n",
      "Epoch [19/100], Step [32300/6235], Loss: 7.9594\n",
      "Epoch [19/100], Step [32400/6235], Loss: 0.5717\n",
      "Epoch [19/100], Step [32500/6235], Loss: 17.4695\n",
      "Epoch [19/100], Step [32600/6235], Loss: 0.4877\n",
      "Epoch [19/100], Step [32700/6235], Loss: 233.7511\n",
      "Epoch [19/100], Step [32800/6235], Loss: 20.8546\n",
      "Epoch [19/100], Step [32900/6235], Loss: 18.3313\n",
      "Epoch [19/100], Step [33000/6235], Loss: 0.2628\n",
      "Epoch [19/100], Step [33100/6235], Loss: 0.2037\n",
      "Epoch [19/100], Step [33200/6235], Loss: 5.3397\n",
      "Epoch [19/100], Step [33300/6235], Loss: 1.5358\n",
      "Epoch [19/100], Step [33400/6235], Loss: 0.4679\n",
      "Epoch [19/100], Step [33500/6235], Loss: 1.1686\n",
      "Epoch [19/100], Step [33600/6235], Loss: 1.0144\n",
      "Epoch [19/100], Step [33700/6235], Loss: 0.6166\n",
      "Epoch [19/100], Step [33800/6235], Loss: 8.7000\n",
      "Epoch [19/100], Step [33900/6235], Loss: 30.8975\n",
      "Epoch [19/100], Step [34000/6235], Loss: 0.0100\n",
      "Epoch [19/100], Step [34100/6235], Loss: 0.0380\n",
      "Epoch [19/100], Step [34200/6235], Loss: 13.8588\n",
      "Epoch [19/100], Step [34300/6235], Loss: 2.1090\n",
      "Epoch [19/100], Step [34400/6235], Loss: 0.6731\n",
      "Epoch [19/100], Step [34500/6235], Loss: 20.3490\n",
      "Epoch [19/100], Step [34600/6235], Loss: 1.6836\n",
      "Epoch [19/100], Step [34700/6235], Loss: 15.4583\n",
      "Epoch [19/100], Step [34800/6235], Loss: 7.5644\n",
      "Epoch [19/100], Step [34900/6235], Loss: 53.8037\n",
      "Epoch [19/100], Step [35000/6235], Loss: 1.6374\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [19/100], Step [35100/6235], Loss: 2.3377\n",
      "Epoch [19/100], Step [35200/6235], Loss: 9.6741\n",
      "Epoch [19/100], Step [35300/6235], Loss: 0.0819\n",
      "Epoch [19/100], Step [35400/6235], Loss: 1.1777\n",
      "Epoch [19/100], Step [35500/6235], Loss: 0.9358\n",
      "Epoch [19/100], Step [35600/6235], Loss: 0.5545\n",
      "Epoch [19/100], Step [35700/6235], Loss: 14.1370\n",
      "Epoch [19/100], Step [35800/6235], Loss: 0.4147\n",
      "Epoch [19/100], Step [35900/6235], Loss: 3.3397\n",
      "Epoch [19/100], Step [36000/6235], Loss: 0.4626\n",
      "Epoch [19/100], Step [36100/6235], Loss: 4.7306\n",
      "Epoch [19/100], Step [36200/6235], Loss: 9.6951\n",
      "Epoch [19/100], Step [36300/6235], Loss: 1.8043\n",
      "Epoch [19/100], Step [36400/6235], Loss: 0.0954\n",
      "Epoch [19/100], Step [36500/6235], Loss: 11.9430\n",
      "Epoch [19/100], Step [36600/6235], Loss: 0.2455\n",
      "Epoch [19/100], Step [36700/6235], Loss: 0.5014\n",
      "Epoch [19/100], Step [36800/6235], Loss: 36.2009\n",
      "Epoch [19/100], Step [36900/6235], Loss: 11.1508\n",
      "Epoch [19/100], Step [37000/6235], Loss: 0.6378\n",
      "Epoch [19/100], Step [37100/6235], Loss: 0.3611\n",
      "Epoch [19/100], Step [37200/6235], Loss: 0.0312\n",
      "Epoch [19/100], Step [37300/6235], Loss: 0.6412\n",
      "Epoch [19/100], Step [37400/6235], Loss: 0.3064\n",
      "Epoch [19/100], Step [37500/6235], Loss: 3.4019\n",
      "Epoch [19/100], Step [37600/6235], Loss: 7.2955\n",
      "Epoch [19/100], Step [37700/6235], Loss: 1.9878\n",
      "Epoch [19/100], Step [37800/6235], Loss: 2.1535\n",
      "Epoch [19/100], Step [37900/6235], Loss: 1.5082\n",
      "Epoch [19/100], Step [38000/6235], Loss: 0.6243\n",
      "Epoch [19/100], Step [38100/6235], Loss: 9.1615\n",
      "Epoch [19/100], Step [38200/6235], Loss: 1.6025\n",
      "Epoch [19/100], Step [38300/6235], Loss: 2.0148\n",
      "Epoch [19/100], Step [38400/6235], Loss: 0.1006\n",
      "Epoch [19/100], Step [38500/6235], Loss: 3.6622\n",
      "Epoch [19/100], Step [38600/6235], Loss: 5.2057\n",
      "Epoch [19/100], Step [38700/6235], Loss: 0.0814\n",
      "Epoch [19/100], Step [38800/6235], Loss: 1.1723\n",
      "Epoch [19/100], Step [38900/6235], Loss: 138.7985\n",
      "Epoch [19/100], Step [39000/6235], Loss: 8.9486\n",
      "Epoch [19/100], Step [39100/6235], Loss: 29.0613\n",
      "Epoch [19/100], Step [39200/6235], Loss: 0.9765\n",
      "Epoch [19/100], Step [39300/6235], Loss: 3.0297\n",
      "Epoch [19/100], Step [39400/6235], Loss: 11.5437\n",
      "Epoch [19/100], Step [39500/6235], Loss: 12.3277\n",
      "Epoch [19/100], Step [39600/6235], Loss: 23.0380\n",
      "Epoch [19/100], Step [39700/6235], Loss: 58.8116\n",
      "Epoch [19/100], Step [39800/6235], Loss: 177.5157\n",
      "Epoch [19/100], Step [39900/6235], Loss: 0.5623\n",
      "Epoch [19/100], Step [40000/6235], Loss: 2.8542\n",
      "Epoch [19/100], Step [40100/6235], Loss: 31.0943\n",
      "Epoch [19/100], Step [40200/6235], Loss: 32.6272\n",
      "Epoch [19/100], Step [40300/6235], Loss: 0.1761\n",
      "Epoch [19/100], Step [40400/6235], Loss: 2.6549\n",
      "Epoch [19/100], Step [40500/6235], Loss: 1.0991\n",
      "Epoch [19/100], Step [40600/6235], Loss: 1.1976\n",
      "Epoch [19/100], Step [40700/6235], Loss: 7.3330\n",
      "Epoch [19/100], Step [40800/6235], Loss: 3.8053\n",
      "Epoch [19/100], Step [40900/6235], Loss: 0.6943\n",
      "Epoch [19/100], Step [41000/6235], Loss: 0.8705\n",
      "Epoch [19/100], Step [41100/6235], Loss: 2.7710\n",
      "Epoch [19/100], Step [41200/6235], Loss: 20.9621\n",
      "Epoch [19/100], Step [41300/6235], Loss: 1.9182\n",
      "Epoch [19/100], Step [41400/6235], Loss: 0.6060\n",
      "Epoch [19/100], Step [41500/6235], Loss: 2.6249\n",
      "Epoch [19/100], Step [41600/6235], Loss: 3.7679\n",
      "Epoch [19/100], Step [41700/6235], Loss: 2.6988\n",
      "Epoch [19/100], Step [41800/6235], Loss: 2.1567\n",
      "Epoch [19/100], Step [41900/6235], Loss: 2.3824\n",
      "Epoch [19/100], Step [42000/6235], Loss: 1.8550\n",
      "Epoch [19/100], Step [42100/6235], Loss: 4.1717\n",
      "Epoch [19/100], Step [42200/6235], Loss: 39.7513\n",
      "Epoch [19/100], Step [42300/6235], Loss: 2.8784\n",
      "Epoch [19/100], Step [42400/6235], Loss: 7.1919\n",
      "Epoch [19/100], Step [42500/6235], Loss: 0.8945\n",
      "Epoch [19/100], Step [42600/6235], Loss: 0.4270\n",
      "Epoch [19/100], Step [42700/6235], Loss: 0.1949\n",
      "Epoch [19/100], Step [42800/6235], Loss: 1.0418\n",
      "Epoch [19/100], Step [42900/6235], Loss: 4.3037\n",
      "Epoch [19/100], Step [43000/6235], Loss: 0.7737\n",
      "Epoch [19/100], Step [43100/6235], Loss: 2.4729\n",
      "Epoch [19/100], Step [43200/6235], Loss: 0.2805\n",
      "Epoch [19/100], Step [43300/6235], Loss: 11.3795\n",
      "Epoch [19/100], Step [43400/6235], Loss: 6.4313\n",
      "Epoch [19/100], Step [43500/6235], Loss: 8.1308\n",
      "Epoch [19/100], Step [43600/6235], Loss: 34.4923\n",
      "Epoch [19/100], Step [43700/6235], Loss: 46.2656\n",
      "Epoch [19/100], Step [43800/6235], Loss: 0.3441\n",
      "Epoch [19/100], Step [43900/6235], Loss: 1.4031\n",
      "Epoch [19/100], Step [44000/6235], Loss: 49.9214\n",
      "Epoch [19/100], Step [44100/6235], Loss: 3.0572\n",
      "Epoch [19/100], Step [44200/6235], Loss: 34.5078\n",
      "Epoch [19/100], Step [44300/6235], Loss: 73.9603\n",
      "Epoch [19/100], Step [44400/6235], Loss: 3.8871\n",
      "Epoch [19/100], Step [44500/6235], Loss: 0.4474\n",
      "Epoch [19/100], Step [44600/6235], Loss: 13.2744\n",
      "Epoch [19/100], Step [44700/6235], Loss: 3.0727\n",
      "Epoch [19/100], Step [44800/6235], Loss: 3.0658\n",
      "Epoch [19/100], Step [44900/6235], Loss: 1.5400\n",
      "Epoch [19/100], Step [45000/6235], Loss: 4.9636\n",
      "Epoch [19/100], Step [45100/6235], Loss: 7.6749\n",
      "Epoch [19/100], Step [45200/6235], Loss: 0.4655\n",
      "Epoch [19/100], Step [45300/6235], Loss: 32.6684\n",
      "Epoch [19/100], Step [45400/6235], Loss: 8.7002\n",
      "Epoch [19/100], Step [45500/6235], Loss: 0.1649\n",
      "Epoch [19/100], Step [45600/6235], Loss: 0.2323\n",
      "Epoch [19/100], Step [45700/6235], Loss: 83.6054\n",
      "Epoch [19/100], Step [45800/6235], Loss: 360.2635\n",
      "Epoch [19/100], Step [45900/6235], Loss: 8.2576\n",
      "Epoch [19/100], Step [46000/6235], Loss: 25.8376\n",
      "Epoch [19/100], Step [46100/6235], Loss: 40.4993\n",
      "Epoch [19/100], Step [46200/6235], Loss: 55.1705\n",
      "Epoch [19/100], Step [46300/6235], Loss: 1.2533\n",
      "Epoch [19/100], Step [46400/6235], Loss: 10.2968\n",
      "Epoch [19/100], Step [46500/6235], Loss: 17.3846\n",
      "Epoch [19/100], Step [46600/6235], Loss: 26.7659\n",
      "Epoch [19/100], Step [46700/6235], Loss: 7.1118\n",
      "Epoch [19/100], Step [46800/6235], Loss: 1.3787\n",
      "Epoch [19/100], Step [46900/6235], Loss: 6.5264\n",
      "Epoch [19/100], Step [47000/6235], Loss: 4.4575\n",
      "Epoch [19/100], Step [47100/6235], Loss: 1.6034\n",
      "Epoch [19/100], Step [47200/6235], Loss: 8.2662\n",
      "Epoch [19/100], Step [47300/6235], Loss: 0.9252\n",
      "Epoch [19/100], Step [47400/6235], Loss: 9.4352\n",
      "Epoch [19/100], Step [47500/6235], Loss: 33.2207\n",
      "Epoch [19/100], Step [47600/6235], Loss: 1.4514\n",
      "Epoch [19/100], Step [47700/6235], Loss: 4.4858\n",
      "Epoch [19/100], Step [47800/6235], Loss: 1.2118\n",
      "Epoch [19/100], Step [47900/6235], Loss: 26.5080\n",
      "Epoch [19/100], Step [48000/6235], Loss: 119.8193\n",
      "Epoch [19/100], Step [48100/6235], Loss: 3.8218\n",
      "Epoch [19/100], Step [48200/6235], Loss: 8.4508\n",
      "Epoch [19/100], Step [48300/6235], Loss: 289.7864\n",
      "Epoch [19/100], Step [48400/6235], Loss: 34.4098\n",
      "Epoch [19/100], Step [48500/6235], Loss: 11.1440\n",
      "Epoch [19/100], Step [48600/6235], Loss: 153.3010\n",
      "Epoch [19/100], Step [48700/6235], Loss: 58.7002\n",
      "Epoch [19/100], Step [48800/6235], Loss: 238.0306\n",
      "Epoch [19/100], Step [48900/6235], Loss: 221.3023\n",
      "Epoch [19/100], Step [49000/6235], Loss: 278.9634\n",
      "Epoch [19/100], Step [49100/6235], Loss: 1711.9626\n",
      "Epoch [19/100], Step [49200/6235], Loss: 724.9250\n",
      "Epoch [19/100], Step [49300/6235], Loss: 1199.0309\n",
      "Epoch [19/100], Step [49400/6235], Loss: 1.1385\n",
      "Epoch [19/100], Step [49500/6235], Loss: 11.1954\n",
      "Epoch [19/100], Step [49600/6235], Loss: 98.4341\n",
      "Epoch [19/100], Step [49700/6235], Loss: 2855.4033\n",
      "Epoch [19/100], Step [49800/6235], Loss: 419.2391\n",
      "Epoch [20/100], Step [100/6235], Loss: 2.2460\n",
      "Epoch [20/100], Step [200/6235], Loss: 0.1611\n",
      "Epoch [20/100], Step [300/6235], Loss: 0.0382\n",
      "Epoch [20/100], Step [400/6235], Loss: 0.0114\n",
      "Epoch [20/100], Step [500/6235], Loss: 23.5540\n",
      "Epoch [20/100], Step [600/6235], Loss: 0.1049\n",
      "Epoch [20/100], Step [700/6235], Loss: 0.6608\n",
      "Epoch [20/100], Step [800/6235], Loss: 0.2085\n",
      "Epoch [20/100], Step [900/6235], Loss: 0.1757\n",
      "Epoch [20/100], Step [1000/6235], Loss: 0.0572\n",
      "Epoch [20/100], Step [1100/6235], Loss: 0.3001\n",
      "Epoch [20/100], Step [1200/6235], Loss: 0.1901\n",
      "Epoch [20/100], Step [1300/6235], Loss: 0.0310\n",
      "Epoch [20/100], Step [1400/6235], Loss: 0.1580\n",
      "Epoch [20/100], Step [1500/6235], Loss: 0.0069\n",
      "Epoch [20/100], Step [1600/6235], Loss: 0.2367\n",
      "Epoch [20/100], Step [1700/6235], Loss: 0.0462\n",
      "Epoch [20/100], Step [1800/6235], Loss: 0.2139\n",
      "Epoch [20/100], Step [1900/6235], Loss: 0.4374\n",
      "Epoch [20/100], Step [2000/6235], Loss: 2.2756\n",
      "Epoch [20/100], Step [2100/6235], Loss: 3.0532\n",
      "Epoch [20/100], Step [2200/6235], Loss: 8.3793\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Step [2300/6235], Loss: 7.1724\n",
      "Epoch [20/100], Step [2400/6235], Loss: 2.6612\n",
      "Epoch [20/100], Step [2500/6235], Loss: 37.6846\n",
      "Epoch [20/100], Step [2600/6235], Loss: 11.8513\n",
      "Epoch [20/100], Step [2700/6235], Loss: 14.0265\n",
      "Epoch [20/100], Step [2800/6235], Loss: 746.5477\n",
      "Epoch [20/100], Step [2900/6235], Loss: 6.7187\n",
      "Epoch [20/100], Step [3000/6235], Loss: 0.1169\n",
      "Epoch [20/100], Step [3100/6235], Loss: 63.5780\n",
      "Epoch [20/100], Step [3200/6235], Loss: 85.4082\n",
      "Epoch [20/100], Step [3300/6235], Loss: 1.5097\n",
      "Epoch [20/100], Step [3400/6235], Loss: 2.7644\n",
      "Epoch [20/100], Step [3500/6235], Loss: 27.0931\n",
      "Epoch [20/100], Step [3600/6235], Loss: 10.2892\n",
      "Epoch [20/100], Step [3700/6235], Loss: 1.0218\n",
      "Epoch [20/100], Step [3800/6235], Loss: 0.5932\n",
      "Epoch [20/100], Step [3900/6235], Loss: 1.6647\n",
      "Epoch [20/100], Step [4000/6235], Loss: 0.0676\n",
      "Epoch [20/100], Step [4100/6235], Loss: 4.4818\n",
      "Epoch [20/100], Step [4200/6235], Loss: 0.3333\n",
      "Epoch [20/100], Step [4300/6235], Loss: 10.5838\n",
      "Epoch [20/100], Step [4400/6235], Loss: 4.1210\n",
      "Epoch [20/100], Step [4500/6235], Loss: 54.5250\n",
      "Epoch [20/100], Step [4600/6235], Loss: 11.5233\n",
      "Epoch [20/100], Step [4700/6235], Loss: 1.2358\n",
      "Epoch [20/100], Step [4800/6235], Loss: 1.5755\n",
      "Epoch [20/100], Step [4900/6235], Loss: 0.0768\n",
      "Epoch [20/100], Step [5000/6235], Loss: 0.5903\n",
      "Epoch [20/100], Step [5100/6235], Loss: 3.3441\n",
      "Epoch [20/100], Step [5200/6235], Loss: 21.3977\n",
      "Epoch [20/100], Step [5300/6235], Loss: 32.3054\n",
      "Epoch [20/100], Step [5400/6235], Loss: 0.5342\n",
      "Epoch [20/100], Step [5500/6235], Loss: 0.4659\n",
      "Epoch [20/100], Step [5600/6235], Loss: 0.6584\n",
      "Epoch [20/100], Step [5700/6235], Loss: 2.1506\n",
      "Epoch [20/100], Step [5800/6235], Loss: 1.0345\n",
      "Epoch [20/100], Step [5900/6235], Loss: 0.0917\n",
      "Epoch [20/100], Step [6000/6235], Loss: 0.2539\n",
      "Epoch [20/100], Step [6100/6235], Loss: 0.1543\n",
      "Epoch [20/100], Step [6200/6235], Loss: 0.6824\n",
      "Epoch [20/100], Step [6300/6235], Loss: 0.8151\n",
      "Epoch [20/100], Step [6400/6235], Loss: 0.3964\n",
      "Epoch [20/100], Step [6500/6235], Loss: 1.4387\n",
      "Epoch [20/100], Step [6600/6235], Loss: 12.8533\n",
      "Epoch [20/100], Step [6700/6235], Loss: 0.8022\n",
      "Epoch [20/100], Step [6800/6235], Loss: 0.8590\n",
      "Epoch [20/100], Step [6900/6235], Loss: 3.5007\n",
      "Epoch [20/100], Step [7000/6235], Loss: 0.2949\n",
      "Epoch [20/100], Step [7100/6235], Loss: 0.2992\n",
      "Epoch [20/100], Step [7200/6235], Loss: 1.5231\n",
      "Epoch [20/100], Step [7300/6235], Loss: 0.4972\n",
      "Epoch [20/100], Step [7400/6235], Loss: 0.0315\n",
      "Epoch [20/100], Step [7500/6235], Loss: 8.5976\n",
      "Epoch [20/100], Step [7600/6235], Loss: 2.3366\n",
      "Epoch [20/100], Step [7700/6235], Loss: 0.6716\n",
      "Epoch [20/100], Step [7800/6235], Loss: 7.8285\n",
      "Epoch [20/100], Step [7900/6235], Loss: 18.5277\n",
      "Epoch [20/100], Step [8000/6235], Loss: 0.6195\n",
      "Epoch [20/100], Step [8100/6235], Loss: 3.6336\n",
      "Epoch [20/100], Step [8200/6235], Loss: 23.4133\n",
      "Epoch [20/100], Step [8300/6235], Loss: 59.5296\n",
      "Epoch [20/100], Step [8400/6235], Loss: 20.2182\n",
      "Epoch [20/100], Step [8500/6235], Loss: 43.8591\n",
      "Epoch [20/100], Step [8600/6235], Loss: 11.4932\n",
      "Epoch [20/100], Step [8700/6235], Loss: 7.4744\n",
      "Epoch [20/100], Step [8800/6235], Loss: 512.2197\n",
      "Epoch [20/100], Step [8900/6235], Loss: 39.9323\n",
      "Epoch [20/100], Step [9000/6235], Loss: 518.7322\n",
      "Epoch [20/100], Step [9100/6235], Loss: 331.9598\n",
      "Epoch [20/100], Step [9200/6235], Loss: 3431.8005\n",
      "Epoch [20/100], Step [9300/6235], Loss: 141.4939\n",
      "Epoch [20/100], Step [9400/6235], Loss: 692.3588\n",
      "Epoch [20/100], Step [9500/6235], Loss: 57.7871\n",
      "Epoch [20/100], Step [9600/6235], Loss: 39.3809\n",
      "Epoch [20/100], Step [9700/6235], Loss: 43.5116\n",
      "Epoch [20/100], Step [9800/6235], Loss: 531.6503\n",
      "Epoch [20/100], Step [9900/6235], Loss: 12.8685\n",
      "Epoch [20/100], Step [10000/6235], Loss: 38.9879\n",
      "Epoch [20/100], Step [10100/6235], Loss: 6.6653\n",
      "Epoch [20/100], Step [10200/6235], Loss: 441.8884\n",
      "Epoch [20/100], Step [10300/6235], Loss: 0.9744\n",
      "Epoch [20/100], Step [10400/6235], Loss: 1.0321\n",
      "Epoch [20/100], Step [10500/6235], Loss: 0.6262\n",
      "Epoch [20/100], Step [10600/6235], Loss: 1579.7819\n",
      "Epoch [20/100], Step [10700/6235], Loss: 23.9520\n",
      "Epoch [20/100], Step [10800/6235], Loss: 151.4376\n",
      "Epoch [20/100], Step [10900/6235], Loss: 3.0549\n",
      "Epoch [20/100], Step [11000/6235], Loss: 217.8506\n",
      "Epoch [20/100], Step [11100/6235], Loss: 30.2048\n",
      "Epoch [20/100], Step [11200/6235], Loss: 59.7772\n",
      "Epoch [20/100], Step [11300/6235], Loss: 209.8902\n",
      "Epoch [20/100], Step [11400/6235], Loss: 47.3800\n",
      "Epoch [20/100], Step [11500/6235], Loss: 3.3305\n",
      "Epoch [20/100], Step [11600/6235], Loss: 4.3996\n",
      "Epoch [20/100], Step [11700/6235], Loss: 105.3658\n",
      "Epoch [20/100], Step [11800/6235], Loss: 82.7346\n",
      "Epoch [20/100], Step [11900/6235], Loss: 782.5707\n",
      "Epoch [20/100], Step [12000/6235], Loss: 456.5507\n",
      "Epoch [20/100], Step [12100/6235], Loss: 320.9977\n",
      "Epoch [20/100], Step [12200/6235], Loss: 9.5717\n",
      "Epoch [20/100], Step [12300/6235], Loss: 3.8917\n",
      "Epoch [20/100], Step [12400/6235], Loss: 113.7068\n",
      "Epoch [20/100], Step [12500/6235], Loss: 162.2777\n",
      "Epoch [20/100], Step [12600/6235], Loss: 1.2411\n",
      "Epoch [20/100], Step [12700/6235], Loss: 21.7355\n",
      "Epoch [20/100], Step [12800/6235], Loss: 28.0226\n",
      "Epoch [20/100], Step [12900/6235], Loss: 55.6076\n",
      "Epoch [20/100], Step [13000/6235], Loss: 0.0826\n",
      "Epoch [20/100], Step [13100/6235], Loss: 75.5248\n",
      "Epoch [20/100], Step [13200/6235], Loss: 11.7173\n",
      "Epoch [20/100], Step [13300/6235], Loss: 16.8319\n",
      "Epoch [20/100], Step [13400/6235], Loss: 114.8758\n",
      "Epoch [20/100], Step [13500/6235], Loss: 6.9036\n",
      "Epoch [20/100], Step [13600/6235], Loss: 0.6993\n",
      "Epoch [20/100], Step [13700/6235], Loss: 107.9662\n",
      "Epoch [20/100], Step [13800/6235], Loss: 114.0119\n",
      "Epoch [20/100], Step [13900/6235], Loss: 71.7148\n",
      "Epoch [20/100], Step [14000/6235], Loss: 1.0037\n",
      "Epoch [20/100], Step [14100/6235], Loss: 8.3555\n",
      "Epoch [20/100], Step [14200/6235], Loss: 66.6821\n",
      "Epoch [20/100], Step [14300/6235], Loss: 2.6564\n",
      "Epoch [20/100], Step [14400/6235], Loss: 24.7083\n",
      "Epoch [20/100], Step [14500/6235], Loss: 26.0338\n",
      "Epoch [20/100], Step [14600/6235], Loss: 2.6786\n",
      "Epoch [20/100], Step [14700/6235], Loss: 27.6550\n",
      "Epoch [20/100], Step [14800/6235], Loss: 31.7401\n",
      "Epoch [20/100], Step [14900/6235], Loss: 0.6762\n",
      "Epoch [20/100], Step [15000/6235], Loss: 1.1584\n",
      "Epoch [20/100], Step [15100/6235], Loss: 0.3315\n",
      "Epoch [20/100], Step [15200/6235], Loss: 50.4568\n",
      "Epoch [20/100], Step [15300/6235], Loss: 3.7644\n",
      "Epoch [20/100], Step [15400/6235], Loss: 27.5894\n",
      "Epoch [20/100], Step [15500/6235], Loss: 0.7539\n",
      "Epoch [20/100], Step [15600/6235], Loss: 248.8515\n",
      "Epoch [20/100], Step [15700/6235], Loss: 187.3767\n",
      "Epoch [20/100], Step [15800/6235], Loss: 2.7458\n",
      "Epoch [20/100], Step [15900/6235], Loss: 3.1977\n",
      "Epoch [20/100], Step [16000/6235], Loss: 18.5011\n",
      "Epoch [20/100], Step [16100/6235], Loss: 1.8903\n",
      "Epoch [20/100], Step [16200/6235], Loss: 13.9619\n",
      "Epoch [20/100], Step [16300/6235], Loss: 17.2021\n",
      "Epoch [20/100], Step [16400/6235], Loss: 28.1897\n",
      "Epoch [20/100], Step [16500/6235], Loss: 464.9119\n",
      "Epoch [20/100], Step [16600/6235], Loss: 30.8584\n",
      "Epoch [20/100], Step [16700/6235], Loss: 0.8205\n",
      "Epoch [20/100], Step [16800/6235], Loss: 6.4792\n",
      "Epoch [20/100], Step [16900/6235], Loss: 3.0639\n",
      "Epoch [20/100], Step [17000/6235], Loss: 0.3303\n",
      "Epoch [20/100], Step [17100/6235], Loss: 0.6994\n",
      "Epoch [20/100], Step [17200/6235], Loss: 117.4357\n",
      "Epoch [20/100], Step [17300/6235], Loss: 59.7939\n",
      "Epoch [20/100], Step [17400/6235], Loss: 32.0651\n",
      "Epoch [20/100], Step [17500/6235], Loss: 12.0028\n",
      "Epoch [20/100], Step [17600/6235], Loss: 1.0422\n",
      "Epoch [20/100], Step [17700/6235], Loss: 10.2308\n",
      "Epoch [20/100], Step [17800/6235], Loss: 37.2600\n",
      "Epoch [20/100], Step [17900/6235], Loss: 9.7409\n",
      "Epoch [20/100], Step [18000/6235], Loss: 0.5710\n",
      "Epoch [20/100], Step [18100/6235], Loss: 7.8285\n",
      "Epoch [20/100], Step [18200/6235], Loss: 1.8781\n",
      "Epoch [20/100], Step [18300/6235], Loss: 9.2639\n",
      "Epoch [20/100], Step [18400/6235], Loss: 3.3922\n",
      "Epoch [20/100], Step [18500/6235], Loss: 10.2844\n",
      "Epoch [20/100], Step [18600/6235], Loss: 0.2104\n",
      "Epoch [20/100], Step [18700/6235], Loss: 0.2934\n",
      "Epoch [20/100], Step [18800/6235], Loss: 145.5530\n",
      "Epoch [20/100], Step [18900/6235], Loss: 1.9521\n",
      "Epoch [20/100], Step [19000/6235], Loss: 9.9481\n",
      "Epoch [20/100], Step [19100/6235], Loss: 43.2918\n",
      "Epoch [20/100], Step [19200/6235], Loss: 0.7313\n",
      "Epoch [20/100], Step [19300/6235], Loss: 0.3807\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Step [19400/6235], Loss: 18.9370\n",
      "Epoch [20/100], Step [19500/6235], Loss: 127.9122\n",
      "Epoch [20/100], Step [19600/6235], Loss: 110.5254\n",
      "Epoch [20/100], Step [19700/6235], Loss: 10.0918\n",
      "Epoch [20/100], Step [19800/6235], Loss: 1.5481\n",
      "Epoch [20/100], Step [19900/6235], Loss: 0.1981\n",
      "Epoch [20/100], Step [20000/6235], Loss: 63.8702\n",
      "Epoch [20/100], Step [20100/6235], Loss: 2.7022\n",
      "Epoch [20/100], Step [20200/6235], Loss: 6.2227\n",
      "Epoch [20/100], Step [20300/6235], Loss: 0.2928\n",
      "Epoch [20/100], Step [20400/6235], Loss: 9.8586\n",
      "Epoch [20/100], Step [20500/6235], Loss: 49.0129\n",
      "Epoch [20/100], Step [20600/6235], Loss: 44.9198\n",
      "Epoch [20/100], Step [20700/6235], Loss: 4.4134\n",
      "Epoch [20/100], Step [20800/6235], Loss: 0.6369\n",
      "Epoch [20/100], Step [20900/6235], Loss: 36.9403\n",
      "Epoch [20/100], Step [21000/6235], Loss: 19.4280\n",
      "Epoch [20/100], Step [21100/6235], Loss: 5.2753\n",
      "Epoch [20/100], Step [21200/6235], Loss: 0.2373\n",
      "Epoch [20/100], Step [21300/6235], Loss: 0.2155\n",
      "Epoch [20/100], Step [21400/6235], Loss: 5.1629\n",
      "Epoch [20/100], Step [21500/6235], Loss: 4.0375\n",
      "Epoch [20/100], Step [21600/6235], Loss: 8.5109\n",
      "Epoch [20/100], Step [21700/6235], Loss: 0.4696\n",
      "Epoch [20/100], Step [21800/6235], Loss: 3.7862\n",
      "Epoch [20/100], Step [21900/6235], Loss: 1.7263\n",
      "Epoch [20/100], Step [22000/6235], Loss: 11.0478\n",
      "Epoch [20/100], Step [22100/6235], Loss: 0.2180\n",
      "Epoch [20/100], Step [22200/6235], Loss: 0.6471\n",
      "Epoch [20/100], Step [22300/6235], Loss: 3.7113\n",
      "Epoch [20/100], Step [22400/6235], Loss: 25.5568\n",
      "Epoch [20/100], Step [22500/6235], Loss: 112.7463\n",
      "Epoch [20/100], Step [22600/6235], Loss: 0.6922\n",
      "Epoch [20/100], Step [22700/6235], Loss: 1.1559\n",
      "Epoch [20/100], Step [22800/6235], Loss: 9.4205\n",
      "Epoch [20/100], Step [22900/6235], Loss: 21.6529\n",
      "Epoch [20/100], Step [23000/6235], Loss: 7.7730\n",
      "Epoch [20/100], Step [23100/6235], Loss: 4.9400\n",
      "Epoch [20/100], Step [23200/6235], Loss: 13.7420\n",
      "Epoch [20/100], Step [23300/6235], Loss: 14.1913\n",
      "Epoch [20/100], Step [23400/6235], Loss: 2.4381\n",
      "Epoch [20/100], Step [23500/6235], Loss: 0.2617\n",
      "Epoch [20/100], Step [23600/6235], Loss: 121.4457\n",
      "Epoch [20/100], Step [23700/6235], Loss: 5.9216\n",
      "Epoch [20/100], Step [23800/6235], Loss: 1.3294\n",
      "Epoch [20/100], Step [23900/6235], Loss: 0.0977\n",
      "Epoch [20/100], Step [24000/6235], Loss: 3.9286\n",
      "Epoch [20/100], Step [24100/6235], Loss: 7.5290\n",
      "Epoch [20/100], Step [24200/6235], Loss: 8.5168\n",
      "Epoch [20/100], Step [24300/6235], Loss: 0.8553\n",
      "Epoch [20/100], Step [24400/6235], Loss: 2.1182\n",
      "Epoch [20/100], Step [24500/6235], Loss: 0.4812\n",
      "Epoch [20/100], Step [24600/6235], Loss: 0.1197\n",
      "Epoch [20/100], Step [24700/6235], Loss: 0.1731\n",
      "Epoch [20/100], Step [24800/6235], Loss: 0.4560\n",
      "Epoch [20/100], Step [24900/6235], Loss: 11.1147\n",
      "Epoch [20/100], Step [25000/6235], Loss: 5.5086\n",
      "Epoch [20/100], Step [25100/6235], Loss: 12.8206\n",
      "Epoch [20/100], Step [25200/6235], Loss: 0.0872\n",
      "Epoch [20/100], Step [25300/6235], Loss: 3.2859\n",
      "Epoch [20/100], Step [25400/6235], Loss: 7.6694\n",
      "Epoch [20/100], Step [25500/6235], Loss: 7.7363\n",
      "Epoch [20/100], Step [25600/6235], Loss: 8.9293\n",
      "Epoch [20/100], Step [25700/6235], Loss: 2.4581\n",
      "Epoch [20/100], Step [25800/6235], Loss: 4.1769\n",
      "Epoch [20/100], Step [25900/6235], Loss: 0.4965\n",
      "Epoch [20/100], Step [26000/6235], Loss: 3.4379\n",
      "Epoch [20/100], Step [26100/6235], Loss: 0.7124\n",
      "Epoch [20/100], Step [26200/6235], Loss: 0.3991\n",
      "Epoch [20/100], Step [26300/6235], Loss: 0.1965\n",
      "Epoch [20/100], Step [26400/6235], Loss: 2.7634\n",
      "Epoch [20/100], Step [26500/6235], Loss: 0.0127\n",
      "Epoch [20/100], Step [26600/6235], Loss: 0.7637\n",
      "Epoch [20/100], Step [26700/6235], Loss: 0.0867\n",
      "Epoch [20/100], Step [26800/6235], Loss: 0.2062\n",
      "Epoch [20/100], Step [26900/6235], Loss: 0.1546\n",
      "Epoch [20/100], Step [27000/6235], Loss: 11.5570\n",
      "Epoch [20/100], Step [27100/6235], Loss: 0.0798\n",
      "Epoch [20/100], Step [27200/6235], Loss: 0.4180\n",
      "Epoch [20/100], Step [27300/6235], Loss: 0.0146\n",
      "Epoch [20/100], Step [27400/6235], Loss: 0.2575\n",
      "Epoch [20/100], Step [27500/6235], Loss: 14.3247\n",
      "Epoch [20/100], Step [27600/6235], Loss: 0.2922\n",
      "Epoch [20/100], Step [27700/6235], Loss: 0.7734\n",
      "Epoch [20/100], Step [27800/6235], Loss: 0.2798\n",
      "Epoch [20/100], Step [27900/6235], Loss: 1.6537\n",
      "Epoch [20/100], Step [28000/6235], Loss: 9.9518\n",
      "Epoch [20/100], Step [28100/6235], Loss: 1.5779\n",
      "Epoch [20/100], Step [28200/6235], Loss: 41.2734\n",
      "Epoch [20/100], Step [28300/6235], Loss: 3.9522\n",
      "Epoch [20/100], Step [28400/6235], Loss: 24.2097\n",
      "Epoch [20/100], Step [28500/6235], Loss: 4.3820\n",
      "Epoch [20/100], Step [28600/6235], Loss: 0.5429\n",
      "Epoch [20/100], Step [28700/6235], Loss: 3.8640\n",
      "Epoch [20/100], Step [28800/6235], Loss: 0.6890\n",
      "Epoch [20/100], Step [28900/6235], Loss: 42.9672\n",
      "Epoch [20/100], Step [29000/6235], Loss: 5.4848\n",
      "Epoch [20/100], Step [29100/6235], Loss: 0.1528\n",
      "Epoch [20/100], Step [29200/6235], Loss: 6.2779\n",
      "Epoch [20/100], Step [29300/6235], Loss: 1.9110\n",
      "Epoch [20/100], Step [29400/6235], Loss: 7.8909\n",
      "Epoch [20/100], Step [29500/6235], Loss: 0.0724\n",
      "Epoch [20/100], Step [29600/6235], Loss: 0.0981\n",
      "Epoch [20/100], Step [29700/6235], Loss: 2.9709\n",
      "Epoch [20/100], Step [29800/6235], Loss: 0.2114\n",
      "Epoch [20/100], Step [29900/6235], Loss: 0.9637\n",
      "Epoch [20/100], Step [30000/6235], Loss: 0.4542\n",
      "Epoch [20/100], Step [30100/6235], Loss: 8.0404\n",
      "Epoch [20/100], Step [30200/6235], Loss: 1.0647\n",
      "Epoch [20/100], Step [30300/6235], Loss: 0.1925\n",
      "Epoch [20/100], Step [30400/6235], Loss: 4.4397\n",
      "Epoch [20/100], Step [30500/6235], Loss: 0.2253\n",
      "Epoch [20/100], Step [30600/6235], Loss: 1.0087\n",
      "Epoch [20/100], Step [30700/6235], Loss: 3.0839\n",
      "Epoch [20/100], Step [30800/6235], Loss: 0.4232\n",
      "Epoch [20/100], Step [30900/6235], Loss: 1.0441\n",
      "Epoch [20/100], Step [31000/6235], Loss: 0.1929\n",
      "Epoch [20/100], Step [31100/6235], Loss: 1.0667\n",
      "Epoch [20/100], Step [31200/6235], Loss: 5.8735\n",
      "Epoch [20/100], Step [31300/6235], Loss: 1.6587\n",
      "Epoch [20/100], Step [31400/6235], Loss: 7.5012\n",
      "Epoch [20/100], Step [31500/6235], Loss: 0.8003\n",
      "Epoch [20/100], Step [31600/6235], Loss: 4.6532\n",
      "Epoch [20/100], Step [31700/6235], Loss: 4.3312\n",
      "Epoch [20/100], Step [31800/6235], Loss: 3.0272\n",
      "Epoch [20/100], Step [31900/6235], Loss: 1533.3685\n",
      "Epoch [20/100], Step [32000/6235], Loss: 56.4188\n",
      "Epoch [20/100], Step [32100/6235], Loss: 1.4980\n",
      "Epoch [20/100], Step [32200/6235], Loss: 153.2334\n",
      "Epoch [20/100], Step [32300/6235], Loss: 0.9809\n",
      "Epoch [20/100], Step [32400/6235], Loss: 1.6481\n",
      "Epoch [20/100], Step [32500/6235], Loss: 9.8163\n",
      "Epoch [20/100], Step [32600/6235], Loss: 0.2712\n",
      "Epoch [20/100], Step [32700/6235], Loss: 89.2865\n",
      "Epoch [20/100], Step [32800/6235], Loss: 1.8035\n",
      "Epoch [20/100], Step [32900/6235], Loss: 6.7058\n",
      "Epoch [20/100], Step [33000/6235], Loss: 0.4337\n",
      "Epoch [20/100], Step [33100/6235], Loss: 1.1868\n",
      "Epoch [20/100], Step [33200/6235], Loss: 1.6086\n",
      "Epoch [20/100], Step [33300/6235], Loss: 11.1015\n",
      "Epoch [20/100], Step [33400/6235], Loss: 101.2568\n",
      "Epoch [20/100], Step [33500/6235], Loss: 2.4873\n",
      "Epoch [20/100], Step [33600/6235], Loss: 1.4805\n",
      "Epoch [20/100], Step [33700/6235], Loss: 0.7421\n",
      "Epoch [20/100], Step [33800/6235], Loss: 4.4702\n",
      "Epoch [20/100], Step [33900/6235], Loss: 27.8340\n",
      "Epoch [20/100], Step [34000/6235], Loss: 0.0368\n",
      "Epoch [20/100], Step [34100/6235], Loss: 0.0166\n",
      "Epoch [20/100], Step [34200/6235], Loss: 1.3919\n",
      "Epoch [20/100], Step [34300/6235], Loss: 5.9005\n",
      "Epoch [20/100], Step [34400/6235], Loss: 1.5902\n",
      "Epoch [20/100], Step [34500/6235], Loss: 135.9492\n",
      "Epoch [20/100], Step [34600/6235], Loss: 1.2620\n",
      "Epoch [20/100], Step [34700/6235], Loss: 0.4507\n",
      "Epoch [20/100], Step [34800/6235], Loss: 13.5599\n",
      "Epoch [20/100], Step [34900/6235], Loss: 68.8354\n",
      "Epoch [20/100], Step [35000/6235], Loss: 0.0527\n",
      "Epoch [20/100], Step [35100/6235], Loss: 1.9055\n",
      "Epoch [20/100], Step [35200/6235], Loss: 2.2488\n",
      "Epoch [20/100], Step [35300/6235], Loss: 1.4642\n",
      "Epoch [20/100], Step [35400/6235], Loss: 0.8253\n",
      "Epoch [20/100], Step [35500/6235], Loss: 2.7550\n",
      "Epoch [20/100], Step [35600/6235], Loss: 4.4742\n",
      "Epoch [20/100], Step [35700/6235], Loss: 4.5255\n",
      "Epoch [20/100], Step [35800/6235], Loss: 0.3554\n",
      "Epoch [20/100], Step [35900/6235], Loss: 0.2043\n",
      "Epoch [20/100], Step [36000/6235], Loss: 2.7832\n",
      "Epoch [20/100], Step [36100/6235], Loss: 0.7294\n",
      "Epoch [20/100], Step [36200/6235], Loss: 19.0290\n",
      "Epoch [20/100], Step [36300/6235], Loss: 0.6158\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [20/100], Step [36400/6235], Loss: 0.4350\n",
      "Epoch [20/100], Step [36500/6235], Loss: 9.7235\n",
      "Epoch [20/100], Step [36600/6235], Loss: 0.0368\n",
      "Epoch [20/100], Step [36700/6235], Loss: 0.2190\n",
      "Epoch [20/100], Step [36800/6235], Loss: 33.4265\n",
      "Epoch [20/100], Step [36900/6235], Loss: 3.3684\n",
      "Epoch [20/100], Step [37000/6235], Loss: 0.2023\n",
      "Epoch [20/100], Step [37100/6235], Loss: 0.0244\n",
      "Epoch [20/100], Step [37200/6235], Loss: 0.0401\n",
      "Epoch [20/100], Step [37300/6235], Loss: 0.4571\n",
      "Epoch [20/100], Step [37400/6235], Loss: 0.2254\n",
      "Epoch [20/100], Step [37500/6235], Loss: 2.9720\n",
      "Epoch [20/100], Step [37600/6235], Loss: 8.2240\n",
      "Epoch [20/100], Step [37700/6235], Loss: 0.7199\n",
      "Epoch [20/100], Step [37800/6235], Loss: 6.0271\n",
      "Epoch [20/100], Step [37900/6235], Loss: 0.1609\n",
      "Epoch [20/100], Step [38000/6235], Loss: 0.3245\n",
      "Epoch [20/100], Step [38100/6235], Loss: 4.7324\n",
      "Epoch [20/100], Step [38200/6235], Loss: 2.1550\n",
      "Epoch [20/100], Step [38300/6235], Loss: 0.8943\n",
      "Epoch [20/100], Step [38400/6235], Loss: 0.0850\n",
      "Epoch [20/100], Step [38500/6235], Loss: 5.1965\n",
      "Epoch [20/100], Step [38600/6235], Loss: 0.1712\n",
      "Epoch [20/100], Step [38700/6235], Loss: 0.1391\n",
      "Epoch [20/100], Step [38800/6235], Loss: 1.0762\n",
      "Epoch [20/100], Step [38900/6235], Loss: 1.4225\n",
      "Epoch [20/100], Step [39000/6235], Loss: 2.5566\n",
      "Epoch [20/100], Step [39100/6235], Loss: 6.0723\n",
      "Epoch [20/100], Step [39200/6235], Loss: 6.3800\n",
      "Epoch [20/100], Step [39300/6235], Loss: 10.7113\n",
      "Epoch [20/100], Step [39400/6235], Loss: 25.3698\n",
      "Epoch [20/100], Step [39500/6235], Loss: 404.5629\n",
      "Epoch [20/100], Step [39600/6235], Loss: 6.7135\n",
      "Epoch [20/100], Step [39700/6235], Loss: 141.4787\n",
      "Epoch [20/100], Step [39800/6235], Loss: 186.8791\n",
      "Epoch [20/100], Step [39900/6235], Loss: 29.3190\n",
      "Epoch [20/100], Step [40000/6235], Loss: 6.6656\n",
      "Epoch [20/100], Step [40100/6235], Loss: 19.7734\n",
      "Epoch [20/100], Step [40200/6235], Loss: 3.5966\n",
      "Epoch [20/100], Step [40300/6235], Loss: 3.4008\n",
      "Epoch [20/100], Step [40400/6235], Loss: 1.4077\n",
      "Epoch [20/100], Step [40500/6235], Loss: 2.8015\n",
      "Epoch [20/100], Step [40600/6235], Loss: 0.2876\n",
      "Epoch [20/100], Step [40700/6235], Loss: 6.7768\n",
      "Epoch [20/100], Step [40800/6235], Loss: 0.5518\n",
      "Epoch [20/100], Step [40900/6235], Loss: 0.5629\n",
      "Epoch [20/100], Step [41000/6235], Loss: 40.6069\n",
      "Epoch [20/100], Step [41100/6235], Loss: 16.9413\n",
      "Epoch [20/100], Step [41200/6235], Loss: 13.2411\n",
      "Epoch [20/100], Step [41300/6235], Loss: 2.6337\n",
      "Epoch [20/100], Step [41400/6235], Loss: 0.5274\n",
      "Epoch [20/100], Step [41500/6235], Loss: 0.6942\n",
      "Epoch [20/100], Step [41600/6235], Loss: 0.0757\n",
      "Epoch [20/100], Step [41700/6235], Loss: 3.3417\n",
      "Epoch [20/100], Step [41800/6235], Loss: 3.6661\n",
      "Epoch [20/100], Step [41900/6235], Loss: 2.3218\n",
      "Epoch [20/100], Step [42000/6235], Loss: 1.9112\n",
      "Epoch [20/100], Step [42100/6235], Loss: 4.6314\n",
      "Epoch [20/100], Step [42200/6235], Loss: 15.2417\n",
      "Epoch [20/100], Step [42300/6235], Loss: 0.5387\n",
      "Epoch [20/100], Step [42400/6235], Loss: 2.0680\n",
      "Epoch [20/100], Step [42500/6235], Loss: 2.9474\n",
      "Epoch [20/100], Step [42600/6235], Loss: 0.4717\n",
      "Epoch [20/100], Step [42700/6235], Loss: 0.2243\n",
      "Epoch [20/100], Step [42800/6235], Loss: 0.1887\n",
      "Epoch [20/100], Step [42900/6235], Loss: 4.0665\n",
      "Epoch [20/100], Step [43000/6235], Loss: 0.1591\n",
      "Epoch [20/100], Step [43100/6235], Loss: 1.6046\n",
      "Epoch [20/100], Step [43200/6235], Loss: 0.5084\n",
      "Epoch [20/100], Step [43300/6235], Loss: 9.9386\n",
      "Epoch [20/100], Step [43400/6235], Loss: 11.5212\n",
      "Epoch [20/100], Step [43500/6235], Loss: 9.3058\n",
      "Epoch [20/100], Step [43600/6235], Loss: 23.5320\n",
      "Epoch [20/100], Step [43700/6235], Loss: 46.8942\n",
      "Epoch [20/100], Step [43800/6235], Loss: 0.9173\n",
      "Epoch [20/100], Step [43900/6235], Loss: 1.3681\n",
      "Epoch [20/100], Step [44000/6235], Loss: 90.3625\n",
      "Epoch [20/100], Step [44100/6235], Loss: 0.5087\n",
      "Epoch [20/100], Step [44200/6235], Loss: 3.1205\n",
      "Epoch [20/100], Step [44300/6235], Loss: 4.1129\n",
      "Epoch [20/100], Step [44400/6235], Loss: 1.0486\n",
      "Epoch [20/100], Step [44500/6235], Loss: 4.0470\n",
      "Epoch [20/100], Step [44600/6235], Loss: 23.1733\n",
      "Epoch [20/100], Step [44700/6235], Loss: 15.1967\n",
      "Epoch [20/100], Step [44800/6235], Loss: 3.8979\n",
      "Epoch [20/100], Step [44900/6235], Loss: 7.5711\n",
      "Epoch [20/100], Step [45000/6235], Loss: 5.1825\n",
      "Epoch [20/100], Step [45100/6235], Loss: 66.6164\n",
      "Epoch [20/100], Step [45200/6235], Loss: 1.0930\n",
      "Epoch [20/100], Step [45300/6235], Loss: 24.5202\n",
      "Epoch [20/100], Step [45400/6235], Loss: 9.3163\n",
      "Epoch [20/100], Step [45500/6235], Loss: 1.9213\n",
      "Epoch [20/100], Step [45600/6235], Loss: 0.6528\n",
      "Epoch [20/100], Step [45700/6235], Loss: 107.1341\n",
      "Epoch [20/100], Step [45800/6235], Loss: 342.9927\n",
      "Epoch [20/100], Step [45900/6235], Loss: 3.2325\n",
      "Epoch [20/100], Step [46000/6235], Loss: 17.9599\n",
      "Epoch [20/100], Step [46100/6235], Loss: 26.8803\n",
      "Epoch [20/100], Step [46200/6235], Loss: 3.8938\n",
      "Epoch [20/100], Step [46300/6235], Loss: 38.5107\n",
      "Epoch [20/100], Step [46400/6235], Loss: 13.2923\n",
      "Epoch [20/100], Step [46500/6235], Loss: 16.5871\n",
      "Epoch [20/100], Step [46600/6235], Loss: 27.4611\n",
      "Epoch [20/100], Step [46700/6235], Loss: 14.8607\n",
      "Epoch [20/100], Step [46800/6235], Loss: 9.2160\n",
      "Epoch [20/100], Step [46900/6235], Loss: 1.2989\n",
      "Epoch [20/100], Step [47000/6235], Loss: 8.1270\n",
      "Epoch [20/100], Step [47100/6235], Loss: 9.1599\n",
      "Epoch [20/100], Step [47200/6235], Loss: 4.6700\n",
      "Epoch [20/100], Step [47300/6235], Loss: 2.0578\n",
      "Epoch [20/100], Step [47400/6235], Loss: 88.4911\n",
      "Epoch [20/100], Step [47500/6235], Loss: 8.9702\n",
      "Epoch [20/100], Step [47600/6235], Loss: 0.6665\n",
      "Epoch [20/100], Step [47700/6235], Loss: 19.7780\n",
      "Epoch [20/100], Step [47800/6235], Loss: 1.1236\n",
      "Epoch [20/100], Step [47900/6235], Loss: 40.8959\n",
      "Epoch [20/100], Step [48000/6235], Loss: 26.9633\n",
      "Epoch [20/100], Step [48100/6235], Loss: 4.1435\n",
      "Epoch [20/100], Step [48200/6235], Loss: 18.2394\n",
      "Epoch [20/100], Step [48300/6235], Loss: 16.4222\n",
      "Epoch [20/100], Step [48400/6235], Loss: 61.2861\n",
      "Epoch [20/100], Step [48500/6235], Loss: 4.4558\n",
      "Epoch [20/100], Step [48600/6235], Loss: 103.8822\n",
      "Epoch [20/100], Step [48700/6235], Loss: 79.7014\n",
      "Epoch [20/100], Step [48800/6235], Loss: 69.9021\n",
      "Epoch [20/100], Step [48900/6235], Loss: 208.5251\n",
      "Epoch [20/100], Step [49000/6235], Loss: 378.8657\n",
      "Epoch [20/100], Step [49100/6235], Loss: 2228.2107\n",
      "Epoch [20/100], Step [49200/6235], Loss: 713.3275\n",
      "Epoch [20/100], Step [49300/6235], Loss: 1062.3263\n",
      "Epoch [20/100], Step [49400/6235], Loss: 13.4106\n",
      "Epoch [20/100], Step [49500/6235], Loss: 55.8847\n",
      "Epoch [20/100], Step [49600/6235], Loss: 1705.6749\n",
      "Epoch [20/100], Step [49700/6235], Loss: 264.2898\n",
      "Epoch [20/100], Step [49800/6235], Loss: 3616.2175\n",
      "Epoch [21/100], Step [100/6235], Loss: 14.5613\n",
      "Epoch [21/100], Step [200/6235], Loss: 0.2500\n",
      "Epoch [21/100], Step [300/6235], Loss: 0.0212\n",
      "Epoch [21/100], Step [400/6235], Loss: 0.0195\n",
      "Epoch [21/100], Step [500/6235], Loss: 1.4008\n",
      "Epoch [21/100], Step [600/6235], Loss: 0.0480\n",
      "Epoch [21/100], Step [700/6235], Loss: 0.5446\n",
      "Epoch [21/100], Step [800/6235], Loss: 0.1027\n",
      "Epoch [21/100], Step [900/6235], Loss: 0.0687\n",
      "Epoch [21/100], Step [1000/6235], Loss: 0.0424\n",
      "Epoch [21/100], Step [1100/6235], Loss: 0.0934\n",
      "Epoch [21/100], Step [1200/6235], Loss: 0.1759\n",
      "Epoch [21/100], Step [1300/6235], Loss: 0.0862\n",
      "Epoch [21/100], Step [1400/6235], Loss: 0.1822\n",
      "Epoch [21/100], Step [1500/6235], Loss: 0.0073\n",
      "Epoch [21/100], Step [1600/6235], Loss: 0.2732\n",
      "Epoch [21/100], Step [1700/6235], Loss: 0.0281\n",
      "Epoch [21/100], Step [1800/6235], Loss: 0.2221\n",
      "Epoch [21/100], Step [1900/6235], Loss: 0.4000\n",
      "Epoch [21/100], Step [2000/6235], Loss: 2.2633\n",
      "Epoch [21/100], Step [2100/6235], Loss: 1.8342\n",
      "Epoch [21/100], Step [2200/6235], Loss: 8.8624\n",
      "Epoch [21/100], Step [2300/6235], Loss: 7.1294\n",
      "Epoch [21/100], Step [2400/6235], Loss: 3.0711\n",
      "Epoch [21/100], Step [2500/6235], Loss: 37.8449\n",
      "Epoch [21/100], Step [2600/6235], Loss: 11.8901\n",
      "Epoch [21/100], Step [2700/6235], Loss: 13.7649\n",
      "Epoch [21/100], Step [2800/6235], Loss: 126.1178\n",
      "Epoch [21/100], Step [2900/6235], Loss: 7.0694\n",
      "Epoch [21/100], Step [3000/6235], Loss: 1.0238\n",
      "Epoch [21/100], Step [3100/6235], Loss: 66.1679\n",
      "Epoch [21/100], Step [3200/6235], Loss: 84.7077\n",
      "Epoch [21/100], Step [3300/6235], Loss: 1.5269\n",
      "Epoch [21/100], Step [3400/6235], Loss: 2.7883\n",
      "Epoch [21/100], Step [3500/6235], Loss: 27.3133\n",
      "Epoch [21/100], Step [3600/6235], Loss: 10.6039\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Step [3700/6235], Loss: 0.9733\n",
      "Epoch [21/100], Step [3800/6235], Loss: 0.5790\n",
      "Epoch [21/100], Step [3900/6235], Loss: 1.6697\n",
      "Epoch [21/100], Step [4000/6235], Loss: 0.0921\n",
      "Epoch [21/100], Step [4100/6235], Loss: 4.4745\n",
      "Epoch [21/100], Step [4200/6235], Loss: 0.4499\n",
      "Epoch [21/100], Step [4300/6235], Loss: 8.8953\n",
      "Epoch [21/100], Step [4400/6235], Loss: 4.0145\n",
      "Epoch [21/100], Step [4500/6235], Loss: 51.7187\n",
      "Epoch [21/100], Step [4600/6235], Loss: 8.1874\n",
      "Epoch [21/100], Step [4700/6235], Loss: 1.2128\n",
      "Epoch [21/100], Step [4800/6235], Loss: 1.6370\n",
      "Epoch [21/100], Step [4900/6235], Loss: 0.1692\n",
      "Epoch [21/100], Step [5000/6235], Loss: 0.2688\n",
      "Epoch [21/100], Step [5100/6235], Loss: 2.2959\n",
      "Epoch [21/100], Step [5200/6235], Loss: 2.3993\n",
      "Epoch [21/100], Step [5300/6235], Loss: 32.7167\n",
      "Epoch [21/100], Step [5400/6235], Loss: 0.0816\n",
      "Epoch [21/100], Step [5500/6235], Loss: 0.2419\n",
      "Epoch [21/100], Step [5600/6235], Loss: 0.4568\n",
      "Epoch [21/100], Step [5700/6235], Loss: 2.0002\n",
      "Epoch [21/100], Step [5800/6235], Loss: 1.0166\n",
      "Epoch [21/100], Step [5900/6235], Loss: 0.2376\n",
      "Epoch [21/100], Step [6000/6235], Loss: 0.1358\n",
      "Epoch [21/100], Step [6100/6235], Loss: 0.1307\n",
      "Epoch [21/100], Step [6200/6235], Loss: 1.6238\n",
      "Epoch [21/100], Step [6300/6235], Loss: 1.0664\n",
      "Epoch [21/100], Step [6400/6235], Loss: 0.0745\n",
      "Epoch [21/100], Step [6500/6235], Loss: 0.9025\n",
      "Epoch [21/100], Step [6600/6235], Loss: 0.8998\n",
      "Epoch [21/100], Step [6700/6235], Loss: 0.6338\n",
      "Epoch [21/100], Step [6800/6235], Loss: 0.7674\n",
      "Epoch [21/100], Step [6900/6235], Loss: 3.4069\n",
      "Epoch [21/100], Step [7000/6235], Loss: 0.4420\n",
      "Epoch [21/100], Step [7100/6235], Loss: 0.1902\n",
      "Epoch [21/100], Step [7200/6235], Loss: 0.3564\n",
      "Epoch [21/100], Step [7300/6235], Loss: 0.1942\n",
      "Epoch [21/100], Step [7400/6235], Loss: 0.0498\n",
      "Epoch [21/100], Step [7500/6235], Loss: 4.0004\n",
      "Epoch [21/100], Step [7600/6235], Loss: 3.4467\n",
      "Epoch [21/100], Step [7700/6235], Loss: 0.7661\n",
      "Epoch [21/100], Step [7800/6235], Loss: 6.0717\n",
      "Epoch [21/100], Step [7900/6235], Loss: 13.7966\n",
      "Epoch [21/100], Step [8000/6235], Loss: 0.7956\n",
      "Epoch [21/100], Step [8100/6235], Loss: 3.2870\n",
      "Epoch [21/100], Step [8200/6235], Loss: 24.7871\n",
      "Epoch [21/100], Step [8300/6235], Loss: 38.6674\n",
      "Epoch [21/100], Step [8400/6235], Loss: 17.5399\n",
      "Epoch [21/100], Step [8500/6235], Loss: 32.3193\n",
      "Epoch [21/100], Step [8600/6235], Loss: 9.4792\n",
      "Epoch [21/100], Step [8700/6235], Loss: 5.0359\n",
      "Epoch [21/100], Step [8800/6235], Loss: 518.6497\n",
      "Epoch [21/100], Step [8900/6235], Loss: 5.2143\n",
      "Epoch [21/100], Step [9000/6235], Loss: 289.5083\n",
      "Epoch [21/100], Step [9100/6235], Loss: 7.9010\n",
      "Epoch [21/100], Step [9200/6235], Loss: 2445.1375\n",
      "Epoch [21/100], Step [9300/6235], Loss: 237.8508\n",
      "Epoch [21/100], Step [9400/6235], Loss: 101.1261\n",
      "Epoch [21/100], Step [9500/6235], Loss: 489.2587\n",
      "Epoch [21/100], Step [9600/6235], Loss: 121.4640\n",
      "Epoch [21/100], Step [9700/6235], Loss: 222.7109\n",
      "Epoch [21/100], Step [9800/6235], Loss: 230.3918\n",
      "Epoch [21/100], Step [9900/6235], Loss: 142.1704\n",
      "Epoch [21/100], Step [10000/6235], Loss: 543.2519\n",
      "Epoch [21/100], Step [10100/6235], Loss: 81.7122\n",
      "Epoch [21/100], Step [10200/6235], Loss: 713.7733\n",
      "Epoch [21/100], Step [10300/6235], Loss: 4.2061\n",
      "Epoch [21/100], Step [10400/6235], Loss: 8.9330\n",
      "Epoch [21/100], Step [10500/6235], Loss: 10.9056\n",
      "Epoch [21/100], Step [10600/6235], Loss: 1768.6178\n",
      "Epoch [21/100], Step [10700/6235], Loss: 131.8479\n",
      "Epoch [21/100], Step [10800/6235], Loss: 31.3955\n",
      "Epoch [21/100], Step [10900/6235], Loss: 5.8041\n",
      "Epoch [21/100], Step [11000/6235], Loss: 61.8568\n",
      "Epoch [21/100], Step [11100/6235], Loss: 1.7386\n",
      "Epoch [21/100], Step [11200/6235], Loss: 127.4620\n",
      "Epoch [21/100], Step [11300/6235], Loss: 226.8791\n",
      "Epoch [21/100], Step [11400/6235], Loss: 296.2701\n",
      "Epoch [21/100], Step [11500/6235], Loss: 14.7301\n",
      "Epoch [21/100], Step [11600/6235], Loss: 1.9138\n",
      "Epoch [21/100], Step [11700/6235], Loss: 172.1618\n",
      "Epoch [21/100], Step [11800/6235], Loss: 32.0919\n",
      "Epoch [21/100], Step [11900/6235], Loss: 688.6169\n",
      "Epoch [21/100], Step [12000/6235], Loss: 113.7768\n",
      "Epoch [21/100], Step [12100/6235], Loss: 478.4597\n",
      "Epoch [21/100], Step [12200/6235], Loss: 101.2065\n",
      "Epoch [21/100], Step [12300/6235], Loss: 43.2559\n",
      "Epoch [21/100], Step [12400/6235], Loss: 144.8225\n",
      "Epoch [21/100], Step [12500/6235], Loss: 210.7679\n",
      "Epoch [21/100], Step [12600/6235], Loss: 48.0378\n",
      "Epoch [21/100], Step [12700/6235], Loss: 14.9561\n",
      "Epoch [21/100], Step [12800/6235], Loss: 8.5658\n",
      "Epoch [21/100], Step [12900/6235], Loss: 51.8910\n",
      "Epoch [21/100], Step [13000/6235], Loss: 1.7753\n",
      "Epoch [21/100], Step [13100/6235], Loss: 116.8088\n",
      "Epoch [21/100], Step [13200/6235], Loss: 46.3043\n",
      "Epoch [21/100], Step [13300/6235], Loss: 1.2325\n",
      "Epoch [21/100], Step [13400/6235], Loss: 1.0628\n",
      "Epoch [21/100], Step [13500/6235], Loss: 1.0232\n",
      "Epoch [21/100], Step [13600/6235], Loss: 29.3817\n",
      "Epoch [21/100], Step [13700/6235], Loss: 184.7114\n",
      "Epoch [21/100], Step [13800/6235], Loss: 134.5907\n",
      "Epoch [21/100], Step [13900/6235], Loss: 20.1789\n",
      "Epoch [21/100], Step [14000/6235], Loss: 0.3546\n",
      "Epoch [21/100], Step [14100/6235], Loss: 312.9172\n",
      "Epoch [21/100], Step [14200/6235], Loss: 21.5450\n",
      "Epoch [21/100], Step [14300/6235], Loss: 15.7482\n",
      "Epoch [21/100], Step [14400/6235], Loss: 0.3813\n",
      "Epoch [21/100], Step [14500/6235], Loss: 6.1739\n",
      "Epoch [21/100], Step [14600/6235], Loss: 3.8556\n",
      "Epoch [21/100], Step [14700/6235], Loss: 10.4959\n",
      "Epoch [21/100], Step [14800/6235], Loss: 10.4442\n",
      "Epoch [21/100], Step [14900/6235], Loss: 0.0774\n",
      "Epoch [21/100], Step [15000/6235], Loss: 0.1163\n",
      "Epoch [21/100], Step [15100/6235], Loss: 0.1782\n",
      "Epoch [21/100], Step [15200/6235], Loss: 32.1834\n",
      "Epoch [21/100], Step [15300/6235], Loss: 21.2157\n",
      "Epoch [21/100], Step [15400/6235], Loss: 0.7205\n",
      "Epoch [21/100], Step [15500/6235], Loss: 35.9167\n",
      "Epoch [21/100], Step [15600/6235], Loss: 16.3120\n",
      "Epoch [21/100], Step [15700/6235], Loss: 9.0538\n",
      "Epoch [21/100], Step [15800/6235], Loss: 0.2891\n",
      "Epoch [21/100], Step [15900/6235], Loss: 3.3661\n",
      "Epoch [21/100], Step [16000/6235], Loss: 19.7339\n",
      "Epoch [21/100], Step [16100/6235], Loss: 1.8275\n",
      "Epoch [21/100], Step [16200/6235], Loss: 4.5718\n",
      "Epoch [21/100], Step [16300/6235], Loss: 40.0888\n",
      "Epoch [21/100], Step [16400/6235], Loss: 80.0967\n",
      "Epoch [21/100], Step [16500/6235], Loss: 619.3159\n",
      "Epoch [21/100], Step [16600/6235], Loss: 14.5474\n",
      "Epoch [21/100], Step [16700/6235], Loss: 3.0252\n",
      "Epoch [21/100], Step [16800/6235], Loss: 1.7958\n",
      "Epoch [21/100], Step [16900/6235], Loss: 9.7352\n",
      "Epoch [21/100], Step [17000/6235], Loss: 1.9186\n",
      "Epoch [21/100], Step [17100/6235], Loss: 0.0472\n",
      "Epoch [21/100], Step [17200/6235], Loss: 55.3438\n",
      "Epoch [21/100], Step [17300/6235], Loss: 20.7477\n",
      "Epoch [21/100], Step [17400/6235], Loss: 37.1164\n",
      "Epoch [21/100], Step [17500/6235], Loss: 1.5166\n",
      "Epoch [21/100], Step [17600/6235], Loss: 0.5123\n",
      "Epoch [21/100], Step [17700/6235], Loss: 6.2621\n",
      "Epoch [21/100], Step [17800/6235], Loss: 12.6624\n",
      "Epoch [21/100], Step [17900/6235], Loss: 5.4192\n",
      "Epoch [21/100], Step [18000/6235], Loss: 5.6834\n",
      "Epoch [21/100], Step [18100/6235], Loss: 10.4615\n",
      "Epoch [21/100], Step [18200/6235], Loss: 18.5468\n",
      "Epoch [21/100], Step [18300/6235], Loss: 6.0872\n",
      "Epoch [21/100], Step [18400/6235], Loss: 9.6421\n",
      "Epoch [21/100], Step [18500/6235], Loss: 10.3007\n",
      "Epoch [21/100], Step [18600/6235], Loss: 4.8072\n",
      "Epoch [21/100], Step [18700/6235], Loss: 0.2345\n",
      "Epoch [21/100], Step [18800/6235], Loss: 48.0103\n",
      "Epoch [21/100], Step [18900/6235], Loss: 2.5080\n",
      "Epoch [21/100], Step [19000/6235], Loss: 33.5714\n",
      "Epoch [21/100], Step [19100/6235], Loss: 8.7138\n",
      "Epoch [21/100], Step [19200/6235], Loss: 4.5576\n",
      "Epoch [21/100], Step [19300/6235], Loss: 4.8248\n",
      "Epoch [21/100], Step [19400/6235], Loss: 297.6157\n",
      "Epoch [21/100], Step [19500/6235], Loss: 42.4937\n",
      "Epoch [21/100], Step [19600/6235], Loss: 116.7422\n",
      "Epoch [21/100], Step [19700/6235], Loss: 30.5970\n",
      "Epoch [21/100], Step [19800/6235], Loss: 6.0935\n",
      "Epoch [21/100], Step [19900/6235], Loss: 1.2345\n",
      "Epoch [21/100], Step [20000/6235], Loss: 85.0598\n",
      "Epoch [21/100], Step [20100/6235], Loss: 8.1874\n",
      "Epoch [21/100], Step [20200/6235], Loss: 1.6615\n",
      "Epoch [21/100], Step [20300/6235], Loss: 5.0070\n",
      "Epoch [21/100], Step [20400/6235], Loss: 22.0812\n",
      "Epoch [21/100], Step [20500/6235], Loss: 31.9150\n",
      "Epoch [21/100], Step [20600/6235], Loss: 21.9867\n",
      "Epoch [21/100], Step [20700/6235], Loss: 1.0852\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Step [20800/6235], Loss: 10.5890\n",
      "Epoch [21/100], Step [20900/6235], Loss: 22.9611\n",
      "Epoch [21/100], Step [21000/6235], Loss: 22.9193\n",
      "Epoch [21/100], Step [21100/6235], Loss: 8.1344\n",
      "Epoch [21/100], Step [21200/6235], Loss: 0.1908\n",
      "Epoch [21/100], Step [21300/6235], Loss: 0.1112\n",
      "Epoch [21/100], Step [21400/6235], Loss: 6.4456\n",
      "Epoch [21/100], Step [21500/6235], Loss: 0.2030\n",
      "Epoch [21/100], Step [21600/6235], Loss: 23.5589\n",
      "Epoch [21/100], Step [21700/6235], Loss: 0.2391\n",
      "Epoch [21/100], Step [21800/6235], Loss: 21.4035\n",
      "Epoch [21/100], Step [21900/6235], Loss: 0.5735\n",
      "Epoch [21/100], Step [22000/6235], Loss: 10.0539\n",
      "Epoch [21/100], Step [22100/6235], Loss: 0.2340\n",
      "Epoch [21/100], Step [22200/6235], Loss: 2.9834\n",
      "Epoch [21/100], Step [22300/6235], Loss: 3.4521\n",
      "Epoch [21/100], Step [22400/6235], Loss: 3.5847\n",
      "Epoch [21/100], Step [22500/6235], Loss: 147.6993\n",
      "Epoch [21/100], Step [22600/6235], Loss: 14.7969\n",
      "Epoch [21/100], Step [22700/6235], Loss: 0.9362\n",
      "Epoch [21/100], Step [22800/6235], Loss: 6.5526\n",
      "Epoch [21/100], Step [22900/6235], Loss: 3.4667\n",
      "Epoch [21/100], Step [23000/6235], Loss: 14.7969\n",
      "Epoch [21/100], Step [23100/6235], Loss: 7.4914\n",
      "Epoch [21/100], Step [23200/6235], Loss: 25.5105\n",
      "Epoch [21/100], Step [23300/6235], Loss: 13.3380\n",
      "Epoch [21/100], Step [23400/6235], Loss: 2.6635\n",
      "Epoch [21/100], Step [23500/6235], Loss: 0.1000\n",
      "Epoch [21/100], Step [23600/6235], Loss: 107.4022\n",
      "Epoch [21/100], Step [23700/6235], Loss: 8.7900\n",
      "Epoch [21/100], Step [23800/6235], Loss: 0.7980\n",
      "Epoch [21/100], Step [23900/6235], Loss: 2.0372\n",
      "Epoch [21/100], Step [24000/6235], Loss: 10.5027\n",
      "Epoch [21/100], Step [24100/6235], Loss: 2.9317\n",
      "Epoch [21/100], Step [24200/6235], Loss: 27.4207\n",
      "Epoch [21/100], Step [24300/6235], Loss: 0.7882\n",
      "Epoch [21/100], Step [24400/6235], Loss: 5.0882\n",
      "Epoch [21/100], Step [24500/6235], Loss: 0.8729\n",
      "Epoch [21/100], Step [24600/6235], Loss: 2.7507\n",
      "Epoch [21/100], Step [24700/6235], Loss: 0.0861\n",
      "Epoch [21/100], Step [24800/6235], Loss: 2.5016\n",
      "Epoch [21/100], Step [24900/6235], Loss: 10.4380\n",
      "Epoch [21/100], Step [25000/6235], Loss: 8.3797\n",
      "Epoch [21/100], Step [25100/6235], Loss: 10.5724\n",
      "Epoch [21/100], Step [25200/6235], Loss: 1.3378\n",
      "Epoch [21/100], Step [25300/6235], Loss: 1.7012\n",
      "Epoch [21/100], Step [25400/6235], Loss: 6.0106\n",
      "Epoch [21/100], Step [25500/6235], Loss: 6.8847\n",
      "Epoch [21/100], Step [25600/6235], Loss: 8.7532\n",
      "Epoch [21/100], Step [25700/6235], Loss: 3.9656\n",
      "Epoch [21/100], Step [25800/6235], Loss: 0.2872\n",
      "Epoch [21/100], Step [25900/6235], Loss: 0.3191\n",
      "Epoch [21/100], Step [26000/6235], Loss: 0.1516\n",
      "Epoch [21/100], Step [26100/6235], Loss: 0.2524\n",
      "Epoch [21/100], Step [26200/6235], Loss: 1.3746\n",
      "Epoch [21/100], Step [26300/6235], Loss: 1.9605\n",
      "Epoch [21/100], Step [26400/6235], Loss: 4.3764\n",
      "Epoch [21/100], Step [26500/6235], Loss: 0.0982\n",
      "Epoch [21/100], Step [26600/6235], Loss: 1.9704\n",
      "Epoch [21/100], Step [26700/6235], Loss: 0.1532\n",
      "Epoch [21/100], Step [26800/6235], Loss: 0.3008\n",
      "Epoch [21/100], Step [26900/6235], Loss: 0.0142\n",
      "Epoch [21/100], Step [27000/6235], Loss: 9.5342\n",
      "Epoch [21/100], Step [27100/6235], Loss: 0.0653\n",
      "Epoch [21/100], Step [27200/6235], Loss: 0.4759\n",
      "Epoch [21/100], Step [27300/6235], Loss: 0.0114\n",
      "Epoch [21/100], Step [27400/6235], Loss: 0.1843\n",
      "Epoch [21/100], Step [27500/6235], Loss: 0.4628\n",
      "Epoch [21/100], Step [27600/6235], Loss: 0.5904\n",
      "Epoch [21/100], Step [27700/6235], Loss: 0.4912\n",
      "Epoch [21/100], Step [27800/6235], Loss: 0.1934\n",
      "Epoch [21/100], Step [27900/6235], Loss: 0.3964\n",
      "Epoch [21/100], Step [28000/6235], Loss: 1.7501\n",
      "Epoch [21/100], Step [28100/6235], Loss: 9.3032\n",
      "Epoch [21/100], Step [28200/6235], Loss: 18.0653\n",
      "Epoch [21/100], Step [28300/6235], Loss: 1.6095\n",
      "Epoch [21/100], Step [28400/6235], Loss: 22.3328\n",
      "Epoch [21/100], Step [28500/6235], Loss: 4.2860\n",
      "Epoch [21/100], Step [28600/6235], Loss: 0.6252\n",
      "Epoch [21/100], Step [28700/6235], Loss: 3.1848\n",
      "Epoch [21/100], Step [28800/6235], Loss: 0.7071\n",
      "Epoch [21/100], Step [28900/6235], Loss: 36.4088\n",
      "Epoch [21/100], Step [29000/6235], Loss: 0.0297\n",
      "Epoch [21/100], Step [29100/6235], Loss: 0.1445\n",
      "Epoch [21/100], Step [29200/6235], Loss: 5.6630\n",
      "Epoch [21/100], Step [29300/6235], Loss: 2.5938\n",
      "Epoch [21/100], Step [29400/6235], Loss: 0.7066\n",
      "Epoch [21/100], Step [29500/6235], Loss: 3.5699\n",
      "Epoch [21/100], Step [29600/6235], Loss: 0.1028\n",
      "Epoch [21/100], Step [29700/6235], Loss: 2.5712\n",
      "Epoch [21/100], Step [29800/6235], Loss: 0.2020\n",
      "Epoch [21/100], Step [29900/6235], Loss: 1.0391\n",
      "Epoch [21/100], Step [30000/6235], Loss: 0.4836\n",
      "Epoch [21/100], Step [30100/6235], Loss: 11.2238\n",
      "Epoch [21/100], Step [30200/6235], Loss: 0.3569\n",
      "Epoch [21/100], Step [30300/6235], Loss: 0.4517\n",
      "Epoch [21/100], Step [30400/6235], Loss: 5.5502\n",
      "Epoch [21/100], Step [30500/6235], Loss: 0.2940\n",
      "Epoch [21/100], Step [30600/6235], Loss: 0.6507\n",
      "Epoch [21/100], Step [30700/6235], Loss: 2.7873\n",
      "Epoch [21/100], Step [30800/6235], Loss: 0.3490\n",
      "Epoch [21/100], Step [30900/6235], Loss: 0.6688\n",
      "Epoch [21/100], Step [31000/6235], Loss: 0.0136\n",
      "Epoch [21/100], Step [31100/6235], Loss: 2.3271\n",
      "Epoch [21/100], Step [31200/6235], Loss: 7.2736\n",
      "Epoch [21/100], Step [31300/6235], Loss: 1.6684\n",
      "Epoch [21/100], Step [31400/6235], Loss: 3.3641\n",
      "Epoch [21/100], Step [31500/6235], Loss: 1.7507\n",
      "Epoch [21/100], Step [31600/6235], Loss: 0.8771\n",
      "Epoch [21/100], Step [31700/6235], Loss: 3.5832\n",
      "Epoch [21/100], Step [31800/6235], Loss: 1.1305\n",
      "Epoch [21/100], Step [31900/6235], Loss: 196.4755\n",
      "Epoch [21/100], Step [32000/6235], Loss: 37.0018\n",
      "Epoch [21/100], Step [32100/6235], Loss: 3.3886\n",
      "Epoch [21/100], Step [32200/6235], Loss: 64.8795\n",
      "Epoch [21/100], Step [32300/6235], Loss: 1.2474\n",
      "Epoch [21/100], Step [32400/6235], Loss: 1.2658\n",
      "Epoch [21/100], Step [32500/6235], Loss: 6.6324\n",
      "Epoch [21/100], Step [32600/6235], Loss: 0.1400\n",
      "Epoch [21/100], Step [32700/6235], Loss: 98.2757\n",
      "Epoch [21/100], Step [32800/6235], Loss: 8.6193\n",
      "Epoch [21/100], Step [32900/6235], Loss: 6.9686\n",
      "Epoch [21/100], Step [33000/6235], Loss: 0.4713\n",
      "Epoch [21/100], Step [33100/6235], Loss: 1.3752\n",
      "Epoch [21/100], Step [33200/6235], Loss: 2.4135\n",
      "Epoch [21/100], Step [33300/6235], Loss: 5.7431\n",
      "Epoch [21/100], Step [33400/6235], Loss: 119.8906\n",
      "Epoch [21/100], Step [33500/6235], Loss: 2.2626\n",
      "Epoch [21/100], Step [33600/6235], Loss: 3.5195\n",
      "Epoch [21/100], Step [33700/6235], Loss: 0.4751\n",
      "Epoch [21/100], Step [33800/6235], Loss: 4.2209\n",
      "Epoch [21/100], Step [33900/6235], Loss: 26.3562\n",
      "Epoch [21/100], Step [34000/6235], Loss: 0.0057\n",
      "Epoch [21/100], Step [34100/6235], Loss: 0.0374\n",
      "Epoch [21/100], Step [34200/6235], Loss: 13.5075\n",
      "Epoch [21/100], Step [34300/6235], Loss: 3.6635\n",
      "Epoch [21/100], Step [34400/6235], Loss: 1.3142\n",
      "Epoch [21/100], Step [34500/6235], Loss: 107.1258\n",
      "Epoch [21/100], Step [34600/6235], Loss: 1.0939\n",
      "Epoch [21/100], Step [34700/6235], Loss: 8.0349\n",
      "Epoch [21/100], Step [34800/6235], Loss: 10.5628\n",
      "Epoch [21/100], Step [34900/6235], Loss: 69.5865\n",
      "Epoch [21/100], Step [35000/6235], Loss: 0.2326\n",
      "Epoch [21/100], Step [35100/6235], Loss: 0.5242\n",
      "Epoch [21/100], Step [35200/6235], Loss: 6.7951\n",
      "Epoch [21/100], Step [35300/6235], Loss: 2.0375\n",
      "Epoch [21/100], Step [35400/6235], Loss: 0.6767\n",
      "Epoch [21/100], Step [35500/6235], Loss: 2.9269\n",
      "Epoch [21/100], Step [35600/6235], Loss: 6.0730\n",
      "Epoch [21/100], Step [35700/6235], Loss: 4.7852\n",
      "Epoch [21/100], Step [35800/6235], Loss: 1.2396\n",
      "Epoch [21/100], Step [35900/6235], Loss: 0.6398\n",
      "Epoch [21/100], Step [36000/6235], Loss: 2.5217\n",
      "Epoch [21/100], Step [36100/6235], Loss: 0.3945\n",
      "Epoch [21/100], Step [36200/6235], Loss: 2.1790\n",
      "Epoch [21/100], Step [36300/6235], Loss: 0.1240\n",
      "Epoch [21/100], Step [36400/6235], Loss: 0.8782\n",
      "Epoch [21/100], Step [36500/6235], Loss: 9.4316\n",
      "Epoch [21/100], Step [36600/6235], Loss: 0.0994\n",
      "Epoch [21/100], Step [36700/6235], Loss: 0.0668\n",
      "Epoch [21/100], Step [36800/6235], Loss: 27.3653\n",
      "Epoch [21/100], Step [36900/6235], Loss: 3.2479\n",
      "Epoch [21/100], Step [37000/6235], Loss: 0.0178\n",
      "Epoch [21/100], Step [37100/6235], Loss: 0.1261\n",
      "Epoch [21/100], Step [37200/6235], Loss: 0.0399\n",
      "Epoch [21/100], Step [37300/6235], Loss: 0.2287\n",
      "Epoch [21/100], Step [37400/6235], Loss: 0.1981\n",
      "Epoch [21/100], Step [37500/6235], Loss: 2.8903\n",
      "Epoch [21/100], Step [37600/6235], Loss: 9.1824\n",
      "Epoch [21/100], Step [37700/6235], Loss: 0.6987\n",
      "Epoch [21/100], Step [37800/6235], Loss: 1.7847\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [21/100], Step [37900/6235], Loss: 2.5036\n",
      "Epoch [21/100], Step [38000/6235], Loss: 0.2650\n",
      "Epoch [21/100], Step [38100/6235], Loss: 4.4370\n",
      "Epoch [21/100], Step [38200/6235], Loss: 1.0552\n",
      "Epoch [21/100], Step [38300/6235], Loss: 2.0214\n",
      "Epoch [21/100], Step [38400/6235], Loss: 0.1221\n",
      "Epoch [21/100], Step [38500/6235], Loss: 5.5181\n",
      "Epoch [21/100], Step [38600/6235], Loss: 5.4952\n",
      "Epoch [21/100], Step [38700/6235], Loss: 0.1364\n",
      "Epoch [21/100], Step [38800/6235], Loss: 1.0421\n",
      "Epoch [21/100], Step [38900/6235], Loss: 3.2931\n",
      "Epoch [21/100], Step [39000/6235], Loss: 15.2802\n",
      "Epoch [21/100], Step [39100/6235], Loss: 23.0143\n",
      "Epoch [21/100], Step [39200/6235], Loss: 0.6866\n",
      "Epoch [21/100], Step [39300/6235], Loss: 6.2487\n",
      "Epoch [21/100], Step [39400/6235], Loss: 67.7458\n",
      "Epoch [21/100], Step [39500/6235], Loss: 4.4627\n",
      "Epoch [21/100], Step [39600/6235], Loss: 5.4382\n",
      "Epoch [21/100], Step [39700/6235], Loss: 201.9341\n",
      "Epoch [21/100], Step [39800/6235], Loss: 30.3951\n",
      "Epoch [21/100], Step [39900/6235], Loss: 0.3857\n",
      "Epoch [21/100], Step [40000/6235], Loss: 5.8748\n",
      "Epoch [21/100], Step [40100/6235], Loss: 29.8858\n",
      "Epoch [21/100], Step [40200/6235], Loss: 1.4538\n",
      "Epoch [21/100], Step [40300/6235], Loss: 0.5322\n",
      "Epoch [21/100], Step [40400/6235], Loss: 2.2844\n",
      "Epoch [21/100], Step [40500/6235], Loss: 2.4103\n",
      "Epoch [21/100], Step [40600/6235], Loss: 0.2228\n",
      "Epoch [21/100], Step [40700/6235], Loss: 7.7785\n",
      "Epoch [21/100], Step [40800/6235], Loss: 1.7462\n",
      "Epoch [21/100], Step [40900/6235], Loss: 0.0629\n",
      "Epoch [21/100], Step [41000/6235], Loss: 27.8874\n",
      "Epoch [21/100], Step [41100/6235], Loss: 13.8586\n",
      "Epoch [21/100], Step [41200/6235], Loss: 19.4515\n",
      "Epoch [21/100], Step [41300/6235], Loss: 0.2835\n",
      "Epoch [21/100], Step [41400/6235], Loss: 1.0795\n",
      "Epoch [21/100], Step [41500/6235], Loss: 4.2018\n",
      "Epoch [21/100], Step [41600/6235], Loss: 0.0370\n",
      "Epoch [21/100], Step [41700/6235], Loss: 0.0740\n",
      "Epoch [21/100], Step [41800/6235], Loss: 0.9682\n",
      "Epoch [21/100], Step [41900/6235], Loss: 4.9558\n",
      "Epoch [21/100], Step [42000/6235], Loss: 3.0042\n",
      "Epoch [21/100], Step [42100/6235], Loss: 8.1854\n",
      "Epoch [21/100], Step [42200/6235], Loss: 77.4771\n",
      "Epoch [21/100], Step [42300/6235], Loss: 1.7595\n",
      "Epoch [21/100], Step [42400/6235], Loss: 2.8160\n",
      "Epoch [21/100], Step [42500/6235], Loss: 2.2325\n",
      "Epoch [21/100], Step [42600/6235], Loss: 0.7628\n",
      "Epoch [21/100], Step [42700/6235], Loss: 0.4204\n",
      "Epoch [21/100], Step [42800/6235], Loss: 0.2720\n",
      "Epoch [21/100], Step [42900/6235], Loss: 4.0663\n",
      "Epoch [21/100], Step [43000/6235], Loss: 0.1794\n",
      "Epoch [21/100], Step [43100/6235], Loss: 1.1722\n",
      "Epoch [21/100], Step [43200/6235], Loss: 0.6516\n",
      "Epoch [21/100], Step [43300/6235], Loss: 9.4599\n",
      "Epoch [21/100], Step [43400/6235], Loss: 12.0272\n",
      "Epoch [21/100], Step [43500/6235], Loss: 9.3403\n",
      "Epoch [21/100], Step [43600/6235], Loss: 19.1979\n",
      "Epoch [21/100], Step [43700/6235], Loss: 42.1454\n",
      "Epoch [21/100], Step [43800/6235], Loss: 0.7699\n",
      "Epoch [21/100], Step [43900/6235], Loss: 3.1202\n",
      "Epoch [21/100], Step [44000/6235], Loss: 50.1128\n",
      "Epoch [21/100], Step [44100/6235], Loss: 1.5000\n",
      "Epoch [21/100], Step [44200/6235], Loss: 2.7030\n",
      "Epoch [21/100], Step [44300/6235], Loss: 4.4979\n",
      "Epoch [21/100], Step [44400/6235], Loss: 0.9524\n",
      "Epoch [21/100], Step [44500/6235], Loss: 1.5745\n",
      "Epoch [21/100], Step [44600/6235], Loss: 20.1349\n",
      "Epoch [21/100], Step [44700/6235], Loss: 32.8843\n",
      "Epoch [21/100], Step [44800/6235], Loss: 2.4560\n",
      "Epoch [21/100], Step [44900/6235], Loss: 8.9126\n",
      "Epoch [21/100], Step [45000/6235], Loss: 5.3651\n",
      "Epoch [21/100], Step [45100/6235], Loss: 42.1539\n",
      "Epoch [21/100], Step [45200/6235], Loss: 1.2747\n",
      "Epoch [21/100], Step [45300/6235], Loss: 24.5285\n",
      "Epoch [21/100], Step [45400/6235], Loss: 8.5909\n",
      "Epoch [21/100], Step [45500/6235], Loss: 2.1680\n",
      "Epoch [21/100], Step [45600/6235], Loss: 0.6896\n",
      "Epoch [21/100], Step [45700/6235], Loss: 115.8086\n",
      "Epoch [21/100], Step [45800/6235], Loss: 307.2653\n",
      "Epoch [21/100], Step [45900/6235], Loss: 5.1221\n",
      "Epoch [21/100], Step [46000/6235], Loss: 18.4159\n",
      "Epoch [21/100], Step [46100/6235], Loss: 7.4084\n",
      "Epoch [21/100], Step [46200/6235], Loss: 53.6186\n",
      "Epoch [21/100], Step [46300/6235], Loss: 31.9312\n",
      "Epoch [21/100], Step [46400/6235], Loss: 8.2379\n",
      "Epoch [21/100], Step [46500/6235], Loss: 25.7652\n",
      "Epoch [21/100], Step [46600/6235], Loss: 28.4969\n",
      "Epoch [21/100], Step [46700/6235], Loss: 4.5426\n",
      "Epoch [21/100], Step [46800/6235], Loss: 3.7067\n",
      "Epoch [21/100], Step [46900/6235], Loss: 4.1688\n",
      "Epoch [21/100], Step [47000/6235], Loss: 5.8674\n",
      "Epoch [21/100], Step [47100/6235], Loss: 1.3168\n",
      "Epoch [21/100], Step [47200/6235], Loss: 4.7564\n",
      "Epoch [21/100], Step [47300/6235], Loss: 0.8383\n",
      "Epoch [21/100], Step [47400/6235], Loss: 65.8866\n",
      "Epoch [21/100], Step [47500/6235], Loss: 0.4635\n",
      "Epoch [21/100], Step [47600/6235], Loss: 0.9009\n",
      "Epoch [21/100], Step [47700/6235], Loss: 5.9797\n",
      "Epoch [21/100], Step [47800/6235], Loss: 0.5664\n",
      "Epoch [21/100], Step [47900/6235], Loss: 27.1573\n",
      "Epoch [21/100], Step [48000/6235], Loss: 138.3946\n",
      "Epoch [21/100], Step [48100/6235], Loss: 3.9636\n",
      "Epoch [21/100], Step [48200/6235], Loss: 8.4183\n",
      "Epoch [21/100], Step [48300/6235], Loss: 72.3415\n",
      "Epoch [21/100], Step [48400/6235], Loss: 59.6782\n",
      "Epoch [21/100], Step [48500/6235], Loss: 5.8152\n",
      "Epoch [21/100], Step [48600/6235], Loss: 138.3292\n",
      "Epoch [21/100], Step [48700/6235], Loss: 99.6289\n",
      "Epoch [21/100], Step [48800/6235], Loss: 64.7268\n",
      "Epoch [21/100], Step [48900/6235], Loss: 277.1419\n",
      "Epoch [21/100], Step [49000/6235], Loss: 262.7244\n",
      "Epoch [21/100], Step [49100/6235], Loss: 1322.9189\n",
      "Epoch [21/100], Step [49200/6235], Loss: 550.3322\n",
      "Epoch [21/100], Step [49300/6235], Loss: 1203.5082\n",
      "Epoch [21/100], Step [49400/6235], Loss: 2.3481\n",
      "Epoch [21/100], Step [49500/6235], Loss: 50.7058\n",
      "Epoch [21/100], Step [49600/6235], Loss: 17.4938\n",
      "Epoch [21/100], Step [49700/6235], Loss: 10449.7627\n",
      "Epoch [21/100], Step [49800/6235], Loss: 691.2390\n",
      "Epoch [22/100], Step [100/6235], Loss: 53.9825\n",
      "Epoch [22/100], Step [200/6235], Loss: 0.1340\n",
      "Epoch [22/100], Step [300/6235], Loss: 0.0201\n",
      "Epoch [22/100], Step [400/6235], Loss: 0.0047\n",
      "Epoch [22/100], Step [500/6235], Loss: 0.8132\n",
      "Epoch [22/100], Step [600/6235], Loss: 0.0449\n",
      "Epoch [22/100], Step [700/6235], Loss: 0.2463\n",
      "Epoch [22/100], Step [800/6235], Loss: 0.0490\n",
      "Epoch [22/100], Step [900/6235], Loss: 0.0712\n",
      "Epoch [22/100], Step [1000/6235], Loss: 0.0245\n",
      "Epoch [22/100], Step [1100/6235], Loss: 0.0859\n",
      "Epoch [22/100], Step [1200/6235], Loss: 0.1314\n",
      "Epoch [22/100], Step [1300/6235], Loss: 0.0741\n",
      "Epoch [22/100], Step [1400/6235], Loss: 0.1442\n",
      "Epoch [22/100], Step [1500/6235], Loss: 0.0033\n",
      "Epoch [22/100], Step [1600/6235], Loss: 0.2101\n",
      "Epoch [22/100], Step [1700/6235], Loss: 0.0516\n",
      "Epoch [22/100], Step [1800/6235], Loss: 0.2613\n",
      "Epoch [22/100], Step [1900/6235], Loss: 0.8466\n",
      "Epoch [22/100], Step [2000/6235], Loss: 1.8042\n",
      "Epoch [22/100], Step [2100/6235], Loss: 3.3803\n",
      "Epoch [22/100], Step [2200/6235], Loss: 11.4939\n",
      "Epoch [22/100], Step [2300/6235], Loss: 27.5027\n",
      "Epoch [22/100], Step [2400/6235], Loss: 17.1379\n",
      "Epoch [22/100], Step [2500/6235], Loss: 26.2754\n",
      "Epoch [22/100], Step [2600/6235], Loss: 5.9924\n",
      "Epoch [22/100], Step [2700/6235], Loss: 48.7133\n",
      "Epoch [22/100], Step [2800/6235], Loss: 308.5283\n",
      "Epoch [22/100], Step [2900/6235], Loss: 7.1986\n",
      "Epoch [22/100], Step [3000/6235], Loss: 0.4745\n",
      "Epoch [22/100], Step [3100/6235], Loss: 39.9371\n",
      "Epoch [22/100], Step [3200/6235], Loss: 49.4573\n",
      "Epoch [22/100], Step [3300/6235], Loss: 0.5134\n",
      "Epoch [22/100], Step [3400/6235], Loss: 1.9271\n",
      "Epoch [22/100], Step [3500/6235], Loss: 35.7600\n",
      "Epoch [22/100], Step [3600/6235], Loss: 12.5834\n",
      "Epoch [22/100], Step [3700/6235], Loss: 1.9586\n",
      "Epoch [22/100], Step [3800/6235], Loss: 0.4032\n",
      "Epoch [22/100], Step [3900/6235], Loss: 1.1904\n",
      "Epoch [22/100], Step [4000/6235], Loss: 0.1610\n",
      "Epoch [22/100], Step [4100/6235], Loss: 1.7369\n",
      "Epoch [22/100], Step [4200/6235], Loss: 0.5793\n",
      "Epoch [22/100], Step [4300/6235], Loss: 9.8041\n",
      "Epoch [22/100], Step [4400/6235], Loss: 0.3023\n",
      "Epoch [22/100], Step [4500/6235], Loss: 67.4523\n",
      "Epoch [22/100], Step [4600/6235], Loss: 19.6714\n",
      "Epoch [22/100], Step [4700/6235], Loss: 2.4238\n",
      "Epoch [22/100], Step [4800/6235], Loss: 3.4122\n",
      "Epoch [22/100], Step [4900/6235], Loss: 0.0517\n",
      "Epoch [22/100], Step [5000/6235], Loss: 1.3174\n",
      "Epoch [22/100], Step [5100/6235], Loss: 5.3248\n",
      "Epoch [22/100], Step [5200/6235], Loss: 4.7836\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Step [5300/6235], Loss: 35.3302\n",
      "Epoch [22/100], Step [5400/6235], Loss: 1.3249\n",
      "Epoch [22/100], Step [5500/6235], Loss: 0.6008\n",
      "Epoch [22/100], Step [5600/6235], Loss: 0.6291\n",
      "Epoch [22/100], Step [5700/6235], Loss: 0.9819\n",
      "Epoch [22/100], Step [5800/6235], Loss: 1.0294\n",
      "Epoch [22/100], Step [5900/6235], Loss: 2.1366\n",
      "Epoch [22/100], Step [6000/6235], Loss: 0.9577\n",
      "Epoch [22/100], Step [6100/6235], Loss: 0.1535\n",
      "Epoch [22/100], Step [6200/6235], Loss: 0.9294\n",
      "Epoch [22/100], Step [6300/6235], Loss: 0.3068\n",
      "Epoch [22/100], Step [6400/6235], Loss: 0.1354\n",
      "Epoch [22/100], Step [6500/6235], Loss: 1.1823\n",
      "Epoch [22/100], Step [6600/6235], Loss: 7.6295\n",
      "Epoch [22/100], Step [6700/6235], Loss: 0.6675\n",
      "Epoch [22/100], Step [6800/6235], Loss: 2.2327\n",
      "Epoch [22/100], Step [6900/6235], Loss: 1.0915\n",
      "Epoch [22/100], Step [7000/6235], Loss: 0.0232\n",
      "Epoch [22/100], Step [7100/6235], Loss: 2.1129\n",
      "Epoch [22/100], Step [7200/6235], Loss: 0.5088\n",
      "Epoch [22/100], Step [7300/6235], Loss: 1.2858\n",
      "Epoch [22/100], Step [7400/6235], Loss: 0.3556\n",
      "Epoch [22/100], Step [7500/6235], Loss: 28.7214\n",
      "Epoch [22/100], Step [7600/6235], Loss: 4.8675\n",
      "Epoch [22/100], Step [7700/6235], Loss: 7.0018\n",
      "Epoch [22/100], Step [7800/6235], Loss: 1.6251\n",
      "Epoch [22/100], Step [7900/6235], Loss: 3.8539\n",
      "Epoch [22/100], Step [8000/6235], Loss: 1.4757\n",
      "Epoch [22/100], Step [8100/6235], Loss: 2.4605\n",
      "Epoch [22/100], Step [8200/6235], Loss: 25.6340\n",
      "Epoch [22/100], Step [8300/6235], Loss: 30.6739\n",
      "Epoch [22/100], Step [8400/6235], Loss: 18.9538\n",
      "Epoch [22/100], Step [8500/6235], Loss: 23.1524\n",
      "Epoch [22/100], Step [8600/6235], Loss: 10.6601\n",
      "Epoch [22/100], Step [8700/6235], Loss: 8.7228\n",
      "Epoch [22/100], Step [8800/6235], Loss: 548.9714\n",
      "Epoch [22/100], Step [8900/6235], Loss: 38.2085\n",
      "Epoch [22/100], Step [9000/6235], Loss: 524.3488\n",
      "Epoch [22/100], Step [9100/6235], Loss: 381.2509\n",
      "Epoch [22/100], Step [9200/6235], Loss: 3294.5356\n",
      "Epoch [22/100], Step [9300/6235], Loss: 29.5562\n",
      "Epoch [22/100], Step [9400/6235], Loss: 573.6291\n",
      "Epoch [22/100], Step [9500/6235], Loss: 11.3479\n",
      "Epoch [22/100], Step [9600/6235], Loss: 53.4766\n",
      "Epoch [22/100], Step [9700/6235], Loss: 116.9028\n",
      "Epoch [22/100], Step [9800/6235], Loss: 443.2028\n",
      "Epoch [22/100], Step [9900/6235], Loss: 4.5286\n",
      "Epoch [22/100], Step [10000/6235], Loss: 18.9630\n",
      "Epoch [22/100], Step [10100/6235], Loss: 27.8507\n",
      "Epoch [22/100], Step [10200/6235], Loss: 444.4058\n",
      "Epoch [22/100], Step [10300/6235], Loss: 0.5715\n",
      "Epoch [22/100], Step [10400/6235], Loss: 0.8219\n",
      "Epoch [22/100], Step [10500/6235], Loss: 4.1050\n",
      "Epoch [22/100], Step [10600/6235], Loss: 2150.6538\n",
      "Epoch [22/100], Step [10700/6235], Loss: 34.6397\n",
      "Epoch [22/100], Step [10800/6235], Loss: 119.1291\n",
      "Epoch [22/100], Step [10900/6235], Loss: 1.3424\n",
      "Epoch [22/100], Step [11000/6235], Loss: 173.2433\n",
      "Epoch [22/100], Step [11100/6235], Loss: 18.8273\n",
      "Epoch [22/100], Step [11200/6235], Loss: 86.4008\n",
      "Epoch [22/100], Step [11300/6235], Loss: 230.5664\n",
      "Epoch [22/100], Step [11400/6235], Loss: 141.9757\n",
      "Epoch [22/100], Step [11500/6235], Loss: 11.2919\n",
      "Epoch [22/100], Step [11600/6235], Loss: 5.6805\n",
      "Epoch [22/100], Step [11700/6235], Loss: 147.3644\n",
      "Epoch [22/100], Step [11800/6235], Loss: 3.1179\n",
      "Epoch [22/100], Step [11900/6235], Loss: 1040.9152\n",
      "Epoch [22/100], Step [12000/6235], Loss: 278.9548\n",
      "Epoch [22/100], Step [12100/6235], Loss: 363.6993\n",
      "Epoch [22/100], Step [12200/6235], Loss: 57.6547\n",
      "Epoch [22/100], Step [12300/6235], Loss: 1.8340\n",
      "Epoch [22/100], Step [12400/6235], Loss: 61.8634\n",
      "Epoch [22/100], Step [12500/6235], Loss: 274.0330\n",
      "Epoch [22/100], Step [12600/6235], Loss: 22.4509\n",
      "Epoch [22/100], Step [12700/6235], Loss: 10.1370\n",
      "Epoch [22/100], Step [12800/6235], Loss: 25.9243\n",
      "Epoch [22/100], Step [12900/6235], Loss: 72.2918\n",
      "Epoch [22/100], Step [13000/6235], Loss: 0.6243\n",
      "Epoch [22/100], Step [13100/6235], Loss: 106.9606\n",
      "Epoch [22/100], Step [13200/6235], Loss: 33.8861\n",
      "Epoch [22/100], Step [13300/6235], Loss: 15.3528\n",
      "Epoch [22/100], Step [13400/6235], Loss: 23.2792\n",
      "Epoch [22/100], Step [13500/6235], Loss: 3.0641\n",
      "Epoch [22/100], Step [13600/6235], Loss: 34.3407\n",
      "Epoch [22/100], Step [13700/6235], Loss: 203.6340\n",
      "Epoch [22/100], Step [13800/6235], Loss: 89.1895\n",
      "Epoch [22/100], Step [13900/6235], Loss: 2.4244\n",
      "Epoch [22/100], Step [14000/6235], Loss: 0.8190\n",
      "Epoch [22/100], Step [14100/6235], Loss: 14.9063\n",
      "Epoch [22/100], Step [14200/6235], Loss: 29.0291\n",
      "Epoch [22/100], Step [14300/6235], Loss: 30.1655\n",
      "Epoch [22/100], Step [14400/6235], Loss: 4.1106\n",
      "Epoch [22/100], Step [14500/6235], Loss: 8.6530\n",
      "Epoch [22/100], Step [14600/6235], Loss: 1.5329\n",
      "Epoch [22/100], Step [14700/6235], Loss: 10.1804\n",
      "Epoch [22/100], Step [14800/6235], Loss: 11.8447\n",
      "Epoch [22/100], Step [14900/6235], Loss: 0.2277\n",
      "Epoch [22/100], Step [15000/6235], Loss: 0.1185\n",
      "Epoch [22/100], Step [15100/6235], Loss: 0.1284\n",
      "Epoch [22/100], Step [15200/6235], Loss: 62.0056\n",
      "Epoch [22/100], Step [15300/6235], Loss: 1.3400\n",
      "Epoch [22/100], Step [15400/6235], Loss: 4.5044\n",
      "Epoch [22/100], Step [15500/6235], Loss: 15.8871\n",
      "Epoch [22/100], Step [15600/6235], Loss: 7.5603\n",
      "Epoch [22/100], Step [15700/6235], Loss: 10.2179\n",
      "Epoch [22/100], Step [15800/6235], Loss: 5.7716\n",
      "Epoch [22/100], Step [15900/6235], Loss: 1.5764\n",
      "Epoch [22/100], Step [16000/6235], Loss: 37.1536\n",
      "Epoch [22/100], Step [16100/6235], Loss: 0.5790\n",
      "Epoch [22/100], Step [16200/6235], Loss: 13.3909\n",
      "Epoch [22/100], Step [16300/6235], Loss: 26.4465\n",
      "Epoch [22/100], Step [16400/6235], Loss: 40.5471\n",
      "Epoch [22/100], Step [16500/6235], Loss: 535.4584\n",
      "Epoch [22/100], Step [16600/6235], Loss: 5.2015\n",
      "Epoch [22/100], Step [16700/6235], Loss: 1.8966\n",
      "Epoch [22/100], Step [16800/6235], Loss: 2.4092\n",
      "Epoch [22/100], Step [16900/6235], Loss: 4.5748\n",
      "Epoch [22/100], Step [17000/6235], Loss: 0.5160\n",
      "Epoch [22/100], Step [17100/6235], Loss: 0.5298\n",
      "Epoch [22/100], Step [17200/6235], Loss: 91.3801\n",
      "Epoch [22/100], Step [17300/6235], Loss: 35.1426\n",
      "Epoch [22/100], Step [17400/6235], Loss: 34.3032\n",
      "Epoch [22/100], Step [17500/6235], Loss: 5.9339\n",
      "Epoch [22/100], Step [17600/6235], Loss: 0.2889\n",
      "Epoch [22/100], Step [17700/6235], Loss: 79.0356\n",
      "Epoch [22/100], Step [17800/6235], Loss: 49.8757\n",
      "Epoch [22/100], Step [17900/6235], Loss: 46.5709\n",
      "Epoch [22/100], Step [18000/6235], Loss: 2.3006\n",
      "Epoch [22/100], Step [18100/6235], Loss: 11.4156\n",
      "Epoch [22/100], Step [18200/6235], Loss: 12.8168\n",
      "Epoch [22/100], Step [18300/6235], Loss: 8.4497\n",
      "Epoch [22/100], Step [18400/6235], Loss: 2.5560\n",
      "Epoch [22/100], Step [18500/6235], Loss: 1.8838\n",
      "Epoch [22/100], Step [18600/6235], Loss: 2.4016\n",
      "Epoch [22/100], Step [18700/6235], Loss: 0.2085\n",
      "Epoch [22/100], Step [18800/6235], Loss: 96.3860\n",
      "Epoch [22/100], Step [18900/6235], Loss: 38.0479\n",
      "Epoch [22/100], Step [19000/6235], Loss: 5.0029\n",
      "Epoch [22/100], Step [19100/6235], Loss: 9.8786\n",
      "Epoch [22/100], Step [19200/6235], Loss: 7.5130\n",
      "Epoch [22/100], Step [19300/6235], Loss: 1.2926\n",
      "Epoch [22/100], Step [19400/6235], Loss: 131.4962\n",
      "Epoch [22/100], Step [19500/6235], Loss: 70.3370\n",
      "Epoch [22/100], Step [19600/6235], Loss: 116.6335\n",
      "Epoch [22/100], Step [19700/6235], Loss: 14.6726\n",
      "Epoch [22/100], Step [19800/6235], Loss: 0.7438\n",
      "Epoch [22/100], Step [19900/6235], Loss: 1.6662\n",
      "Epoch [22/100], Step [20000/6235], Loss: 78.8263\n",
      "Epoch [22/100], Step [20100/6235], Loss: 4.6292\n",
      "Epoch [22/100], Step [20200/6235], Loss: 6.1573\n",
      "Epoch [22/100], Step [20300/6235], Loss: 2.1374\n",
      "Epoch [22/100], Step [20400/6235], Loss: 27.5578\n",
      "Epoch [22/100], Step [20500/6235], Loss: 26.4407\n",
      "Epoch [22/100], Step [20600/6235], Loss: 78.5764\n",
      "Epoch [22/100], Step [20700/6235], Loss: 18.0215\n",
      "Epoch [22/100], Step [20800/6235], Loss: 4.9884\n",
      "Epoch [22/100], Step [20900/6235], Loss: 31.3728\n",
      "Epoch [22/100], Step [21000/6235], Loss: 23.5640\n",
      "Epoch [22/100], Step [21100/6235], Loss: 4.1755\n",
      "Epoch [22/100], Step [21200/6235], Loss: 0.4676\n",
      "Epoch [22/100], Step [21300/6235], Loss: 0.0977\n",
      "Epoch [22/100], Step [21400/6235], Loss: 4.0617\n",
      "Epoch [22/100], Step [21500/6235], Loss: 2.4035\n",
      "Epoch [22/100], Step [21600/6235], Loss: 32.8829\n",
      "Epoch [22/100], Step [21700/6235], Loss: 0.0728\n",
      "Epoch [22/100], Step [21800/6235], Loss: 15.4778\n",
      "Epoch [22/100], Step [21900/6235], Loss: 0.0569\n",
      "Epoch [22/100], Step [22000/6235], Loss: 2.3197\n",
      "Epoch [22/100], Step [22100/6235], Loss: 4.4056\n",
      "Epoch [22/100], Step [22200/6235], Loss: 3.3073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Step [22300/6235], Loss: 0.9897\n",
      "Epoch [22/100], Step [22400/6235], Loss: 0.7309\n",
      "Epoch [22/100], Step [22500/6235], Loss: 169.7457\n",
      "Epoch [22/100], Step [22600/6235], Loss: 19.6016\n",
      "Epoch [22/100], Step [22700/6235], Loss: 1.7577\n",
      "Epoch [22/100], Step [22800/6235], Loss: 8.9942\n",
      "Epoch [22/100], Step [22900/6235], Loss: 11.8911\n",
      "Epoch [22/100], Step [23000/6235], Loss: 8.3462\n",
      "Epoch [22/100], Step [23100/6235], Loss: 0.2712\n",
      "Epoch [22/100], Step [23200/6235], Loss: 13.8370\n",
      "Epoch [22/100], Step [23300/6235], Loss: 17.9848\n",
      "Epoch [22/100], Step [23400/6235], Loss: 1.7135\n",
      "Epoch [22/100], Step [23500/6235], Loss: 0.0901\n",
      "Epoch [22/100], Step [23600/6235], Loss: 113.4023\n",
      "Epoch [22/100], Step [23700/6235], Loss: 6.5929\n",
      "Epoch [22/100], Step [23800/6235], Loss: 1.0258\n",
      "Epoch [22/100], Step [23900/6235], Loss: 6.0690\n",
      "Epoch [22/100], Step [24000/6235], Loss: 0.4996\n",
      "Epoch [22/100], Step [24100/6235], Loss: 0.9394\n",
      "Epoch [22/100], Step [24200/6235], Loss: 46.7730\n",
      "Epoch [22/100], Step [24300/6235], Loss: 2.7090\n",
      "Epoch [22/100], Step [24400/6235], Loss: 6.2877\n",
      "Epoch [22/100], Step [24500/6235], Loss: 2.8766\n",
      "Epoch [22/100], Step [24600/6235], Loss: 0.2161\n",
      "Epoch [22/100], Step [24700/6235], Loss: 3.3244\n",
      "Epoch [22/100], Step [24800/6235], Loss: 0.1269\n",
      "Epoch [22/100], Step [24900/6235], Loss: 16.5754\n",
      "Epoch [22/100], Step [25000/6235], Loss: 18.9491\n",
      "Epoch [22/100], Step [25100/6235], Loss: 7.1416\n",
      "Epoch [22/100], Step [25200/6235], Loss: 1.1741\n",
      "Epoch [22/100], Step [25300/6235], Loss: 0.5984\n",
      "Epoch [22/100], Step [25400/6235], Loss: 9.5968\n",
      "Epoch [22/100], Step [25500/6235], Loss: 8.0419\n",
      "Epoch [22/100], Step [25600/6235], Loss: 4.8596\n",
      "Epoch [22/100], Step [25700/6235], Loss: 0.2644\n",
      "Epoch [22/100], Step [25800/6235], Loss: 0.1690\n",
      "Epoch [22/100], Step [25900/6235], Loss: 7.2515\n",
      "Epoch [22/100], Step [26000/6235], Loss: 2.5665\n",
      "Epoch [22/100], Step [26100/6235], Loss: 1.1858\n",
      "Epoch [22/100], Step [26200/6235], Loss: 0.3961\n",
      "Epoch [22/100], Step [26300/6235], Loss: 4.9648\n",
      "Epoch [22/100], Step [26400/6235], Loss: 0.0897\n",
      "Epoch [22/100], Step [26500/6235], Loss: 0.0178\n",
      "Epoch [22/100], Step [26600/6235], Loss: 1.3315\n",
      "Epoch [22/100], Step [26700/6235], Loss: 0.3477\n",
      "Epoch [22/100], Step [26800/6235], Loss: 0.1540\n",
      "Epoch [22/100], Step [26900/6235], Loss: 0.0012\n",
      "Epoch [22/100], Step [27000/6235], Loss: 15.5096\n",
      "Epoch [22/100], Step [27100/6235], Loss: 0.0493\n",
      "Epoch [22/100], Step [27200/6235], Loss: 0.0145\n",
      "Epoch [22/100], Step [27300/6235], Loss: 0.1767\n",
      "Epoch [22/100], Step [27400/6235], Loss: 0.7568\n",
      "Epoch [22/100], Step [27500/6235], Loss: 21.9705\n",
      "Epoch [22/100], Step [27600/6235], Loss: 1.3759\n",
      "Epoch [22/100], Step [27700/6235], Loss: 1.2434\n",
      "Epoch [22/100], Step [27800/6235], Loss: 8.1290\n",
      "Epoch [22/100], Step [27900/6235], Loss: 1.8070\n",
      "Epoch [22/100], Step [28000/6235], Loss: 162.8062\n",
      "Epoch [22/100], Step [28100/6235], Loss: 0.7313\n",
      "Epoch [22/100], Step [28200/6235], Loss: 36.2393\n",
      "Epoch [22/100], Step [28300/6235], Loss: 2.9252\n",
      "Epoch [22/100], Step [28400/6235], Loss: 24.5750\n",
      "Epoch [22/100], Step [28500/6235], Loss: 4.7481\n",
      "Epoch [22/100], Step [28600/6235], Loss: 0.1292\n",
      "Epoch [22/100], Step [28700/6235], Loss: 5.4790\n",
      "Epoch [22/100], Step [28800/6235], Loss: 0.5600\n",
      "Epoch [22/100], Step [28900/6235], Loss: 70.2109\n",
      "Epoch [22/100], Step [29000/6235], Loss: 11.9399\n",
      "Epoch [22/100], Step [29100/6235], Loss: 0.0345\n",
      "Epoch [22/100], Step [29200/6235], Loss: 2.2414\n",
      "Epoch [22/100], Step [29300/6235], Loss: 14.0109\n",
      "Epoch [22/100], Step [29400/6235], Loss: 1.4460\n",
      "Epoch [22/100], Step [29500/6235], Loss: 4.0042\n",
      "Epoch [22/100], Step [29600/6235], Loss: 0.3641\n",
      "Epoch [22/100], Step [29700/6235], Loss: 2.0077\n",
      "Epoch [22/100], Step [29800/6235], Loss: 1.2480\n",
      "Epoch [22/100], Step [29900/6235], Loss: 1.5574\n",
      "Epoch [22/100], Step [30000/6235], Loss: 6.6043\n",
      "Epoch [22/100], Step [30100/6235], Loss: 10.2998\n",
      "Epoch [22/100], Step [30200/6235], Loss: 1.7619\n",
      "Epoch [22/100], Step [30300/6235], Loss: 0.0812\n",
      "Epoch [22/100], Step [30400/6235], Loss: 1.8338\n",
      "Epoch [22/100], Step [30500/6235], Loss: 2.7808\n",
      "Epoch [22/100], Step [30600/6235], Loss: 1.7969\n",
      "Epoch [22/100], Step [30700/6235], Loss: 1.3732\n",
      "Epoch [22/100], Step [30800/6235], Loss: 0.5638\n",
      "Epoch [22/100], Step [30900/6235], Loss: 3.2162\n",
      "Epoch [22/100], Step [31000/6235], Loss: 0.2743\n",
      "Epoch [22/100], Step [31100/6235], Loss: 0.0595\n",
      "Epoch [22/100], Step [31200/6235], Loss: 4.5921\n",
      "Epoch [22/100], Step [31300/6235], Loss: 6.3850\n",
      "Epoch [22/100], Step [31400/6235], Loss: 0.5755\n",
      "Epoch [22/100], Step [31500/6235], Loss: 0.7874\n",
      "Epoch [22/100], Step [31600/6235], Loss: 9.8240\n",
      "Epoch [22/100], Step [31700/6235], Loss: 15.9912\n",
      "Epoch [22/100], Step [31800/6235], Loss: 1.8600\n",
      "Epoch [22/100], Step [31900/6235], Loss: 111.1513\n",
      "Epoch [22/100], Step [32000/6235], Loss: 87.8740\n",
      "Epoch [22/100], Step [32100/6235], Loss: 6.0721\n",
      "Epoch [22/100], Step [32200/6235], Loss: 93.7304\n",
      "Epoch [22/100], Step [32300/6235], Loss: 0.6742\n",
      "Epoch [22/100], Step [32400/6235], Loss: 1.2657\n",
      "Epoch [22/100], Step [32500/6235], Loss: 16.0114\n",
      "Epoch [22/100], Step [32600/6235], Loss: 0.4896\n",
      "Epoch [22/100], Step [32700/6235], Loss: 75.1569\n",
      "Epoch [22/100], Step [32800/6235], Loss: 1.4710\n",
      "Epoch [22/100], Step [32900/6235], Loss: 13.9798\n",
      "Epoch [22/100], Step [33000/6235], Loss: 0.2823\n",
      "Epoch [22/100], Step [33100/6235], Loss: 0.4846\n",
      "Epoch [22/100], Step [33200/6235], Loss: 1.9015\n",
      "Epoch [22/100], Step [33300/6235], Loss: 0.1592\n",
      "Epoch [22/100], Step [33400/6235], Loss: 101.0075\n",
      "Epoch [22/100], Step [33500/6235], Loss: 0.6355\n",
      "Epoch [22/100], Step [33600/6235], Loss: 2.8633\n",
      "Epoch [22/100], Step [33700/6235], Loss: 0.2281\n",
      "Epoch [22/100], Step [33800/6235], Loss: 16.3704\n",
      "Epoch [22/100], Step [33900/6235], Loss: 18.4170\n",
      "Epoch [22/100], Step [34000/6235], Loss: 0.0309\n",
      "Epoch [22/100], Step [34100/6235], Loss: 0.0143\n",
      "Epoch [22/100], Step [34200/6235], Loss: 0.5575\n",
      "Epoch [22/100], Step [34300/6235], Loss: 5.8640\n",
      "Epoch [22/100], Step [34400/6235], Loss: 1.1882\n",
      "Epoch [22/100], Step [34500/6235], Loss: 54.9458\n",
      "Epoch [22/100], Step [34600/6235], Loss: 3.1078\n",
      "Epoch [22/100], Step [34700/6235], Loss: 12.2819\n",
      "Epoch [22/100], Step [34800/6235], Loss: 13.6988\n",
      "Epoch [22/100], Step [34900/6235], Loss: 25.2424\n",
      "Epoch [22/100], Step [35000/6235], Loss: 0.2831\n",
      "Epoch [22/100], Step [35100/6235], Loss: 2.7865\n",
      "Epoch [22/100], Step [35200/6235], Loss: 5.2811\n",
      "Epoch [22/100], Step [35300/6235], Loss: 0.5089\n",
      "Epoch [22/100], Step [35400/6235], Loss: 0.9032\n",
      "Epoch [22/100], Step [35500/6235], Loss: 1.4784\n",
      "Epoch [22/100], Step [35600/6235], Loss: 5.7761\n",
      "Epoch [22/100], Step [35700/6235], Loss: 6.1274\n",
      "Epoch [22/100], Step [35800/6235], Loss: 0.0504\n",
      "Epoch [22/100], Step [35900/6235], Loss: 0.3499\n",
      "Epoch [22/100], Step [36000/6235], Loss: 3.2076\n",
      "Epoch [22/100], Step [36100/6235], Loss: 1.4491\n",
      "Epoch [22/100], Step [36200/6235], Loss: 16.5480\n",
      "Epoch [22/100], Step [36300/6235], Loss: 0.4264\n",
      "Epoch [22/100], Step [36400/6235], Loss: 0.1123\n",
      "Epoch [22/100], Step [36500/6235], Loss: 10.2494\n",
      "Epoch [22/100], Step [36600/6235], Loss: 0.0614\n",
      "Epoch [22/100], Step [36700/6235], Loss: 0.3921\n",
      "Epoch [22/100], Step [36800/6235], Loss: 36.3203\n",
      "Epoch [22/100], Step [36900/6235], Loss: 3.4246\n",
      "Epoch [22/100], Step [37000/6235], Loss: 0.5726\n",
      "Epoch [22/100], Step [37100/6235], Loss: 0.2091\n",
      "Epoch [22/100], Step [37200/6235], Loss: 0.0264\n",
      "Epoch [22/100], Step [37300/6235], Loss: 0.6127\n",
      "Epoch [22/100], Step [37400/6235], Loss: 0.2741\n",
      "Epoch [22/100], Step [37500/6235], Loss: 3.1150\n",
      "Epoch [22/100], Step [37600/6235], Loss: 7.5872\n",
      "Epoch [22/100], Step [37700/6235], Loss: 0.6883\n",
      "Epoch [22/100], Step [37800/6235], Loss: 6.3713\n",
      "Epoch [22/100], Step [37900/6235], Loss: 6.0745\n",
      "Epoch [22/100], Step [38000/6235], Loss: 0.4546\n",
      "Epoch [22/100], Step [38100/6235], Loss: 5.1581\n",
      "Epoch [22/100], Step [38200/6235], Loss: 2.1412\n",
      "Epoch [22/100], Step [38300/6235], Loss: 0.1724\n",
      "Epoch [22/100], Step [38400/6235], Loss: 0.0728\n",
      "Epoch [22/100], Step [38500/6235], Loss: 4.4221\n",
      "Epoch [22/100], Step [38600/6235], Loss: 0.4284\n",
      "Epoch [22/100], Step [38700/6235], Loss: 0.0537\n",
      "Epoch [22/100], Step [38800/6235], Loss: 1.1481\n",
      "Epoch [22/100], Step [38900/6235], Loss: 1.7068\n",
      "Epoch [22/100], Step [39000/6235], Loss: 0.2990\n",
      "Epoch [22/100], Step [39100/6235], Loss: 25.3730\n",
      "Epoch [22/100], Step [39200/6235], Loss: 0.6085\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [22/100], Step [39300/6235], Loss: 26.8669\n",
      "Epoch [22/100], Step [39400/6235], Loss: 313.0270\n",
      "Epoch [22/100], Step [39500/6235], Loss: 125.2058\n",
      "Epoch [22/100], Step [39600/6235], Loss: 27.0050\n",
      "Epoch [22/100], Step [39700/6235], Loss: 409.0558\n",
      "Epoch [22/100], Step [39800/6235], Loss: 127.2925\n",
      "Epoch [22/100], Step [39900/6235], Loss: 1.4618\n",
      "Epoch [22/100], Step [40000/6235], Loss: 9.5287\n",
      "Epoch [22/100], Step [40100/6235], Loss: 17.0150\n",
      "Epoch [22/100], Step [40200/6235], Loss: 3.1288\n",
      "Epoch [22/100], Step [40300/6235], Loss: 0.5997\n",
      "Epoch [22/100], Step [40400/6235], Loss: 0.8039\n",
      "Epoch [22/100], Step [40500/6235], Loss: 2.8057\n",
      "Epoch [22/100], Step [40600/6235], Loss: 0.2688\n",
      "Epoch [22/100], Step [40700/6235], Loss: 6.9855\n",
      "Epoch [22/100], Step [40800/6235], Loss: 0.6586\n",
      "Epoch [22/100], Step [40900/6235], Loss: 0.4965\n",
      "Epoch [22/100], Step [41000/6235], Loss: 41.0595\n",
      "Epoch [22/100], Step [41100/6235], Loss: 34.0182\n",
      "Epoch [22/100], Step [41200/6235], Loss: 11.8270\n",
      "Epoch [22/100], Step [41300/6235], Loss: 0.1259\n",
      "Epoch [22/100], Step [41400/6235], Loss: 0.4335\n",
      "Epoch [22/100], Step [41500/6235], Loss: 8.0618\n",
      "Epoch [22/100], Step [41600/6235], Loss: 0.2346\n",
      "Epoch [22/100], Step [41700/6235], Loss: 0.0898\n",
      "Epoch [22/100], Step [41800/6235], Loss: 0.8952\n",
      "Epoch [22/100], Step [41900/6235], Loss: 5.1251\n",
      "Epoch [22/100], Step [42000/6235], Loss: 3.4032\n",
      "Epoch [22/100], Step [42100/6235], Loss: 9.0030\n",
      "Epoch [22/100], Step [42200/6235], Loss: 85.1942\n",
      "Epoch [22/100], Step [42300/6235], Loss: 1.7289\n",
      "Epoch [22/100], Step [42400/6235], Loss: 1.8551\n",
      "Epoch [22/100], Step [42500/6235], Loss: 0.9630\n",
      "Epoch [22/100], Step [42600/6235], Loss: 1.3393\n",
      "Epoch [22/100], Step [42700/6235], Loss: 0.6103\n",
      "Epoch [22/100], Step [42800/6235], Loss: 0.3251\n",
      "Epoch [22/100], Step [42900/6235], Loss: 3.9927\n",
      "Epoch [22/100], Step [43000/6235], Loss: 0.1938\n",
      "Epoch [22/100], Step [43100/6235], Loss: 0.9073\n",
      "Epoch [22/100], Step [43200/6235], Loss: 0.7608\n",
      "Epoch [22/100], Step [43300/6235], Loss: 9.1534\n",
      "Epoch [22/100], Step [43400/6235], Loss: 11.4168\n",
      "Epoch [22/100], Step [43500/6235], Loss: 9.4635\n",
      "Epoch [22/100], Step [43600/6235], Loss: 15.2046\n",
      "Epoch [22/100], Step [43700/6235], Loss: 47.9814\n",
      "Epoch [22/100], Step [43800/6235], Loss: 0.2859\n",
      "Epoch [22/100], Step [43900/6235], Loss: 3.8816\n",
      "Epoch [22/100], Step [44000/6235], Loss: 59.7684\n",
      "Epoch [22/100], Step [44100/6235], Loss: 0.7339\n",
      "Epoch [22/100], Step [44200/6235], Loss: 15.5434\n",
      "Epoch [22/100], Step [44300/6235], Loss: 21.6824\n",
      "Epoch [22/100], Step [44400/6235], Loss: 1.6904\n",
      "Epoch [22/100], Step [44500/6235], Loss: 0.4723\n",
      "Epoch [22/100], Step [44600/6235], Loss: 17.0679\n",
      "Epoch [22/100], Step [44700/6235], Loss: 2.4905\n",
      "Epoch [22/100], Step [44800/6235], Loss: 1.8702\n",
      "Epoch [22/100], Step [44900/6235], Loss: 10.5936\n",
      "Epoch [22/100], Step [45000/6235], Loss: 5.5591\n",
      "Epoch [22/100], Step [45100/6235], Loss: 57.1994\n",
      "Epoch [22/100], Step [45200/6235], Loss: 0.6119\n",
      "Epoch [22/100], Step [45300/6235], Loss: 23.7823\n",
      "Epoch [22/100], Step [45400/6235], Loss: 11.7799\n",
      "Epoch [22/100], Step [45500/6235], Loss: 2.2483\n",
      "Epoch [22/100], Step [45600/6235], Loss: 0.8816\n",
      "Epoch [22/100], Step [45700/6235], Loss: 103.4914\n",
      "Epoch [22/100], Step [45800/6235], Loss: 326.4455\n",
      "Epoch [22/100], Step [45900/6235], Loss: 6.2438\n",
      "Epoch [22/100], Step [46000/6235], Loss: 15.3805\n",
      "Epoch [22/100], Step [46100/6235], Loss: 48.9007\n",
      "Epoch [22/100], Step [46200/6235], Loss: 7.7673\n",
      "Epoch [22/100], Step [46300/6235], Loss: 53.1999\n",
      "Epoch [22/100], Step [46400/6235], Loss: 13.6126\n",
      "Epoch [22/100], Step [46500/6235], Loss: 68.8331\n",
      "Epoch [22/100], Step [46600/6235], Loss: 19.7095\n",
      "Epoch [22/100], Step [46700/6235], Loss: 20.8919\n",
      "Epoch [22/100], Step [46800/6235], Loss: 1.1140\n",
      "Epoch [22/100], Step [46900/6235], Loss: 2.1452\n",
      "Epoch [22/100], Step [47000/6235], Loss: 7.2225\n",
      "Epoch [22/100], Step [47100/6235], Loss: 0.9617\n",
      "Epoch [22/100], Step [47200/6235], Loss: 14.4665\n",
      "Epoch [22/100], Step [47300/6235], Loss: 1.1958\n",
      "Epoch [22/100], Step [47400/6235], Loss: 9.9302\n",
      "Epoch [22/100], Step [47500/6235], Loss: 11.3789\n",
      "Epoch [22/100], Step [47600/6235], Loss: 2.9779\n",
      "Epoch [22/100], Step [47700/6235], Loss: 11.1619\n",
      "Epoch [22/100], Step [47800/6235], Loss: 6.3626\n",
      "Epoch [22/100], Step [47900/6235], Loss: 18.8691\n",
      "Epoch [22/100], Step [48000/6235], Loss: 55.2146\n",
      "Epoch [22/100], Step [48100/6235], Loss: 4.3908\n",
      "Epoch [22/100], Step [48200/6235], Loss: 10.3404\n",
      "Epoch [22/100], Step [48300/6235], Loss: 240.8742\n",
      "Epoch [22/100], Step [48400/6235], Loss: 32.0834\n",
      "Epoch [22/100], Step [48500/6235], Loss: 10.7772\n",
      "Epoch [22/100], Step [48600/6235], Loss: 156.6399\n",
      "Epoch [22/100], Step [48700/6235], Loss: 48.5850\n",
      "Epoch [22/100], Step [48800/6235], Loss: 442.3016\n",
      "Epoch [22/100], Step [48900/6235], Loss: 151.4335\n",
      "Epoch [22/100], Step [49000/6235], Loss: 302.7048\n",
      "Epoch [22/100], Step [49100/6235], Loss: 2069.9336\n",
      "Epoch [22/100], Step [49200/6235], Loss: 810.2883\n",
      "Epoch [22/100], Step [49300/6235], Loss: 1252.0331\n",
      "Epoch [22/100], Step [49400/6235], Loss: 2.1229\n",
      "Epoch [22/100], Step [49500/6235], Loss: 48.9894\n",
      "Epoch [22/100], Step [49600/6235], Loss: 147.4903\n",
      "Epoch [22/100], Step [49700/6235], Loss: 3205.2217\n",
      "Epoch [22/100], Step [49800/6235], Loss: 55.7041\n",
      "Epoch [23/100], Step [100/6235], Loss: 25.3747\n",
      "Epoch [23/100], Step [200/6235], Loss: 0.1666\n",
      "Epoch [23/100], Step [300/6235], Loss: 0.0425\n",
      "Epoch [23/100], Step [400/6235], Loss: 0.0135\n",
      "Epoch [23/100], Step [500/6235], Loss: 8.7986\n",
      "Epoch [23/100], Step [600/6235], Loss: 0.0545\n",
      "Epoch [23/100], Step [700/6235], Loss: 0.4580\n",
      "Epoch [23/100], Step [800/6235], Loss: 0.1289\n",
      "Epoch [23/100], Step [900/6235], Loss: 0.0522\n",
      "Epoch [23/100], Step [1000/6235], Loss: 0.0361\n",
      "Epoch [23/100], Step [1100/6235], Loss: 0.0907\n",
      "Epoch [23/100], Step [1200/6235], Loss: 0.1433\n",
      "Epoch [23/100], Step [1300/6235], Loss: 0.0592\n",
      "Epoch [23/100], Step [1400/6235], Loss: 0.0504\n",
      "Epoch [23/100], Step [1500/6235], Loss: 0.0052\n",
      "Epoch [23/100], Step [1600/6235], Loss: 0.2035\n",
      "Epoch [23/100], Step [1700/6235], Loss: 0.0427\n",
      "Epoch [23/100], Step [1800/6235], Loss: 0.2532\n",
      "Epoch [23/100], Step [1900/6235], Loss: 0.7993\n",
      "Epoch [23/100], Step [2000/6235], Loss: 1.8743\n",
      "Epoch [23/100], Step [2100/6235], Loss: 0.3171\n",
      "Epoch [23/100], Step [2200/6235], Loss: 11.6595\n",
      "Epoch [23/100], Step [2300/6235], Loss: 26.8639\n",
      "Epoch [23/100], Step [2400/6235], Loss: 16.2766\n",
      "Epoch [23/100], Step [2500/6235], Loss: 28.0136\n",
      "Epoch [23/100], Step [2600/6235], Loss: 6.4416\n",
      "Epoch [23/100], Step [2700/6235], Loss: 36.1152\n",
      "Epoch [23/100], Step [2800/6235], Loss: 16.0948\n",
      "Epoch [23/100], Step [2900/6235], Loss: 6.8621\n",
      "Epoch [23/100], Step [3000/6235], Loss: 0.7813\n",
      "Epoch [23/100], Step [3100/6235], Loss: 45.4748\n",
      "Epoch [23/100], Step [3200/6235], Loss: 68.4859\n",
      "Epoch [23/100], Step [3300/6235], Loss: 0.4557\n",
      "Epoch [23/100], Step [3400/6235], Loss: 3.0400\n",
      "Epoch [23/100], Step [3500/6235], Loss: 38.4764\n",
      "Epoch [23/100], Step [3600/6235], Loss: 10.0884\n",
      "Epoch [23/100], Step [3700/6235], Loss: 1.4500\n",
      "Epoch [23/100], Step [3800/6235], Loss: 0.5008\n",
      "Epoch [23/100], Step [3900/6235], Loss: 0.7516\n",
      "Epoch [23/100], Step [4000/6235], Loss: 0.1572\n",
      "Epoch [23/100], Step [4100/6235], Loss: 3.3274\n",
      "Epoch [23/100], Step [4200/6235], Loss: 0.2344\n",
      "Epoch [23/100], Step [4300/6235], Loss: 9.6598\n",
      "Epoch [23/100], Step [4400/6235], Loss: 1.0708\n",
      "Epoch [23/100], Step [4500/6235], Loss: 82.3264\n",
      "Epoch [23/100], Step [4600/6235], Loss: 13.7785\n",
      "Epoch [23/100], Step [4700/6235], Loss: 2.3520\n",
      "Epoch [23/100], Step [4800/6235], Loss: 1.1813\n",
      "Epoch [23/100], Step [4900/6235], Loss: 0.1251\n",
      "Epoch [23/100], Step [5000/6235], Loss: 0.8858\n",
      "Epoch [23/100], Step [5100/6235], Loss: 2.1702\n",
      "Epoch [23/100], Step [5200/6235], Loss: 3.5405\n",
      "Epoch [23/100], Step [5300/6235], Loss: 33.6604\n",
      "Epoch [23/100], Step [5400/6235], Loss: 2.7389\n",
      "Epoch [23/100], Step [5500/6235], Loss: 0.2713\n",
      "Epoch [23/100], Step [5600/6235], Loss: 0.1653\n",
      "Epoch [23/100], Step [5700/6235], Loss: 0.5588\n",
      "Epoch [23/100], Step [5800/6235], Loss: 1.2893\n",
      "Epoch [23/100], Step [5900/6235], Loss: 0.6504\n",
      "Epoch [23/100], Step [6000/6235], Loss: 0.4158\n",
      "Epoch [23/100], Step [6100/6235], Loss: 0.2219\n",
      "Epoch [23/100], Step [6200/6235], Loss: 0.2771\n",
      "Epoch [23/100], Step [6300/6235], Loss: 0.1463\n",
      "Epoch [23/100], Step [6400/6235], Loss: 0.1854\n",
      "Epoch [23/100], Step [6500/6235], Loss: 0.6896\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Step [6600/6235], Loss: 18.0902\n",
      "Epoch [23/100], Step [6700/6235], Loss: 0.7176\n",
      "Epoch [23/100], Step [6800/6235], Loss: 0.1341\n",
      "Epoch [23/100], Step [6900/6235], Loss: 2.0875\n",
      "Epoch [23/100], Step [7000/6235], Loss: 0.0373\n",
      "Epoch [23/100], Step [7100/6235], Loss: 0.1035\n",
      "Epoch [23/100], Step [7200/6235], Loss: 1.9132\n",
      "Epoch [23/100], Step [7300/6235], Loss: 0.3096\n",
      "Epoch [23/100], Step [7400/6235], Loss: 0.0045\n",
      "Epoch [23/100], Step [7500/6235], Loss: 5.7975\n",
      "Epoch [23/100], Step [7600/6235], Loss: 0.7284\n",
      "Epoch [23/100], Step [7700/6235], Loss: 1.6173\n",
      "Epoch [23/100], Step [7800/6235], Loss: 5.7580\n",
      "Epoch [23/100], Step [7900/6235], Loss: 9.7371\n",
      "Epoch [23/100], Step [8000/6235], Loss: 0.1902\n",
      "Epoch [23/100], Step [8100/6235], Loss: 4.1131\n",
      "Epoch [23/100], Step [8200/6235], Loss: 20.5586\n",
      "Epoch [23/100], Step [8300/6235], Loss: 66.0772\n",
      "Epoch [23/100], Step [8400/6235], Loss: 35.1130\n",
      "Epoch [23/100], Step [8500/6235], Loss: 73.2773\n",
      "Epoch [23/100], Step [8600/6235], Loss: 0.9721\n",
      "Epoch [23/100], Step [8700/6235], Loss: 43.9872\n",
      "Epoch [23/100], Step [8800/6235], Loss: 275.8246\n",
      "Epoch [23/100], Step [8900/6235], Loss: 134.9094\n",
      "Epoch [23/100], Step [9000/6235], Loss: 415.6116\n",
      "Epoch [23/100], Step [9100/6235], Loss: 533.6746\n",
      "Epoch [23/100], Step [9200/6235], Loss: 3285.2566\n",
      "Epoch [23/100], Step [9300/6235], Loss: 12.2669\n",
      "Epoch [23/100], Step [9400/6235], Loss: 762.7094\n",
      "Epoch [23/100], Step [9500/6235], Loss: 15.9086\n",
      "Epoch [23/100], Step [9600/6235], Loss: 300.0685\n",
      "Epoch [23/100], Step [9700/6235], Loss: 161.5629\n",
      "Epoch [23/100], Step [9800/6235], Loss: 373.6597\n",
      "Epoch [23/100], Step [9900/6235], Loss: 6.9122\n",
      "Epoch [23/100], Step [10000/6235], Loss: 46.6858\n",
      "Epoch [23/100], Step [10100/6235], Loss: 11.0465\n",
      "Epoch [23/100], Step [10200/6235], Loss: 472.4094\n",
      "Epoch [23/100], Step [10300/6235], Loss: 0.5126\n",
      "Epoch [23/100], Step [10400/6235], Loss: 1.6359\n",
      "Epoch [23/100], Step [10500/6235], Loss: 10.1162\n",
      "Epoch [23/100], Step [10600/6235], Loss: 1859.3713\n",
      "Epoch [23/100], Step [10700/6235], Loss: 59.1535\n",
      "Epoch [23/100], Step [10800/6235], Loss: 87.1786\n",
      "Epoch [23/100], Step [10900/6235], Loss: 3.2532\n",
      "Epoch [23/100], Step [11000/6235], Loss: 138.2861\n",
      "Epoch [23/100], Step [11100/6235], Loss: 10.0403\n",
      "Epoch [23/100], Step [11200/6235], Loss: 108.3193\n",
      "Epoch [23/100], Step [11300/6235], Loss: 239.1457\n",
      "Epoch [23/100], Step [11400/6235], Loss: 193.6142\n",
      "Epoch [23/100], Step [11500/6235], Loss: 16.5121\n",
      "Epoch [23/100], Step [11600/6235], Loss: 4.9554\n",
      "Epoch [23/100], Step [11700/6235], Loss: 162.8301\n",
      "Epoch [23/100], Step [11800/6235], Loss: 9.7871\n",
      "Epoch [23/100], Step [11900/6235], Loss: 949.0084\n",
      "Epoch [23/100], Step [12000/6235], Loss: 144.8036\n",
      "Epoch [23/100], Step [12100/6235], Loss: 421.5053\n",
      "Epoch [23/100], Step [12200/6235], Loss: 21.4372\n",
      "Epoch [23/100], Step [12300/6235], Loss: 2.9741\n",
      "Epoch [23/100], Step [12400/6235], Loss: 430.6942\n",
      "Epoch [23/100], Step [12500/6235], Loss: 225.0426\n",
      "Epoch [23/100], Step [12600/6235], Loss: 19.2288\n",
      "Epoch [23/100], Step [12700/6235], Loss: 25.6556\n",
      "Epoch [23/100], Step [12800/6235], Loss: 7.5335\n",
      "Epoch [23/100], Step [12900/6235], Loss: 70.7474\n",
      "Epoch [23/100], Step [13000/6235], Loss: 0.7917\n",
      "Epoch [23/100], Step [13100/6235], Loss: 112.0831\n",
      "Epoch [23/100], Step [13200/6235], Loss: 33.2343\n",
      "Epoch [23/100], Step [13300/6235], Loss: 17.5711\n",
      "Epoch [23/100], Step [13400/6235], Loss: 30.9531\n",
      "Epoch [23/100], Step [13500/6235], Loss: 1.3619\n",
      "Epoch [23/100], Step [13600/6235], Loss: 14.9065\n",
      "Epoch [23/100], Step [13700/6235], Loss: 123.9023\n",
      "Epoch [23/100], Step [13800/6235], Loss: 83.2233\n",
      "Epoch [23/100], Step [13900/6235], Loss: 73.0430\n",
      "Epoch [23/100], Step [14000/6235], Loss: 1.0649\n",
      "Epoch [23/100], Step [14100/6235], Loss: 160.2310\n",
      "Epoch [23/100], Step [14200/6235], Loss: 82.3550\n",
      "Epoch [23/100], Step [14300/6235], Loss: 18.9511\n",
      "Epoch [23/100], Step [14400/6235], Loss: 15.0315\n",
      "Epoch [23/100], Step [14500/6235], Loss: 22.5466\n",
      "Epoch [23/100], Step [14600/6235], Loss: 1.3507\n",
      "Epoch [23/100], Step [14700/6235], Loss: 25.9468\n",
      "Epoch [23/100], Step [14800/6235], Loss: 31.9432\n",
      "Epoch [23/100], Step [14900/6235], Loss: 0.6851\n",
      "Epoch [23/100], Step [15000/6235], Loss: 1.1369\n",
      "Epoch [23/100], Step [15100/6235], Loss: 0.2918\n",
      "Epoch [23/100], Step [15200/6235], Loss: 61.0782\n",
      "Epoch [23/100], Step [15300/6235], Loss: 2.9840\n",
      "Epoch [23/100], Step [15400/6235], Loss: 5.0714\n",
      "Epoch [23/100], Step [15500/6235], Loss: 29.4307\n",
      "Epoch [23/100], Step [15600/6235], Loss: 204.3552\n",
      "Epoch [23/100], Step [15700/6235], Loss: 76.2156\n",
      "Epoch [23/100], Step [15800/6235], Loss: 1.6844\n",
      "Epoch [23/100], Step [15900/6235], Loss: 3.2790\n",
      "Epoch [23/100], Step [16000/6235], Loss: 34.3314\n",
      "Epoch [23/100], Step [16100/6235], Loss: 31.4858\n",
      "Epoch [23/100], Step [16200/6235], Loss: 7.7861\n",
      "Epoch [23/100], Step [16300/6235], Loss: 33.2727\n",
      "Epoch [23/100], Step [16400/6235], Loss: 48.4862\n",
      "Epoch [23/100], Step [16500/6235], Loss: 614.0685\n",
      "Epoch [23/100], Step [16600/6235], Loss: 16.7135\n",
      "Epoch [23/100], Step [16700/6235], Loss: 2.2870\n",
      "Epoch [23/100], Step [16800/6235], Loss: 0.9899\n",
      "Epoch [23/100], Step [16900/6235], Loss: 7.6958\n",
      "Epoch [23/100], Step [17000/6235], Loss: 0.8985\n",
      "Epoch [23/100], Step [17100/6235], Loss: 0.2375\n",
      "Epoch [23/100], Step [17200/6235], Loss: 74.4871\n",
      "Epoch [23/100], Step [17300/6235], Loss: 27.6629\n",
      "Epoch [23/100], Step [17400/6235], Loss: 46.7800\n",
      "Epoch [23/100], Step [17500/6235], Loss: 3.0223\n",
      "Epoch [23/100], Step [17600/6235], Loss: 0.3389\n",
      "Epoch [23/100], Step [17700/6235], Loss: 139.7846\n",
      "Epoch [23/100], Step [17800/6235], Loss: 6.0779\n",
      "Epoch [23/100], Step [17900/6235], Loss: 13.6980\n",
      "Epoch [23/100], Step [18000/6235], Loss: 0.6185\n",
      "Epoch [23/100], Step [18100/6235], Loss: 8.9897\n",
      "Epoch [23/100], Step [18200/6235], Loss: 5.3674\n",
      "Epoch [23/100], Step [18300/6235], Loss: 11.4340\n",
      "Epoch [23/100], Step [18400/6235], Loss: 0.6246\n",
      "Epoch [23/100], Step [18500/6235], Loss: 6.1202\n",
      "Epoch [23/100], Step [18600/6235], Loss: 0.1909\n",
      "Epoch [23/100], Step [18700/6235], Loss: 0.2676\n",
      "Epoch [23/100], Step [18800/6235], Loss: 53.2046\n",
      "Epoch [23/100], Step [18900/6235], Loss: 21.8012\n",
      "Epoch [23/100], Step [19000/6235], Loss: 7.0825\n",
      "Epoch [23/100], Step [19100/6235], Loss: 2.7668\n",
      "Epoch [23/100], Step [19200/6235], Loss: 4.5522\n",
      "Epoch [23/100], Step [19300/6235], Loss: 1.3778\n",
      "Epoch [23/100], Step [19400/6235], Loss: 213.6947\n",
      "Epoch [23/100], Step [19500/6235], Loss: 73.0695\n",
      "Epoch [23/100], Step [19600/6235], Loss: 81.5208\n",
      "Epoch [23/100], Step [19700/6235], Loss: 14.7843\n",
      "Epoch [23/100], Step [19800/6235], Loss: 2.1677\n",
      "Epoch [23/100], Step [19900/6235], Loss: 0.6551\n",
      "Epoch [23/100], Step [20000/6235], Loss: 3.8439\n",
      "Epoch [23/100], Step [20100/6235], Loss: 0.6500\n",
      "Epoch [23/100], Step [20200/6235], Loss: 0.3540\n",
      "Epoch [23/100], Step [20300/6235], Loss: 7.6031\n",
      "Epoch [23/100], Step [20400/6235], Loss: 10.4404\n",
      "Epoch [23/100], Step [20500/6235], Loss: 50.3815\n",
      "Epoch [23/100], Step [20600/6235], Loss: 29.1162\n",
      "Epoch [23/100], Step [20700/6235], Loss: 15.4166\n",
      "Epoch [23/100], Step [20800/6235], Loss: 10.0622\n",
      "Epoch [23/100], Step [20900/6235], Loss: 31.6731\n",
      "Epoch [23/100], Step [21000/6235], Loss: 9.8914\n",
      "Epoch [23/100], Step [21100/6235], Loss: 0.7495\n",
      "Epoch [23/100], Step [21200/6235], Loss: 0.2085\n",
      "Epoch [23/100], Step [21300/6235], Loss: 0.2345\n",
      "Epoch [23/100], Step [21400/6235], Loss: 4.4525\n",
      "Epoch [23/100], Step [21500/6235], Loss: 0.4018\n",
      "Epoch [23/100], Step [21600/6235], Loss: 2.0754\n",
      "Epoch [23/100], Step [21700/6235], Loss: 15.8135\n",
      "Epoch [23/100], Step [21800/6235], Loss: 0.2320\n",
      "Epoch [23/100], Step [21900/6235], Loss: 1.2573\n",
      "Epoch [23/100], Step [22000/6235], Loss: 7.9252\n",
      "Epoch [23/100], Step [22100/6235], Loss: 0.3116\n",
      "Epoch [23/100], Step [22200/6235], Loss: 2.7150\n",
      "Epoch [23/100], Step [22300/6235], Loss: 13.2286\n",
      "Epoch [23/100], Step [22400/6235], Loss: 2.4782\n",
      "Epoch [23/100], Step [22500/6235], Loss: 53.1228\n",
      "Epoch [23/100], Step [22600/6235], Loss: 17.7759\n",
      "Epoch [23/100], Step [22700/6235], Loss: 3.1016\n",
      "Epoch [23/100], Step [22800/6235], Loss: 9.5672\n",
      "Epoch [23/100], Step [22900/6235], Loss: 20.2367\n",
      "Epoch [23/100], Step [23000/6235], Loss: 11.5381\n",
      "Epoch [23/100], Step [23100/6235], Loss: 5.2666\n",
      "Epoch [23/100], Step [23200/6235], Loss: 0.4213\n",
      "Epoch [23/100], Step [23300/6235], Loss: 18.2188\n",
      "Epoch [23/100], Step [23400/6235], Loss: 2.2899\n",
      "Epoch [23/100], Step [23500/6235], Loss: 0.4651\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Step [23600/6235], Loss: 112.7017\n",
      "Epoch [23/100], Step [23700/6235], Loss: 5.5403\n",
      "Epoch [23/100], Step [23800/6235], Loss: 0.6651\n",
      "Epoch [23/100], Step [23900/6235], Loss: 2.9043\n",
      "Epoch [23/100], Step [24000/6235], Loss: 8.8627\n",
      "Epoch [23/100], Step [24100/6235], Loss: 3.4504\n",
      "Epoch [23/100], Step [24200/6235], Loss: 15.7779\n",
      "Epoch [23/100], Step [24300/6235], Loss: 0.8370\n",
      "Epoch [23/100], Step [24400/6235], Loss: 0.8581\n",
      "Epoch [23/100], Step [24500/6235], Loss: 2.9962\n",
      "Epoch [23/100], Step [24600/6235], Loss: 1.2382\n",
      "Epoch [23/100], Step [24700/6235], Loss: 0.1492\n",
      "Epoch [23/100], Step [24800/6235], Loss: 0.0873\n",
      "Epoch [23/100], Step [24900/6235], Loss: 6.1395\n",
      "Epoch [23/100], Step [25000/6235], Loss: 15.7797\n",
      "Epoch [23/100], Step [25100/6235], Loss: 15.1814\n",
      "Epoch [23/100], Step [25200/6235], Loss: 1.4867\n",
      "Epoch [23/100], Step [25300/6235], Loss: 6.1140\n",
      "Epoch [23/100], Step [25400/6235], Loss: 6.2514\n",
      "Epoch [23/100], Step [25500/6235], Loss: 4.3123\n",
      "Epoch [23/100], Step [25600/6235], Loss: 8.3438\n",
      "Epoch [23/100], Step [25700/6235], Loss: 3.8938\n",
      "Epoch [23/100], Step [25800/6235], Loss: 7.6781\n",
      "Epoch [23/100], Step [25900/6235], Loss: 0.4309\n",
      "Epoch [23/100], Step [26000/6235], Loss: 0.0305\n",
      "Epoch [23/100], Step [26100/6235], Loss: 1.0123\n",
      "Epoch [23/100], Step [26200/6235], Loss: 0.0159\n",
      "Epoch [23/100], Step [26300/6235], Loss: 1.0388\n",
      "Epoch [23/100], Step [26400/6235], Loss: 5.4439\n",
      "Epoch [23/100], Step [26500/6235], Loss: 0.0160\n",
      "Epoch [23/100], Step [26600/6235], Loss: 1.6761\n",
      "Epoch [23/100], Step [26700/6235], Loss: 0.1387\n",
      "Epoch [23/100], Step [26800/6235], Loss: 0.6238\n",
      "Epoch [23/100], Step [26900/6235], Loss: 0.0025\n",
      "Epoch [23/100], Step [27000/6235], Loss: 9.4581\n",
      "Epoch [23/100], Step [27100/6235], Loss: 0.0753\n",
      "Epoch [23/100], Step [27200/6235], Loss: 0.4624\n",
      "Epoch [23/100], Step [27300/6235], Loss: 0.1484\n",
      "Epoch [23/100], Step [27400/6235], Loss: 0.1452\n",
      "Epoch [23/100], Step [27500/6235], Loss: 12.6732\n",
      "Epoch [23/100], Step [27600/6235], Loss: 0.0748\n",
      "Epoch [23/100], Step [27700/6235], Loss: 0.8119\n",
      "Epoch [23/100], Step [27800/6235], Loss: 3.4462\n",
      "Epoch [23/100], Step [27900/6235], Loss: 1.2599\n",
      "Epoch [23/100], Step [28000/6235], Loss: 14.9774\n",
      "Epoch [23/100], Step [28100/6235], Loss: 1.3993\n",
      "Epoch [23/100], Step [28200/6235], Loss: 31.4664\n",
      "Epoch [23/100], Step [28300/6235], Loss: 2.4359\n",
      "Epoch [23/100], Step [28400/6235], Loss: 20.1930\n",
      "Epoch [23/100], Step [28500/6235], Loss: 4.2981\n",
      "Epoch [23/100], Step [28600/6235], Loss: 0.8626\n",
      "Epoch [23/100], Step [28700/6235], Loss: 2.7469\n",
      "Epoch [23/100], Step [28800/6235], Loss: 0.7600\n",
      "Epoch [23/100], Step [28900/6235], Loss: 23.9512\n",
      "Epoch [23/100], Step [29000/6235], Loss: 1.0635\n",
      "Epoch [23/100], Step [29100/6235], Loss: 3.0848\n",
      "Epoch [23/100], Step [29200/6235], Loss: 6.0382\n",
      "Epoch [23/100], Step [29300/6235], Loss: 2.2410\n",
      "Epoch [23/100], Step [29400/6235], Loss: 4.0158\n",
      "Epoch [23/100], Step [29500/6235], Loss: 1.2293\n",
      "Epoch [23/100], Step [29600/6235], Loss: 0.2951\n",
      "Epoch [23/100], Step [29700/6235], Loss: 2.4175\n",
      "Epoch [23/100], Step [29800/6235], Loss: 0.3137\n",
      "Epoch [23/100], Step [29900/6235], Loss: 3.9001\n",
      "Epoch [23/100], Step [30000/6235], Loss: 3.4391\n",
      "Epoch [23/100], Step [30100/6235], Loss: 5.7418\n",
      "Epoch [23/100], Step [30200/6235], Loss: 0.1259\n",
      "Epoch [23/100], Step [30300/6235], Loss: 0.7768\n",
      "Epoch [23/100], Step [30400/6235], Loss: 2.8064\n",
      "Epoch [23/100], Step [30500/6235], Loss: 0.2589\n",
      "Epoch [23/100], Step [30600/6235], Loss: 0.0194\n",
      "Epoch [23/100], Step [30700/6235], Loss: 3.0293\n",
      "Epoch [23/100], Step [30800/6235], Loss: 0.3548\n",
      "Epoch [23/100], Step [30900/6235], Loss: 0.6347\n",
      "Epoch [23/100], Step [31000/6235], Loss: 0.0184\n",
      "Epoch [23/100], Step [31100/6235], Loss: 2.6114\n",
      "Epoch [23/100], Step [31200/6235], Loss: 3.0571\n",
      "Epoch [23/100], Step [31300/6235], Loss: 1.3115\n",
      "Epoch [23/100], Step [31400/6235], Loss: 1.5841\n",
      "Epoch [23/100], Step [31500/6235], Loss: 0.7325\n",
      "Epoch [23/100], Step [31600/6235], Loss: 14.8940\n",
      "Epoch [23/100], Step [31700/6235], Loss: 0.6926\n",
      "Epoch [23/100], Step [31800/6235], Loss: 3.1567\n",
      "Epoch [23/100], Step [31900/6235], Loss: 33.8522\n",
      "Epoch [23/100], Step [32000/6235], Loss: 135.5206\n",
      "Epoch [23/100], Step [32100/6235], Loss: 7.5336\n",
      "Epoch [23/100], Step [32200/6235], Loss: 37.8571\n",
      "Epoch [23/100], Step [32300/6235], Loss: 0.3187\n",
      "Epoch [23/100], Step [32400/6235], Loss: 1.7396\n",
      "Epoch [23/100], Step [32500/6235], Loss: 6.0660\n",
      "Epoch [23/100], Step [32600/6235], Loss: 0.1454\n",
      "Epoch [23/100], Step [32700/6235], Loss: 81.1843\n",
      "Epoch [23/100], Step [32800/6235], Loss: 24.2014\n",
      "Epoch [23/100], Step [32900/6235], Loss: 8.2338\n",
      "Epoch [23/100], Step [33000/6235], Loss: 0.5302\n",
      "Epoch [23/100], Step [33100/6235], Loss: 1.2252\n",
      "Epoch [23/100], Step [33200/6235], Loss: 2.1391\n",
      "Epoch [23/100], Step [33300/6235], Loss: 8.2263\n",
      "Epoch [23/100], Step [33400/6235], Loss: 61.3906\n",
      "Epoch [23/100], Step [33500/6235], Loss: 0.4002\n",
      "Epoch [23/100], Step [33600/6235], Loss: 1.0480\n",
      "Epoch [23/100], Step [33700/6235], Loss: 2.5444\n",
      "Epoch [23/100], Step [33800/6235], Loss: 5.7575\n",
      "Epoch [23/100], Step [33900/6235], Loss: 26.1466\n",
      "Epoch [23/100], Step [34000/6235], Loss: 0.0088\n",
      "Epoch [23/100], Step [34100/6235], Loss: 0.0264\n",
      "Epoch [23/100], Step [34200/6235], Loss: 11.9872\n",
      "Epoch [23/100], Step [34300/6235], Loss: 4.0770\n",
      "Epoch [23/100], Step [34400/6235], Loss: 1.5821\n",
      "Epoch [23/100], Step [34500/6235], Loss: 116.8439\n",
      "Epoch [23/100], Step [34600/6235], Loss: 1.5832\n",
      "Epoch [23/100], Step [34700/6235], Loss: 7.5021\n",
      "Epoch [23/100], Step [34800/6235], Loss: 10.4244\n",
      "Epoch [23/100], Step [34900/6235], Loss: 69.6026\n",
      "Epoch [23/100], Step [35000/6235], Loss: 0.1784\n",
      "Epoch [23/100], Step [35100/6235], Loss: 1.1287\n",
      "Epoch [23/100], Step [35200/6235], Loss: 0.5860\n",
      "Epoch [23/100], Step [35300/6235], Loss: 2.6909\n",
      "Epoch [23/100], Step [35400/6235], Loss: 0.3765\n",
      "Epoch [23/100], Step [35500/6235], Loss: 2.7416\n",
      "Epoch [23/100], Step [35600/6235], Loss: 5.7180\n",
      "Epoch [23/100], Step [35700/6235], Loss: 3.6860\n",
      "Epoch [23/100], Step [35800/6235], Loss: 1.3036\n",
      "Epoch [23/100], Step [35900/6235], Loss: 0.2068\n",
      "Epoch [23/100], Step [36000/6235], Loss: 2.2144\n",
      "Epoch [23/100], Step [36100/6235], Loss: 0.1471\n",
      "Epoch [23/100], Step [36200/6235], Loss: 3.2304\n",
      "Epoch [23/100], Step [36300/6235], Loss: 0.7927\n",
      "Epoch [23/100], Step [36400/6235], Loss: 1.4009\n",
      "Epoch [23/100], Step [36500/6235], Loss: 9.4169\n",
      "Epoch [23/100], Step [36600/6235], Loss: 0.1146\n",
      "Epoch [23/100], Step [36700/6235], Loss: 0.0938\n",
      "Epoch [23/100], Step [36800/6235], Loss: 22.8534\n",
      "Epoch [23/100], Step [36900/6235], Loss: 2.9109\n",
      "Epoch [23/100], Step [37000/6235], Loss: 0.0672\n",
      "Epoch [23/100], Step [37100/6235], Loss: 0.3551\n",
      "Epoch [23/100], Step [37200/6235], Loss: 0.0565\n",
      "Epoch [23/100], Step [37300/6235], Loss: 0.1547\n",
      "Epoch [23/100], Step [37400/6235], Loss: 0.1976\n",
      "Epoch [23/100], Step [37500/6235], Loss: 2.7498\n",
      "Epoch [23/100], Step [37600/6235], Loss: 9.9437\n",
      "Epoch [23/100], Step [37700/6235], Loss: 0.1617\n",
      "Epoch [23/100], Step [37800/6235], Loss: 9.8656\n",
      "Epoch [23/100], Step [37900/6235], Loss: 0.0478\n",
      "Epoch [23/100], Step [38000/6235], Loss: 0.1870\n",
      "Epoch [23/100], Step [38100/6235], Loss: 4.2340\n",
      "Epoch [23/100], Step [38200/6235], Loss: 2.1643\n",
      "Epoch [23/100], Step [38300/6235], Loss: 4.7304\n",
      "Epoch [23/100], Step [38400/6235], Loss: 0.0642\n",
      "Epoch [23/100], Step [38500/6235], Loss: 5.6217\n",
      "Epoch [23/100], Step [38600/6235], Loss: 0.9208\n",
      "Epoch [23/100], Step [38700/6235], Loss: 0.1667\n",
      "Epoch [23/100], Step [38800/6235], Loss: 0.7665\n",
      "Epoch [23/100], Step [38900/6235], Loss: 5.2613\n",
      "Epoch [23/100], Step [39000/6235], Loss: 18.0181\n",
      "Epoch [23/100], Step [39100/6235], Loss: 23.9515\n",
      "Epoch [23/100], Step [39200/6235], Loss: 0.8425\n",
      "Epoch [23/100], Step [39300/6235], Loss: 2.1319\n",
      "Epoch [23/100], Step [39400/6235], Loss: 227.4533\n",
      "Epoch [23/100], Step [39500/6235], Loss: 245.7807\n",
      "Epoch [23/100], Step [39600/6235], Loss: 14.4081\n",
      "Epoch [23/100], Step [39700/6235], Loss: 62.2876\n",
      "Epoch [23/100], Step [39800/6235], Loss: 16.3251\n",
      "Epoch [23/100], Step [39900/6235], Loss: 0.5917\n",
      "Epoch [23/100], Step [40000/6235], Loss: 14.6306\n",
      "Epoch [23/100], Step [40100/6235], Loss: 29.4707\n",
      "Epoch [23/100], Step [40200/6235], Loss: 2.1099\n",
      "Epoch [23/100], Step [40300/6235], Loss: 0.2693\n",
      "Epoch [23/100], Step [40400/6235], Loss: 2.2476\n",
      "Epoch [23/100], Step [40500/6235], Loss: 2.3408\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [23/100], Step [40600/6235], Loss: 0.2254\n",
      "Epoch [23/100], Step [40700/6235], Loss: 7.7171\n",
      "Epoch [23/100], Step [40800/6235], Loss: 1.6425\n",
      "Epoch [23/100], Step [40900/6235], Loss: 0.0777\n",
      "Epoch [23/100], Step [41000/6235], Loss: 33.6636\n",
      "Epoch [23/100], Step [41100/6235], Loss: 27.6035\n",
      "Epoch [23/100], Step [41200/6235], Loss: 13.2722\n",
      "Epoch [23/100], Step [41300/6235], Loss: 6.8159\n",
      "Epoch [23/100], Step [41400/6235], Loss: 3.3208\n",
      "Epoch [23/100], Step [41500/6235], Loss: 0.0830\n",
      "Epoch [23/100], Step [41600/6235], Loss: 0.2575\n",
      "Epoch [23/100], Step [41700/6235], Loss: 1.6528\n",
      "Epoch [23/100], Step [41800/6235], Loss: 0.9291\n",
      "Epoch [23/100], Step [41900/6235], Loss: 0.1649\n",
      "Epoch [23/100], Step [42000/6235], Loss: 5.2247\n",
      "Epoch [23/100], Step [42100/6235], Loss: 1.1474\n",
      "Epoch [23/100], Step [42200/6235], Loss: 47.6309\n",
      "Epoch [23/100], Step [42300/6235], Loss: 0.5023\n",
      "Epoch [23/100], Step [42400/6235], Loss: 1.9589\n",
      "Epoch [23/100], Step [42500/6235], Loss: 2.2523\n",
      "Epoch [23/100], Step [42600/6235], Loss: 0.4165\n",
      "Epoch [23/100], Step [42700/6235], Loss: 0.1664\n",
      "Epoch [23/100], Step [42800/6235], Loss: 0.1756\n",
      "Epoch [23/100], Step [42900/6235], Loss: 4.0878\n",
      "Epoch [23/100], Step [43000/6235], Loss: 0.2289\n",
      "Epoch [23/100], Step [43100/6235], Loss: 1.9496\n",
      "Epoch [23/100], Step [43200/6235], Loss: 0.4224\n",
      "Epoch [23/100], Step [43300/6235], Loss: 10.6388\n",
      "Epoch [23/100], Step [43400/6235], Loss: 7.3927\n",
      "Epoch [23/100], Step [43500/6235], Loss: 8.4562\n",
      "Epoch [23/100], Step [43600/6235], Loss: 29.5982\n",
      "Epoch [23/100], Step [43700/6235], Loss: 39.8088\n",
      "Epoch [23/100], Step [43800/6235], Loss: 0.5126\n",
      "Epoch [23/100], Step [43900/6235], Loss: 0.9323\n",
      "Epoch [23/100], Step [44000/6235], Loss: 57.1808\n",
      "Epoch [23/100], Step [44100/6235], Loss: 3.2308\n",
      "Epoch [23/100], Step [44200/6235], Loss: 36.3317\n",
      "Epoch [23/100], Step [44300/6235], Loss: 8.0238\n",
      "Epoch [23/100], Step [44400/6235], Loss: 0.7199\n",
      "Epoch [23/100], Step [44500/6235], Loss: 1.2809\n",
      "Epoch [23/100], Step [44600/6235], Loss: 26.2017\n",
      "Epoch [23/100], Step [44700/6235], Loss: 7.9687\n",
      "Epoch [23/100], Step [44800/6235], Loss: 5.0842\n",
      "Epoch [23/100], Step [44900/6235], Loss: 3.5670\n",
      "Epoch [23/100], Step [45000/6235], Loss: 4.9111\n",
      "Epoch [23/100], Step [45100/6235], Loss: 59.3409\n",
      "Epoch [23/100], Step [45200/6235], Loss: 0.6082\n",
      "Epoch [23/100], Step [45300/6235], Loss: 29.9480\n",
      "Epoch [23/100], Step [45400/6235], Loss: 12.1729\n",
      "Epoch [23/100], Step [45500/6235], Loss: 0.4669\n",
      "Epoch [23/100], Step [45600/6235], Loss: 0.1769\n",
      "Epoch [23/100], Step [45700/6235], Loss: 87.9710\n",
      "Epoch [23/100], Step [45800/6235], Loss: 346.8692\n",
      "Epoch [23/100], Step [45900/6235], Loss: 13.1875\n",
      "Epoch [23/100], Step [46000/6235], Loss: 30.2357\n",
      "Epoch [23/100], Step [46100/6235], Loss: 46.6546\n",
      "Epoch [23/100], Step [46200/6235], Loss: 21.0742\n",
      "Epoch [23/100], Step [46300/6235], Loss: 14.7343\n",
      "Epoch [23/100], Step [46400/6235], Loss: 13.6304\n",
      "Epoch [23/100], Step [46500/6235], Loss: 7.5820\n",
      "Epoch [23/100], Step [46600/6235], Loss: 26.6367\n",
      "Epoch [23/100], Step [46700/6235], Loss: 11.9985\n",
      "Epoch [23/100], Step [46800/6235], Loss: 0.7916\n",
      "Epoch [23/100], Step [46900/6235], Loss: 2.9787\n",
      "Epoch [23/100], Step [47000/6235], Loss: 6.9244\n",
      "Epoch [23/100], Step [47100/6235], Loss: 1.1427\n",
      "Epoch [23/100], Step [47200/6235], Loss: 6.4490\n",
      "Epoch [23/100], Step [47300/6235], Loss: 0.6596\n",
      "Epoch [23/100], Step [47400/6235], Loss: 11.6034\n",
      "Epoch [23/100], Step [47500/6235], Loss: 1.9030\n",
      "Epoch [23/100], Step [47600/6235], Loss: 1.1805\n",
      "Epoch [23/100], Step [47700/6235], Loss: 4.2401\n",
      "Epoch [23/100], Step [47800/6235], Loss: 1.4736\n",
      "Epoch [23/100], Step [47900/6235], Loss: 19.9370\n",
      "Epoch [23/100], Step [48000/6235], Loss: 145.3453\n",
      "Epoch [23/100], Step [48100/6235], Loss: 4.0635\n",
      "Epoch [23/100], Step [48200/6235], Loss: 3.2869\n",
      "Epoch [23/100], Step [48300/6235], Loss: 238.7673\n",
      "Epoch [23/100], Step [48400/6235], Loss: 30.9316\n",
      "Epoch [23/100], Step [48500/6235], Loss: 10.3536\n",
      "Epoch [23/100], Step [48600/6235], Loss: 153.7313\n",
      "Epoch [23/100], Step [48700/6235], Loss: 63.0037\n",
      "Epoch [23/100], Step [48800/6235], Loss: 339.8923\n",
      "Epoch [23/100], Step [48900/6235], Loss: 163.0856\n",
      "Epoch [23/100], Step [49000/6235], Loss: 261.7932\n",
      "Epoch [23/100], Step [49100/6235], Loss: 1042.7777\n",
      "Epoch [23/100], Step [49200/6235], Loss: 736.3740\n",
      "Epoch [23/100], Step [49300/6235], Loss: 1207.2039\n",
      "Epoch [23/100], Step [49400/6235], Loss: 2.0054\n",
      "Epoch [23/100], Step [49500/6235], Loss: 40.4099\n",
      "Epoch [23/100], Step [49600/6235], Loss: 85.2354\n",
      "Epoch [23/100], Step [49700/6235], Loss: 3319.6191\n",
      "Epoch [23/100], Step [49800/6235], Loss: 63.3041\n",
      "Epoch [24/100], Step [100/6235], Loss: 17.8203\n",
      "Epoch [24/100], Step [200/6235], Loss: 0.1949\n",
      "Epoch [24/100], Step [300/6235], Loss: 0.0149\n",
      "Epoch [24/100], Step [400/6235], Loss: 0.0032\n",
      "Epoch [24/100], Step [500/6235], Loss: 2.4963\n",
      "Epoch [24/100], Step [600/6235], Loss: 0.0569\n",
      "Epoch [24/100], Step [700/6235], Loss: 0.5038\n",
      "Epoch [24/100], Step [800/6235], Loss: 0.1288\n",
      "Epoch [24/100], Step [900/6235], Loss: 0.0227\n",
      "Epoch [24/100], Step [1000/6235], Loss: 0.0298\n",
      "Epoch [24/100], Step [1100/6235], Loss: 0.0124\n",
      "Epoch [24/100], Step [1200/6235], Loss: 0.1882\n",
      "Epoch [24/100], Step [1300/6235], Loss: 0.0369\n",
      "Epoch [24/100], Step [1400/6235], Loss: 0.0286\n",
      "Epoch [24/100], Step [1500/6235], Loss: 0.0072\n",
      "Epoch [24/100], Step [1600/6235], Loss: 0.2203\n",
      "Epoch [24/100], Step [1700/6235], Loss: 0.0078\n",
      "Epoch [24/100], Step [1800/6235], Loss: 0.2062\n",
      "Epoch [24/100], Step [1900/6235], Loss: 0.5734\n",
      "Epoch [24/100], Step [2000/6235], Loss: 2.2197\n",
      "Epoch [24/100], Step [2100/6235], Loss: 1.0391\n",
      "Epoch [24/100], Step [2200/6235], Loss: 9.8598\n",
      "Epoch [24/100], Step [2300/6235], Loss: 13.3747\n",
      "Epoch [24/100], Step [2400/6235], Loss: 5.3035\n",
      "Epoch [24/100], Step [2500/6235], Loss: 36.6554\n",
      "Epoch [24/100], Step [2600/6235], Loss: 9.9538\n",
      "Epoch [24/100], Step [2700/6235], Loss: 19.1714\n",
      "Epoch [24/100], Step [2800/6235], Loss: 250.3359\n",
      "Epoch [24/100], Step [2900/6235], Loss: 6.4981\n",
      "Epoch [24/100], Step [3000/6235], Loss: 0.2782\n",
      "Epoch [24/100], Step [3100/6235], Loss: 63.5120\n",
      "Epoch [24/100], Step [3200/6235], Loss: 85.2377\n",
      "Epoch [24/100], Step [3300/6235], Loss: 1.4914\n",
      "Epoch [24/100], Step [3400/6235], Loss: 3.0487\n",
      "Epoch [24/100], Step [3500/6235], Loss: 31.1542\n",
      "Epoch [24/100], Step [3600/6235], Loss: 10.1571\n",
      "Epoch [24/100], Step [3700/6235], Loss: 0.9819\n",
      "Epoch [24/100], Step [3800/6235], Loss: 0.5610\n",
      "Epoch [24/100], Step [3900/6235], Loss: 1.8727\n",
      "Epoch [24/100], Step [4000/6235], Loss: 0.0707\n",
      "Epoch [24/100], Step [4100/6235], Loss: 4.7280\n",
      "Epoch [24/100], Step [4200/6235], Loss: 0.2075\n",
      "Epoch [24/100], Step [4300/6235], Loss: 10.2312\n",
      "Epoch [24/100], Step [4400/6235], Loss: 4.1594\n",
      "Epoch [24/100], Step [4500/6235], Loss: 52.8037\n",
      "Epoch [24/100], Step [4600/6235], Loss: 8.3207\n",
      "Epoch [24/100], Step [4700/6235], Loss: 1.4541\n",
      "Epoch [24/100], Step [4800/6235], Loss: 1.8331\n",
      "Epoch [24/100], Step [4900/6235], Loss: 0.0807\n",
      "Epoch [24/100], Step [5000/6235], Loss: 0.2701\n",
      "Epoch [24/100], Step [5100/6235], Loss: 2.2631\n",
      "Epoch [24/100], Step [5200/6235], Loss: 1.3704\n",
      "Epoch [24/100], Step [5300/6235], Loss: 32.7621\n",
      "Epoch [24/100], Step [5400/6235], Loss: 1.3181\n",
      "Epoch [24/100], Step [5500/6235], Loss: 0.2446\n",
      "Epoch [24/100], Step [5600/6235], Loss: 0.3840\n",
      "Epoch [24/100], Step [5700/6235], Loss: 1.9961\n",
      "Epoch [24/100], Step [5800/6235], Loss: 1.1241\n",
      "Epoch [24/100], Step [5900/6235], Loss: 0.0414\n",
      "Epoch [24/100], Step [6000/6235], Loss: 0.4507\n",
      "Epoch [24/100], Step [6100/6235], Loss: 0.0906\n",
      "Epoch [24/100], Step [6200/6235], Loss: 0.8052\n",
      "Epoch [24/100], Step [6300/6235], Loss: 1.4026\n",
      "Epoch [24/100], Step [6400/6235], Loss: 0.0526\n",
      "Epoch [24/100], Step [6500/6235], Loss: 0.4302\n",
      "Epoch [24/100], Step [6600/6235], Loss: 2.0340\n",
      "Epoch [24/100], Step [6700/6235], Loss: 0.6922\n",
      "Epoch [24/100], Step [6800/6235], Loss: 0.7044\n",
      "Epoch [24/100], Step [6900/6235], Loss: 2.9213\n",
      "Epoch [24/100], Step [7000/6235], Loss: 0.6424\n",
      "Epoch [24/100], Step [7100/6235], Loss: 0.2691\n",
      "Epoch [24/100], Step [7200/6235], Loss: 0.1041\n",
      "Epoch [24/100], Step [7300/6235], Loss: 1.9489\n",
      "Epoch [24/100], Step [7400/6235], Loss: 0.1641\n",
      "Epoch [24/100], Step [7500/6235], Loss: 1.9114\n",
      "Epoch [24/100], Step [7600/6235], Loss: 18.9947\n",
      "Epoch [24/100], Step [7700/6235], Loss: 9.8900\n",
      "Epoch [24/100], Step [7800/6235], Loss: 14.2995\n",
      "Epoch [24/100], Step [7900/6235], Loss: 16.9828\n",
      "Epoch [24/100], Step [8000/6235], Loss: 0.5637\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Step [8100/6235], Loss: 3.5377\n",
      "Epoch [24/100], Step [8200/6235], Loss: 23.4542\n",
      "Epoch [24/100], Step [8300/6235], Loss: 57.9159\n",
      "Epoch [24/100], Step [8400/6235], Loss: 35.1136\n",
      "Epoch [24/100], Step [8500/6235], Loss: 76.0635\n",
      "Epoch [24/100], Step [8600/6235], Loss: 0.7602\n",
      "Epoch [24/100], Step [8700/6235], Loss: 45.7214\n",
      "Epoch [24/100], Step [8800/6235], Loss: 188.0251\n",
      "Epoch [24/100], Step [8900/6235], Loss: 28.7715\n",
      "Epoch [24/100], Step [9000/6235], Loss: 256.3949\n",
      "Epoch [24/100], Step [9100/6235], Loss: 1700.3961\n",
      "Epoch [24/100], Step [9200/6235], Loss: 4666.0625\n",
      "Epoch [24/100], Step [9300/6235], Loss: 61.3398\n",
      "Epoch [24/100], Step [9400/6235], Loss: 9.5124\n",
      "Epoch [24/100], Step [9500/6235], Loss: 162.2366\n",
      "Epoch [24/100], Step [9600/6235], Loss: 327.5335\n",
      "Epoch [24/100], Step [9700/6235], Loss: 11.1022\n",
      "Epoch [24/100], Step [9800/6235], Loss: 259.7918\n",
      "Epoch [24/100], Step [9900/6235], Loss: 5.9337\n",
      "Epoch [24/100], Step [10000/6235], Loss: 11.5319\n",
      "Epoch [24/100], Step [10100/6235], Loss: 2.7055\n",
      "Epoch [24/100], Step [10200/6235], Loss: 568.8818\n",
      "Epoch [24/100], Step [10300/6235], Loss: 4.5927\n",
      "Epoch [24/100], Step [10400/6235], Loss: 7.3486\n",
      "Epoch [24/100], Step [10500/6235], Loss: 14.7688\n",
      "Epoch [24/100], Step [10600/6235], Loss: 1685.4761\n",
      "Epoch [24/100], Step [10700/6235], Loss: 25.0109\n",
      "Epoch [24/100], Step [10800/6235], Loss: 84.8458\n",
      "Epoch [24/100], Step [10900/6235], Loss: 14.8171\n",
      "Epoch [24/100], Step [11000/6235], Loss: 252.0423\n",
      "Epoch [24/100], Step [11100/6235], Loss: 39.4389\n",
      "Epoch [24/100], Step [11200/6235], Loss: 40.4753\n",
      "Epoch [24/100], Step [11300/6235], Loss: 185.1874\n",
      "Epoch [24/100], Step [11400/6235], Loss: 5.8317\n",
      "Epoch [24/100], Step [11500/6235], Loss: 0.8502\n",
      "Epoch [24/100], Step [11600/6235], Loss: 2.7273\n",
      "Epoch [24/100], Step [11700/6235], Loss: 78.1949\n",
      "Epoch [24/100], Step [11800/6235], Loss: 6.6275\n",
      "Epoch [24/100], Step [11900/6235], Loss: 207.0459\n",
      "Epoch [24/100], Step [12000/6235], Loss: 290.0045\n",
      "Epoch [24/100], Step [12100/6235], Loss: 281.9836\n",
      "Epoch [24/100], Step [12200/6235], Loss: 9.1373\n",
      "Epoch [24/100], Step [12300/6235], Loss: 2.0296\n",
      "Epoch [24/100], Step [12400/6235], Loss: 504.4901\n",
      "Epoch [24/100], Step [12500/6235], Loss: 108.6039\n",
      "Epoch [24/100], Step [12600/6235], Loss: 4.4028\n",
      "Epoch [24/100], Step [12700/6235], Loss: 23.6575\n",
      "Epoch [24/100], Step [12800/6235], Loss: 26.5505\n",
      "Epoch [24/100], Step [12900/6235], Loss: 50.1451\n",
      "Epoch [24/100], Step [13000/6235], Loss: 0.0893\n",
      "Epoch [24/100], Step [13100/6235], Loss: 67.1973\n",
      "Epoch [24/100], Step [13200/6235], Loss: 8.2089\n",
      "Epoch [24/100], Step [13300/6235], Loss: 19.7127\n",
      "Epoch [24/100], Step [13400/6235], Loss: 152.7559\n",
      "Epoch [24/100], Step [13500/6235], Loss: 0.4269\n",
      "Epoch [24/100], Step [13600/6235], Loss: 8.8895\n",
      "Epoch [24/100], Step [13700/6235], Loss: 9.7169\n",
      "Epoch [24/100], Step [13800/6235], Loss: 112.1785\n",
      "Epoch [24/100], Step [13900/6235], Loss: 42.0791\n",
      "Epoch [24/100], Step [14000/6235], Loss: 0.6039\n",
      "Epoch [24/100], Step [14100/6235], Loss: 37.9145\n",
      "Epoch [24/100], Step [14200/6235], Loss: 105.0119\n",
      "Epoch [24/100], Step [14300/6235], Loss: 15.5062\n",
      "Epoch [24/100], Step [14400/6235], Loss: 26.6464\n",
      "Epoch [24/100], Step [14500/6235], Loss: 56.6666\n",
      "Epoch [24/100], Step [14600/6235], Loss: 0.0985\n",
      "Epoch [24/100], Step [14700/6235], Loss: 44.8659\n",
      "Epoch [24/100], Step [14800/6235], Loss: 26.8022\n",
      "Epoch [24/100], Step [14900/6235], Loss: 2.3735\n",
      "Epoch [24/100], Step [15000/6235], Loss: 4.5217\n",
      "Epoch [24/100], Step [15100/6235], Loss: 0.1250\n",
      "Epoch [24/100], Step [15200/6235], Loss: 10.2495\n",
      "Epoch [24/100], Step [15300/6235], Loss: 48.6661\n",
      "Epoch [24/100], Step [15400/6235], Loss: 6.5374\n",
      "Epoch [24/100], Step [15500/6235], Loss: 4.7700\n",
      "Epoch [24/100], Step [15600/6235], Loss: 312.5943\n",
      "Epoch [24/100], Step [15700/6235], Loss: 138.9156\n",
      "Epoch [24/100], Step [15800/6235], Loss: 5.7537\n",
      "Epoch [24/100], Step [15900/6235], Loss: 2.3681\n",
      "Epoch [24/100], Step [16000/6235], Loss: 4.7408\n",
      "Epoch [24/100], Step [16100/6235], Loss: 0.6637\n",
      "Epoch [24/100], Step [16200/6235], Loss: 10.2297\n",
      "Epoch [24/100], Step [16300/6235], Loss: 13.4078\n",
      "Epoch [24/100], Step [16400/6235], Loss: 25.3300\n",
      "Epoch [24/100], Step [16500/6235], Loss: 444.7251\n",
      "Epoch [24/100], Step [16600/6235], Loss: 38.4781\n",
      "Epoch [24/100], Step [16700/6235], Loss: 0.6870\n",
      "Epoch [24/100], Step [16800/6235], Loss: 7.9517\n",
      "Epoch [24/100], Step [16900/6235], Loss: 2.6743\n",
      "Epoch [24/100], Step [17000/6235], Loss: 0.2669\n",
      "Epoch [24/100], Step [17100/6235], Loss: 0.5904\n",
      "Epoch [24/100], Step [17200/6235], Loss: 126.8961\n",
      "Epoch [24/100], Step [17300/6235], Loss: 64.7281\n",
      "Epoch [24/100], Step [17400/6235], Loss: 41.9746\n",
      "Epoch [24/100], Step [17500/6235], Loss: 5.7707\n",
      "Epoch [24/100], Step [17600/6235], Loss: 2.0294\n",
      "Epoch [24/100], Step [17700/6235], Loss: 35.1925\n",
      "Epoch [24/100], Step [17800/6235], Loss: 30.5677\n",
      "Epoch [24/100], Step [17900/6235], Loss: 12.6453\n",
      "Epoch [24/100], Step [18000/6235], Loss: 6.0467\n",
      "Epoch [24/100], Step [18100/6235], Loss: 6.9670\n",
      "Epoch [24/100], Step [18200/6235], Loss: 1.6565\n",
      "Epoch [24/100], Step [18300/6235], Loss: 2.9837\n",
      "Epoch [24/100], Step [18400/6235], Loss: 0.9980\n",
      "Epoch [24/100], Step [18500/6235], Loss: 0.4536\n",
      "Epoch [24/100], Step [18600/6235], Loss: 2.8612\n",
      "Epoch [24/100], Step [18700/6235], Loss: 0.6811\n",
      "Epoch [24/100], Step [18800/6235], Loss: 47.7713\n",
      "Epoch [24/100], Step [18900/6235], Loss: 0.6234\n",
      "Epoch [24/100], Step [19000/6235], Loss: 17.7578\n",
      "Epoch [24/100], Step [19100/6235], Loss: 6.9114\n",
      "Epoch [24/100], Step [19200/6235], Loss: 4.2113\n",
      "Epoch [24/100], Step [19300/6235], Loss: 3.9035\n",
      "Epoch [24/100], Step [19400/6235], Loss: 204.7245\n",
      "Epoch [24/100], Step [19500/6235], Loss: 38.3848\n",
      "Epoch [24/100], Step [19600/6235], Loss: 55.3965\n",
      "Epoch [24/100], Step [19700/6235], Loss: 17.0716\n",
      "Epoch [24/100], Step [19800/6235], Loss: 8.7239\n",
      "Epoch [24/100], Step [19900/6235], Loss: 0.4564\n",
      "Epoch [24/100], Step [20000/6235], Loss: 13.1230\n",
      "Epoch [24/100], Step [20100/6235], Loss: 3.2924\n",
      "Epoch [24/100], Step [20200/6235], Loss: 10.8002\n",
      "Epoch [24/100], Step [20300/6235], Loss: 2.0094\n",
      "Epoch [24/100], Step [20400/6235], Loss: 2.8505\n",
      "Epoch [24/100], Step [20500/6235], Loss: 64.1733\n",
      "Epoch [24/100], Step [20600/6235], Loss: 78.9901\n",
      "Epoch [24/100], Step [20700/6235], Loss: 26.0338\n",
      "Epoch [24/100], Step [20800/6235], Loss: 1.5268\n",
      "Epoch [24/100], Step [20900/6235], Loss: 26.0007\n",
      "Epoch [24/100], Step [21000/6235], Loss: 17.9895\n",
      "Epoch [24/100], Step [21100/6235], Loss: 7.5362\n",
      "Epoch [24/100], Step [21200/6235], Loss: 0.3237\n",
      "Epoch [24/100], Step [21300/6235], Loss: 0.1630\n",
      "Epoch [24/100], Step [21400/6235], Loss: 0.4162\n",
      "Epoch [24/100], Step [21500/6235], Loss: 0.7591\n",
      "Epoch [24/100], Step [21600/6235], Loss: 1.4692\n",
      "Epoch [24/100], Step [21700/6235], Loss: 1.1611\n",
      "Epoch [24/100], Step [21800/6235], Loss: 0.3676\n",
      "Epoch [24/100], Step [21900/6235], Loss: 0.3790\n",
      "Epoch [24/100], Step [22000/6235], Loss: 3.6767\n",
      "Epoch [24/100], Step [22100/6235], Loss: 3.2388\n",
      "Epoch [24/100], Step [22200/6235], Loss: 9.2771\n",
      "Epoch [24/100], Step [22300/6235], Loss: 4.3382\n",
      "Epoch [24/100], Step [22400/6235], Loss: 0.7603\n",
      "Epoch [24/100], Step [22500/6235], Loss: 173.6209\n",
      "Epoch [24/100], Step [22600/6235], Loss: 20.6166\n",
      "Epoch [24/100], Step [22700/6235], Loss: 2.6613\n",
      "Epoch [24/100], Step [22800/6235], Loss: 7.4688\n",
      "Epoch [24/100], Step [22900/6235], Loss: 18.0965\n",
      "Epoch [24/100], Step [23000/6235], Loss: 17.3843\n",
      "Epoch [24/100], Step [23100/6235], Loss: 4.4052\n",
      "Epoch [24/100], Step [23200/6235], Loss: 23.5669\n",
      "Epoch [24/100], Step [23300/6235], Loss: 16.4232\n",
      "Epoch [24/100], Step [23400/6235], Loss: 2.6966\n",
      "Epoch [24/100], Step [23500/6235], Loss: 0.5308\n",
      "Epoch [24/100], Step [23600/6235], Loss: 119.5943\n",
      "Epoch [24/100], Step [23700/6235], Loss: 4.6463\n",
      "Epoch [24/100], Step [23800/6235], Loss: 0.6961\n",
      "Epoch [24/100], Step [23900/6235], Loss: 1.0458\n",
      "Epoch [24/100], Step [24000/6235], Loss: 7.7474\n",
      "Epoch [24/100], Step [24100/6235], Loss: 5.1032\n",
      "Epoch [24/100], Step [24200/6235], Loss: 36.4184\n",
      "Epoch [24/100], Step [24300/6235], Loss: 0.7602\n",
      "Epoch [24/100], Step [24400/6235], Loss: 1.0649\n",
      "Epoch [24/100], Step [24500/6235], Loss: 4.9905\n",
      "Epoch [24/100], Step [24600/6235], Loss: 1.8882\n",
      "Epoch [24/100], Step [24700/6235], Loss: 0.2044\n",
      "Epoch [24/100], Step [24800/6235], Loss: 0.3056\n",
      "Epoch [24/100], Step [24900/6235], Loss: 6.4447\n",
      "Epoch [24/100], Step [25000/6235], Loss: 7.2611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Step [25100/6235], Loss: 14.9742\n",
      "Epoch [24/100], Step [25200/6235], Loss: 0.6096\n",
      "Epoch [24/100], Step [25300/6235], Loss: 5.7478\n",
      "Epoch [24/100], Step [25400/6235], Loss: 7.6730\n",
      "Epoch [24/100], Step [25500/6235], Loss: 7.9521\n",
      "Epoch [24/100], Step [25600/6235], Loss: 10.1284\n",
      "Epoch [24/100], Step [25700/6235], Loss: 2.5455\n",
      "Epoch [24/100], Step [25800/6235], Loss: 5.7844\n",
      "Epoch [24/100], Step [25900/6235], Loss: 0.5908\n",
      "Epoch [24/100], Step [26000/6235], Loss: 0.5825\n",
      "Epoch [24/100], Step [26100/6235], Loss: 1.0673\n",
      "Epoch [24/100], Step [26200/6235], Loss: 0.0198\n",
      "Epoch [24/100], Step [26300/6235], Loss: 1.8211\n",
      "Epoch [24/100], Step [26400/6235], Loss: 4.8642\n",
      "Epoch [24/100], Step [26500/6235], Loss: 0.0306\n",
      "Epoch [24/100], Step [26600/6235], Loss: 1.3011\n",
      "Epoch [24/100], Step [26700/6235], Loss: 0.1410\n",
      "Epoch [24/100], Step [26800/6235], Loss: 0.6091\n",
      "Epoch [24/100], Step [26900/6235], Loss: 0.0140\n",
      "Epoch [24/100], Step [27000/6235], Loss: 9.8172\n",
      "Epoch [24/100], Step [27100/6235], Loss: 0.0443\n",
      "Epoch [24/100], Step [27200/6235], Loss: 0.5111\n",
      "Epoch [24/100], Step [27300/6235], Loss: 0.0347\n",
      "Epoch [24/100], Step [27400/6235], Loss: 0.1749\n",
      "Epoch [24/100], Step [27500/6235], Loss: 0.3149\n",
      "Epoch [24/100], Step [27600/6235], Loss: 0.0167\n",
      "Epoch [24/100], Step [27700/6235], Loss: 0.8089\n",
      "Epoch [24/100], Step [27800/6235], Loss: 4.1710\n",
      "Epoch [24/100], Step [27900/6235], Loss: 1.8656\n",
      "Epoch [24/100], Step [28000/6235], Loss: 107.0031\n",
      "Epoch [24/100], Step [28100/6235], Loss: 5.5799\n",
      "Epoch [24/100], Step [28200/6235], Loss: 38.6478\n",
      "Epoch [24/100], Step [28300/6235], Loss: 1.8002\n",
      "Epoch [24/100], Step [28400/6235], Loss: 20.7064\n",
      "Epoch [24/100], Step [28500/6235], Loss: 1.9221\n",
      "Epoch [24/100], Step [28600/6235], Loss: 1.8878\n",
      "Epoch [24/100], Step [28700/6235], Loss: 1.9555\n",
      "Epoch [24/100], Step [28800/6235], Loss: 0.9402\n",
      "Epoch [24/100], Step [28900/6235], Loss: 20.1014\n",
      "Epoch [24/100], Step [29000/6235], Loss: 1.1662\n",
      "Epoch [24/100], Step [29100/6235], Loss: 1.6328\n",
      "Epoch [24/100], Step [29200/6235], Loss: 5.6363\n",
      "Epoch [24/100], Step [29300/6235], Loss: 1.4414\n",
      "Epoch [24/100], Step [29400/6235], Loss: 0.0956\n",
      "Epoch [24/100], Step [29500/6235], Loss: 1.1479\n",
      "Epoch [24/100], Step [29600/6235], Loss: 0.6412\n",
      "Epoch [24/100], Step [29700/6235], Loss: 2.3611\n",
      "Epoch [24/100], Step [29800/6235], Loss: 0.2031\n",
      "Epoch [24/100], Step [29900/6235], Loss: 4.6051\n",
      "Epoch [24/100], Step [30000/6235], Loss: 1.6592\n",
      "Epoch [24/100], Step [30100/6235], Loss: 2.1312\n",
      "Epoch [24/100], Step [30200/6235], Loss: 0.0832\n",
      "Epoch [24/100], Step [30300/6235], Loss: 1.0283\n",
      "Epoch [24/100], Step [30400/6235], Loss: 6.3254\n",
      "Epoch [24/100], Step [30500/6235], Loss: 0.6183\n",
      "Epoch [24/100], Step [30600/6235], Loss: 0.3054\n",
      "Epoch [24/100], Step [30700/6235], Loss: 2.8792\n",
      "Epoch [24/100], Step [30800/6235], Loss: 0.3485\n",
      "Epoch [24/100], Step [30900/6235], Loss: 0.3739\n",
      "Epoch [24/100], Step [31000/6235], Loss: 0.0640\n",
      "Epoch [24/100], Step [31100/6235], Loss: 2.8690\n",
      "Epoch [24/100], Step [31200/6235], Loss: 2.4087\n",
      "Epoch [24/100], Step [31300/6235], Loss: 1.1818\n",
      "Epoch [24/100], Step [31400/6235], Loss: 0.6499\n",
      "Epoch [24/100], Step [31500/6235], Loss: 0.7326\n",
      "Epoch [24/100], Step [31600/6235], Loss: 11.4563\n",
      "Epoch [24/100], Step [31700/6235], Loss: 5.3385\n",
      "Epoch [24/100], Step [31800/6235], Loss: 0.5357\n",
      "Epoch [24/100], Step [31900/6235], Loss: 1813.3041\n",
      "Epoch [24/100], Step [32000/6235], Loss: 123.4533\n",
      "Epoch [24/100], Step [32100/6235], Loss: 2.5276\n",
      "Epoch [24/100], Step [32200/6235], Loss: 148.4053\n",
      "Epoch [24/100], Step [32300/6235], Loss: 0.7354\n",
      "Epoch [24/100], Step [32400/6235], Loss: 0.6999\n",
      "Epoch [24/100], Step [32500/6235], Loss: 2.4052\n",
      "Epoch [24/100], Step [32600/6235], Loss: 0.0078\n",
      "Epoch [24/100], Step [32700/6235], Loss: 114.9876\n",
      "Epoch [24/100], Step [32800/6235], Loss: 50.4680\n",
      "Epoch [24/100], Step [32900/6235], Loss: 1.4764\n",
      "Epoch [24/100], Step [33000/6235], Loss: 0.9455\n",
      "Epoch [24/100], Step [33100/6235], Loss: 0.8738\n",
      "Epoch [24/100], Step [33200/6235], Loss: 2.3108\n",
      "Epoch [24/100], Step [33300/6235], Loss: 0.0980\n",
      "Epoch [24/100], Step [33400/6235], Loss: 14.2287\n",
      "Epoch [24/100], Step [33500/6235], Loss: 1.5974\n",
      "Epoch [24/100], Step [33600/6235], Loss: 5.5939\n",
      "Epoch [24/100], Step [33700/6235], Loss: 6.7149\n",
      "Epoch [24/100], Step [33800/6235], Loss: 1.3830\n",
      "Epoch [24/100], Step [33900/6235], Loss: 25.2860\n",
      "Epoch [24/100], Step [34000/6235], Loss: 0.0666\n",
      "Epoch [24/100], Step [34100/6235], Loss: 0.1030\n",
      "Epoch [24/100], Step [34200/6235], Loss: 0.4380\n",
      "Epoch [24/100], Step [34300/6235], Loss: 7.8656\n",
      "Epoch [24/100], Step [34400/6235], Loss: 0.1388\n",
      "Epoch [24/100], Step [34500/6235], Loss: 164.0680\n",
      "Epoch [24/100], Step [34600/6235], Loss: 1.0321\n",
      "Epoch [24/100], Step [34700/6235], Loss: 65.0584\n",
      "Epoch [24/100], Step [34800/6235], Loss: 13.8107\n",
      "Epoch [24/100], Step [34900/6235], Loss: 53.9630\n",
      "Epoch [24/100], Step [35000/6235], Loss: 0.4545\n",
      "Epoch [24/100], Step [35100/6235], Loss: 0.4626\n",
      "Epoch [24/100], Step [35200/6235], Loss: 0.1809\n",
      "Epoch [24/100], Step [35300/6235], Loss: 2.4293\n",
      "Epoch [24/100], Step [35400/6235], Loss: 0.4257\n",
      "Epoch [24/100], Step [35500/6235], Loss: 1.8233\n",
      "Epoch [24/100], Step [35600/6235], Loss: 9.0594\n",
      "Epoch [24/100], Step [35700/6235], Loss: 4.1005\n",
      "Epoch [24/100], Step [35800/6235], Loss: 10.5905\n",
      "Epoch [24/100], Step [35900/6235], Loss: 3.9691\n",
      "Epoch [24/100], Step [36000/6235], Loss: 1.5803\n",
      "Epoch [24/100], Step [36100/6235], Loss: 0.0610\n",
      "Epoch [24/100], Step [36200/6235], Loss: 17.4570\n",
      "Epoch [24/100], Step [36300/6235], Loss: 1.1377\n",
      "Epoch [24/100], Step [36400/6235], Loss: 2.4883\n",
      "Epoch [24/100], Step [36500/6235], Loss: 8.5953\n",
      "Epoch [24/100], Step [36600/6235], Loss: 0.1634\n",
      "Epoch [24/100], Step [36700/6235], Loss: 0.3713\n",
      "Epoch [24/100], Step [36800/6235], Loss: 13.7737\n",
      "Epoch [24/100], Step [36900/6235], Loss: 4.6941\n",
      "Epoch [24/100], Step [37000/6235], Loss: 0.3998\n",
      "Epoch [24/100], Step [37100/6235], Loss: 0.9009\n",
      "Epoch [24/100], Step [37200/6235], Loss: 0.0803\n",
      "Epoch [24/100], Step [37300/6235], Loss: 0.0546\n",
      "Epoch [24/100], Step [37400/6235], Loss: 0.2057\n",
      "Epoch [24/100], Step [37500/6235], Loss: 3.7334\n",
      "Epoch [24/100], Step [37600/6235], Loss: 11.0856\n",
      "Epoch [24/100], Step [37700/6235], Loss: 0.2569\n",
      "Epoch [24/100], Step [37800/6235], Loss: 9.3070\n",
      "Epoch [24/100], Step [37900/6235], Loss: 6.9018\n",
      "Epoch [24/100], Step [38000/6235], Loss: 0.2474\n",
      "Epoch [24/100], Step [38100/6235], Loss: 4.2657\n",
      "Epoch [24/100], Step [38200/6235], Loss: 1.7543\n",
      "Epoch [24/100], Step [38300/6235], Loss: 2.9328\n",
      "Epoch [24/100], Step [38400/6235], Loss: 0.2061\n",
      "Epoch [24/100], Step [38500/6235], Loss: 3.9647\n",
      "Epoch [24/100], Step [38600/6235], Loss: 0.0446\n",
      "Epoch [24/100], Step [38700/6235], Loss: 0.0420\n",
      "Epoch [24/100], Step [38800/6235], Loss: 0.3770\n",
      "Epoch [24/100], Step [38900/6235], Loss: 4.9290\n",
      "Epoch [24/100], Step [39000/6235], Loss: 7.8049\n",
      "Epoch [24/100], Step [39100/6235], Loss: 17.3662\n",
      "Epoch [24/100], Step [39200/6235], Loss: 0.6783\n",
      "Epoch [24/100], Step [39300/6235], Loss: 30.4028\n",
      "Epoch [24/100], Step [39400/6235], Loss: 206.7604\n",
      "Epoch [24/100], Step [39500/6235], Loss: 383.5998\n",
      "Epoch [24/100], Step [39600/6235], Loss: 23.4239\n",
      "Epoch [24/100], Step [39700/6235], Loss: 626.4437\n",
      "Epoch [24/100], Step [39800/6235], Loss: 11.0258\n",
      "Epoch [24/100], Step [39900/6235], Loss: 0.3968\n",
      "Epoch [24/100], Step [40000/6235], Loss: 12.4922\n",
      "Epoch [24/100], Step [40100/6235], Loss: 16.4858\n",
      "Epoch [24/100], Step [40200/6235], Loss: 5.6537\n",
      "Epoch [24/100], Step [40300/6235], Loss: 0.8722\n",
      "Epoch [24/100], Step [40400/6235], Loss: 1.4181\n",
      "Epoch [24/100], Step [40500/6235], Loss: 2.8921\n",
      "Epoch [24/100], Step [40600/6235], Loss: 0.2314\n",
      "Epoch [24/100], Step [40700/6235], Loss: 6.4715\n",
      "Epoch [24/100], Step [40800/6235], Loss: 0.5153\n",
      "Epoch [24/100], Step [40900/6235], Loss: 0.9342\n",
      "Epoch [24/100], Step [41000/6235], Loss: 47.5230\n",
      "Epoch [24/100], Step [41100/6235], Loss: 28.8837\n",
      "Epoch [24/100], Step [41200/6235], Loss: 7.5385\n",
      "Epoch [24/100], Step [41300/6235], Loss: 2.6031\n",
      "Epoch [24/100], Step [41400/6235], Loss: 2.3468\n",
      "Epoch [24/100], Step [41500/6235], Loss: 0.5211\n",
      "Epoch [24/100], Step [41600/6235], Loss: 0.3466\n",
      "Epoch [24/100], Step [41700/6235], Loss: 3.1878\n",
      "Epoch [24/100], Step [41800/6235], Loss: 4.0449\n",
      "Epoch [24/100], Step [41900/6235], Loss: 3.1538\n",
      "Epoch [24/100], Step [42000/6235], Loss: 2.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [24/100], Step [42100/6235], Loss: 6.5323\n",
      "Epoch [24/100], Step [42200/6235], Loss: 9.6829\n",
      "Epoch [24/100], Step [42300/6235], Loss: 1.9317\n",
      "Epoch [24/100], Step [42400/6235], Loss: 6.3943\n",
      "Epoch [24/100], Step [42500/6235], Loss: 0.3930\n",
      "Epoch [24/100], Step [42600/6235], Loss: 1.9312\n",
      "Epoch [24/100], Step [42700/6235], Loss: 0.7012\n",
      "Epoch [24/100], Step [42800/6235], Loss: 4.7353\n",
      "Epoch [24/100], Step [42900/6235], Loss: 3.1180\n",
      "Epoch [24/100], Step [43000/6235], Loss: 0.1909\n",
      "Epoch [24/100], Step [43100/6235], Loss: 0.2124\n",
      "Epoch [24/100], Step [43200/6235], Loss: 1.0834\n",
      "Epoch [24/100], Step [43300/6235], Loss: 8.3104\n",
      "Epoch [24/100], Step [43400/6235], Loss: 10.4694\n",
      "Epoch [24/100], Step [43500/6235], Loss: 9.7505\n",
      "Epoch [24/100], Step [43600/6235], Loss: 8.8921\n",
      "Epoch [24/100], Step [43700/6235], Loss: 48.6879\n",
      "Epoch [24/100], Step [43800/6235], Loss: 0.3846\n",
      "Epoch [24/100], Step [43900/6235], Loss: 2.7701\n",
      "Epoch [24/100], Step [44000/6235], Loss: 81.7495\n",
      "Epoch [24/100], Step [44100/6235], Loss: 1.7161\n",
      "Epoch [24/100], Step [44200/6235], Loss: 2.5667\n",
      "Epoch [24/100], Step [44300/6235], Loss: 5.4978\n",
      "Epoch [24/100], Step [44400/6235], Loss: 0.9126\n",
      "Epoch [24/100], Step [44500/6235], Loss: 4.5033\n",
      "Epoch [24/100], Step [44600/6235], Loss: 22.6058\n",
      "Epoch [24/100], Step [44700/6235], Loss: 0.4189\n",
      "Epoch [24/100], Step [44800/6235], Loss: 1.3965\n",
      "Epoch [24/100], Step [44900/6235], Loss: 12.0842\n",
      "Epoch [24/100], Step [45000/6235], Loss: 6.4608\n",
      "Epoch [24/100], Step [45100/6235], Loss: 76.1008\n",
      "Epoch [24/100], Step [45200/6235], Loss: 5.1541\n",
      "Epoch [24/100], Step [45300/6235], Loss: 23.9238\n",
      "Epoch [24/100], Step [45400/6235], Loss: 5.7614\n",
      "Epoch [24/100], Step [45500/6235], Loss: 3.0229\n",
      "Epoch [24/100], Step [45600/6235], Loss: 1.1174\n",
      "Epoch [24/100], Step [45700/6235], Loss: 117.8544\n",
      "Epoch [24/100], Step [45800/6235], Loss: 332.4004\n",
      "Epoch [24/100], Step [45900/6235], Loss: 112.8824\n",
      "Epoch [24/100], Step [46000/6235], Loss: 16.2158\n",
      "Epoch [24/100], Step [46100/6235], Loss: 115.5098\n",
      "Epoch [24/100], Step [46200/6235], Loss: 67.9835\n",
      "Epoch [24/100], Step [46300/6235], Loss: 33.6648\n",
      "Epoch [24/100], Step [46400/6235], Loss: 9.2442\n",
      "Epoch [24/100], Step [46500/6235], Loss: 76.7410\n",
      "Epoch [24/100], Step [46600/6235], Loss: 13.7180\n",
      "Epoch [24/100], Step [46700/6235], Loss: 37.7892\n",
      "Epoch [24/100], Step [46800/6235], Loss: 14.5828\n",
      "Epoch [24/100], Step [46900/6235], Loss: 0.4938\n",
      "Epoch [24/100], Step [47000/6235], Loss: 8.3471\n",
      "Epoch [24/100], Step [47100/6235], Loss: 19.2831\n",
      "Epoch [24/100], Step [47200/6235], Loss: 5.5909\n",
      "Epoch [24/100], Step [47300/6235], Loss: 1.1986\n",
      "Epoch [24/100], Step [47400/6235], Loss: 72.7403\n",
      "Epoch [24/100], Step [47500/6235], Loss: 6.1314\n",
      "Epoch [24/100], Step [47600/6235], Loss: 1.1865\n",
      "Epoch [24/100], Step [47700/6235], Loss: 5.4960\n",
      "Epoch [24/100], Step [47800/6235], Loss: 1.0676\n",
      "Epoch [24/100], Step [47900/6235], Loss: 16.1375\n",
      "Epoch [24/100], Step [48000/6235], Loss: 118.4032\n",
      "Epoch [24/100], Step [48100/6235], Loss: 2.9865\n",
      "Epoch [24/100], Step [48200/6235], Loss: 9.5110\n",
      "Epoch [24/100], Step [48300/6235], Loss: 185.5197\n",
      "Epoch [24/100], Step [48400/6235], Loss: 31.5621\n",
      "Epoch [24/100], Step [48500/6235], Loss: 10.6339\n",
      "Epoch [24/100], Step [48600/6235], Loss: 160.1548\n",
      "Epoch [24/100], Step [48700/6235], Loss: 52.9086\n",
      "Epoch [24/100], Step [48800/6235], Loss: 349.0531\n",
      "Epoch [24/100], Step [48900/6235], Loss: 198.6129\n",
      "Epoch [24/100], Step [49000/6235], Loss: 270.5876\n",
      "Epoch [24/100], Step [49100/6235], Loss: 2201.7964\n",
      "Epoch [24/100], Step [49200/6235], Loss: 739.1453\n",
      "Epoch [24/100], Step [49300/6235], Loss: 1072.8046\n",
      "Epoch [24/100], Step [49400/6235], Loss: 325.4534\n",
      "Epoch [24/100], Step [49500/6235], Loss: 3.5154\n",
      "Epoch [24/100], Step [49600/6235], Loss: 22.5123\n",
      "Epoch [24/100], Step [49700/6235], Loss: 6991.5298\n",
      "Epoch [24/100], Step [49800/6235], Loss: 1077.5428\n",
      "Epoch [25/100], Step [100/6235], Loss: 33.7563\n",
      "Epoch [25/100], Step [200/6235], Loss: 0.1096\n",
      "Epoch [25/100], Step [300/6235], Loss: 0.0071\n",
      "Epoch [25/100], Step [400/6235], Loss: 0.0021\n",
      "Epoch [25/100], Step [500/6235], Loss: 2.3491\n",
      "Epoch [25/100], Step [600/6235], Loss: 0.0329\n",
      "Epoch [25/100], Step [700/6235], Loss: 0.3798\n",
      "Epoch [25/100], Step [800/6235], Loss: 0.1253\n",
      "Epoch [25/100], Step [900/6235], Loss: 0.0554\n",
      "Epoch [25/100], Step [1000/6235], Loss: 0.0279\n",
      "Epoch [25/100], Step [1100/6235], Loss: 0.0664\n",
      "Epoch [25/100], Step [1200/6235], Loss: 0.1602\n",
      "Epoch [25/100], Step [1300/6235], Loss: 0.0498\n",
      "Epoch [25/100], Step [1400/6235], Loss: 0.0892\n",
      "Epoch [25/100], Step [1500/6235], Loss: 0.0047\n",
      "Epoch [25/100], Step [1600/6235], Loss: 0.2152\n",
      "Epoch [25/100], Step [1700/6235], Loss: 0.0030\n",
      "Epoch [25/100], Step [1800/6235], Loss: 0.1843\n",
      "Epoch [25/100], Step [1900/6235], Loss: 0.7963\n",
      "Epoch [25/100], Step [2000/6235], Loss: 2.2064\n",
      "Epoch [25/100], Step [2100/6235], Loss: 0.7879\n",
      "Epoch [25/100], Step [2200/6235], Loss: 10.4201\n",
      "Epoch [25/100], Step [2300/6235], Loss: 17.8585\n",
      "Epoch [25/100], Step [2400/6235], Loss: 9.0574\n",
      "Epoch [25/100], Step [2500/6235], Loss: 39.0195\n",
      "Epoch [25/100], Step [2600/6235], Loss: 9.0288\n",
      "Epoch [25/100], Step [2700/6235], Loss: 26.2497\n",
      "Epoch [25/100], Step [2800/6235], Loss: 47.0260\n",
      "Epoch [25/100], Step [2900/6235], Loss: 6.2762\n",
      "Epoch [25/100], Step [3000/6235], Loss: 0.8048\n",
      "Epoch [25/100], Step [3100/6235], Loss: 55.3188\n",
      "Epoch [25/100], Step [3200/6235], Loss: 76.1673\n",
      "Epoch [25/100], Step [3300/6235], Loss: 0.3209\n",
      "Epoch [25/100], Step [3400/6235], Loss: 2.8859\n",
      "Epoch [25/100], Step [3500/6235], Loss: 32.0441\n",
      "Epoch [25/100], Step [3600/6235], Loss: 10.3895\n",
      "Epoch [25/100], Step [3700/6235], Loss: 1.4052\n",
      "Epoch [25/100], Step [3800/6235], Loss: 0.5183\n",
      "Epoch [25/100], Step [3900/6235], Loss: 0.9280\n",
      "Epoch [25/100], Step [4000/6235], Loss: 0.1382\n",
      "Epoch [25/100], Step [4100/6235], Loss: 3.5158\n",
      "Epoch [25/100], Step [4200/6235], Loss: 0.3605\n",
      "Epoch [25/100], Step [4300/6235], Loss: 8.6226\n",
      "Epoch [25/100], Step [4400/6235], Loss: 1.9060\n",
      "Epoch [25/100], Step [4500/6235], Loss: 64.8524\n",
      "Epoch [25/100], Step [4600/6235], Loss: 12.1039\n",
      "Epoch [25/100], Step [4700/6235], Loss: 2.1711\n",
      "Epoch [25/100], Step [4800/6235], Loss: 0.6064\n",
      "Epoch [25/100], Step [4900/6235], Loss: 0.0808\n",
      "Epoch [25/100], Step [5000/6235], Loss: 0.7341\n",
      "Epoch [25/100], Step [5100/6235], Loss: 0.9176\n",
      "Epoch [25/100], Step [5200/6235], Loss: 3.7319\n",
      "Epoch [25/100], Step [5300/6235], Loss: 34.0285\n",
      "Epoch [25/100], Step [5400/6235], Loss: 2.0095\n",
      "Epoch [25/100], Step [5500/6235], Loss: 0.2087\n",
      "Epoch [25/100], Step [5600/6235], Loss: 0.0815\n",
      "Epoch [25/100], Step [5700/6235], Loss: 0.8231\n",
      "Epoch [25/100], Step [5800/6235], Loss: 1.2017\n",
      "Epoch [25/100], Step [5900/6235], Loss: 0.5378\n",
      "Epoch [25/100], Step [6000/6235], Loss: 0.3657\n",
      "Epoch [25/100], Step [6100/6235], Loss: 0.1018\n",
      "Epoch [25/100], Step [6200/6235], Loss: 0.3546\n",
      "Epoch [25/100], Step [6300/6235], Loss: 0.3140\n",
      "Epoch [25/100], Step [6400/6235], Loss: 0.1422\n",
      "Epoch [25/100], Step [6500/6235], Loss: 0.8275\n",
      "Epoch [25/100], Step [6600/6235], Loss: 0.5755\n",
      "Epoch [25/100], Step [6700/6235], Loss: 0.5716\n",
      "Epoch [25/100], Step [6800/6235], Loss: 0.4392\n",
      "Epoch [25/100], Step [6900/6235], Loss: 2.2981\n",
      "Epoch [25/100], Step [7000/6235], Loss: 0.0769\n",
      "Epoch [25/100], Step [7100/6235], Loss: 0.1208\n",
      "Epoch [25/100], Step [7200/6235], Loss: 1.7976\n",
      "Epoch [25/100], Step [7300/6235], Loss: 1.5974\n",
      "Epoch [25/100], Step [7400/6235], Loss: 0.0302\n",
      "Epoch [25/100], Step [7500/6235], Loss: 14.3237\n",
      "Epoch [25/100], Step [7600/6235], Loss: 12.0098\n",
      "Epoch [25/100], Step [7700/6235], Loss: 3.9835\n",
      "Epoch [25/100], Step [7800/6235], Loss: 0.8645\n",
      "Epoch [25/100], Step [7900/6235], Loss: 10.9165\n",
      "Epoch [25/100], Step [8000/6235], Loss: 0.9722\n",
      "Epoch [25/100], Step [8100/6235], Loss: 3.3425\n",
      "Epoch [25/100], Step [8200/6235], Loss: 24.4078\n",
      "Epoch [25/100], Step [8300/6235], Loss: 43.3681\n",
      "Epoch [25/100], Step [8400/6235], Loss: 19.9043\n",
      "Epoch [25/100], Step [8500/6235], Loss: 19.3812\n",
      "Epoch [25/100], Step [8600/6235], Loss: 8.9354\n",
      "Epoch [25/100], Step [8700/6235], Loss: 5.1341\n",
      "Epoch [25/100], Step [8800/6235], Loss: 715.1630\n",
      "Epoch [25/100], Step [8900/6235], Loss: 14.2038\n",
      "Epoch [25/100], Step [9000/6235], Loss: 502.0766\n",
      "Epoch [25/100], Step [9100/6235], Loss: 299.2898\n",
      "Epoch [25/100], Step [9200/6235], Loss: 3537.4893\n",
      "Epoch [25/100], Step [9300/6235], Loss: 42.3503\n",
      "Epoch [25/100], Step [9400/6235], Loss: 142.7102\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Step [9500/6235], Loss: 9.7467\n",
      "Epoch [25/100], Step [9600/6235], Loss: 142.7048\n",
      "Epoch [25/100], Step [9700/6235], Loss: 35.1618\n",
      "Epoch [25/100], Step [9800/6235], Loss: 555.1743\n",
      "Epoch [25/100], Step [9900/6235], Loss: 9.0286\n",
      "Epoch [25/100], Step [10000/6235], Loss: 33.8752\n",
      "Epoch [25/100], Step [10100/6235], Loss: 5.1547\n",
      "Epoch [25/100], Step [10200/6235], Loss: 460.4604\n",
      "Epoch [25/100], Step [10300/6235], Loss: 1.5574\n",
      "Epoch [25/100], Step [10400/6235], Loss: 2.5399\n",
      "Epoch [25/100], Step [10500/6235], Loss: 4.1816\n",
      "Epoch [25/100], Step [10600/6235], Loss: 2107.1887\n",
      "Epoch [25/100], Step [10700/6235], Loss: 62.4345\n",
      "Epoch [25/100], Step [10800/6235], Loss: 48.9196\n",
      "Epoch [25/100], Step [10900/6235], Loss: 11.3681\n",
      "Epoch [25/100], Step [11000/6235], Loss: 240.0200\n",
      "Epoch [25/100], Step [11100/6235], Loss: 37.8349\n",
      "Epoch [25/100], Step [11200/6235], Loss: 43.9798\n",
      "Epoch [25/100], Step [11300/6235], Loss: 191.1262\n",
      "Epoch [25/100], Step [11400/6235], Loss: 13.5734\n",
      "Epoch [25/100], Step [11500/6235], Loss: 0.9167\n",
      "Epoch [25/100], Step [11600/6235], Loss: 2.8286\n",
      "Epoch [25/100], Step [11700/6235], Loss: 83.7738\n",
      "Epoch [25/100], Step [11800/6235], Loss: 32.0028\n",
      "Epoch [25/100], Step [11900/6235], Loss: 876.9220\n",
      "Epoch [25/100], Step [12000/6235], Loss: 267.6490\n",
      "Epoch [25/100], Step [12100/6235], Loss: 328.6464\n",
      "Epoch [25/100], Step [12200/6235], Loss: 12.9745\n",
      "Epoch [25/100], Step [12300/6235], Loss: 2.2140\n",
      "Epoch [25/100], Step [12400/6235], Loss: 136.3962\n",
      "Epoch [25/100], Step [12500/6235], Loss: 211.4873\n",
      "Epoch [25/100], Step [12600/6235], Loss: 2.0656\n",
      "Epoch [25/100], Step [12700/6235], Loss: 21.8425\n",
      "Epoch [25/100], Step [12800/6235], Loss: 14.0819\n",
      "Epoch [25/100], Step [12900/6235], Loss: 52.8590\n",
      "Epoch [25/100], Step [13000/6235], Loss: 0.0858\n",
      "Epoch [25/100], Step [13100/6235], Loss: 71.8553\n",
      "Epoch [25/100], Step [13200/6235], Loss: 10.2046\n",
      "Epoch [25/100], Step [13300/6235], Loss: 17.0532\n",
      "Epoch [25/100], Step [13400/6235], Loss: 132.2652\n",
      "Epoch [25/100], Step [13500/6235], Loss: 15.3867\n",
      "Epoch [25/100], Step [13600/6235], Loss: 0.4631\n",
      "Epoch [25/100], Step [13700/6235], Loss: 89.8665\n",
      "Epoch [25/100], Step [13800/6235], Loss: 147.7386\n",
      "Epoch [25/100], Step [13900/6235], Loss: 61.1147\n",
      "Epoch [25/100], Step [14000/6235], Loss: 1.3684\n",
      "Epoch [25/100], Step [14100/6235], Loss: 172.6715\n",
      "Epoch [25/100], Step [14200/6235], Loss: 103.3887\n",
      "Epoch [25/100], Step [14300/6235], Loss: 5.8183\n",
      "Epoch [25/100], Step [14400/6235], Loss: 36.5109\n",
      "Epoch [25/100], Step [14500/6235], Loss: 51.2593\n",
      "Epoch [25/100], Step [14600/6235], Loss: 0.1083\n",
      "Epoch [25/100], Step [14700/6235], Loss: 45.7985\n",
      "Epoch [25/100], Step [14800/6235], Loss: 30.2816\n",
      "Epoch [25/100], Step [14900/6235], Loss: 1.6001\n",
      "Epoch [25/100], Step [15000/6235], Loss: 3.1632\n",
      "Epoch [25/100], Step [15100/6235], Loss: 0.2271\n",
      "Epoch [25/100], Step [15200/6235], Loss: 11.7852\n",
      "Epoch [25/100], Step [15300/6235], Loss: 71.4223\n",
      "Epoch [25/100], Step [15400/6235], Loss: 1.2568\n",
      "Epoch [25/100], Step [15500/6235], Loss: 19.7128\n",
      "Epoch [25/100], Step [15600/6235], Loss: 213.9139\n",
      "Epoch [25/100], Step [15700/6235], Loss: 17.8930\n",
      "Epoch [25/100], Step [15800/6235], Loss: 10.6941\n",
      "Epoch [25/100], Step [15900/6235], Loss: 0.3069\n",
      "Epoch [25/100], Step [16000/6235], Loss: 31.9866\n",
      "Epoch [25/100], Step [16100/6235], Loss: 1.8448\n",
      "Epoch [25/100], Step [16200/6235], Loss: 11.4700\n",
      "Epoch [25/100], Step [16300/6235], Loss: 13.6531\n",
      "Epoch [25/100], Step [16400/6235], Loss: 25.2646\n",
      "Epoch [25/100], Step [16500/6235], Loss: 433.4471\n",
      "Epoch [25/100], Step [16600/6235], Loss: 26.5690\n",
      "Epoch [25/100], Step [16700/6235], Loss: 0.7339\n",
      "Epoch [25/100], Step [16800/6235], Loss: 8.2874\n",
      "Epoch [25/100], Step [16900/6235], Loss: 2.7571\n",
      "Epoch [25/100], Step [17000/6235], Loss: 0.2525\n",
      "Epoch [25/100], Step [17100/6235], Loss: 0.6464\n",
      "Epoch [25/100], Step [17200/6235], Loss: 129.1344\n",
      "Epoch [25/100], Step [17300/6235], Loss: 56.3892\n",
      "Epoch [25/100], Step [17400/6235], Loss: 44.1597\n",
      "Epoch [25/100], Step [17500/6235], Loss: 2.8726\n",
      "Epoch [25/100], Step [17600/6235], Loss: 1.9270\n",
      "Epoch [25/100], Step [17700/6235], Loss: 7.5737\n",
      "Epoch [25/100], Step [17800/6235], Loss: 33.3415\n",
      "Epoch [25/100], Step [17900/6235], Loss: 15.0458\n",
      "Epoch [25/100], Step [18000/6235], Loss: 0.9779\n",
      "Epoch [25/100], Step [18100/6235], Loss: 14.8615\n",
      "Epoch [25/100], Step [18200/6235], Loss: 0.5474\n",
      "Epoch [25/100], Step [18300/6235], Loss: 3.9331\n",
      "Epoch [25/100], Step [18400/6235], Loss: 5.5720\n",
      "Epoch [25/100], Step [18500/6235], Loss: 2.7242\n",
      "Epoch [25/100], Step [18600/6235], Loss: 2.7379\n",
      "Epoch [25/100], Step [18700/6235], Loss: 0.5506\n",
      "Epoch [25/100], Step [18800/6235], Loss: 37.4439\n",
      "Epoch [25/100], Step [18900/6235], Loss: 2.9828\n",
      "Epoch [25/100], Step [19000/6235], Loss: 5.1001\n",
      "Epoch [25/100], Step [19100/6235], Loss: 1.3244\n",
      "Epoch [25/100], Step [19200/6235], Loss: 6.5588\n",
      "Epoch [25/100], Step [19300/6235], Loss: 6.4334\n",
      "Epoch [25/100], Step [19400/6235], Loss: 61.7291\n",
      "Epoch [25/100], Step [19500/6235], Loss: 172.7098\n",
      "Epoch [25/100], Step [19600/6235], Loss: 108.1195\n",
      "Epoch [25/100], Step [19700/6235], Loss: 30.8371\n",
      "Epoch [25/100], Step [19800/6235], Loss: 2.5418\n",
      "Epoch [25/100], Step [19900/6235], Loss: 0.1673\n",
      "Epoch [25/100], Step [20000/6235], Loss: 8.5397\n",
      "Epoch [25/100], Step [20100/6235], Loss: 0.1582\n",
      "Epoch [25/100], Step [20200/6235], Loss: 1.4746\n",
      "Epoch [25/100], Step [20300/6235], Loss: 3.0237\n",
      "Epoch [25/100], Step [20400/6235], Loss: 14.6954\n",
      "Epoch [25/100], Step [20500/6235], Loss: 52.8036\n",
      "Epoch [25/100], Step [20600/6235], Loss: 107.9824\n",
      "Epoch [25/100], Step [20700/6235], Loss: 2.5278\n",
      "Epoch [25/100], Step [20800/6235], Loss: 3.8609\n",
      "Epoch [25/100], Step [20900/6235], Loss: 6.7452\n",
      "Epoch [25/100], Step [21000/6235], Loss: 13.1811\n",
      "Epoch [25/100], Step [21100/6235], Loss: 4.3982\n",
      "Epoch [25/100], Step [21200/6235], Loss: 0.3413\n",
      "Epoch [25/100], Step [21300/6235], Loss: 0.0522\n",
      "Epoch [25/100], Step [21400/6235], Loss: 5.1526\n",
      "Epoch [25/100], Step [21500/6235], Loss: 1.2147\n",
      "Epoch [25/100], Step [21600/6235], Loss: 4.3798\n",
      "Epoch [25/100], Step [21700/6235], Loss: 12.7698\n",
      "Epoch [25/100], Step [21800/6235], Loss: 18.8194\n",
      "Epoch [25/100], Step [21900/6235], Loss: 0.1433\n",
      "Epoch [25/100], Step [22000/6235], Loss: 0.1239\n",
      "Epoch [25/100], Step [22100/6235], Loss: 7.5022\n",
      "Epoch [25/100], Step [22200/6235], Loss: 0.6738\n",
      "Epoch [25/100], Step [22300/6235], Loss: 2.8001\n",
      "Epoch [25/100], Step [22400/6235], Loss: 0.2505\n",
      "Epoch [25/100], Step [22500/6235], Loss: 24.0868\n",
      "Epoch [25/100], Step [22600/6235], Loss: 21.4336\n",
      "Epoch [25/100], Step [22700/6235], Loss: 1.8933\n",
      "Epoch [25/100], Step [22800/6235], Loss: 4.1496\n",
      "Epoch [25/100], Step [22900/6235], Loss: 9.4094\n",
      "Epoch [25/100], Step [23000/6235], Loss: 21.2858\n",
      "Epoch [25/100], Step [23100/6235], Loss: 10.5632\n",
      "Epoch [25/100], Step [23200/6235], Loss: 11.2673\n",
      "Epoch [25/100], Step [23300/6235], Loss: 18.9041\n",
      "Epoch [25/100], Step [23400/6235], Loss: 2.6161\n",
      "Epoch [25/100], Step [23500/6235], Loss: 0.0839\n",
      "Epoch [25/100], Step [23600/6235], Loss: 133.0139\n",
      "Epoch [25/100], Step [23700/6235], Loss: 5.5689\n",
      "Epoch [25/100], Step [23800/6235], Loss: 0.7761\n",
      "Epoch [25/100], Step [23900/6235], Loss: 1.5806\n",
      "Epoch [25/100], Step [24000/6235], Loss: 1.5777\n",
      "Epoch [25/100], Step [24100/6235], Loss: 0.7032\n",
      "Epoch [25/100], Step [24200/6235], Loss: 12.6940\n",
      "Epoch [25/100], Step [24300/6235], Loss: 0.4803\n",
      "Epoch [25/100], Step [24400/6235], Loss: 0.0274\n",
      "Epoch [25/100], Step [24500/6235], Loss: 4.7343\n",
      "Epoch [25/100], Step [24600/6235], Loss: 1.3007\n",
      "Epoch [25/100], Step [24700/6235], Loss: 0.0317\n",
      "Epoch [25/100], Step [24800/6235], Loss: 0.2170\n",
      "Epoch [25/100], Step [24900/6235], Loss: 11.7647\n",
      "Epoch [25/100], Step [25000/6235], Loss: 8.1486\n",
      "Epoch [25/100], Step [25100/6235], Loss: 11.3239\n",
      "Epoch [25/100], Step [25200/6235], Loss: 0.3323\n",
      "Epoch [25/100], Step [25300/6235], Loss: 4.4056\n",
      "Epoch [25/100], Step [25400/6235], Loss: 2.2280\n",
      "Epoch [25/100], Step [25500/6235], Loss: 9.3603\n",
      "Epoch [25/100], Step [25600/6235], Loss: 10.4858\n",
      "Epoch [25/100], Step [25700/6235], Loss: 0.5153\n",
      "Epoch [25/100], Step [25800/6235], Loss: 2.6443\n",
      "Epoch [25/100], Step [25900/6235], Loss: 3.1776\n",
      "Epoch [25/100], Step [26000/6235], Loss: 0.0402\n",
      "Epoch [25/100], Step [26100/6235], Loss: 0.7041\n",
      "Epoch [25/100], Step [26200/6235], Loss: 0.3749\n",
      "Epoch [25/100], Step [26300/6235], Loss: 0.5055\n",
      "Epoch [25/100], Step [26400/6235], Loss: 3.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Step [26500/6235], Loss: 0.0198\n",
      "Epoch [25/100], Step [26600/6235], Loss: 0.6649\n",
      "Epoch [25/100], Step [26700/6235], Loss: 0.1088\n",
      "Epoch [25/100], Step [26800/6235], Loss: 0.3827\n",
      "Epoch [25/100], Step [26900/6235], Loss: 0.1070\n",
      "Epoch [25/100], Step [27000/6235], Loss: 11.5864\n",
      "Epoch [25/100], Step [27100/6235], Loss: 0.1054\n",
      "Epoch [25/100], Step [27200/6235], Loss: 0.3289\n",
      "Epoch [25/100], Step [27300/6235], Loss: 0.0214\n",
      "Epoch [25/100], Step [27400/6235], Loss: 0.2380\n",
      "Epoch [25/100], Step [27500/6235], Loss: 7.2133\n",
      "Epoch [25/100], Step [27600/6235], Loss: 0.1235\n",
      "Epoch [25/100], Step [27700/6235], Loss: 0.5140\n",
      "Epoch [25/100], Step [27800/6235], Loss: 3.3261\n",
      "Epoch [25/100], Step [27900/6235], Loss: 0.6742\n",
      "Epoch [25/100], Step [28000/6235], Loss: 58.8552\n",
      "Epoch [25/100], Step [28100/6235], Loss: 11.3443\n",
      "Epoch [25/100], Step [28200/6235], Loss: 38.9544\n",
      "Epoch [25/100], Step [28300/6235], Loss: 0.5507\n",
      "Epoch [25/100], Step [28400/6235], Loss: 15.8087\n",
      "Epoch [25/100], Step [28500/6235], Loss: 1.7774\n",
      "Epoch [25/100], Step [28600/6235], Loss: 1.6762\n",
      "Epoch [25/100], Step [28700/6235], Loss: 1.7434\n",
      "Epoch [25/100], Step [28800/6235], Loss: 0.8928\n",
      "Epoch [25/100], Step [28900/6235], Loss: 22.3681\n",
      "Epoch [25/100], Step [29000/6235], Loss: 0.7418\n",
      "Epoch [25/100], Step [29100/6235], Loss: 1.3702\n",
      "Epoch [25/100], Step [29200/6235], Loss: 7.1650\n",
      "Epoch [25/100], Step [29300/6235], Loss: 8.1498\n",
      "Epoch [25/100], Step [29400/6235], Loss: 0.9926\n",
      "Epoch [25/100], Step [29500/6235], Loss: 3.9444\n",
      "Epoch [25/100], Step [29600/6235], Loss: 0.0341\n",
      "Epoch [25/100], Step [29700/6235], Loss: 2.8903\n",
      "Epoch [25/100], Step [29800/6235], Loss: 0.2045\n",
      "Epoch [25/100], Step [29900/6235], Loss: 5.5969\n",
      "Epoch [25/100], Step [30000/6235], Loss: 1.9965\n",
      "Epoch [25/100], Step [30100/6235], Loss: 5.1591\n",
      "Epoch [25/100], Step [30200/6235], Loss: 0.3561\n",
      "Epoch [25/100], Step [30300/6235], Loss: 0.6958\n",
      "Epoch [25/100], Step [30400/6235], Loss: 6.1620\n",
      "Epoch [25/100], Step [30500/6235], Loss: 0.0819\n",
      "Epoch [25/100], Step [30600/6235], Loss: 0.8041\n",
      "Epoch [25/100], Step [30700/6235], Loss: 2.9520\n",
      "Epoch [25/100], Step [30800/6235], Loss: 0.3496\n",
      "Epoch [25/100], Step [30900/6235], Loss: 0.1910\n",
      "Epoch [25/100], Step [31000/6235], Loss: 0.0302\n",
      "Epoch [25/100], Step [31100/6235], Loss: 2.7759\n",
      "Epoch [25/100], Step [31200/6235], Loss: 2.3683\n",
      "Epoch [25/100], Step [31300/6235], Loss: 1.2693\n",
      "Epoch [25/100], Step [31400/6235], Loss: 3.1309\n",
      "Epoch [25/100], Step [31500/6235], Loss: 0.5183\n",
      "Epoch [25/100], Step [31600/6235], Loss: 1.1853\n",
      "Epoch [25/100], Step [31700/6235], Loss: 12.1407\n",
      "Epoch [25/100], Step [31800/6235], Loss: 0.7110\n",
      "Epoch [25/100], Step [31900/6235], Loss: 1414.6927\n",
      "Epoch [25/100], Step [32000/6235], Loss: 75.8827\n",
      "Epoch [25/100], Step [32100/6235], Loss: 2.1213\n",
      "Epoch [25/100], Step [32200/6235], Loss: 159.4232\n",
      "Epoch [25/100], Step [32300/6235], Loss: 0.8156\n",
      "Epoch [25/100], Step [32400/6235], Loss: 1.4540\n",
      "Epoch [25/100], Step [32500/6235], Loss: 3.1055\n",
      "Epoch [25/100], Step [32600/6235], Loss: 0.0334\n",
      "Epoch [25/100], Step [32700/6235], Loss: 127.8962\n",
      "Epoch [25/100], Step [32800/6235], Loss: 21.2331\n",
      "Epoch [25/100], Step [32900/6235], Loss: 0.1182\n",
      "Epoch [25/100], Step [33000/6235], Loss: 0.6646\n",
      "Epoch [25/100], Step [33100/6235], Loss: 1.2438\n",
      "Epoch [25/100], Step [33200/6235], Loss: 1.2367\n",
      "Epoch [25/100], Step [33300/6235], Loss: 0.6242\n",
      "Epoch [25/100], Step [33400/6235], Loss: 110.6209\n",
      "Epoch [25/100], Step [33500/6235], Loss: 2.1427\n",
      "Epoch [25/100], Step [33600/6235], Loss: 4.8580\n",
      "Epoch [25/100], Step [33700/6235], Loss: 3.5537\n",
      "Epoch [25/100], Step [33800/6235], Loss: 1.4512\n",
      "Epoch [25/100], Step [33900/6235], Loss: 25.4763\n",
      "Epoch [25/100], Step [34000/6235], Loss: 0.0533\n",
      "Epoch [25/100], Step [34100/6235], Loss: 0.1261\n",
      "Epoch [25/100], Step [34200/6235], Loss: 0.8805\n",
      "Epoch [25/100], Step [34300/6235], Loss: 7.9992\n",
      "Epoch [25/100], Step [34400/6235], Loss: 0.0982\n",
      "Epoch [25/100], Step [34500/6235], Loss: 104.1886\n",
      "Epoch [25/100], Step [34600/6235], Loss: 0.0240\n",
      "Epoch [25/100], Step [34700/6235], Loss: 16.4289\n",
      "Epoch [25/100], Step [34800/6235], Loss: 8.1865\n",
      "Epoch [25/100], Step [34900/6235], Loss: 63.6142\n",
      "Epoch [25/100], Step [35000/6235], Loss: 2.2631\n",
      "Epoch [25/100], Step [35100/6235], Loss: 0.5204\n",
      "Epoch [25/100], Step [35200/6235], Loss: 0.4009\n",
      "Epoch [25/100], Step [35300/6235], Loss: 2.9934\n",
      "Epoch [25/100], Step [35400/6235], Loss: 0.4632\n",
      "Epoch [25/100], Step [35500/6235], Loss: 1.4276\n",
      "Epoch [25/100], Step [35600/6235], Loss: 2.7713\n",
      "Epoch [25/100], Step [35700/6235], Loss: 6.0867\n",
      "Epoch [25/100], Step [35800/6235], Loss: 9.7212\n",
      "Epoch [25/100], Step [35900/6235], Loss: 4.5337\n",
      "Epoch [25/100], Step [36000/6235], Loss: 0.5234\n",
      "Epoch [25/100], Step [36100/6235], Loss: 0.0264\n",
      "Epoch [25/100], Step [36200/6235], Loss: 16.9689\n",
      "Epoch [25/100], Step [36300/6235], Loss: 1.1358\n",
      "Epoch [25/100], Step [36400/6235], Loss: 2.3369\n",
      "Epoch [25/100], Step [36500/6235], Loss: 8.7690\n",
      "Epoch [25/100], Step [36600/6235], Loss: 0.1208\n",
      "Epoch [25/100], Step [36700/6235], Loss: 0.3163\n",
      "Epoch [25/100], Step [36800/6235], Loss: 14.9599\n",
      "Epoch [25/100], Step [36900/6235], Loss: 3.6094\n",
      "Epoch [25/100], Step [37000/6235], Loss: 0.3798\n",
      "Epoch [25/100], Step [37100/6235], Loss: 0.8107\n",
      "Epoch [25/100], Step [37200/6235], Loss: 0.0774\n",
      "Epoch [25/100], Step [37300/6235], Loss: 0.0671\n",
      "Epoch [25/100], Step [37400/6235], Loss: 0.2109\n",
      "Epoch [25/100], Step [37500/6235], Loss: 3.1238\n",
      "Epoch [25/100], Step [37600/6235], Loss: 10.0678\n",
      "Epoch [25/100], Step [37700/6235], Loss: 0.0342\n",
      "Epoch [25/100], Step [37800/6235], Loss: 9.1314\n",
      "Epoch [25/100], Step [37900/6235], Loss: 4.3204\n",
      "Epoch [25/100], Step [38000/6235], Loss: 0.1542\n",
      "Epoch [25/100], Step [38100/6235], Loss: 2.2795\n",
      "Epoch [25/100], Step [38200/6235], Loss: 2.1486\n",
      "Epoch [25/100], Step [38300/6235], Loss: 0.0449\n",
      "Epoch [25/100], Step [38400/6235], Loss: 0.1442\n",
      "Epoch [25/100], Step [38500/6235], Loss: 4.4734\n",
      "Epoch [25/100], Step [38600/6235], Loss: 0.0953\n",
      "Epoch [25/100], Step [38700/6235], Loss: 0.1420\n",
      "Epoch [25/100], Step [38800/6235], Loss: 0.4420\n",
      "Epoch [25/100], Step [38900/6235], Loss: 20.5803\n",
      "Epoch [25/100], Step [39000/6235], Loss: 13.9359\n",
      "Epoch [25/100], Step [39100/6235], Loss: 11.4010\n",
      "Epoch [25/100], Step [39200/6235], Loss: 0.2858\n",
      "Epoch [25/100], Step [39300/6235], Loss: 5.7607\n",
      "Epoch [25/100], Step [39400/6235], Loss: 275.6909\n",
      "Epoch [25/100], Step [39500/6235], Loss: 6.8502\n",
      "Epoch [25/100], Step [39600/6235], Loss: 4.8434\n",
      "Epoch [25/100], Step [39700/6235], Loss: 314.2442\n",
      "Epoch [25/100], Step [39800/6235], Loss: 134.2253\n",
      "Epoch [25/100], Step [39900/6235], Loss: 1.6620\n",
      "Epoch [25/100], Step [40000/6235], Loss: 20.0310\n",
      "Epoch [25/100], Step [40100/6235], Loss: 24.4733\n",
      "Epoch [25/100], Step [40200/6235], Loss: 0.9006\n",
      "Epoch [25/100], Step [40300/6235], Loss: 0.7102\n",
      "Epoch [25/100], Step [40400/6235], Loss: 2.0296\n",
      "Epoch [25/100], Step [40500/6235], Loss: 2.4889\n",
      "Epoch [25/100], Step [40600/6235], Loss: 0.2337\n",
      "Epoch [25/100], Step [40700/6235], Loss: 7.5604\n",
      "Epoch [25/100], Step [40800/6235], Loss: 1.2327\n",
      "Epoch [25/100], Step [40900/6235], Loss: 0.1728\n",
      "Epoch [25/100], Step [41000/6235], Loss: 42.2894\n",
      "Epoch [25/100], Step [41100/6235], Loss: 34.4900\n",
      "Epoch [25/100], Step [41200/6235], Loss: 22.2233\n",
      "Epoch [25/100], Step [41300/6235], Loss: 1.3768\n",
      "Epoch [25/100], Step [41400/6235], Loss: 0.3486\n",
      "Epoch [25/100], Step [41500/6235], Loss: 1.9243\n",
      "Epoch [25/100], Step [41600/6235], Loss: 0.0256\n",
      "Epoch [25/100], Step [41700/6235], Loss: 0.1511\n",
      "Epoch [25/100], Step [41800/6235], Loss: 1.3894\n",
      "Epoch [25/100], Step [41900/6235], Loss: 4.6982\n",
      "Epoch [25/100], Step [42000/6235], Loss: 3.3791\n",
      "Epoch [25/100], Step [42100/6235], Loss: 8.2522\n",
      "Epoch [25/100], Step [42200/6235], Loss: 29.5300\n",
      "Epoch [25/100], Step [42300/6235], Loss: 3.1493\n",
      "Epoch [25/100], Step [42400/6235], Loss: 3.8983\n",
      "Epoch [25/100], Step [42500/6235], Loss: 1.3347\n",
      "Epoch [25/100], Step [42600/6235], Loss: 1.5324\n",
      "Epoch [25/100], Step [42700/6235], Loss: 0.6290\n",
      "Epoch [25/100], Step [42800/6235], Loss: 0.7199\n",
      "Epoch [25/100], Step [42900/6235], Loss: 3.8680\n",
      "Epoch [25/100], Step [43000/6235], Loss: 0.2302\n",
      "Epoch [25/100], Step [43100/6235], Loss: 0.7440\n",
      "Epoch [25/100], Step [43200/6235], Loss: 0.8569\n",
      "Epoch [25/100], Step [43300/6235], Loss: 9.0405\n",
      "Epoch [25/100], Step [43400/6235], Loss: 12.4766\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [25/100], Step [43500/6235], Loss: 9.3519\n",
      "Epoch [25/100], Step [43600/6235], Loss: 17.4529\n",
      "Epoch [25/100], Step [43700/6235], Loss: 44.9393\n",
      "Epoch [25/100], Step [43800/6235], Loss: 0.7438\n",
      "Epoch [25/100], Step [43900/6235], Loss: 1.2666\n",
      "Epoch [25/100], Step [44000/6235], Loss: 73.4790\n",
      "Epoch [25/100], Step [44100/6235], Loss: 3.4115\n",
      "Epoch [25/100], Step [44200/6235], Loss: 36.5977\n",
      "Epoch [25/100], Step [44300/6235], Loss: 6.7684\n",
      "Epoch [25/100], Step [44400/6235], Loss: 2.9529\n",
      "Epoch [25/100], Step [44500/6235], Loss: 1.9412\n",
      "Epoch [25/100], Step [44600/6235], Loss: 25.4989\n",
      "Epoch [25/100], Step [44700/6235], Loss: 7.2706\n",
      "Epoch [25/100], Step [44800/6235], Loss: 3.4891\n",
      "Epoch [25/100], Step [44900/6235], Loss: 4.1932\n",
      "Epoch [25/100], Step [45000/6235], Loss: 5.0624\n",
      "Epoch [25/100], Step [45100/6235], Loss: 11.0011\n",
      "Epoch [25/100], Step [45200/6235], Loss: 0.1989\n",
      "Epoch [25/100], Step [45300/6235], Loss: 31.8898\n",
      "Epoch [25/100], Step [45400/6235], Loss: 13.2120\n",
      "Epoch [25/100], Step [45500/6235], Loss: 0.2783\n",
      "Epoch [25/100], Step [45600/6235], Loss: 0.2487\n",
      "Epoch [25/100], Step [45700/6235], Loss: 88.7977\n",
      "Epoch [25/100], Step [45800/6235], Loss: 479.7693\n",
      "Epoch [25/100], Step [45900/6235], Loss: 9.8701\n",
      "Epoch [25/100], Step [46000/6235], Loss: 71.2929\n",
      "Epoch [25/100], Step [46100/6235], Loss: 8.3225\n",
      "Epoch [25/100], Step [46200/6235], Loss: 9.6150\n",
      "Epoch [25/100], Step [46300/6235], Loss: 25.8059\n",
      "Epoch [25/100], Step [46400/6235], Loss: 8.2910\n",
      "Epoch [25/100], Step [46500/6235], Loss: 4.0802\n",
      "Epoch [25/100], Step [46600/6235], Loss: 17.7423\n",
      "Epoch [25/100], Step [46700/6235], Loss: 2.2347\n",
      "Epoch [25/100], Step [46800/6235], Loss: 10.2580\n",
      "Epoch [25/100], Step [46900/6235], Loss: 9.4111\n",
      "Epoch [25/100], Step [47000/6235], Loss: 3.3044\n",
      "Epoch [25/100], Step [47100/6235], Loss: 5.8463\n",
      "Epoch [25/100], Step [47200/6235], Loss: 11.8630\n",
      "Epoch [25/100], Step [47300/6235], Loss: 1.0500\n",
      "Epoch [25/100], Step [47400/6235], Loss: 10.5236\n",
      "Epoch [25/100], Step [47500/6235], Loss: 3.9886\n",
      "Epoch [25/100], Step [47600/6235], Loss: 5.5816\n",
      "Epoch [25/100], Step [47700/6235], Loss: 6.2872\n",
      "Epoch [25/100], Step [47800/6235], Loss: 6.4084\n",
      "Epoch [25/100], Step [47900/6235], Loss: 18.2644\n",
      "Epoch [25/100], Step [48000/6235], Loss: 31.8825\n",
      "Epoch [25/100], Step [48100/6235], Loss: 4.1257\n",
      "Epoch [25/100], Step [48200/6235], Loss: 17.1989\n",
      "Epoch [25/100], Step [48300/6235], Loss: 270.7921\n",
      "Epoch [25/100], Step [48400/6235], Loss: 18.6059\n",
      "Epoch [25/100], Step [48500/6235], Loss: 22.4786\n",
      "Epoch [25/100], Step [48600/6235], Loss: 165.2124\n",
      "Epoch [25/100], Step [48700/6235], Loss: 15.9500\n",
      "Epoch [25/100], Step [48800/6235], Loss: 253.8951\n",
      "Epoch [25/100], Step [48900/6235], Loss: 169.3593\n",
      "Epoch [25/100], Step [49000/6235], Loss: 234.9810\n",
      "Epoch [25/100], Step [49100/6235], Loss: 2766.9729\n",
      "Epoch [25/100], Step [49200/6235], Loss: 732.3173\n",
      "Epoch [25/100], Step [49300/6235], Loss: 1237.0173\n",
      "Epoch [25/100], Step [49400/6235], Loss: 142.0576\n",
      "Epoch [25/100], Step [49500/6235], Loss: 4.3825\n",
      "Epoch [25/100], Step [49600/6235], Loss: 103.3160\n",
      "Epoch [25/100], Step [49700/6235], Loss: 2031.7373\n",
      "Epoch [25/100], Step [49800/6235], Loss: 1033.5850\n",
      "Epoch [26/100], Step [100/6235], Loss: 9.5680\n",
      "Epoch [26/100], Step [200/6235], Loss: 3.4998\n",
      "Epoch [26/100], Step [300/6235], Loss: 0.5152\n",
      "Epoch [26/100], Step [400/6235], Loss: 0.1405\n",
      "Epoch [26/100], Step [500/6235], Loss: 5.3981\n",
      "Epoch [26/100], Step [600/6235], Loss: 3.5397\n",
      "Epoch [26/100], Step [700/6235], Loss: 1.0038\n",
      "Epoch [26/100], Step [800/6235], Loss: 2.0405\n",
      "Epoch [26/100], Step [900/6235], Loss: 0.5830\n",
      "Epoch [26/100], Step [1000/6235], Loss: 0.1796\n",
      "Epoch [26/100], Step [1100/6235], Loss: 0.0489\n",
      "Epoch [26/100], Step [1200/6235], Loss: 0.1491\n",
      "Epoch [26/100], Step [1300/6235], Loss: 0.0326\n",
      "Epoch [26/100], Step [1400/6235], Loss: 0.1089\n",
      "Epoch [26/100], Step [1500/6235], Loss: 0.0306\n",
      "Epoch [26/100], Step [1600/6235], Loss: 0.2596\n",
      "Epoch [26/100], Step [1700/6235], Loss: 0.2885\n",
      "Epoch [26/100], Step [1800/6235], Loss: 0.3170\n",
      "Epoch [26/100], Step [1900/6235], Loss: 0.2945\n",
      "Epoch [26/100], Step [2000/6235], Loss: 2.0002\n",
      "Epoch [26/100], Step [2100/6235], Loss: 4.4143\n",
      "Epoch [26/100], Step [2200/6235], Loss: 4.2859\n",
      "Epoch [26/100], Step [2300/6235], Loss: 1.2537\n",
      "Epoch [26/100], Step [2400/6235], Loss: 1.8820\n",
      "Epoch [26/100], Step [2500/6235], Loss: 12.9357\n",
      "Epoch [26/100], Step [2600/6235], Loss: 16.0520\n",
      "Epoch [26/100], Step [2700/6235], Loss: 10.3897\n",
      "Epoch [26/100], Step [2800/6235], Loss: 125.5221\n",
      "Epoch [26/100], Step [2900/6235], Loss: 14.6179\n",
      "Epoch [26/100], Step [3000/6235], Loss: 0.2291\n",
      "Epoch [26/100], Step [3100/6235], Loss: 70.1560\n",
      "Epoch [26/100], Step [3200/6235], Loss: 36.8579\n",
      "Epoch [26/100], Step [3300/6235], Loss: 9.9356\n",
      "Epoch [26/100], Step [3400/6235], Loss: 4.4460\n",
      "Epoch [26/100], Step [3500/6235], Loss: 55.7497\n",
      "Epoch [26/100], Step [3600/6235], Loss: 0.9066\n",
      "Epoch [26/100], Step [3700/6235], Loss: 0.0994\n",
      "Epoch [26/100], Step [3800/6235], Loss: 0.0896\n",
      "Epoch [26/100], Step [3900/6235], Loss: 0.2229\n",
      "Epoch [26/100], Step [4000/6235], Loss: 0.1394\n",
      "Epoch [26/100], Step [4100/6235], Loss: 9.9199\n",
      "Epoch [26/100], Step [4200/6235], Loss: 4.4178\n",
      "Epoch [26/100], Step [4300/6235], Loss: 5.7192\n",
      "Epoch [26/100], Step [4400/6235], Loss: 0.5723\n",
      "Epoch [26/100], Step [4500/6235], Loss: 41.3392\n",
      "Epoch [26/100], Step [4600/6235], Loss: 1.7538\n",
      "Epoch [26/100], Step [4700/6235], Loss: 0.1463\n",
      "Epoch [26/100], Step [4800/6235], Loss: 6.6552\n",
      "Epoch [26/100], Step [4900/6235], Loss: 2.4909\n",
      "Epoch [26/100], Step [5000/6235], Loss: 0.0773\n",
      "Epoch [26/100], Step [5100/6235], Loss: 0.2250\n",
      "Epoch [26/100], Step [5200/6235], Loss: 5.4839\n",
      "Epoch [26/100], Step [5300/6235], Loss: 20.9876\n",
      "Epoch [26/100], Step [5400/6235], Loss: 2.3358\n",
      "Epoch [26/100], Step [5500/6235], Loss: 0.1402\n",
      "Epoch [26/100], Step [5600/6235], Loss: 0.2899\n",
      "Epoch [26/100], Step [5700/6235], Loss: 0.1911\n",
      "Epoch [26/100], Step [5800/6235], Loss: 0.1041\n",
      "Epoch [26/100], Step [5900/6235], Loss: 0.1337\n",
      "Epoch [26/100], Step [6000/6235], Loss: 0.1818\n",
      "Epoch [26/100], Step [6100/6235], Loss: 0.0854\n",
      "Epoch [26/100], Step [6200/6235], Loss: 6.7799\n",
      "Epoch [26/100], Step [6300/6235], Loss: 0.5350\n",
      "Epoch [26/100], Step [6400/6235], Loss: 0.0090\n",
      "Epoch [26/100], Step [6500/6235], Loss: 1.7385\n",
      "Epoch [26/100], Step [6600/6235], Loss: 5.8545\n",
      "Epoch [26/100], Step [6700/6235], Loss: 1.2830\n",
      "Epoch [26/100], Step [6800/6235], Loss: 0.2788\n",
      "Epoch [26/100], Step [6900/6235], Loss: 0.3059\n",
      "Epoch [26/100], Step [7000/6235], Loss: 0.3288\n",
      "Epoch [26/100], Step [7100/6235], Loss: 0.3322\n",
      "Epoch [26/100], Step [7200/6235], Loss: 0.0657\n",
      "Epoch [26/100], Step [7300/6235], Loss: 0.0583\n",
      "Epoch [26/100], Step [7400/6235], Loss: 0.2146\n",
      "Epoch [26/100], Step [7500/6235], Loss: 0.4704\n",
      "Epoch [26/100], Step [7600/6235], Loss: 0.2299\n",
      "Epoch [26/100], Step [7700/6235], Loss: 19.2189\n",
      "Epoch [26/100], Step [7800/6235], Loss: 2.2787\n",
      "Epoch [26/100], Step [7900/6235], Loss: 0.2532\n",
      "Epoch [26/100], Step [8000/6235], Loss: 0.0297\n",
      "Epoch [26/100], Step [8100/6235], Loss: 3.1256\n",
      "Epoch [26/100], Step [8200/6235], Loss: 10.2144\n",
      "Epoch [26/100], Step [8300/6235], Loss: 16.6703\n",
      "Epoch [26/100], Step [8400/6235], Loss: 355.3391\n",
      "Epoch [26/100], Step [8500/6235], Loss: 1.7038\n",
      "Epoch [26/100], Step [8600/6235], Loss: 4.7259\n",
      "Epoch [26/100], Step [8700/6235], Loss: 28.2802\n",
      "Epoch [26/100], Step [8800/6235], Loss: 47.1492\n",
      "Epoch [26/100], Step [8900/6235], Loss: 0.9472\n",
      "Epoch [26/100], Step [9000/6235], Loss: 285.1061\n",
      "Epoch [26/100], Step [9100/6235], Loss: 1192.8239\n",
      "Epoch [26/100], Step [9200/6235], Loss: 3624.4404\n",
      "Epoch [26/100], Step [9300/6235], Loss: 92.4439\n",
      "Epoch [26/100], Step [9400/6235], Loss: 52.9572\n",
      "Epoch [26/100], Step [9500/6235], Loss: 824.8337\n",
      "Epoch [26/100], Step [9600/6235], Loss: 425.0370\n",
      "Epoch [26/100], Step [9700/6235], Loss: 6.3588\n",
      "Epoch [26/100], Step [9800/6235], Loss: 12.4909\n",
      "Epoch [26/100], Step [9900/6235], Loss: 56.9257\n",
      "Epoch [26/100], Step [10000/6235], Loss: 272.6524\n",
      "Epoch [26/100], Step [10100/6235], Loss: 4.3395\n",
      "Epoch [26/100], Step [10200/6235], Loss: 582.3699\n",
      "Epoch [26/100], Step [10300/6235], Loss: 2.4161\n",
      "Epoch [26/100], Step [10400/6235], Loss: 10.8590\n",
      "Epoch [26/100], Step [10500/6235], Loss: 30.2749\n",
      "Epoch [26/100], Step [10600/6235], Loss: 1956.3176\n",
      "Epoch [26/100], Step [10700/6235], Loss: 18.0283\n",
      "Epoch [26/100], Step [10800/6235], Loss: 71.2698\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Step [10900/6235], Loss: 40.1816\n",
      "Epoch [26/100], Step [11000/6235], Loss: 281.5212\n",
      "Epoch [26/100], Step [11100/6235], Loss: 44.9246\n",
      "Epoch [26/100], Step [11200/6235], Loss: 22.2562\n",
      "Epoch [26/100], Step [11300/6235], Loss: 156.3319\n",
      "Epoch [26/100], Step [11400/6235], Loss: 5.8418\n",
      "Epoch [26/100], Step [11500/6235], Loss: 0.9040\n",
      "Epoch [26/100], Step [11600/6235], Loss: 0.8697\n",
      "Epoch [26/100], Step [11700/6235], Loss: 47.3243\n",
      "Epoch [26/100], Step [11800/6235], Loss: 164.6739\n",
      "Epoch [26/100], Step [11900/6235], Loss: 187.3583\n",
      "Epoch [26/100], Step [12000/6235], Loss: 302.4518\n",
      "Epoch [26/100], Step [12100/6235], Loss: 227.0308\n",
      "Epoch [26/100], Step [12200/6235], Loss: 1.5140\n",
      "Epoch [26/100], Step [12300/6235], Loss: 2.9160\n",
      "Epoch [26/100], Step [12400/6235], Loss: 178.7997\n",
      "Epoch [26/100], Step [12500/6235], Loss: 66.7053\n",
      "Epoch [26/100], Step [12600/6235], Loss: 21.3010\n",
      "Epoch [26/100], Step [12700/6235], Loss: 5.9540\n",
      "Epoch [26/100], Step [12800/6235], Loss: 16.0660\n",
      "Epoch [26/100], Step [12900/6235], Loss: 26.9091\n",
      "Epoch [26/100], Step [13000/6235], Loss: 0.1790\n",
      "Epoch [26/100], Step [13100/6235], Loss: 60.9924\n",
      "Epoch [26/100], Step [13200/6235], Loss: 9.0650\n",
      "Epoch [26/100], Step [13300/6235], Loss: 31.8672\n",
      "Epoch [26/100], Step [13400/6235], Loss: 219.1001\n",
      "Epoch [26/100], Step [13500/6235], Loss: 6.4176\n",
      "Epoch [26/100], Step [13600/6235], Loss: 2.8995\n",
      "Epoch [26/100], Step [13700/6235], Loss: 162.5322\n",
      "Epoch [26/100], Step [13800/6235], Loss: 86.8577\n",
      "Epoch [26/100], Step [13900/6235], Loss: 3.1819\n",
      "Epoch [26/100], Step [14000/6235], Loss: 10.5409\n",
      "Epoch [26/100], Step [14100/6235], Loss: 41.0548\n",
      "Epoch [26/100], Step [14200/6235], Loss: 122.5936\n",
      "Epoch [26/100], Step [14300/6235], Loss: 51.1447\n",
      "Epoch [26/100], Step [14400/6235], Loss: 39.3784\n",
      "Epoch [26/100], Step [14500/6235], Loss: 43.9892\n",
      "Epoch [26/100], Step [14600/6235], Loss: 0.1345\n",
      "Epoch [26/100], Step [14700/6235], Loss: 45.0374\n",
      "Epoch [26/100], Step [14800/6235], Loss: 32.5996\n",
      "Epoch [26/100], Step [14900/6235], Loss: 1.4683\n",
      "Epoch [26/100], Step [15000/6235], Loss: 2.5159\n",
      "Epoch [26/100], Step [15100/6235], Loss: 0.2893\n",
      "Epoch [26/100], Step [15200/6235], Loss: 0.6110\n",
      "Epoch [26/100], Step [15300/6235], Loss: 6.0751\n",
      "Epoch [26/100], Step [15400/6235], Loss: 40.6365\n",
      "Epoch [26/100], Step [15500/6235], Loss: 12.9812\n",
      "Epoch [26/100], Step [15600/6235], Loss: 9.9044\n",
      "Epoch [26/100], Step [15700/6235], Loss: 200.8788\n",
      "Epoch [26/100], Step [15800/6235], Loss: 9.4243\n",
      "Epoch [26/100], Step [15900/6235], Loss: 0.6841\n",
      "Epoch [26/100], Step [16000/6235], Loss: 179.1302\n",
      "Epoch [26/100], Step [16100/6235], Loss: 2.1585\n",
      "Epoch [26/100], Step [16200/6235], Loss: 0.5880\n",
      "Epoch [26/100], Step [16300/6235], Loss: 8.3259\n",
      "Epoch [26/100], Step [16400/6235], Loss: 19.2259\n",
      "Epoch [26/100], Step [16500/6235], Loss: 272.2073\n",
      "Epoch [26/100], Step [16600/6235], Loss: 45.1048\n",
      "Epoch [26/100], Step [16700/6235], Loss: 0.2540\n",
      "Epoch [26/100], Step [16800/6235], Loss: 12.4417\n",
      "Epoch [26/100], Step [16900/6235], Loss: 0.1564\n",
      "Epoch [26/100], Step [17000/6235], Loss: 0.0938\n",
      "Epoch [26/100], Step [17100/6235], Loss: 0.1758\n",
      "Epoch [26/100], Step [17200/6235], Loss: 200.4351\n",
      "Epoch [26/100], Step [17300/6235], Loss: 5.4352\n",
      "Epoch [26/100], Step [17400/6235], Loss: 60.9838\n",
      "Epoch [26/100], Step [17500/6235], Loss: 16.1298\n",
      "Epoch [26/100], Step [17600/6235], Loss: 2.6790\n",
      "Epoch [26/100], Step [17700/6235], Loss: 48.0401\n",
      "Epoch [26/100], Step [17800/6235], Loss: 34.6223\n",
      "Epoch [26/100], Step [17900/6235], Loss: 16.6788\n",
      "Epoch [26/100], Step [18000/6235], Loss: 14.2572\n",
      "Epoch [26/100], Step [18100/6235], Loss: 18.7455\n",
      "Epoch [26/100], Step [18200/6235], Loss: 0.4256\n",
      "Epoch [26/100], Step [18300/6235], Loss: 0.9371\n",
      "Epoch [26/100], Step [18400/6235], Loss: 0.7671\n",
      "Epoch [26/100], Step [18500/6235], Loss: 14.8354\n",
      "Epoch [26/100], Step [18600/6235], Loss: 4.0604\n",
      "Epoch [26/100], Step [18700/6235], Loss: 1.1432\n",
      "Epoch [26/100], Step [18800/6235], Loss: 138.1141\n",
      "Epoch [26/100], Step [18900/6235], Loss: 67.4386\n",
      "Epoch [26/100], Step [19000/6235], Loss: 24.1422\n",
      "Epoch [26/100], Step [19100/6235], Loss: 43.0239\n",
      "Epoch [26/100], Step [19200/6235], Loss: 1.8027\n",
      "Epoch [26/100], Step [19300/6235], Loss: 48.1265\n",
      "Epoch [26/100], Step [19400/6235], Loss: 5.2886\n",
      "Epoch [26/100], Step [19500/6235], Loss: 58.6341\n",
      "Epoch [26/100], Step [19600/6235], Loss: 27.3929\n",
      "Epoch [26/100], Step [19700/6235], Loss: 2.4434\n",
      "Epoch [26/100], Step [19800/6235], Loss: 3.2364\n",
      "Epoch [26/100], Step [19900/6235], Loss: 0.1504\n",
      "Epoch [26/100], Step [20000/6235], Loss: 63.0513\n",
      "Epoch [26/100], Step [20100/6235], Loss: 4.6480\n",
      "Epoch [26/100], Step [20200/6235], Loss: 3.6030\n",
      "Epoch [26/100], Step [20300/6235], Loss: 0.9977\n",
      "Epoch [26/100], Step [20400/6235], Loss: 9.3354\n",
      "Epoch [26/100], Step [20500/6235], Loss: 60.6412\n",
      "Epoch [26/100], Step [20600/6235], Loss: 8.9779\n",
      "Epoch [26/100], Step [20700/6235], Loss: 15.5547\n",
      "Epoch [26/100], Step [20800/6235], Loss: 3.9606\n",
      "Epoch [26/100], Step [20900/6235], Loss: 0.5180\n",
      "Epoch [26/100], Step [21000/6235], Loss: 15.1978\n",
      "Epoch [26/100], Step [21100/6235], Loss: 7.2820\n",
      "Epoch [26/100], Step [21200/6235], Loss: 0.3390\n",
      "Epoch [26/100], Step [21300/6235], Loss: 0.1255\n",
      "Epoch [26/100], Step [21400/6235], Loss: 1.1772\n",
      "Epoch [26/100], Step [21500/6235], Loss: 2.4895\n",
      "Epoch [26/100], Step [21600/6235], Loss: 0.4856\n",
      "Epoch [26/100], Step [21700/6235], Loss: 3.1941\n",
      "Epoch [26/100], Step [21800/6235], Loss: 0.5562\n",
      "Epoch [26/100], Step [21900/6235], Loss: 0.9270\n",
      "Epoch [26/100], Step [22000/6235], Loss: 6.9434\n",
      "Epoch [26/100], Step [22100/6235], Loss: 0.8901\n",
      "Epoch [26/100], Step [22200/6235], Loss: 6.7858\n",
      "Epoch [26/100], Step [22300/6235], Loss: 15.1890\n",
      "Epoch [26/100], Step [22400/6235], Loss: 16.3897\n",
      "Epoch [26/100], Step [22500/6235], Loss: 136.5180\n",
      "Epoch [26/100], Step [22600/6235], Loss: 37.6818\n",
      "Epoch [26/100], Step [22700/6235], Loss: 1.7671\n",
      "Epoch [26/100], Step [22800/6235], Loss: 10.7514\n",
      "Epoch [26/100], Step [22900/6235], Loss: 7.8047\n",
      "Epoch [26/100], Step [23000/6235], Loss: 10.0144\n",
      "Epoch [26/100], Step [23100/6235], Loss: 6.3406\n",
      "Epoch [26/100], Step [23200/6235], Loss: 0.5630\n",
      "Epoch [26/100], Step [23300/6235], Loss: 18.9218\n",
      "Epoch [26/100], Step [23400/6235], Loss: 2.4316\n",
      "Epoch [26/100], Step [23500/6235], Loss: 0.4957\n",
      "Epoch [26/100], Step [23600/6235], Loss: 118.1860\n",
      "Epoch [26/100], Step [23700/6235], Loss: 2.8139\n",
      "Epoch [26/100], Step [23800/6235], Loss: 0.6805\n",
      "Epoch [26/100], Step [23900/6235], Loss: 0.4900\n",
      "Epoch [26/100], Step [24000/6235], Loss: 4.7933\n",
      "Epoch [26/100], Step [24100/6235], Loss: 3.7191\n",
      "Epoch [26/100], Step [24200/6235], Loss: 7.5541\n",
      "Epoch [26/100], Step [24300/6235], Loss: 0.1740\n",
      "Epoch [26/100], Step [24400/6235], Loss: 4.1252\n",
      "Epoch [26/100], Step [24500/6235], Loss: 4.5171\n",
      "Epoch [26/100], Step [24600/6235], Loss: 1.1866\n",
      "Epoch [26/100], Step [24700/6235], Loss: 1.1046\n",
      "Epoch [26/100], Step [24800/6235], Loss: 0.1389\n",
      "Epoch [26/100], Step [24900/6235], Loss: 8.5179\n",
      "Epoch [26/100], Step [25000/6235], Loss: 2.3158\n",
      "Epoch [26/100], Step [25100/6235], Loss: 13.4174\n",
      "Epoch [26/100], Step [25200/6235], Loss: 0.6525\n",
      "Epoch [26/100], Step [25300/6235], Loss: 5.6500\n",
      "Epoch [26/100], Step [25400/6235], Loss: 7.7207\n",
      "Epoch [26/100], Step [25500/6235], Loss: 7.8811\n",
      "Epoch [26/100], Step [25600/6235], Loss: 9.7536\n",
      "Epoch [26/100], Step [25700/6235], Loss: 2.8283\n",
      "Epoch [26/100], Step [25800/6235], Loss: 6.7607\n",
      "Epoch [26/100], Step [25900/6235], Loss: 0.4066\n",
      "Epoch [26/100], Step [26000/6235], Loss: 1.1297\n",
      "Epoch [26/100], Step [26100/6235], Loss: 0.7564\n",
      "Epoch [26/100], Step [26200/6235], Loss: 0.1927\n",
      "Epoch [26/100], Step [26300/6235], Loss: 3.3082\n",
      "Epoch [26/100], Step [26400/6235], Loss: 4.9043\n",
      "Epoch [26/100], Step [26500/6235], Loss: 0.2065\n",
      "Epoch [26/100], Step [26600/6235], Loss: 1.5867\n",
      "Epoch [26/100], Step [26700/6235], Loss: 0.1665\n",
      "Epoch [26/100], Step [26800/6235], Loss: 0.6147\n",
      "Epoch [26/100], Step [26900/6235], Loss: 0.0163\n",
      "Epoch [26/100], Step [27000/6235], Loss: 9.8334\n",
      "Epoch [26/100], Step [27100/6235], Loss: 0.0484\n",
      "Epoch [26/100], Step [27200/6235], Loss: 0.5094\n",
      "Epoch [26/100], Step [27300/6235], Loss: 0.0452\n",
      "Epoch [26/100], Step [27400/6235], Loss: 0.1862\n",
      "Epoch [26/100], Step [27500/6235], Loss: 1.5361\n",
      "Epoch [26/100], Step [27600/6235], Loss: 0.1530\n",
      "Epoch [26/100], Step [27700/6235], Loss: 0.9559\n",
      "Epoch [26/100], Step [27800/6235], Loss: 5.4127\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Step [27900/6235], Loss: 1.7570\n",
      "Epoch [26/100], Step [28000/6235], Loss: 20.0573\n",
      "Epoch [26/100], Step [28100/6235], Loss: 9.8880\n",
      "Epoch [26/100], Step [28200/6235], Loss: 36.2260\n",
      "Epoch [26/100], Step [28300/6235], Loss: 0.9546\n",
      "Epoch [26/100], Step [28400/6235], Loss: 17.9917\n",
      "Epoch [26/100], Step [28500/6235], Loss: 1.3350\n",
      "Epoch [26/100], Step [28600/6235], Loss: 1.6967\n",
      "Epoch [26/100], Step [28700/6235], Loss: 0.8722\n",
      "Epoch [26/100], Step [28800/6235], Loss: 0.9114\n",
      "Epoch [26/100], Step [28900/6235], Loss: 19.9836\n",
      "Epoch [26/100], Step [29000/6235], Loss: 8.2843\n",
      "Epoch [26/100], Step [29100/6235], Loss: 0.2536\n",
      "Epoch [26/100], Step [29200/6235], Loss: 5.5987\n",
      "Epoch [26/100], Step [29300/6235], Loss: 8.7359\n",
      "Epoch [26/100], Step [29400/6235], Loss: 6.8088\n",
      "Epoch [26/100], Step [29500/6235], Loss: 6.6126\n",
      "Epoch [26/100], Step [29600/6235], Loss: 0.6833\n",
      "Epoch [26/100], Step [29700/6235], Loss: 2.6425\n",
      "Epoch [26/100], Step [29800/6235], Loss: 0.2231\n",
      "Epoch [26/100], Step [29900/6235], Loss: 3.5358\n",
      "Epoch [26/100], Step [30000/6235], Loss: 1.6029\n",
      "Epoch [26/100], Step [30100/6235], Loss: 12.2398\n",
      "Epoch [26/100], Step [30200/6235], Loss: 0.1044\n",
      "Epoch [26/100], Step [30300/6235], Loss: 1.0539\n",
      "Epoch [26/100], Step [30400/6235], Loss: 6.5836\n",
      "Epoch [26/100], Step [30500/6235], Loss: 0.4838\n",
      "Epoch [26/100], Step [30600/6235], Loss: 0.5377\n",
      "Epoch [26/100], Step [30700/6235], Loss: 2.7317\n",
      "Epoch [26/100], Step [30800/6235], Loss: 0.3894\n",
      "Epoch [26/100], Step [30900/6235], Loss: 0.0516\n",
      "Epoch [26/100], Step [31000/6235], Loss: 0.1023\n",
      "Epoch [26/100], Step [31100/6235], Loss: 2.8904\n",
      "Epoch [26/100], Step [31200/6235], Loss: 2.4051\n",
      "Epoch [26/100], Step [31300/6235], Loss: 1.6917\n",
      "Epoch [26/100], Step [31400/6235], Loss: 5.5805\n",
      "Epoch [26/100], Step [31500/6235], Loss: 0.8767\n",
      "Epoch [26/100], Step [31600/6235], Loss: 2.3930\n",
      "Epoch [26/100], Step [31700/6235], Loss: 0.0796\n",
      "Epoch [26/100], Step [31800/6235], Loss: 1.5993\n",
      "Epoch [26/100], Step [31900/6235], Loss: 818.7419\n",
      "Epoch [26/100], Step [32000/6235], Loss: 31.0102\n",
      "Epoch [26/100], Step [32100/6235], Loss: 1.3037\n",
      "Epoch [26/100], Step [32200/6235], Loss: 39.1769\n",
      "Epoch [26/100], Step [32300/6235], Loss: 0.2996\n",
      "Epoch [26/100], Step [32400/6235], Loss: 0.5959\n",
      "Epoch [26/100], Step [32500/6235], Loss: 3.0241\n",
      "Epoch [26/100], Step [32600/6235], Loss: 0.0184\n",
      "Epoch [26/100], Step [32700/6235], Loss: 172.8048\n",
      "Epoch [26/100], Step [32800/6235], Loss: 11.8249\n",
      "Epoch [26/100], Step [32900/6235], Loss: 2.3452\n",
      "Epoch [26/100], Step [33000/6235], Loss: 0.2662\n",
      "Epoch [26/100], Step [33100/6235], Loss: 0.5414\n",
      "Epoch [26/100], Step [33200/6235], Loss: 1.1182\n",
      "Epoch [26/100], Step [33300/6235], Loss: 8.2706\n",
      "Epoch [26/100], Step [33400/6235], Loss: 2.5703\n",
      "Epoch [26/100], Step [33500/6235], Loss: 0.7895\n",
      "Epoch [26/100], Step [33600/6235], Loss: 8.5414\n",
      "Epoch [26/100], Step [33700/6235], Loss: 12.1864\n",
      "Epoch [26/100], Step [33800/6235], Loss: 1.0192\n",
      "Epoch [26/100], Step [33900/6235], Loss: 28.3354\n",
      "Epoch [26/100], Step [34000/6235], Loss: 0.0496\n",
      "Epoch [26/100], Step [34100/6235], Loss: 0.4503\n",
      "Epoch [26/100], Step [34200/6235], Loss: 2.1847\n",
      "Epoch [26/100], Step [34300/6235], Loss: 6.0813\n",
      "Epoch [26/100], Step [34400/6235], Loss: 0.2438\n",
      "Epoch [26/100], Step [34500/6235], Loss: 19.8121\n",
      "Epoch [26/100], Step [34600/6235], Loss: 2.5379\n",
      "Epoch [26/100], Step [34700/6235], Loss: 8.3714\n",
      "Epoch [26/100], Step [34800/6235], Loss: 13.8510\n",
      "Epoch [26/100], Step [34900/6235], Loss: 68.6894\n",
      "Epoch [26/100], Step [35000/6235], Loss: 0.5457\n",
      "Epoch [26/100], Step [35100/6235], Loss: 1.1880\n",
      "Epoch [26/100], Step [35200/6235], Loss: 0.5423\n",
      "Epoch [26/100], Step [35300/6235], Loss: 2.8980\n",
      "Epoch [26/100], Step [35400/6235], Loss: 0.5814\n",
      "Epoch [26/100], Step [35500/6235], Loss: 0.2613\n",
      "Epoch [26/100], Step [35600/6235], Loss: 2.7811\n",
      "Epoch [26/100], Step [35700/6235], Loss: 4.6007\n",
      "Epoch [26/100], Step [35800/6235], Loss: 0.1114\n",
      "Epoch [26/100], Step [35900/6235], Loss: 2.4012\n",
      "Epoch [26/100], Step [36000/6235], Loss: 0.2363\n",
      "Epoch [26/100], Step [36100/6235], Loss: 0.0967\n",
      "Epoch [26/100], Step [36200/6235], Loss: 8.5402\n",
      "Epoch [26/100], Step [36300/6235], Loss: 0.8241\n",
      "Epoch [26/100], Step [36400/6235], Loss: 3.1226\n",
      "Epoch [26/100], Step [36500/6235], Loss: 7.3376\n",
      "Epoch [26/100], Step [36600/6235], Loss: 0.0780\n",
      "Epoch [26/100], Step [36700/6235], Loss: 0.5990\n",
      "Epoch [26/100], Step [36800/6235], Loss: 5.4930\n",
      "Epoch [26/100], Step [36900/6235], Loss: 11.7688\n",
      "Epoch [26/100], Step [37000/6235], Loss: 0.9243\n",
      "Epoch [26/100], Step [37100/6235], Loss: 1.8200\n",
      "Epoch [26/100], Step [37200/6235], Loss: 0.0441\n",
      "Epoch [26/100], Step [37300/6235], Loss: 0.0390\n",
      "Epoch [26/100], Step [37400/6235], Loss: 0.1771\n",
      "Epoch [26/100], Step [37500/6235], Loss: 6.2802\n",
      "Epoch [26/100], Step [37600/6235], Loss: 12.2056\n",
      "Epoch [26/100], Step [37700/6235], Loss: 1.9208\n",
      "Epoch [26/100], Step [37800/6235], Loss: 6.0217\n",
      "Epoch [26/100], Step [37900/6235], Loss: 8.6906\n",
      "Epoch [26/100], Step [38000/6235], Loss: 0.8334\n",
      "Epoch [26/100], Step [38100/6235], Loss: 3.7573\n",
      "Epoch [26/100], Step [38200/6235], Loss: 2.5975\n",
      "Epoch [26/100], Step [38300/6235], Loss: 0.5260\n",
      "Epoch [26/100], Step [38400/6235], Loss: 0.0730\n",
      "Epoch [26/100], Step [38500/6235], Loss: 2.2557\n",
      "Epoch [26/100], Step [38600/6235], Loss: 0.4082\n",
      "Epoch [26/100], Step [38700/6235], Loss: 0.0684\n",
      "Epoch [26/100], Step [38800/6235], Loss: 0.1532\n",
      "Epoch [26/100], Step [38900/6235], Loss: 1.6595\n",
      "Epoch [26/100], Step [39000/6235], Loss: 8.4938\n",
      "Epoch [26/100], Step [39100/6235], Loss: 21.7693\n",
      "Epoch [26/100], Step [39200/6235], Loss: 0.7786\n",
      "Epoch [26/100], Step [39300/6235], Loss: 31.0160\n",
      "Epoch [26/100], Step [39400/6235], Loss: 65.4143\n",
      "Epoch [26/100], Step [39500/6235], Loss: 347.7458\n",
      "Epoch [26/100], Step [39600/6235], Loss: 9.3110\n",
      "Epoch [26/100], Step [39700/6235], Loss: 250.7085\n",
      "Epoch [26/100], Step [39800/6235], Loss: 52.1230\n",
      "Epoch [26/100], Step [39900/6235], Loss: 2.0234\n",
      "Epoch [26/100], Step [40000/6235], Loss: 8.7381\n",
      "Epoch [26/100], Step [40100/6235], Loss: 27.5066\n",
      "Epoch [26/100], Step [40200/6235], Loss: 0.9203\n",
      "Epoch [26/100], Step [40300/6235], Loss: 0.8397\n",
      "Epoch [26/100], Step [40400/6235], Loss: 2.0809\n",
      "Epoch [26/100], Step [40500/6235], Loss: 2.5164\n",
      "Epoch [26/100], Step [40600/6235], Loss: 0.2307\n",
      "Epoch [26/100], Step [40700/6235], Loss: 7.4866\n",
      "Epoch [26/100], Step [40800/6235], Loss: 0.9848\n",
      "Epoch [26/100], Step [40900/6235], Loss: 0.2644\n",
      "Epoch [26/100], Step [41000/6235], Loss: 46.2602\n",
      "Epoch [26/100], Step [41100/6235], Loss: 33.3936\n",
      "Epoch [26/100], Step [41200/6235], Loss: 2.9706\n",
      "Epoch [26/100], Step [41300/6235], Loss: 5.0971\n",
      "Epoch [26/100], Step [41400/6235], Loss: 3.5867\n",
      "Epoch [26/100], Step [41500/6235], Loss: 0.7491\n",
      "Epoch [26/100], Step [41600/6235], Loss: 1.5761\n",
      "Epoch [26/100], Step [41700/6235], Loss: 3.9816\n",
      "Epoch [26/100], Step [41800/6235], Loss: 0.2114\n",
      "Epoch [26/100], Step [41900/6235], Loss: 0.5388\n",
      "Epoch [26/100], Step [42000/6235], Loss: 2.0167\n",
      "Epoch [26/100], Step [42100/6235], Loss: 3.6402\n",
      "Epoch [26/100], Step [42200/6235], Loss: 10.9502\n",
      "Epoch [26/100], Step [42300/6235], Loss: 0.4296\n",
      "Epoch [26/100], Step [42400/6235], Loss: 2.2321\n",
      "Epoch [26/100], Step [42500/6235], Loss: 1.6834\n",
      "Epoch [26/100], Step [42600/6235], Loss: 0.5103\n",
      "Epoch [26/100], Step [42700/6235], Loss: 0.2298\n",
      "Epoch [26/100], Step [42800/6235], Loss: 0.6943\n",
      "Epoch [26/100], Step [42900/6235], Loss: 4.1975\n",
      "Epoch [26/100], Step [43000/6235], Loss: 0.1944\n",
      "Epoch [26/100], Step [43100/6235], Loss: 0.9884\n",
      "Epoch [26/100], Step [43200/6235], Loss: 0.7399\n",
      "Epoch [26/100], Step [43300/6235], Loss: 9.4362\n",
      "Epoch [26/100], Step [43400/6235], Loss: 10.6850\n",
      "Epoch [26/100], Step [43500/6235], Loss: 9.2852\n",
      "Epoch [26/100], Step [43600/6235], Loss: 21.9457\n",
      "Epoch [26/100], Step [43700/6235], Loss: 41.9425\n",
      "Epoch [26/100], Step [43800/6235], Loss: 0.7384\n",
      "Epoch [26/100], Step [43900/6235], Loss: 0.6133\n",
      "Epoch [26/100], Step [44000/6235], Loss: 53.9796\n",
      "Epoch [26/100], Step [44100/6235], Loss: 3.4541\n",
      "Epoch [26/100], Step [44200/6235], Loss: 5.1107\n",
      "Epoch [26/100], Step [44300/6235], Loss: 89.9007\n",
      "Epoch [26/100], Step [44400/6235], Loss: 4.6555\n",
      "Epoch [26/100], Step [44500/6235], Loss: 1.8571\n",
      "Epoch [26/100], Step [44600/6235], Loss: 18.6679\n",
      "Epoch [26/100], Step [44700/6235], Loss: 2.8476\n",
      "Epoch [26/100], Step [44800/6235], Loss: 4.4200\n",
      "Epoch [26/100], Step [44900/6235], Loss: 4.1850\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [26/100], Step [45000/6235], Loss: 4.9912\n",
      "Epoch [26/100], Step [45100/6235], Loss: 17.9731\n",
      "Epoch [26/100], Step [45200/6235], Loss: 0.3155\n",
      "Epoch [26/100], Step [45300/6235], Loss: 31.5471\n",
      "Epoch [26/100], Step [45400/6235], Loss: 12.9002\n",
      "Epoch [26/100], Step [45500/6235], Loss: 0.4261\n",
      "Epoch [26/100], Step [45600/6235], Loss: 0.1636\n",
      "Epoch [26/100], Step [45700/6235], Loss: 91.0995\n",
      "Epoch [26/100], Step [45800/6235], Loss: 311.4093\n",
      "Epoch [26/100], Step [45900/6235], Loss: 26.8793\n",
      "Epoch [26/100], Step [46000/6235], Loss: 1.1987\n",
      "Epoch [26/100], Step [46100/6235], Loss: 21.6996\n",
      "Epoch [26/100], Step [46200/6235], Loss: 18.6925\n",
      "Epoch [26/100], Step [46300/6235], Loss: 119.1775\n",
      "Epoch [26/100], Step [46400/6235], Loss: 9.0941\n",
      "Epoch [26/100], Step [46500/6235], Loss: 17.2134\n",
      "Epoch [26/100], Step [46600/6235], Loss: 17.1928\n",
      "Epoch [26/100], Step [46700/6235], Loss: 7.2452\n",
      "Epoch [26/100], Step [46800/6235], Loss: 2.3690\n",
      "Epoch [26/100], Step [46900/6235], Loss: 4.3624\n",
      "Epoch [26/100], Step [47000/6235], Loss: 5.4701\n",
      "Epoch [26/100], Step [47100/6235], Loss: 0.4325\n",
      "Epoch [26/100], Step [47200/6235], Loss: 4.8259\n",
      "Epoch [26/100], Step [47300/6235], Loss: 0.4297\n",
      "Epoch [26/100], Step [47400/6235], Loss: 17.5858\n",
      "Epoch [26/100], Step [47500/6235], Loss: 1.4118\n",
      "Epoch [26/100], Step [47600/6235], Loss: 1.7028\n",
      "Epoch [26/100], Step [47700/6235], Loss: 5.0029\n",
      "Epoch [26/100], Step [47800/6235], Loss: 1.2937\n",
      "Epoch [26/100], Step [47900/6235], Loss: 32.7329\n",
      "Epoch [26/100], Step [48000/6235], Loss: 118.3240\n",
      "Epoch [26/100], Step [48100/6235], Loss: 3.0099\n",
      "Epoch [26/100], Step [48200/6235], Loss: 14.6676\n",
      "Epoch [26/100], Step [48300/6235], Loss: 215.4549\n",
      "Epoch [26/100], Step [48400/6235], Loss: 32.8093\n",
      "Epoch [26/100], Step [48500/6235], Loss: 9.0938\n",
      "Epoch [26/100], Step [48600/6235], Loss: 138.0800\n",
      "Epoch [26/100], Step [48700/6235], Loss: 89.3849\n",
      "Epoch [26/100], Step [48800/6235], Loss: 121.7502\n",
      "Epoch [26/100], Step [48900/6235], Loss: 76.4267\n",
      "Epoch [26/100], Step [49000/6235], Loss: 279.6007\n",
      "Epoch [26/100], Step [49100/6235], Loss: 1285.8779\n",
      "Epoch [26/100], Step [49200/6235], Loss: 760.3417\n",
      "Epoch [26/100], Step [49300/6235], Loss: 1321.3728\n",
      "Epoch [26/100], Step [49400/6235], Loss: 296.8551\n",
      "Epoch [26/100], Step [49500/6235], Loss: 6.6638\n",
      "Epoch [26/100], Step [49600/6235], Loss: 121.8876\n",
      "Epoch [26/100], Step [49700/6235], Loss: 1724.6285\n",
      "Epoch [26/100], Step [49800/6235], Loss: 448.0901\n",
      "Epoch [27/100], Step [100/6235], Loss: 11.0114\n",
      "Epoch [27/100], Step [200/6235], Loss: 0.1098\n",
      "Epoch [27/100], Step [300/6235], Loss: 0.0114\n",
      "Epoch [27/100], Step [400/6235], Loss: 0.0114\n",
      "Epoch [27/100], Step [500/6235], Loss: 10.2086\n",
      "Epoch [27/100], Step [600/6235], Loss: 0.0456\n",
      "Epoch [27/100], Step [700/6235], Loss: 0.4153\n",
      "Epoch [27/100], Step [800/6235], Loss: 0.1778\n",
      "Epoch [27/100], Step [900/6235], Loss: 0.1021\n",
      "Epoch [27/100], Step [1000/6235], Loss: 0.0543\n",
      "Epoch [27/100], Step [1100/6235], Loss: 0.2612\n",
      "Epoch [27/100], Step [1200/6235], Loss: 0.1724\n",
      "Epoch [27/100], Step [1300/6235], Loss: 0.0688\n",
      "Epoch [27/100], Step [1400/6235], Loss: 0.3267\n",
      "Epoch [27/100], Step [1500/6235], Loss: 0.0041\n",
      "Epoch [27/100], Step [1600/6235], Loss: 0.2193\n",
      "Epoch [27/100], Step [1700/6235], Loss: 0.0473\n",
      "Epoch [27/100], Step [1800/6235], Loss: 0.1873\n",
      "Epoch [27/100], Step [1900/6235], Loss: 0.6319\n",
      "Epoch [27/100], Step [2000/6235], Loss: 2.1961\n",
      "Epoch [27/100], Step [2100/6235], Loss: 2.3236\n",
      "Epoch [27/100], Step [2200/6235], Loss: 9.8891\n",
      "Epoch [27/100], Step [2300/6235], Loss: 14.6827\n",
      "Epoch [27/100], Step [2400/6235], Loss: 6.1299\n",
      "Epoch [27/100], Step [2500/6235], Loss: 38.1401\n",
      "Epoch [27/100], Step [2600/6235], Loss: 10.2273\n",
      "Epoch [27/100], Step [2700/6235], Loss: 17.2392\n",
      "Epoch [27/100], Step [2800/6235], Loss: 167.9342\n",
      "Epoch [27/100], Step [2900/6235], Loss: 6.9124\n",
      "Epoch [27/100], Step [3000/6235], Loss: 0.6751\n",
      "Epoch [27/100], Step [3100/6235], Loss: 67.5610\n",
      "Epoch [27/100], Step [3200/6235], Loss: 84.0411\n",
      "Epoch [27/100], Step [3300/6235], Loss: 1.4748\n",
      "Epoch [27/100], Step [3400/6235], Loss: 3.2223\n",
      "Epoch [27/100], Step [3500/6235], Loss: 28.2471\n",
      "Epoch [27/100], Step [3600/6235], Loss: 9.9529\n",
      "Epoch [27/100], Step [3700/6235], Loss: 1.1372\n",
      "Epoch [27/100], Step [3800/6235], Loss: 0.5977\n",
      "Epoch [27/100], Step [3900/6235], Loss: 1.6311\n",
      "Epoch [27/100], Step [4000/6235], Loss: 0.0937\n",
      "Epoch [27/100], Step [4100/6235], Loss: 4.4262\n",
      "Epoch [27/100], Step [4200/6235], Loss: 0.6114\n",
      "Epoch [27/100], Step [4300/6235], Loss: 10.7175\n",
      "Epoch [27/100], Step [4400/6235], Loss: 3.8398\n",
      "Epoch [27/100], Step [4500/6235], Loss: 59.5117\n",
      "Epoch [27/100], Step [4600/6235], Loss: 12.1877\n",
      "Epoch [27/100], Step [4700/6235], Loss: 1.5940\n",
      "Epoch [27/100], Step [4800/6235], Loss: 0.6740\n",
      "Epoch [27/100], Step [4900/6235], Loss: 1.2807\n",
      "Epoch [27/100], Step [5000/6235], Loss: 0.4169\n",
      "Epoch [27/100], Step [5100/6235], Loss: 4.4731\n",
      "Epoch [27/100], Step [5200/6235], Loss: 21.8884\n",
      "Epoch [27/100], Step [5300/6235], Loss: 30.2203\n",
      "Epoch [27/100], Step [5400/6235], Loss: 0.7220\n",
      "Epoch [27/100], Step [5500/6235], Loss: 0.4805\n",
      "Epoch [27/100], Step [5600/6235], Loss: 0.3064\n",
      "Epoch [27/100], Step [5700/6235], Loss: 2.0886\n",
      "Epoch [27/100], Step [5800/6235], Loss: 2.0474\n",
      "Epoch [27/100], Step [5900/6235], Loss: 0.0868\n",
      "Epoch [27/100], Step [6000/6235], Loss: 0.1040\n",
      "Epoch [27/100], Step [6100/6235], Loss: 0.2928\n",
      "Epoch [27/100], Step [6200/6235], Loss: 0.7197\n",
      "Epoch [27/100], Step [6300/6235], Loss: 4.7525\n",
      "Epoch [27/100], Step [6400/6235], Loss: 0.0762\n",
      "Epoch [27/100], Step [6500/6235], Loss: 1.6336\n",
      "Epoch [27/100], Step [6600/6235], Loss: 4.8124\n",
      "Epoch [27/100], Step [6700/6235], Loss: 1.2529\n",
      "Epoch [27/100], Step [6800/6235], Loss: 0.5680\n",
      "Epoch [27/100], Step [6900/6235], Loss: 3.3223\n",
      "Epoch [27/100], Step [7000/6235], Loss: 1.4192\n",
      "Epoch [27/100], Step [7100/6235], Loss: 0.3053\n",
      "Epoch [27/100], Step [7200/6235], Loss: 0.2492\n",
      "Epoch [27/100], Step [7300/6235], Loss: 1.8557\n",
      "Epoch [27/100], Step [7400/6235], Loss: 0.0341\n",
      "Epoch [27/100], Step [7500/6235], Loss: 2.7687\n",
      "Epoch [27/100], Step [7600/6235], Loss: 15.5855\n",
      "Epoch [27/100], Step [7700/6235], Loss: 1.8826\n",
      "Epoch [27/100], Step [7800/6235], Loss: 12.4770\n",
      "Epoch [27/100], Step [7900/6235], Loss: 13.8237\n",
      "Epoch [27/100], Step [8000/6235], Loss: 0.4891\n",
      "Epoch [27/100], Step [8100/6235], Loss: 3.6518\n",
      "Epoch [27/100], Step [8200/6235], Loss: 22.6347\n",
      "Epoch [27/100], Step [8300/6235], Loss: 64.1563\n",
      "Epoch [27/100], Step [8400/6235], Loss: 47.7987\n",
      "Epoch [27/100], Step [8500/6235], Loss: 76.8965\n",
      "Epoch [27/100], Step [8600/6235], Loss: 7.7357\n",
      "Epoch [27/100], Step [8700/6235], Loss: 70.2217\n",
      "Epoch [27/100], Step [8800/6235], Loss: 22.0984\n",
      "Epoch [27/100], Step [8900/6235], Loss: 33.8447\n",
      "Epoch [27/100], Step [9000/6235], Loss: 649.0693\n",
      "Epoch [27/100], Step [9100/6235], Loss: 1750.5892\n",
      "Epoch [27/100], Step [9200/6235], Loss: 3510.9832\n",
      "Epoch [27/100], Step [9300/6235], Loss: 55.0358\n",
      "Epoch [27/100], Step [9400/6235], Loss: 756.9880\n",
      "Epoch [27/100], Step [9500/6235], Loss: 13.1835\n",
      "Epoch [27/100], Step [9600/6235], Loss: 215.6165\n",
      "Epoch [27/100], Step [9700/6235], Loss: 199.5721\n",
      "Epoch [27/100], Step [9800/6235], Loss: 478.2719\n",
      "Epoch [27/100], Step [9900/6235], Loss: 111.0950\n",
      "Epoch [27/100], Step [10000/6235], Loss: 157.0506\n",
      "Epoch [27/100], Step [10100/6235], Loss: 3.6305\n",
      "Epoch [27/100], Step [10200/6235], Loss: 549.1353\n",
      "Epoch [27/100], Step [10300/6235], Loss: 4.8869\n",
      "Epoch [27/100], Step [10400/6235], Loss: 5.5944\n",
      "Epoch [27/100], Step [10500/6235], Loss: 21.3251\n",
      "Epoch [27/100], Step [10600/6235], Loss: 287.1012\n",
      "Epoch [27/100], Step [10700/6235], Loss: 31.6808\n",
      "Epoch [27/100], Step [10800/6235], Loss: 85.3577\n",
      "Epoch [27/100], Step [10900/6235], Loss: 1.7869\n",
      "Epoch [27/100], Step [11000/6235], Loss: 224.3593\n",
      "Epoch [27/100], Step [11100/6235], Loss: 18.8779\n",
      "Epoch [27/100], Step [11200/6235], Loss: 78.9663\n",
      "Epoch [27/100], Step [11300/6235], Loss: 219.8844\n",
      "Epoch [27/100], Step [11400/6235], Loss: 17.8292\n",
      "Epoch [27/100], Step [11500/6235], Loss: 1.8774\n",
      "Epoch [27/100], Step [11600/6235], Loss: 4.2474\n",
      "Epoch [27/100], Step [11700/6235], Loss: 81.1509\n",
      "Epoch [27/100], Step [11800/6235], Loss: 102.8016\n",
      "Epoch [27/100], Step [11900/6235], Loss: 244.3463\n",
      "Epoch [27/100], Step [12000/6235], Loss: 323.7623\n",
      "Epoch [27/100], Step [12100/6235], Loss: 211.0332\n",
      "Epoch [27/100], Step [12200/6235], Loss: 18.3700\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Step [12300/6235], Loss: 12.2755\n",
      "Epoch [27/100], Step [12400/6235], Loss: 403.8330\n",
      "Epoch [27/100], Step [12500/6235], Loss: 3.6296\n",
      "Epoch [27/100], Step [12600/6235], Loss: 91.1280\n",
      "Epoch [27/100], Step [12700/6235], Loss: 1.3932\n",
      "Epoch [27/100], Step [12800/6235], Loss: 11.6909\n",
      "Epoch [27/100], Step [12900/6235], Loss: 35.3136\n",
      "Epoch [27/100], Step [13000/6235], Loss: 0.3015\n",
      "Epoch [27/100], Step [13100/6235], Loss: 66.4071\n",
      "Epoch [27/100], Step [13200/6235], Loss: 8.6319\n",
      "Epoch [27/100], Step [13300/6235], Loss: 20.5608\n",
      "Epoch [27/100], Step [13400/6235], Loss: 250.5416\n",
      "Epoch [27/100], Step [13500/6235], Loss: 3.8994\n",
      "Epoch [27/100], Step [13600/6235], Loss: 1.2287\n",
      "Epoch [27/100], Step [13700/6235], Loss: 134.4724\n",
      "Epoch [27/100], Step [13800/6235], Loss: 155.4585\n",
      "Epoch [27/100], Step [13900/6235], Loss: 21.9825\n",
      "Epoch [27/100], Step [14000/6235], Loss: 8.2093\n",
      "Epoch [27/100], Step [14100/6235], Loss: 256.0025\n",
      "Epoch [27/100], Step [14200/6235], Loss: 44.0565\n",
      "Epoch [27/100], Step [14300/6235], Loss: 13.8179\n",
      "Epoch [27/100], Step [14400/6235], Loss: 35.5544\n",
      "Epoch [27/100], Step [14500/6235], Loss: 54.4663\n",
      "Epoch [27/100], Step [14600/6235], Loss: 0.2952\n",
      "Epoch [27/100], Step [14700/6235], Loss: 45.0236\n",
      "Epoch [27/100], Step [14800/6235], Loss: 31.6915\n",
      "Epoch [27/100], Step [14900/6235], Loss: 1.5764\n",
      "Epoch [27/100], Step [15000/6235], Loss: 2.9048\n",
      "Epoch [27/100], Step [15100/6235], Loss: 0.2334\n",
      "Epoch [27/100], Step [15200/6235], Loss: 5.2602\n",
      "Epoch [27/100], Step [15300/6235], Loss: 6.1963\n",
      "Epoch [27/100], Step [15400/6235], Loss: 86.6870\n",
      "Epoch [27/100], Step [15500/6235], Loss: 12.3700\n",
      "Epoch [27/100], Step [15600/6235], Loss: 176.5802\n",
      "Epoch [27/100], Step [15700/6235], Loss: 194.6868\n",
      "Epoch [27/100], Step [15800/6235], Loss: 10.3651\n",
      "Epoch [27/100], Step [15900/6235], Loss: 0.2124\n",
      "Epoch [27/100], Step [16000/6235], Loss: 142.4522\n",
      "Epoch [27/100], Step [16100/6235], Loss: 2.6290\n",
      "Epoch [27/100], Step [16200/6235], Loss: 0.5609\n",
      "Epoch [27/100], Step [16300/6235], Loss: 10.0374\n",
      "Epoch [27/100], Step [16400/6235], Loss: 16.4594\n",
      "Epoch [27/100], Step [16500/6235], Loss: 181.2394\n",
      "Epoch [27/100], Step [16600/6235], Loss: 45.1147\n",
      "Epoch [27/100], Step [16700/6235], Loss: 0.2909\n",
      "Epoch [27/100], Step [16800/6235], Loss: 10.0435\n",
      "Epoch [27/100], Step [16900/6235], Loss: 0.5092\n",
      "Epoch [27/100], Step [17000/6235], Loss: 0.1777\n",
      "Epoch [27/100], Step [17100/6235], Loss: 0.0195\n",
      "Epoch [27/100], Step [17200/6235], Loss: 223.7487\n",
      "Epoch [27/100], Step [17300/6235], Loss: 2.2086\n",
      "Epoch [27/100], Step [17400/6235], Loss: 31.2477\n",
      "Epoch [27/100], Step [17500/6235], Loss: 12.3601\n",
      "Epoch [27/100], Step [17600/6235], Loss: 2.3924\n",
      "Epoch [27/100], Step [17700/6235], Loss: 51.7388\n",
      "Epoch [27/100], Step [17800/6235], Loss: 10.8207\n",
      "Epoch [27/100], Step [17900/6235], Loss: 10.2183\n",
      "Epoch [27/100], Step [18000/6235], Loss: 7.5001\n",
      "Epoch [27/100], Step [18100/6235], Loss: 11.7485\n",
      "Epoch [27/100], Step [18200/6235], Loss: 1.0715\n",
      "Epoch [27/100], Step [18300/6235], Loss: 4.2087\n",
      "Epoch [27/100], Step [18400/6235], Loss: 0.5591\n",
      "Epoch [27/100], Step [18500/6235], Loss: 9.0393\n",
      "Epoch [27/100], Step [18600/6235], Loss: 3.8867\n",
      "Epoch [27/100], Step [18700/6235], Loss: 0.9441\n",
      "Epoch [27/100], Step [18800/6235], Loss: 83.7933\n",
      "Epoch [27/100], Step [18900/6235], Loss: 60.4266\n",
      "Epoch [27/100], Step [19000/6235], Loss: 7.4350\n",
      "Epoch [27/100], Step [19100/6235], Loss: 5.8408\n",
      "Epoch [27/100], Step [19200/6235], Loss: 1.7443\n",
      "Epoch [27/100], Step [19300/6235], Loss: 4.3079\n",
      "Epoch [27/100], Step [19400/6235], Loss: 138.7238\n",
      "Epoch [27/100], Step [19500/6235], Loss: 158.8995\n",
      "Epoch [27/100], Step [19600/6235], Loss: 112.6059\n",
      "Epoch [27/100], Step [19700/6235], Loss: 4.7206\n",
      "Epoch [27/100], Step [19800/6235], Loss: 2.0432\n",
      "Epoch [27/100], Step [19900/6235], Loss: 0.2880\n",
      "Epoch [27/100], Step [20000/6235], Loss: 84.0987\n",
      "Epoch [27/100], Step [20100/6235], Loss: 2.6948\n",
      "Epoch [27/100], Step [20200/6235], Loss: 4.2833\n",
      "Epoch [27/100], Step [20300/6235], Loss: 1.1975\n",
      "Epoch [27/100], Step [20400/6235], Loss: 23.3448\n",
      "Epoch [27/100], Step [20500/6235], Loss: 40.4571\n",
      "Epoch [27/100], Step [20600/6235], Loss: 153.6632\n",
      "Epoch [27/100], Step [20700/6235], Loss: 11.7621\n",
      "Epoch [27/100], Step [20800/6235], Loss: 1.3602\n",
      "Epoch [27/100], Step [20900/6235], Loss: 19.9428\n",
      "Epoch [27/100], Step [21000/6235], Loss: 15.2907\n",
      "Epoch [27/100], Step [21100/6235], Loss: 6.5346\n",
      "Epoch [27/100], Step [21200/6235], Loss: 0.3250\n",
      "Epoch [27/100], Step [21300/6235], Loss: 0.1134\n",
      "Epoch [27/100], Step [21400/6235], Loss: 5.6620\n",
      "Epoch [27/100], Step [21500/6235], Loss: 0.2226\n",
      "Epoch [27/100], Step [21600/6235], Loss: 25.8949\n",
      "Epoch [27/100], Step [21700/6235], Loss: 0.2990\n",
      "Epoch [27/100], Step [21800/6235], Loss: 5.4880\n",
      "Epoch [27/100], Step [21900/6235], Loss: 1.4064\n",
      "Epoch [27/100], Step [22000/6235], Loss: 7.4910\n",
      "Epoch [27/100], Step [22100/6235], Loss: 0.8180\n",
      "Epoch [27/100], Step [22200/6235], Loss: 5.7682\n",
      "Epoch [27/100], Step [22300/6235], Loss: 2.3234\n",
      "Epoch [27/100], Step [22400/6235], Loss: 11.4165\n",
      "Epoch [27/100], Step [22500/6235], Loss: 170.7303\n",
      "Epoch [27/100], Step [22600/6235], Loss: 5.2395\n",
      "Epoch [27/100], Step [22700/6235], Loss: 0.6784\n",
      "Epoch [27/100], Step [22800/6235], Loss: 3.6709\n",
      "Epoch [27/100], Step [22900/6235], Loss: 5.2514\n",
      "Epoch [27/100], Step [23000/6235], Loss: 6.5515\n",
      "Epoch [27/100], Step [23100/6235], Loss: 7.4431\n",
      "Epoch [27/100], Step [23200/6235], Loss: 6.9306\n",
      "Epoch [27/100], Step [23300/6235], Loss: 19.3162\n",
      "Epoch [27/100], Step [23400/6235], Loss: 1.5959\n",
      "Epoch [27/100], Step [23500/6235], Loss: 0.1367\n",
      "Epoch [27/100], Step [23600/6235], Loss: 126.4981\n",
      "Epoch [27/100], Step [23700/6235], Loss: 5.0205\n",
      "Epoch [27/100], Step [23800/6235], Loss: 1.2483\n",
      "Epoch [27/100], Step [23900/6235], Loss: 5.1367\n",
      "Epoch [27/100], Step [24000/6235], Loss: 0.5420\n",
      "Epoch [27/100], Step [24100/6235], Loss: 1.1840\n",
      "Epoch [27/100], Step [24200/6235], Loss: 28.9479\n",
      "Epoch [27/100], Step [24300/6235], Loss: 1.2810\n",
      "Epoch [27/100], Step [24400/6235], Loss: 1.2217\n",
      "Epoch [27/100], Step [24500/6235], Loss: 0.3886\n",
      "Epoch [27/100], Step [24600/6235], Loss: 0.1822\n",
      "Epoch [27/100], Step [24700/6235], Loss: 1.2343\n",
      "Epoch [27/100], Step [24800/6235], Loss: 0.4107\n",
      "Epoch [27/100], Step [24900/6235], Loss: 14.6073\n",
      "Epoch [27/100], Step [25000/6235], Loss: 13.8688\n",
      "Epoch [27/100], Step [25100/6235], Loss: 6.3025\n",
      "Epoch [27/100], Step [25200/6235], Loss: 0.0653\n",
      "Epoch [27/100], Step [25300/6235], Loss: 0.9031\n",
      "Epoch [27/100], Step [25400/6235], Loss: 9.7995\n",
      "Epoch [27/100], Step [25500/6235], Loss: 8.2192\n",
      "Epoch [27/100], Step [25600/6235], Loss: 6.2714\n",
      "Epoch [27/100], Step [25700/6235], Loss: 0.2785\n",
      "Epoch [27/100], Step [25800/6235], Loss: 0.0517\n",
      "Epoch [27/100], Step [25900/6235], Loss: 7.0952\n",
      "Epoch [27/100], Step [26000/6235], Loss: 0.7798\n",
      "Epoch [27/100], Step [26100/6235], Loss: 0.0537\n",
      "Epoch [27/100], Step [26200/6235], Loss: 1.3828\n",
      "Epoch [27/100], Step [26300/6235], Loss: 1.9385\n",
      "Epoch [27/100], Step [26400/6235], Loss: 0.3028\n",
      "Epoch [27/100], Step [26500/6235], Loss: 0.0311\n",
      "Epoch [27/100], Step [26600/6235], Loss: 0.6296\n",
      "Epoch [27/100], Step [26700/6235], Loss: 0.2071\n",
      "Epoch [27/100], Step [26800/6235], Loss: 0.1180\n",
      "Epoch [27/100], Step [26900/6235], Loss: 0.0319\n",
      "Epoch [27/100], Step [27000/6235], Loss: 16.1253\n",
      "Epoch [27/100], Step [27100/6235], Loss: 0.0520\n",
      "Epoch [27/100], Step [27200/6235], Loss: 0.0144\n",
      "Epoch [27/100], Step [27300/6235], Loss: 0.1024\n",
      "Epoch [27/100], Step [27400/6235], Loss: 0.6607\n",
      "Epoch [27/100], Step [27500/6235], Loss: 0.9892\n",
      "Epoch [27/100], Step [27600/6235], Loss: 1.1672\n",
      "Epoch [27/100], Step [27700/6235], Loss: 0.7705\n",
      "Epoch [27/100], Step [27800/6235], Loss: 5.6583\n",
      "Epoch [27/100], Step [27900/6235], Loss: 0.0735\n",
      "Epoch [27/100], Step [28000/6235], Loss: 129.2049\n",
      "Epoch [27/100], Step [28100/6235], Loss: 3.6289\n",
      "Epoch [27/100], Step [28200/6235], Loss: 28.7370\n",
      "Epoch [27/100], Step [28300/6235], Loss: 1.9261\n",
      "Epoch [27/100], Step [28400/6235], Loss: 21.8731\n",
      "Epoch [27/100], Step [28500/6235], Loss: 1.7642\n",
      "Epoch [27/100], Step [28600/6235], Loss: 1.3735\n",
      "Epoch [27/100], Step [28700/6235], Loss: 2.5855\n",
      "Epoch [27/100], Step [28800/6235], Loss: 0.6735\n",
      "Epoch [27/100], Step [28900/6235], Loss: 39.6675\n",
      "Epoch [27/100], Step [29000/6235], Loss: 6.4599\n",
      "Epoch [27/100], Step [29100/6235], Loss: 0.4720\n",
      "Epoch [27/100], Step [29200/6235], Loss: 5.7034\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Step [29300/6235], Loss: 12.5155\n",
      "Epoch [27/100], Step [29400/6235], Loss: 0.4250\n",
      "Epoch [27/100], Step [29500/6235], Loss: 1.2117\n",
      "Epoch [27/100], Step [29600/6235], Loss: 0.4230\n",
      "Epoch [27/100], Step [29700/6235], Loss: 2.8151\n",
      "Epoch [27/100], Step [29800/6235], Loss: 0.6376\n",
      "Epoch [27/100], Step [29900/6235], Loss: 4.5593\n",
      "Epoch [27/100], Step [30000/6235], Loss: 1.7235\n",
      "Epoch [27/100], Step [30100/6235], Loss: 7.1033\n",
      "Epoch [27/100], Step [30200/6235], Loss: 1.8531\n",
      "Epoch [27/100], Step [30300/6235], Loss: 0.0547\n",
      "Epoch [27/100], Step [30400/6235], Loss: 2.4545\n",
      "Epoch [27/100], Step [30500/6235], Loss: 0.2677\n",
      "Epoch [27/100], Step [30600/6235], Loss: 1.1719\n",
      "Epoch [27/100], Step [30700/6235], Loss: 2.5255\n",
      "Epoch [27/100], Step [30800/6235], Loss: 0.4959\n",
      "Epoch [27/100], Step [30900/6235], Loss: 1.4755\n",
      "Epoch [27/100], Step [31000/6235], Loss: 0.3038\n",
      "Epoch [27/100], Step [31100/6235], Loss: 0.5072\n",
      "Epoch [27/100], Step [31200/6235], Loss: 4.1197\n",
      "Epoch [27/100], Step [31300/6235], Loss: 1.1104\n",
      "Epoch [27/100], Step [31400/6235], Loss: 4.4072\n",
      "Epoch [27/100], Step [31500/6235], Loss: 0.6169\n",
      "Epoch [27/100], Step [31600/6235], Loss: 3.5617\n",
      "Epoch [27/100], Step [31700/6235], Loss: 8.9951\n",
      "Epoch [27/100], Step [31800/6235], Loss: 1.7813\n",
      "Epoch [27/100], Step [31900/6235], Loss: 34.9790\n",
      "Epoch [27/100], Step [32000/6235], Loss: 0.6647\n",
      "Epoch [27/100], Step [32100/6235], Loss: 0.8085\n",
      "Epoch [27/100], Step [32200/6235], Loss: 59.8846\n",
      "Epoch [27/100], Step [32300/6235], Loss: 2.4278\n",
      "Epoch [27/100], Step [32400/6235], Loss: 1.1764\n",
      "Epoch [27/100], Step [32500/6235], Loss: 8.4403\n",
      "Epoch [27/100], Step [32600/6235], Loss: 0.2363\n",
      "Epoch [27/100], Step [32700/6235], Loss: 106.4678\n",
      "Epoch [27/100], Step [32800/6235], Loss: 43.7730\n",
      "Epoch [27/100], Step [32900/6235], Loss: 0.8957\n",
      "Epoch [27/100], Step [33000/6235], Loss: 0.8588\n",
      "Epoch [27/100], Step [33100/6235], Loss: 0.4937\n",
      "Epoch [27/100], Step [33200/6235], Loss: 1.4463\n",
      "Epoch [27/100], Step [33300/6235], Loss: 1.1136\n",
      "Epoch [27/100], Step [33400/6235], Loss: 143.9555\n",
      "Epoch [27/100], Step [33500/6235], Loss: 1.2826\n",
      "Epoch [27/100], Step [33600/6235], Loss: 5.5524\n",
      "Epoch [27/100], Step [33700/6235], Loss: 1.0778\n",
      "Epoch [27/100], Step [33800/6235], Loss: 0.7598\n",
      "Epoch [27/100], Step [33900/6235], Loss: 27.4082\n",
      "Epoch [27/100], Step [34000/6235], Loss: 0.0425\n",
      "Epoch [27/100], Step [34100/6235], Loss: 0.3892\n",
      "Epoch [27/100], Step [34200/6235], Loss: 1.9703\n",
      "Epoch [27/100], Step [34300/6235], Loss: 6.0313\n",
      "Epoch [27/100], Step [34400/6235], Loss: 0.1613\n",
      "Epoch [27/100], Step [34500/6235], Loss: 31.3279\n",
      "Epoch [27/100], Step [34600/6235], Loss: 3.0522\n",
      "Epoch [27/100], Step [34700/6235], Loss: 26.9367\n",
      "Epoch [27/100], Step [34800/6235], Loss: 7.7966\n",
      "Epoch [27/100], Step [34900/6235], Loss: 47.1373\n",
      "Epoch [27/100], Step [35000/6235], Loss: 2.3539\n",
      "Epoch [27/100], Step [35100/6235], Loss: 4.0313\n",
      "Epoch [27/100], Step [35200/6235], Loss: 1.0458\n",
      "Epoch [27/100], Step [35300/6235], Loss: 1.0231\n",
      "Epoch [27/100], Step [35400/6235], Loss: 0.4136\n",
      "Epoch [27/100], Step [35500/6235], Loss: 1.5067\n",
      "Epoch [27/100], Step [35600/6235], Loss: 0.7483\n",
      "Epoch [27/100], Step [35700/6235], Loss: 6.4099\n",
      "Epoch [27/100], Step [35800/6235], Loss: 6.2734\n",
      "Epoch [27/100], Step [35900/6235], Loss: 5.0147\n",
      "Epoch [27/100], Step [36000/6235], Loss: 0.0822\n",
      "Epoch [27/100], Step [36100/6235], Loss: 0.0509\n",
      "Epoch [27/100], Step [36200/6235], Loss: 24.9057\n",
      "Epoch [27/100], Step [36300/6235], Loss: 0.1423\n",
      "Epoch [27/100], Step [36400/6235], Loss: 2.9761\n",
      "Epoch [27/100], Step [36500/6235], Loss: 7.8900\n",
      "Epoch [27/100], Step [36600/6235], Loss: 0.1051\n",
      "Epoch [27/100], Step [36700/6235], Loss: 0.5965\n",
      "Epoch [27/100], Step [36800/6235], Loss: 7.6620\n",
      "Epoch [27/100], Step [36900/6235], Loss: 9.4679\n",
      "Epoch [27/100], Step [37000/6235], Loss: 0.8605\n",
      "Epoch [27/100], Step [37100/6235], Loss: 1.5473\n",
      "Epoch [27/100], Step [37200/6235], Loss: 0.0553\n",
      "Epoch [27/100], Step [37300/6235], Loss: 0.0270\n",
      "Epoch [27/100], Step [37400/6235], Loss: 0.1918\n",
      "Epoch [27/100], Step [37500/6235], Loss: 5.7809\n",
      "Epoch [27/100], Step [37600/6235], Loss: 12.1183\n",
      "Epoch [27/100], Step [37700/6235], Loss: 1.9921\n",
      "Epoch [27/100], Step [37800/6235], Loss: 5.7534\n",
      "Epoch [27/100], Step [37900/6235], Loss: 7.5540\n",
      "Epoch [27/100], Step [38000/6235], Loss: 0.6905\n",
      "Epoch [27/100], Step [38100/6235], Loss: 4.1522\n",
      "Epoch [27/100], Step [38200/6235], Loss: 2.7099\n",
      "Epoch [27/100], Step [38300/6235], Loss: 0.5782\n",
      "Epoch [27/100], Step [38400/6235], Loss: 0.0838\n",
      "Epoch [27/100], Step [38500/6235], Loss: 2.3608\n",
      "Epoch [27/100], Step [38600/6235], Loss: 0.2438\n",
      "Epoch [27/100], Step [38700/6235], Loss: 0.0514\n",
      "Epoch [27/100], Step [38800/6235], Loss: 0.2159\n",
      "Epoch [27/100], Step [38900/6235], Loss: 9.4899\n",
      "Epoch [27/100], Step [39000/6235], Loss: 9.7314\n",
      "Epoch [27/100], Step [39100/6235], Loss: 15.5300\n",
      "Epoch [27/100], Step [39200/6235], Loss: 0.2019\n",
      "Epoch [27/100], Step [39300/6235], Loss: 28.4723\n",
      "Epoch [27/100], Step [39400/6235], Loss: 230.1808\n",
      "Epoch [27/100], Step [39500/6235], Loss: 12.1603\n",
      "Epoch [27/100], Step [39600/6235], Loss: 10.3309\n",
      "Epoch [27/100], Step [39700/6235], Loss: 170.4877\n",
      "Epoch [27/100], Step [39800/6235], Loss: 76.0739\n",
      "Epoch [27/100], Step [39900/6235], Loss: 1.1085\n",
      "Epoch [27/100], Step [40000/6235], Loss: 7.0254\n",
      "Epoch [27/100], Step [40100/6235], Loss: 18.9924\n",
      "Epoch [27/100], Step [40200/6235], Loss: 2.3787\n",
      "Epoch [27/100], Step [40300/6235], Loss: 0.9047\n",
      "Epoch [27/100], Step [40400/6235], Loss: 1.6158\n",
      "Epoch [27/100], Step [40500/6235], Loss: 2.6186\n",
      "Epoch [27/100], Step [40600/6235], Loss: 0.1872\n",
      "Epoch [27/100], Step [40700/6235], Loss: 7.3350\n",
      "Epoch [27/100], Step [40800/6235], Loss: 0.7774\n",
      "Epoch [27/100], Step [40900/6235], Loss: 0.4326\n",
      "Epoch [27/100], Step [41000/6235], Loss: 47.5667\n",
      "Epoch [27/100], Step [41100/6235], Loss: 17.6974\n",
      "Epoch [27/100], Step [41200/6235], Loss: 4.2375\n",
      "Epoch [27/100], Step [41300/6235], Loss: 2.6573\n",
      "Epoch [27/100], Step [41400/6235], Loss: 1.8421\n",
      "Epoch [27/100], Step [41500/6235], Loss: 0.6520\n",
      "Epoch [27/100], Step [41600/6235], Loss: 0.0343\n",
      "Epoch [27/100], Step [41700/6235], Loss: 0.2736\n",
      "Epoch [27/100], Step [41800/6235], Loss: 1.8911\n",
      "Epoch [27/100], Step [41900/6235], Loss: 4.6888\n",
      "Epoch [27/100], Step [42000/6235], Loss: 4.2465\n",
      "Epoch [27/100], Step [42100/6235], Loss: 9.6238\n",
      "Epoch [27/100], Step [42200/6235], Loss: 40.3218\n",
      "Epoch [27/100], Step [42300/6235], Loss: 1.6423\n",
      "Epoch [27/100], Step [42400/6235], Loss: 3.2425\n",
      "Epoch [27/100], Step [42500/6235], Loss: 0.7437\n",
      "Epoch [27/100], Step [42600/6235], Loss: 2.3860\n",
      "Epoch [27/100], Step [42700/6235], Loss: 0.7047\n",
      "Epoch [27/100], Step [42800/6235], Loss: 8.5018\n",
      "Epoch [27/100], Step [42900/6235], Loss: 2.3080\n",
      "Epoch [27/100], Step [43000/6235], Loss: 0.2012\n",
      "Epoch [27/100], Step [43100/6235], Loss: 0.0734\n",
      "Epoch [27/100], Step [43200/6235], Loss: 1.0183\n",
      "Epoch [27/100], Step [43300/6235], Loss: 7.7680\n",
      "Epoch [27/100], Step [43400/6235], Loss: 9.9041\n",
      "Epoch [27/100], Step [43500/6235], Loss: 9.7730\n",
      "Epoch [27/100], Step [43600/6235], Loss: 8.4578\n",
      "Epoch [27/100], Step [43700/6235], Loss: 49.7737\n",
      "Epoch [27/100], Step [43800/6235], Loss: 0.5174\n",
      "Epoch [27/100], Step [43900/6235], Loss: 1.8789\n",
      "Epoch [27/100], Step [44000/6235], Loss: 32.3996\n",
      "Epoch [27/100], Step [44100/6235], Loss: 0.4790\n",
      "Epoch [27/100], Step [44200/6235], Loss: 1.0877\n",
      "Epoch [27/100], Step [44300/6235], Loss: 44.5872\n",
      "Epoch [27/100], Step [44400/6235], Loss: 0.7348\n",
      "Epoch [27/100], Step [44500/6235], Loss: 2.7781\n",
      "Epoch [27/100], Step [44600/6235], Loss: 16.2171\n",
      "Epoch [27/100], Step [44700/6235], Loss: 39.9707\n",
      "Epoch [27/100], Step [44800/6235], Loss: 3.2800\n",
      "Epoch [27/100], Step [44900/6235], Loss: 5.9956\n",
      "Epoch [27/100], Step [45000/6235], Loss: 4.9292\n",
      "Epoch [27/100], Step [45100/6235], Loss: 39.1368\n",
      "Epoch [27/100], Step [45200/6235], Loss: 1.2252\n",
      "Epoch [27/100], Step [45300/6235], Loss: 28.4684\n",
      "Epoch [27/100], Step [45400/6235], Loss: 11.7455\n",
      "Epoch [27/100], Step [45500/6235], Loss: 0.5587\n",
      "Epoch [27/100], Step [45600/6235], Loss: 0.1657\n",
      "Epoch [27/100], Step [45700/6235], Loss: 88.5105\n",
      "Epoch [27/100], Step [45800/6235], Loss: 293.6417\n",
      "Epoch [27/100], Step [45900/6235], Loss: 3.2442\n",
      "Epoch [27/100], Step [46000/6235], Loss: 17.2985\n",
      "Epoch [27/100], Step [46100/6235], Loss: 17.9136\n",
      "Epoch [27/100], Step [46200/6235], Loss: 25.5323\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [27/100], Step [46300/6235], Loss: 51.9730\n",
      "Epoch [27/100], Step [46400/6235], Loss: 10.3111\n",
      "Epoch [27/100], Step [46500/6235], Loss: 64.6249\n",
      "Epoch [27/100], Step [46600/6235], Loss: 26.3827\n",
      "Epoch [27/100], Step [46700/6235], Loss: 4.7813\n",
      "Epoch [27/100], Step [46800/6235], Loss: 11.0135\n",
      "Epoch [27/100], Step [46900/6235], Loss: 9.0951\n",
      "Epoch [27/100], Step [47000/6235], Loss: 3.3194\n",
      "Epoch [27/100], Step [47100/6235], Loss: 8.1140\n",
      "Epoch [27/100], Step [47200/6235], Loss: 23.5355\n",
      "Epoch [27/100], Step [47300/6235], Loss: 1.0464\n",
      "Epoch [27/100], Step [47400/6235], Loss: 17.8560\n",
      "Epoch [27/100], Step [47500/6235], Loss: 0.9658\n",
      "Epoch [27/100], Step [47600/6235], Loss: 3.0741\n",
      "Epoch [27/100], Step [47700/6235], Loss: 3.9356\n",
      "Epoch [27/100], Step [47800/6235], Loss: 3.3189\n",
      "Epoch [27/100], Step [47900/6235], Loss: 22.4815\n",
      "Epoch [27/100], Step [48000/6235], Loss: 98.2427\n",
      "Epoch [27/100], Step [48100/6235], Loss: 3.9775\n",
      "Epoch [27/100], Step [48200/6235], Loss: 12.3565\n",
      "Epoch [27/100], Step [48300/6235], Loss: 260.8014\n",
      "Epoch [27/100], Step [48400/6235], Loss: 26.2018\n",
      "Epoch [27/100], Step [48500/6235], Loss: 13.4510\n",
      "Epoch [27/100], Step [48600/6235], Loss: 160.2955\n",
      "Epoch [27/100], Step [48700/6235], Loss: 44.0042\n",
      "Epoch [27/100], Step [48800/6235], Loss: 202.1037\n",
      "Epoch [27/100], Step [48900/6235], Loss: 79.1557\n",
      "Epoch [27/100], Step [49000/6235], Loss: 276.2729\n",
      "Epoch [27/100], Step [49100/6235], Loss: 2339.5417\n",
      "Epoch [27/100], Step [49200/6235], Loss: 582.9383\n",
      "Epoch [27/100], Step [49300/6235], Loss: 1207.6135\n",
      "Epoch [27/100], Step [49400/6235], Loss: 2.2169\n",
      "Epoch [27/100], Step [49500/6235], Loss: 24.7049\n",
      "Epoch [27/100], Step [49600/6235], Loss: 76.8924\n",
      "Epoch [27/100], Step [49700/6235], Loss: 12717.7324\n",
      "Epoch [27/100], Step [49800/6235], Loss: 793.3629\n",
      "Epoch [28/100], Step [100/6235], Loss: 1.8481\n",
      "Epoch [28/100], Step [200/6235], Loss: 0.2877\n",
      "Epoch [28/100], Step [300/6235], Loss: 0.1962\n",
      "Epoch [28/100], Step [400/6235], Loss: 0.0263\n",
      "Epoch [28/100], Step [500/6235], Loss: 47.2642\n",
      "Epoch [28/100], Step [600/6235], Loss: 0.1008\n",
      "Epoch [28/100], Step [700/6235], Loss: 1.9844\n",
      "Epoch [28/100], Step [800/6235], Loss: 0.1113\n",
      "Epoch [28/100], Step [900/6235], Loss: 0.1926\n",
      "Epoch [28/100], Step [1000/6235], Loss: 0.1172\n",
      "Epoch [28/100], Step [1100/6235], Loss: 0.4327\n",
      "Epoch [28/100], Step [1200/6235], Loss: 0.2177\n",
      "Epoch [28/100], Step [1300/6235], Loss: 0.0421\n",
      "Epoch [28/100], Step [1400/6235], Loss: 0.2041\n",
      "Epoch [28/100], Step [1500/6235], Loss: 0.0121\n",
      "Epoch [28/100], Step [1600/6235], Loss: 0.2848\n",
      "Epoch [28/100], Step [1700/6235], Loss: 0.0596\n",
      "Epoch [28/100], Step [1800/6235], Loss: 0.2459\n",
      "Epoch [28/100], Step [1900/6235], Loss: 0.3928\n",
      "Epoch [28/100], Step [2000/6235], Loss: 2.3539\n",
      "Epoch [28/100], Step [2100/6235], Loss: 2.1904\n",
      "Epoch [28/100], Step [2200/6235], Loss: 7.7284\n",
      "Epoch [28/100], Step [2300/6235], Loss: 5.3081\n",
      "Epoch [28/100], Step [2400/6235], Loss: 1.6616\n",
      "Epoch [28/100], Step [2500/6235], Loss: 35.6884\n",
      "Epoch [28/100], Step [2600/6235], Loss: 12.7045\n",
      "Epoch [28/100], Step [2700/6235], Loss: 10.1522\n",
      "Epoch [28/100], Step [2800/6235], Loss: 127.6909\n",
      "Epoch [28/100], Step [2900/6235], Loss: 10.4738\n",
      "Epoch [28/100], Step [3000/6235], Loss: 0.3608\n",
      "Epoch [28/100], Step [3100/6235], Loss: 67.8842\n",
      "Epoch [28/100], Step [3200/6235], Loss: 85.7798\n",
      "Epoch [28/100], Step [3300/6235], Loss: 4.0375\n",
      "Epoch [28/100], Step [3400/6235], Loss: 2.4189\n",
      "Epoch [28/100], Step [3500/6235], Loss: 31.3550\n",
      "Epoch [28/100], Step [3600/6235], Loss: 10.3203\n",
      "Epoch [28/100], Step [3700/6235], Loss: 0.2830\n",
      "Epoch [28/100], Step [3800/6235], Loss: 0.4736\n",
      "Epoch [28/100], Step [3900/6235], Loss: 1.3789\n",
      "Epoch [28/100], Step [4000/6235], Loss: 0.0659\n",
      "Epoch [28/100], Step [4100/6235], Loss: 5.7474\n",
      "Epoch [28/100], Step [4200/6235], Loss: 0.6799\n",
      "Epoch [28/100], Step [4300/6235], Loss: 9.4665\n",
      "Epoch [28/100], Step [4400/6235], Loss: 4.3403\n",
      "Epoch [28/100], Step [4500/6235], Loss: 43.6405\n",
      "Epoch [28/100], Step [4600/6235], Loss: 4.0385\n",
      "Epoch [28/100], Step [4700/6235], Loss: 0.4853\n",
      "Epoch [28/100], Step [4800/6235], Loss: 7.2021\n",
      "Epoch [28/100], Step [4900/6235], Loss: 0.1804\n",
      "Epoch [28/100], Step [5000/6235], Loss: 0.1564\n",
      "Epoch [28/100], Step [5100/6235], Loss: 2.6085\n",
      "Epoch [28/100], Step [5200/6235], Loss: 0.5408\n",
      "Epoch [28/100], Step [5300/6235], Loss: 39.0108\n",
      "Epoch [28/100], Step [5400/6235], Loss: 1.4863\n",
      "Epoch [28/100], Step [5500/6235], Loss: 0.2943\n",
      "Epoch [28/100], Step [5600/6235], Loss: 1.2558\n",
      "Epoch [28/100], Step [5700/6235], Loss: 0.6792\n",
      "Epoch [28/100], Step [5800/6235], Loss: 0.4144\n",
      "Epoch [28/100], Step [5900/6235], Loss: 0.2951\n",
      "Epoch [28/100], Step [6000/6235], Loss: 2.1677\n",
      "Epoch [28/100], Step [6100/6235], Loss: 0.2944\n",
      "Epoch [28/100], Step [6200/6235], Loss: 1.5677\n",
      "Epoch [28/100], Step [6300/6235], Loss: 1.8659\n",
      "Epoch [28/100], Step [6400/6235], Loss: 0.0782\n",
      "Epoch [28/100], Step [6500/6235], Loss: 0.9932\n",
      "Epoch [28/100], Step [6600/6235], Loss: 8.4673\n",
      "Epoch [28/100], Step [6700/6235], Loss: 2.2384\n",
      "Epoch [28/100], Step [6800/6235], Loss: 0.2459\n",
      "Epoch [28/100], Step [6900/6235], Loss: 1.8950\n",
      "Epoch [28/100], Step [7000/6235], Loss: 1.2099\n",
      "Epoch [28/100], Step [7100/6235], Loss: 0.6086\n",
      "Epoch [28/100], Step [7200/6235], Loss: 0.1855\n",
      "Epoch [28/100], Step [7300/6235], Loss: 0.0697\n",
      "Epoch [28/100], Step [7400/6235], Loss: 0.2552\n",
      "Epoch [28/100], Step [7500/6235], Loss: 1.5334\n",
      "Epoch [28/100], Step [7600/6235], Loss: 16.3430\n",
      "Epoch [28/100], Step [7700/6235], Loss: 13.6313\n",
      "Epoch [28/100], Step [7800/6235], Loss: 15.4791\n",
      "Epoch [28/100], Step [7900/6235], Loss: 17.8870\n",
      "Epoch [28/100], Step [8000/6235], Loss: 0.4977\n",
      "Epoch [28/100], Step [8100/6235], Loss: 3.4456\n",
      "Epoch [28/100], Step [8200/6235], Loss: 23.8490\n",
      "Epoch [28/100], Step [8300/6235], Loss: 52.7942\n",
      "Epoch [28/100], Step [8400/6235], Loss: 17.7415\n",
      "Epoch [28/100], Step [8500/6235], Loss: 65.8925\n",
      "Epoch [28/100], Step [8600/6235], Loss: 7.1751\n",
      "Epoch [28/100], Step [8700/6235], Loss: 23.4910\n",
      "Epoch [28/100], Step [8800/6235], Loss: 344.4500\n",
      "Epoch [28/100], Step [8900/6235], Loss: 123.9110\n",
      "Epoch [28/100], Step [9000/6235], Loss: 473.0817\n",
      "Epoch [28/100], Step [9100/6235], Loss: 452.9737\n",
      "Epoch [28/100], Step [9200/6235], Loss: 2727.2280\n",
      "Epoch [28/100], Step [9300/6235], Loss: 106.3296\n",
      "Epoch [28/100], Step [9400/6235], Loss: 292.4750\n",
      "Epoch [28/100], Step [9500/6235], Loss: 833.5518\n",
      "Epoch [28/100], Step [9600/6235], Loss: 262.9160\n",
      "Epoch [28/100], Step [9700/6235], Loss: 42.6461\n",
      "Epoch [28/100], Step [9800/6235], Loss: 349.5561\n",
      "Epoch [28/100], Step [9900/6235], Loss: 54.4419\n",
      "Epoch [28/100], Step [10000/6235], Loss: 126.4879\n",
      "Epoch [28/100], Step [10100/6235], Loss: 1.4502\n",
      "Epoch [28/100], Step [10200/6235], Loss: 727.5428\n",
      "Epoch [28/100], Step [10300/6235], Loss: 6.4580\n",
      "Epoch [28/100], Step [10400/6235], Loss: 0.5311\n",
      "Epoch [28/100], Step [10500/6235], Loss: 7.1320\n",
      "Epoch [28/100], Step [10600/6235], Loss: 366.2496\n",
      "Epoch [28/100], Step [10700/6235], Loss: 26.3180\n",
      "Epoch [28/100], Step [10800/6235], Loss: 98.1873\n",
      "Epoch [28/100], Step [10900/6235], Loss: 1.2087\n",
      "Epoch [28/100], Step [11000/6235], Loss: 237.3401\n",
      "Epoch [28/100], Step [11100/6235], Loss: 24.0678\n",
      "Epoch [28/100], Step [11200/6235], Loss: 67.0323\n",
      "Epoch [28/100], Step [11300/6235], Loss: 207.9379\n",
      "Epoch [28/100], Step [11400/6235], Loss: 7.0587\n",
      "Epoch [28/100], Step [11500/6235], Loss: 1.2232\n",
      "Epoch [28/100], Step [11600/6235], Loss: 3.4430\n",
      "Epoch [28/100], Step [11700/6235], Loss: 71.1294\n",
      "Epoch [28/100], Step [11800/6235], Loss: 1.4558\n",
      "Epoch [28/100], Step [11900/6235], Loss: 534.0976\n",
      "Epoch [28/100], Step [12000/6235], Loss: 407.1284\n",
      "Epoch [28/100], Step [12100/6235], Loss: 255.8025\n",
      "Epoch [28/100], Step [12200/6235], Loss: 4.9219\n",
      "Epoch [28/100], Step [12300/6235], Loss: 5.5105\n",
      "Epoch [28/100], Step [12400/6235], Loss: 470.4527\n",
      "Epoch [28/100], Step [12500/6235], Loss: 6.6278\n",
      "Epoch [28/100], Step [12600/6235], Loss: 80.8792\n",
      "Epoch [28/100], Step [12700/6235], Loss: 1.8030\n",
      "Epoch [28/100], Step [12800/6235], Loss: 12.3295\n",
      "Epoch [28/100], Step [12900/6235], Loss: 30.7443\n",
      "Epoch [28/100], Step [13000/6235], Loss: 0.4101\n",
      "Epoch [28/100], Step [13100/6235], Loss: 67.9787\n",
      "Epoch [28/100], Step [13200/6235], Loss: 10.8867\n",
      "Epoch [28/100], Step [13300/6235], Loss: 24.5829\n",
      "Epoch [28/100], Step [13400/6235], Loss: 254.2283\n",
      "Epoch [28/100], Step [13500/6235], Loss: 0.6840\n",
      "Epoch [28/100], Step [13600/6235], Loss: 4.8217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Step [13700/6235], Loss: 196.7958\n",
      "Epoch [28/100], Step [13800/6235], Loss: 72.4485\n",
      "Epoch [28/100], Step [13900/6235], Loss: 73.5252\n",
      "Epoch [28/100], Step [14000/6235], Loss: 2.1158\n",
      "Epoch [28/100], Step [14100/6235], Loss: 37.1198\n",
      "Epoch [28/100], Step [14200/6235], Loss: 2.9923\n",
      "Epoch [28/100], Step [14300/6235], Loss: 19.9089\n",
      "Epoch [28/100], Step [14400/6235], Loss: 39.9759\n",
      "Epoch [28/100], Step [14500/6235], Loss: 52.9869\n",
      "Epoch [28/100], Step [14600/6235], Loss: 0.3539\n",
      "Epoch [28/100], Step [14700/6235], Loss: 44.4950\n",
      "Epoch [28/100], Step [14800/6235], Loss: 33.1936\n",
      "Epoch [28/100], Step [14900/6235], Loss: 2.1644\n",
      "Epoch [28/100], Step [15000/6235], Loss: 3.0241\n",
      "Epoch [28/100], Step [15100/6235], Loss: 0.1654\n",
      "Epoch [28/100], Step [15200/6235], Loss: 13.6678\n",
      "Epoch [28/100], Step [15300/6235], Loss: 19.7604\n",
      "Epoch [28/100], Step [15400/6235], Loss: 53.8628\n",
      "Epoch [28/100], Step [15500/6235], Loss: 1.7042\n",
      "Epoch [28/100], Step [15600/6235], Loss: 184.4935\n",
      "Epoch [28/100], Step [15700/6235], Loss: 196.4919\n",
      "Epoch [28/100], Step [15800/6235], Loss: 9.4555\n",
      "Epoch [28/100], Step [15900/6235], Loss: 0.4300\n",
      "Epoch [28/100], Step [16000/6235], Loss: 33.6910\n",
      "Epoch [28/100], Step [16100/6235], Loss: 3.8478\n",
      "Epoch [28/100], Step [16200/6235], Loss: 0.5200\n",
      "Epoch [28/100], Step [16300/6235], Loss: 8.6016\n",
      "Epoch [28/100], Step [16400/6235], Loss: 22.2210\n",
      "Epoch [28/100], Step [16500/6235], Loss: 522.7081\n",
      "Epoch [28/100], Step [16600/6235], Loss: 38.5433\n",
      "Epoch [28/100], Step [16700/6235], Loss: 0.3122\n",
      "Epoch [28/100], Step [16800/6235], Loss: 11.0249\n",
      "Epoch [28/100], Step [16900/6235], Loss: 0.4765\n",
      "Epoch [28/100], Step [17000/6235], Loss: 0.1685\n",
      "Epoch [28/100], Step [17100/6235], Loss: 0.1173\n",
      "Epoch [28/100], Step [17200/6235], Loss: 228.2846\n",
      "Epoch [28/100], Step [17300/6235], Loss: 0.9639\n",
      "Epoch [28/100], Step [17400/6235], Loss: 39.0124\n",
      "Epoch [28/100], Step [17500/6235], Loss: 7.6691\n",
      "Epoch [28/100], Step [17600/6235], Loss: 2.7352\n",
      "Epoch [28/100], Step [17700/6235], Loss: 1.8342\n",
      "Epoch [28/100], Step [17800/6235], Loss: 27.7378\n",
      "Epoch [28/100], Step [17900/6235], Loss: 8.2389\n",
      "Epoch [28/100], Step [18000/6235], Loss: 9.7589\n",
      "Epoch [28/100], Step [18100/6235], Loss: 13.2664\n",
      "Epoch [28/100], Step [18200/6235], Loss: 0.6303\n",
      "Epoch [28/100], Step [18300/6235], Loss: 0.9952\n",
      "Epoch [28/100], Step [18400/6235], Loss: 1.4736\n",
      "Epoch [28/100], Step [18500/6235], Loss: 22.2475\n",
      "Epoch [28/100], Step [18600/6235], Loss: 5.4887\n",
      "Epoch [28/100], Step [18700/6235], Loss: 2.0656\n",
      "Epoch [28/100], Step [18800/6235], Loss: 140.2290\n",
      "Epoch [28/100], Step [18900/6235], Loss: 45.0409\n",
      "Epoch [28/100], Step [19000/6235], Loss: 6.3689\n",
      "Epoch [28/100], Step [19100/6235], Loss: 6.8080\n",
      "Epoch [28/100], Step [19200/6235], Loss: 1.4586\n",
      "Epoch [28/100], Step [19300/6235], Loss: 1.2209\n",
      "Epoch [28/100], Step [19400/6235], Loss: 159.7918\n",
      "Epoch [28/100], Step [19500/6235], Loss: 135.9472\n",
      "Epoch [28/100], Step [19600/6235], Loss: 41.8635\n",
      "Epoch [28/100], Step [19700/6235], Loss: 10.9304\n",
      "Epoch [28/100], Step [19800/6235], Loss: 6.5463\n",
      "Epoch [28/100], Step [19900/6235], Loss: 0.1237\n",
      "Epoch [28/100], Step [20000/6235], Loss: 68.0882\n",
      "Epoch [28/100], Step [20100/6235], Loss: 3.1375\n",
      "Epoch [28/100], Step [20200/6235], Loss: 5.4579\n",
      "Epoch [28/100], Step [20300/6235], Loss: 2.4543\n",
      "Epoch [28/100], Step [20400/6235], Loss: 9.3480\n",
      "Epoch [28/100], Step [20500/6235], Loss: 58.6931\n",
      "Epoch [28/100], Step [20600/6235], Loss: 31.0309\n",
      "Epoch [28/100], Step [20700/6235], Loss: 23.4729\n",
      "Epoch [28/100], Step [20800/6235], Loss: 2.0683\n",
      "Epoch [28/100], Step [20900/6235], Loss: 1.8085\n",
      "Epoch [28/100], Step [21000/6235], Loss: 16.4938\n",
      "Epoch [28/100], Step [21100/6235], Loss: 6.2024\n",
      "Epoch [28/100], Step [21200/6235], Loss: 0.2605\n",
      "Epoch [28/100], Step [21300/6235], Loss: 0.1233\n",
      "Epoch [28/100], Step [21400/6235], Loss: 0.8887\n",
      "Epoch [28/100], Step [21500/6235], Loss: 4.2133\n",
      "Epoch [28/100], Step [21600/6235], Loss: 8.3876\n",
      "Epoch [28/100], Step [21700/6235], Loss: 0.3140\n",
      "Epoch [28/100], Step [21800/6235], Loss: 4.0537\n",
      "Epoch [28/100], Step [21900/6235], Loss: 1.7134\n",
      "Epoch [28/100], Step [22000/6235], Loss: 11.9076\n",
      "Epoch [28/100], Step [22100/6235], Loss: 0.2061\n",
      "Epoch [28/100], Step [22200/6235], Loss: 3.2788\n",
      "Epoch [28/100], Step [22300/6235], Loss: 1.2562\n",
      "Epoch [28/100], Step [22400/6235], Loss: 0.5754\n",
      "Epoch [28/100], Step [22500/6235], Loss: 149.1686\n",
      "Epoch [28/100], Step [22600/6235], Loss: 34.8469\n",
      "Epoch [28/100], Step [22700/6235], Loss: 1.3575\n",
      "Epoch [28/100], Step [22800/6235], Loss: 7.9798\n",
      "Epoch [28/100], Step [22900/6235], Loss: 19.0249\n",
      "Epoch [28/100], Step [23000/6235], Loss: 18.5929\n",
      "Epoch [28/100], Step [23100/6235], Loss: 7.4882\n",
      "Epoch [28/100], Step [23200/6235], Loss: 3.2455\n",
      "Epoch [28/100], Step [23300/6235], Loss: 20.3835\n",
      "Epoch [28/100], Step [23400/6235], Loss: 2.6707\n",
      "Epoch [28/100], Step [23500/6235], Loss: 0.4272\n",
      "Epoch [28/100], Step [23600/6235], Loss: 131.9286\n",
      "Epoch [28/100], Step [23700/6235], Loss: 2.4099\n",
      "Epoch [28/100], Step [23800/6235], Loss: 0.6466\n",
      "Epoch [28/100], Step [23900/6235], Loss: 0.0915\n",
      "Epoch [28/100], Step [24000/6235], Loss: 4.3320\n",
      "Epoch [28/100], Step [24100/6235], Loss: 0.7785\n",
      "Epoch [28/100], Step [24200/6235], Loss: 39.4835\n",
      "Epoch [28/100], Step [24300/6235], Loss: 0.4646\n",
      "Epoch [28/100], Step [24400/6235], Loss: 0.2420\n",
      "Epoch [28/100], Step [24500/6235], Loss: 3.2583\n",
      "Epoch [28/100], Step [24600/6235], Loss: 0.3100\n",
      "Epoch [28/100], Step [24700/6235], Loss: 0.1918\n",
      "Epoch [28/100], Step [24800/6235], Loss: 0.3819\n",
      "Epoch [28/100], Step [24900/6235], Loss: 10.3397\n",
      "Epoch [28/100], Step [25000/6235], Loss: 8.6014\n",
      "Epoch [28/100], Step [25100/6235], Loss: 9.1343\n",
      "Epoch [28/100], Step [25200/6235], Loss: 0.0533\n",
      "Epoch [28/100], Step [25300/6235], Loss: 2.0442\n",
      "Epoch [28/100], Step [25400/6235], Loss: 5.0697\n",
      "Epoch [28/100], Step [25500/6235], Loss: 9.5969\n",
      "Epoch [28/100], Step [25600/6235], Loss: 10.8581\n",
      "Epoch [28/100], Step [25700/6235], Loss: 0.2332\n",
      "Epoch [28/100], Step [25800/6235], Loss: 2.3232\n",
      "Epoch [28/100], Step [25900/6235], Loss: 1.1722\n",
      "Epoch [28/100], Step [26000/6235], Loss: 0.0430\n",
      "Epoch [28/100], Step [26100/6235], Loss: 0.4408\n",
      "Epoch [28/100], Step [26200/6235], Loss: 0.8164\n",
      "Epoch [28/100], Step [26300/6235], Loss: 0.0434\n",
      "Epoch [28/100], Step [26400/6235], Loss: 1.8969\n",
      "Epoch [28/100], Step [26500/6235], Loss: 0.0107\n",
      "Epoch [28/100], Step [26600/6235], Loss: 0.0933\n",
      "Epoch [28/100], Step [26700/6235], Loss: 0.0261\n",
      "Epoch [28/100], Step [26800/6235], Loss: 0.0853\n",
      "Epoch [28/100], Step [26900/6235], Loss: 0.1688\n",
      "Epoch [28/100], Step [27000/6235], Loss: 14.3413\n",
      "Epoch [28/100], Step [27100/6235], Loss: 0.1241\n",
      "Epoch [28/100], Step [27200/6235], Loss: 0.0924\n",
      "Epoch [28/100], Step [27300/6235], Loss: 0.0110\n",
      "Epoch [28/100], Step [27400/6235], Loss: 0.3628\n",
      "Epoch [28/100], Step [27500/6235], Loss: 0.0273\n",
      "Epoch [28/100], Step [27600/6235], Loss: 0.2951\n",
      "Epoch [28/100], Step [27700/6235], Loss: 0.8996\n",
      "Epoch [28/100], Step [27800/6235], Loss: 5.3956\n",
      "Epoch [28/100], Step [27900/6235], Loss: 3.2436\n",
      "Epoch [28/100], Step [28000/6235], Loss: 174.7693\n",
      "Epoch [28/100], Step [28100/6235], Loss: 5.8280\n",
      "Epoch [28/100], Step [28200/6235], Loss: 30.9496\n",
      "Epoch [28/100], Step [28300/6235], Loss: 1.8373\n",
      "Epoch [28/100], Step [28400/6235], Loss: 20.3833\n",
      "Epoch [28/100], Step [28500/6235], Loss: 1.6756\n",
      "Epoch [28/100], Step [28600/6235], Loss: 1.5681\n",
      "Epoch [28/100], Step [28700/6235], Loss: 2.2347\n",
      "Epoch [28/100], Step [28800/6235], Loss: 0.7225\n",
      "Epoch [28/100], Step [28900/6235], Loss: 32.7937\n",
      "Epoch [28/100], Step [29000/6235], Loss: 4.3136\n",
      "Epoch [28/100], Step [29100/6235], Loss: 0.6472\n",
      "Epoch [28/100], Step [29200/6235], Loss: 6.1810\n",
      "Epoch [28/100], Step [29300/6235], Loss: 7.7136\n",
      "Epoch [28/100], Step [29400/6235], Loss: 0.0647\n",
      "Epoch [28/100], Step [29500/6235], Loss: 4.7748\n",
      "Epoch [28/100], Step [29600/6235], Loss: 0.5883\n",
      "Epoch [28/100], Step [29700/6235], Loss: 3.0354\n",
      "Epoch [28/100], Step [29800/6235], Loss: 0.2576\n",
      "Epoch [28/100], Step [29900/6235], Loss: 6.5752\n",
      "Epoch [28/100], Step [30000/6235], Loss: 0.9344\n",
      "Epoch [28/100], Step [30100/6235], Loss: 8.0041\n",
      "Epoch [28/100], Step [30200/6235], Loss: 1.3800\n",
      "Epoch [28/100], Step [30300/6235], Loss: 0.1193\n",
      "Epoch [28/100], Step [30400/6235], Loss: 3.7577\n",
      "Epoch [28/100], Step [30500/6235], Loss: 0.2386\n",
      "Epoch [28/100], Step [30600/6235], Loss: 0.4771\n",
      "Epoch [28/100], Step [30700/6235], Loss: 3.1094\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Step [30800/6235], Loss: 0.4207\n",
      "Epoch [28/100], Step [30900/6235], Loss: 0.7837\n",
      "Epoch [28/100], Step [31000/6235], Loss: 0.1163\n",
      "Epoch [28/100], Step [31100/6235], Loss: 1.6625\n",
      "Epoch [28/100], Step [31200/6235], Loss: 2.6766\n",
      "Epoch [28/100], Step [31300/6235], Loss: 3.5119\n",
      "Epoch [28/100], Step [31400/6235], Loss: 5.5444\n",
      "Epoch [28/100], Step [31500/6235], Loss: 0.5484\n",
      "Epoch [28/100], Step [31600/6235], Loss: 5.8955\n",
      "Epoch [28/100], Step [31700/6235], Loss: 2.6189\n",
      "Epoch [28/100], Step [31800/6235], Loss: 0.3765\n",
      "Epoch [28/100], Step [31900/6235], Loss: 182.8061\n",
      "Epoch [28/100], Step [32000/6235], Loss: 1.4018\n",
      "Epoch [28/100], Step [32100/6235], Loss: 0.3844\n",
      "Epoch [28/100], Step [32200/6235], Loss: 145.8304\n",
      "Epoch [28/100], Step [32300/6235], Loss: 4.8261\n",
      "Epoch [28/100], Step [32400/6235], Loss: 0.4659\n",
      "Epoch [28/100], Step [32500/6235], Loss: 1.7928\n",
      "Epoch [28/100], Step [32600/6235], Loss: 0.0101\n",
      "Epoch [28/100], Step [32700/6235], Loss: 193.5897\n",
      "Epoch [28/100], Step [32800/6235], Loss: 1.8285\n",
      "Epoch [28/100], Step [32900/6235], Loss: 0.6368\n",
      "Epoch [28/100], Step [33000/6235], Loss: 1.5862\n",
      "Epoch [28/100], Step [33100/6235], Loss: 0.1931\n",
      "Epoch [28/100], Step [33200/6235], Loss: 8.4425\n",
      "Epoch [28/100], Step [33300/6235], Loss: 0.3589\n",
      "Epoch [28/100], Step [33400/6235], Loss: 6.3901\n",
      "Epoch [28/100], Step [33500/6235], Loss: 1.3875\n",
      "Epoch [28/100], Step [33600/6235], Loss: 6.4138\n",
      "Epoch [28/100], Step [33700/6235], Loss: 3.9571\n",
      "Epoch [28/100], Step [33800/6235], Loss: 0.6912\n",
      "Epoch [28/100], Step [33900/6235], Loss: 26.0641\n",
      "Epoch [28/100], Step [34000/6235], Loss: 0.0380\n",
      "Epoch [28/100], Step [34100/6235], Loss: 0.4008\n",
      "Epoch [28/100], Step [34200/6235], Loss: 1.9023\n",
      "Epoch [28/100], Step [34300/6235], Loss: 6.6320\n",
      "Epoch [28/100], Step [34400/6235], Loss: 0.1738\n",
      "Epoch [28/100], Step [34500/6235], Loss: 41.4580\n",
      "Epoch [28/100], Step [34600/6235], Loss: 1.3770\n",
      "Epoch [28/100], Step [34700/6235], Loss: 16.0342\n",
      "Epoch [28/100], Step [34800/6235], Loss: 13.6011\n",
      "Epoch [28/100], Step [34900/6235], Loss: 67.9365\n",
      "Epoch [28/100], Step [35000/6235], Loss: 0.3135\n",
      "Epoch [28/100], Step [35100/6235], Loss: 1.2110\n",
      "Epoch [28/100], Step [35200/6235], Loss: 0.5375\n",
      "Epoch [28/100], Step [35300/6235], Loss: 2.8943\n",
      "Epoch [28/100], Step [35400/6235], Loss: 0.7179\n",
      "Epoch [28/100], Step [35500/6235], Loss: 0.5167\n",
      "Epoch [28/100], Step [35600/6235], Loss: 5.7837\n",
      "Epoch [28/100], Step [35700/6235], Loss: 4.4834\n",
      "Epoch [28/100], Step [35800/6235], Loss: 0.8698\n",
      "Epoch [28/100], Step [35900/6235], Loss: 2.3988\n",
      "Epoch [28/100], Step [36000/6235], Loss: 0.1326\n",
      "Epoch [28/100], Step [36100/6235], Loss: 0.0768\n",
      "Epoch [28/100], Step [36200/6235], Loss: 34.3996\n",
      "Epoch [28/100], Step [36300/6235], Loss: 2.4569\n",
      "Epoch [28/100], Step [36400/6235], Loss: 3.0737\n",
      "Epoch [28/100], Step [36500/6235], Loss: 7.0115\n",
      "Epoch [28/100], Step [36600/6235], Loss: 0.0618\n",
      "Epoch [28/100], Step [36700/6235], Loss: 0.5762\n",
      "Epoch [28/100], Step [36800/6235], Loss: 3.4363\n",
      "Epoch [28/100], Step [36900/6235], Loss: 12.4029\n",
      "Epoch [28/100], Step [37000/6235], Loss: 0.9704\n",
      "Epoch [28/100], Step [37100/6235], Loss: 2.1848\n",
      "Epoch [28/100], Step [37200/6235], Loss: 0.0334\n",
      "Epoch [28/100], Step [37300/6235], Loss: 0.0745\n",
      "Epoch [28/100], Step [37400/6235], Loss: 0.1648\n",
      "Epoch [28/100], Step [37500/6235], Loss: 7.3493\n",
      "Epoch [28/100], Step [37600/6235], Loss: 12.3555\n",
      "Epoch [28/100], Step [37700/6235], Loss: 2.4094\n",
      "Epoch [28/100], Step [37800/6235], Loss: 3.8404\n",
      "Epoch [28/100], Step [37900/6235], Loss: 8.1837\n",
      "Epoch [28/100], Step [38000/6235], Loss: 0.8796\n",
      "Epoch [28/100], Step [38100/6235], Loss: 4.4891\n",
      "Epoch [28/100], Step [38200/6235], Loss: 2.4381\n",
      "Epoch [28/100], Step [38300/6235], Loss: 0.4307\n",
      "Epoch [28/100], Step [38400/6235], Loss: 0.0553\n",
      "Epoch [28/100], Step [38500/6235], Loss: 1.8170\n",
      "Epoch [28/100], Step [38600/6235], Loss: 0.3548\n",
      "Epoch [28/100], Step [38700/6235], Loss: 0.0468\n",
      "Epoch [28/100], Step [38800/6235], Loss: 0.1570\n",
      "Epoch [28/100], Step [38900/6235], Loss: 1.1908\n",
      "Epoch [28/100], Step [39000/6235], Loss: 8.2743\n",
      "Epoch [28/100], Step [39100/6235], Loss: 17.5631\n",
      "Epoch [28/100], Step [39200/6235], Loss: 0.3608\n",
      "Epoch [28/100], Step [39300/6235], Loss: 14.5012\n",
      "Epoch [28/100], Step [39400/6235], Loss: 138.9797\n",
      "Epoch [28/100], Step [39500/6235], Loss: 116.1045\n",
      "Epoch [28/100], Step [39600/6235], Loss: 6.9819\n",
      "Epoch [28/100], Step [39700/6235], Loss: 87.7703\n",
      "Epoch [28/100], Step [39800/6235], Loss: 107.1346\n",
      "Epoch [28/100], Step [39900/6235], Loss: 1.0076\n",
      "Epoch [28/100], Step [40000/6235], Loss: 14.7784\n",
      "Epoch [28/100], Step [40100/6235], Loss: 26.5308\n",
      "Epoch [28/100], Step [40200/6235], Loss: 1.7076\n",
      "Epoch [28/100], Step [40300/6235], Loss: 0.8891\n",
      "Epoch [28/100], Step [40400/6235], Loss: 2.7004\n",
      "Epoch [28/100], Step [40500/6235], Loss: 2.2129\n",
      "Epoch [28/100], Step [40600/6235], Loss: 0.3023\n",
      "Epoch [28/100], Step [40700/6235], Loss: 7.7378\n",
      "Epoch [28/100], Step [40800/6235], Loss: 1.9825\n",
      "Epoch [28/100], Step [40900/6235], Loss: 0.0579\n",
      "Epoch [28/100], Step [41000/6235], Loss: 38.3031\n",
      "Epoch [28/100], Step [41100/6235], Loss: 0.3578\n",
      "Epoch [28/100], Step [41200/6235], Loss: 31.0454\n",
      "Epoch [28/100], Step [41300/6235], Loss: 2.8097\n",
      "Epoch [28/100], Step [41400/6235], Loss: 0.1695\n",
      "Epoch [28/100], Step [41500/6235], Loss: 3.7982\n",
      "Epoch [28/100], Step [41600/6235], Loss: 0.4305\n",
      "Epoch [28/100], Step [41700/6235], Loss: 0.0847\n",
      "Epoch [28/100], Step [41800/6235], Loss: 0.7418\n",
      "Epoch [28/100], Step [41900/6235], Loss: 4.9846\n",
      "Epoch [28/100], Step [42000/6235], Loss: 4.5988\n",
      "Epoch [28/100], Step [42100/6235], Loss: 10.9161\n",
      "Epoch [28/100], Step [42200/6235], Loss: 62.6965\n",
      "Epoch [28/100], Step [42300/6235], Loss: 0.8265\n",
      "Epoch [28/100], Step [42400/6235], Loss: 4.7979\n",
      "Epoch [28/100], Step [42500/6235], Loss: 1.6546\n",
      "Epoch [28/100], Step [42600/6235], Loss: 0.7850\n",
      "Epoch [28/100], Step [42700/6235], Loss: 0.4228\n",
      "Epoch [28/100], Step [42800/6235], Loss: 3.8080\n",
      "Epoch [28/100], Step [42900/6235], Loss: 3.4088\n",
      "Epoch [28/100], Step [43000/6235], Loss: 0.2268\n",
      "Epoch [28/100], Step [43100/6235], Loss: 0.3069\n",
      "Epoch [28/100], Step [43200/6235], Loss: 1.0717\n",
      "Epoch [28/100], Step [43300/6235], Loss: 8.5444\n",
      "Epoch [28/100], Step [43400/6235], Loss: 11.8620\n",
      "Epoch [28/100], Step [43500/6235], Loss: 9.4480\n",
      "Epoch [28/100], Step [43600/6235], Loss: 13.6778\n",
      "Epoch [28/100], Step [43700/6235], Loss: 47.0350\n",
      "Epoch [28/100], Step [43800/6235], Loss: 0.8170\n",
      "Epoch [28/100], Step [43900/6235], Loss: 1.2730\n",
      "Epoch [28/100], Step [44000/6235], Loss: 76.2489\n",
      "Epoch [28/100], Step [44100/6235], Loss: 3.3561\n",
      "Epoch [28/100], Step [44200/6235], Loss: 11.6099\n",
      "Epoch [28/100], Step [44300/6235], Loss: 39.4502\n",
      "Epoch [28/100], Step [44400/6235], Loss: 4.0902\n",
      "Epoch [28/100], Step [44500/6235], Loss: 1.9672\n",
      "Epoch [28/100], Step [44600/6235], Loss: 26.7463\n",
      "Epoch [28/100], Step [44700/6235], Loss: 0.7411\n",
      "Epoch [28/100], Step [44800/6235], Loss: 3.7700\n",
      "Epoch [28/100], Step [44900/6235], Loss: 3.4264\n",
      "Epoch [28/100], Step [45000/6235], Loss: 4.9230\n",
      "Epoch [28/100], Step [45100/6235], Loss: 42.7290\n",
      "Epoch [28/100], Step [45200/6235], Loss: 0.5964\n",
      "Epoch [28/100], Step [45300/6235], Loss: 34.2922\n",
      "Epoch [28/100], Step [45400/6235], Loss: 12.8052\n",
      "Epoch [28/100], Step [45500/6235], Loss: 0.1867\n",
      "Epoch [28/100], Step [45600/6235], Loss: 0.2410\n",
      "Epoch [28/100], Step [45700/6235], Loss: 70.2408\n",
      "Epoch [28/100], Step [45800/6235], Loss: 364.5173\n",
      "Epoch [28/100], Step [45900/6235], Loss: 9.1124\n",
      "Epoch [28/100], Step [46000/6235], Loss: 28.0643\n",
      "Epoch [28/100], Step [46100/6235], Loss: 17.1381\n",
      "Epoch [28/100], Step [46200/6235], Loss: 15.7248\n",
      "Epoch [28/100], Step [46300/6235], Loss: 104.3339\n",
      "Epoch [28/100], Step [46400/6235], Loss: 11.8331\n",
      "Epoch [28/100], Step [46500/6235], Loss: 9.1774\n",
      "Epoch [28/100], Step [46600/6235], Loss: 23.1400\n",
      "Epoch [28/100], Step [46700/6235], Loss: 2.8235\n",
      "Epoch [28/100], Step [46800/6235], Loss: 13.5479\n",
      "Epoch [28/100], Step [46900/6235], Loss: 14.6000\n",
      "Epoch [28/100], Step [47000/6235], Loss: 1.6717\n",
      "Epoch [28/100], Step [47100/6235], Loss: 19.2905\n",
      "Epoch [28/100], Step [47200/6235], Loss: 25.8504\n",
      "Epoch [28/100], Step [47300/6235], Loss: 0.9864\n",
      "Epoch [28/100], Step [47400/6235], Loss: 23.8380\n",
      "Epoch [28/100], Step [47500/6235], Loss: 19.0187\n",
      "Epoch [28/100], Step [47600/6235], Loss: 8.6869\n",
      "Epoch [28/100], Step [47700/6235], Loss: 6.5686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [28/100], Step [47800/6235], Loss: 6.8634\n",
      "Epoch [28/100], Step [47900/6235], Loss: 21.0002\n",
      "Epoch [28/100], Step [48000/6235], Loss: 34.5660\n",
      "Epoch [28/100], Step [48100/6235], Loss: 4.6719\n",
      "Epoch [28/100], Step [48200/6235], Loss: 10.1642\n",
      "Epoch [28/100], Step [48300/6235], Loss: 429.0006\n",
      "Epoch [28/100], Step [48400/6235], Loss: 18.4953\n",
      "Epoch [28/100], Step [48500/6235], Loss: 19.9262\n",
      "Epoch [28/100], Step [48600/6235], Loss: 166.6418\n",
      "Epoch [28/100], Step [48700/6235], Loss: 20.3549\n",
      "Epoch [28/100], Step [48800/6235], Loss: 490.1117\n",
      "Epoch [28/100], Step [48900/6235], Loss: 560.3989\n",
      "Epoch [28/100], Step [49000/6235], Loss: 160.2603\n",
      "Epoch [28/100], Step [49100/6235], Loss: 2791.9907\n",
      "Epoch [28/100], Step [49200/6235], Loss: 1038.9238\n",
      "Epoch [28/100], Step [49300/6235], Loss: 1180.5964\n",
      "Epoch [28/100], Step [49400/6235], Loss: 48.2809\n",
      "Epoch [28/100], Step [49500/6235], Loss: 6.3953\n",
      "Epoch [28/100], Step [49600/6235], Loss: 117.8561\n",
      "Epoch [28/100], Step [49700/6235], Loss: 5274.7344\n",
      "Epoch [28/100], Step [49800/6235], Loss: 439.6628\n",
      "Epoch [29/100], Step [100/6235], Loss: 14.0358\n",
      "Epoch [29/100], Step [200/6235], Loss: 0.6810\n",
      "Epoch [29/100], Step [300/6235], Loss: 0.5692\n",
      "Epoch [29/100], Step [400/6235], Loss: 0.3151\n",
      "Epoch [29/100], Step [500/6235], Loss: 0.6928\n",
      "Epoch [29/100], Step [600/6235], Loss: 0.0302\n",
      "Epoch [29/100], Step [700/6235], Loss: 0.6375\n",
      "Epoch [29/100], Step [800/6235], Loss: 0.0650\n",
      "Epoch [29/100], Step [900/6235], Loss: 0.0778\n",
      "Epoch [29/100], Step [1000/6235], Loss: 0.0312\n",
      "Epoch [29/100], Step [1100/6235], Loss: 0.1407\n",
      "Epoch [29/100], Step [1200/6235], Loss: 0.1980\n",
      "Epoch [29/100], Step [1300/6235], Loss: 0.0491\n",
      "Epoch [29/100], Step [1400/6235], Loss: 0.3085\n",
      "Epoch [29/100], Step [1500/6235], Loss: 0.0088\n",
      "Epoch [29/100], Step [1600/6235], Loss: 0.2448\n",
      "Epoch [29/100], Step [1700/6235], Loss: 0.1670\n",
      "Epoch [29/100], Step [1800/6235], Loss: 0.2316\n",
      "Epoch [29/100], Step [1900/6235], Loss: 0.3115\n",
      "Epoch [29/100], Step [2000/6235], Loss: 2.2647\n",
      "Epoch [29/100], Step [2100/6235], Loss: 2.0442\n",
      "Epoch [29/100], Step [2200/6235], Loss: 6.8695\n",
      "Epoch [29/100], Step [2300/6235], Loss: 2.1789\n",
      "Epoch [29/100], Step [2400/6235], Loss: 2.5942\n",
      "Epoch [29/100], Step [2500/6235], Loss: 32.9972\n",
      "Epoch [29/100], Step [2600/6235], Loss: 13.2660\n",
      "Epoch [29/100], Step [2700/6235], Loss: 10.7538\n",
      "Epoch [29/100], Step [2800/6235], Loss: 60.6629\n",
      "Epoch [29/100], Step [2900/6235], Loss: 18.2098\n",
      "Epoch [29/100], Step [3000/6235], Loss: 1.3372\n",
      "Epoch [29/100], Step [3100/6235], Loss: 63.5526\n",
      "Epoch [29/100], Step [3200/6235], Loss: 60.3805\n",
      "Epoch [29/100], Step [3300/6235], Loss: 10.5078\n",
      "Epoch [29/100], Step [3400/6235], Loss: 2.2687\n",
      "Epoch [29/100], Step [3500/6235], Loss: 45.8644\n",
      "Epoch [29/100], Step [3600/6235], Loss: 4.5635\n",
      "Epoch [29/100], Step [3700/6235], Loss: 0.0354\n",
      "Epoch [29/100], Step [3800/6235], Loss: 0.0335\n",
      "Epoch [29/100], Step [3900/6235], Loss: 0.0508\n",
      "Epoch [29/100], Step [4000/6235], Loss: 0.0767\n",
      "Epoch [29/100], Step [4100/6235], Loss: 8.7954\n",
      "Epoch [29/100], Step [4200/6235], Loss: 1.7093\n",
      "Epoch [29/100], Step [4300/6235], Loss: 6.9090\n",
      "Epoch [29/100], Step [4400/6235], Loss: 1.2797\n",
      "Epoch [29/100], Step [4500/6235], Loss: 37.8721\n",
      "Epoch [29/100], Step [4600/6235], Loss: 0.3622\n",
      "Epoch [29/100], Step [4700/6235], Loss: 0.1772\n",
      "Epoch [29/100], Step [4800/6235], Loss: 9.8607\n",
      "Epoch [29/100], Step [4900/6235], Loss: 0.0123\n",
      "Epoch [29/100], Step [5000/6235], Loss: 0.0574\n",
      "Epoch [29/100], Step [5100/6235], Loss: 0.7747\n",
      "Epoch [29/100], Step [5200/6235], Loss: 2.1911\n",
      "Epoch [29/100], Step [5300/6235], Loss: 38.0085\n",
      "Epoch [29/100], Step [5400/6235], Loss: 0.4445\n",
      "Epoch [29/100], Step [5500/6235], Loss: 0.2025\n",
      "Epoch [29/100], Step [5600/6235], Loss: 0.2299\n",
      "Epoch [29/100], Step [5700/6235], Loss: 0.1132\n",
      "Epoch [29/100], Step [5800/6235], Loss: 0.5615\n",
      "Epoch [29/100], Step [5900/6235], Loss: 0.0792\n",
      "Epoch [29/100], Step [6000/6235], Loss: 1.3120\n",
      "Epoch [29/100], Step [6100/6235], Loss: 0.0985\n",
      "Epoch [29/100], Step [6200/6235], Loss: 3.9708\n",
      "Epoch [29/100], Step [6300/6235], Loss: 0.1043\n",
      "Epoch [29/100], Step [6400/6235], Loss: 0.1380\n",
      "Epoch [29/100], Step [6500/6235], Loss: 4.7033\n",
      "Epoch [29/100], Step [6600/6235], Loss: 9.4870\n",
      "Epoch [29/100], Step [6700/6235], Loss: 2.0884\n",
      "Epoch [29/100], Step [6800/6235], Loss: 0.3503\n",
      "Epoch [29/100], Step [6900/6235], Loss: 0.5467\n",
      "Epoch [29/100], Step [7000/6235], Loss: 0.0229\n",
      "Epoch [29/100], Step [7100/6235], Loss: 0.1317\n",
      "Epoch [29/100], Step [7200/6235], Loss: 0.4659\n",
      "Epoch [29/100], Step [7300/6235], Loss: 0.2508\n",
      "Epoch [29/100], Step [7400/6235], Loss: 0.0999\n",
      "Epoch [29/100], Step [7500/6235], Loss: 0.6459\n",
      "Epoch [29/100], Step [7600/6235], Loss: 2.8657\n",
      "Epoch [29/100], Step [7700/6235], Loss: 15.0704\n",
      "Epoch [29/100], Step [7800/6235], Loss: 2.0535\n",
      "Epoch [29/100], Step [7900/6235], Loss: 4.1781\n",
      "Epoch [29/100], Step [8000/6235], Loss: 0.1536\n",
      "Epoch [29/100], Step [8100/6235], Loss: 4.3898\n",
      "Epoch [29/100], Step [8200/6235], Loss: 12.2941\n",
      "Epoch [29/100], Step [8300/6235], Loss: 33.7832\n",
      "Epoch [29/100], Step [8400/6235], Loss: 194.0335\n",
      "Epoch [29/100], Step [8500/6235], Loss: 0.8783\n",
      "Epoch [29/100], Step [8600/6235], Loss: 151.2808\n",
      "Epoch [29/100], Step [8700/6235], Loss: 90.4787\n",
      "Epoch [29/100], Step [8800/6235], Loss: 16.1773\n",
      "Epoch [29/100], Step [8900/6235], Loss: 1.3411\n",
      "Epoch [29/100], Step [9000/6235], Loss: 539.1838\n",
      "Epoch [29/100], Step [9100/6235], Loss: 1259.3066\n",
      "Epoch [29/100], Step [9200/6235], Loss: 3405.5273\n",
      "Epoch [29/100], Step [9300/6235], Loss: 177.0353\n",
      "Epoch [29/100], Step [9400/6235], Loss: 314.7273\n",
      "Epoch [29/100], Step [9500/6235], Loss: 38.3912\n",
      "Epoch [29/100], Step [9600/6235], Loss: 228.7700\n",
      "Epoch [29/100], Step [9700/6235], Loss: 156.0867\n",
      "Epoch [29/100], Step [9800/6235], Loss: 156.2232\n",
      "Epoch [29/100], Step [9900/6235], Loss: 5.2677\n",
      "Epoch [29/100], Step [10000/6235], Loss: 274.6907\n",
      "Epoch [29/100], Step [10100/6235], Loss: 4.6837\n",
      "Epoch [29/100], Step [10200/6235], Loss: 679.9414\n",
      "Epoch [29/100], Step [10300/6235], Loss: 3.3654\n",
      "Epoch [29/100], Step [10400/6235], Loss: 1.3261\n",
      "Epoch [29/100], Step [10500/6235], Loss: 0.6872\n",
      "Epoch [29/100], Step [10600/6235], Loss: 324.3671\n",
      "Epoch [29/100], Step [10700/6235], Loss: 61.0526\n",
      "Epoch [29/100], Step [10800/6235], Loss: 34.6712\n",
      "Epoch [29/100], Step [10900/6235], Loss: 4.7660\n",
      "Epoch [29/100], Step [11000/6235], Loss: 212.9688\n",
      "Epoch [29/100], Step [11100/6235], Loss: 14.3286\n",
      "Epoch [29/100], Step [11200/6235], Loss: 87.2921\n",
      "Epoch [29/100], Step [11300/6235], Loss: 223.0912\n",
      "Epoch [29/100], Step [11400/6235], Loss: 19.1767\n",
      "Epoch [29/100], Step [11500/6235], Loss: 3.8854\n",
      "Epoch [29/100], Step [11600/6235], Loss: 3.5143\n",
      "Epoch [29/100], Step [11700/6235], Loss: 69.6904\n",
      "Epoch [29/100], Step [11800/6235], Loss: 4.4730\n",
      "Epoch [29/100], Step [11900/6235], Loss: 60.7012\n",
      "Epoch [29/100], Step [12000/6235], Loss: 286.1663\n",
      "Epoch [29/100], Step [12100/6235], Loss: 334.0590\n",
      "Epoch [29/100], Step [12200/6235], Loss: 95.4072\n",
      "Epoch [29/100], Step [12300/6235], Loss: 20.6552\n",
      "Epoch [29/100], Step [12400/6235], Loss: 500.6774\n",
      "Epoch [29/100], Step [12500/6235], Loss: 186.4157\n",
      "Epoch [29/100], Step [12600/6235], Loss: 0.4713\n",
      "Epoch [29/100], Step [12700/6235], Loss: 4.0155\n",
      "Epoch [29/100], Step [12800/6235], Loss: 21.6322\n",
      "Epoch [29/100], Step [12900/6235], Loss: 31.0204\n",
      "Epoch [29/100], Step [13000/6235], Loss: 0.1443\n",
      "Epoch [29/100], Step [13100/6235], Loss: 63.7177\n",
      "Epoch [29/100], Step [13200/6235], Loss: 7.7641\n",
      "Epoch [29/100], Step [13300/6235], Loss: 20.6436\n",
      "Epoch [29/100], Step [13400/6235], Loss: 243.6174\n",
      "Epoch [29/100], Step [13500/6235], Loss: 4.5620\n",
      "Epoch [29/100], Step [13600/6235], Loss: 4.9883\n",
      "Epoch [29/100], Step [13700/6235], Loss: 171.2230\n",
      "Epoch [29/100], Step [13800/6235], Loss: 95.6364\n",
      "Epoch [29/100], Step [13900/6235], Loss: 4.0157\n",
      "Epoch [29/100], Step [14000/6235], Loss: 12.6845\n",
      "Epoch [29/100], Step [14100/6235], Loss: 23.4526\n",
      "Epoch [29/100], Step [14200/6235], Loss: 10.6310\n",
      "Epoch [29/100], Step [14300/6235], Loss: 0.7895\n",
      "Epoch [29/100], Step [14400/6235], Loss: 25.2687\n",
      "Epoch [29/100], Step [14500/6235], Loss: 36.4021\n",
      "Epoch [29/100], Step [14600/6235], Loss: 0.0757\n",
      "Epoch [29/100], Step [14700/6235], Loss: 44.2963\n",
      "Epoch [29/100], Step [14800/6235], Loss: 33.2720\n",
      "Epoch [29/100], Step [14900/6235], Loss: 1.3581\n",
      "Epoch [29/100], Step [15000/6235], Loss: 2.3445\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Step [15100/6235], Loss: 0.3273\n",
      "Epoch [29/100], Step [15200/6235], Loss: 0.8611\n",
      "Epoch [29/100], Step [15300/6235], Loss: 17.1445\n",
      "Epoch [29/100], Step [15400/6235], Loss: 4.1133\n",
      "Epoch [29/100], Step [15500/6235], Loss: 14.2158\n",
      "Epoch [29/100], Step [15600/6235], Loss: 15.0771\n",
      "Epoch [29/100], Step [15700/6235], Loss: 60.3779\n",
      "Epoch [29/100], Step [15800/6235], Loss: 11.1749\n",
      "Epoch [29/100], Step [15900/6235], Loss: 0.3880\n",
      "Epoch [29/100], Step [16000/6235], Loss: 150.5873\n",
      "Epoch [29/100], Step [16100/6235], Loss: 0.6498\n",
      "Epoch [29/100], Step [16200/6235], Loss: 1.5193\n",
      "Epoch [29/100], Step [16300/6235], Loss: 9.7627\n",
      "Epoch [29/100], Step [16400/6235], Loss: 15.9216\n",
      "Epoch [29/100], Step [16500/6235], Loss: 171.3610\n",
      "Epoch [29/100], Step [16600/6235], Loss: 43.7989\n",
      "Epoch [29/100], Step [16700/6235], Loss: 0.2749\n",
      "Epoch [29/100], Step [16800/6235], Loss: 10.4470\n",
      "Epoch [29/100], Step [16900/6235], Loss: 0.5594\n",
      "Epoch [29/100], Step [17000/6235], Loss: 0.1748\n",
      "Epoch [29/100], Step [17100/6235], Loss: 0.0085\n",
      "Epoch [29/100], Step [17200/6235], Loss: 250.6053\n",
      "Epoch [29/100], Step [17300/6235], Loss: 22.0099\n",
      "Epoch [29/100], Step [17400/6235], Loss: 58.7779\n",
      "Epoch [29/100], Step [17500/6235], Loss: 12.1683\n",
      "Epoch [29/100], Step [17600/6235], Loss: 2.5734\n",
      "Epoch [29/100], Step [17700/6235], Loss: 4.3891\n",
      "Epoch [29/100], Step [17800/6235], Loss: 14.6541\n",
      "Epoch [29/100], Step [17900/6235], Loss: 2.8871\n",
      "Epoch [29/100], Step [18000/6235], Loss: 1.8965\n",
      "Epoch [29/100], Step [18100/6235], Loss: 13.6557\n",
      "Epoch [29/100], Step [18200/6235], Loss: 1.1448\n",
      "Epoch [29/100], Step [18300/6235], Loss: 6.0320\n",
      "Epoch [29/100], Step [18400/6235], Loss: 1.1394\n",
      "Epoch [29/100], Step [18500/6235], Loss: 16.1206\n",
      "Epoch [29/100], Step [18600/6235], Loss: 4.1849\n",
      "Epoch [29/100], Step [18700/6235], Loss: 1.2550\n",
      "Epoch [29/100], Step [18800/6235], Loss: 66.0733\n",
      "Epoch [29/100], Step [18900/6235], Loss: 18.5732\n",
      "Epoch [29/100], Step [19000/6235], Loss: 0.8258\n",
      "Epoch [29/100], Step [19100/6235], Loss: 4.9026\n",
      "Epoch [29/100], Step [19200/6235], Loss: 3.6360\n",
      "Epoch [29/100], Step [19300/6235], Loss: 3.4622\n",
      "Epoch [29/100], Step [19400/6235], Loss: 260.0287\n",
      "Epoch [29/100], Step [19500/6235], Loss: 106.0710\n",
      "Epoch [29/100], Step [19600/6235], Loss: 63.7484\n",
      "Epoch [29/100], Step [19700/6235], Loss: 11.8259\n",
      "Epoch [29/100], Step [19800/6235], Loss: 6.6401\n",
      "Epoch [29/100], Step [19900/6235], Loss: 0.1232\n",
      "Epoch [29/100], Step [20000/6235], Loss: 70.2909\n",
      "Epoch [29/100], Step [20100/6235], Loss: 2.4236\n",
      "Epoch [29/100], Step [20200/6235], Loss: 2.3631\n",
      "Epoch [29/100], Step [20300/6235], Loss: 2.4487\n",
      "Epoch [29/100], Step [20400/6235], Loss: 9.5200\n",
      "Epoch [29/100], Step [20500/6235], Loss: 58.7928\n",
      "Epoch [29/100], Step [20600/6235], Loss: 331.0264\n",
      "Epoch [29/100], Step [20700/6235], Loss: 9.1059\n",
      "Epoch [29/100], Step [20800/6235], Loss: 3.1441\n",
      "Epoch [29/100], Step [20900/6235], Loss: 1.3796\n",
      "Epoch [29/100], Step [21000/6235], Loss: 12.2493\n",
      "Epoch [29/100], Step [21100/6235], Loss: 6.1116\n",
      "Epoch [29/100], Step [21200/6235], Loss: 0.2974\n",
      "Epoch [29/100], Step [21300/6235], Loss: 0.0981\n",
      "Epoch [29/100], Step [21400/6235], Loss: 3.1296\n",
      "Epoch [29/100], Step [21500/6235], Loss: 0.2985\n",
      "Epoch [29/100], Step [21600/6235], Loss: 0.7237\n",
      "Epoch [29/100], Step [21700/6235], Loss: 19.4952\n",
      "Epoch [29/100], Step [21800/6235], Loss: 2.1436\n",
      "Epoch [29/100], Step [21900/6235], Loss: 0.0189\n",
      "Epoch [29/100], Step [22000/6235], Loss: 0.9133\n",
      "Epoch [29/100], Step [22100/6235], Loss: 6.1964\n",
      "Epoch [29/100], Step [22200/6235], Loss: 16.3025\n",
      "Epoch [29/100], Step [22300/6235], Loss: 11.6759\n",
      "Epoch [29/100], Step [22400/6235], Loss: 8.8172\n",
      "Epoch [29/100], Step [22500/6235], Loss: 172.8055\n",
      "Epoch [29/100], Step [22600/6235], Loss: 17.9498\n",
      "Epoch [29/100], Step [22700/6235], Loss: 0.1726\n",
      "Epoch [29/100], Step [22800/6235], Loss: 3.2181\n",
      "Epoch [29/100], Step [22900/6235], Loss: 10.5074\n",
      "Epoch [29/100], Step [23000/6235], Loss: 6.6194\n",
      "Epoch [29/100], Step [23100/6235], Loss: 6.2948\n",
      "Epoch [29/100], Step [23200/6235], Loss: 5.7793\n",
      "Epoch [29/100], Step [23300/6235], Loss: 21.0019\n",
      "Epoch [29/100], Step [23400/6235], Loss: 2.6832\n",
      "Epoch [29/100], Step [23500/6235], Loss: 0.1459\n",
      "Epoch [29/100], Step [23600/6235], Loss: 136.0624\n",
      "Epoch [29/100], Step [23700/6235], Loss: 2.0248\n",
      "Epoch [29/100], Step [23800/6235], Loss: 0.6530\n",
      "Epoch [29/100], Step [23900/6235], Loss: 0.0704\n",
      "Epoch [29/100], Step [24000/6235], Loss: 3.7979\n",
      "Epoch [29/100], Step [24100/6235], Loss: 7.6049\n",
      "Epoch [29/100], Step [24200/6235], Loss: 18.9359\n",
      "Epoch [29/100], Step [24300/6235], Loss: 0.5127\n",
      "Epoch [29/100], Step [24400/6235], Loss: 0.2671\n",
      "Epoch [29/100], Step [24500/6235], Loss: 3.4222\n",
      "Epoch [29/100], Step [24600/6235], Loss: 0.5206\n",
      "Epoch [29/100], Step [24700/6235], Loss: 0.5806\n",
      "Epoch [29/100], Step [24800/6235], Loss: 0.3089\n",
      "Epoch [29/100], Step [24900/6235], Loss: 12.5715\n",
      "Epoch [29/100], Step [25000/6235], Loss: 4.8027\n",
      "Epoch [29/100], Step [25100/6235], Loss: 10.9792\n",
      "Epoch [29/100], Step [25200/6235], Loss: 0.2591\n",
      "Epoch [29/100], Step [25300/6235], Loss: 3.9728\n",
      "Epoch [29/100], Step [25400/6235], Loss: 2.3345\n",
      "Epoch [29/100], Step [25500/6235], Loss: 9.3857\n",
      "Epoch [29/100], Step [25600/6235], Loss: 10.5920\n",
      "Epoch [29/100], Step [25700/6235], Loss: 0.4793\n",
      "Epoch [29/100], Step [25800/6235], Loss: 3.0534\n",
      "Epoch [29/100], Step [25900/6235], Loss: 1.7241\n",
      "Epoch [29/100], Step [26000/6235], Loss: 0.0494\n",
      "Epoch [29/100], Step [26100/6235], Loss: 0.5452\n",
      "Epoch [29/100], Step [26200/6235], Loss: 0.4968\n",
      "Epoch [29/100], Step [26300/6235], Loss: 0.2277\n",
      "Epoch [29/100], Step [26400/6235], Loss: 2.7370\n",
      "Epoch [29/100], Step [26500/6235], Loss: 0.0141\n",
      "Epoch [29/100], Step [26600/6235], Loss: 0.3962\n",
      "Epoch [29/100], Step [26700/6235], Loss: 0.0582\n",
      "Epoch [29/100], Step [26800/6235], Loss: 0.2246\n",
      "Epoch [29/100], Step [26900/6235], Loss: 0.1619\n",
      "Epoch [29/100], Step [27000/6235], Loss: 12.8801\n",
      "Epoch [29/100], Step [27100/6235], Loss: 0.1257\n",
      "Epoch [29/100], Step [27200/6235], Loss: 0.2032\n",
      "Epoch [29/100], Step [27300/6235], Loss: 0.0204\n",
      "Epoch [29/100], Step [27400/6235], Loss: 0.2846\n",
      "Epoch [29/100], Step [27500/6235], Loss: 0.0451\n",
      "Epoch [29/100], Step [27600/6235], Loss: 0.0329\n",
      "Epoch [29/100], Step [27700/6235], Loss: 0.9779\n",
      "Epoch [29/100], Step [27800/6235], Loss: 6.5194\n",
      "Epoch [29/100], Step [27900/6235], Loss: 1.3354\n",
      "Epoch [29/100], Step [28000/6235], Loss: 86.9084\n",
      "Epoch [29/100], Step [28100/6235], Loss: 1.2401\n",
      "Epoch [29/100], Step [28200/6235], Loss: 36.1596\n",
      "Epoch [29/100], Step [28300/6235], Loss: 0.1850\n",
      "Epoch [29/100], Step [28400/6235], Loss: 17.9533\n",
      "Epoch [29/100], Step [28500/6235], Loss: 1.2145\n",
      "Epoch [29/100], Step [28600/6235], Loss: 1.5873\n",
      "Epoch [29/100], Step [28700/6235], Loss: 1.6163\n",
      "Epoch [29/100], Step [28800/6235], Loss: 0.7900\n",
      "Epoch [29/100], Step [28900/6235], Loss: 25.9360\n",
      "Epoch [29/100], Step [29000/6235], Loss: 1.5502\n",
      "Epoch [29/100], Step [29100/6235], Loss: 0.3865\n",
      "Epoch [29/100], Step [29200/6235], Loss: 5.9956\n",
      "Epoch [29/100], Step [29300/6235], Loss: 9.8862\n",
      "Epoch [29/100], Step [29400/6235], Loss: 1.3288\n",
      "Epoch [29/100], Step [29500/6235], Loss: 0.5258\n",
      "Epoch [29/100], Step [29600/6235], Loss: 0.6562\n",
      "Epoch [29/100], Step [29700/6235], Loss: 2.9518\n",
      "Epoch [29/100], Step [29800/6235], Loss: 0.1969\n",
      "Epoch [29/100], Step [29900/6235], Loss: 5.7931\n",
      "Epoch [29/100], Step [30000/6235], Loss: 2.0771\n",
      "Epoch [29/100], Step [30100/6235], Loss: 8.5632\n",
      "Epoch [29/100], Step [30200/6235], Loss: 0.7486\n",
      "Epoch [29/100], Step [30300/6235], Loss: 0.4363\n",
      "Epoch [29/100], Step [30400/6235], Loss: 5.3771\n",
      "Epoch [29/100], Step [30500/6235], Loss: 0.0935\n",
      "Epoch [29/100], Step [30600/6235], Loss: 1.7990\n",
      "Epoch [29/100], Step [30700/6235], Loss: 3.0461\n",
      "Epoch [29/100], Step [30800/6235], Loss: 0.3515\n",
      "Epoch [29/100], Step [30900/6235], Loss: 0.3233\n",
      "Epoch [29/100], Step [31000/6235], Loss: 0.0159\n",
      "Epoch [29/100], Step [31100/6235], Loss: 2.6484\n",
      "Epoch [29/100], Step [31200/6235], Loss: 2.3344\n",
      "Epoch [29/100], Step [31300/6235], Loss: 0.8848\n",
      "Epoch [29/100], Step [31400/6235], Loss: 3.3540\n",
      "Epoch [29/100], Step [31500/6235], Loss: 1.0029\n",
      "Epoch [29/100], Step [31600/6235], Loss: 8.6658\n",
      "Epoch [29/100], Step [31700/6235], Loss: 14.3990\n",
      "Epoch [29/100], Step [31800/6235], Loss: 1.3983\n",
      "Epoch [29/100], Step [31900/6235], Loss: 109.6710\n",
      "Epoch [29/100], Step [32000/6235], Loss: 48.4439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Step [32100/6235], Loss: 1.2811\n",
      "Epoch [29/100], Step [32200/6235], Loss: 153.7035\n",
      "Epoch [29/100], Step [32300/6235], Loss: 1.6234\n",
      "Epoch [29/100], Step [32400/6235], Loss: 1.4487\n",
      "Epoch [29/100], Step [32500/6235], Loss: 8.8676\n",
      "Epoch [29/100], Step [32600/6235], Loss: 0.2818\n",
      "Epoch [29/100], Step [32700/6235], Loss: 86.8405\n",
      "Epoch [29/100], Step [32800/6235], Loss: 17.3615\n",
      "Epoch [29/100], Step [32900/6235], Loss: 1.0177\n",
      "Epoch [29/100], Step [33000/6235], Loss: 0.6207\n",
      "Epoch [29/100], Step [33100/6235], Loss: 1.2054\n",
      "Epoch [29/100], Step [33200/6235], Loss: 1.5579\n",
      "Epoch [29/100], Step [33300/6235], Loss: 0.2054\n",
      "Epoch [29/100], Step [33400/6235], Loss: 151.3499\n",
      "Epoch [29/100], Step [33500/6235], Loss: 0.8835\n",
      "Epoch [29/100], Step [33600/6235], Loss: 4.3643\n",
      "Epoch [29/100], Step [33700/6235], Loss: 0.7854\n",
      "Epoch [29/100], Step [33800/6235], Loss: 3.0214\n",
      "Epoch [29/100], Step [33900/6235], Loss: 25.5760\n",
      "Epoch [29/100], Step [34000/6235], Loss: 0.0126\n",
      "Epoch [29/100], Step [34100/6235], Loss: 0.2812\n",
      "Epoch [29/100], Step [34200/6235], Loss: 1.9411\n",
      "Epoch [29/100], Step [34300/6235], Loss: 7.2641\n",
      "Epoch [29/100], Step [34400/6235], Loss: 0.1445\n",
      "Epoch [29/100], Step [34500/6235], Loss: 126.5692\n",
      "Epoch [29/100], Step [34600/6235], Loss: 0.3504\n",
      "Epoch [29/100], Step [34700/6235], Loss: 10.7298\n",
      "Epoch [29/100], Step [34800/6235], Loss: 7.8410\n",
      "Epoch [29/100], Step [34900/6235], Loss: 64.9364\n",
      "Epoch [29/100], Step [35000/6235], Loss: 0.2265\n",
      "Epoch [29/100], Step [35100/6235], Loss: 0.8872\n",
      "Epoch [29/100], Step [35200/6235], Loss: 0.5362\n",
      "Epoch [29/100], Step [35300/6235], Loss: 3.1137\n",
      "Epoch [29/100], Step [35400/6235], Loss: 0.5320\n",
      "Epoch [29/100], Step [35500/6235], Loss: 0.7431\n",
      "Epoch [29/100], Step [35600/6235], Loss: 2.9026\n",
      "Epoch [29/100], Step [35700/6235], Loss: 4.6977\n",
      "Epoch [29/100], Step [35800/6235], Loss: 0.5236\n",
      "Epoch [29/100], Step [35900/6235], Loss: 1.5322\n",
      "Epoch [29/100], Step [36000/6235], Loss: 0.1693\n",
      "Epoch [29/100], Step [36100/6235], Loss: 0.0100\n",
      "Epoch [29/100], Step [36200/6235], Loss: 13.7419\n",
      "Epoch [29/100], Step [36300/6235], Loss: 0.0548\n",
      "Epoch [29/100], Step [36400/6235], Loss: 3.0258\n",
      "Epoch [29/100], Step [36500/6235], Loss: 7.7940\n",
      "Epoch [29/100], Step [36600/6235], Loss: 0.1019\n",
      "Epoch [29/100], Step [36700/6235], Loss: 0.5768\n",
      "Epoch [29/100], Step [36800/6235], Loss: 7.4205\n",
      "Epoch [29/100], Step [36900/6235], Loss: 13.5822\n",
      "Epoch [29/100], Step [37000/6235], Loss: 0.8474\n",
      "Epoch [29/100], Step [37100/6235], Loss: 1.6959\n",
      "Epoch [29/100], Step [37200/6235], Loss: 0.0532\n",
      "Epoch [29/100], Step [37300/6235], Loss: 0.0291\n",
      "Epoch [29/100], Step [37400/6235], Loss: 0.1840\n",
      "Epoch [29/100], Step [37500/6235], Loss: 5.7115\n",
      "Epoch [29/100], Step [37600/6235], Loss: 12.0521\n",
      "Epoch [29/100], Step [37700/6235], Loss: 1.8056\n",
      "Epoch [29/100], Step [37800/6235], Loss: 5.6117\n",
      "Epoch [29/100], Step [37900/6235], Loss: 7.4383\n",
      "Epoch [29/100], Step [38000/6235], Loss: 0.6010\n",
      "Epoch [29/100], Step [38100/6235], Loss: 3.9871\n",
      "Epoch [29/100], Step [38200/6235], Loss: 1.8068\n",
      "Epoch [29/100], Step [38300/6235], Loss: 0.0944\n",
      "Epoch [29/100], Step [38400/6235], Loss: 0.0965\n",
      "Epoch [29/100], Step [38500/6235], Loss: 2.3958\n",
      "Epoch [29/100], Step [38600/6235], Loss: 0.2832\n",
      "Epoch [29/100], Step [38700/6235], Loss: 0.0573\n",
      "Epoch [29/100], Step [38800/6235], Loss: 0.1788\n",
      "Epoch [29/100], Step [38900/6235], Loss: 7.1095\n",
      "Epoch [29/100], Step [39000/6235], Loss: 0.2722\n",
      "Epoch [29/100], Step [39100/6235], Loss: 4.7154\n",
      "Epoch [29/100], Step [39200/6235], Loss: 0.7215\n",
      "Epoch [29/100], Step [39300/6235], Loss: 29.4356\n",
      "Epoch [29/100], Step [39400/6235], Loss: 120.8264\n",
      "Epoch [29/100], Step [39500/6235], Loss: 227.8572\n",
      "Epoch [29/100], Step [39600/6235], Loss: 7.4558\n",
      "Epoch [29/100], Step [39700/6235], Loss: 97.7345\n",
      "Epoch [29/100], Step [39800/6235], Loss: 164.4212\n",
      "Epoch [29/100], Step [39900/6235], Loss: 0.6941\n",
      "Epoch [29/100], Step [40000/6235], Loss: 15.2700\n",
      "Epoch [29/100], Step [40100/6235], Loss: 26.0639\n",
      "Epoch [29/100], Step [40200/6235], Loss: 1.2863\n",
      "Epoch [29/100], Step [40300/6235], Loss: 1.2226\n",
      "Epoch [29/100], Step [40400/6235], Loss: 1.8385\n",
      "Epoch [29/100], Step [40500/6235], Loss: 2.5162\n",
      "Epoch [29/100], Step [40600/6235], Loss: 0.2207\n",
      "Epoch [29/100], Step [40700/6235], Loss: 7.4229\n",
      "Epoch [29/100], Step [40800/6235], Loss: 0.8695\n",
      "Epoch [29/100], Step [40900/6235], Loss: 0.3395\n",
      "Epoch [29/100], Step [41000/6235], Loss: 48.3610\n",
      "Epoch [29/100], Step [41100/6235], Loss: 1.5267\n",
      "Epoch [29/100], Step [41200/6235], Loss: 29.4100\n",
      "Epoch [29/100], Step [41300/6235], Loss: 3.2661\n",
      "Epoch [29/100], Step [41400/6235], Loss: 0.0445\n",
      "Epoch [29/100], Step [41500/6235], Loss: 2.2463\n",
      "Epoch [29/100], Step [41600/6235], Loss: 0.4702\n",
      "Epoch [29/100], Step [41700/6235], Loss: 0.0753\n",
      "Epoch [29/100], Step [41800/6235], Loss: 1.1704\n",
      "Epoch [29/100], Step [41900/6235], Loss: 4.7676\n",
      "Epoch [29/100], Step [42000/6235], Loss: 4.5971\n",
      "Epoch [29/100], Step [42100/6235], Loss: 10.6730\n",
      "Epoch [29/100], Step [42200/6235], Loss: 48.5734\n",
      "Epoch [29/100], Step [42300/6235], Loss: 1.2646\n",
      "Epoch [29/100], Step [42400/6235], Loss: 3.5291\n",
      "Epoch [29/100], Step [42500/6235], Loss: 0.7187\n",
      "Epoch [29/100], Step [42600/6235], Loss: 2.2665\n",
      "Epoch [29/100], Step [42700/6235], Loss: 0.7430\n",
      "Epoch [29/100], Step [42800/6235], Loss: 11.2569\n",
      "Epoch [29/100], Step [42900/6235], Loss: 1.6947\n",
      "Epoch [29/100], Step [43000/6235], Loss: 0.1477\n",
      "Epoch [29/100], Step [43100/6235], Loss: 0.0324\n",
      "Epoch [29/100], Step [43200/6235], Loss: 0.8808\n",
      "Epoch [29/100], Step [43300/6235], Loss: 7.4531\n",
      "Epoch [29/100], Step [43400/6235], Loss: 9.7788\n",
      "Epoch [29/100], Step [43500/6235], Loss: 9.8111\n",
      "Epoch [29/100], Step [43600/6235], Loss: 7.4189\n",
      "Epoch [29/100], Step [43700/6235], Loss: 49.1267\n",
      "Epoch [29/100], Step [43800/6235], Loss: 0.5437\n",
      "Epoch [29/100], Step [43900/6235], Loss: 0.6199\n",
      "Epoch [29/100], Step [44000/6235], Loss: 72.1208\n",
      "Epoch [29/100], Step [44100/6235], Loss: 4.8181\n",
      "Epoch [29/100], Step [44200/6235], Loss: 3.1864\n",
      "Epoch [29/100], Step [44300/6235], Loss: 0.3924\n",
      "Epoch [29/100], Step [44400/6235], Loss: 0.9088\n",
      "Epoch [29/100], Step [44500/6235], Loss: 3.9605\n",
      "Epoch [29/100], Step [44600/6235], Loss: 21.0601\n",
      "Epoch [29/100], Step [44700/6235], Loss: 0.7865\n",
      "Epoch [29/100], Step [44800/6235], Loss: 3.6798\n",
      "Epoch [29/100], Step [44900/6235], Loss: 6.5547\n",
      "Epoch [29/100], Step [45000/6235], Loss: 5.1319\n",
      "Epoch [29/100], Step [45100/6235], Loss: 35.9601\n",
      "Epoch [29/100], Step [45200/6235], Loss: 2.2054\n",
      "Epoch [29/100], Step [45300/6235], Loss: 28.2343\n",
      "Epoch [29/100], Step [45400/6235], Loss: 10.9084\n",
      "Epoch [29/100], Step [45500/6235], Loss: 0.6780\n",
      "Epoch [29/100], Step [45600/6235], Loss: 0.1845\n",
      "Epoch [29/100], Step [45700/6235], Loss: 84.2100\n",
      "Epoch [29/100], Step [45800/6235], Loss: 323.5989\n",
      "Epoch [29/100], Step [45900/6235], Loss: 20.5910\n",
      "Epoch [29/100], Step [46000/6235], Loss: 6.5745\n",
      "Epoch [29/100], Step [46100/6235], Loss: 13.3350\n",
      "Epoch [29/100], Step [46200/6235], Loss: 20.2843\n",
      "Epoch [29/100], Step [46300/6235], Loss: 4.9786\n",
      "Epoch [29/100], Step [46400/6235], Loss: 12.6827\n",
      "Epoch [29/100], Step [46500/6235], Loss: 10.3397\n",
      "Epoch [29/100], Step [46600/6235], Loss: 10.6654\n",
      "Epoch [29/100], Step [46700/6235], Loss: 14.8205\n",
      "Epoch [29/100], Step [46800/6235], Loss: 2.9568\n",
      "Epoch [29/100], Step [46900/6235], Loss: 5.9039\n",
      "Epoch [29/100], Step [47000/6235], Loss: 5.1263\n",
      "Epoch [29/100], Step [47100/6235], Loss: 1.8135\n",
      "Epoch [29/100], Step [47200/6235], Loss: 11.1862\n",
      "Epoch [29/100], Step [47300/6235], Loss: 1.0694\n",
      "Epoch [29/100], Step [47400/6235], Loss: 10.4673\n",
      "Epoch [29/100], Step [47500/6235], Loss: 1.6597\n",
      "Epoch [29/100], Step [47600/6235], Loss: 4.9066\n",
      "Epoch [29/100], Step [47700/6235], Loss: 6.9501\n",
      "Epoch [29/100], Step [47800/6235], Loss: 7.3495\n",
      "Epoch [29/100], Step [47900/6235], Loss: 16.9024\n",
      "Epoch [29/100], Step [48000/6235], Loss: 113.5620\n",
      "Epoch [29/100], Step [48100/6235], Loss: 3.1731\n",
      "Epoch [29/100], Step [48200/6235], Loss: 21.4637\n",
      "Epoch [29/100], Step [48300/6235], Loss: 477.0754\n",
      "Epoch [29/100], Step [48400/6235], Loss: 22.3996\n",
      "Epoch [29/100], Step [48500/6235], Loss: 15.4066\n",
      "Epoch [29/100], Step [48600/6235], Loss: 165.5942\n",
      "Epoch [29/100], Step [48700/6235], Loss: 26.5908\n",
      "Epoch [29/100], Step [48800/6235], Loss: 567.8692\n",
      "Epoch [29/100], Step [48900/6235], Loss: 527.3104\n",
      "Epoch [29/100], Step [49000/6235], Loss: 213.6957\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [29/100], Step [49100/6235], Loss: 3246.7612\n",
      "Epoch [29/100], Step [49200/6235], Loss: 591.0774\n",
      "Epoch [29/100], Step [49300/6235], Loss: 1198.4034\n",
      "Epoch [29/100], Step [49400/6235], Loss: 180.6125\n",
      "Epoch [29/100], Step [49500/6235], Loss: 1.4544\n",
      "Epoch [29/100], Step [49600/6235], Loss: 52.7490\n",
      "Epoch [29/100], Step [49700/6235], Loss: 1068.2869\n",
      "Epoch [29/100], Step [49800/6235], Loss: 212.8558\n",
      "Epoch [30/100], Step [100/6235], Loss: 28.4062\n",
      "Epoch [30/100], Step [200/6235], Loss: 0.1775\n",
      "Epoch [30/100], Step [300/6235], Loss: 0.0302\n",
      "Epoch [30/100], Step [400/6235], Loss: 0.0036\n",
      "Epoch [30/100], Step [500/6235], Loss: 4.7107\n",
      "Epoch [30/100], Step [600/6235], Loss: 0.0308\n",
      "Epoch [30/100], Step [700/6235], Loss: 0.5150\n",
      "Epoch [30/100], Step [800/6235], Loss: 0.2003\n",
      "Epoch [30/100], Step [900/6235], Loss: 0.0747\n",
      "Epoch [30/100], Step [1000/6235], Loss: 0.0317\n",
      "Epoch [30/100], Step [1100/6235], Loss: 0.2245\n",
      "Epoch [30/100], Step [1200/6235], Loss: 0.1916\n",
      "Epoch [30/100], Step [1300/6235], Loss: 0.0684\n",
      "Epoch [30/100], Step [1400/6235], Loss: 0.3592\n",
      "Epoch [30/100], Step [1500/6235], Loss: 0.0058\n",
      "Epoch [30/100], Step [1600/6235], Loss: 0.2272\n",
      "Epoch [30/100], Step [1700/6235], Loss: 0.0177\n",
      "Epoch [30/100], Step [1800/6235], Loss: 0.1860\n",
      "Epoch [30/100], Step [1900/6235], Loss: 0.7010\n",
      "Epoch [30/100], Step [2000/6235], Loss: 2.2137\n",
      "Epoch [30/100], Step [2100/6235], Loss: 1.0734\n",
      "Epoch [30/100], Step [2200/6235], Loss: 10.2083\n",
      "Epoch [30/100], Step [2300/6235], Loss: 16.4769\n",
      "Epoch [30/100], Step [2400/6235], Loss: 7.1455\n",
      "Epoch [30/100], Step [2500/6235], Loss: 38.9741\n",
      "Epoch [30/100], Step [2600/6235], Loss: 9.5054\n",
      "Epoch [30/100], Step [2700/6235], Loss: 21.5071\n",
      "Epoch [30/100], Step [2800/6235], Loss: 134.6670\n",
      "Epoch [30/100], Step [2900/6235], Loss: 6.4376\n",
      "Epoch [30/100], Step [3000/6235], Loss: 0.4326\n",
      "Epoch [30/100], Step [3100/6235], Loss: 61.5115\n",
      "Epoch [30/100], Step [3200/6235], Loss: 83.9259\n",
      "Epoch [30/100], Step [3300/6235], Loss: 1.4405\n",
      "Epoch [30/100], Step [3400/6235], Loss: 2.8505\n",
      "Epoch [30/100], Step [3500/6235], Loss: 29.3822\n",
      "Epoch [30/100], Step [3600/6235], Loss: 10.1972\n",
      "Epoch [30/100], Step [3700/6235], Loss: 1.0648\n",
      "Epoch [30/100], Step [3800/6235], Loss: 0.5895\n",
      "Epoch [30/100], Step [3900/6235], Loss: 1.7551\n",
      "Epoch [30/100], Step [4000/6235], Loss: 0.0648\n",
      "Epoch [30/100], Step [4100/6235], Loss: 4.6353\n",
      "Epoch [30/100], Step [4200/6235], Loss: 0.1822\n",
      "Epoch [30/100], Step [4300/6235], Loss: 10.8001\n",
      "Epoch [30/100], Step [4400/6235], Loss: 4.0449\n",
      "Epoch [30/100], Step [4500/6235], Loss: 58.0981\n",
      "Epoch [30/100], Step [4600/6235], Loss: 9.0002\n",
      "Epoch [30/100], Step [4700/6235], Loss: 1.5174\n",
      "Epoch [30/100], Step [4800/6235], Loss: 1.2081\n",
      "Epoch [30/100], Step [4900/6235], Loss: 0.1654\n",
      "Epoch [30/100], Step [5000/6235], Loss: 0.3476\n",
      "Epoch [30/100], Step [5100/6235], Loss: 6.0280\n",
      "Epoch [30/100], Step [5200/6235], Loss: 1.7426\n",
      "Epoch [30/100], Step [5300/6235], Loss: 30.8455\n",
      "Epoch [30/100], Step [5400/6235], Loss: 0.2442\n",
      "Epoch [30/100], Step [5500/6235], Loss: 0.1100\n",
      "Epoch [30/100], Step [5600/6235], Loss: 0.3197\n",
      "Epoch [30/100], Step [5700/6235], Loss: 2.0193\n",
      "Epoch [30/100], Step [5800/6235], Loss: 0.9511\n",
      "Epoch [30/100], Step [5900/6235], Loss: 0.0143\n",
      "Epoch [30/100], Step [6000/6235], Loss: 0.3167\n",
      "Epoch [30/100], Step [6100/6235], Loss: 0.0989\n",
      "Epoch [30/100], Step [6200/6235], Loss: 0.6339\n",
      "Epoch [30/100], Step [6300/6235], Loss: 1.6533\n",
      "Epoch [30/100], Step [6400/6235], Loss: 0.0222\n",
      "Epoch [30/100], Step [6500/6235], Loss: 0.5235\n",
      "Epoch [30/100], Step [6600/6235], Loss: 2.1120\n",
      "Epoch [30/100], Step [6700/6235], Loss: 1.3614\n",
      "Epoch [30/100], Step [6800/6235], Loss: 0.5575\n",
      "Epoch [30/100], Step [6900/6235], Loss: 2.7072\n",
      "Epoch [30/100], Step [7000/6235], Loss: 0.6198\n",
      "Epoch [30/100], Step [7100/6235], Loss: 0.1970\n",
      "Epoch [30/100], Step [7200/6235], Loss: 2.1848\n",
      "Epoch [30/100], Step [7300/6235], Loss: 2.9165\n",
      "Epoch [30/100], Step [7400/6235], Loss: 0.1563\n",
      "Epoch [30/100], Step [7500/6235], Loss: 1.8758\n",
      "Epoch [30/100], Step [7600/6235], Loss: 19.3534\n",
      "Epoch [30/100], Step [7700/6235], Loss: 12.9890\n",
      "Epoch [30/100], Step [7800/6235], Loss: 14.3993\n",
      "Epoch [30/100], Step [7900/6235], Loss: 10.8726\n",
      "Epoch [30/100], Step [8000/6235], Loss: 0.3137\n",
      "Epoch [30/100], Step [8100/6235], Loss: 3.8992\n",
      "Epoch [30/100], Step [8200/6235], Loss: 21.6596\n",
      "Epoch [30/100], Step [8300/6235], Loss: 65.3040\n",
      "Epoch [30/100], Step [8400/6235], Loss: 54.8548\n",
      "Epoch [30/100], Step [8500/6235], Loss: 74.7158\n",
      "Epoch [30/100], Step [8600/6235], Loss: 19.1205\n",
      "Epoch [30/100], Step [8700/6235], Loss: 88.8839\n",
      "Epoch [30/100], Step [8800/6235], Loss: 368.7722\n",
      "Epoch [30/100], Step [8900/6235], Loss: 13.0652\n",
      "Epoch [30/100], Step [9000/6235], Loss: 691.9131\n",
      "Epoch [30/100], Step [9100/6235], Loss: 2545.5481\n",
      "Epoch [30/100], Step [9200/6235], Loss: 5091.8657\n",
      "Epoch [30/100], Step [9300/6235], Loss: 27.0880\n",
      "Epoch [30/100], Step [9400/6235], Loss: 134.6418\n",
      "Epoch [30/100], Step [9500/6235], Loss: 535.8069\n",
      "Epoch [30/100], Step [9600/6235], Loss: 423.1590\n",
      "Epoch [30/100], Step [9700/6235], Loss: 71.1045\n",
      "Epoch [30/100], Step [9800/6235], Loss: 838.4883\n",
      "Epoch [30/100], Step [9900/6235], Loss: 12.2549\n",
      "Epoch [30/100], Step [10000/6235], Loss: 84.2126\n",
      "Epoch [30/100], Step [10100/6235], Loss: 1.6321\n",
      "Epoch [30/100], Step [10200/6235], Loss: 739.1342\n",
      "Epoch [30/100], Step [10300/6235], Loss: 5.5704\n",
      "Epoch [30/100], Step [10400/6235], Loss: 0.4013\n",
      "Epoch [30/100], Step [10500/6235], Loss: 1.4384\n",
      "Epoch [30/100], Step [10600/6235], Loss: 51.5054\n",
      "Epoch [30/100], Step [10700/6235], Loss: 55.0040\n",
      "Epoch [30/100], Step [10800/6235], Loss: 30.5119\n",
      "Epoch [30/100], Step [10900/6235], Loss: 3.7594\n",
      "Epoch [30/100], Step [11000/6235], Loss: 245.0572\n",
      "Epoch [30/100], Step [11100/6235], Loss: 18.6847\n",
      "Epoch [30/100], Step [11200/6235], Loss: 72.8951\n",
      "Epoch [30/100], Step [11300/6235], Loss: 202.6248\n",
      "Epoch [30/100], Step [11400/6235], Loss: 1.5895\n",
      "Epoch [30/100], Step [11500/6235], Loss: 0.7381\n",
      "Epoch [30/100], Step [11600/6235], Loss: 0.9669\n",
      "Epoch [30/100], Step [11700/6235], Loss: 46.1417\n",
      "Epoch [30/100], Step [11800/6235], Loss: 80.6759\n",
      "Epoch [30/100], Step [11900/6235], Loss: 10.5353\n",
      "Epoch [30/100], Step [12000/6235], Loss: 573.3626\n",
      "Epoch [30/100], Step [12100/6235], Loss: 181.4462\n",
      "Epoch [30/100], Step [12200/6235], Loss: 37.7364\n",
      "Epoch [30/100], Step [12300/6235], Loss: 14.6329\n",
      "Epoch [30/100], Step [12400/6235], Loss: 388.3957\n",
      "Epoch [30/100], Step [12500/6235], Loss: 26.2597\n",
      "Epoch [30/100], Step [12600/6235], Loss: 40.8629\n",
      "Epoch [30/100], Step [12700/6235], Loss: 2.0239\n",
      "Epoch [30/100], Step [12800/6235], Loss: 4.8909\n",
      "Epoch [30/100], Step [12900/6235], Loss: 35.0204\n",
      "Epoch [30/100], Step [13000/6235], Loss: 0.2564\n",
      "Epoch [30/100], Step [13100/6235], Loss: 66.3386\n",
      "Epoch [30/100], Step [13200/6235], Loss: 12.4939\n",
      "Epoch [30/100], Step [13300/6235], Loss: 43.9089\n",
      "Epoch [30/100], Step [13400/6235], Loss: 250.2891\n",
      "Epoch [30/100], Step [13500/6235], Loss: 2.8973\n",
      "Epoch [30/100], Step [13600/6235], Loss: 0.2914\n",
      "Epoch [30/100], Step [13700/6235], Loss: 97.6783\n",
      "Epoch [30/100], Step [13800/6235], Loss: 151.1774\n",
      "Epoch [30/100], Step [13900/6235], Loss: 41.0207\n",
      "Epoch [30/100], Step [14000/6235], Loss: 15.3843\n",
      "Epoch [30/100], Step [14100/6235], Loss: 10.1392\n",
      "Epoch [30/100], Step [14200/6235], Loss: 64.8617\n",
      "Epoch [30/100], Step [14300/6235], Loss: 44.0668\n",
      "Epoch [30/100], Step [14400/6235], Loss: 39.4683\n",
      "Epoch [30/100], Step [14500/6235], Loss: 43.6958\n",
      "Epoch [30/100], Step [14600/6235], Loss: 0.3423\n",
      "Epoch [30/100], Step [14700/6235], Loss: 45.2589\n",
      "Epoch [30/100], Step [14800/6235], Loss: 31.8958\n",
      "Epoch [30/100], Step [14900/6235], Loss: 1.8295\n",
      "Epoch [30/100], Step [15000/6235], Loss: 2.9005\n",
      "Epoch [30/100], Step [15100/6235], Loss: 0.2172\n",
      "Epoch [30/100], Step [15200/6235], Loss: 6.4794\n",
      "Epoch [30/100], Step [15300/6235], Loss: 25.4767\n",
      "Epoch [30/100], Step [15400/6235], Loss: 2.1048\n",
      "Epoch [30/100], Step [15500/6235], Loss: 19.7215\n",
      "Epoch [30/100], Step [15600/6235], Loss: 119.2595\n",
      "Epoch [30/100], Step [15700/6235], Loss: 219.9891\n",
      "Epoch [30/100], Step [15800/6235], Loss: 9.0883\n",
      "Epoch [30/100], Step [15900/6235], Loss: 0.4009\n",
      "Epoch [30/100], Step [16000/6235], Loss: 75.4491\n",
      "Epoch [30/100], Step [16100/6235], Loss: 0.5646\n",
      "Epoch [30/100], Step [16200/6235], Loss: 0.5099\n",
      "Epoch [30/100], Step [16300/6235], Loss: 8.7507\n",
      "Epoch [30/100], Step [16400/6235], Loss: 31.2680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Step [16500/6235], Loss: 284.1724\n",
      "Epoch [30/100], Step [16600/6235], Loss: 47.8156\n",
      "Epoch [30/100], Step [16700/6235], Loss: 0.3078\n",
      "Epoch [30/100], Step [16800/6235], Loss: 12.7187\n",
      "Epoch [30/100], Step [16900/6235], Loss: 0.5396\n",
      "Epoch [30/100], Step [17000/6235], Loss: 0.1826\n",
      "Epoch [30/100], Step [17100/6235], Loss: 0.0654\n",
      "Epoch [30/100], Step [17200/6235], Loss: 240.9332\n",
      "Epoch [30/100], Step [17300/6235], Loss: 0.7318\n",
      "Epoch [30/100], Step [17400/6235], Loss: 62.5910\n",
      "Epoch [30/100], Step [17500/6235], Loss: 8.3179\n",
      "Epoch [30/100], Step [17600/6235], Loss: 3.0822\n",
      "Epoch [30/100], Step [17700/6235], Loss: 0.6849\n",
      "Epoch [30/100], Step [17800/6235], Loss: 22.0622\n",
      "Epoch [30/100], Step [17900/6235], Loss: 11.5507\n",
      "Epoch [30/100], Step [18000/6235], Loss: 1.3903\n",
      "Epoch [30/100], Step [18100/6235], Loss: 15.8559\n",
      "Epoch [30/100], Step [18200/6235], Loss: 0.4003\n",
      "Epoch [30/100], Step [18300/6235], Loss: 0.8552\n",
      "Epoch [30/100], Step [18400/6235], Loss: 1.3535\n",
      "Epoch [30/100], Step [18500/6235], Loss: 10.5993\n",
      "Epoch [30/100], Step [18600/6235], Loss: 4.3381\n",
      "Epoch [30/100], Step [18700/6235], Loss: 1.1943\n",
      "Epoch [30/100], Step [18800/6235], Loss: 91.3649\n",
      "Epoch [30/100], Step [18900/6235], Loss: 47.9406\n",
      "Epoch [30/100], Step [19000/6235], Loss: 9.4352\n",
      "Epoch [30/100], Step [19100/6235], Loss: 6.2799\n",
      "Epoch [30/100], Step [19200/6235], Loss: 1.3270\n",
      "Epoch [30/100], Step [19300/6235], Loss: 3.7827\n",
      "Epoch [30/100], Step [19400/6235], Loss: 125.3692\n",
      "Epoch [30/100], Step [19500/6235], Loss: 37.2561\n",
      "Epoch [30/100], Step [19600/6235], Loss: 61.5478\n",
      "Epoch [30/100], Step [19700/6235], Loss: 9.7534\n",
      "Epoch [30/100], Step [19800/6235], Loss: 4.9170\n",
      "Epoch [30/100], Step [19900/6235], Loss: 0.1324\n",
      "Epoch [30/100], Step [20000/6235], Loss: 69.2475\n",
      "Epoch [30/100], Step [20100/6235], Loss: 3.2834\n",
      "Epoch [30/100], Step [20200/6235], Loss: 2.3359\n",
      "Epoch [30/100], Step [20300/6235], Loss: 1.8269\n",
      "Epoch [30/100], Step [20400/6235], Loss: 9.0487\n",
      "Epoch [30/100], Step [20500/6235], Loss: 56.7968\n",
      "Epoch [30/100], Step [20600/6235], Loss: 228.5531\n",
      "Epoch [30/100], Step [20700/6235], Loss: 25.2265\n",
      "Epoch [30/100], Step [20800/6235], Loss: 1.4503\n",
      "Epoch [30/100], Step [20900/6235], Loss: 20.6866\n",
      "Epoch [30/100], Step [21000/6235], Loss: 24.7422\n",
      "Epoch [30/100], Step [21100/6235], Loss: 6.9633\n",
      "Epoch [30/100], Step [21200/6235], Loss: 0.3336\n",
      "Epoch [30/100], Step [21300/6235], Loss: 0.0493\n",
      "Epoch [30/100], Step [21400/6235], Loss: 2.4659\n",
      "Epoch [30/100], Step [21500/6235], Loss: 1.7313\n",
      "Epoch [30/100], Step [21600/6235], Loss: 27.0565\n",
      "Epoch [30/100], Step [21700/6235], Loss: 0.2496\n",
      "Epoch [30/100], Step [21800/6235], Loss: 3.9767\n",
      "Epoch [30/100], Step [21900/6235], Loss: 1.7457\n",
      "Epoch [30/100], Step [22000/6235], Loss: 10.7114\n",
      "Epoch [30/100], Step [22100/6235], Loss: 0.0347\n",
      "Epoch [30/100], Step [22200/6235], Loss: 0.6008\n",
      "Epoch [30/100], Step [22300/6235], Loss: 1.2035\n",
      "Epoch [30/100], Step [22400/6235], Loss: 3.9005\n",
      "Epoch [30/100], Step [22500/6235], Loss: 114.8212\n",
      "Epoch [30/100], Step [22600/6235], Loss: 17.9652\n",
      "Epoch [30/100], Step [22700/6235], Loss: 0.4253\n",
      "Epoch [30/100], Step [22800/6235], Loss: 10.6590\n",
      "Epoch [30/100], Step [22900/6235], Loss: 14.4419\n",
      "Epoch [30/100], Step [23000/6235], Loss: 21.3782\n",
      "Epoch [30/100], Step [23100/6235], Loss: 5.8939\n",
      "Epoch [30/100], Step [23200/6235], Loss: 1.5585\n",
      "Epoch [30/100], Step [23300/6235], Loss: 20.7571\n",
      "Epoch [30/100], Step [23400/6235], Loss: 2.6888\n",
      "Epoch [30/100], Step [23500/6235], Loss: 0.2084\n",
      "Epoch [30/100], Step [23600/6235], Loss: 137.1749\n",
      "Epoch [30/100], Step [23700/6235], Loss: 2.8752\n",
      "Epoch [30/100], Step [23800/6235], Loss: 0.7618\n",
      "Epoch [30/100], Step [23900/6235], Loss: 0.3342\n",
      "Epoch [30/100], Step [24000/6235], Loss: 2.6773\n",
      "Epoch [30/100], Step [24100/6235], Loss: 0.2133\n",
      "Epoch [30/100], Step [24200/6235], Loss: 54.5338\n",
      "Epoch [30/100], Step [24300/6235], Loss: 0.5518\n",
      "Epoch [30/100], Step [24400/6235], Loss: 0.2365\n",
      "Epoch [30/100], Step [24500/6235], Loss: 0.9648\n",
      "Epoch [30/100], Step [24600/6235], Loss: 0.0970\n",
      "Epoch [30/100], Step [24700/6235], Loss: 0.1529\n",
      "Epoch [30/100], Step [24800/6235], Loss: 0.5363\n",
      "Epoch [30/100], Step [24900/6235], Loss: 8.9574\n",
      "Epoch [30/100], Step [25000/6235], Loss: 7.7038\n",
      "Epoch [30/100], Step [25100/6235], Loss: 8.0683\n",
      "Epoch [30/100], Step [25200/6235], Loss: 0.0475\n",
      "Epoch [30/100], Step [25300/6235], Loss: 2.1195\n",
      "Epoch [30/100], Step [25400/6235], Loss: 3.0652\n",
      "Epoch [30/100], Step [25500/6235], Loss: 9.3978\n",
      "Epoch [30/100], Step [25600/6235], Loss: 9.1822\n",
      "Epoch [30/100], Step [25700/6235], Loss: 0.0629\n",
      "Epoch [30/100], Step [25800/6235], Loss: 1.1846\n",
      "Epoch [30/100], Step [25900/6235], Loss: 2.3877\n",
      "Epoch [30/100], Step [26000/6235], Loss: 0.1034\n",
      "Epoch [30/100], Step [26100/6235], Loss: 0.1686\n",
      "Epoch [30/100], Step [26200/6235], Loss: 1.2832\n",
      "Epoch [30/100], Step [26300/6235], Loss: 0.5126\n",
      "Epoch [30/100], Step [26400/6235], Loss: 1.0105\n",
      "Epoch [30/100], Step [26500/6235], Loss: 0.0412\n",
      "Epoch [30/100], Step [26600/6235], Loss: 0.0414\n",
      "Epoch [30/100], Step [26700/6235], Loss: 0.0652\n",
      "Epoch [30/100], Step [26800/6235], Loss: 0.0602\n",
      "Epoch [30/100], Step [26900/6235], Loss: 0.1109\n",
      "Epoch [30/100], Step [27000/6235], Loss: 15.7773\n",
      "Epoch [30/100], Step [27100/6235], Loss: 0.1028\n",
      "Epoch [30/100], Step [27200/6235], Loss: 0.0205\n",
      "Epoch [30/100], Step [27300/6235], Loss: 0.0098\n",
      "Epoch [30/100], Step [27400/6235], Loss: 0.5029\n",
      "Epoch [30/100], Step [27500/6235], Loss: 0.0613\n",
      "Epoch [30/100], Step [27600/6235], Loss: 0.2100\n",
      "Epoch [30/100], Step [27700/6235], Loss: 0.8046\n",
      "Epoch [30/100], Step [27800/6235], Loss: 0.1816\n",
      "Epoch [30/100], Step [27900/6235], Loss: 3.3210\n",
      "Epoch [30/100], Step [28000/6235], Loss: 154.6930\n",
      "Epoch [30/100], Step [28100/6235], Loss: 6.0822\n",
      "Epoch [30/100], Step [28200/6235], Loss: 37.1384\n",
      "Epoch [30/100], Step [28300/6235], Loss: 1.5381\n",
      "Epoch [30/100], Step [28400/6235], Loss: 24.9197\n",
      "Epoch [30/100], Step [28500/6235], Loss: 4.1560\n",
      "Epoch [30/100], Step [28600/6235], Loss: 0.7539\n",
      "Epoch [30/100], Step [28700/6235], Loss: 3.6010\n",
      "Epoch [30/100], Step [28800/6235], Loss: 0.6702\n",
      "Epoch [30/100], Step [28900/6235], Loss: 48.3183\n",
      "Epoch [30/100], Step [29000/6235], Loss: 2.3935\n",
      "Epoch [30/100], Step [29100/6235], Loss: 0.0165\n",
      "Epoch [30/100], Step [29200/6235], Loss: 5.1766\n",
      "Epoch [30/100], Step [29300/6235], Loss: 11.7231\n",
      "Epoch [30/100], Step [29400/6235], Loss: 3.5316\n",
      "Epoch [30/100], Step [29500/6235], Loss: 7.6866\n",
      "Epoch [30/100], Step [29600/6235], Loss: 0.1499\n",
      "Epoch [30/100], Step [29700/6235], Loss: 2.8473\n",
      "Epoch [30/100], Step [29800/6235], Loss: 0.6219\n",
      "Epoch [30/100], Step [29900/6235], Loss: 1.6023\n",
      "Epoch [30/100], Step [30000/6235], Loss: 3.7251\n",
      "Epoch [30/100], Step [30100/6235], Loss: 6.9731\n",
      "Epoch [30/100], Step [30200/6235], Loss: 1.8654\n",
      "Epoch [30/100], Step [30300/6235], Loss: 0.0596\n",
      "Epoch [30/100], Step [30400/6235], Loss: 2.4679\n",
      "Epoch [30/100], Step [30500/6235], Loss: 0.2963\n",
      "Epoch [30/100], Step [30600/6235], Loss: 1.1860\n",
      "Epoch [30/100], Step [30700/6235], Loss: 2.5326\n",
      "Epoch [30/100], Step [30800/6235], Loss: 0.4981\n",
      "Epoch [30/100], Step [30900/6235], Loss: 1.5036\n",
      "Epoch [30/100], Step [31000/6235], Loss: 0.3106\n",
      "Epoch [30/100], Step [31100/6235], Loss: 0.4828\n",
      "Epoch [30/100], Step [31200/6235], Loss: 7.2037\n",
      "Epoch [30/100], Step [31300/6235], Loss: 1.6231\n",
      "Epoch [30/100], Step [31400/6235], Loss: 2.4604\n",
      "Epoch [30/100], Step [31500/6235], Loss: 0.6790\n",
      "Epoch [30/100], Step [31600/6235], Loss: 6.1456\n",
      "Epoch [30/100], Step [31700/6235], Loss: 32.8605\n",
      "Epoch [30/100], Step [31800/6235], Loss: 1.6980\n",
      "Epoch [30/100], Step [31900/6235], Loss: 430.3901\n",
      "Epoch [30/100], Step [32000/6235], Loss: 2.5713\n",
      "Epoch [30/100], Step [32100/6235], Loss: 0.5309\n",
      "Epoch [30/100], Step [32200/6235], Loss: 96.4152\n",
      "Epoch [30/100], Step [32300/6235], Loss: 0.7655\n",
      "Epoch [30/100], Step [32400/6235], Loss: 1.1296\n",
      "Epoch [30/100], Step [32500/6235], Loss: 7.8589\n",
      "Epoch [30/100], Step [32600/6235], Loss: 0.2472\n",
      "Epoch [30/100], Step [32700/6235], Loss: 114.7401\n",
      "Epoch [30/100], Step [32800/6235], Loss: 19.3440\n",
      "Epoch [30/100], Step [32900/6235], Loss: 0.4050\n",
      "Epoch [30/100], Step [33000/6235], Loss: 0.4958\n",
      "Epoch [30/100], Step [33100/6235], Loss: 0.5095\n",
      "Epoch [30/100], Step [33200/6235], Loss: 0.9045\n",
      "Epoch [30/100], Step [33300/6235], Loss: 0.9773\n",
      "Epoch [30/100], Step [33400/6235], Loss: 136.4954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [30/100], Step [33500/6235], Loss: 1.6557\n",
      "Epoch [30/100], Step [33600/6235], Loss: 3.5986\n",
      "Epoch [30/100], Step [33700/6235], Loss: 1.1512\n",
      "Epoch [30/100], Step [33800/6235], Loss: 0.5966\n",
      "Epoch [30/100], Step [33900/6235], Loss: 26.1994\n",
      "Epoch [30/100], Step [34000/6235], Loss: 0.0801\n",
      "Epoch [30/100], Step [34100/6235], Loss: 0.5036\n",
      "Epoch [30/100], Step [34200/6235], Loss: 2.1616\n",
      "Epoch [30/100], Step [34300/6235], Loss: 4.9218\n",
      "Epoch [30/100], Step [34400/6235], Loss: 0.2539\n",
      "Epoch [30/100], Step [34500/6235], Loss: 29.0414\n",
      "Epoch [30/100], Step [34600/6235], Loss: 2.2479\n",
      "Epoch [30/100], Step [34700/6235], Loss: 21.4893\n",
      "Epoch [30/100], Step [34800/6235], Loss: 11.1858\n",
      "Epoch [30/100], Step [34900/6235], Loss: 67.7845\n",
      "Epoch [30/100], Step [35000/6235], Loss: 0.2739\n",
      "Epoch [30/100], Step [35100/6235], Loss: 0.7694\n",
      "Epoch [30/100], Step [35200/6235], Loss: 0.4678\n",
      "Epoch [30/100], Step [35300/6235], Loss: 3.0803\n",
      "Epoch [30/100], Step [35400/6235], Loss: 0.5563\n",
      "Epoch [30/100], Step [35500/6235], Loss: 0.5612\n",
      "Epoch [30/100], Step [35600/6235], Loss: 3.3618\n",
      "Epoch [30/100], Step [35700/6235], Loss: 4.7808\n",
      "Epoch [30/100], Step [35800/6235], Loss: 0.2765\n",
      "Epoch [30/100], Step [35900/6235], Loss: 1.9408\n",
      "Epoch [30/100], Step [36000/6235], Loss: 0.0370\n",
      "Epoch [30/100], Step [36100/6235], Loss: 0.1182\n",
      "Epoch [30/100], Step [36200/6235], Loss: 16.6469\n",
      "Epoch [30/100], Step [36300/6235], Loss: 0.2195\n",
      "Epoch [30/100], Step [36400/6235], Loss: 2.7549\n",
      "Epoch [30/100], Step [36500/6235], Loss: 7.9387\n",
      "Epoch [30/100], Step [36600/6235], Loss: 0.0978\n",
      "Epoch [30/100], Step [36700/6235], Loss: 0.5868\n",
      "Epoch [30/100], Step [36800/6235], Loss: 6.6624\n",
      "Epoch [30/100], Step [36900/6235], Loss: 9.9056\n",
      "Epoch [30/100], Step [37000/6235], Loss: 0.8725\n",
      "Epoch [30/100], Step [37100/6235], Loss: 1.7472\n",
      "Epoch [30/100], Step [37200/6235], Loss: 0.0534\n",
      "Epoch [30/100], Step [37300/6235], Loss: 0.0327\n",
      "Epoch [30/100], Step [37400/6235], Loss: 0.1825\n",
      "Epoch [30/100], Step [37500/6235], Loss: 5.6325\n",
      "Epoch [30/100], Step [37600/6235], Loss: 12.0592\n",
      "Epoch [30/100], Step [37700/6235], Loss: 1.1120\n",
      "Epoch [30/100], Step [37800/6235], Loss: 7.2212\n",
      "Epoch [30/100], Step [37900/6235], Loss: 5.8852\n",
      "Epoch [30/100], Step [38000/6235], Loss: 0.9181\n",
      "Epoch [30/100], Step [38100/6235], Loss: 4.1966\n",
      "Epoch [30/100], Step [38200/6235], Loss: 1.7067\n",
      "Epoch [30/100], Step [38300/6235], Loss: 0.3108\n",
      "Epoch [30/100], Step [38400/6235], Loss: 0.0807\n",
      "Epoch [30/100], Step [38500/6235], Loss: 2.0770\n",
      "Epoch [30/100], Step [38600/6235], Loss: 0.2840\n",
      "Epoch [30/100], Step [38700/6235], Loss: 0.2865\n",
      "Epoch [30/100], Step [38800/6235], Loss: 0.1610\n",
      "Epoch [30/100], Step [38900/6235], Loss: 16.8106\n",
      "Epoch [30/100], Step [39000/6235], Loss: 10.5652\n",
      "Epoch [30/100], Step [39100/6235], Loss: 21.8138\n",
      "Epoch [30/100], Step [39200/6235], Loss: 0.2511\n",
      "Epoch [30/100], Step [39300/6235], Loss: 42.5652\n",
      "Epoch [30/100], Step [39400/6235], Loss: 168.2330\n",
      "Epoch [30/100], Step [39500/6235], Loss: 94.2970\n",
      "Epoch [30/100], Step [39600/6235], Loss: 6.5276\n",
      "Epoch [30/100], Step [39700/6235], Loss: 132.0335\n",
      "Epoch [30/100], Step [39800/6235], Loss: 3.2093\n",
      "Epoch [30/100], Step [39900/6235], Loss: 1.8237\n",
      "Epoch [30/100], Step [40000/6235], Loss: 0.7879\n",
      "Epoch [30/100], Step [40100/6235], Loss: 26.0130\n",
      "Epoch [30/100], Step [40200/6235], Loss: 3.1124\n",
      "Epoch [30/100], Step [40300/6235], Loss: 1.0468\n",
      "Epoch [30/100], Step [40400/6235], Loss: 2.6063\n",
      "Epoch [30/100], Step [40500/6235], Loss: 2.1679\n",
      "Epoch [30/100], Step [40600/6235], Loss: 0.3469\n",
      "Epoch [30/100], Step [40700/6235], Loss: 7.6503\n",
      "Epoch [30/100], Step [40800/6235], Loss: 1.7879\n",
      "Epoch [30/100], Step [40900/6235], Loss: 0.0655\n",
      "Epoch [30/100], Step [41000/6235], Loss: 43.2515\n",
      "Epoch [30/100], Step [41100/6235], Loss: 45.4332\n",
      "Epoch [30/100], Step [41200/6235], Loss: 4.1791\n",
      "Epoch [30/100], Step [41300/6235], Loss: 6.1344\n",
      "Epoch [30/100], Step [41400/6235], Loss: 3.5950\n",
      "Epoch [30/100], Step [41500/6235], Loss: 0.1561\n",
      "Epoch [30/100], Step [41600/6235], Loss: 0.6291\n",
      "Epoch [30/100], Step [41700/6235], Loss: 2.1103\n",
      "Epoch [30/100], Step [41800/6235], Loss: 6.6642\n",
      "Epoch [30/100], Step [41900/6235], Loss: 0.3037\n",
      "Epoch [30/100], Step [42000/6235], Loss: 19.8966\n",
      "Epoch [30/100], Step [42100/6235], Loss: 0.2765\n",
      "Epoch [30/100], Step [42200/6235], Loss: 124.3686\n",
      "Epoch [30/100], Step [42300/6235], Loss: 3.2840\n",
      "Epoch [30/100], Step [42400/6235], Loss: 2.0358\n",
      "Epoch [30/100], Step [42500/6235], Loss: 1.0698\n",
      "Epoch [30/100], Step [42600/6235], Loss: 0.4574\n",
      "Epoch [30/100], Step [42700/6235], Loss: 0.9814\n",
      "Epoch [30/100], Step [42800/6235], Loss: 3.8597\n",
      "Epoch [30/100], Step [42900/6235], Loss: 2.4560\n",
      "Epoch [30/100], Step [43000/6235], Loss: 2.1210\n",
      "Epoch [30/100], Step [43100/6235], Loss: 3.5564\n",
      "Epoch [30/100], Step [43200/6235], Loss: 0.4463\n",
      "Epoch [30/100], Step [43300/6235], Loss: 13.8221\n",
      "Epoch [30/100], Step [43400/6235], Loss: 0.2767\n",
      "Epoch [30/100], Step [43500/6235], Loss: 0.9879\n",
      "Epoch [30/100], Step [43600/6235], Loss: 35.3026\n",
      "Epoch [30/100], Step [43700/6235], Loss: 0.3696\n",
      "Epoch [30/100], Step [43800/6235], Loss: 8.4693\n",
      "Epoch [30/100], Step [43900/6235], Loss: 0.3548\n",
      "Epoch [30/100], Step [44000/6235], Loss: 44.7653\n",
      "Epoch [30/100], Step [44100/6235], Loss: 1.3313\n",
      "Epoch [30/100], Step [44200/6235], Loss: 16.6978\n",
      "Epoch [30/100], Step [44300/6235], Loss: 32.1042\n",
      "Epoch [30/100], Step [44400/6235], Loss: 0.5701\n",
      "Epoch [30/100], Step [44500/6235], Loss: 7.7339\n",
      "Epoch [30/100], Step [44600/6235], Loss: 11.3364\n",
      "Epoch [30/100], Step [44700/6235], Loss: 0.9247\n",
      "Epoch [30/100], Step [44800/6235], Loss: 7.4780\n",
      "Epoch [30/100], Step [44900/6235], Loss: 1.7683\n",
      "Epoch [30/100], Step [45000/6235], Loss: 0.2859\n",
      "Epoch [30/100], Step [45100/6235], Loss: 8.3046\n",
      "Epoch [30/100], Step [45200/6235], Loss: 23.8670\n",
      "Epoch [30/100], Step [45300/6235], Loss: 2.9370\n",
      "Epoch [30/100], Step [45400/6235], Loss: 0.6420\n",
      "Epoch [30/100], Step [45500/6235], Loss: 0.2484\n",
      "Epoch [30/100], Step [45600/6235], Loss: 2.5868\n",
      "Epoch [30/100], Step [45700/6235], Loss: 5.0589\n",
      "Epoch [30/100], Step [45800/6235], Loss: 646.2478\n",
      "Epoch [30/100], Step [45900/6235], Loss: 1.5623\n",
      "Epoch [30/100], Step [46000/6235], Loss: 129.3383\n",
      "Epoch [30/100], Step [46100/6235], Loss: 71.7157\n",
      "Epoch [30/100], Step [46200/6235], Loss: 15.8054\n",
      "Epoch [30/100], Step [46300/6235], Loss: 207.7174\n",
      "Epoch [30/100], Step [46400/6235], Loss: 1.7288\n",
      "Epoch [30/100], Step [46500/6235], Loss: 177.0571\n",
      "Epoch [30/100], Step [46600/6235], Loss: 23.7097\n",
      "Epoch [30/100], Step [46700/6235], Loss: 3.5141\n",
      "Epoch [30/100], Step [46800/6235], Loss: 33.1958\n",
      "Epoch [30/100], Step [46900/6235], Loss: 22.2225\n",
      "Epoch [30/100], Step [47000/6235], Loss: 2.6387\n",
      "Epoch [30/100], Step [47100/6235], Loss: 93.2177\n",
      "Epoch [30/100], Step [47200/6235], Loss: 101.4255\n",
      "Epoch [30/100], Step [47300/6235], Loss: 2.1609\n",
      "Epoch [30/100], Step [47400/6235], Loss: 396.7196\n",
      "Epoch [30/100], Step [47500/6235], Loss: 21.3144\n",
      "Epoch [30/100], Step [47600/6235], Loss: 3.8350\n",
      "Epoch [30/100], Step [47700/6235], Loss: 22.6074\n",
      "Epoch [30/100], Step [47800/6235], Loss: 60.1733\n",
      "Epoch [30/100], Step [47900/6235], Loss: 14.0240\n",
      "Epoch [30/100], Step [48000/6235], Loss: 27.4373\n",
      "Epoch [30/100], Step [48100/6235], Loss: 9.4495\n",
      "Epoch [30/100], Step [48200/6235], Loss: 38.4962\n",
      "Epoch [30/100], Step [48300/6235], Loss: 778.2685\n",
      "Epoch [30/100], Step [48400/6235], Loss: 2.8896\n",
      "Epoch [30/100], Step [48500/6235], Loss: 19.9639\n",
      "Epoch [30/100], Step [48600/6235], Loss: 25.4471\n",
      "Epoch [30/100], Step [48700/6235], Loss: 20.2282\n",
      "Epoch [30/100], Step [48800/6235], Loss: 892.1146\n",
      "Epoch [30/100], Step [48900/6235], Loss: 285.0436\n",
      "Epoch [30/100], Step [49000/6235], Loss: 171.8084\n",
      "Epoch [30/100], Step [49100/6235], Loss: 2885.3743\n",
      "Epoch [30/100], Step [49200/6235], Loss: 719.6860\n",
      "Epoch [30/100], Step [49300/6235], Loss: 760.9543\n",
      "Epoch [30/100], Step [49400/6235], Loss: 109.7807\n",
      "Epoch [30/100], Step [49500/6235], Loss: 5.5284\n",
      "Epoch [30/100], Step [49600/6235], Loss: 192.5513\n",
      "Epoch [30/100], Step [49700/6235], Loss: 290.0000\n",
      "Epoch [30/100], Step [49800/6235], Loss: 1532.7415\n",
      "Epoch [31/100], Step [100/6235], Loss: 14.1735\n",
      "Epoch [31/100], Step [200/6235], Loss: 0.1687\n",
      "Epoch [31/100], Step [300/6235], Loss: 0.0155\n",
      "Epoch [31/100], Step [400/6235], Loss: 0.0012\n",
      "Epoch [31/100], Step [500/6235], Loss: 0.3856\n",
      "Epoch [31/100], Step [600/6235], Loss: 0.0348\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Step [700/6235], Loss: 0.4526\n",
      "Epoch [31/100], Step [800/6235], Loss: 0.0045\n",
      "Epoch [31/100], Step [900/6235], Loss: 0.0486\n",
      "Epoch [31/100], Step [1000/6235], Loss: 0.0137\n",
      "Epoch [31/100], Step [1100/6235], Loss: 0.0559\n",
      "Epoch [31/100], Step [1200/6235], Loss: 0.1348\n",
      "Epoch [31/100], Step [1300/6235], Loss: 0.0145\n",
      "Epoch [31/100], Step [1400/6235], Loss: 0.1454\n",
      "Epoch [31/100], Step [1500/6235], Loss: 0.0052\n",
      "Epoch [31/100], Step [1600/6235], Loss: 0.2454\n",
      "Epoch [31/100], Step [1700/6235], Loss: 0.2902\n",
      "Epoch [31/100], Step [1800/6235], Loss: 0.3822\n",
      "Epoch [31/100], Step [1900/6235], Loss: 0.2195\n",
      "Epoch [31/100], Step [2000/6235], Loss: 1.9819\n",
      "Epoch [31/100], Step [2100/6235], Loss: 3.0502\n",
      "Epoch [31/100], Step [2200/6235], Loss: 2.8305\n",
      "Epoch [31/100], Step [2300/6235], Loss: 2.1989\n",
      "Epoch [31/100], Step [2400/6235], Loss: 8.8939\n",
      "Epoch [31/100], Step [2500/6235], Loss: 13.0200\n",
      "Epoch [31/100], Step [2600/6235], Loss: 15.4240\n",
      "Epoch [31/100], Step [2700/6235], Loss: 22.8282\n",
      "Epoch [31/100], Step [2800/6235], Loss: 104.0828\n",
      "Epoch [31/100], Step [2900/6235], Loss: 6.9350\n",
      "Epoch [31/100], Step [3000/6235], Loss: 4.6305\n",
      "Epoch [31/100], Step [3100/6235], Loss: 103.1087\n",
      "Epoch [31/100], Step [3200/6235], Loss: 3.9910\n",
      "Epoch [31/100], Step [3300/6235], Loss: 1.3060\n",
      "Epoch [31/100], Step [3400/6235], Loss: 7.0840\n",
      "Epoch [31/100], Step [3500/6235], Loss: 75.9982\n",
      "Epoch [31/100], Step [3600/6235], Loss: 3.9752\n",
      "Epoch [31/100], Step [3700/6235], Loss: 0.2762\n",
      "Epoch [31/100], Step [3800/6235], Loss: 0.3237\n",
      "Epoch [31/100], Step [3900/6235], Loss: 0.5275\n",
      "Epoch [31/100], Step [4000/6235], Loss: 0.6818\n",
      "Epoch [31/100], Step [4100/6235], Loss: 5.6181\n",
      "Epoch [31/100], Step [4200/6235], Loss: 0.5170\n",
      "Epoch [31/100], Step [4300/6235], Loss: 2.6005\n",
      "Epoch [31/100], Step [4400/6235], Loss: 0.0675\n",
      "Epoch [31/100], Step [4500/6235], Loss: 67.1581\n",
      "Epoch [31/100], Step [4600/6235], Loss: 20.0397\n",
      "Epoch [31/100], Step [4700/6235], Loss: 2.1128\n",
      "Epoch [31/100], Step [4800/6235], Loss: 1.8036\n",
      "Epoch [31/100], Step [4900/6235], Loss: 1.2445\n",
      "Epoch [31/100], Step [5000/6235], Loss: 0.3435\n",
      "Epoch [31/100], Step [5100/6235], Loss: 9.1208\n",
      "Epoch [31/100], Step [5200/6235], Loss: 1.3392\n",
      "Epoch [31/100], Step [5300/6235], Loss: 14.3960\n",
      "Epoch [31/100], Step [5400/6235], Loss: 2.5185\n",
      "Epoch [31/100], Step [5500/6235], Loss: 0.7200\n",
      "Epoch [31/100], Step [5600/6235], Loss: 0.7265\n",
      "Epoch [31/100], Step [5700/6235], Loss: 0.5761\n",
      "Epoch [31/100], Step [5800/6235], Loss: 0.8879\n",
      "Epoch [31/100], Step [5900/6235], Loss: 0.0174\n",
      "Epoch [31/100], Step [6000/6235], Loss: 0.8713\n",
      "Epoch [31/100], Step [6100/6235], Loss: 0.0303\n",
      "Epoch [31/100], Step [6200/6235], Loss: 5.1459\n",
      "Epoch [31/100], Step [6300/6235], Loss: 0.4516\n",
      "Epoch [31/100], Step [6400/6235], Loss: 0.0924\n",
      "Epoch [31/100], Step [6500/6235], Loss: 1.1156\n",
      "Epoch [31/100], Step [6600/6235], Loss: 16.3095\n",
      "Epoch [31/100], Step [6700/6235], Loss: 3.1496\n",
      "Epoch [31/100], Step [6800/6235], Loss: 0.3352\n",
      "Epoch [31/100], Step [6900/6235], Loss: 0.9237\n",
      "Epoch [31/100], Step [7000/6235], Loss: 0.0227\n",
      "Epoch [31/100], Step [7100/6235], Loss: 0.2934\n",
      "Epoch [31/100], Step [7200/6235], Loss: 0.3425\n",
      "Epoch [31/100], Step [7300/6235], Loss: 1.9607\n",
      "Epoch [31/100], Step [7400/6235], Loss: 0.2998\n",
      "Epoch [31/100], Step [7500/6235], Loss: 0.4513\n",
      "Epoch [31/100], Step [7600/6235], Loss: 0.9490\n",
      "Epoch [31/100], Step [7700/6235], Loss: 6.6879\n",
      "Epoch [31/100], Step [7800/6235], Loss: 6.9856\n",
      "Epoch [31/100], Step [7900/6235], Loss: 7.3155\n",
      "Epoch [31/100], Step [8000/6235], Loss: 0.4257\n",
      "Epoch [31/100], Step [8100/6235], Loss: 0.3365\n",
      "Epoch [31/100], Step [8200/6235], Loss: 10.7484\n",
      "Epoch [31/100], Step [8300/6235], Loss: 2.7495\n",
      "Epoch [31/100], Step [8400/6235], Loss: 427.4913\n",
      "Epoch [31/100], Step [8500/6235], Loss: 1.9137\n",
      "Epoch [31/100], Step [8600/6235], Loss: 124.5075\n",
      "Epoch [31/100], Step [8700/6235], Loss: 107.0442\n",
      "Epoch [31/100], Step [8800/6235], Loss: 746.4101\n",
      "Epoch [31/100], Step [8900/6235], Loss: 188.5791\n",
      "Epoch [31/100], Step [9000/6235], Loss: 398.2214\n",
      "Epoch [31/100], Step [9100/6235], Loss: 51.8992\n",
      "Epoch [31/100], Step [9200/6235], Loss: 2677.1436\n",
      "Epoch [31/100], Step [9300/6235], Loss: 90.2297\n",
      "Epoch [31/100], Step [9400/6235], Loss: 281.3977\n",
      "Epoch [31/100], Step [9500/6235], Loss: 1153.1749\n",
      "Epoch [31/100], Step [9600/6235], Loss: 499.1005\n",
      "Epoch [31/100], Step [9700/6235], Loss: 7.0076\n",
      "Epoch [31/100], Step [9800/6235], Loss: 1755.1102\n",
      "Epoch [31/100], Step [9900/6235], Loss: 1257.7678\n",
      "Epoch [31/100], Step [10000/6235], Loss: 470.0160\n",
      "Epoch [31/100], Step [10100/6235], Loss: 4.1116\n",
      "Epoch [31/100], Step [10200/6235], Loss: 939.7912\n",
      "Epoch [31/100], Step [10300/6235], Loss: 1.4123\n",
      "Epoch [31/100], Step [10400/6235], Loss: 15.0651\n",
      "Epoch [31/100], Step [10500/6235], Loss: 4.4934\n",
      "Epoch [31/100], Step [10600/6235], Loss: 26.9456\n",
      "Epoch [31/100], Step [10700/6235], Loss: 350.5549\n",
      "Epoch [31/100], Step [10800/6235], Loss: 54.9118\n",
      "Epoch [31/100], Step [10900/6235], Loss: 7.0687\n",
      "Epoch [31/100], Step [11000/6235], Loss: 104.6914\n",
      "Epoch [31/100], Step [11100/6235], Loss: 1.6175\n",
      "Epoch [31/100], Step [11200/6235], Loss: 120.6120\n",
      "Epoch [31/100], Step [11300/6235], Loss: 249.4881\n",
      "Epoch [31/100], Step [11400/6235], Loss: 65.4497\n",
      "Epoch [31/100], Step [11500/6235], Loss: 6.5041\n",
      "Epoch [31/100], Step [11600/6235], Loss: 5.3573\n",
      "Epoch [31/100], Step [11700/6235], Loss: 88.0838\n",
      "Epoch [31/100], Step [11800/6235], Loss: 360.8112\n",
      "Epoch [31/100], Step [11900/6235], Loss: 23.5799\n",
      "Epoch [31/100], Step [12000/6235], Loss: 677.8868\n",
      "Epoch [31/100], Step [12100/6235], Loss: 237.3004\n",
      "Epoch [31/100], Step [12200/6235], Loss: 145.3150\n",
      "Epoch [31/100], Step [12300/6235], Loss: 43.8827\n",
      "Epoch [31/100], Step [12400/6235], Loss: 423.4789\n",
      "Epoch [31/100], Step [12500/6235], Loss: 4.3537\n",
      "Epoch [31/100], Step [12600/6235], Loss: 143.8545\n",
      "Epoch [31/100], Step [12700/6235], Loss: 3.4221\n",
      "Epoch [31/100], Step [12800/6235], Loss: 3.4528\n",
      "Epoch [31/100], Step [12900/6235], Loss: 49.6991\n",
      "Epoch [31/100], Step [13000/6235], Loss: 1.4502\n",
      "Epoch [31/100], Step [13100/6235], Loss: 76.4953\n",
      "Epoch [31/100], Step [13200/6235], Loss: 28.0879\n",
      "Epoch [31/100], Step [13300/6235], Loss: 45.5521\n",
      "Epoch [31/100], Step [13400/6235], Loss: 245.7310\n",
      "Epoch [31/100], Step [13500/6235], Loss: 41.5209\n",
      "Epoch [31/100], Step [13600/6235], Loss: 43.2482\n",
      "Epoch [31/100], Step [13700/6235], Loss: 19.1147\n",
      "Epoch [31/100], Step [13800/6235], Loss: 159.1125\n",
      "Epoch [31/100], Step [13900/6235], Loss: 51.4684\n",
      "Epoch [31/100], Step [14000/6235], Loss: 10.8617\n",
      "Epoch [31/100], Step [14100/6235], Loss: 9.3577\n",
      "Epoch [31/100], Step [14200/6235], Loss: 121.4068\n",
      "Epoch [31/100], Step [14300/6235], Loss: 90.6926\n",
      "Epoch [31/100], Step [14400/6235], Loss: 37.7348\n",
      "Epoch [31/100], Step [14500/6235], Loss: 92.7819\n",
      "Epoch [31/100], Step [14600/6235], Loss: 0.9509\n",
      "Epoch [31/100], Step [14700/6235], Loss: 43.3600\n",
      "Epoch [31/100], Step [14800/6235], Loss: 29.9825\n",
      "Epoch [31/100], Step [14900/6235], Loss: 3.6128\n",
      "Epoch [31/100], Step [15000/6235], Loss: 4.5496\n",
      "Epoch [31/100], Step [15100/6235], Loss: 0.0667\n",
      "Epoch [31/100], Step [15200/6235], Loss: 40.5808\n",
      "Epoch [31/100], Step [15300/6235], Loss: 35.5025\n",
      "Epoch [31/100], Step [15400/6235], Loss: 40.0835\n",
      "Epoch [31/100], Step [15500/6235], Loss: 8.2700\n",
      "Epoch [31/100], Step [15600/6235], Loss: 82.5210\n",
      "Epoch [31/100], Step [15700/6235], Loss: 63.4825\n",
      "Epoch [31/100], Step [15800/6235], Loss: 1.9395\n",
      "Epoch [31/100], Step [15900/6235], Loss: 1.4491\n",
      "Epoch [31/100], Step [16000/6235], Loss: 0.3724\n",
      "Epoch [31/100], Step [16100/6235], Loss: 17.6256\n",
      "Epoch [31/100], Step [16200/6235], Loss: 0.4786\n",
      "Epoch [31/100], Step [16300/6235], Loss: 12.1947\n",
      "Epoch [31/100], Step [16400/6235], Loss: 32.7727\n",
      "Epoch [31/100], Step [16500/6235], Loss: 405.2954\n",
      "Epoch [31/100], Step [16600/6235], Loss: 27.1864\n",
      "Epoch [31/100], Step [16700/6235], Loss: 0.3671\n",
      "Epoch [31/100], Step [16800/6235], Loss: 9.6847\n",
      "Epoch [31/100], Step [16900/6235], Loss: 0.6116\n",
      "Epoch [31/100], Step [17000/6235], Loss: 0.1942\n",
      "Epoch [31/100], Step [17100/6235], Loss: 0.0889\n",
      "Epoch [31/100], Step [17200/6235], Loss: 298.4296\n",
      "Epoch [31/100], Step [17300/6235], Loss: 39.8874\n",
      "Epoch [31/100], Step [17400/6235], Loss: 31.6417\n",
      "Epoch [31/100], Step [17500/6235], Loss: 1.0554\n",
      "Epoch [31/100], Step [17600/6235], Loss: 5.0639\n",
      "Epoch [31/100], Step [17700/6235], Loss: 7.8708\n",
      "Epoch [31/100], Step [17800/6235], Loss: 11.6184\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Step [17900/6235], Loss: 3.8443\n",
      "Epoch [31/100], Step [18000/6235], Loss: 9.5168\n",
      "Epoch [31/100], Step [18100/6235], Loss: 19.3234\n",
      "Epoch [31/100], Step [18200/6235], Loss: 1.3145\n",
      "Epoch [31/100], Step [18300/6235], Loss: 1.8578\n",
      "Epoch [31/100], Step [18400/6235], Loss: 6.3190\n",
      "Epoch [31/100], Step [18500/6235], Loss: 38.7390\n",
      "Epoch [31/100], Step [18600/6235], Loss: 7.3724\n",
      "Epoch [31/100], Step [18700/6235], Loss: 3.0778\n",
      "Epoch [31/100], Step [18800/6235], Loss: 206.6938\n",
      "Epoch [31/100], Step [18900/6235], Loss: 72.2124\n",
      "Epoch [31/100], Step [19000/6235], Loss: 5.3032\n",
      "Epoch [31/100], Step [19100/6235], Loss: 26.2223\n",
      "Epoch [31/100], Step [19200/6235], Loss: 2.5961\n",
      "Epoch [31/100], Step [19300/6235], Loss: 7.1068\n",
      "Epoch [31/100], Step [19400/6235], Loss: 45.0914\n",
      "Epoch [31/100], Step [19500/6235], Loss: 12.2881\n",
      "Epoch [31/100], Step [19600/6235], Loss: 24.1063\n",
      "Epoch [31/100], Step [19700/6235], Loss: 0.8053\n",
      "Epoch [31/100], Step [19800/6235], Loss: 2.0580\n",
      "Epoch [31/100], Step [19900/6235], Loss: 0.9158\n",
      "Epoch [31/100], Step [20000/6235], Loss: 69.6745\n",
      "Epoch [31/100], Step [20100/6235], Loss: 4.9124\n",
      "Epoch [31/100], Step [20200/6235], Loss: 2.2553\n",
      "Epoch [31/100], Step [20300/6235], Loss: 0.3463\n",
      "Epoch [31/100], Step [20400/6235], Loss: 1.4462\n",
      "Epoch [31/100], Step [20500/6235], Loss: 65.1461\n",
      "Epoch [31/100], Step [20600/6235], Loss: 27.9729\n",
      "Epoch [31/100], Step [20700/6235], Loss: 23.6965\n",
      "Epoch [31/100], Step [20800/6235], Loss: 5.6392\n",
      "Epoch [31/100], Step [20900/6235], Loss: 1.2943\n",
      "Epoch [31/100], Step [21000/6235], Loss: 9.3507\n",
      "Epoch [31/100], Step [21100/6235], Loss: 2.7290\n",
      "Epoch [31/100], Step [21200/6235], Loss: 0.4265\n",
      "Epoch [31/100], Step [21300/6235], Loss: 0.7040\n",
      "Epoch [31/100], Step [21400/6235], Loss: 0.1689\n",
      "Epoch [31/100], Step [21500/6235], Loss: 0.2786\n",
      "Epoch [31/100], Step [21600/6235], Loss: 27.3944\n",
      "Epoch [31/100], Step [21700/6235], Loss: 0.2986\n",
      "Epoch [31/100], Step [21800/6235], Loss: 0.1809\n",
      "Epoch [31/100], Step [21900/6235], Loss: 1.1202\n",
      "Epoch [31/100], Step [22000/6235], Loss: 11.4097\n",
      "Epoch [31/100], Step [22100/6235], Loss: 3.5115\n",
      "Epoch [31/100], Step [22200/6235], Loss: 0.2195\n",
      "Epoch [31/100], Step [22300/6235], Loss: 5.0374\n",
      "Epoch [31/100], Step [22400/6235], Loss: 5.9212\n",
      "Epoch [31/100], Step [22500/6235], Loss: 31.3907\n",
      "Epoch [31/100], Step [22600/6235], Loss: 29.7407\n",
      "Epoch [31/100], Step [22700/6235], Loss: 1.1595\n",
      "Epoch [31/100], Step [22800/6235], Loss: 24.9180\n",
      "Epoch [31/100], Step [22900/6235], Loss: 25.4200\n",
      "Epoch [31/100], Step [23000/6235], Loss: 7.4437\n",
      "Epoch [31/100], Step [23100/6235], Loss: 6.0331\n",
      "Epoch [31/100], Step [23200/6235], Loss: 0.1062\n",
      "Epoch [31/100], Step [23300/6235], Loss: 15.3167\n",
      "Epoch [31/100], Step [23400/6235], Loss: 2.2652\n",
      "Epoch [31/100], Step [23500/6235], Loss: 0.2501\n",
      "Epoch [31/100], Step [23600/6235], Loss: 90.2268\n",
      "Epoch [31/100], Step [23700/6235], Loss: 2.8699\n",
      "Epoch [31/100], Step [23800/6235], Loss: 1.4419\n",
      "Epoch [31/100], Step [23900/6235], Loss: 4.8821\n",
      "Epoch [31/100], Step [24000/6235], Loss: 13.7568\n",
      "Epoch [31/100], Step [24100/6235], Loss: 10.3563\n",
      "Epoch [31/100], Step [24200/6235], Loss: 12.6940\n",
      "Epoch [31/100], Step [24300/6235], Loss: 0.1210\n",
      "Epoch [31/100], Step [24400/6235], Loss: 2.1687\n",
      "Epoch [31/100], Step [24500/6235], Loss: 18.8219\n",
      "Epoch [31/100], Step [24600/6235], Loss: 3.6553\n",
      "Epoch [31/100], Step [24700/6235], Loss: 0.9211\n",
      "Epoch [31/100], Step [24800/6235], Loss: 2.9690\n",
      "Epoch [31/100], Step [24900/6235], Loss: 8.4458\n",
      "Epoch [31/100], Step [25000/6235], Loss: 0.6175\n",
      "Epoch [31/100], Step [25100/6235], Loss: 16.1814\n",
      "Epoch [31/100], Step [25200/6235], Loss: 2.6734\n",
      "Epoch [31/100], Step [25300/6235], Loss: 6.8324\n",
      "Epoch [31/100], Step [25400/6235], Loss: 0.4702\n",
      "Epoch [31/100], Step [25500/6235], Loss: 4.2273\n",
      "Epoch [31/100], Step [25600/6235], Loss: 7.0604\n",
      "Epoch [31/100], Step [25700/6235], Loss: 3.7537\n",
      "Epoch [31/100], Step [25800/6235], Loss: 7.1071\n",
      "Epoch [31/100], Step [25900/6235], Loss: 1.9808\n",
      "Epoch [31/100], Step [26000/6235], Loss: 0.2368\n",
      "Epoch [31/100], Step [26100/6235], Loss: 1.0103\n",
      "Epoch [31/100], Step [26200/6235], Loss: 0.0649\n",
      "Epoch [31/100], Step [26300/6235], Loss: 2.3704\n",
      "Epoch [31/100], Step [26400/6235], Loss: 5.6559\n",
      "Epoch [31/100], Step [26500/6235], Loss: 0.5003\n",
      "Epoch [31/100], Step [26600/6235], Loss: 2.3919\n",
      "Epoch [31/100], Step [26700/6235], Loss: 0.1407\n",
      "Epoch [31/100], Step [26800/6235], Loss: 0.6702\n",
      "Epoch [31/100], Step [26900/6235], Loss: 0.0007\n",
      "Epoch [31/100], Step [27000/6235], Loss: 9.5837\n",
      "Epoch [31/100], Step [27100/6235], Loss: 0.0585\n",
      "Epoch [31/100], Step [27200/6235], Loss: 0.5041\n",
      "Epoch [31/100], Step [27300/6235], Loss: 0.1016\n",
      "Epoch [31/100], Step [27400/6235], Loss: 0.1462\n",
      "Epoch [31/100], Step [27500/6235], Loss: 1.5591\n",
      "Epoch [31/100], Step [27600/6235], Loss: 0.1095\n",
      "Epoch [31/100], Step [27700/6235], Loss: 0.9346\n",
      "Epoch [31/100], Step [27800/6235], Loss: 4.7822\n",
      "Epoch [31/100], Step [27900/6235], Loss: 0.0930\n",
      "Epoch [31/100], Step [28000/6235], Loss: 208.5930\n",
      "Epoch [31/100], Step [28100/6235], Loss: 0.8333\n",
      "Epoch [31/100], Step [28200/6235], Loss: 37.1076\n",
      "Epoch [31/100], Step [28300/6235], Loss: 0.2848\n",
      "Epoch [31/100], Step [28400/6235], Loss: 12.6963\n",
      "Epoch [31/100], Step [28500/6235], Loss: 0.6693\n",
      "Epoch [31/100], Step [28600/6235], Loss: 1.6646\n",
      "Epoch [31/100], Step [28700/6235], Loss: 0.5224\n",
      "Epoch [31/100], Step [28800/6235], Loss: 1.0887\n",
      "Epoch [31/100], Step [28900/6235], Loss: 18.2105\n",
      "Epoch [31/100], Step [29000/6235], Loss: 0.2340\n",
      "Epoch [31/100], Step [29100/6235], Loss: 0.5592\n",
      "Epoch [31/100], Step [29200/6235], Loss: 5.5802\n",
      "Epoch [31/100], Step [29300/6235], Loss: 1.2063\n",
      "Epoch [31/100], Step [29400/6235], Loss: 0.5342\n",
      "Epoch [31/100], Step [29500/6235], Loss: 10.6215\n",
      "Epoch [31/100], Step [29600/6235], Loss: 0.4747\n",
      "Epoch [31/100], Step [29700/6235], Loss: 2.6955\n",
      "Epoch [31/100], Step [29800/6235], Loss: 0.2115\n",
      "Epoch [31/100], Step [29900/6235], Loss: 7.6089\n",
      "Epoch [31/100], Step [30000/6235], Loss: 5.6845\n",
      "Epoch [31/100], Step [30100/6235], Loss: 11.3648\n",
      "Epoch [31/100], Step [30200/6235], Loss: 0.3019\n",
      "Epoch [31/100], Step [30300/6235], Loss: 0.8847\n",
      "Epoch [31/100], Step [30400/6235], Loss: 6.5580\n",
      "Epoch [31/100], Step [30500/6235], Loss: 0.6608\n",
      "Epoch [31/100], Step [30600/6235], Loss: 0.2447\n",
      "Epoch [31/100], Step [30700/6235], Loss: 2.8501\n",
      "Epoch [31/100], Step [30800/6235], Loss: 0.3606\n",
      "Epoch [31/100], Step [30900/6235], Loss: 0.0530\n",
      "Epoch [31/100], Step [31000/6235], Loss: 0.0622\n",
      "Epoch [31/100], Step [31100/6235], Loss: 2.8908\n",
      "Epoch [31/100], Step [31200/6235], Loss: 2.3118\n",
      "Epoch [31/100], Step [31300/6235], Loss: 3.6091\n",
      "Epoch [31/100], Step [31400/6235], Loss: 7.8997\n",
      "Epoch [31/100], Step [31500/6235], Loss: 0.0525\n",
      "Epoch [31/100], Step [31600/6235], Loss: 6.7001\n",
      "Epoch [31/100], Step [31700/6235], Loss: 45.1477\n",
      "Epoch [31/100], Step [31800/6235], Loss: 1.0425\n",
      "Epoch [31/100], Step [31900/6235], Loss: 322.6686\n",
      "Epoch [31/100], Step [32000/6235], Loss: 39.4427\n",
      "Epoch [31/100], Step [32100/6235], Loss: 0.2021\n",
      "Epoch [31/100], Step [32200/6235], Loss: 34.5783\n",
      "Epoch [31/100], Step [32300/6235], Loss: 0.4934\n",
      "Epoch [31/100], Step [32400/6235], Loss: 0.5255\n",
      "Epoch [31/100], Step [32500/6235], Loss: 2.4540\n",
      "Epoch [31/100], Step [32600/6235], Loss: 0.0220\n",
      "Epoch [31/100], Step [32700/6235], Loss: 178.7317\n",
      "Epoch [31/100], Step [32800/6235], Loss: 25.8609\n",
      "Epoch [31/100], Step [32900/6235], Loss: 8.6042\n",
      "Epoch [31/100], Step [33000/6235], Loss: 1.4460\n",
      "Epoch [31/100], Step [33100/6235], Loss: 0.4788\n",
      "Epoch [31/100], Step [33200/6235], Loss: 1.4440\n",
      "Epoch [31/100], Step [33300/6235], Loss: 6.7003\n",
      "Epoch [31/100], Step [33400/6235], Loss: 24.9549\n",
      "Epoch [31/100], Step [33500/6235], Loss: 2.2846\n",
      "Epoch [31/100], Step [33600/6235], Loss: 7.1868\n",
      "Epoch [31/100], Step [33700/6235], Loss: 2.7447\n",
      "Epoch [31/100], Step [33800/6235], Loss: 1.0817\n",
      "Epoch [31/100], Step [33900/6235], Loss: 28.4117\n",
      "Epoch [31/100], Step [34000/6235], Loss: 0.1246\n",
      "Epoch [31/100], Step [34100/6235], Loss: 0.6835\n",
      "Epoch [31/100], Step [34200/6235], Loss: 1.8408\n",
      "Epoch [31/100], Step [34300/6235], Loss: 3.4669\n",
      "Epoch [31/100], Step [34400/6235], Loss: 0.0962\n",
      "Epoch [31/100], Step [34500/6235], Loss: 27.3931\n",
      "Epoch [31/100], Step [34600/6235], Loss: 2.3683\n",
      "Epoch [31/100], Step [34700/6235], Loss: 4.6952\n",
      "Epoch [31/100], Step [34800/6235], Loss: 14.5875\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [31/100], Step [34900/6235], Loss: 70.0472\n",
      "Epoch [31/100], Step [35000/6235], Loss: 0.3398\n",
      "Epoch [31/100], Step [35100/6235], Loss: 1.2385\n",
      "Epoch [31/100], Step [35200/6235], Loss: 0.5022\n",
      "Epoch [31/100], Step [35300/6235], Loss: 2.5730\n",
      "Epoch [31/100], Step [35400/6235], Loss: 0.4963\n",
      "Epoch [31/100], Step [35500/6235], Loss: 0.2434\n",
      "Epoch [31/100], Step [35600/6235], Loss: 2.7066\n",
      "Epoch [31/100], Step [35700/6235], Loss: 4.1090\n",
      "Epoch [31/100], Step [35800/6235], Loss: 0.6111\n",
      "Epoch [31/100], Step [35900/6235], Loss: 1.2181\n",
      "Epoch [31/100], Step [36000/6235], Loss: 0.2721\n",
      "Epoch [31/100], Step [36100/6235], Loss: 0.1553\n",
      "Epoch [31/100], Step [36200/6235], Loss: 43.9976\n",
      "Epoch [31/100], Step [36300/6235], Loss: 0.2083\n",
      "Epoch [31/100], Step [36400/6235], Loss: 2.6270\n",
      "Epoch [31/100], Step [36500/6235], Loss: 6.2590\n",
      "Epoch [31/100], Step [36600/6235], Loss: 0.0424\n",
      "Epoch [31/100], Step [36700/6235], Loss: 0.4587\n",
      "Epoch [31/100], Step [36800/6235], Loss: 1.2326\n",
      "Epoch [31/100], Step [36900/6235], Loss: 12.0052\n",
      "Epoch [31/100], Step [37000/6235], Loss: 0.9855\n",
      "Epoch [31/100], Step [37100/6235], Loss: 2.6229\n",
      "Epoch [31/100], Step [37200/6235], Loss: 0.0256\n",
      "Epoch [31/100], Step [37300/6235], Loss: 0.2140\n",
      "Epoch [31/100], Step [37400/6235], Loss: 0.1690\n",
      "Epoch [31/100], Step [37500/6235], Loss: 8.5839\n",
      "Epoch [31/100], Step [37600/6235], Loss: 11.9729\n",
      "Epoch [31/100], Step [37700/6235], Loss: 2.6139\n",
      "Epoch [31/100], Step [37800/6235], Loss: 1.6129\n",
      "Epoch [31/100], Step [37900/6235], Loss: 4.5104\n",
      "Epoch [31/100], Step [38000/6235], Loss: 1.1386\n",
      "Epoch [31/100], Step [38100/6235], Loss: 3.7065\n",
      "Epoch [31/100], Step [38200/6235], Loss: 2.9172\n",
      "Epoch [31/100], Step [38300/6235], Loss: 0.2365\n",
      "Epoch [31/100], Step [38400/6235], Loss: 0.0914\n",
      "Epoch [31/100], Step [38500/6235], Loss: 1.3168\n",
      "Epoch [31/100], Step [38600/6235], Loss: 0.4454\n",
      "Epoch [31/100], Step [38700/6235], Loss: 0.4376\n",
      "Epoch [31/100], Step [38800/6235], Loss: 0.1639\n",
      "Epoch [31/100], Step [38900/6235], Loss: 7.5933\n",
      "Epoch [31/100], Step [39000/6235], Loss: 0.4343\n",
      "Epoch [31/100], Step [39100/6235], Loss: 10.6906\n",
      "Epoch [31/100], Step [39200/6235], Loss: 0.4823\n",
      "Epoch [31/100], Step [39300/6235], Loss: 41.7292\n",
      "Epoch [31/100], Step [39400/6235], Loss: 300.8819\n",
      "Epoch [31/100], Step [39500/6235], Loss: 197.4876\n",
      "Epoch [31/100], Step [39600/6235], Loss: 12.6173\n",
      "Epoch [31/100], Step [39700/6235], Loss: 226.7818\n",
      "Epoch [31/100], Step [39800/6235], Loss: 54.1684\n",
      "Epoch [31/100], Step [39900/6235], Loss: 1.3914\n",
      "Epoch [31/100], Step [40000/6235], Loss: 14.3043\n",
      "Epoch [31/100], Step [40100/6235], Loss: 30.8578\n",
      "Epoch [31/100], Step [40200/6235], Loss: 21.7271\n",
      "Epoch [31/100], Step [40300/6235], Loss: 0.4698\n",
      "Epoch [31/100], Step [40400/6235], Loss: 2.7984\n",
      "Epoch [31/100], Step [40500/6235], Loss: 1.3110\n",
      "Epoch [31/100], Step [40600/6235], Loss: 1.3472\n",
      "Epoch [31/100], Step [40700/6235], Loss: 7.1067\n",
      "Epoch [31/100], Step [40800/6235], Loss: 3.2833\n",
      "Epoch [31/100], Step [40900/6235], Loss: 0.4916\n",
      "Epoch [31/100], Step [41000/6235], Loss: 21.0549\n",
      "Epoch [31/100], Step [41100/6235], Loss: 1.1733\n",
      "Epoch [31/100], Step [41200/6235], Loss: 28.9579\n",
      "Epoch [31/100], Step [41300/6235], Loss: 1.3052\n",
      "Epoch [31/100], Step [41400/6235], Loss: 0.5979\n",
      "Epoch [31/100], Step [41500/6235], Loss: 11.1699\n",
      "Epoch [31/100], Step [41600/6235], Loss: 1.3306\n",
      "Epoch [31/100], Step [41700/6235], Loss: 0.1652\n",
      "Epoch [31/100], Step [41800/6235], Loss: 0.6403\n",
      "Epoch [31/100], Step [41900/6235], Loss: 4.7559\n",
      "Epoch [31/100], Step [42000/6235], Loss: 4.7069\n",
      "Epoch [31/100], Step [42100/6235], Loss: 11.5463\n",
      "Epoch [31/100], Step [42200/6235], Loss: 63.2412\n",
      "Epoch [31/100], Step [42300/6235], Loss: 1.0964\n",
      "Epoch [31/100], Step [42400/6235], Loss: 4.7456\n",
      "Epoch [31/100], Step [42500/6235], Loss: 0.7744\n",
      "Epoch [31/100], Step [42600/6235], Loss: 1.7487\n",
      "Epoch [31/100], Step [42700/6235], Loss: 0.7254\n",
      "Epoch [31/100], Step [42800/6235], Loss: 5.6072\n",
      "Epoch [31/100], Step [42900/6235], Loss: 3.2532\n",
      "Epoch [31/100], Step [43000/6235], Loss: 0.2362\n",
      "Epoch [31/100], Step [43100/6235], Loss: 0.2683\n",
      "Epoch [31/100], Step [43200/6235], Loss: 1.0851\n",
      "Epoch [31/100], Step [43300/6235], Loss: 8.6412\n",
      "Epoch [31/100], Step [43400/6235], Loss: 12.5181\n",
      "Epoch [31/100], Step [43500/6235], Loss: 9.3651\n",
      "Epoch [31/100], Step [43600/6235], Loss: 16.6075\n",
      "Epoch [31/100], Step [43700/6235], Loss: 41.3835\n",
      "Epoch [31/100], Step [43800/6235], Loss: 0.6397\n",
      "Epoch [31/100], Step [43900/6235], Loss: 0.7573\n",
      "Epoch [31/100], Step [44000/6235], Loss: 64.5718\n",
      "Epoch [31/100], Step [44100/6235], Loss: 4.9179\n",
      "Epoch [31/100], Step [44200/6235], Loss: 18.2788\n",
      "Epoch [31/100], Step [44300/6235], Loss: 43.3432\n",
      "Epoch [31/100], Step [44400/6235], Loss: 5.4371\n",
      "Epoch [31/100], Step [44500/6235], Loss: 2.6291\n",
      "Epoch [31/100], Step [44600/6235], Loss: 27.5830\n",
      "Epoch [31/100], Step [44700/6235], Loss: 1.0155\n",
      "Epoch [31/100], Step [44800/6235], Loss: 2.2718\n",
      "Epoch [31/100], Step [44900/6235], Loss: 1.4774\n",
      "Epoch [31/100], Step [45000/6235], Loss: 4.8170\n",
      "Epoch [31/100], Step [45100/6235], Loss: 30.9091\n",
      "Epoch [31/100], Step [45200/6235], Loss: 0.4960\n",
      "Epoch [31/100], Step [45300/6235], Loss: 45.8520\n",
      "Epoch [31/100], Step [45400/6235], Loss: 9.2102\n",
      "Epoch [31/100], Step [45500/6235], Loss: 0.1530\n",
      "Epoch [31/100], Step [45600/6235], Loss: 0.1838\n",
      "Epoch [31/100], Step [45700/6235], Loss: 19.5492\n",
      "Epoch [31/100], Step [45800/6235], Loss: 254.5895\n",
      "Epoch [31/100], Step [45900/6235], Loss: 3.2803\n",
      "Epoch [31/100], Step [46000/6235], Loss: 85.6171\n",
      "Epoch [31/100], Step [46100/6235], Loss: 9.4472\n",
      "Epoch [31/100], Step [46200/6235], Loss: 6.7495\n",
      "Epoch [31/100], Step [46300/6235], Loss: 10.7130\n",
      "Epoch [31/100], Step [46400/6235], Loss: 3.0593\n",
      "Epoch [31/100], Step [46500/6235], Loss: 18.2456\n",
      "Epoch [31/100], Step [46600/6235], Loss: 2.4820\n",
      "Epoch [31/100], Step [46700/6235], Loss: 9.7784\n",
      "Epoch [31/100], Step [46800/6235], Loss: 50.4999\n",
      "Epoch [31/100], Step [46900/6235], Loss: 53.2792\n",
      "Epoch [31/100], Step [47000/6235], Loss: 1.8975\n",
      "Epoch [31/100], Step [47100/6235], Loss: 133.8478\n",
      "Epoch [31/100], Step [47200/6235], Loss: 22.0623\n",
      "Epoch [31/100], Step [47300/6235], Loss: 6.9932\n",
      "Epoch [31/100], Step [47400/6235], Loss: 393.5192\n",
      "Epoch [31/100], Step [47500/6235], Loss: 24.0501\n",
      "Epoch [31/100], Step [47600/6235], Loss: 8.9777\n",
      "Epoch [31/100], Step [47700/6235], Loss: 28.0498\n",
      "Epoch [31/100], Step [47800/6235], Loss: 46.8180\n",
      "Epoch [31/100], Step [47900/6235], Loss: 14.4841\n",
      "Epoch [31/100], Step [48000/6235], Loss: 6.0425\n",
      "Epoch [31/100], Step [48100/6235], Loss: 7.7558\n",
      "Epoch [31/100], Step [48200/6235], Loss: 16.4564\n",
      "Epoch [31/100], Step [48300/6235], Loss: 689.3240\n",
      "Epoch [31/100], Step [48400/6235], Loss: 3.9186\n",
      "Epoch [31/100], Step [48500/6235], Loss: 40.8885\n",
      "Epoch [31/100], Step [48600/6235], Loss: 52.4497\n",
      "Epoch [31/100], Step [48700/6235], Loss: 7.7743\n",
      "Epoch [31/100], Step [48800/6235], Loss: 215.3559\n",
      "Epoch [31/100], Step [48900/6235], Loss: 401.1609\n",
      "Epoch [31/100], Step [49000/6235], Loss: 131.7975\n",
      "Epoch [31/100], Step [49100/6235], Loss: 2023.4641\n",
      "Epoch [31/100], Step [49200/6235], Loss: 780.3786\n",
      "Epoch [31/100], Step [49300/6235], Loss: 1095.1730\n",
      "Epoch [31/100], Step [49400/6235], Loss: 94.3607\n",
      "Epoch [31/100], Step [49500/6235], Loss: 39.0329\n",
      "Epoch [31/100], Step [49600/6235], Loss: 406.9530\n",
      "Epoch [31/100], Step [49700/6235], Loss: 9010.4600\n",
      "Epoch [31/100], Step [49800/6235], Loss: 1450.7802\n",
      "Epoch [32/100], Step [100/6235], Loss: 48.2506\n",
      "Epoch [32/100], Step [200/6235], Loss: 0.6173\n",
      "Epoch [32/100], Step [300/6235], Loss: 0.6345\n",
      "Epoch [32/100], Step [400/6235], Loss: 0.3433\n",
      "Epoch [32/100], Step [500/6235], Loss: 6.1698\n",
      "Epoch [32/100], Step [600/6235], Loss: 0.1458\n",
      "Epoch [32/100], Step [700/6235], Loss: 0.2999\n",
      "Epoch [32/100], Step [800/6235], Loss: 0.0066\n",
      "Epoch [32/100], Step [900/6235], Loss: 0.0273\n",
      "Epoch [32/100], Step [1000/6235], Loss: 0.0131\n",
      "Epoch [32/100], Step [1100/6235], Loss: 0.2789\n",
      "Epoch [32/100], Step [1200/6235], Loss: 0.1143\n",
      "Epoch [32/100], Step [1300/6235], Loss: 0.0080\n",
      "Epoch [32/100], Step [1400/6235], Loss: 0.4370\n",
      "Epoch [32/100], Step [1500/6235], Loss: 0.0021\n",
      "Epoch [32/100], Step [1600/6235], Loss: 0.2700\n",
      "Epoch [32/100], Step [1700/6235], Loss: 0.1154\n",
      "Epoch [32/100], Step [1800/6235], Loss: 0.3889\n",
      "Epoch [32/100], Step [1900/6235], Loss: 0.1218\n",
      "Epoch [32/100], Step [2000/6235], Loss: 2.3043\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Step [2100/6235], Loss: 2.6148\n",
      "Epoch [32/100], Step [2200/6235], Loss: 1.8650\n",
      "Epoch [32/100], Step [2300/6235], Loss: 1.1303\n",
      "Epoch [32/100], Step [2400/6235], Loss: 17.4459\n",
      "Epoch [32/100], Step [2500/6235], Loss: 4.9648\n",
      "Epoch [32/100], Step [2600/6235], Loss: 12.2634\n",
      "Epoch [32/100], Step [2700/6235], Loss: 23.0804\n",
      "Epoch [32/100], Step [2800/6235], Loss: 10.1906\n",
      "Epoch [32/100], Step [2900/6235], Loss: 9.5522\n",
      "Epoch [32/100], Step [3000/6235], Loss: 6.1307\n",
      "Epoch [32/100], Step [3100/6235], Loss: 103.1855\n",
      "Epoch [32/100], Step [3200/6235], Loss: 3.3731\n",
      "Epoch [32/100], Step [3300/6235], Loss: 1.3344\n",
      "Epoch [32/100], Step [3400/6235], Loss: 6.7145\n",
      "Epoch [32/100], Step [3500/6235], Loss: 81.2279\n",
      "Epoch [32/100], Step [3600/6235], Loss: 4.4857\n",
      "Epoch [32/100], Step [3700/6235], Loss: 0.3361\n",
      "Epoch [32/100], Step [3800/6235], Loss: 0.3751\n",
      "Epoch [32/100], Step [3900/6235], Loss: 0.5793\n",
      "Epoch [32/100], Step [4000/6235], Loss: 0.7349\n",
      "Epoch [32/100], Step [4100/6235], Loss: 5.2876\n",
      "Epoch [32/100], Step [4200/6235], Loss: 0.2910\n",
      "Epoch [32/100], Step [4300/6235], Loss: 1.5129\n",
      "Epoch [32/100], Step [4400/6235], Loss: 0.0118\n",
      "Epoch [32/100], Step [4500/6235], Loss: 62.9515\n",
      "Epoch [32/100], Step [4600/6235], Loss: 19.7734\n",
      "Epoch [32/100], Step [4700/6235], Loss: 2.7788\n",
      "Epoch [32/100], Step [4800/6235], Loss: 1.8507\n",
      "Epoch [32/100], Step [4900/6235], Loss: 1.0431\n",
      "Epoch [32/100], Step [5000/6235], Loss: 0.5904\n",
      "Epoch [32/100], Step [5100/6235], Loss: 11.1623\n",
      "Epoch [32/100], Step [5200/6235], Loss: 0.9449\n",
      "Epoch [32/100], Step [5300/6235], Loss: 14.3485\n",
      "Epoch [32/100], Step [5400/6235], Loss: 2.2094\n",
      "Epoch [32/100], Step [5500/6235], Loss: 0.5641\n",
      "Epoch [32/100], Step [5600/6235], Loss: 0.6991\n",
      "Epoch [32/100], Step [5700/6235], Loss: 0.5669\n",
      "Epoch [32/100], Step [5800/6235], Loss: 1.0254\n",
      "Epoch [32/100], Step [5900/6235], Loss: 0.0270\n",
      "Epoch [32/100], Step [6000/6235], Loss: 0.4842\n",
      "Epoch [32/100], Step [6100/6235], Loss: 0.0079\n",
      "Epoch [32/100], Step [6200/6235], Loss: 4.7932\n",
      "Epoch [32/100], Step [6300/6235], Loss: 0.3782\n",
      "Epoch [32/100], Step [6400/6235], Loss: 0.0155\n",
      "Epoch [32/100], Step [6500/6235], Loss: 1.1495\n",
      "Epoch [32/100], Step [6600/6235], Loss: 3.1903\n",
      "Epoch [32/100], Step [6700/6235], Loss: 2.0373\n",
      "Epoch [32/100], Step [6800/6235], Loss: 0.3960\n",
      "Epoch [32/100], Step [6900/6235], Loss: 0.2779\n",
      "Epoch [32/100], Step [7000/6235], Loss: 0.0299\n",
      "Epoch [32/100], Step [7100/6235], Loss: 0.2726\n",
      "Epoch [32/100], Step [7200/6235], Loss: 0.4503\n",
      "Epoch [32/100], Step [7300/6235], Loss: 1.0593\n",
      "Epoch [32/100], Step [7400/6235], Loss: 0.0677\n",
      "Epoch [32/100], Step [7500/6235], Loss: 0.3804\n",
      "Epoch [32/100], Step [7600/6235], Loss: 3.9132\n",
      "Epoch [32/100], Step [7700/6235], Loss: 4.8804\n",
      "Epoch [32/100], Step [7800/6235], Loss: 2.4226\n",
      "Epoch [32/100], Step [7900/6235], Loss: 6.2802\n",
      "Epoch [32/100], Step [8000/6235], Loss: 0.5777\n",
      "Epoch [32/100], Step [8100/6235], Loss: 0.4724\n",
      "Epoch [32/100], Step [8200/6235], Loss: 10.0558\n",
      "Epoch [32/100], Step [8300/6235], Loss: 22.8786\n",
      "Epoch [32/100], Step [8400/6235], Loss: 568.3506\n",
      "Epoch [32/100], Step [8500/6235], Loss: 10.4479\n",
      "Epoch [32/100], Step [8600/6235], Loss: 55.3752\n",
      "Epoch [32/100], Step [8700/6235], Loss: 18.8286\n",
      "Epoch [32/100], Step [8800/6235], Loss: 1057.4095\n",
      "Epoch [32/100], Step [8900/6235], Loss: 6.7787\n",
      "Epoch [32/100], Step [9000/6235], Loss: 418.0421\n",
      "Epoch [32/100], Step [9100/6235], Loss: 535.8733\n",
      "Epoch [32/100], Step [9200/6235], Loss: 2543.4539\n",
      "Epoch [32/100], Step [9300/6235], Loss: 214.8058\n",
      "Epoch [32/100], Step [9400/6235], Loss: 119.0188\n",
      "Epoch [32/100], Step [9500/6235], Loss: 1215.9498\n",
      "Epoch [32/100], Step [9600/6235], Loss: 398.8519\n",
      "Epoch [32/100], Step [9700/6235], Loss: 4.0112\n",
      "Epoch [32/100], Step [9800/6235], Loss: 3165.2820\n",
      "Epoch [32/100], Step [9900/6235], Loss: 39.5759\n",
      "Epoch [32/100], Step [10000/6235], Loss: 265.5867\n",
      "Epoch [32/100], Step [10100/6235], Loss: 1.3589\n",
      "Epoch [32/100], Step [10200/6235], Loss: 790.0482\n",
      "Epoch [32/100], Step [10300/6235], Loss: 1.7674\n",
      "Epoch [32/100], Step [10400/6235], Loss: 6.6069\n",
      "Epoch [32/100], Step [10500/6235], Loss: 5.2389\n",
      "Epoch [32/100], Step [10600/6235], Loss: 23.2760\n",
      "Epoch [32/100], Step [10700/6235], Loss: 306.3702\n",
      "Epoch [32/100], Step [10800/6235], Loss: 5.8107\n",
      "Epoch [32/100], Step [10900/6235], Loss: 7.7174\n",
      "Epoch [32/100], Step [11000/6235], Loss: 139.8642\n",
      "Epoch [32/100], Step [11100/6235], Loss: 0.6450\n",
      "Epoch [32/100], Step [11200/6235], Loss: 121.1384\n",
      "Epoch [32/100], Step [11300/6235], Loss: 249.1317\n",
      "Epoch [32/100], Step [11400/6235], Loss: 77.1081\n",
      "Epoch [32/100], Step [11500/6235], Loss: 5.6876\n",
      "Epoch [32/100], Step [11600/6235], Loss: 4.8796\n",
      "Epoch [32/100], Step [11700/6235], Loss: 81.9503\n",
      "Epoch [32/100], Step [11800/6235], Loss: 7.5709\n",
      "Epoch [32/100], Step [11900/6235], Loss: 27.6333\n",
      "Epoch [32/100], Step [12000/6235], Loss: 662.1113\n",
      "Epoch [32/100], Step [12100/6235], Loss: 201.8943\n",
      "Epoch [32/100], Step [12200/6235], Loss: 36.2386\n",
      "Epoch [32/100], Step [12300/6235], Loss: 4.1639\n",
      "Epoch [32/100], Step [12400/6235], Loss: 476.7103\n",
      "Epoch [32/100], Step [12500/6235], Loss: 41.9347\n",
      "Epoch [32/100], Step [12600/6235], Loss: 15.8597\n",
      "Epoch [32/100], Step [12700/6235], Loss: 5.9596\n",
      "Epoch [32/100], Step [12800/6235], Loss: 13.3420\n",
      "Epoch [32/100], Step [12900/6235], Loss: 34.0898\n",
      "Epoch [32/100], Step [13000/6235], Loss: 1.0083\n",
      "Epoch [32/100], Step [13100/6235], Loss: 70.0860\n",
      "Epoch [32/100], Step [13200/6235], Loss: 4.8890\n",
      "Epoch [32/100], Step [13300/6235], Loss: 14.4257\n",
      "Epoch [32/100], Step [13400/6235], Loss: 246.3337\n",
      "Epoch [32/100], Step [13500/6235], Loss: 3.3017\n",
      "Epoch [32/100], Step [13600/6235], Loss: 4.6951\n",
      "Epoch [32/100], Step [13700/6235], Loss: 205.5145\n",
      "Epoch [32/100], Step [13800/6235], Loss: 123.0729\n",
      "Epoch [32/100], Step [13900/6235], Loss: 164.2997\n",
      "Epoch [32/100], Step [14000/6235], Loss: 4.6228\n",
      "Epoch [32/100], Step [14100/6235], Loss: 79.3342\n",
      "Epoch [32/100], Step [14200/6235], Loss: 57.2724\n",
      "Epoch [32/100], Step [14300/6235], Loss: 61.5603\n",
      "Epoch [32/100], Step [14400/6235], Loss: 38.3954\n",
      "Epoch [32/100], Step [14500/6235], Loss: 18.5106\n",
      "Epoch [32/100], Step [14600/6235], Loss: 2.9690\n",
      "Epoch [32/100], Step [14700/6235], Loss: 18.5945\n",
      "Epoch [32/100], Step [14800/6235], Loss: 23.5221\n",
      "Epoch [32/100], Step [14900/6235], Loss: 0.8488\n",
      "Epoch [32/100], Step [15000/6235], Loss: 0.9782\n",
      "Epoch [32/100], Step [15100/6235], Loss: 0.3811\n",
      "Epoch [32/100], Step [15200/6235], Loss: 6.1982\n",
      "Epoch [32/100], Step [15300/6235], Loss: 34.0232\n",
      "Epoch [32/100], Step [15400/6235], Loss: 76.2670\n",
      "Epoch [32/100], Step [15500/6235], Loss: 13.8006\n",
      "Epoch [32/100], Step [15600/6235], Loss: 170.4904\n",
      "Epoch [32/100], Step [15700/6235], Loss: 173.3415\n",
      "Epoch [32/100], Step [15800/6235], Loss: 10.9202\n",
      "Epoch [32/100], Step [15900/6235], Loss: 0.3575\n",
      "Epoch [32/100], Step [16000/6235], Loss: 69.9213\n",
      "Epoch [32/100], Step [16100/6235], Loss: 3.1714\n",
      "Epoch [32/100], Step [16200/6235], Loss: 14.0084\n",
      "Epoch [32/100], Step [16300/6235], Loss: 11.7022\n",
      "Epoch [32/100], Step [16400/6235], Loss: 42.8375\n",
      "Epoch [32/100], Step [16500/6235], Loss: 144.2717\n",
      "Epoch [32/100], Step [16600/6235], Loss: 12.1634\n",
      "Epoch [32/100], Step [16700/6235], Loss: 0.7007\n",
      "Epoch [32/100], Step [16800/6235], Loss: 9.0756\n",
      "Epoch [32/100], Step [16900/6235], Loss: 0.3648\n",
      "Epoch [32/100], Step [17000/6235], Loss: 0.2481\n",
      "Epoch [32/100], Step [17100/6235], Loss: 0.4213\n",
      "Epoch [32/100], Step [17200/6235], Loss: 303.9543\n",
      "Epoch [32/100], Step [17300/6235], Loss: 3.6520\n",
      "Epoch [32/100], Step [17400/6235], Loss: 31.2316\n",
      "Epoch [32/100], Step [17500/6235], Loss: 0.6284\n",
      "Epoch [32/100], Step [17600/6235], Loss: 4.3976\n",
      "Epoch [32/100], Step [17700/6235], Loss: 15.7243\n",
      "Epoch [32/100], Step [17800/6235], Loss: 20.5664\n",
      "Epoch [32/100], Step [17900/6235], Loss: 7.5269\n",
      "Epoch [32/100], Step [18000/6235], Loss: 13.4286\n",
      "Epoch [32/100], Step [18100/6235], Loss: 15.8547\n",
      "Epoch [32/100], Step [18200/6235], Loss: 0.4877\n",
      "Epoch [32/100], Step [18300/6235], Loss: 10.4513\n",
      "Epoch [32/100], Step [18400/6235], Loss: 1.0222\n",
      "Epoch [32/100], Step [18500/6235], Loss: 17.5223\n",
      "Epoch [32/100], Step [18600/6235], Loss: 5.9583\n",
      "Epoch [32/100], Step [18700/6235], Loss: 1.2000\n",
      "Epoch [32/100], Step [18800/6235], Loss: 105.6871\n",
      "Epoch [32/100], Step [18900/6235], Loss: 47.1869\n",
      "Epoch [32/100], Step [19000/6235], Loss: 5.6250\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Step [19100/6235], Loss: 24.9516\n",
      "Epoch [32/100], Step [19200/6235], Loss: 2.0872\n",
      "Epoch [32/100], Step [19300/6235], Loss: 7.6550\n",
      "Epoch [32/100], Step [19400/6235], Loss: 81.3734\n",
      "Epoch [32/100], Step [19500/6235], Loss: 24.4938\n",
      "Epoch [32/100], Step [19600/6235], Loss: 19.6061\n",
      "Epoch [32/100], Step [19700/6235], Loss: 5.4200\n",
      "Epoch [32/100], Step [19800/6235], Loss: 4.7351\n",
      "Epoch [32/100], Step [19900/6235], Loss: 0.1171\n",
      "Epoch [32/100], Step [20000/6235], Loss: 70.2063\n",
      "Epoch [32/100], Step [20100/6235], Loss: 4.0337\n",
      "Epoch [32/100], Step [20200/6235], Loss: 0.6919\n",
      "Epoch [32/100], Step [20300/6235], Loss: 2.0709\n",
      "Epoch [32/100], Step [20400/6235], Loss: 7.5895\n",
      "Epoch [32/100], Step [20500/6235], Loss: 60.1232\n",
      "Epoch [32/100], Step [20600/6235], Loss: 68.1068\n",
      "Epoch [32/100], Step [20700/6235], Loss: 14.5636\n",
      "Epoch [32/100], Step [20800/6235], Loss: 11.2849\n",
      "Epoch [32/100], Step [20900/6235], Loss: 21.0829\n",
      "Epoch [32/100], Step [21000/6235], Loss: 20.1540\n",
      "Epoch [32/100], Step [21100/6235], Loss: 7.0670\n",
      "Epoch [32/100], Step [21200/6235], Loss: 0.2544\n",
      "Epoch [32/100], Step [21300/6235], Loss: 0.0527\n",
      "Epoch [32/100], Step [21400/6235], Loss: 2.1961\n",
      "Epoch [32/100], Step [21500/6235], Loss: 0.1802\n",
      "Epoch [32/100], Step [21600/6235], Loss: 25.9171\n",
      "Epoch [32/100], Step [21700/6235], Loss: 0.1881\n",
      "Epoch [32/100], Step [21800/6235], Loss: 4.6459\n",
      "Epoch [32/100], Step [21900/6235], Loss: 1.4657\n",
      "Epoch [32/100], Step [22000/6235], Loss: 9.9879\n",
      "Epoch [32/100], Step [22100/6235], Loss: 0.1062\n",
      "Epoch [32/100], Step [22200/6235], Loss: 5.0195\n",
      "Epoch [32/100], Step [22300/6235], Loss: 0.8862\n",
      "Epoch [32/100], Step [22400/6235], Loss: 6.6407\n",
      "Epoch [32/100], Step [22500/6235], Loss: 162.4071\n",
      "Epoch [32/100], Step [22600/6235], Loss: 12.0909\n",
      "Epoch [32/100], Step [22700/6235], Loss: 1.4637\n",
      "Epoch [32/100], Step [22800/6235], Loss: 5.9246\n",
      "Epoch [32/100], Step [22900/6235], Loss: 2.5148\n",
      "Epoch [32/100], Step [23000/6235], Loss: 7.3259\n",
      "Epoch [32/100], Step [23100/6235], Loss: 4.5374\n",
      "Epoch [32/100], Step [23200/6235], Loss: 8.6916\n",
      "Epoch [32/100], Step [23300/6235], Loss: 20.1640\n",
      "Epoch [32/100], Step [23400/6235], Loss: 2.4047\n",
      "Epoch [32/100], Step [23500/6235], Loss: 0.0485\n",
      "Epoch [32/100], Step [23600/6235], Loss: 135.5890\n",
      "Epoch [32/100], Step [23700/6235], Loss: 3.1597\n",
      "Epoch [32/100], Step [23800/6235], Loss: 0.8402\n",
      "Epoch [32/100], Step [23900/6235], Loss: 1.6341\n",
      "Epoch [32/100], Step [24000/6235], Loss: 1.9348\n",
      "Epoch [32/100], Step [24100/6235], Loss: 0.5930\n",
      "Epoch [32/100], Step [24200/6235], Loss: 50.0046\n",
      "Epoch [32/100], Step [24300/6235], Loss: 0.6989\n",
      "Epoch [32/100], Step [24400/6235], Loss: 0.0860\n",
      "Epoch [32/100], Step [24500/6235], Loss: 2.4610\n",
      "Epoch [32/100], Step [24600/6235], Loss: 0.4838\n",
      "Epoch [32/100], Step [24700/6235], Loss: 0.0694\n",
      "Epoch [32/100], Step [24800/6235], Loss: 0.4513\n",
      "Epoch [32/100], Step [24900/6235], Loss: 8.5473\n",
      "Epoch [32/100], Step [25000/6235], Loss: 9.0122\n",
      "Epoch [32/100], Step [25100/6235], Loss: 7.2915\n",
      "Epoch [32/100], Step [25200/6235], Loss: 0.0346\n",
      "Epoch [32/100], Step [25300/6235], Loss: 1.9148\n",
      "Epoch [32/100], Step [25400/6235], Loss: 4.4793\n",
      "Epoch [32/100], Step [25500/6235], Loss: 9.0997\n",
      "Epoch [32/100], Step [25600/6235], Loss: 8.2767\n",
      "Epoch [32/100], Step [25700/6235], Loss: 0.0908\n",
      "Epoch [32/100], Step [25800/6235], Loss: 0.5187\n",
      "Epoch [32/100], Step [25900/6235], Loss: 4.7239\n",
      "Epoch [32/100], Step [26000/6235], Loss: 0.2321\n",
      "Epoch [32/100], Step [26100/6235], Loss: 0.1216\n",
      "Epoch [32/100], Step [26200/6235], Loss: 1.3419\n",
      "Epoch [32/100], Step [26300/6235], Loss: 0.5029\n",
      "Epoch [32/100], Step [26400/6235], Loss: 0.9751\n",
      "Epoch [32/100], Step [26500/6235], Loss: 0.0459\n",
      "Epoch [32/100], Step [26600/6235], Loss: 0.1034\n",
      "Epoch [32/100], Step [26700/6235], Loss: 0.0811\n",
      "Epoch [32/100], Step [26800/6235], Loss: 0.0670\n",
      "Epoch [32/100], Step [26900/6235], Loss: 0.1046\n",
      "Epoch [32/100], Step [27000/6235], Loss: 16.0488\n",
      "Epoch [32/100], Step [27100/6235], Loss: 0.0870\n",
      "Epoch [32/100], Step [27200/6235], Loss: 0.0092\n",
      "Epoch [32/100], Step [27300/6235], Loss: 0.0166\n",
      "Epoch [32/100], Step [27400/6235], Loss: 0.5286\n",
      "Epoch [32/100], Step [27500/6235], Loss: 1.8045\n",
      "Epoch [32/100], Step [27600/6235], Loss: 0.5338\n",
      "Epoch [32/100], Step [27700/6235], Loss: 0.9336\n",
      "Epoch [32/100], Step [27800/6235], Loss: 4.1620\n",
      "Epoch [32/100], Step [27900/6235], Loss: 4.6305\n",
      "Epoch [32/100], Step [28000/6235], Loss: 199.7648\n",
      "Epoch [32/100], Step [28100/6235], Loss: 0.7733\n",
      "Epoch [32/100], Step [28200/6235], Loss: 34.2665\n",
      "Epoch [32/100], Step [28300/6235], Loss: 1.7878\n",
      "Epoch [32/100], Step [28400/6235], Loss: 19.9617\n",
      "Epoch [32/100], Step [28500/6235], Loss: 1.2486\n",
      "Epoch [32/100], Step [28600/6235], Loss: 1.6638\n",
      "Epoch [32/100], Step [28700/6235], Loss: 2.2033\n",
      "Epoch [32/100], Step [28800/6235], Loss: 0.7194\n",
      "Epoch [32/100], Step [28900/6235], Loss: 36.7301\n",
      "Epoch [32/100], Step [29000/6235], Loss: 0.0550\n",
      "Epoch [32/100], Step [29100/6235], Loss: 1.2394\n",
      "Epoch [32/100], Step [29200/6235], Loss: 5.8466\n",
      "Epoch [32/100], Step [29300/6235], Loss: 5.8375\n",
      "Epoch [32/100], Step [29400/6235], Loss: 3.8653\n",
      "Epoch [32/100], Step [29500/6235], Loss: 11.7298\n",
      "Epoch [32/100], Step [29600/6235], Loss: 0.5332\n",
      "Epoch [32/100], Step [29700/6235], Loss: 2.8960\n",
      "Epoch [32/100], Step [29800/6235], Loss: 0.5004\n",
      "Epoch [32/100], Step [29900/6235], Loss: 1.4639\n",
      "Epoch [32/100], Step [30000/6235], Loss: 2.2654\n",
      "Epoch [32/100], Step [30100/6235], Loss: 6.2737\n",
      "Epoch [32/100], Step [30200/6235], Loss: 1.8383\n",
      "Epoch [32/100], Step [30300/6235], Loss: 0.0583\n",
      "Epoch [32/100], Step [30400/6235], Loss: 2.7299\n",
      "Epoch [32/100], Step [30500/6235], Loss: 0.0445\n",
      "Epoch [32/100], Step [30600/6235], Loss: 0.8533\n",
      "Epoch [32/100], Step [30700/6235], Loss: 2.8567\n",
      "Epoch [32/100], Step [30800/6235], Loss: 0.4694\n",
      "Epoch [32/100], Step [30900/6235], Loss: 1.1035\n",
      "Epoch [32/100], Step [31000/6235], Loss: 0.2210\n",
      "Epoch [32/100], Step [31100/6235], Loss: 1.0853\n",
      "Epoch [32/100], Step [31200/6235], Loss: 2.9000\n",
      "Epoch [32/100], Step [31300/6235], Loss: 1.2050\n",
      "Epoch [32/100], Step [31400/6235], Loss: 6.1360\n",
      "Epoch [32/100], Step [31500/6235], Loss: 0.8383\n",
      "Epoch [32/100], Step [31600/6235], Loss: 12.3261\n",
      "Epoch [32/100], Step [31700/6235], Loss: 18.6028\n",
      "Epoch [32/100], Step [31800/6235], Loss: 0.3793\n",
      "Epoch [32/100], Step [31900/6235], Loss: 1147.4473\n",
      "Epoch [32/100], Step [32000/6235], Loss: 23.2512\n",
      "Epoch [32/100], Step [32100/6235], Loss: 0.4490\n",
      "Epoch [32/100], Step [32200/6235], Loss: 140.1604\n",
      "Epoch [32/100], Step [32300/6235], Loss: 1.4338\n",
      "Epoch [32/100], Step [32400/6235], Loss: 0.5042\n",
      "Epoch [32/100], Step [32500/6235], Loss: 2.2212\n",
      "Epoch [32/100], Step [32600/6235], Loss: 0.0097\n",
      "Epoch [32/100], Step [32700/6235], Loss: 172.9604\n",
      "Epoch [32/100], Step [32800/6235], Loss: 26.9999\n",
      "Epoch [32/100], Step [32900/6235], Loss: 2.3155\n",
      "Epoch [32/100], Step [33000/6235], Loss: 0.2098\n",
      "Epoch [32/100], Step [33100/6235], Loss: 0.5641\n",
      "Epoch [32/100], Step [33200/6235], Loss: 1.5548\n",
      "Epoch [32/100], Step [33300/6235], Loss: 3.8417\n",
      "Epoch [32/100], Step [33400/6235], Loss: 1.9699\n",
      "Epoch [32/100], Step [33500/6235], Loss: 0.3316\n",
      "Epoch [32/100], Step [33600/6235], Loss: 10.2127\n",
      "Epoch [32/100], Step [33700/6235], Loss: 11.7615\n",
      "Epoch [32/100], Step [33800/6235], Loss: 0.4877\n",
      "Epoch [32/100], Step [33900/6235], Loss: 27.8518\n",
      "Epoch [32/100], Step [34000/6235], Loss: 0.1922\n",
      "Epoch [32/100], Step [34100/6235], Loss: 0.9608\n",
      "Epoch [32/100], Step [34200/6235], Loss: 2.4139\n",
      "Epoch [32/100], Step [34300/6235], Loss: 1.7746\n",
      "Epoch [32/100], Step [34400/6235], Loss: 0.0786\n",
      "Epoch [32/100], Step [34500/6235], Loss: 28.1569\n",
      "Epoch [32/100], Step [34600/6235], Loss: 3.4621\n",
      "Epoch [32/100], Step [34700/6235], Loss: 0.3807\n",
      "Epoch [32/100], Step [34800/6235], Loss: 14.8809\n",
      "Epoch [32/100], Step [34900/6235], Loss: 67.3596\n",
      "Epoch [32/100], Step [35000/6235], Loss: 0.2585\n",
      "Epoch [32/100], Step [35100/6235], Loss: 1.0078\n",
      "Epoch [32/100], Step [35200/6235], Loss: 0.6856\n",
      "Epoch [32/100], Step [35300/6235], Loss: 2.7592\n",
      "Epoch [32/100], Step [35400/6235], Loss: 0.5210\n",
      "Epoch [32/100], Step [35500/6235], Loss: 0.1704\n",
      "Epoch [32/100], Step [35600/6235], Loss: 7.1375\n",
      "Epoch [32/100], Step [35700/6235], Loss: 3.9629\n",
      "Epoch [32/100], Step [35800/6235], Loss: 0.9865\n",
      "Epoch [32/100], Step [35900/6235], Loss: 3.8603\n",
      "Epoch [32/100], Step [36000/6235], Loss: 0.1917\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [32/100], Step [36100/6235], Loss: 0.1113\n",
      "Epoch [32/100], Step [36200/6235], Loss: 44.3270\n",
      "Epoch [32/100], Step [36300/6235], Loss: 0.5493\n",
      "Epoch [32/100], Step [36400/6235], Loss: 2.5941\n",
      "Epoch [32/100], Step [36500/6235], Loss: 6.0985\n",
      "Epoch [32/100], Step [36600/6235], Loss: 0.0290\n",
      "Epoch [32/100], Step [36700/6235], Loss: 0.4135\n",
      "Epoch [32/100], Step [36800/6235], Loss: 0.8495\n",
      "Epoch [32/100], Step [36900/6235], Loss: 9.8815\n",
      "Epoch [32/100], Step [37000/6235], Loss: 0.9934\n",
      "Epoch [32/100], Step [37100/6235], Loss: 2.8779\n",
      "Epoch [32/100], Step [37200/6235], Loss: 0.0253\n",
      "Epoch [32/100], Step [37300/6235], Loss: 0.2668\n",
      "Epoch [32/100], Step [37400/6235], Loss: 0.1781\n",
      "Epoch [32/100], Step [37500/6235], Loss: 8.6812\n",
      "Epoch [32/100], Step [37600/6235], Loss: 11.3635\n",
      "Epoch [32/100], Step [37700/6235], Loss: 2.2218\n",
      "Epoch [32/100], Step [37800/6235], Loss: 5.1306\n",
      "Epoch [32/100], Step [37900/6235], Loss: 2.2252\n",
      "Epoch [32/100], Step [38000/6235], Loss: 0.8332\n",
      "Epoch [32/100], Step [38100/6235], Loss: 4.9964\n",
      "Epoch [32/100], Step [38200/6235], Loss: 2.1604\n",
      "Epoch [32/100], Step [38300/6235], Loss: 0.2647\n",
      "Epoch [32/100], Step [38400/6235], Loss: 0.1385\n",
      "Epoch [32/100], Step [38500/6235], Loss: 1.2639\n",
      "Epoch [32/100], Step [38600/6235], Loss: 0.4508\n",
      "Epoch [32/100], Step [38700/6235], Loss: 0.3938\n",
      "Epoch [32/100], Step [38800/6235], Loss: 0.0981\n",
      "Epoch [32/100], Step [38900/6235], Loss: 0.8433\n",
      "Epoch [32/100], Step [39000/6235], Loss: 3.4027\n",
      "Epoch [32/100], Step [39100/6235], Loss: 19.3166\n",
      "Epoch [32/100], Step [39200/6235], Loss: 0.3727\n",
      "Epoch [32/100], Step [39300/6235], Loss: 51.0290\n",
      "Epoch [32/100], Step [39400/6235], Loss: 67.8760\n",
      "Epoch [32/100], Step [39500/6235], Loss: 276.9129\n",
      "Epoch [32/100], Step [39600/6235], Loss: 12.0559\n",
      "Epoch [32/100], Step [39700/6235], Loss: 92.6320\n",
      "Epoch [32/100], Step [39800/6235], Loss: 181.5915\n",
      "Epoch [32/100], Step [39900/6235], Loss: 0.1931\n",
      "Epoch [32/100], Step [40000/6235], Loss: 12.9595\n",
      "Epoch [32/100], Step [40100/6235], Loss: 27.9761\n",
      "Epoch [32/100], Step [40200/6235], Loss: 4.4606\n",
      "Epoch [32/100], Step [40300/6235], Loss: 0.8405\n",
      "Epoch [32/100], Step [40400/6235], Loss: 2.7476\n",
      "Epoch [32/100], Step [40500/6235], Loss: 1.9169\n",
      "Epoch [32/100], Step [40600/6235], Loss: 0.4591\n",
      "Epoch [32/100], Step [40700/6235], Loss: 7.6923\n",
      "Epoch [32/100], Step [40800/6235], Loss: 2.5123\n",
      "Epoch [32/100], Step [40900/6235], Loss: 0.1471\n",
      "Epoch [32/100], Step [41000/6235], Loss: 33.2235\n",
      "Epoch [32/100], Step [41100/6235], Loss: 2.6106\n",
      "Epoch [32/100], Step [41200/6235], Loss: 17.5724\n",
      "Epoch [32/100], Step [41300/6235], Loss: 2.6997\n",
      "Epoch [32/100], Step [41400/6235], Loss: 0.9812\n",
      "Epoch [32/100], Step [41500/6235], Loss: 0.6204\n",
      "Epoch [32/100], Step [41600/6235], Loss: 0.3825\n",
      "Epoch [32/100], Step [41700/6235], Loss: 1.9692\n",
      "Epoch [32/100], Step [41800/6235], Loss: 3.8286\n",
      "Epoch [32/100], Step [41900/6235], Loss: 3.3636\n",
      "Epoch [32/100], Step [42000/6235], Loss: 2.8651\n",
      "Epoch [32/100], Step [42100/6235], Loss: 6.2984\n",
      "Epoch [32/100], Step [42200/6235], Loss: 9.7727\n",
      "Epoch [32/100], Step [42300/6235], Loss: 3.0236\n",
      "Epoch [32/100], Step [42400/6235], Loss: 7.8284\n",
      "Epoch [32/100], Step [42500/6235], Loss: 0.6573\n",
      "Epoch [32/100], Step [42600/6235], Loss: 0.9389\n",
      "Epoch [32/100], Step [42700/6235], Loss: 0.4158\n",
      "Epoch [32/100], Step [42800/6235], Loss: 1.1671\n",
      "Epoch [32/100], Step [42900/6235], Loss: 4.1684\n",
      "Epoch [32/100], Step [43000/6235], Loss: 0.1933\n",
      "Epoch [32/100], Step [43100/6235], Loss: 1.0624\n",
      "Epoch [32/100], Step [43200/6235], Loss: 0.7066\n",
      "Epoch [32/100], Step [43300/6235], Loss: 9.6403\n",
      "Epoch [32/100], Step [43400/6235], Loss: 9.5638\n",
      "Epoch [32/100], Step [43500/6235], Loss: 8.9646\n",
      "Epoch [32/100], Step [43600/6235], Loss: 26.1606\n",
      "Epoch [32/100], Step [43700/6235], Loss: 39.3136\n",
      "Epoch [32/100], Step [43800/6235], Loss: 0.4670\n",
      "Epoch [32/100], Step [43900/6235], Loss: 1.2333\n",
      "Epoch [32/100], Step [44000/6235], Loss: 62.7715\n",
      "Epoch [32/100], Step [44100/6235], Loss: 4.6647\n",
      "Epoch [32/100], Step [44200/6235], Loss: 2.4814\n",
      "Epoch [32/100], Step [44300/6235], Loss: 60.5052\n",
      "Epoch [32/100], Step [44400/6235], Loss: 2.5217\n",
      "Epoch [32/100], Step [44500/6235], Loss: 2.8052\n",
      "Epoch [32/100], Step [44600/6235], Loss: 11.5375\n",
      "Epoch [32/100], Step [44700/6235], Loss: 12.7351\n",
      "Epoch [32/100], Step [44800/6235], Loss: 0.6840\n",
      "Epoch [32/100], Step [44900/6235], Loss: 1.1799\n",
      "Epoch [32/100], Step [45000/6235], Loss: 4.2251\n",
      "Epoch [32/100], Step [45100/6235], Loss: 42.1659\n",
      "Epoch [32/100], Step [45200/6235], Loss: 0.2907\n",
      "Epoch [32/100], Step [45300/6235], Loss: 38.7364\n",
      "Epoch [32/100], Step [45400/6235], Loss: 7.9704\n",
      "Epoch [32/100], Step [45500/6235], Loss: 0.1521\n",
      "Epoch [32/100], Step [45600/6235], Loss: 0.2263\n",
      "Epoch [32/100], Step [45700/6235], Loss: 19.9965\n",
      "Epoch [32/100], Step [45800/6235], Loss: 238.7426\n",
      "Epoch [32/100], Step [45900/6235], Loss: 15.2140\n",
      "Epoch [32/100], Step [46000/6235], Loss: 4.6522\n",
      "Epoch [32/100], Step [46100/6235], Loss: 10.1662\n",
      "Epoch [32/100], Step [46200/6235], Loss: 45.3806\n",
      "Epoch [32/100], Step [46300/6235], Loss: 24.9160\n",
      "Epoch [32/100], Step [46400/6235], Loss: 5.3222\n",
      "Epoch [32/100], Step [46500/6235], Loss: 1.7884\n",
      "Epoch [32/100], Step [46600/6235], Loss: 27.5688\n",
      "Epoch [32/100], Step [46700/6235], Loss: 2.3930\n",
      "Epoch [32/100], Step [46800/6235], Loss: 31.2238\n",
      "Epoch [32/100], Step [46900/6235], Loss: 22.5962\n",
      "Epoch [32/100], Step [47000/6235], Loss: 0.6359\n",
      "Epoch [32/100], Step [47100/6235], Loss: 64.0429\n",
      "Epoch [32/100], Step [47200/6235], Loss: 77.6921\n",
      "Epoch [32/100], Step [47300/6235], Loss: 0.6633\n",
      "Epoch [32/100], Step [47400/6235], Loss: 152.3646\n",
      "Epoch [32/100], Step [47500/6235], Loss: 3.0049\n",
      "Epoch [32/100], Step [47600/6235], Loss: 15.6581\n",
      "Epoch [32/100], Step [47700/6235], Loss: 13.9258\n",
      "Epoch [32/100], Step [47800/6235], Loss: 16.9205\n",
      "Epoch [32/100], Step [47900/6235], Loss: 17.9299\n",
      "Epoch [32/100], Step [48000/6235], Loss: 6.7637\n",
      "Epoch [32/100], Step [48100/6235], Loss: 3.9431\n",
      "Epoch [32/100], Step [48200/6235], Loss: 24.4118\n",
      "Epoch [32/100], Step [48300/6235], Loss: 388.6651\n",
      "Epoch [32/100], Step [48400/6235], Loss: 15.8325\n",
      "Epoch [32/100], Step [48500/6235], Loss: 35.7121\n",
      "Epoch [32/100], Step [48600/6235], Loss: 152.3916\n",
      "Epoch [32/100], Step [48700/6235], Loss: 4.3293\n",
      "Epoch [32/100], Step [48800/6235], Loss: 168.8371\n",
      "Epoch [32/100], Step [48900/6235], Loss: 566.0562\n",
      "Epoch [32/100], Step [49000/6235], Loss: 181.7446\n",
      "Epoch [32/100], Step [49100/6235], Loss: 2325.3127\n",
      "Epoch [32/100], Step [49200/6235], Loss: 633.9645\n",
      "Epoch [32/100], Step [49300/6235], Loss: 935.2670\n",
      "Epoch [32/100], Step [49400/6235], Loss: 163.7900\n",
      "Epoch [32/100], Step [49500/6235], Loss: 10.3181\n",
      "Epoch [32/100], Step [49600/6235], Loss: 97.5174\n",
      "Epoch [32/100], Step [49700/6235], Loss: 4488.5288\n",
      "Epoch [32/100], Step [49800/6235], Loss: 96.2419\n",
      "Epoch [33/100], Step [100/6235], Loss: 35.6489\n",
      "Epoch [33/100], Step [200/6235], Loss: 0.2022\n",
      "Epoch [33/100], Step [300/6235], Loss: 0.1050\n",
      "Epoch [33/100], Step [400/6235], Loss: 0.0113\n",
      "Epoch [33/100], Step [500/6235], Loss: 72.3486\n",
      "Epoch [33/100], Step [600/6235], Loss: 0.1415\n",
      "Epoch [33/100], Step [700/6235], Loss: 0.8012\n",
      "Epoch [33/100], Step [800/6235], Loss: 0.0700\n",
      "Epoch [33/100], Step [900/6235], Loss: 1.0930\n",
      "Epoch [33/100], Step [1000/6235], Loss: 0.1364\n",
      "Epoch [33/100], Step [1100/6235], Loss: 3.5839\n",
      "Epoch [33/100], Step [1200/6235], Loss: 0.2187\n",
      "Epoch [33/100], Step [1300/6235], Loss: 0.1675\n",
      "Epoch [33/100], Step [1400/6235], Loss: 4.3122\n",
      "Epoch [33/100], Step [1500/6235], Loss: 0.0214\n",
      "Epoch [33/100], Step [1600/6235], Loss: 0.2700\n",
      "Epoch [33/100], Step [1700/6235], Loss: 0.5660\n",
      "Epoch [33/100], Step [1800/6235], Loss: 0.4108\n",
      "Epoch [33/100], Step [1900/6235], Loss: 0.3489\n",
      "Epoch [33/100], Step [2000/6235], Loss: 2.4564\n",
      "Epoch [33/100], Step [2100/6235], Loss: 2.2531\n",
      "Epoch [33/100], Step [2200/6235], Loss: 5.7405\n",
      "Epoch [33/100], Step [2300/6235], Loss: 0.3112\n",
      "Epoch [33/100], Step [2400/6235], Loss: 0.9369\n",
      "Epoch [33/100], Step [2500/6235], Loss: 33.1092\n",
      "Epoch [33/100], Step [2600/6235], Loss: 14.2569\n",
      "Epoch [33/100], Step [2700/6235], Loss: 5.9147\n",
      "Epoch [33/100], Step [2800/6235], Loss: 183.3771\n",
      "Epoch [33/100], Step [2900/6235], Loss: 11.7010\n",
      "Epoch [33/100], Step [3000/6235], Loss: 0.0758\n",
      "Epoch [33/100], Step [3100/6235], Loss: 80.1541\n",
      "Epoch [33/100], Step [3200/6235], Loss: 25.9344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Step [3300/6235], Loss: 4.2616\n",
      "Epoch [33/100], Step [3400/6235], Loss: 6.2728\n",
      "Epoch [33/100], Step [3500/6235], Loss: 58.4554\n",
      "Epoch [33/100], Step [3600/6235], Loss: 0.2253\n",
      "Epoch [33/100], Step [3700/6235], Loss: 0.1670\n",
      "Epoch [33/100], Step [3800/6235], Loss: 0.1165\n",
      "Epoch [33/100], Step [3900/6235], Loss: 0.1638\n",
      "Epoch [33/100], Step [4000/6235], Loss: 0.1834\n",
      "Epoch [33/100], Step [4100/6235], Loss: 9.5949\n",
      "Epoch [33/100], Step [4200/6235], Loss: 5.6617\n",
      "Epoch [33/100], Step [4300/6235], Loss: 3.6336\n",
      "Epoch [33/100], Step [4400/6235], Loss: 0.2898\n",
      "Epoch [33/100], Step [4500/6235], Loss: 44.3090\n",
      "Epoch [33/100], Step [4600/6235], Loss: 5.9156\n",
      "Epoch [33/100], Step [4700/6235], Loss: 0.1145\n",
      "Epoch [33/100], Step [4800/6235], Loss: 3.8907\n",
      "Epoch [33/100], Step [4900/6235], Loss: 4.5011\n",
      "Epoch [33/100], Step [5000/6235], Loss: 0.2063\n",
      "Epoch [33/100], Step [5100/6235], Loss: 0.7852\n",
      "Epoch [33/100], Step [5200/6235], Loss: 5.9881\n",
      "Epoch [33/100], Step [5300/6235], Loss: 12.6903\n",
      "Epoch [33/100], Step [5400/6235], Loss: 3.9008\n",
      "Epoch [33/100], Step [5500/6235], Loss: 0.0696\n",
      "Epoch [33/100], Step [5600/6235], Loss: 0.1146\n",
      "Epoch [33/100], Step [5700/6235], Loss: 0.1322\n",
      "Epoch [33/100], Step [5800/6235], Loss: 0.3688\n",
      "Epoch [33/100], Step [5900/6235], Loss: 0.0621\n",
      "Epoch [33/100], Step [6000/6235], Loss: 1.5175\n",
      "Epoch [33/100], Step [6100/6235], Loss: 0.0494\n",
      "Epoch [33/100], Step [6200/6235], Loss: 7.4158\n",
      "Epoch [33/100], Step [6300/6235], Loss: 1.1718\n",
      "Epoch [33/100], Step [6400/6235], Loss: 0.0322\n",
      "Epoch [33/100], Step [6500/6235], Loss: 0.4186\n",
      "Epoch [33/100], Step [6600/6235], Loss: 6.6422\n",
      "Epoch [33/100], Step [6700/6235], Loss: 1.2841\n",
      "Epoch [33/100], Step [6800/6235], Loss: 0.3983\n",
      "Epoch [33/100], Step [6900/6235], Loss: 0.3273\n",
      "Epoch [33/100], Step [7000/6235], Loss: 0.0101\n",
      "Epoch [33/100], Step [7100/6235], Loss: 0.4024\n",
      "Epoch [33/100], Step [7200/6235], Loss: 0.8093\n",
      "Epoch [33/100], Step [7300/6235], Loss: 0.7992\n",
      "Epoch [33/100], Step [7400/6235], Loss: 0.0640\n",
      "Epoch [33/100], Step [7500/6235], Loss: 0.1749\n",
      "Epoch [33/100], Step [7600/6235], Loss: 5.6465\n",
      "Epoch [33/100], Step [7700/6235], Loss: 10.0911\n",
      "Epoch [33/100], Step [7800/6235], Loss: 2.3933\n",
      "Epoch [33/100], Step [7900/6235], Loss: 6.0523\n",
      "Epoch [33/100], Step [8000/6235], Loss: 0.6097\n",
      "Epoch [33/100], Step [8100/6235], Loss: 0.3428\n",
      "Epoch [33/100], Step [8200/6235], Loss: 10.5852\n",
      "Epoch [33/100], Step [8300/6235], Loss: 17.8940\n",
      "Epoch [33/100], Step [8400/6235], Loss: 654.1691\n",
      "Epoch [33/100], Step [8500/6235], Loss: 18.6437\n",
      "Epoch [33/100], Step [8600/6235], Loss: 25.5562\n",
      "Epoch [33/100], Step [8700/6235], Loss: 36.7751\n",
      "Epoch [33/100], Step [8800/6235], Loss: 377.8362\n",
      "Epoch [33/100], Step [8900/6235], Loss: 179.4826\n",
      "Epoch [33/100], Step [9000/6235], Loss: 461.1383\n",
      "Epoch [33/100], Step [9100/6235], Loss: 190.6319\n",
      "Epoch [33/100], Step [9200/6235], Loss: 2577.0320\n",
      "Epoch [33/100], Step [9300/6235], Loss: 255.0279\n",
      "Epoch [33/100], Step [9400/6235], Loss: 521.8354\n",
      "Epoch [33/100], Step [9500/6235], Loss: 41.4414\n",
      "Epoch [33/100], Step [9600/6235], Loss: 324.0351\n",
      "Epoch [33/100], Step [9700/6235], Loss: 58.7526\n",
      "Epoch [33/100], Step [9800/6235], Loss: 1227.4248\n",
      "Epoch [33/100], Step [9900/6235], Loss: 70.6430\n",
      "Epoch [33/100], Step [10000/6235], Loss: 229.7876\n",
      "Epoch [33/100], Step [10100/6235], Loss: 1.9941\n",
      "Epoch [33/100], Step [10200/6235], Loss: 1010.3782\n",
      "Epoch [33/100], Step [10300/6235], Loss: 4.6990\n",
      "Epoch [33/100], Step [10400/6235], Loss: 17.0682\n",
      "Epoch [33/100], Step [10500/6235], Loss: 11.2857\n",
      "Epoch [33/100], Step [10600/6235], Loss: 2.6281\n",
      "Epoch [33/100], Step [10700/6235], Loss: 301.1091\n",
      "Epoch [33/100], Step [10800/6235], Loss: 3.7105\n",
      "Epoch [33/100], Step [10900/6235], Loss: 7.6979\n",
      "Epoch [33/100], Step [11000/6235], Loss: 133.7532\n",
      "Epoch [33/100], Step [11100/6235], Loss: 1.4892\n",
      "Epoch [33/100], Step [11200/6235], Loss: 120.5984\n",
      "Epoch [33/100], Step [11300/6235], Loss: 247.7919\n",
      "Epoch [33/100], Step [11400/6235], Loss: 52.7168\n",
      "Epoch [33/100], Step [11500/6235], Loss: 4.5905\n",
      "Epoch [33/100], Step [11600/6235], Loss: 5.1737\n",
      "Epoch [33/100], Step [11700/6235], Loss: 89.6666\n",
      "Epoch [33/100], Step [11800/6235], Loss: 2.8474\n",
      "Epoch [33/100], Step [11900/6235], Loss: 200.6223\n",
      "Epoch [33/100], Step [12000/6235], Loss: 650.8091\n",
      "Epoch [33/100], Step [12100/6235], Loss: 259.7910\n",
      "Epoch [33/100], Step [12200/6235], Loss: 7.0533\n",
      "Epoch [33/100], Step [12300/6235], Loss: 1.5405\n",
      "Epoch [33/100], Step [12400/6235], Loss: 150.6386\n",
      "Epoch [33/100], Step [12500/6235], Loss: 15.5468\n",
      "Epoch [33/100], Step [12600/6235], Loss: 42.0312\n",
      "Epoch [33/100], Step [12700/6235], Loss: 6.3216\n",
      "Epoch [33/100], Step [12800/6235], Loss: 12.4548\n",
      "Epoch [33/100], Step [12900/6235], Loss: 34.4991\n",
      "Epoch [33/100], Step [13000/6235], Loss: 0.5396\n",
      "Epoch [33/100], Step [13100/6235], Loss: 67.3068\n",
      "Epoch [33/100], Step [13200/6235], Loss: 8.3811\n",
      "Epoch [33/100], Step [13300/6235], Loss: 27.4141\n",
      "Epoch [33/100], Step [13400/6235], Loss: 248.5662\n",
      "Epoch [33/100], Step [13500/6235], Loss: 1.5739\n",
      "Epoch [33/100], Step [13600/6235], Loss: 2.7937\n",
      "Epoch [33/100], Step [13700/6235], Loss: 143.1268\n",
      "Epoch [33/100], Step [13800/6235], Loss: 114.5650\n",
      "Epoch [33/100], Step [13900/6235], Loss: 26.1511\n",
      "Epoch [33/100], Step [14000/6235], Loss: 14.1812\n",
      "Epoch [33/100], Step [14100/6235], Loss: 49.4047\n",
      "Epoch [33/100], Step [14200/6235], Loss: 7.2441\n",
      "Epoch [33/100], Step [14300/6235], Loss: 10.9211\n",
      "Epoch [33/100], Step [14400/6235], Loss: 39.2550\n",
      "Epoch [33/100], Step [14500/6235], Loss: 50.8781\n",
      "Epoch [33/100], Step [14600/6235], Loss: 0.1093\n",
      "Epoch [33/100], Step [14700/6235], Loss: 44.7208\n",
      "Epoch [33/100], Step [14800/6235], Loss: 32.9951\n",
      "Epoch [33/100], Step [14900/6235], Loss: 1.2335\n",
      "Epoch [33/100], Step [15000/6235], Loss: 2.2476\n",
      "Epoch [33/100], Step [15100/6235], Loss: 0.3607\n",
      "Epoch [33/100], Step [15200/6235], Loss: 2.0671\n",
      "Epoch [33/100], Step [15300/6235], Loss: 5.5228\n",
      "Epoch [33/100], Step [15400/6235], Loss: 3.4984\n",
      "Epoch [33/100], Step [15500/6235], Loss: 7.6914\n",
      "Epoch [33/100], Step [15600/6235], Loss: 103.3291\n",
      "Epoch [33/100], Step [15700/6235], Loss: 194.2735\n",
      "Epoch [33/100], Step [15800/6235], Loss: 3.6745\n",
      "Epoch [33/100], Step [15900/6235], Loss: 1.6878\n",
      "Epoch [33/100], Step [16000/6235], Loss: 122.1355\n",
      "Epoch [33/100], Step [16100/6235], Loss: 0.8157\n",
      "Epoch [33/100], Step [16200/6235], Loss: 0.2307\n",
      "Epoch [33/100], Step [16300/6235], Loss: 9.7470\n",
      "Epoch [33/100], Step [16400/6235], Loss: 31.0172\n",
      "Epoch [33/100], Step [16500/6235], Loss: 229.0307\n",
      "Epoch [33/100], Step [16600/6235], Loss: 44.3026\n",
      "Epoch [33/100], Step [16700/6235], Loss: 0.8612\n",
      "Epoch [33/100], Step [16800/6235], Loss: 8.6572\n",
      "Epoch [33/100], Step [16900/6235], Loss: 0.1591\n",
      "Epoch [33/100], Step [17000/6235], Loss: 0.3008\n",
      "Epoch [33/100], Step [17100/6235], Loss: 0.5121\n",
      "Epoch [33/100], Step [17200/6235], Loss: 301.5945\n",
      "Epoch [33/100], Step [17300/6235], Loss: 9.5209\n",
      "Epoch [33/100], Step [17400/6235], Loss: 32.9488\n",
      "Epoch [33/100], Step [17500/6235], Loss: 0.6118\n",
      "Epoch [33/100], Step [17600/6235], Loss: 3.1818\n",
      "Epoch [33/100], Step [17700/6235], Loss: 1.5950\n",
      "Epoch [33/100], Step [17800/6235], Loss: 41.6256\n",
      "Epoch [33/100], Step [17900/6235], Loss: 7.1144\n",
      "Epoch [33/100], Step [18000/6235], Loss: 11.4990\n",
      "Epoch [33/100], Step [18100/6235], Loss: 14.7951\n",
      "Epoch [33/100], Step [18200/6235], Loss: 0.4904\n",
      "Epoch [33/100], Step [18300/6235], Loss: 2.0759\n",
      "Epoch [33/100], Step [18400/6235], Loss: 1.0955\n",
      "Epoch [33/100], Step [18500/6235], Loss: 32.8507\n",
      "Epoch [33/100], Step [18600/6235], Loss: 3.0942\n",
      "Epoch [33/100], Step [18700/6235], Loss: 0.8675\n",
      "Epoch [33/100], Step [18800/6235], Loss: 165.7465\n",
      "Epoch [33/100], Step [18900/6235], Loss: 81.3338\n",
      "Epoch [33/100], Step [19000/6235], Loss: 13.2694\n",
      "Epoch [33/100], Step [19100/6235], Loss: 7.0720\n",
      "Epoch [33/100], Step [19200/6235], Loss: 3.4121\n",
      "Epoch [33/100], Step [19300/6235], Loss: 1.3270\n",
      "Epoch [33/100], Step [19400/6235], Loss: 273.3494\n",
      "Epoch [33/100], Step [19500/6235], Loss: 69.8611\n",
      "Epoch [33/100], Step [19600/6235], Loss: 74.0166\n",
      "Epoch [33/100], Step [19700/6235], Loss: 10.5016\n",
      "Epoch [33/100], Step [19800/6235], Loss: 8.0742\n",
      "Epoch [33/100], Step [19900/6235], Loss: 0.1269\n",
      "Epoch [33/100], Step [20000/6235], Loss: 68.3373\n",
      "Epoch [33/100], Step [20100/6235], Loss: 0.2925\n",
      "Epoch [33/100], Step [20200/6235], Loss: 5.5201\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Step [20300/6235], Loss: 2.6151\n",
      "Epoch [33/100], Step [20400/6235], Loss: 15.7351\n",
      "Epoch [33/100], Step [20500/6235], Loss: 50.5030\n",
      "Epoch [33/100], Step [20600/6235], Loss: 172.7882\n",
      "Epoch [33/100], Step [20700/6235], Loss: 30.5352\n",
      "Epoch [33/100], Step [20800/6235], Loss: 1.2775\n",
      "Epoch [33/100], Step [20900/6235], Loss: 0.1241\n",
      "Epoch [33/100], Step [21000/6235], Loss: 12.5926\n",
      "Epoch [33/100], Step [21100/6235], Loss: 6.5712\n",
      "Epoch [33/100], Step [21200/6235], Loss: 0.3342\n",
      "Epoch [33/100], Step [21300/6235], Loss: 0.0650\n",
      "Epoch [33/100], Step [21400/6235], Loss: 2.3680\n",
      "Epoch [33/100], Step [21500/6235], Loss: 0.7766\n",
      "Epoch [33/100], Step [21600/6235], Loss: 32.4440\n",
      "Epoch [33/100], Step [21700/6235], Loss: 0.6477\n",
      "Epoch [33/100], Step [21800/6235], Loss: 4.0137\n",
      "Epoch [33/100], Step [21900/6235], Loss: 1.7963\n",
      "Epoch [33/100], Step [22000/6235], Loss: 11.3370\n",
      "Epoch [33/100], Step [22100/6235], Loss: 0.1354\n",
      "Epoch [33/100], Step [22200/6235], Loss: 2.1826\n",
      "Epoch [33/100], Step [22300/6235], Loss: 2.3094\n",
      "Epoch [33/100], Step [22400/6235], Loss: 6.3109\n",
      "Epoch [33/100], Step [22500/6235], Loss: 58.0776\n",
      "Epoch [33/100], Step [22600/6235], Loss: 20.9162\n",
      "Epoch [33/100], Step [22700/6235], Loss: 1.6549\n",
      "Epoch [33/100], Step [22800/6235], Loss: 8.7232\n",
      "Epoch [33/100], Step [22900/6235], Loss: 18.9445\n",
      "Epoch [33/100], Step [23000/6235], Loss: 18.3558\n",
      "Epoch [33/100], Step [23100/6235], Loss: 3.6475\n",
      "Epoch [33/100], Step [23200/6235], Loss: 3.3160\n",
      "Epoch [33/100], Step [23300/6235], Loss: 20.9935\n",
      "Epoch [33/100], Step [23400/6235], Loss: 2.6935\n",
      "Epoch [33/100], Step [23500/6235], Loss: 0.3239\n",
      "Epoch [33/100], Step [23600/6235], Loss: 134.8035\n",
      "Epoch [33/100], Step [23700/6235], Loss: 3.4036\n",
      "Epoch [33/100], Step [23800/6235], Loss: 0.8583\n",
      "Epoch [33/100], Step [23900/6235], Loss: 0.4222\n",
      "Epoch [33/100], Step [24000/6235], Loss: 4.0236\n",
      "Epoch [33/100], Step [24100/6235], Loss: 3.5585\n",
      "Epoch [33/100], Step [24200/6235], Loss: 13.8940\n",
      "Epoch [33/100], Step [24300/6235], Loss: 0.8561\n",
      "Epoch [33/100], Step [24400/6235], Loss: 1.9158\n",
      "Epoch [33/100], Step [24500/6235], Loss: 2.1047\n",
      "Epoch [33/100], Step [24600/6235], Loss: 1.8379\n",
      "Epoch [33/100], Step [24700/6235], Loss: 0.2801\n",
      "Epoch [33/100], Step [24800/6235], Loss: 0.4966\n",
      "Epoch [33/100], Step [24900/6235], Loss: 7.7890\n",
      "Epoch [33/100], Step [25000/6235], Loss: 6.4326\n",
      "Epoch [33/100], Step [25100/6235], Loss: 9.8816\n",
      "Epoch [33/100], Step [25200/6235], Loss: 0.0532\n",
      "Epoch [33/100], Step [25300/6235], Loss: 2.9277\n",
      "Epoch [33/100], Step [25400/6235], Loss: 2.4810\n",
      "Epoch [33/100], Step [25500/6235], Loss: 9.4897\n",
      "Epoch [33/100], Step [25600/6235], Loss: 9.6129\n",
      "Epoch [33/100], Step [25700/6235], Loss: 0.2936\n",
      "Epoch [33/100], Step [25800/6235], Loss: 2.5759\n",
      "Epoch [33/100], Step [25900/6235], Loss: 1.2420\n",
      "Epoch [33/100], Step [26000/6235], Loss: 0.0992\n",
      "Epoch [33/100], Step [26100/6235], Loss: 0.2486\n",
      "Epoch [33/100], Step [26200/6235], Loss: 0.8749\n",
      "Epoch [33/100], Step [26300/6235], Loss: 0.0317\n",
      "Epoch [33/100], Step [26400/6235], Loss: 1.9893\n",
      "Epoch [33/100], Step [26500/6235], Loss: 0.0147\n",
      "Epoch [33/100], Step [26600/6235], Loss: 0.1119\n",
      "Epoch [33/100], Step [26700/6235], Loss: 0.0313\n",
      "Epoch [33/100], Step [26800/6235], Loss: 0.0855\n",
      "Epoch [33/100], Step [26900/6235], Loss: 0.1717\n",
      "Epoch [33/100], Step [27000/6235], Loss: 14.0435\n",
      "Epoch [33/100], Step [27100/6235], Loss: 0.1293\n",
      "Epoch [33/100], Step [27200/6235], Loss: 0.1216\n",
      "Epoch [33/100], Step [27300/6235], Loss: 0.0188\n",
      "Epoch [33/100], Step [27400/6235], Loss: 0.3517\n",
      "Epoch [33/100], Step [27500/6235], Loss: 0.3583\n",
      "Epoch [33/100], Step [27600/6235], Loss: 0.2081\n",
      "Epoch [33/100], Step [27700/6235], Loss: 0.8608\n",
      "Epoch [33/100], Step [27800/6235], Loss: 2.4504\n",
      "Epoch [33/100], Step [27900/6235], Loss: 1.4915\n",
      "Epoch [33/100], Step [28000/6235], Loss: 7.6704\n",
      "Epoch [33/100], Step [28100/6235], Loss: 2.7372\n",
      "Epoch [33/100], Step [28200/6235], Loss: 26.4110\n",
      "Epoch [33/100], Step [28300/6235], Loss: 0.0417\n",
      "Epoch [33/100], Step [28400/6235], Loss: 21.5840\n",
      "Epoch [33/100], Step [28500/6235], Loss: 1.9170\n",
      "Epoch [33/100], Step [28600/6235], Loss: 1.2006\n",
      "Epoch [33/100], Step [28700/6235], Loss: 2.5412\n",
      "Epoch [33/100], Step [28800/6235], Loss: 0.6878\n",
      "Epoch [33/100], Step [28900/6235], Loss: 37.1109\n",
      "Epoch [33/100], Step [29000/6235], Loss: 2.0542\n",
      "Epoch [33/100], Step [29100/6235], Loss: 0.2489\n",
      "Epoch [33/100], Step [29200/6235], Loss: 6.1344\n",
      "Epoch [33/100], Step [29300/6235], Loss: 13.0727\n",
      "Epoch [33/100], Step [29400/6235], Loss: 4.3209\n",
      "Epoch [33/100], Step [29500/6235], Loss: 1.0313\n",
      "Epoch [33/100], Step [29600/6235], Loss: 0.2072\n",
      "Epoch [33/100], Step [29700/6235], Loss: 3.0535\n",
      "Epoch [33/100], Step [29800/6235], Loss: 0.2671\n",
      "Epoch [33/100], Step [29900/6235], Loss: 1.7341\n",
      "Epoch [33/100], Step [30000/6235], Loss: 4.5455\n",
      "Epoch [33/100], Step [30100/6235], Loss: 7.8302\n",
      "Epoch [33/100], Step [30200/6235], Loss: 1.3542\n",
      "Epoch [33/100], Step [30300/6235], Loss: 0.1233\n",
      "Epoch [33/100], Step [30400/6235], Loss: 3.8067\n",
      "Epoch [33/100], Step [30500/6235], Loss: 0.1539\n",
      "Epoch [33/100], Step [30600/6235], Loss: 0.7563\n",
      "Epoch [33/100], Step [30700/6235], Loss: 3.1038\n",
      "Epoch [33/100], Step [30800/6235], Loss: 0.4301\n",
      "Epoch [33/100], Step [30900/6235], Loss: 0.8406\n",
      "Epoch [33/100], Step [31000/6235], Loss: 0.1368\n",
      "Epoch [33/100], Step [31100/6235], Loss: 1.4987\n",
      "Epoch [33/100], Step [31200/6235], Loss: 4.1203\n",
      "Epoch [33/100], Step [31300/6235], Loss: 1.4151\n",
      "Epoch [33/100], Step [31400/6235], Loss: 2.5505\n",
      "Epoch [33/100], Step [31500/6235], Loss: 0.7918\n",
      "Epoch [33/100], Step [31600/6235], Loss: 6.6230\n",
      "Epoch [33/100], Step [31700/6235], Loss: 0.5414\n",
      "Epoch [33/100], Step [31800/6235], Loss: 2.4631\n",
      "Epoch [33/100], Step [31900/6235], Loss: 1194.3145\n",
      "Epoch [33/100], Step [32000/6235], Loss: 7.2435\n",
      "Epoch [33/100], Step [32100/6235], Loss: 0.1275\n",
      "Epoch [33/100], Step [32200/6235], Loss: 54.5795\n",
      "Epoch [33/100], Step [32300/6235], Loss: 2.2024\n",
      "Epoch [33/100], Step [32400/6235], Loss: 1.4944\n",
      "Epoch [33/100], Step [32500/6235], Loss: 10.5223\n",
      "Epoch [33/100], Step [32600/6235], Loss: 0.3081\n",
      "Epoch [33/100], Step [32700/6235], Loss: 172.7792\n",
      "Epoch [33/100], Step [32800/6235], Loss: 2.5047\n",
      "Epoch [33/100], Step [32900/6235], Loss: 0.7653\n",
      "Epoch [33/100], Step [33000/6235], Loss: 0.8562\n",
      "Epoch [33/100], Step [33100/6235], Loss: 0.7282\n",
      "Epoch [33/100], Step [33200/6235], Loss: 1.2050\n",
      "Epoch [33/100], Step [33300/6235], Loss: 2.1477\n",
      "Epoch [33/100], Step [33400/6235], Loss: 10.1315\n",
      "Epoch [33/100], Step [33500/6235], Loss: 1.9645\n",
      "Epoch [33/100], Step [33600/6235], Loss: 6.9850\n",
      "Epoch [33/100], Step [33700/6235], Loss: 6.0236\n",
      "Epoch [33/100], Step [33800/6235], Loss: 0.4311\n",
      "Epoch [33/100], Step [33900/6235], Loss: 28.2528\n",
      "Epoch [33/100], Step [34000/6235], Loss: 0.0897\n",
      "Epoch [33/100], Step [34100/6235], Loss: 0.5984\n",
      "Epoch [33/100], Step [34200/6235], Loss: 2.2731\n",
      "Epoch [33/100], Step [34300/6235], Loss: 3.8195\n",
      "Epoch [33/100], Step [34400/6235], Loss: 0.1620\n",
      "Epoch [33/100], Step [34500/6235], Loss: 18.9044\n",
      "Epoch [33/100], Step [34600/6235], Loss: 1.8242\n",
      "Epoch [33/100], Step [34700/6235], Loss: 14.0917\n",
      "Epoch [33/100], Step [34800/6235], Loss: 13.8063\n",
      "Epoch [33/100], Step [34900/6235], Loss: 71.7795\n",
      "Epoch [33/100], Step [35000/6235], Loss: 0.3176\n",
      "Epoch [33/100], Step [35100/6235], Loss: 1.0052\n",
      "Epoch [33/100], Step [35200/6235], Loss: 0.5979\n",
      "Epoch [33/100], Step [35300/6235], Loss: 2.9180\n",
      "Epoch [33/100], Step [35400/6235], Loss: 0.6608\n",
      "Epoch [33/100], Step [35500/6235], Loss: 0.7062\n",
      "Epoch [33/100], Step [35600/6235], Loss: 8.8555\n",
      "Epoch [33/100], Step [35700/6235], Loss: 4.5121\n",
      "Epoch [33/100], Step [35800/6235], Loss: 2.2905\n",
      "Epoch [33/100], Step [35900/6235], Loss: 0.6688\n",
      "Epoch [33/100], Step [36000/6235], Loss: 0.5383\n",
      "Epoch [33/100], Step [36100/6235], Loss: 0.0414\n",
      "Epoch [33/100], Step [36200/6235], Loss: 17.1956\n",
      "Epoch [33/100], Step [36300/6235], Loss: 0.3887\n",
      "Epoch [33/100], Step [36400/6235], Loss: 3.0694\n",
      "Epoch [33/100], Step [36500/6235], Loss: 7.4491\n",
      "Epoch [33/100], Step [36600/6235], Loss: 0.0823\n",
      "Epoch [33/100], Step [36700/6235], Loss: 0.6033\n",
      "Epoch [33/100], Step [36800/6235], Loss: 4.8123\n",
      "Epoch [33/100], Step [36900/6235], Loss: 11.6848\n",
      "Epoch [33/100], Step [37000/6235], Loss: 0.9593\n",
      "Epoch [33/100], Step [37100/6235], Loss: 1.9319\n",
      "Epoch [33/100], Step [37200/6235], Loss: 0.0409\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [33/100], Step [37300/6235], Loss: 0.0449\n",
      "Epoch [33/100], Step [37400/6235], Loss: 0.1731\n",
      "Epoch [33/100], Step [37500/6235], Loss: 6.7719\n",
      "Epoch [33/100], Step [37600/6235], Loss: 12.2847\n",
      "Epoch [33/100], Step [37700/6235], Loss: 1.8262\n",
      "Epoch [33/100], Step [37800/6235], Loss: 7.4940\n",
      "Epoch [33/100], Step [37900/6235], Loss: 4.8087\n",
      "Epoch [33/100], Step [38000/6235], Loss: 0.9880\n",
      "Epoch [33/100], Step [38100/6235], Loss: 4.1432\n",
      "Epoch [33/100], Step [38200/6235], Loss: 1.7366\n",
      "Epoch [33/100], Step [38300/6235], Loss: 0.3083\n",
      "Epoch [33/100], Step [38400/6235], Loss: 0.0497\n",
      "Epoch [33/100], Step [38500/6235], Loss: 1.6753\n",
      "Epoch [33/100], Step [38600/6235], Loss: 0.4023\n",
      "Epoch [33/100], Step [38700/6235], Loss: 0.0424\n",
      "Epoch [33/100], Step [38800/6235], Loss: 0.1406\n",
      "Epoch [33/100], Step [38900/6235], Loss: 0.3748\n",
      "Epoch [33/100], Step [39000/6235], Loss: 20.3970\n",
      "Epoch [33/100], Step [39100/6235], Loss: 22.6927\n",
      "Epoch [33/100], Step [39200/6235], Loss: 0.6896\n",
      "Epoch [33/100], Step [39300/6235], Loss: 55.9308\n",
      "Epoch [33/100], Step [39400/6235], Loss: 360.9973\n",
      "Epoch [33/100], Step [39500/6235], Loss: 15.6387\n",
      "Epoch [33/100], Step [39600/6235], Loss: 20.2505\n",
      "Epoch [33/100], Step [39700/6235], Loss: 313.2196\n",
      "Epoch [33/100], Step [39800/6235], Loss: 145.5069\n",
      "Epoch [33/100], Step [39900/6235], Loss: 0.2993\n",
      "Epoch [33/100], Step [40000/6235], Loss: 7.8817\n",
      "Epoch [33/100], Step [40100/6235], Loss: 28.8035\n",
      "Epoch [33/100], Step [40200/6235], Loss: 3.6300\n",
      "Epoch [33/100], Step [40300/6235], Loss: 0.6505\n",
      "Epoch [33/100], Step [40400/6235], Loss: 2.7927\n",
      "Epoch [33/100], Step [40500/6235], Loss: 2.2279\n",
      "Epoch [33/100], Step [40600/6235], Loss: 0.3095\n",
      "Epoch [33/100], Step [40700/6235], Loss: 7.7909\n",
      "Epoch [33/100], Step [40800/6235], Loss: 1.9209\n",
      "Epoch [33/100], Step [40900/6235], Loss: 0.0600\n",
      "Epoch [33/100], Step [41000/6235], Loss: 41.3601\n",
      "Epoch [33/100], Step [41100/6235], Loss: 29.9774\n",
      "Epoch [33/100], Step [41200/6235], Loss: 9.9373\n",
      "Epoch [33/100], Step [41300/6235], Loss: 7.0493\n",
      "Epoch [33/100], Step [41400/6235], Loss: 2.2727\n",
      "Epoch [33/100], Step [41500/6235], Loss: 0.2691\n",
      "Epoch [33/100], Step [41600/6235], Loss: 0.5806\n",
      "Epoch [33/100], Step [41700/6235], Loss: 1.5577\n",
      "Epoch [33/100], Step [41800/6235], Loss: 0.3121\n",
      "Epoch [33/100], Step [41900/6235], Loss: 0.1519\n",
      "Epoch [33/100], Step [42000/6235], Loss: 4.2368\n",
      "Epoch [33/100], Step [42100/6235], Loss: 1.2976\n",
      "Epoch [33/100], Step [42200/6235], Loss: 60.8812\n",
      "Epoch [33/100], Step [42300/6235], Loss: 5.8459\n",
      "Epoch [33/100], Step [42400/6235], Loss: 0.3592\n",
      "Epoch [33/100], Step [42500/6235], Loss: 2.3070\n",
      "Epoch [33/100], Step [42600/6235], Loss: 0.4596\n",
      "Epoch [33/100], Step [42700/6235], Loss: 0.1684\n",
      "Epoch [33/100], Step [42800/6235], Loss: 0.0882\n",
      "Epoch [33/100], Step [42900/6235], Loss: 4.2005\n",
      "Epoch [33/100], Step [43000/6235], Loss: 0.1885\n",
      "Epoch [33/100], Step [43100/6235], Loss: 1.9665\n",
      "Epoch [33/100], Step [43200/6235], Loss: 0.4309\n",
      "Epoch [33/100], Step [43300/6235], Loss: 10.9914\n",
      "Epoch [33/100], Step [43400/6235], Loss: 6.4222\n",
      "Epoch [33/100], Step [43500/6235], Loss: 6.9434\n",
      "Epoch [33/100], Step [43600/6235], Loss: 35.1100\n",
      "Epoch [33/100], Step [43700/6235], Loss: 29.4848\n",
      "Epoch [33/100], Step [43800/6235], Loss: 0.2716\n",
      "Epoch [33/100], Step [43900/6235], Loss: 1.2916\n",
      "Epoch [33/100], Step [44000/6235], Loss: 46.3017\n",
      "Epoch [33/100], Step [44100/6235], Loss: 4.8924\n",
      "Epoch [33/100], Step [44200/6235], Loss: 2.1555\n",
      "Epoch [33/100], Step [44300/6235], Loss: 85.1603\n",
      "Epoch [33/100], Step [44400/6235], Loss: 4.9926\n",
      "Epoch [33/100], Step [44500/6235], Loss: 2.8431\n",
      "Epoch [33/100], Step [44600/6235], Loss: 29.4254\n",
      "Epoch [33/100], Step [44700/6235], Loss: 5.5278\n",
      "Epoch [33/100], Step [44800/6235], Loss: 2.9016\n",
      "Epoch [33/100], Step [44900/6235], Loss: 1.6457\n",
      "Epoch [33/100], Step [45000/6235], Loss: 5.1216\n",
      "Epoch [33/100], Step [45100/6235], Loss: 36.4130\n",
      "Epoch [33/100], Step [45200/6235], Loss: 0.5434\n",
      "Epoch [33/100], Step [45300/6235], Loss: 43.9047\n",
      "Epoch [33/100], Step [45400/6235], Loss: 10.6787\n",
      "Epoch [33/100], Step [45500/6235], Loss: 0.1310\n",
      "Epoch [33/100], Step [45600/6235], Loss: 0.1108\n",
      "Epoch [33/100], Step [45700/6235], Loss: 29.1699\n",
      "Epoch [33/100], Step [45800/6235], Loss: 203.5031\n",
      "Epoch [33/100], Step [45900/6235], Loss: 11.5997\n",
      "Epoch [33/100], Step [46000/6235], Loss: 38.9254\n",
      "Epoch [33/100], Step [46100/6235], Loss: 70.4696\n",
      "Epoch [33/100], Step [46200/6235], Loss: 11.4797\n",
      "Epoch [33/100], Step [46300/6235], Loss: 15.6202\n",
      "Epoch [33/100], Step [46400/6235], Loss: 11.0333\n",
      "Epoch [33/100], Step [46500/6235], Loss: 28.9416\n",
      "Epoch [33/100], Step [46600/6235], Loss: 25.5242\n",
      "Epoch [33/100], Step [46700/6235], Loss: 1.8789\n",
      "Epoch [33/100], Step [46800/6235], Loss: 31.2383\n",
      "Epoch [33/100], Step [46900/6235], Loss: 20.8067\n",
      "Epoch [33/100], Step [47000/6235], Loss: 0.7056\n",
      "Epoch [33/100], Step [47100/6235], Loss: 47.8978\n",
      "Epoch [33/100], Step [47200/6235], Loss: 74.3999\n",
      "Epoch [33/100], Step [47300/6235], Loss: 0.6762\n",
      "Epoch [33/100], Step [47400/6235], Loss: 112.0917\n",
      "Epoch [33/100], Step [47500/6235], Loss: 8.5742\n",
      "Epoch [33/100], Step [47600/6235], Loss: 12.0682\n",
      "Epoch [33/100], Step [47700/6235], Loss: 10.6416\n",
      "Epoch [33/100], Step [47800/6235], Loss: 10.9670\n",
      "Epoch [33/100], Step [47900/6235], Loss: 17.8468\n",
      "Epoch [33/100], Step [48000/6235], Loss: 2.2793\n",
      "Epoch [33/100], Step [48100/6235], Loss: 3.7469\n",
      "Epoch [33/100], Step [48200/6235], Loss: 24.5475\n",
      "Epoch [33/100], Step [48300/6235], Loss: 440.5871\n",
      "Epoch [33/100], Step [48400/6235], Loss: 20.7743\n",
      "Epoch [33/100], Step [48500/6235], Loss: 20.6004\n",
      "Epoch [33/100], Step [48600/6235], Loss: 167.3100\n",
      "Epoch [33/100], Step [48700/6235], Loss: 20.6380\n",
      "Epoch [33/100], Step [48800/6235], Loss: 232.6072\n",
      "Epoch [33/100], Step [48900/6235], Loss: 221.5449\n",
      "Epoch [33/100], Step [49000/6235], Loss: 143.5332\n",
      "Epoch [33/100], Step [49100/6235], Loss: 2807.9814\n",
      "Epoch [33/100], Step [49200/6235], Loss: 868.4998\n",
      "Epoch [33/100], Step [49300/6235], Loss: 1181.9519\n",
      "Epoch [33/100], Step [49400/6235], Loss: 2.5777\n",
      "Epoch [33/100], Step [49500/6235], Loss: 34.9884\n",
      "Epoch [33/100], Step [49600/6235], Loss: 886.5090\n",
      "Epoch [33/100], Step [49700/6235], Loss: 11146.0605\n",
      "Epoch [33/100], Step [49800/6235], Loss: 1509.7006\n",
      "Epoch [34/100], Step [100/6235], Loss: 35.8697\n",
      "Epoch [34/100], Step [200/6235], Loss: 0.1874\n",
      "Epoch [34/100], Step [300/6235], Loss: 0.0363\n",
      "Epoch [34/100], Step [400/6235], Loss: 0.0036\n",
      "Epoch [34/100], Step [500/6235], Loss: 19.2204\n",
      "Epoch [34/100], Step [600/6235], Loss: 0.0732\n",
      "Epoch [34/100], Step [700/6235], Loss: 1.1367\n",
      "Epoch [34/100], Step [800/6235], Loss: 0.0709\n",
      "Epoch [34/100], Step [900/6235], Loss: 0.1545\n",
      "Epoch [34/100], Step [1000/6235], Loss: 0.0361\n",
      "Epoch [34/100], Step [1100/6235], Loss: 0.1742\n",
      "Epoch [34/100], Step [1200/6235], Loss: 0.1639\n",
      "Epoch [34/100], Step [1300/6235], Loss: 0.0188\n",
      "Epoch [34/100], Step [1400/6235], Loss: 0.1126\n",
      "Epoch [34/100], Step [1500/6235], Loss: 0.0080\n",
      "Epoch [34/100], Step [1600/6235], Loss: 0.2523\n",
      "Epoch [34/100], Step [1700/6235], Loss: 0.1654\n",
      "Epoch [34/100], Step [1800/6235], Loss: 0.2555\n",
      "Epoch [34/100], Step [1900/6235], Loss: 0.2928\n",
      "Epoch [34/100], Step [2000/6235], Loss: 2.2455\n",
      "Epoch [34/100], Step [2100/6235], Loss: 2.7248\n",
      "Epoch [34/100], Step [2200/6235], Loss: 5.5819\n",
      "Epoch [34/100], Step [2300/6235], Loss: 0.2716\n",
      "Epoch [34/100], Step [2400/6235], Loss: 0.8946\n",
      "Epoch [34/100], Step [2500/6235], Loss: 19.9695\n",
      "Epoch [34/100], Step [2600/6235], Loss: 13.9179\n",
      "Epoch [34/100], Step [2700/6235], Loss: 8.0031\n",
      "Epoch [34/100], Step [2800/6235], Loss: 51.4961\n",
      "Epoch [34/100], Step [2900/6235], Loss: 17.1510\n",
      "Epoch [34/100], Step [3000/6235], Loss: 1.1484\n",
      "Epoch [34/100], Step [3100/6235], Loss: 65.6029\n",
      "Epoch [34/100], Step [3200/6235], Loss: 40.6800\n",
      "Epoch [34/100], Step [3300/6235], Loss: 10.0792\n",
      "Epoch [34/100], Step [3400/6235], Loss: 4.2299\n",
      "Epoch [34/100], Step [3500/6235], Loss: 57.4123\n",
      "Epoch [34/100], Step [3600/6235], Loss: 0.9679\n",
      "Epoch [34/100], Step [3700/6235], Loss: 0.0851\n",
      "Epoch [34/100], Step [3800/6235], Loss: 0.1104\n",
      "Epoch [34/100], Step [3900/6235], Loss: 0.1501\n",
      "Epoch [34/100], Step [4000/6235], Loss: 0.1250\n",
      "Epoch [34/100], Step [4100/6235], Loss: 9.9817\n",
      "Epoch [34/100], Step [4200/6235], Loss: 3.9884\n",
      "Epoch [34/100], Step [4300/6235], Loss: 5.2156\n",
      "Epoch [34/100], Step [4400/6235], Loss: 0.5666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Step [4500/6235], Loss: 59.9979\n",
      "Epoch [34/100], Step [4600/6235], Loss: 1.7037\n",
      "Epoch [34/100], Step [4700/6235], Loss: 0.1245\n",
      "Epoch [34/100], Step [4800/6235], Loss: 7.0952\n",
      "Epoch [34/100], Step [4900/6235], Loss: 1.7743\n",
      "Epoch [34/100], Step [5000/6235], Loss: 0.1022\n",
      "Epoch [34/100], Step [5100/6235], Loss: 3.8503\n",
      "Epoch [34/100], Step [5200/6235], Loss: 4.5074\n",
      "Epoch [34/100], Step [5300/6235], Loss: 23.3732\n",
      "Epoch [34/100], Step [5400/6235], Loss: 4.9438\n",
      "Epoch [34/100], Step [5500/6235], Loss: 0.2543\n",
      "Epoch [34/100], Step [5600/6235], Loss: 0.3208\n",
      "Epoch [34/100], Step [5700/6235], Loss: 0.1154\n",
      "Epoch [34/100], Step [5800/6235], Loss: 0.2118\n",
      "Epoch [34/100], Step [5900/6235], Loss: 0.2555\n",
      "Epoch [34/100], Step [6000/6235], Loss: 0.1370\n",
      "Epoch [34/100], Step [6100/6235], Loss: 0.1052\n",
      "Epoch [34/100], Step [6200/6235], Loss: 6.4745\n",
      "Epoch [34/100], Step [6300/6235], Loss: 0.4341\n",
      "Epoch [34/100], Step [6400/6235], Loss: 0.0944\n",
      "Epoch [34/100], Step [6500/6235], Loss: 2.2911\n",
      "Epoch [34/100], Step [6600/6235], Loss: 6.2154\n",
      "Epoch [34/100], Step [6700/6235], Loss: 1.0446\n",
      "Epoch [34/100], Step [6800/6235], Loss: 0.2793\n",
      "Epoch [34/100], Step [6900/6235], Loss: 0.5458\n",
      "Epoch [34/100], Step [7000/6235], Loss: 0.3654\n",
      "Epoch [34/100], Step [7100/6235], Loss: 0.3517\n",
      "Epoch [34/100], Step [7200/6235], Loss: 0.0904\n",
      "Epoch [34/100], Step [7300/6235], Loss: 1.8705\n",
      "Epoch [34/100], Step [7400/6235], Loss: 0.1326\n",
      "Epoch [34/100], Step [7500/6235], Loss: 0.0895\n",
      "Epoch [34/100], Step [7600/6235], Loss: 4.4335\n",
      "Epoch [34/100], Step [7700/6235], Loss: 12.3996\n",
      "Epoch [34/100], Step [7800/6235], Loss: 1.8169\n",
      "Epoch [34/100], Step [7900/6235], Loss: 4.1166\n",
      "Epoch [34/100], Step [8000/6235], Loss: 0.3958\n",
      "Epoch [34/100], Step [8100/6235], Loss: 1.0484\n",
      "Epoch [34/100], Step [8200/6235], Loss: 10.3692\n",
      "Epoch [34/100], Step [8300/6235], Loss: 14.4744\n",
      "Epoch [34/100], Step [8400/6235], Loss: 603.8578\n",
      "Epoch [34/100], Step [8500/6235], Loss: 18.1130\n",
      "Epoch [34/100], Step [8600/6235], Loss: 23.1434\n",
      "Epoch [34/100], Step [8700/6235], Loss: 32.2887\n",
      "Epoch [34/100], Step [8800/6235], Loss: 67.3982\n",
      "Epoch [34/100], Step [8900/6235], Loss: 263.1626\n",
      "Epoch [34/100], Step [9000/6235], Loss: 471.9345\n",
      "Epoch [34/100], Step [9100/6235], Loss: 102.9279\n",
      "Epoch [34/100], Step [9200/6235], Loss: 2513.8911\n",
      "Epoch [34/100], Step [9300/6235], Loss: 174.5014\n",
      "Epoch [34/100], Step [9400/6235], Loss: 799.8423\n",
      "Epoch [34/100], Step [9500/6235], Loss: 1787.6809\n",
      "Epoch [34/100], Step [9600/6235], Loss: 367.8661\n",
      "Epoch [34/100], Step [9700/6235], Loss: 2.0630\n",
      "Epoch [34/100], Step [9800/6235], Loss: 542.0765\n",
      "Epoch [34/100], Step [9900/6235], Loss: 156.3676\n",
      "Epoch [34/100], Step [10000/6235], Loss: 456.4477\n",
      "Epoch [34/100], Step [10100/6235], Loss: 2.0958\n",
      "Epoch [34/100], Step [10200/6235], Loss: 815.5366\n",
      "Epoch [34/100], Step [10300/6235], Loss: 3.5587\n",
      "Epoch [34/100], Step [10400/6235], Loss: 17.1156\n",
      "Epoch [34/100], Step [10500/6235], Loss: 22.2508\n",
      "Epoch [34/100], Step [10600/6235], Loss: 37.7015\n",
      "Epoch [34/100], Step [10700/6235], Loss: 269.8006\n",
      "Epoch [34/100], Step [10800/6235], Loss: 109.9916\n",
      "Epoch [34/100], Step [10900/6235], Loss: 7.8221\n",
      "Epoch [34/100], Step [11000/6235], Loss: 151.5946\n",
      "Epoch [34/100], Step [11100/6235], Loss: 0.5581\n",
      "Epoch [34/100], Step [11200/6235], Loss: 118.5283\n",
      "Epoch [34/100], Step [11300/6235], Loss: 243.9148\n",
      "Epoch [34/100], Step [11400/6235], Loss: 1.8032\n",
      "Epoch [34/100], Step [11500/6235], Loss: 1.0576\n",
      "Epoch [34/100], Step [11600/6235], Loss: 2.0112\n",
      "Epoch [34/100], Step [11700/6235], Loss: 50.8319\n",
      "Epoch [34/100], Step [11800/6235], Loss: 20.8456\n",
      "Epoch [34/100], Step [11900/6235], Loss: 195.8737\n",
      "Epoch [34/100], Step [12000/6235], Loss: 208.7963\n",
      "Epoch [34/100], Step [12100/6235], Loss: 198.2625\n",
      "Epoch [34/100], Step [12200/6235], Loss: 12.2750\n",
      "Epoch [34/100], Step [12300/6235], Loss: 7.2540\n",
      "Epoch [34/100], Step [12400/6235], Loss: 527.1011\n",
      "Epoch [34/100], Step [12500/6235], Loss: 28.7838\n",
      "Epoch [34/100], Step [12600/6235], Loss: 35.0120\n",
      "Epoch [34/100], Step [12700/6235], Loss: 0.9208\n",
      "Epoch [34/100], Step [12800/6235], Loss: 5.5146\n",
      "Epoch [34/100], Step [12900/6235], Loss: 47.7271\n",
      "Epoch [34/100], Step [13000/6235], Loss: 2.3065\n",
      "Epoch [34/100], Step [13100/6235], Loss: 84.2976\n",
      "Epoch [34/100], Step [13200/6235], Loss: 32.9329\n",
      "Epoch [34/100], Step [13300/6235], Loss: 24.5863\n",
      "Epoch [34/100], Step [13400/6235], Loss: 251.2885\n",
      "Epoch [34/100], Step [13500/6235], Loss: 1.2042\n",
      "Epoch [34/100], Step [13600/6235], Loss: 6.1089\n",
      "Epoch [34/100], Step [13700/6235], Loss: 207.0563\n",
      "Epoch [34/100], Step [13800/6235], Loss: 79.6391\n",
      "Epoch [34/100], Step [13900/6235], Loss: 98.1798\n",
      "Epoch [34/100], Step [14000/6235], Loss: 1.3381\n",
      "Epoch [34/100], Step [14100/6235], Loss: 38.6285\n",
      "Epoch [34/100], Step [14200/6235], Loss: 96.5340\n",
      "Epoch [34/100], Step [14300/6235], Loss: 89.1908\n",
      "Epoch [34/100], Step [14400/6235], Loss: 39.0752\n",
      "Epoch [34/100], Step [14500/6235], Loss: 27.6121\n",
      "Epoch [34/100], Step [14600/6235], Loss: 0.6950\n",
      "Epoch [34/100], Step [14700/6235], Loss: 34.6865\n",
      "Epoch [34/100], Step [14800/6235], Loss: 32.0838\n",
      "Epoch [34/100], Step [14900/6235], Loss: 0.9436\n",
      "Epoch [34/100], Step [15000/6235], Loss: 1.5800\n",
      "Epoch [34/100], Step [15100/6235], Loss: 0.5305\n",
      "Epoch [34/100], Step [15200/6235], Loss: 1.5579\n",
      "Epoch [34/100], Step [15300/6235], Loss: 11.5538\n",
      "Epoch [34/100], Step [15400/6235], Loss: 1.2188\n",
      "Epoch [34/100], Step [15500/6235], Loss: 18.1318\n",
      "Epoch [34/100], Step [15600/6235], Loss: 7.3985\n",
      "Epoch [34/100], Step [15700/6235], Loss: 256.8976\n",
      "Epoch [34/100], Step [15800/6235], Loss: 7.2908\n",
      "Epoch [34/100], Step [15900/6235], Loss: 0.4213\n",
      "Epoch [34/100], Step [16000/6235], Loss: 82.1365\n",
      "Epoch [34/100], Step [16100/6235], Loss: 11.7296\n",
      "Epoch [34/100], Step [16200/6235], Loss: 1.9583\n",
      "Epoch [34/100], Step [16300/6235], Loss: 12.3477\n",
      "Epoch [34/100], Step [16400/6235], Loss: 33.1439\n",
      "Epoch [34/100], Step [16500/6235], Loss: 177.9369\n",
      "Epoch [34/100], Step [16600/6235], Loss: 35.9006\n",
      "Epoch [34/100], Step [16700/6235], Loss: 0.2274\n",
      "Epoch [34/100], Step [16800/6235], Loss: 9.5215\n",
      "Epoch [34/100], Step [16900/6235], Loss: 0.5771\n",
      "Epoch [34/100], Step [17000/6235], Loss: 0.1937\n",
      "Epoch [34/100], Step [17100/6235], Loss: 0.0693\n",
      "Epoch [34/100], Step [17200/6235], Loss: 300.3113\n",
      "Epoch [34/100], Step [17300/6235], Loss: 14.2064\n",
      "Epoch [34/100], Step [17400/6235], Loss: 32.4431\n",
      "Epoch [34/100], Step [17500/6235], Loss: 1.3603\n",
      "Epoch [34/100], Step [17600/6235], Loss: 5.4523\n",
      "Epoch [34/100], Step [17700/6235], Loss: 23.7700\n",
      "Epoch [34/100], Step [17800/6235], Loss: 20.5195\n",
      "Epoch [34/100], Step [17900/6235], Loss: 6.4452\n",
      "Epoch [34/100], Step [18000/6235], Loss: 9.0655\n",
      "Epoch [34/100], Step [18100/6235], Loss: 18.8915\n",
      "Epoch [34/100], Step [18200/6235], Loss: 1.3286\n",
      "Epoch [34/100], Step [18300/6235], Loss: 2.2841\n",
      "Epoch [34/100], Step [18400/6235], Loss: 2.1810\n",
      "Epoch [34/100], Step [18500/6235], Loss: 9.8673\n",
      "Epoch [34/100], Step [18600/6235], Loss: 5.8440\n",
      "Epoch [34/100], Step [18700/6235], Loss: 1.7848\n",
      "Epoch [34/100], Step [18800/6235], Loss: 83.7359\n",
      "Epoch [34/100], Step [18900/6235], Loss: 34.0787\n",
      "Epoch [34/100], Step [19000/6235], Loss: 0.6382\n",
      "Epoch [34/100], Step [19100/6235], Loss: 7.9114\n",
      "Epoch [34/100], Step [19200/6235], Loss: 3.6638\n",
      "Epoch [34/100], Step [19300/6235], Loss: 1.1984\n",
      "Epoch [34/100], Step [19400/6235], Loss: 125.5250\n",
      "Epoch [34/100], Step [19500/6235], Loss: 94.7152\n",
      "Epoch [34/100], Step [19600/6235], Loss: 103.0374\n",
      "Epoch [34/100], Step [19700/6235], Loss: 10.2095\n",
      "Epoch [34/100], Step [19800/6235], Loss: 4.5114\n",
      "Epoch [34/100], Step [19900/6235], Loss: 0.1055\n",
      "Epoch [34/100], Step [20000/6235], Loss: 89.5667\n",
      "Epoch [34/100], Step [20100/6235], Loss: 0.6932\n",
      "Epoch [34/100], Step [20200/6235], Loss: 6.4997\n",
      "Epoch [34/100], Step [20300/6235], Loss: 1.2327\n",
      "Epoch [34/100], Step [20400/6235], Loss: 20.5286\n",
      "Epoch [34/100], Step [20500/6235], Loss: 46.8526\n",
      "Epoch [34/100], Step [20600/6235], Loss: 277.2514\n",
      "Epoch [34/100], Step [20700/6235], Loss: 23.1261\n",
      "Epoch [34/100], Step [20800/6235], Loss: 22.7324\n",
      "Epoch [34/100], Step [20900/6235], Loss: 25.4751\n",
      "Epoch [34/100], Step [21000/6235], Loss: 12.0890\n",
      "Epoch [34/100], Step [21100/6235], Loss: 6.5917\n",
      "Epoch [34/100], Step [21200/6235], Loss: 0.3424\n",
      "Epoch [34/100], Step [21300/6235], Loss: 0.0273\n",
      "Epoch [34/100], Step [21400/6235], Loss: 5.1049\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Step [21500/6235], Loss: 0.2255\n",
      "Epoch [34/100], Step [21600/6235], Loss: 28.0969\n",
      "Epoch [34/100], Step [21700/6235], Loss: 0.2281\n",
      "Epoch [34/100], Step [21800/6235], Loss: 2.0186\n",
      "Epoch [34/100], Step [21900/6235], Loss: 1.0739\n",
      "Epoch [34/100], Step [22000/6235], Loss: 7.1481\n",
      "Epoch [34/100], Step [22100/6235], Loss: 1.0500\n",
      "Epoch [34/100], Step [22200/6235], Loss: 6.8872\n",
      "Epoch [34/100], Step [22300/6235], Loss: 8.6300\n",
      "Epoch [34/100], Step [22400/6235], Loss: 8.7778\n",
      "Epoch [34/100], Step [22500/6235], Loss: 85.5667\n",
      "Epoch [34/100], Step [22600/6235], Loss: 25.7225\n",
      "Epoch [34/100], Step [22700/6235], Loss: 1.4134\n",
      "Epoch [34/100], Step [22800/6235], Loss: 3.8395\n",
      "Epoch [34/100], Step [22900/6235], Loss: 8.4750\n",
      "Epoch [34/100], Step [23000/6235], Loss: 16.0251\n",
      "Epoch [34/100], Step [23100/6235], Loss: 7.6336\n",
      "Epoch [34/100], Step [23200/6235], Loss: 6.5028\n",
      "Epoch [34/100], Step [23300/6235], Loss: 18.5199\n",
      "Epoch [34/100], Step [23400/6235], Loss: 1.5266\n",
      "Epoch [34/100], Step [23500/6235], Loss: 0.1679\n",
      "Epoch [34/100], Step [23600/6235], Loss: 127.7019\n",
      "Epoch [34/100], Step [23700/6235], Loss: 3.7815\n",
      "Epoch [34/100], Step [23800/6235], Loss: 1.0642\n",
      "Epoch [34/100], Step [23900/6235], Loss: 5.0297\n",
      "Epoch [34/100], Step [24000/6235], Loss: 0.3526\n",
      "Epoch [34/100], Step [24100/6235], Loss: 0.5985\n",
      "Epoch [34/100], Step [24200/6235], Loss: 30.0268\n",
      "Epoch [34/100], Step [24300/6235], Loss: 0.6167\n",
      "Epoch [34/100], Step [24400/6235], Loss: 0.0801\n",
      "Epoch [34/100], Step [24500/6235], Loss: 1.0860\n",
      "Epoch [34/100], Step [24600/6235], Loss: 0.0173\n",
      "Epoch [34/100], Step [24700/6235], Loss: 0.2359\n",
      "Epoch [34/100], Step [24800/6235], Loss: 0.4791\n",
      "Epoch [34/100], Step [24900/6235], Loss: 8.9695\n",
      "Epoch [34/100], Step [25000/6235], Loss: 11.1945\n",
      "Epoch [34/100], Step [25100/6235], Loss: 6.3059\n",
      "Epoch [34/100], Step [25200/6235], Loss: 0.0569\n",
      "Epoch [34/100], Step [25300/6235], Loss: 0.8692\n",
      "Epoch [34/100], Step [25400/6235], Loss: 9.7349\n",
      "Epoch [34/100], Step [25500/6235], Loss: 7.8319\n",
      "Epoch [34/100], Step [25600/6235], Loss: 5.8092\n",
      "Epoch [34/100], Step [25700/6235], Loss: 0.3305\n",
      "Epoch [34/100], Step [25800/6235], Loss: 0.0480\n",
      "Epoch [34/100], Step [25900/6235], Loss: 7.9065\n",
      "Epoch [34/100], Step [26000/6235], Loss: 3.1755\n",
      "Epoch [34/100], Step [26100/6235], Loss: 0.0256\n",
      "Epoch [34/100], Step [26200/6235], Loss: 1.3991\n",
      "Epoch [34/100], Step [26300/6235], Loss: 1.8560\n",
      "Epoch [34/100], Step [26400/6235], Loss: 0.3320\n",
      "Epoch [34/100], Step [26500/6235], Loss: 0.0315\n",
      "Epoch [34/100], Step [26600/6235], Loss: 0.6798\n",
      "Epoch [34/100], Step [26700/6235], Loss: 0.2085\n",
      "Epoch [34/100], Step [26800/6235], Loss: 0.1222\n",
      "Epoch [34/100], Step [26900/6235], Loss: 0.0337\n",
      "Epoch [34/100], Step [27000/6235], Loss: 16.0773\n",
      "Epoch [34/100], Step [27100/6235], Loss: 0.0483\n",
      "Epoch [34/100], Step [27200/6235], Loss: 0.0162\n",
      "Epoch [34/100], Step [27300/6235], Loss: 0.1175\n",
      "Epoch [34/100], Step [27400/6235], Loss: 0.6633\n",
      "Epoch [34/100], Step [27500/6235], Loss: 0.6848\n",
      "Epoch [34/100], Step [27600/6235], Loss: 0.4740\n",
      "Epoch [34/100], Step [27700/6235], Loss: 0.9669\n",
      "Epoch [34/100], Step [27800/6235], Loss: 3.6242\n",
      "Epoch [34/100], Step [27900/6235], Loss: 0.0795\n",
      "Epoch [34/100], Step [28000/6235], Loss: 101.4762\n",
      "Epoch [34/100], Step [28100/6235], Loss: 1.2549\n",
      "Epoch [34/100], Step [28200/6235], Loss: 38.8418\n",
      "Epoch [34/100], Step [28300/6235], Loss: 1.2049\n",
      "Epoch [34/100], Step [28400/6235], Loss: 25.1420\n",
      "Epoch [34/100], Step [28500/6235], Loss: 3.5404\n",
      "Epoch [34/100], Step [28600/6235], Loss: 1.1566\n",
      "Epoch [34/100], Step [28700/6235], Loss: 3.5311\n",
      "Epoch [34/100], Step [28800/6235], Loss: 0.6462\n",
      "Epoch [34/100], Step [28900/6235], Loss: 54.5730\n",
      "Epoch [34/100], Step [29000/6235], Loss: 1.5267\n",
      "Epoch [34/100], Step [29100/6235], Loss: 0.4780\n",
      "Epoch [34/100], Step [29200/6235], Loss: 3.8647\n",
      "Epoch [34/100], Step [29300/6235], Loss: 14.2853\n",
      "Epoch [34/100], Step [29400/6235], Loss: 0.4502\n",
      "Epoch [34/100], Step [29500/6235], Loss: 1.4227\n",
      "Epoch [34/100], Step [29600/6235], Loss: 0.6872\n",
      "Epoch [34/100], Step [29700/6235], Loss: 2.1244\n",
      "Epoch [34/100], Step [29800/6235], Loss: 1.1097\n",
      "Epoch [34/100], Step [29900/6235], Loss: 1.7512\n",
      "Epoch [34/100], Step [30000/6235], Loss: 3.5890\n",
      "Epoch [34/100], Step [30100/6235], Loss: 8.1279\n",
      "Epoch [34/100], Step [30200/6235], Loss: 1.7757\n",
      "Epoch [34/100], Step [30300/6235], Loss: 0.0665\n",
      "Epoch [34/100], Step [30400/6235], Loss: 1.9319\n",
      "Epoch [34/100], Step [30500/6235], Loss: 1.4187\n",
      "Epoch [34/100], Step [30600/6235], Loss: 1.5619\n",
      "Epoch [34/100], Step [30700/6235], Loss: 2.0584\n",
      "Epoch [34/100], Step [30800/6235], Loss: 0.5364\n",
      "Epoch [34/100], Step [30900/6235], Loss: 1.8879\n",
      "Epoch [34/100], Step [31000/6235], Loss: 0.3333\n",
      "Epoch [34/100], Step [31100/6235], Loss: 0.3079\n",
      "Epoch [34/100], Step [31200/6235], Loss: 6.0372\n",
      "Epoch [34/100], Step [31300/6235], Loss: 3.6744\n",
      "Epoch [34/100], Step [31400/6235], Loss: 0.2613\n",
      "Epoch [34/100], Step [31500/6235], Loss: 0.6905\n",
      "Epoch [34/100], Step [31600/6235], Loss: 4.3183\n",
      "Epoch [34/100], Step [31700/6235], Loss: 4.4714\n",
      "Epoch [34/100], Step [31800/6235], Loss: 1.3670\n",
      "Epoch [34/100], Step [31900/6235], Loss: 471.1026\n",
      "Epoch [34/100], Step [32000/6235], Loss: 1.8367\n",
      "Epoch [34/100], Step [32100/6235], Loss: 0.6160\n",
      "Epoch [34/100], Step [32200/6235], Loss: 131.1077\n",
      "Epoch [34/100], Step [32300/6235], Loss: 0.1780\n",
      "Epoch [34/100], Step [32400/6235], Loss: 1.0008\n",
      "Epoch [34/100], Step [32500/6235], Loss: 3.8674\n",
      "Epoch [34/100], Step [32600/6235], Loss: 0.0827\n",
      "Epoch [34/100], Step [32700/6235], Loss: 199.4613\n",
      "Epoch [34/100], Step [32800/6235], Loss: 5.9187\n",
      "Epoch [34/100], Step [32900/6235], Loss: 1.7902\n",
      "Epoch [34/100], Step [33000/6235], Loss: 0.5280\n",
      "Epoch [34/100], Step [33100/6235], Loss: 0.4830\n",
      "Epoch [34/100], Step [33200/6235], Loss: 0.6757\n",
      "Epoch [34/100], Step [33300/6235], Loss: 6.2807\n",
      "Epoch [34/100], Step [33400/6235], Loss: 1.9804\n",
      "Epoch [34/100], Step [33500/6235], Loss: 2.2494\n",
      "Epoch [34/100], Step [33600/6235], Loss: 1.5585\n",
      "Epoch [34/100], Step [33700/6235], Loss: 2.7364\n",
      "Epoch [34/100], Step [33800/6235], Loss: 1.0259\n",
      "Epoch [34/100], Step [33900/6235], Loss: 22.9048\n",
      "Epoch [34/100], Step [34000/6235], Loss: 0.0951\n",
      "Epoch [34/100], Step [34100/6235], Loss: 0.0315\n",
      "Epoch [34/100], Step [34200/6235], Loss: 12.6971\n",
      "Epoch [34/100], Step [34300/6235], Loss: 6.0367\n",
      "Epoch [34/100], Step [34400/6235], Loss: 0.0769\n",
      "Epoch [34/100], Step [34500/6235], Loss: 7.5566\n",
      "Epoch [34/100], Step [34600/6235], Loss: 1.8294\n",
      "Epoch [34/100], Step [34700/6235], Loss: 8.4732\n",
      "Epoch [34/100], Step [34800/6235], Loss: 9.9957\n",
      "Epoch [34/100], Step [34900/6235], Loss: 66.5584\n",
      "Epoch [34/100], Step [35000/6235], Loss: 0.1936\n",
      "Epoch [34/100], Step [35100/6235], Loss: 0.4831\n",
      "Epoch [34/100], Step [35200/6235], Loss: 0.6040\n",
      "Epoch [34/100], Step [35300/6235], Loss: 2.8458\n",
      "Epoch [34/100], Step [35400/6235], Loss: 0.5062\n",
      "Epoch [34/100], Step [35500/6235], Loss: 0.4104\n",
      "Epoch [34/100], Step [35600/6235], Loss: 2.4811\n",
      "Epoch [34/100], Step [35700/6235], Loss: 4.1398\n",
      "Epoch [34/100], Step [35800/6235], Loss: 0.7603\n",
      "Epoch [34/100], Step [35900/6235], Loss: 3.9057\n",
      "Epoch [34/100], Step [36000/6235], Loss: 0.2027\n",
      "Epoch [34/100], Step [36100/6235], Loss: 0.1309\n",
      "Epoch [34/100], Step [36200/6235], Loss: 49.0488\n",
      "Epoch [34/100], Step [36300/6235], Loss: 0.1090\n",
      "Epoch [34/100], Step [36400/6235], Loss: 2.4722\n",
      "Epoch [34/100], Step [36500/6235], Loss: 5.8430\n",
      "Epoch [34/100], Step [36600/6235], Loss: 0.0256\n",
      "Epoch [34/100], Step [36700/6235], Loss: 0.3869\n",
      "Epoch [34/100], Step [36800/6235], Loss: 0.5845\n",
      "Epoch [34/100], Step [36900/6235], Loss: 9.3541\n",
      "Epoch [34/100], Step [37000/6235], Loss: 1.0031\n",
      "Epoch [34/100], Step [37100/6235], Loss: 2.9906\n",
      "Epoch [34/100], Step [37200/6235], Loss: 0.0240\n",
      "Epoch [34/100], Step [37300/6235], Loss: 0.3428\n",
      "Epoch [34/100], Step [37400/6235], Loss: 0.1990\n",
      "Epoch [34/100], Step [37500/6235], Loss: 9.0164\n",
      "Epoch [34/100], Step [37600/6235], Loss: 11.1382\n",
      "Epoch [34/100], Step [37700/6235], Loss: 2.3567\n",
      "Epoch [34/100], Step [37800/6235], Loss: 1.4126\n",
      "Epoch [34/100], Step [37900/6235], Loss: 4.0102\n",
      "Epoch [34/100], Step [38000/6235], Loss: 0.8846\n",
      "Epoch [34/100], Step [38100/6235], Loss: 4.1116\n",
      "Epoch [34/100], Step [38200/6235], Loss: 2.8613\n",
      "Epoch [34/100], Step [38300/6235], Loss: 0.1887\n",
      "Epoch [34/100], Step [38400/6235], Loss: 0.1778\n",
      "Epoch [34/100], Step [38500/6235], Loss: 1.1912\n",
      "Epoch [34/100], Step [38600/6235], Loss: 0.5273\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [34/100], Step [38700/6235], Loss: 0.5604\n",
      "Epoch [34/100], Step [38800/6235], Loss: 0.1360\n",
      "Epoch [34/100], Step [38900/6235], Loss: 1.9847\n",
      "Epoch [34/100], Step [39000/6235], Loss: 0.2740\n",
      "Epoch [34/100], Step [39100/6235], Loss: 13.7543\n",
      "Epoch [34/100], Step [39200/6235], Loss: 1.0478\n",
      "Epoch [34/100], Step [39300/6235], Loss: 2.5941\n",
      "Epoch [34/100], Step [39400/6235], Loss: 318.1890\n",
      "Epoch [34/100], Step [39500/6235], Loss: 33.1596\n",
      "Epoch [34/100], Step [39600/6235], Loss: 8.7691\n",
      "Epoch [34/100], Step [39700/6235], Loss: 60.3356\n",
      "Epoch [34/100], Step [39800/6235], Loss: 169.2396\n",
      "Epoch [34/100], Step [39900/6235], Loss: 0.3891\n",
      "Epoch [34/100], Step [40000/6235], Loss: 17.1129\n",
      "Epoch [34/100], Step [40100/6235], Loss: 28.1151\n",
      "Epoch [34/100], Step [40200/6235], Loss: 3.4115\n",
      "Epoch [34/100], Step [40300/6235], Loss: 0.7624\n",
      "Epoch [34/100], Step [40400/6235], Loss: 2.8622\n",
      "Epoch [34/100], Step [40500/6235], Loss: 2.1161\n",
      "Epoch [34/100], Step [40600/6235], Loss: 0.4000\n",
      "Epoch [34/100], Step [40700/6235], Loss: 7.6440\n",
      "Epoch [34/100], Step [40800/6235], Loss: 2.1402\n",
      "Epoch [34/100], Step [40900/6235], Loss: 0.0736\n",
      "Epoch [34/100], Step [41000/6235], Loss: 40.2668\n",
      "Epoch [34/100], Step [41100/6235], Loss: 3.3653\n",
      "Epoch [34/100], Step [41200/6235], Loss: 5.6561\n",
      "Epoch [34/100], Step [41300/6235], Loss: 2.8479\n",
      "Epoch [34/100], Step [41400/6235], Loss: 0.7299\n",
      "Epoch [34/100], Step [41500/6235], Loss: 0.9862\n",
      "Epoch [34/100], Step [41600/6235], Loss: 0.4302\n",
      "Epoch [34/100], Step [41700/6235], Loss: 4.1949\n",
      "Epoch [34/100], Step [41800/6235], Loss: 4.3639\n",
      "Epoch [34/100], Step [41900/6235], Loss: 3.4401\n",
      "Epoch [34/100], Step [42000/6235], Loss: 3.1964\n",
      "Epoch [34/100], Step [42100/6235], Loss: 6.8093\n",
      "Epoch [34/100], Step [42200/6235], Loss: 5.3329\n",
      "Epoch [34/100], Step [42300/6235], Loss: 1.7308\n",
      "Epoch [34/100], Step [42400/6235], Loss: 4.9098\n",
      "Epoch [34/100], Step [42500/6235], Loss: 0.5078\n",
      "Epoch [34/100], Step [42600/6235], Loss: 1.0699\n",
      "Epoch [34/100], Step [42700/6235], Loss: 0.4439\n",
      "Epoch [34/100], Step [42800/6235], Loss: 2.7769\n",
      "Epoch [34/100], Step [42900/6235], Loss: 4.1010\n",
      "Epoch [34/100], Step [43000/6235], Loss: 0.2179\n",
      "Epoch [34/100], Step [43100/6235], Loss: 0.7498\n",
      "Epoch [34/100], Step [43200/6235], Loss: 0.8724\n",
      "Epoch [34/100], Step [43300/6235], Loss: 9.2989\n",
      "Epoch [34/100], Step [43400/6235], Loss: 10.4177\n",
      "Epoch [34/100], Step [43500/6235], Loss: 9.1330\n",
      "Epoch [34/100], Step [43600/6235], Loss: 23.2698\n",
      "Epoch [34/100], Step [43700/6235], Loss: 38.9240\n",
      "Epoch [34/100], Step [43800/6235], Loss: 0.5211\n",
      "Epoch [34/100], Step [43900/6235], Loss: 1.3742\n",
      "Epoch [34/100], Step [44000/6235], Loss: 61.8025\n",
      "Epoch [34/100], Step [44100/6235], Loss: 4.7604\n",
      "Epoch [34/100], Step [44200/6235], Loss: 34.5027\n",
      "Epoch [34/100], Step [44300/6235], Loss: 77.7399\n",
      "Epoch [34/100], Step [44400/6235], Loss: 5.1842\n",
      "Epoch [34/100], Step [44500/6235], Loss: 3.0413\n",
      "Epoch [34/100], Step [44600/6235], Loss: 22.2117\n",
      "Epoch [34/100], Step [44700/6235], Loss: 7.9442\n",
      "Epoch [34/100], Step [44800/6235], Loss: 1.0044\n",
      "Epoch [34/100], Step [44900/6235], Loss: 1.1845\n",
      "Epoch [34/100], Step [45000/6235], Loss: 4.4799\n",
      "Epoch [34/100], Step [45100/6235], Loss: 41.1065\n",
      "Epoch [34/100], Step [45200/6235], Loss: 0.3729\n",
      "Epoch [34/100], Step [45300/6235], Loss: 26.1599\n",
      "Epoch [34/100], Step [45400/6235], Loss: 6.7665\n",
      "Epoch [34/100], Step [45500/6235], Loss: 0.1598\n",
      "Epoch [34/100], Step [45600/6235], Loss: 0.2503\n",
      "Epoch [34/100], Step [45700/6235], Loss: 16.2687\n",
      "Epoch [34/100], Step [45800/6235], Loss: 240.3212\n",
      "Epoch [34/100], Step [45900/6235], Loss: 11.5331\n",
      "Epoch [34/100], Step [46000/6235], Loss: 0.4283\n",
      "Epoch [34/100], Step [46100/6235], Loss: 8.5137\n",
      "Epoch [34/100], Step [46200/6235], Loss: 11.4268\n",
      "Epoch [34/100], Step [46300/6235], Loss: 22.2187\n",
      "Epoch [34/100], Step [46400/6235], Loss: 7.6269\n",
      "Epoch [34/100], Step [46500/6235], Loss: 15.3073\n",
      "Epoch [34/100], Step [46600/6235], Loss: 19.7715\n",
      "Epoch [34/100], Step [46700/6235], Loss: 0.3020\n",
      "Epoch [34/100], Step [46800/6235], Loss: 20.0454\n",
      "Epoch [34/100], Step [46900/6235], Loss: 20.1582\n",
      "Epoch [34/100], Step [47000/6235], Loss: 0.7610\n",
      "Epoch [34/100], Step [47100/6235], Loss: 37.5791\n",
      "Epoch [34/100], Step [47200/6235], Loss: 44.7956\n",
      "Epoch [34/100], Step [47300/6235], Loss: 0.8353\n",
      "Epoch [34/100], Step [47400/6235], Loss: 62.3314\n",
      "Epoch [34/100], Step [47500/6235], Loss: 13.6086\n",
      "Epoch [34/100], Step [47600/6235], Loss: 10.6192\n",
      "Epoch [34/100], Step [47700/6235], Loss: 6.9985\n",
      "Epoch [34/100], Step [47800/6235], Loss: 9.2299\n",
      "Epoch [34/100], Step [47900/6235], Loss: 22.5737\n",
      "Epoch [34/100], Step [48000/6235], Loss: 3.3480\n",
      "Epoch [34/100], Step [48100/6235], Loss: 4.7043\n",
      "Epoch [34/100], Step [48200/6235], Loss: 12.3565\n",
      "Epoch [34/100], Step [48300/6235], Loss: 434.3142\n",
      "Epoch [34/100], Step [48400/6235], Loss: 14.8608\n",
      "Epoch [34/100], Step [48500/6235], Loss: 30.5659\n",
      "Epoch [34/100], Step [48600/6235], Loss: 156.4967\n",
      "Epoch [34/100], Step [48700/6235], Loss: 6.2151\n",
      "Epoch [34/100], Step [48800/6235], Loss: 596.1688\n",
      "Epoch [34/100], Step [48900/6235], Loss: 44.1653\n",
      "Epoch [34/100], Step [49000/6235], Loss: 252.2030\n",
      "Epoch [34/100], Step [49100/6235], Loss: 1411.2618\n",
      "Epoch [34/100], Step [49200/6235], Loss: 937.9358\n",
      "Epoch [34/100], Step [49300/6235], Loss: 1089.1113\n",
      "Epoch [34/100], Step [49400/6235], Loss: 95.9667\n",
      "Epoch [34/100], Step [49500/6235], Loss: 1.2587\n",
      "Epoch [34/100], Step [49600/6235], Loss: 200.6484\n",
      "Epoch [34/100], Step [49700/6235], Loss: 9997.7979\n",
      "Epoch [34/100], Step [49800/6235], Loss: 1443.5010\n",
      "Epoch [35/100], Step [100/6235], Loss: 2.5169\n",
      "Epoch [35/100], Step [200/6235], Loss: 0.1402\n",
      "Epoch [35/100], Step [300/6235], Loss: 0.0030\n",
      "Epoch [35/100], Step [400/6235], Loss: 0.0006\n",
      "Epoch [35/100], Step [500/6235], Loss: 0.1011\n",
      "Epoch [35/100], Step [600/6235], Loss: 0.0194\n",
      "Epoch [35/100], Step [700/6235], Loss: 0.5009\n",
      "Epoch [35/100], Step [800/6235], Loss: 0.1009\n",
      "Epoch [35/100], Step [900/6235], Loss: 0.0270\n",
      "Epoch [35/100], Step [1000/6235], Loss: 0.0261\n",
      "Epoch [35/100], Step [1100/6235], Loss: 0.0142\n",
      "Epoch [35/100], Step [1200/6235], Loss: 0.1764\n",
      "Epoch [35/100], Step [1300/6235], Loss: 0.0249\n",
      "Epoch [35/100], Step [1400/6235], Loss: 0.0364\n",
      "Epoch [35/100], Step [1500/6235], Loss: 0.0058\n",
      "Epoch [35/100], Step [1600/6235], Loss: 0.2251\n",
      "Epoch [35/100], Step [1700/6235], Loss: 0.0225\n",
      "Epoch [35/100], Step [1800/6235], Loss: 0.1955\n",
      "Epoch [35/100], Step [1900/6235], Loss: 0.3852\n",
      "Epoch [35/100], Step [2000/6235], Loss: 2.2131\n",
      "Epoch [35/100], Step [2100/6235], Loss: 1.2863\n",
      "Epoch [35/100], Step [2200/6235], Loss: 8.2169\n",
      "Epoch [35/100], Step [2300/6235], Loss: 5.9917\n",
      "Epoch [35/100], Step [2400/6235], Loss: 1.1608\n",
      "Epoch [35/100], Step [2500/6235], Loss: 33.0073\n",
      "Epoch [35/100], Step [2600/6235], Loss: 13.3224\n",
      "Epoch [35/100], Step [2700/6235], Loss: 5.5281\n",
      "Epoch [35/100], Step [2800/6235], Loss: 89.6059\n",
      "Epoch [35/100], Step [2900/6235], Loss: 17.0329\n",
      "Epoch [35/100], Step [3000/6235], Loss: 0.5698\n",
      "Epoch [35/100], Step [3100/6235], Loss: 70.0682\n",
      "Epoch [35/100], Step [3200/6235], Loss: 33.6258\n",
      "Epoch [35/100], Step [3300/6235], Loss: 7.8473\n",
      "Epoch [35/100], Step [3400/6235], Loss: 5.0163\n",
      "Epoch [35/100], Step [3500/6235], Loss: 54.9002\n",
      "Epoch [35/100], Step [3600/6235], Loss: 0.4928\n",
      "Epoch [35/100], Step [3700/6235], Loss: 0.0761\n",
      "Epoch [35/100], Step [3800/6235], Loss: 0.0947\n",
      "Epoch [35/100], Step [3900/6235], Loss: 0.1522\n",
      "Epoch [35/100], Step [4000/6235], Loss: 0.1449\n",
      "Epoch [35/100], Step [4100/6235], Loss: 9.8441\n",
      "Epoch [35/100], Step [4200/6235], Loss: 5.0851\n",
      "Epoch [35/100], Step [4300/6235], Loss: 5.0550\n",
      "Epoch [35/100], Step [4400/6235], Loss: 0.5207\n",
      "Epoch [35/100], Step [4500/6235], Loss: 39.6850\n",
      "Epoch [35/100], Step [4600/6235], Loss: 3.1032\n",
      "Epoch [35/100], Step [4700/6235], Loss: 0.0590\n",
      "Epoch [35/100], Step [4800/6235], Loss: 5.5846\n",
      "Epoch [35/100], Step [4900/6235], Loss: 3.1675\n",
      "Epoch [35/100], Step [5000/6235], Loss: 0.0825\n",
      "Epoch [35/100], Step [5100/6235], Loss: 0.1676\n",
      "Epoch [35/100], Step [5200/6235], Loss: 5.2148\n",
      "Epoch [35/100], Step [5300/6235], Loss: 17.5258\n",
      "Epoch [35/100], Step [5400/6235], Loss: 2.0894\n",
      "Epoch [35/100], Step [5500/6235], Loss: 0.1913\n",
      "Epoch [35/100], Step [5600/6235], Loss: 0.2939\n",
      "Epoch [35/100], Step [5700/6235], Loss: 0.0408\n",
      "Epoch [35/100], Step [5800/6235], Loss: 0.1688\n",
      "Epoch [35/100], Step [5900/6235], Loss: 0.0776\n",
      "Epoch [35/100], Step [6000/6235], Loss: 0.7405\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Step [6100/6235], Loss: 0.1573\n",
      "Epoch [35/100], Step [6200/6235], Loss: 7.6626\n",
      "Epoch [35/100], Step [6300/6235], Loss: 0.8240\n",
      "Epoch [35/100], Step [6400/6235], Loss: 0.0248\n",
      "Epoch [35/100], Step [6500/6235], Loss: 0.3287\n",
      "Epoch [35/100], Step [6600/6235], Loss: 7.6142\n",
      "Epoch [35/100], Step [6700/6235], Loss: 1.4891\n",
      "Epoch [35/100], Step [6800/6235], Loss: 0.5104\n",
      "Epoch [35/100], Step [6900/6235], Loss: 0.3718\n",
      "Epoch [35/100], Step [7000/6235], Loss: 0.0157\n",
      "Epoch [35/100], Step [7100/6235], Loss: 0.4744\n",
      "Epoch [35/100], Step [7200/6235], Loss: 0.8719\n",
      "Epoch [35/100], Step [7300/6235], Loss: 0.8499\n",
      "Epoch [35/100], Step [7400/6235], Loss: 0.0417\n",
      "Epoch [35/100], Step [7500/6235], Loss: 1.1879\n",
      "Epoch [35/100], Step [7600/6235], Loss: 3.1553\n",
      "Epoch [35/100], Step [7700/6235], Loss: 3.7130\n",
      "Epoch [35/100], Step [7800/6235], Loss: 5.1532\n",
      "Epoch [35/100], Step [7900/6235], Loss: 12.9340\n",
      "Epoch [35/100], Step [8000/6235], Loss: 0.3629\n",
      "Epoch [35/100], Step [8100/6235], Loss: 0.0527\n",
      "Epoch [35/100], Step [8200/6235], Loss: 10.4371\n",
      "Epoch [35/100], Step [8300/6235], Loss: 7.2021\n",
      "Epoch [35/100], Step [8400/6235], Loss: 458.8593\n",
      "Epoch [35/100], Step [8500/6235], Loss: 1.1492\n",
      "Epoch [35/100], Step [8600/6235], Loss: 126.2104\n",
      "Epoch [35/100], Step [8700/6235], Loss: 102.2513\n",
      "Epoch [35/100], Step [8800/6235], Loss: 492.0992\n",
      "Epoch [35/100], Step [8900/6235], Loss: 62.5562\n",
      "Epoch [35/100], Step [9000/6235], Loss: 360.3668\n",
      "Epoch [35/100], Step [9100/6235], Loss: 1181.9111\n",
      "Epoch [35/100], Step [9200/6235], Loss: 897.6911\n",
      "Epoch [35/100], Step [9300/6235], Loss: 18.5539\n",
      "Epoch [35/100], Step [9400/6235], Loss: 932.9222\n",
      "Epoch [35/100], Step [9500/6235], Loss: 1966.5288\n",
      "Epoch [35/100], Step [9600/6235], Loss: 409.6861\n",
      "Epoch [35/100], Step [9700/6235], Loss: 18.7614\n",
      "Epoch [35/100], Step [9800/6235], Loss: 21.1616\n",
      "Epoch [35/100], Step [9900/6235], Loss: 7.3515\n",
      "Epoch [35/100], Step [10000/6235], Loss: 410.6104\n",
      "Epoch [35/100], Step [10100/6235], Loss: 38.2123\n",
      "Epoch [35/100], Step [10200/6235], Loss: 1142.0746\n",
      "Epoch [35/100], Step [10300/6235], Loss: 35.6279\n",
      "Epoch [35/100], Step [10400/6235], Loss: 10.4485\n",
      "Epoch [35/100], Step [10500/6235], Loss: 4.0614\n",
      "Epoch [35/100], Step [10600/6235], Loss: 131.1779\n",
      "Epoch [35/100], Step [10700/6235], Loss: 14.3447\n",
      "Epoch [35/100], Step [10800/6235], Loss: 80.4151\n",
      "Epoch [35/100], Step [10900/6235], Loss: 70.9093\n",
      "Epoch [35/100], Step [11000/6235], Loss: 298.5151\n",
      "Epoch [35/100], Step [11100/6235], Loss: 41.1468\n",
      "Epoch [35/100], Step [11200/6235], Loss: 9.0608\n",
      "Epoch [35/100], Step [11300/6235], Loss: 112.6201\n",
      "Epoch [35/100], Step [11400/6235], Loss: 8.9267\n",
      "Epoch [35/100], Step [11500/6235], Loss: 5.4819\n",
      "Epoch [35/100], Step [11600/6235], Loss: 4.2686\n",
      "Epoch [35/100], Step [11700/6235], Loss: 40.5828\n",
      "Epoch [35/100], Step [11800/6235], Loss: 1.1809\n",
      "Epoch [35/100], Step [11900/6235], Loss: 70.1231\n",
      "Epoch [35/100], Step [12000/6235], Loss: 570.1461\n",
      "Epoch [35/100], Step [12100/6235], Loss: 197.6087\n",
      "Epoch [35/100], Step [12200/6235], Loss: 14.3362\n",
      "Epoch [35/100], Step [12300/6235], Loss: 7.1440\n",
      "Epoch [35/100], Step [12400/6235], Loss: 301.1926\n",
      "Epoch [35/100], Step [12500/6235], Loss: 83.0712\n",
      "Epoch [35/100], Step [12600/6235], Loss: 6.3376\n",
      "Epoch [35/100], Step [12700/6235], Loss: 0.9004\n",
      "Epoch [35/100], Step [12800/6235], Loss: 1.6918\n",
      "Epoch [35/100], Step [12900/6235], Loss: 33.4896\n",
      "Epoch [35/100], Step [13000/6235], Loss: 0.7850\n",
      "Epoch [35/100], Step [13100/6235], Loss: 63.5294\n",
      "Epoch [35/100], Step [13200/6235], Loss: 7.4842\n",
      "Epoch [35/100], Step [13300/6235], Loss: 15.4483\n",
      "Epoch [35/100], Step [13400/6235], Loss: 207.7052\n",
      "Epoch [35/100], Step [13500/6235], Loss: 4.0235\n",
      "Epoch [35/100], Step [13600/6235], Loss: 3.9174\n",
      "Epoch [35/100], Step [13700/6235], Loss: 209.2131\n",
      "Epoch [35/100], Step [13800/6235], Loss: 140.5835\n",
      "Epoch [35/100], Step [13900/6235], Loss: 148.6781\n",
      "Epoch [35/100], Step [14000/6235], Loss: 1.0668\n",
      "Epoch [35/100], Step [14100/6235], Loss: 57.8579\n",
      "Epoch [35/100], Step [14200/6235], Loss: 15.4193\n",
      "Epoch [35/100], Step [14300/6235], Loss: 2.9058\n",
      "Epoch [35/100], Step [14400/6235], Loss: 20.8026\n",
      "Epoch [35/100], Step [14500/6235], Loss: 22.9173\n",
      "Epoch [35/100], Step [14600/6235], Loss: 2.7211\n",
      "Epoch [35/100], Step [14700/6235], Loss: 11.2070\n",
      "Epoch [35/100], Step [14800/6235], Loss: 17.5789\n",
      "Epoch [35/100], Step [14900/6235], Loss: 0.8391\n",
      "Epoch [35/100], Step [15000/6235], Loss: 0.3675\n",
      "Epoch [35/100], Step [15100/6235], Loss: 0.0680\n",
      "Epoch [35/100], Step [15200/6235], Loss: 37.0901\n",
      "Epoch [35/100], Step [15300/6235], Loss: 35.2495\n",
      "Epoch [35/100], Step [15400/6235], Loss: 5.9638\n",
      "Epoch [35/100], Step [15500/6235], Loss: 10.2020\n",
      "Epoch [35/100], Step [15600/6235], Loss: 102.7326\n",
      "Epoch [35/100], Step [15700/6235], Loss: 114.8678\n",
      "Epoch [35/100], Step [15800/6235], Loss: 4.6828\n",
      "Epoch [35/100], Step [15900/6235], Loss: 2.9582\n",
      "Epoch [35/100], Step [16000/6235], Loss: 2.7250\n",
      "Epoch [35/100], Step [16100/6235], Loss: 4.1320\n",
      "Epoch [35/100], Step [16200/6235], Loss: 0.2400\n",
      "Epoch [35/100], Step [16300/6235], Loss: 10.3082\n",
      "Epoch [35/100], Step [16400/6235], Loss: 16.2027\n",
      "Epoch [35/100], Step [16500/6235], Loss: 78.5687\n",
      "Epoch [35/100], Step [16600/6235], Loss: 11.0940\n",
      "Epoch [35/100], Step [16700/6235], Loss: 1.2071\n",
      "Epoch [35/100], Step [16800/6235], Loss: 11.5374\n",
      "Epoch [35/100], Step [16900/6235], Loss: 0.3481\n",
      "Epoch [35/100], Step [17000/6235], Loss: 0.1821\n",
      "Epoch [35/100], Step [17100/6235], Loss: 0.0319\n",
      "Epoch [35/100], Step [17200/6235], Loss: 203.0538\n",
      "Epoch [35/100], Step [17300/6235], Loss: 69.3048\n",
      "Epoch [35/100], Step [17400/6235], Loss: 55.1564\n",
      "Epoch [35/100], Step [17500/6235], Loss: 1.2412\n",
      "Epoch [35/100], Step [17600/6235], Loss: 3.7026\n",
      "Epoch [35/100], Step [17700/6235], Loss: 18.9270\n",
      "Epoch [35/100], Step [17800/6235], Loss: 12.5528\n",
      "Epoch [35/100], Step [17900/6235], Loss: 6.6379\n",
      "Epoch [35/100], Step [18000/6235], Loss: 0.9756\n",
      "Epoch [35/100], Step [18100/6235], Loss: 14.3068\n",
      "Epoch [35/100], Step [18200/6235], Loss: 0.6066\n",
      "Epoch [35/100], Step [18300/6235], Loss: 1.7370\n",
      "Epoch [35/100], Step [18400/6235], Loss: 0.1967\n",
      "Epoch [35/100], Step [18500/6235], Loss: 8.2119\n",
      "Epoch [35/100], Step [18600/6235], Loss: 5.9240\n",
      "Epoch [35/100], Step [18700/6235], Loss: 0.9660\n",
      "Epoch [35/100], Step [18800/6235], Loss: 84.0739\n",
      "Epoch [35/100], Step [18900/6235], Loss: 44.1865\n",
      "Epoch [35/100], Step [19000/6235], Loss: 4.4698\n",
      "Epoch [35/100], Step [19100/6235], Loss: 27.0611\n",
      "Epoch [35/100], Step [19200/6235], Loss: 2.7572\n",
      "Epoch [35/100], Step [19300/6235], Loss: 8.8888\n",
      "Epoch [35/100], Step [19400/6235], Loss: 39.2174\n",
      "Epoch [35/100], Step [19500/6235], Loss: 114.9157\n",
      "Epoch [35/100], Step [19600/6235], Loss: 41.8832\n",
      "Epoch [35/100], Step [19700/6235], Loss: 8.2295\n",
      "Epoch [35/100], Step [19800/6235], Loss: 3.7211\n",
      "Epoch [35/100], Step [19900/6235], Loss: 0.1044\n",
      "Epoch [35/100], Step [20000/6235], Loss: 69.6286\n",
      "Epoch [35/100], Step [20100/6235], Loss: 2.5757\n",
      "Epoch [35/100], Step [20200/6235], Loss: 6.4667\n",
      "Epoch [35/100], Step [20300/6235], Loss: 2.5758\n",
      "Epoch [35/100], Step [20400/6235], Loss: 11.9576\n",
      "Epoch [35/100], Step [20500/6235], Loss: 55.4203\n",
      "Epoch [35/100], Step [20600/6235], Loss: 284.7182\n",
      "Epoch [35/100], Step [20700/6235], Loss: 30.6607\n",
      "Epoch [35/100], Step [20800/6235], Loss: 37.1250\n",
      "Epoch [35/100], Step [20900/6235], Loss: 32.9892\n",
      "Epoch [35/100], Step [21000/6235], Loss: 16.1138\n",
      "Epoch [35/100], Step [21100/6235], Loss: 7.7018\n",
      "Epoch [35/100], Step [21200/6235], Loss: 0.3453\n",
      "Epoch [35/100], Step [21300/6235], Loss: 0.1400\n",
      "Epoch [35/100], Step [21400/6235], Loss: 7.0200\n",
      "Epoch [35/100], Step [21500/6235], Loss: 0.5121\n",
      "Epoch [35/100], Step [21600/6235], Loss: 0.9306\n",
      "Epoch [35/100], Step [21700/6235], Loss: 2.1847\n",
      "Epoch [35/100], Step [21800/6235], Loss: 0.2256\n",
      "Epoch [35/100], Step [21900/6235], Loss: 0.4487\n",
      "Epoch [35/100], Step [22000/6235], Loss: 3.2442\n",
      "Epoch [35/100], Step [22100/6235], Loss: 4.1098\n",
      "Epoch [35/100], Step [22200/6235], Loss: 9.6326\n",
      "Epoch [35/100], Step [22300/6235], Loss: 0.1632\n",
      "Epoch [35/100], Step [22400/6235], Loss: 2.5170\n",
      "Epoch [35/100], Step [22500/6235], Loss: 114.2385\n",
      "Epoch [35/100], Step [22600/6235], Loss: 6.4744\n",
      "Epoch [35/100], Step [22700/6235], Loss: 0.3404\n",
      "Epoch [35/100], Step [22800/6235], Loss: 3.2936\n",
      "Epoch [35/100], Step [22900/6235], Loss: 5.7422\n",
      "Epoch [35/100], Step [23000/6235], Loss: 13.7851\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Step [23100/6235], Loss: 3.1896\n",
      "Epoch [35/100], Step [23200/6235], Loss: 11.9212\n",
      "Epoch [35/100], Step [23300/6235], Loss: 11.9909\n",
      "Epoch [35/100], Step [23400/6235], Loss: 0.8338\n",
      "Epoch [35/100], Step [23500/6235], Loss: 0.2473\n",
      "Epoch [35/100], Step [23600/6235], Loss: 121.0846\n",
      "Epoch [35/100], Step [23700/6235], Loss: 4.7692\n",
      "Epoch [35/100], Step [23800/6235], Loss: 1.0876\n",
      "Epoch [35/100], Step [23900/6235], Loss: 6.9438\n",
      "Epoch [35/100], Step [24000/6235], Loss: 0.1660\n",
      "Epoch [35/100], Step [24100/6235], Loss: 0.4947\n",
      "Epoch [35/100], Step [24200/6235], Loss: 40.0172\n",
      "Epoch [35/100], Step [24300/6235], Loss: 0.8829\n",
      "Epoch [35/100], Step [24400/6235], Loss: 0.9923\n",
      "Epoch [35/100], Step [24500/6235], Loss: 0.3451\n",
      "Epoch [35/100], Step [24600/6235], Loss: 1.4073\n",
      "Epoch [35/100], Step [24700/6235], Loss: 0.5211\n",
      "Epoch [35/100], Step [24800/6235], Loss: 0.2474\n",
      "Epoch [35/100], Step [24900/6235], Loss: 10.0881\n",
      "Epoch [35/100], Step [25000/6235], Loss: 14.1917\n",
      "Epoch [35/100], Step [25100/6235], Loss: 6.3071\n",
      "Epoch [35/100], Step [25200/6235], Loss: 0.2638\n",
      "Epoch [35/100], Step [25300/6235], Loss: 0.6749\n",
      "Epoch [35/100], Step [25400/6235], Loss: 7.1507\n",
      "Epoch [35/100], Step [25500/6235], Loss: 6.4660\n",
      "Epoch [35/100], Step [25600/6235], Loss: 3.3351\n",
      "Epoch [35/100], Step [25700/6235], Loss: 0.3923\n",
      "Epoch [35/100], Step [25800/6235], Loss: 0.0992\n",
      "Epoch [35/100], Step [25900/6235], Loss: 9.6052\n",
      "Epoch [35/100], Step [26000/6235], Loss: 1.2786\n",
      "Epoch [35/100], Step [26100/6235], Loss: 0.0918\n",
      "Epoch [35/100], Step [26200/6235], Loss: 0.9932\n",
      "Epoch [35/100], Step [26300/6235], Loss: 3.9804\n",
      "Epoch [35/100], Step [26400/6235], Loss: 0.1100\n",
      "Epoch [35/100], Step [26500/6235], Loss: 0.0083\n",
      "Epoch [35/100], Step [26600/6235], Loss: 1.4509\n",
      "Epoch [35/100], Step [26700/6235], Loss: 0.3366\n",
      "Epoch [35/100], Step [26800/6235], Loss: 0.1362\n",
      "Epoch [35/100], Step [26900/6235], Loss: 0.0049\n",
      "Epoch [35/100], Step [27000/6235], Loss: 15.1494\n",
      "Epoch [35/100], Step [27100/6235], Loss: 0.0503\n",
      "Epoch [35/100], Step [27200/6235], Loss: 0.0269\n",
      "Epoch [35/100], Step [27300/6235], Loss: 0.2175\n",
      "Epoch [35/100], Step [27400/6235], Loss: 0.7419\n",
      "Epoch [35/100], Step [27500/6235], Loss: 14.8383\n",
      "Epoch [35/100], Step [27600/6235], Loss: 0.6407\n",
      "Epoch [35/100], Step [27700/6235], Loss: 1.2092\n",
      "Epoch [35/100], Step [27800/6235], Loss: 5.5596\n",
      "Epoch [35/100], Step [27900/6235], Loss: 2.6185\n",
      "Epoch [35/100], Step [28000/6235], Loss: 38.8432\n",
      "Epoch [35/100], Step [28100/6235], Loss: 0.6561\n",
      "Epoch [35/100], Step [28200/6235], Loss: 25.5307\n",
      "Epoch [35/100], Step [28300/6235], Loss: 1.9546\n",
      "Epoch [35/100], Step [28400/6235], Loss: 26.2003\n",
      "Epoch [35/100], Step [28500/6235], Loss: 3.8102\n",
      "Epoch [35/100], Step [28600/6235], Loss: 1.0000\n",
      "Epoch [35/100], Step [28700/6235], Loss: 4.0220\n",
      "Epoch [35/100], Step [28800/6235], Loss: 0.6525\n",
      "Epoch [35/100], Step [28900/6235], Loss: 60.1087\n",
      "Epoch [35/100], Step [29000/6235], Loss: 5.9115\n",
      "Epoch [35/100], Step [29100/6235], Loss: 0.4783\n",
      "Epoch [35/100], Step [29200/6235], Loss: 2.9048\n",
      "Epoch [35/100], Step [29300/6235], Loss: 0.7421\n",
      "Epoch [35/100], Step [29400/6235], Loss: 1.4227\n",
      "Epoch [35/100], Step [29500/6235], Loss: 4.4468\n",
      "Epoch [35/100], Step [29600/6235], Loss: 0.4099\n",
      "Epoch [35/100], Step [29700/6235], Loss: 1.6516\n",
      "Epoch [35/100], Step [29800/6235], Loss: 1.3807\n",
      "Epoch [35/100], Step [29900/6235], Loss: 0.9178\n",
      "Epoch [35/100], Step [30000/6235], Loss: 7.1193\n",
      "Epoch [35/100], Step [30100/6235], Loss: 10.0748\n",
      "Epoch [35/100], Step [30200/6235], Loss: 1.4979\n",
      "Epoch [35/100], Step [30300/6235], Loss: 0.0568\n",
      "Epoch [35/100], Step [30400/6235], Loss: 1.5546\n",
      "Epoch [35/100], Step [30500/6235], Loss: 0.7009\n",
      "Epoch [35/100], Step [30600/6235], Loss: 0.4444\n",
      "Epoch [35/100], Step [30700/6235], Loss: 1.4822\n",
      "Epoch [35/100], Step [30800/6235], Loss: 0.5598\n",
      "Epoch [35/100], Step [30900/6235], Loss: 2.5753\n",
      "Epoch [35/100], Step [31000/6235], Loss: 0.3280\n",
      "Epoch [35/100], Step [31100/6235], Loss: 0.1131\n",
      "Epoch [35/100], Step [31200/6235], Loss: 4.7990\n",
      "Epoch [35/100], Step [31300/6235], Loss: 3.7918\n",
      "Epoch [35/100], Step [31400/6235], Loss: 0.5616\n",
      "Epoch [35/100], Step [31500/6235], Loss: 0.7447\n",
      "Epoch [35/100], Step [31600/6235], Loss: 5.4447\n",
      "Epoch [35/100], Step [31700/6235], Loss: 2.4910\n",
      "Epoch [35/100], Step [31800/6235], Loss: 1.1047\n",
      "Epoch [35/100], Step [31900/6235], Loss: 911.2621\n",
      "Epoch [35/100], Step [32000/6235], Loss: 46.7462\n",
      "Epoch [35/100], Step [32100/6235], Loss: 0.9201\n",
      "Epoch [35/100], Step [32200/6235], Loss: 143.4321\n",
      "Epoch [35/100], Step [32300/6235], Loss: 1.3437\n",
      "Epoch [35/100], Step [32400/6235], Loss: 0.7490\n",
      "Epoch [35/100], Step [32500/6235], Loss: 6.0372\n",
      "Epoch [35/100], Step [32600/6235], Loss: 0.0747\n",
      "Epoch [35/100], Step [32700/6235], Loss: 116.6827\n",
      "Epoch [35/100], Step [32800/6235], Loss: 37.4608\n",
      "Epoch [35/100], Step [32900/6235], Loss: 1.2301\n",
      "Epoch [35/100], Step [33000/6235], Loss: 0.3170\n",
      "Epoch [35/100], Step [33100/6235], Loss: 0.3509\n",
      "Epoch [35/100], Step [33200/6235], Loss: 1.1978\n",
      "Epoch [35/100], Step [33300/6235], Loss: 1.9070\n",
      "Epoch [35/100], Step [33400/6235], Loss: 74.6718\n",
      "Epoch [35/100], Step [33500/6235], Loss: 2.2893\n",
      "Epoch [35/100], Step [33600/6235], Loss: 8.7523\n",
      "Epoch [35/100], Step [33700/6235], Loss: 8.1909\n",
      "Epoch [35/100], Step [33800/6235], Loss: 0.3794\n",
      "Epoch [35/100], Step [33900/6235], Loss: 29.9773\n",
      "Epoch [35/100], Step [34000/6235], Loss: 0.1983\n",
      "Epoch [35/100], Step [34100/6235], Loss: 0.9773\n",
      "Epoch [35/100], Step [34200/6235], Loss: 2.0655\n",
      "Epoch [35/100], Step [34300/6235], Loss: 1.0252\n",
      "Epoch [35/100], Step [34400/6235], Loss: 0.1107\n",
      "Epoch [35/100], Step [34500/6235], Loss: 24.4533\n",
      "Epoch [35/100], Step [34600/6235], Loss: 3.0006\n",
      "Epoch [35/100], Step [34700/6235], Loss: 4.6713\n",
      "Epoch [35/100], Step [34800/6235], Loss: 12.5863\n",
      "Epoch [35/100], Step [34900/6235], Loss: 70.3395\n",
      "Epoch [35/100], Step [35000/6235], Loss: 0.4589\n",
      "Epoch [35/100], Step [35100/6235], Loss: 1.2308\n",
      "Epoch [35/100], Step [35200/6235], Loss: 0.5536\n",
      "Epoch [35/100], Step [35300/6235], Loss: 2.9168\n",
      "Epoch [35/100], Step [35400/6235], Loss: 0.5913\n",
      "Epoch [35/100], Step [35500/6235], Loss: 0.0990\n",
      "Epoch [35/100], Step [35600/6235], Loss: 7.4850\n",
      "Epoch [35/100], Step [35700/6235], Loss: 3.3587\n",
      "Epoch [35/100], Step [35800/6235], Loss: 0.1197\n",
      "Epoch [35/100], Step [35900/6235], Loss: 0.0918\n",
      "Epoch [35/100], Step [36000/6235], Loss: 0.2612\n",
      "Epoch [35/100], Step [36100/6235], Loss: 0.0782\n",
      "Epoch [35/100], Step [36200/6235], Loss: 26.2160\n",
      "Epoch [35/100], Step [36300/6235], Loss: 0.9654\n",
      "Epoch [35/100], Step [36400/6235], Loss: 2.8003\n",
      "Epoch [35/100], Step [36500/6235], Loss: 6.5482\n",
      "Epoch [35/100], Step [36600/6235], Loss: 0.0599\n",
      "Epoch [35/100], Step [36700/6235], Loss: 0.4516\n",
      "Epoch [35/100], Step [36800/6235], Loss: 1.0244\n",
      "Epoch [35/100], Step [36900/6235], Loss: 12.5477\n",
      "Epoch [35/100], Step [37000/6235], Loss: 1.0250\n",
      "Epoch [35/100], Step [37100/6235], Loss: 2.8158\n",
      "Epoch [35/100], Step [37200/6235], Loss: 0.0385\n",
      "Epoch [35/100], Step [37300/6235], Loss: 0.2335\n",
      "Epoch [35/100], Step [37400/6235], Loss: 0.1796\n",
      "Epoch [35/100], Step [37500/6235], Loss: 8.5672\n",
      "Epoch [35/100], Step [37600/6235], Loss: 11.4115\n",
      "Epoch [35/100], Step [37700/6235], Loss: 1.1806\n",
      "Epoch [35/100], Step [37800/6235], Loss: 3.1141\n",
      "Epoch [35/100], Step [37900/6235], Loss: 5.2746\n",
      "Epoch [35/100], Step [38000/6235], Loss: 0.9778\n",
      "Epoch [35/100], Step [38100/6235], Loss: 3.5280\n",
      "Epoch [35/100], Step [38200/6235], Loss: 2.6988\n",
      "Epoch [35/100], Step [38300/6235], Loss: 0.2424\n",
      "Epoch [35/100], Step [38400/6235], Loss: 0.2191\n",
      "Epoch [35/100], Step [38500/6235], Loss: 1.1681\n",
      "Epoch [35/100], Step [38600/6235], Loss: 0.8302\n",
      "Epoch [35/100], Step [38700/6235], Loss: 0.0758\n",
      "Epoch [35/100], Step [38800/6235], Loss: 0.0952\n",
      "Epoch [35/100], Step [38900/6235], Loss: 25.6569\n",
      "Epoch [35/100], Step [39000/6235], Loss: 6.3151\n",
      "Epoch [35/100], Step [39100/6235], Loss: 15.4147\n",
      "Epoch [35/100], Step [39200/6235], Loss: 0.3740\n",
      "Epoch [35/100], Step [39300/6235], Loss: 56.9607\n",
      "Epoch [35/100], Step [39400/6235], Loss: 74.9589\n",
      "Epoch [35/100], Step [39500/6235], Loss: 5.2477\n",
      "Epoch [35/100], Step [39600/6235], Loss: 23.2448\n",
      "Epoch [35/100], Step [39700/6235], Loss: 106.3794\n",
      "Epoch [35/100], Step [39800/6235], Loss: 135.6187\n",
      "Epoch [35/100], Step [39900/6235], Loss: 0.9580\n",
      "Epoch [35/100], Step [40000/6235], Loss: 14.2168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [35/100], Step [40100/6235], Loss: 30.0246\n",
      "Epoch [35/100], Step [40200/6235], Loss: 1.7062\n",
      "Epoch [35/100], Step [40300/6235], Loss: 1.0392\n",
      "Epoch [35/100], Step [40400/6235], Loss: 2.6293\n",
      "Epoch [35/100], Step [40500/6235], Loss: 2.3081\n",
      "Epoch [35/100], Step [40600/6235], Loss: 0.3385\n",
      "Epoch [35/100], Step [40700/6235], Loss: 7.6920\n",
      "Epoch [35/100], Step [40800/6235], Loss: 1.8486\n",
      "Epoch [35/100], Step [40900/6235], Loss: 0.0582\n",
      "Epoch [35/100], Step [41000/6235], Loss: 37.5003\n",
      "Epoch [35/100], Step [41100/6235], Loss: 11.7411\n",
      "Epoch [35/100], Step [41200/6235], Loss: 19.1137\n",
      "Epoch [35/100], Step [41300/6235], Loss: 3.1244\n",
      "Epoch [35/100], Step [41400/6235], Loss: 0.0233\n",
      "Epoch [35/100], Step [41500/6235], Loss: 0.5098\n",
      "Epoch [35/100], Step [41600/6235], Loss: 0.1786\n",
      "Epoch [35/100], Step [41700/6235], Loss: 0.9834\n",
      "Epoch [35/100], Step [41800/6235], Loss: 2.8117\n",
      "Epoch [35/100], Step [41900/6235], Loss: 3.8512\n",
      "Epoch [35/100], Step [42000/6235], Loss: 2.9772\n",
      "Epoch [35/100], Step [42100/6235], Loss: 6.9056\n",
      "Epoch [35/100], Step [42200/6235], Loss: 15.6183\n",
      "Epoch [35/100], Step [42300/6235], Loss: 1.8432\n",
      "Epoch [35/100], Step [42400/6235], Loss: 6.6326\n",
      "Epoch [35/100], Step [42500/6235], Loss: 1.2175\n",
      "Epoch [35/100], Step [42600/6235], Loss: 0.6882\n",
      "Epoch [35/100], Step [42700/6235], Loss: 0.3313\n",
      "Epoch [35/100], Step [42800/6235], Loss: 0.4125\n",
      "Epoch [35/100], Step [42900/6235], Loss: 4.2373\n",
      "Epoch [35/100], Step [43000/6235], Loss: 0.1832\n",
      "Epoch [35/100], Step [43100/6235], Loss: 1.4253\n",
      "Epoch [35/100], Step [43200/6235], Loss: 0.5573\n",
      "Epoch [35/100], Step [43300/6235], Loss: 10.0445\n",
      "Epoch [35/100], Step [43400/6235], Loss: 8.1229\n",
      "Epoch [35/100], Step [43500/6235], Loss: 8.6090\n",
      "Epoch [35/100], Step [43600/6235], Loss: 28.9741\n",
      "Epoch [35/100], Step [43700/6235], Loss: 38.3596\n",
      "Epoch [35/100], Step [43800/6235], Loss: 0.3057\n",
      "Epoch [35/100], Step [43900/6235], Loss: 1.1222\n",
      "Epoch [35/100], Step [44000/6235], Loss: 48.1257\n",
      "Epoch [35/100], Step [44100/6235], Loss: 5.1694\n",
      "Epoch [35/100], Step [44200/6235], Loss: 3.5335\n",
      "Epoch [35/100], Step [44300/6235], Loss: 66.0952\n",
      "Epoch [35/100], Step [44400/6235], Loss: 4.3677\n",
      "Epoch [35/100], Step [44500/6235], Loss: 2.8197\n",
      "Epoch [35/100], Step [44600/6235], Loss: 8.5570\n",
      "Epoch [35/100], Step [44700/6235], Loss: 2.0230\n",
      "Epoch [35/100], Step [44800/6235], Loss: 0.3821\n",
      "Epoch [35/100], Step [44900/6235], Loss: 0.9812\n",
      "Epoch [35/100], Step [45000/6235], Loss: 3.4502\n",
      "Epoch [35/100], Step [45100/6235], Loss: 24.4215\n",
      "Epoch [35/100], Step [45200/6235], Loss: 0.4959\n",
      "Epoch [35/100], Step [45300/6235], Loss: 4.6943\n",
      "Epoch [35/100], Step [45400/6235], Loss: 7.1660\n",
      "Epoch [35/100], Step [45500/6235], Loss: 0.1603\n",
      "Epoch [35/100], Step [45600/6235], Loss: 0.4465\n",
      "Epoch [35/100], Step [45700/6235], Loss: 16.7554\n",
      "Epoch [35/100], Step [45800/6235], Loss: 278.0911\n",
      "Epoch [35/100], Step [45900/6235], Loss: 7.1615\n",
      "Epoch [35/100], Step [46000/6235], Loss: 35.4020\n",
      "Epoch [35/100], Step [46100/6235], Loss: 12.0159\n",
      "Epoch [35/100], Step [46200/6235], Loss: 29.5150\n",
      "Epoch [35/100], Step [46300/6235], Loss: 181.8766\n",
      "Epoch [35/100], Step [46400/6235], Loss: 3.0740\n",
      "Epoch [35/100], Step [46500/6235], Loss: 21.4740\n",
      "Epoch [35/100], Step [46600/6235], Loss: 13.8025\n",
      "Epoch [35/100], Step [46700/6235], Loss: 2.2873\n",
      "Epoch [35/100], Step [46800/6235], Loss: 29.0365\n",
      "Epoch [35/100], Step [46900/6235], Loss: 22.8269\n",
      "Epoch [35/100], Step [47000/6235], Loss: 0.6066\n",
      "Epoch [35/100], Step [47100/6235], Loss: 60.7705\n",
      "Epoch [35/100], Step [47200/6235], Loss: 68.6227\n",
      "Epoch [35/100], Step [47300/6235], Loss: 0.6822\n",
      "Epoch [35/100], Step [47400/6235], Loss: 111.8933\n",
      "Epoch [35/100], Step [47500/6235], Loss: 2.2823\n",
      "Epoch [35/100], Step [47600/6235], Loss: 14.7526\n",
      "Epoch [35/100], Step [47700/6235], Loss: 11.2140\n",
      "Epoch [35/100], Step [47800/6235], Loss: 14.4195\n",
      "Epoch [35/100], Step [47900/6235], Loss: 19.2608\n",
      "Epoch [35/100], Step [48000/6235], Loss: 1.0541\n",
      "Epoch [35/100], Step [48100/6235], Loss: 4.5633\n",
      "Epoch [35/100], Step [48200/6235], Loss: 17.0607\n",
      "Epoch [35/100], Step [48300/6235], Loss: 517.1693\n",
      "Epoch [35/100], Step [48400/6235], Loss: 13.6877\n",
      "Epoch [35/100], Step [48500/6235], Loss: 37.1402\n",
      "Epoch [35/100], Step [48600/6235], Loss: 147.7627\n",
      "Epoch [35/100], Step [48700/6235], Loss: 3.6290\n",
      "Epoch [35/100], Step [48800/6235], Loss: 234.1194\n",
      "Epoch [35/100], Step [48900/6235], Loss: 19.4815\n",
      "Epoch [35/100], Step [49000/6235], Loss: 262.2605\n",
      "Epoch [35/100], Step [49100/6235], Loss: 2106.9592\n",
      "Epoch [35/100], Step [49200/6235], Loss: 766.1333\n",
      "Epoch [35/100], Step [49300/6235], Loss: 1201.0934\n",
      "Epoch [35/100], Step [49400/6235], Loss: 2.2355\n",
      "Epoch [35/100], Step [49500/6235], Loss: 16.7947\n",
      "Epoch [35/100], Step [49600/6235], Loss: 111.3631\n",
      "Epoch [35/100], Step [49700/6235], Loss: 7095.7383\n",
      "Epoch [35/100], Step [49800/6235], Loss: 2152.6814\n",
      "Epoch [36/100], Step [100/6235], Loss: 23.5287\n",
      "Epoch [36/100], Step [200/6235], Loss: 0.2407\n",
      "Epoch [36/100], Step [300/6235], Loss: 0.0084\n",
      "Epoch [36/100], Step [400/6235], Loss: 0.0017\n",
      "Epoch [36/100], Step [500/6235], Loss: 0.5349\n",
      "Epoch [36/100], Step [600/6235], Loss: 0.0229\n",
      "Epoch [36/100], Step [700/6235], Loss: 0.5999\n",
      "Epoch [36/100], Step [800/6235], Loss: 0.0413\n",
      "Epoch [36/100], Step [900/6235], Loss: 0.0721\n",
      "Epoch [36/100], Step [1000/6235], Loss: 0.0206\n",
      "Epoch [36/100], Step [1100/6235], Loss: 0.0659\n",
      "Epoch [36/100], Step [1200/6235], Loss: 0.1602\n",
      "Epoch [36/100], Step [1300/6235], Loss: 0.0098\n",
      "Epoch [36/100], Step [1400/6235], Loss: 0.1676\n",
      "Epoch [36/100], Step [1500/6235], Loss: 0.0085\n",
      "Epoch [36/100], Step [1600/6235], Loss: 0.2402\n",
      "Epoch [36/100], Step [1700/6235], Loss: 0.2179\n",
      "Epoch [36/100], Step [1800/6235], Loss: 0.2786\n",
      "Epoch [36/100], Step [1900/6235], Loss: 0.2851\n",
      "Epoch [36/100], Step [2000/6235], Loss: 2.1437\n",
      "Epoch [36/100], Step [2100/6235], Loss: 2.4564\n",
      "Epoch [36/100], Step [2200/6235], Loss: 4.9444\n",
      "Epoch [36/100], Step [2300/6235], Loss: 0.5389\n",
      "Epoch [36/100], Step [2400/6235], Loss: 1.7114\n",
      "Epoch [36/100], Step [2500/6235], Loss: 17.4542\n",
      "Epoch [36/100], Step [2600/6235], Loss: 15.6077\n",
      "Epoch [36/100], Step [2700/6235], Loss: 7.9848\n",
      "Epoch [36/100], Step [2800/6235], Loss: 85.1860\n",
      "Epoch [36/100], Step [2900/6235], Loss: 10.2089\n",
      "Epoch [36/100], Step [3000/6235], Loss: 0.2325\n",
      "Epoch [36/100], Step [3100/6235], Loss: 83.4835\n",
      "Epoch [36/100], Step [3200/6235], Loss: 22.4899\n",
      "Epoch [36/100], Step [3300/6235], Loss: 2.9500\n",
      "Epoch [36/100], Step [3400/6235], Loss: 6.8077\n",
      "Epoch [36/100], Step [3500/6235], Loss: 58.6313\n",
      "Epoch [36/100], Step [3600/6235], Loss: 0.2215\n",
      "Epoch [36/100], Step [3700/6235], Loss: 0.1415\n",
      "Epoch [36/100], Step [3800/6235], Loss: 0.1266\n",
      "Epoch [36/100], Step [3900/6235], Loss: 0.0723\n",
      "Epoch [36/100], Step [4000/6235], Loss: 0.2195\n",
      "Epoch [36/100], Step [4100/6235], Loss: 9.1499\n",
      "Epoch [36/100], Step [4200/6235], Loss: 5.6778\n",
      "Epoch [36/100], Step [4300/6235], Loss: 4.1193\n",
      "Epoch [36/100], Step [4400/6235], Loss: 0.1930\n",
      "Epoch [36/100], Step [4500/6235], Loss: 45.5081\n",
      "Epoch [36/100], Step [4600/6235], Loss: 7.7113\n",
      "Epoch [36/100], Step [4700/6235], Loss: 0.0900\n",
      "Epoch [36/100], Step [4800/6235], Loss: 3.3710\n",
      "Epoch [36/100], Step [4900/6235], Loss: 4.5322\n",
      "Epoch [36/100], Step [5000/6235], Loss: 0.1650\n",
      "Epoch [36/100], Step [5100/6235], Loss: 0.9881\n",
      "Epoch [36/100], Step [5200/6235], Loss: 5.7094\n",
      "Epoch [36/100], Step [5300/6235], Loss: 11.5080\n",
      "Epoch [36/100], Step [5400/6235], Loss: 2.8843\n",
      "Epoch [36/100], Step [5500/6235], Loss: 0.0137\n",
      "Epoch [36/100], Step [5600/6235], Loss: 0.1737\n",
      "Epoch [36/100], Step [5700/6235], Loss: 0.0585\n",
      "Epoch [36/100], Step [5800/6235], Loss: 0.3591\n",
      "Epoch [36/100], Step [5900/6235], Loss: 0.0251\n",
      "Epoch [36/100], Step [6000/6235], Loss: 1.7682\n",
      "Epoch [36/100], Step [6100/6235], Loss: 0.0845\n",
      "Epoch [36/100], Step [6200/6235], Loss: 7.3156\n",
      "Epoch [36/100], Step [6300/6235], Loss: 0.9049\n",
      "Epoch [36/100], Step [6400/6235], Loss: 0.0197\n",
      "Epoch [36/100], Step [6500/6235], Loss: 0.4624\n",
      "Epoch [36/100], Step [6600/6235], Loss: 5.3481\n",
      "Epoch [36/100], Step [6700/6235], Loss: 1.0758\n",
      "Epoch [36/100], Step [6800/6235], Loss: 0.2580\n",
      "Epoch [36/100], Step [6900/6235], Loss: 0.2668\n",
      "Epoch [36/100], Step [7000/6235], Loss: 0.0163\n",
      "Epoch [36/100], Step [7100/6235], Loss: 0.4774\n",
      "Epoch [36/100], Step [7200/6235], Loss: 1.0787\n",
      "Epoch [36/100], Step [7300/6235], Loss: 0.7021\n",
      "Epoch [36/100], Step [7400/6235], Loss: 0.0525\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Step [7500/6235], Loss: 0.8252\n",
      "Epoch [36/100], Step [7600/6235], Loss: 5.5375\n",
      "Epoch [36/100], Step [7700/6235], Loss: 8.2805\n",
      "Epoch [36/100], Step [7800/6235], Loss: 2.8510\n",
      "Epoch [36/100], Step [7900/6235], Loss: 6.6488\n",
      "Epoch [36/100], Step [8000/6235], Loss: 0.6309\n",
      "Epoch [36/100], Step [8100/6235], Loss: 0.3161\n",
      "Epoch [36/100], Step [8200/6235], Loss: 10.3093\n",
      "Epoch [36/100], Step [8300/6235], Loss: 17.9481\n",
      "Epoch [36/100], Step [8400/6235], Loss: 651.1929\n",
      "Epoch [36/100], Step [8500/6235], Loss: 15.2200\n",
      "Epoch [36/100], Step [8600/6235], Loss: 30.7658\n",
      "Epoch [36/100], Step [8700/6235], Loss: 38.5231\n",
      "Epoch [36/100], Step [8800/6235], Loss: 569.9079\n",
      "Epoch [36/100], Step [8900/6235], Loss: 240.0020\n",
      "Epoch [36/100], Step [9000/6235], Loss: 529.7293\n",
      "Epoch [36/100], Step [9100/6235], Loss: 852.6921\n",
      "Epoch [36/100], Step [9200/6235], Loss: 511.4460\n",
      "Epoch [36/100], Step [9300/6235], Loss: 260.7111\n",
      "Epoch [36/100], Step [9400/6235], Loss: 75.1013\n",
      "Epoch [36/100], Step [9500/6235], Loss: 2322.1912\n",
      "Epoch [36/100], Step [9600/6235], Loss: 449.0150\n",
      "Epoch [36/100], Step [9700/6235], Loss: 6.9040\n",
      "Epoch [36/100], Step [9800/6235], Loss: 26.3954\n",
      "Epoch [36/100], Step [9900/6235], Loss: 284.1126\n",
      "Epoch [36/100], Step [10000/6235], Loss: 856.1099\n",
      "Epoch [36/100], Step [10100/6235], Loss: 1.3882\n",
      "Epoch [36/100], Step [10200/6235], Loss: 44.6096\n",
      "Epoch [36/100], Step [10300/6235], Loss: 46.2220\n",
      "Epoch [36/100], Step [10400/6235], Loss: 3.1528\n",
      "Epoch [36/100], Step [10500/6235], Loss: 11.9131\n",
      "Epoch [36/100], Step [10600/6235], Loss: 107.1260\n",
      "Epoch [36/100], Step [10700/6235], Loss: 249.5404\n",
      "Epoch [36/100], Step [10800/6235], Loss: 2.5568\n",
      "Epoch [36/100], Step [10900/6235], Loss: 7.7137\n",
      "Epoch [36/100], Step [11000/6235], Loss: 184.5803\n",
      "Epoch [36/100], Step [11100/6235], Loss: 5.7202\n",
      "Epoch [36/100], Step [11200/6235], Loss: 108.2495\n",
      "Epoch [36/100], Step [11300/6235], Loss: 237.2840\n",
      "Epoch [36/100], Step [11400/6235], Loss: 14.3561\n",
      "Epoch [36/100], Step [11500/6235], Loss: 1.6512\n",
      "Epoch [36/100], Step [11600/6235], Loss: 4.2032\n",
      "Epoch [36/100], Step [11700/6235], Loss: 73.9746\n",
      "Epoch [36/100], Step [11800/6235], Loss: 5.5891\n",
      "Epoch [36/100], Step [11900/6235], Loss: 142.9849\n",
      "Epoch [36/100], Step [12000/6235], Loss: 392.0066\n",
      "Epoch [36/100], Step [12100/6235], Loss: 398.6477\n",
      "Epoch [36/100], Step [12200/6235], Loss: 163.7281\n",
      "Epoch [36/100], Step [12300/6235], Loss: 47.5838\n",
      "Epoch [36/100], Step [12400/6235], Loss: 676.3579\n",
      "Epoch [36/100], Step [12500/6235], Loss: 61.5430\n",
      "Epoch [36/100], Step [12600/6235], Loss: 36.5346\n",
      "Epoch [36/100], Step [12700/6235], Loss: 5.0898\n",
      "Epoch [36/100], Step [12800/6235], Loss: 12.3714\n",
      "Epoch [36/100], Step [12900/6235], Loss: 34.9373\n",
      "Epoch [36/100], Step [13000/6235], Loss: 1.2941\n",
      "Epoch [36/100], Step [13100/6235], Loss: 73.4798\n",
      "Epoch [36/100], Step [13200/6235], Loss: 18.3243\n",
      "Epoch [36/100], Step [13300/6235], Loss: 18.9227\n",
      "Epoch [36/100], Step [13400/6235], Loss: 254.5977\n",
      "Epoch [36/100], Step [13500/6235], Loss: 4.1322\n",
      "Epoch [36/100], Step [13600/6235], Loss: 10.2565\n",
      "Epoch [36/100], Step [13700/6235], Loss: 196.2034\n",
      "Epoch [36/100], Step [13800/6235], Loss: 73.9419\n",
      "Epoch [36/100], Step [13900/6235], Loss: 44.6484\n",
      "Epoch [36/100], Step [14000/6235], Loss: 1.6117\n",
      "Epoch [36/100], Step [14100/6235], Loss: 42.4342\n",
      "Epoch [36/100], Step [14200/6235], Loss: 132.6417\n",
      "Epoch [36/100], Step [14300/6235], Loss: 82.6946\n",
      "Epoch [36/100], Step [14400/6235], Loss: 38.7910\n",
      "Epoch [36/100], Step [14500/6235], Loss: 22.3253\n",
      "Epoch [36/100], Step [14600/6235], Loss: 1.6119\n",
      "Epoch [36/100], Step [14700/6235], Loss: 28.6005\n",
      "Epoch [36/100], Step [14800/6235], Loss: 29.3951\n",
      "Epoch [36/100], Step [14900/6235], Loss: 0.8210\n",
      "Epoch [36/100], Step [15000/6235], Loss: 1.3954\n",
      "Epoch [36/100], Step [15100/6235], Loss: 0.5575\n",
      "Epoch [36/100], Step [15200/6235], Loss: 0.1648\n",
      "Epoch [36/100], Step [15300/6235], Loss: 19.2091\n",
      "Epoch [36/100], Step [15400/6235], Loss: 12.3494\n",
      "Epoch [36/100], Step [15500/6235], Loss: 1.5410\n",
      "Epoch [36/100], Step [15600/6235], Loss: 69.5718\n",
      "Epoch [36/100], Step [15700/6235], Loss: 334.8817\n",
      "Epoch [36/100], Step [15800/6235], Loss: 9.9943\n",
      "Epoch [36/100], Step [15900/6235], Loss: 0.4435\n",
      "Epoch [36/100], Step [16000/6235], Loss: 35.0572\n",
      "Epoch [36/100], Step [16100/6235], Loss: 1.3598\n",
      "Epoch [36/100], Step [16200/6235], Loss: 0.6062\n",
      "Epoch [36/100], Step [16300/6235], Loss: 9.6580\n",
      "Epoch [36/100], Step [16400/6235], Loss: 29.5969\n",
      "Epoch [36/100], Step [16500/6235], Loss: 611.4940\n",
      "Epoch [36/100], Step [16600/6235], Loss: 32.2684\n",
      "Epoch [36/100], Step [16700/6235], Loss: 0.2958\n",
      "Epoch [36/100], Step [16800/6235], Loss: 10.3490\n",
      "Epoch [36/100], Step [16900/6235], Loss: 0.5524\n",
      "Epoch [36/100], Step [17000/6235], Loss: 0.1788\n",
      "Epoch [36/100], Step [17100/6235], Loss: 0.0918\n",
      "Epoch [36/100], Step [17200/6235], Loss: 250.1434\n",
      "Epoch [36/100], Step [17300/6235], Loss: 3.3496\n",
      "Epoch [36/100], Step [17400/6235], Loss: 28.6650\n",
      "Epoch [36/100], Step [17500/6235], Loss: 1.0738\n",
      "Epoch [36/100], Step [17600/6235], Loss: 4.4370\n",
      "Epoch [36/100], Step [17700/6235], Loss: 24.7435\n",
      "Epoch [36/100], Step [17800/6235], Loss: 9.6219\n",
      "Epoch [36/100], Step [17900/6235], Loss: 10.6936\n",
      "Epoch [36/100], Step [18000/6235], Loss: 1.8046\n",
      "Epoch [36/100], Step [18100/6235], Loss: 19.7014\n",
      "Epoch [36/100], Step [18200/6235], Loss: 0.7750\n",
      "Epoch [36/100], Step [18300/6235], Loss: 2.9937\n",
      "Epoch [36/100], Step [18400/6235], Loss: 4.1503\n",
      "Epoch [36/100], Step [18500/6235], Loss: 31.1023\n",
      "Epoch [36/100], Step [18600/6235], Loss: 7.2467\n",
      "Epoch [36/100], Step [18700/6235], Loss: 2.3479\n",
      "Epoch [36/100], Step [18800/6235], Loss: 68.4074\n",
      "Epoch [36/100], Step [18900/6235], Loss: 13.6583\n",
      "Epoch [36/100], Step [19000/6235], Loss: 0.6202\n",
      "Epoch [36/100], Step [19100/6235], Loss: 5.9045\n",
      "Epoch [36/100], Step [19200/6235], Loss: 0.9812\n",
      "Epoch [36/100], Step [19300/6235], Loss: 0.5784\n",
      "Epoch [36/100], Step [19400/6235], Loss: 294.8090\n",
      "Epoch [36/100], Step [19500/6235], Loss: 40.5532\n",
      "Epoch [36/100], Step [19600/6235], Loss: 46.2985\n",
      "Epoch [36/100], Step [19700/6235], Loss: 3.9210\n",
      "Epoch [36/100], Step [19800/6235], Loss: 7.2883\n",
      "Epoch [36/100], Step [19900/6235], Loss: 0.0422\n",
      "Epoch [36/100], Step [20000/6235], Loss: 70.8601\n",
      "Epoch [36/100], Step [20100/6235], Loss: 2.1116\n",
      "Epoch [36/100], Step [20200/6235], Loss: 7.6723\n",
      "Epoch [36/100], Step [20300/6235], Loss: 2.6083\n",
      "Epoch [36/100], Step [20400/6235], Loss: 11.6945\n",
      "Epoch [36/100], Step [20500/6235], Loss: 59.2683\n",
      "Epoch [36/100], Step [20600/6235], Loss: 9.5949\n",
      "Epoch [36/100], Step [20700/6235], Loss: 4.7329\n",
      "Epoch [36/100], Step [20800/6235], Loss: 1.1017\n",
      "Epoch [36/100], Step [20900/6235], Loss: 17.4232\n",
      "Epoch [36/100], Step [21000/6235], Loss: 11.7209\n",
      "Epoch [36/100], Step [21100/6235], Loss: 6.7103\n",
      "Epoch [36/100], Step [21200/6235], Loss: 0.3019\n",
      "Epoch [36/100], Step [21300/6235], Loss: 0.2613\n",
      "Epoch [36/100], Step [21400/6235], Loss: 3.8371\n",
      "Epoch [36/100], Step [21500/6235], Loss: 0.1239\n",
      "Epoch [36/100], Step [21600/6235], Loss: 0.6949\n",
      "Epoch [36/100], Step [21700/6235], Loss: 14.0035\n",
      "Epoch [36/100], Step [21800/6235], Loss: 4.1658\n",
      "Epoch [36/100], Step [21900/6235], Loss: 0.0264\n",
      "Epoch [36/100], Step [22000/6235], Loss: 0.0416\n",
      "Epoch [36/100], Step [22100/6235], Loss: 7.6871\n",
      "Epoch [36/100], Step [22200/6235], Loss: 0.3092\n",
      "Epoch [36/100], Step [22300/6235], Loss: 2.7126\n",
      "Epoch [36/100], Step [22400/6235], Loss: 0.3598\n",
      "Epoch [36/100], Step [22500/6235], Loss: 53.8226\n",
      "Epoch [36/100], Step [22600/6235], Loss: 14.1243\n",
      "Epoch [36/100], Step [22700/6235], Loss: 1.9621\n",
      "Epoch [36/100], Step [22800/6235], Loss: 2.8174\n",
      "Epoch [36/100], Step [22900/6235], Loss: 6.2008\n",
      "Epoch [36/100], Step [23000/6235], Loss: 18.3306\n",
      "Epoch [36/100], Step [23100/6235], Loss: 8.5633\n",
      "Epoch [36/100], Step [23200/6235], Loss: 6.8992\n",
      "Epoch [36/100], Step [23300/6235], Loss: 16.4099\n",
      "Epoch [36/100], Step [23400/6235], Loss: 1.3346\n",
      "Epoch [36/100], Step [23500/6235], Loss: 0.2082\n",
      "Epoch [36/100], Step [23600/6235], Loss: 131.6980\n",
      "Epoch [36/100], Step [23700/6235], Loss: 2.2229\n",
      "Epoch [36/100], Step [23800/6235], Loss: 0.9476\n",
      "Epoch [36/100], Step [23900/6235], Loss: 6.0940\n",
      "Epoch [36/100], Step [24000/6235], Loss: 0.5771\n",
      "Epoch [36/100], Step [24100/6235], Loss: 0.4710\n",
      "Epoch [36/100], Step [24200/6235], Loss: 31.7522\n",
      "Epoch [36/100], Step [24300/6235], Loss: 0.5439\n",
      "Epoch [36/100], Step [24400/6235], Loss: 0.0616\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Step [24500/6235], Loss: 3.1036\n",
      "Epoch [36/100], Step [24600/6235], Loss: 0.0687\n",
      "Epoch [36/100], Step [24700/6235], Loss: 0.2732\n",
      "Epoch [36/100], Step [24800/6235], Loss: 0.3060\n",
      "Epoch [36/100], Step [24900/6235], Loss: 12.7051\n",
      "Epoch [36/100], Step [25000/6235], Loss: 14.0003\n",
      "Epoch [36/100], Step [25100/6235], Loss: 6.4070\n",
      "Epoch [36/100], Step [25200/6235], Loss: 0.0196\n",
      "Epoch [36/100], Step [25300/6235], Loss: 1.5026\n",
      "Epoch [36/100], Step [25400/6235], Loss: 4.8104\n",
      "Epoch [36/100], Step [25500/6235], Loss: 8.0354\n",
      "Epoch [36/100], Step [25600/6235], Loss: 6.3181\n",
      "Epoch [36/100], Step [25700/6235], Loss: 0.3089\n",
      "Epoch [36/100], Step [25800/6235], Loss: 0.1286\n",
      "Epoch [36/100], Step [25900/6235], Loss: 7.7394\n",
      "Epoch [36/100], Step [26000/6235], Loss: 2.7172\n",
      "Epoch [36/100], Step [26100/6235], Loss: 0.0500\n",
      "Epoch [36/100], Step [26200/6235], Loss: 1.4340\n",
      "Epoch [36/100], Step [26300/6235], Loss: 0.9405\n",
      "Epoch [36/100], Step [26400/6235], Loss: 0.6628\n",
      "Epoch [36/100], Step [26500/6235], Loss: 0.0461\n",
      "Epoch [36/100], Step [26600/6235], Loss: 0.3409\n",
      "Epoch [36/100], Step [26700/6235], Loss: 0.1325\n",
      "Epoch [36/100], Step [26800/6235], Loss: 0.0829\n",
      "Epoch [36/100], Step [26900/6235], Loss: 0.0739\n",
      "Epoch [36/100], Step [27000/6235], Loss: 16.2710\n",
      "Epoch [36/100], Step [27100/6235], Loss: 0.0607\n",
      "Epoch [36/100], Step [27200/6235], Loss: 0.0113\n",
      "Epoch [36/100], Step [27300/6235], Loss: 0.0561\n",
      "Epoch [36/100], Step [27400/6235], Loss: 0.5936\n",
      "Epoch [36/100], Step [27500/6235], Loss: 1.2386\n",
      "Epoch [36/100], Step [27600/6235], Loss: 0.2016\n",
      "Epoch [36/100], Step [27700/6235], Loss: 0.9123\n",
      "Epoch [36/100], Step [27800/6235], Loss: 3.7696\n",
      "Epoch [36/100], Step [27900/6235], Loss: 3.2204\n",
      "Epoch [36/100], Step [28000/6235], Loss: 205.5160\n",
      "Epoch [36/100], Step [28100/6235], Loss: 3.6569\n",
      "Epoch [36/100], Step [28200/6235], Loss: 30.0466\n",
      "Epoch [36/100], Step [28300/6235], Loss: 0.5643\n",
      "Epoch [36/100], Step [28400/6235], Loss: 18.6977\n",
      "Epoch [36/100], Step [28500/6235], Loss: 1.9435\n",
      "Epoch [36/100], Step [28600/6235], Loss: 1.6957\n",
      "Epoch [36/100], Step [28700/6235], Loss: 1.8357\n",
      "Epoch [36/100], Step [28800/6235], Loss: 0.7415\n",
      "Epoch [36/100], Step [28900/6235], Loss: 34.1881\n",
      "Epoch [36/100], Step [29000/6235], Loss: 0.9908\n",
      "Epoch [36/100], Step [29100/6235], Loss: 0.6580\n",
      "Epoch [36/100], Step [29200/6235], Loss: 5.8740\n",
      "Epoch [36/100], Step [29300/6235], Loss: 14.9906\n",
      "Epoch [36/100], Step [29400/6235], Loss: 0.2527\n",
      "Epoch [36/100], Step [29500/6235], Loss: 2.8300\n",
      "Epoch [36/100], Step [29600/6235], Loss: 0.0214\n",
      "Epoch [36/100], Step [29700/6235], Loss: 2.8880\n",
      "Epoch [36/100], Step [29800/6235], Loss: 0.5071\n",
      "Epoch [36/100], Step [29900/6235], Loss: 3.2285\n",
      "Epoch [36/100], Step [30000/6235], Loss: 2.6299\n",
      "Epoch [36/100], Step [30100/6235], Loss: 6.8401\n",
      "Epoch [36/100], Step [30200/6235], Loss: 1.7699\n",
      "Epoch [36/100], Step [30300/6235], Loss: 0.0590\n",
      "Epoch [36/100], Step [30400/6235], Loss: 2.8832\n",
      "Epoch [36/100], Step [30500/6235], Loss: 0.0211\n",
      "Epoch [36/100], Step [30600/6235], Loss: 0.6957\n",
      "Epoch [36/100], Step [30700/6235], Loss: 2.9824\n",
      "Epoch [36/100], Step [30800/6235], Loss: 0.4502\n",
      "Epoch [36/100], Step [30900/6235], Loss: 0.9465\n",
      "Epoch [36/100], Step [31000/6235], Loss: 0.1639\n",
      "Epoch [36/100], Step [31100/6235], Loss: 1.4588\n",
      "Epoch [36/100], Step [31200/6235], Loss: 2.5795\n",
      "Epoch [36/100], Step [31300/6235], Loss: 4.3972\n",
      "Epoch [36/100], Step [31400/6235], Loss: 9.3636\n",
      "Epoch [36/100], Step [31500/6235], Loss: 0.6523\n",
      "Epoch [36/100], Step [31600/6235], Loss: 6.9910\n",
      "Epoch [36/100], Step [31700/6235], Loss: 5.8062\n",
      "Epoch [36/100], Step [31800/6235], Loss: 0.6238\n",
      "Epoch [36/100], Step [31900/6235], Loss: 417.7193\n",
      "Epoch [36/100], Step [32000/6235], Loss: 29.8901\n",
      "Epoch [36/100], Step [32100/6235], Loss: 0.4445\n",
      "Epoch [36/100], Step [32200/6235], Loss: 139.1082\n",
      "Epoch [36/100], Step [32300/6235], Loss: 3.0449\n",
      "Epoch [36/100], Step [32400/6235], Loss: 0.4794\n",
      "Epoch [36/100], Step [32500/6235], Loss: 1.7782\n",
      "Epoch [36/100], Step [32600/6235], Loss: 0.0107\n",
      "Epoch [36/100], Step [32700/6235], Loss: 189.7688\n",
      "Epoch [36/100], Step [32800/6235], Loss: 12.0444\n",
      "Epoch [36/100], Step [32900/6235], Loss: 5.0718\n",
      "Epoch [36/100], Step [33000/6235], Loss: 0.4172\n",
      "Epoch [36/100], Step [33100/6235], Loss: 0.5537\n",
      "Epoch [36/100], Step [33200/6235], Loss: 1.3784\n",
      "Epoch [36/100], Step [33300/6235], Loss: 1.5022\n",
      "Epoch [36/100], Step [33400/6235], Loss: 19.6935\n",
      "Epoch [36/100], Step [33500/6235], Loss: 0.2273\n",
      "Epoch [36/100], Step [33600/6235], Loss: 10.1717\n",
      "Epoch [36/100], Step [33700/6235], Loss: 15.0982\n",
      "Epoch [36/100], Step [33800/6235], Loss: 0.6146\n",
      "Epoch [36/100], Step [33900/6235], Loss: 31.4878\n",
      "Epoch [36/100], Step [34000/6235], Loss: 0.1911\n",
      "Epoch [36/100], Step [34100/6235], Loss: 0.8790\n",
      "Epoch [36/100], Step [34200/6235], Loss: 2.1491\n",
      "Epoch [36/100], Step [34300/6235], Loss: 2.5568\n",
      "Epoch [36/100], Step [34400/6235], Loss: 0.1340\n",
      "Epoch [36/100], Step [34500/6235], Loss: 17.9685\n",
      "Epoch [36/100], Step [34600/6235], Loss: 1.5537\n",
      "Epoch [36/100], Step [34700/6235], Loss: 1.8312\n",
      "Epoch [36/100], Step [34800/6235], Loss: 13.2503\n",
      "Epoch [36/100], Step [34900/6235], Loss: 77.5594\n",
      "Epoch [36/100], Step [35000/6235], Loss: 1.1470\n",
      "Epoch [36/100], Step [35100/6235], Loss: 1.2789\n",
      "Epoch [36/100], Step [35200/6235], Loss: 0.4869\n",
      "Epoch [36/100], Step [35300/6235], Loss: 2.3057\n",
      "Epoch [36/100], Step [35400/6235], Loss: 0.5063\n",
      "Epoch [36/100], Step [35500/6235], Loss: 0.3673\n",
      "Epoch [36/100], Step [35600/6235], Loss: 3.4936\n",
      "Epoch [36/100], Step [35700/6235], Loss: 4.1114\n",
      "Epoch [36/100], Step [35800/6235], Loss: 1.2387\n",
      "Epoch [36/100], Step [35900/6235], Loss: 3.9498\n",
      "Epoch [36/100], Step [36000/6235], Loss: 0.3134\n",
      "Epoch [36/100], Step [36100/6235], Loss: 0.1730\n",
      "Epoch [36/100], Step [36200/6235], Loss: 46.2773\n",
      "Epoch [36/100], Step [36300/6235], Loss: 0.6963\n",
      "Epoch [36/100], Step [36400/6235], Loss: 2.5497\n",
      "Epoch [36/100], Step [36500/6235], Loss: 6.0835\n",
      "Epoch [36/100], Step [36600/6235], Loss: 0.0288\n",
      "Epoch [36/100], Step [36700/6235], Loss: 0.4570\n",
      "Epoch [36/100], Step [36800/6235], Loss: 1.1718\n",
      "Epoch [36/100], Step [36900/6235], Loss: 11.0437\n",
      "Epoch [36/100], Step [37000/6235], Loss: 0.9836\n",
      "Epoch [36/100], Step [37100/6235], Loss: 2.7905\n",
      "Epoch [36/100], Step [37200/6235], Loss: 0.0240\n",
      "Epoch [36/100], Step [37300/6235], Loss: 0.2654\n",
      "Epoch [36/100], Step [37400/6235], Loss: 0.1800\n",
      "Epoch [36/100], Step [37500/6235], Loss: 8.7256\n",
      "Epoch [36/100], Step [37600/6235], Loss: 11.8226\n",
      "Epoch [36/100], Step [37700/6235], Loss: 2.2968\n",
      "Epoch [36/100], Step [37800/6235], Loss: 6.2117\n",
      "Epoch [36/100], Step [37900/6235], Loss: 7.0381\n",
      "Epoch [36/100], Step [38000/6235], Loss: 0.9701\n",
      "Epoch [36/100], Step [38100/6235], Loss: 3.8018\n",
      "Epoch [36/100], Step [38200/6235], Loss: 2.7746\n",
      "Epoch [36/100], Step [38300/6235], Loss: 0.2532\n",
      "Epoch [36/100], Step [38400/6235], Loss: 0.0792\n",
      "Epoch [36/100], Step [38500/6235], Loss: 1.3161\n",
      "Epoch [36/100], Step [38600/6235], Loss: 0.5277\n",
      "Epoch [36/100], Step [38700/6235], Loss: 0.4424\n",
      "Epoch [36/100], Step [38800/6235], Loss: 0.1446\n",
      "Epoch [36/100], Step [38900/6235], Loss: 3.1769\n",
      "Epoch [36/100], Step [39000/6235], Loss: 3.5595\n",
      "Epoch [36/100], Step [39100/6235], Loss: 24.5138\n",
      "Epoch [36/100], Step [39200/6235], Loss: 0.2459\n",
      "Epoch [36/100], Step [39300/6235], Loss: 37.4884\n",
      "Epoch [36/100], Step [39400/6235], Loss: 246.1759\n",
      "Epoch [36/100], Step [39500/6235], Loss: 5.4480\n",
      "Epoch [36/100], Step [39600/6235], Loss: 33.0110\n",
      "Epoch [36/100], Step [39700/6235], Loss: 833.3701\n",
      "Epoch [36/100], Step [39800/6235], Loss: 36.8614\n",
      "Epoch [36/100], Step [39900/6235], Loss: 0.8430\n",
      "Epoch [36/100], Step [40000/6235], Loss: 1.4687\n",
      "Epoch [36/100], Step [40100/6235], Loss: 25.8026\n",
      "Epoch [36/100], Step [40200/6235], Loss: 53.2091\n",
      "Epoch [36/100], Step [40300/6235], Loss: 0.4395\n",
      "Epoch [36/100], Step [40400/6235], Loss: 0.4084\n",
      "Epoch [36/100], Step [40500/6235], Loss: 0.4636\n",
      "Epoch [36/100], Step [40600/6235], Loss: 3.6764\n",
      "Epoch [36/100], Step [40700/6235], Loss: 6.1874\n",
      "Epoch [36/100], Step [40800/6235], Loss: 3.6660\n",
      "Epoch [36/100], Step [40900/6235], Loss: 0.7853\n",
      "Epoch [36/100], Step [41000/6235], Loss: 2.3489\n",
      "Epoch [36/100], Step [41100/6235], Loss: 7.4670\n",
      "Epoch [36/100], Step [41200/6235], Loss: 19.6914\n",
      "Epoch [36/100], Step [41300/6235], Loss: 2.6289\n",
      "Epoch [36/100], Step [41400/6235], Loss: 1.7435\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [36/100], Step [41500/6235], Loss: 1.0362\n",
      "Epoch [36/100], Step [41600/6235], Loss: 0.4521\n",
      "Epoch [36/100], Step [41700/6235], Loss: 3.8432\n",
      "Epoch [36/100], Step [41800/6235], Loss: 3.9805\n",
      "Epoch [36/100], Step [41900/6235], Loss: 3.1282\n",
      "Epoch [36/100], Step [42000/6235], Loss: 2.5703\n",
      "Epoch [36/100], Step [42100/6235], Loss: 5.9214\n",
      "Epoch [36/100], Step [42200/6235], Loss: 7.2727\n",
      "Epoch [36/100], Step [42300/6235], Loss: 2.4679\n",
      "Epoch [36/100], Step [42400/6235], Loss: 7.6832\n",
      "Epoch [36/100], Step [42500/6235], Loss: 0.5942\n",
      "Epoch [36/100], Step [42600/6235], Loss: 0.5748\n",
      "Epoch [36/100], Step [42700/6235], Loss: 0.2676\n",
      "Epoch [36/100], Step [42800/6235], Loss: 0.0799\n",
      "Epoch [36/100], Step [42900/6235], Loss: 4.1362\n",
      "Epoch [36/100], Step [43000/6235], Loss: 0.1516\n",
      "Epoch [36/100], Step [43100/6235], Loss: 1.7988\n",
      "Epoch [36/100], Step [43200/6235], Loss: 0.4441\n",
      "Epoch [36/100], Step [43300/6235], Loss: 10.5979\n",
      "Epoch [36/100], Step [43400/6235], Loss: 6.9793\n",
      "Epoch [36/100], Step [43500/6235], Loss: 7.9928\n",
      "Epoch [36/100], Step [43600/6235], Loss: 33.0944\n",
      "Epoch [36/100], Step [43700/6235], Loss: 38.9547\n",
      "Epoch [36/100], Step [43800/6235], Loss: 0.2978\n",
      "Epoch [36/100], Step [43900/6235], Loss: 1.5432\n",
      "Epoch [36/100], Step [44000/6235], Loss: 58.9925\n",
      "Epoch [36/100], Step [44100/6235], Loss: 4.3789\n",
      "Epoch [36/100], Step [44200/6235], Loss: 37.9332\n",
      "Epoch [36/100], Step [44300/6235], Loss: 60.4364\n",
      "Epoch [36/100], Step [44400/6235], Loss: 4.1755\n",
      "Epoch [36/100], Step [44500/6235], Loss: 1.2896\n",
      "Epoch [36/100], Step [44600/6235], Loss: 11.1254\n",
      "Epoch [36/100], Step [44700/6235], Loss: 9.4629\n",
      "Epoch [36/100], Step [44800/6235], Loss: 1.1448\n",
      "Epoch [36/100], Step [44900/6235], Loss: 0.6615\n",
      "Epoch [36/100], Step [45000/6235], Loss: 1.4529\n",
      "Epoch [36/100], Step [45100/6235], Loss: 21.7855\n",
      "Epoch [36/100], Step [45200/6235], Loss: 1.7340\n",
      "Epoch [36/100], Step [45300/6235], Loss: 0.2768\n",
      "Epoch [36/100], Step [45400/6235], Loss: 5.2169\n",
      "Epoch [36/100], Step [45500/6235], Loss: 0.1580\n",
      "Epoch [36/100], Step [45600/6235], Loss: 1.0457\n",
      "Epoch [36/100], Step [45700/6235], Loss: 8.3713\n",
      "Epoch [36/100], Step [45800/6235], Loss: 238.5784\n",
      "Epoch [36/100], Step [45900/6235], Loss: 14.8056\n",
      "Epoch [36/100], Step [46000/6235], Loss: 1.1545\n",
      "Epoch [36/100], Step [46100/6235], Loss: 7.6774\n",
      "Epoch [36/100], Step [46200/6235], Loss: 2.1973\n",
      "Epoch [36/100], Step [46300/6235], Loss: 222.8458\n",
      "Epoch [36/100], Step [46400/6235], Loss: 1.5895\n",
      "Epoch [36/100], Step [46500/6235], Loss: 5.9702\n",
      "Epoch [36/100], Step [46600/6235], Loss: 26.7042\n",
      "Epoch [36/100], Step [46700/6235], Loss: 0.7831\n",
      "Epoch [36/100], Step [46800/6235], Loss: 22.6522\n",
      "Epoch [36/100], Step [46900/6235], Loss: 23.9135\n",
      "Epoch [36/100], Step [47000/6235], Loss: 0.6760\n",
      "Epoch [36/100], Step [47100/6235], Loss: 56.7967\n",
      "Epoch [36/100], Step [47200/6235], Loss: 48.1884\n",
      "Epoch [36/100], Step [47300/6235], Loss: 0.6983\n",
      "Epoch [36/100], Step [47400/6235], Loss: 55.8751\n",
      "Epoch [36/100], Step [47500/6235], Loss: 13.2089\n",
      "Epoch [36/100], Step [47600/6235], Loss: 16.8419\n",
      "Epoch [36/100], Step [47700/6235], Loss: 14.0918\n",
      "Epoch [36/100], Step [47800/6235], Loss: 15.2547\n",
      "Epoch [36/100], Step [47900/6235], Loss: 20.2678\n",
      "Epoch [36/100], Step [48000/6235], Loss: 54.3506\n",
      "Epoch [36/100], Step [48100/6235], Loss: 3.7521\n",
      "Epoch [36/100], Step [48200/6235], Loss: 25.7247\n",
      "Epoch [36/100], Step [48300/6235], Loss: 343.5239\n",
      "Epoch [36/100], Step [48400/6235], Loss: 18.0014\n",
      "Epoch [36/100], Step [48500/6235], Loss: 31.4836\n",
      "Epoch [36/100], Step [48600/6235], Loss: 159.5613\n",
      "Epoch [36/100], Step [48700/6235], Loss: 7.0606\n",
      "Epoch [36/100], Step [48800/6235], Loss: 354.8263\n",
      "Epoch [36/100], Step [48900/6235], Loss: 670.5704\n",
      "Epoch [36/100], Step [49000/6235], Loss: 77.1095\n",
      "Epoch [36/100], Step [49100/6235], Loss: 1304.5199\n",
      "Epoch [36/100], Step [49200/6235], Loss: 627.5760\n",
      "Epoch [36/100], Step [49300/6235], Loss: 960.8792\n",
      "Epoch [36/100], Step [49400/6235], Loss: 141.3952\n",
      "Epoch [36/100], Step [49500/6235], Loss: 21.5886\n",
      "Epoch [36/100], Step [49600/6235], Loss: 58.0127\n",
      "Epoch [36/100], Step [49700/6235], Loss: 1130.1147\n",
      "Epoch [36/100], Step [49800/6235], Loss: 372.0276\n",
      "Epoch [37/100], Step [100/6235], Loss: 5.6547\n",
      "Epoch [37/100], Step [200/6235], Loss: 0.3742\n",
      "Epoch [37/100], Step [300/6235], Loss: 0.0288\n",
      "Epoch [37/100], Step [400/6235], Loss: 0.0007\n",
      "Epoch [37/100], Step [500/6235], Loss: 0.1269\n",
      "Epoch [37/100], Step [600/6235], Loss: 0.0237\n",
      "Epoch [37/100], Step [700/6235], Loss: 0.5224\n",
      "Epoch [37/100], Step [800/6235], Loss: 0.0232\n",
      "Epoch [37/100], Step [900/6235], Loss: 0.0549\n",
      "Epoch [37/100], Step [1000/6235], Loss: 0.0149\n",
      "Epoch [37/100], Step [1100/6235], Loss: 0.0163\n",
      "Epoch [37/100], Step [1200/6235], Loss: 0.1415\n",
      "Epoch [37/100], Step [1300/6235], Loss: 0.0008\n",
      "Epoch [37/100], Step [1400/6235], Loss: 0.0526\n",
      "Epoch [37/100], Step [1500/6235], Loss: 0.0045\n",
      "Epoch [37/100], Step [1600/6235], Loss: 0.2363\n",
      "Epoch [37/100], Step [1700/6235], Loss: 0.3005\n",
      "Epoch [37/100], Step [1800/6235], Loss: 0.3414\n",
      "Epoch [37/100], Step [1900/6235], Loss: 0.2706\n",
      "Epoch [37/100], Step [2000/6235], Loss: 1.9165\n",
      "Epoch [37/100], Step [2100/6235], Loss: 2.9771\n",
      "Epoch [37/100], Step [2200/6235], Loss: 3.7896\n",
      "Epoch [37/100], Step [2300/6235], Loss: 2.4351\n",
      "Epoch [37/100], Step [2400/6235], Loss: 3.5486\n",
      "Epoch [37/100], Step [2500/6235], Loss: 13.6162\n",
      "Epoch [37/100], Step [2600/6235], Loss: 17.8154\n",
      "Epoch [37/100], Step [2700/6235], Loss: 13.5270\n",
      "Epoch [37/100], Step [2800/6235], Loss: 90.9369\n",
      "Epoch [37/100], Step [2900/6235], Loss: 5.9302\n",
      "Epoch [37/100], Step [3000/6235], Loss: 2.8836\n",
      "Epoch [37/100], Step [3100/6235], Loss: 104.0406\n",
      "Epoch [37/100], Step [3200/6235], Loss: 7.1659\n",
      "Epoch [37/100], Step [3300/6235], Loss: 0.6456\n",
      "Epoch [37/100], Step [3400/6235], Loss: 7.2948\n",
      "Epoch [37/100], Step [3500/6235], Loss: 69.4961\n",
      "Epoch [37/100], Step [3600/6235], Loss: 2.5722\n",
      "Epoch [37/100], Step [3700/6235], Loss: 0.1208\n",
      "Epoch [37/100], Step [3800/6235], Loss: 0.2287\n",
      "Epoch [37/100], Step [3900/6235], Loss: 0.2017\n",
      "Epoch [37/100], Step [4000/6235], Loss: 0.5221\n",
      "Epoch [37/100], Step [4100/6235], Loss: 6.5757\n",
      "Epoch [37/100], Step [4200/6235], Loss: 1.7447\n",
      "Epoch [37/100], Step [4300/6235], Loss: 2.1226\n",
      "Epoch [37/100], Step [4400/6235], Loss: 0.0689\n",
      "Epoch [37/100], Step [4500/6235], Loss: 57.1630\n",
      "Epoch [37/100], Step [4600/6235], Loss: 17.3334\n",
      "Epoch [37/100], Step [4700/6235], Loss: 1.3783\n",
      "Epoch [37/100], Step [4800/6235], Loss: 1.7623\n",
      "Epoch [37/100], Step [4900/6235], Loss: 1.6206\n",
      "Epoch [37/100], Step [5000/6235], Loss: 0.1437\n",
      "Epoch [37/100], Step [5100/6235], Loss: 7.5233\n",
      "Epoch [37/100], Step [5200/6235], Loss: 1.3182\n",
      "Epoch [37/100], Step [5300/6235], Loss: 14.0139\n",
      "Epoch [37/100], Step [5400/6235], Loss: 3.0376\n",
      "Epoch [37/100], Step [5500/6235], Loss: 0.7490\n",
      "Epoch [37/100], Step [5600/6235], Loss: 0.5434\n",
      "Epoch [37/100], Step [5700/6235], Loss: 0.3201\n",
      "Epoch [37/100], Step [5800/6235], Loss: 1.0857\n",
      "Epoch [37/100], Step [5900/6235], Loss: 0.0093\n",
      "Epoch [37/100], Step [6000/6235], Loss: 0.8338\n",
      "Epoch [37/100], Step [6100/6235], Loss: 0.0213\n",
      "Epoch [37/100], Step [6200/6235], Loss: 5.6420\n",
      "Epoch [37/100], Step [6300/6235], Loss: 0.6510\n",
      "Epoch [37/100], Step [6400/6235], Loss: 0.1137\n",
      "Epoch [37/100], Step [6500/6235], Loss: 1.4828\n",
      "Epoch [37/100], Step [6600/6235], Loss: 1.5114\n",
      "Epoch [37/100], Step [6700/6235], Loss: 1.6684\n",
      "Epoch [37/100], Step [6800/6235], Loss: 0.2942\n",
      "Epoch [37/100], Step [6900/6235], Loss: 0.6304\n",
      "Epoch [37/100], Step [7000/6235], Loss: 0.0434\n",
      "Epoch [37/100], Step [7100/6235], Loss: 0.4891\n",
      "Epoch [37/100], Step [7200/6235], Loss: 0.6879\n",
      "Epoch [37/100], Step [7300/6235], Loss: 2.6455\n",
      "Epoch [37/100], Step [7400/6235], Loss: 0.2782\n",
      "Epoch [37/100], Step [7500/6235], Loss: 0.6497\n",
      "Epoch [37/100], Step [7600/6235], Loss: 0.6080\n",
      "Epoch [37/100], Step [7700/6235], Loss: 2.2228\n",
      "Epoch [37/100], Step [7800/6235], Loss: 6.4507\n",
      "Epoch [37/100], Step [7900/6235], Loss: 7.7303\n",
      "Epoch [37/100], Step [8000/6235], Loss: 0.1838\n",
      "Epoch [37/100], Step [8100/6235], Loss: 0.1941\n",
      "Epoch [37/100], Step [8200/6235], Loss: 10.2821\n",
      "Epoch [37/100], Step [8300/6235], Loss: 6.1458\n",
      "Epoch [37/100], Step [8400/6235], Loss: 460.1771\n",
      "Epoch [37/100], Step [8500/6235], Loss: 1.8174\n",
      "Epoch [37/100], Step [8600/6235], Loss: 123.1583\n",
      "Epoch [37/100], Step [8700/6235], Loss: 110.1412\n",
      "Epoch [37/100], Step [8800/6235], Loss: 614.2180\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Step [8900/6235], Loss: 92.7099\n",
      "Epoch [37/100], Step [9000/6235], Loss: 279.2270\n",
      "Epoch [37/100], Step [9100/6235], Loss: 544.8455\n",
      "Epoch [37/100], Step [9200/6235], Loss: 547.8188\n",
      "Epoch [37/100], Step [9300/6235], Loss: 111.9238\n",
      "Epoch [37/100], Step [9400/6235], Loss: 827.9680\n",
      "Epoch [37/100], Step [9500/6235], Loss: 246.3759\n",
      "Epoch [37/100], Step [9600/6235], Loss: 363.0108\n",
      "Epoch [37/100], Step [9700/6235], Loss: 168.5796\n",
      "Epoch [37/100], Step [9800/6235], Loss: 2969.7336\n",
      "Epoch [37/100], Step [9900/6235], Loss: 141.9197\n",
      "Epoch [37/100], Step [10000/6235], Loss: 294.2048\n",
      "Epoch [37/100], Step [10100/6235], Loss: 2.7269\n",
      "Epoch [37/100], Step [10200/6235], Loss: 970.5776\n",
      "Epoch [37/100], Step [10300/6235], Loss: 3.2178\n",
      "Epoch [37/100], Step [10400/6235], Loss: 16.3312\n",
      "Epoch [37/100], Step [10500/6235], Loss: 7.5172\n",
      "Epoch [37/100], Step [10600/6235], Loss: 7.9852\n",
      "Epoch [37/100], Step [10700/6235], Loss: 353.5934\n",
      "Epoch [37/100], Step [10800/6235], Loss: 77.7378\n",
      "Epoch [37/100], Step [10900/6235], Loss: 7.1291\n",
      "Epoch [37/100], Step [11000/6235], Loss: 54.0022\n",
      "Epoch [37/100], Step [11100/6235], Loss: 5.4435\n",
      "Epoch [37/100], Step [11200/6235], Loss: 116.5813\n",
      "Epoch [37/100], Step [11300/6235], Loss: 226.7431\n",
      "Epoch [37/100], Step [11400/6235], Loss: 200.2240\n",
      "Epoch [37/100], Step [11500/6235], Loss: 17.6300\n",
      "Epoch [37/100], Step [11600/6235], Loss: 3.4613\n",
      "Epoch [37/100], Step [11700/6235], Loss: 134.2917\n",
      "Epoch [37/100], Step [11800/6235], Loss: 97.4352\n",
      "Epoch [37/100], Step [11900/6235], Loss: 52.5202\n",
      "Epoch [37/100], Step [12000/6235], Loss: 664.6290\n",
      "Epoch [37/100], Step [12100/6235], Loss: 171.1084\n",
      "Epoch [37/100], Step [12200/6235], Loss: 1.4902\n",
      "Epoch [37/100], Step [12300/6235], Loss: 4.0188\n",
      "Epoch [37/100], Step [12400/6235], Loss: 467.4939\n",
      "Epoch [37/100], Step [12500/6235], Loss: 30.2344\n",
      "Epoch [37/100], Step [12600/6235], Loss: 41.0768\n",
      "Epoch [37/100], Step [12700/6235], Loss: 4.4793\n",
      "Epoch [37/100], Step [12800/6235], Loss: 7.2887\n",
      "Epoch [37/100], Step [12900/6235], Loss: 50.6908\n",
      "Epoch [37/100], Step [13000/6235], Loss: 2.4913\n",
      "Epoch [37/100], Step [13100/6235], Loss: 81.7090\n",
      "Epoch [37/100], Step [13200/6235], Loss: 20.6405\n",
      "Epoch [37/100], Step [13300/6235], Loss: 21.6313\n",
      "Epoch [37/100], Step [13400/6235], Loss: 255.5640\n",
      "Epoch [37/100], Step [13500/6235], Loss: 2.8037\n",
      "Epoch [37/100], Step [13600/6235], Loss: 9.3083\n",
      "Epoch [37/100], Step [13700/6235], Loss: 195.3161\n",
      "Epoch [37/100], Step [13800/6235], Loss: 78.6699\n",
      "Epoch [37/100], Step [13900/6235], Loss: 80.5576\n",
      "Epoch [37/100], Step [14000/6235], Loss: 0.4034\n",
      "Epoch [37/100], Step [14100/6235], Loss: 41.3080\n",
      "Epoch [37/100], Step [14200/6235], Loss: 99.8031\n",
      "Epoch [37/100], Step [14300/6235], Loss: 82.7599\n",
      "Epoch [37/100], Step [14400/6235], Loss: 38.4423\n",
      "Epoch [37/100], Step [14500/6235], Loss: 21.3689\n",
      "Epoch [37/100], Step [14600/6235], Loss: 2.2458\n",
      "Epoch [37/100], Step [14700/6235], Loss: 24.2630\n",
      "Epoch [37/100], Step [14800/6235], Loss: 26.7365\n",
      "Epoch [37/100], Step [14900/6235], Loss: 0.8079\n",
      "Epoch [37/100], Step [15000/6235], Loss: 1.2765\n",
      "Epoch [37/100], Step [15100/6235], Loss: 0.5252\n",
      "Epoch [37/100], Step [15200/6235], Loss: 2.6891\n",
      "Epoch [37/100], Step [15300/6235], Loss: 25.8758\n",
      "Epoch [37/100], Step [15400/6235], Loss: 77.4429\n",
      "Epoch [37/100], Step [15500/6235], Loss: 11.8811\n",
      "Epoch [37/100], Step [15600/6235], Loss: 147.6790\n",
      "Epoch [37/100], Step [15700/6235], Loss: 242.1339\n",
      "Epoch [37/100], Step [15800/6235], Loss: 9.4011\n",
      "Epoch [37/100], Step [15900/6235], Loss: 0.4258\n",
      "Epoch [37/100], Step [16000/6235], Loss: 17.2593\n",
      "Epoch [37/100], Step [16100/6235], Loss: 18.0413\n",
      "Epoch [37/100], Step [16200/6235], Loss: 1.0422\n",
      "Epoch [37/100], Step [16300/6235], Loss: 11.0742\n",
      "Epoch [37/100], Step [16400/6235], Loss: 25.3270\n",
      "Epoch [37/100], Step [16500/6235], Loss: 71.6093\n",
      "Epoch [37/100], Step [16600/6235], Loss: 3.7920\n",
      "Epoch [37/100], Step [16700/6235], Loss: 1.9453\n",
      "Epoch [37/100], Step [16800/6235], Loss: 12.8638\n",
      "Epoch [37/100], Step [16900/6235], Loss: 0.0834\n",
      "Epoch [37/100], Step [17000/6235], Loss: 0.1864\n",
      "Epoch [37/100], Step [17100/6235], Loss: 0.0780\n",
      "Epoch [37/100], Step [17200/6235], Loss: 270.5219\n",
      "Epoch [37/100], Step [17300/6235], Loss: 16.8680\n",
      "Epoch [37/100], Step [17400/6235], Loss: 31.0730\n",
      "Epoch [37/100], Step [17500/6235], Loss: 1.5002\n",
      "Epoch [37/100], Step [17600/6235], Loss: 5.2586\n",
      "Epoch [37/100], Step [17700/6235], Loss: 4.5730\n",
      "Epoch [37/100], Step [17800/6235], Loss: 10.6505\n",
      "Epoch [37/100], Step [17900/6235], Loss: 14.8871\n",
      "Epoch [37/100], Step [18000/6235], Loss: 9.2040\n",
      "Epoch [37/100], Step [18100/6235], Loss: 17.3183\n",
      "Epoch [37/100], Step [18200/6235], Loss: 1.3464\n",
      "Epoch [37/100], Step [18300/6235], Loss: 0.8685\n",
      "Epoch [37/100], Step [18400/6235], Loss: 4.5462\n",
      "Epoch [37/100], Step [18500/6235], Loss: 30.6873\n",
      "Epoch [37/100], Step [18600/6235], Loss: 7.0213\n",
      "Epoch [37/100], Step [18700/6235], Loss: 2.0271\n",
      "Epoch [37/100], Step [18800/6235], Loss: 66.7514\n",
      "Epoch [37/100], Step [18900/6235], Loss: 41.2019\n",
      "Epoch [37/100], Step [19000/6235], Loss: 0.7747\n",
      "Epoch [37/100], Step [19100/6235], Loss: 3.9862\n",
      "Epoch [37/100], Step [19200/6235], Loss: 2.3786\n",
      "Epoch [37/100], Step [19300/6235], Loss: 5.7437\n",
      "Epoch [37/100], Step [19400/6235], Loss: 152.3660\n",
      "Epoch [37/100], Step [19500/6235], Loss: 44.8373\n",
      "Epoch [37/100], Step [19600/6235], Loss: 19.8246\n",
      "Epoch [37/100], Step [19700/6235], Loss: 4.3193\n",
      "Epoch [37/100], Step [19800/6235], Loss: 3.7835\n",
      "Epoch [37/100], Step [19900/6235], Loss: 0.1166\n",
      "Epoch [37/100], Step [20000/6235], Loss: 71.1906\n",
      "Epoch [37/100], Step [20100/6235], Loss: 4.4564\n",
      "Epoch [37/100], Step [20200/6235], Loss: 0.6654\n",
      "Epoch [37/100], Step [20300/6235], Loss: 2.1153\n",
      "Epoch [37/100], Step [20400/6235], Loss: 6.8776\n",
      "Epoch [37/100], Step [20500/6235], Loss: 61.8434\n",
      "Epoch [37/100], Step [20600/6235], Loss: 31.8367\n",
      "Epoch [37/100], Step [20700/6235], Loss: 19.3630\n",
      "Epoch [37/100], Step [20800/6235], Loss: 4.0983\n",
      "Epoch [37/100], Step [20900/6235], Loss: 8.0776\n",
      "Epoch [37/100], Step [21000/6235], Loss: 19.2307\n",
      "Epoch [37/100], Step [21100/6235], Loss: 7.7963\n",
      "Epoch [37/100], Step [21200/6235], Loss: 0.3456\n",
      "Epoch [37/100], Step [21300/6235], Loss: 0.2819\n",
      "Epoch [37/100], Step [21400/6235], Loss: 2.3593\n",
      "Epoch [37/100], Step [21500/6235], Loss: 4.8606\n",
      "Epoch [37/100], Step [21600/6235], Loss: 0.4344\n",
      "Epoch [37/100], Step [21700/6235], Loss: 2.1087\n",
      "Epoch [37/100], Step [21800/6235], Loss: 0.5086\n",
      "Epoch [37/100], Step [21900/6235], Loss: 0.7277\n",
      "Epoch [37/100], Step [22000/6235], Loss: 4.5895\n",
      "Epoch [37/100], Step [22100/6235], Loss: 2.9273\n",
      "Epoch [37/100], Step [22200/6235], Loss: 0.2073\n",
      "Epoch [37/100], Step [22300/6235], Loss: 5.1491\n",
      "Epoch [37/100], Step [22400/6235], Loss: 1.8478\n",
      "Epoch [37/100], Step [22500/6235], Loss: 134.4840\n",
      "Epoch [37/100], Step [22600/6235], Loss: 19.2096\n",
      "Epoch [37/100], Step [22700/6235], Loss: 0.6060\n",
      "Epoch [37/100], Step [22800/6235], Loss: 3.7577\n",
      "Epoch [37/100], Step [22900/6235], Loss: 7.7874\n",
      "Epoch [37/100], Step [23000/6235], Loss: 6.5622\n",
      "Epoch [37/100], Step [23100/6235], Loss: 1.1775\n",
      "Epoch [37/100], Step [23200/6235], Loss: 8.9968\n",
      "Epoch [37/100], Step [23300/6235], Loss: 18.9958\n",
      "Epoch [37/100], Step [23400/6235], Loss: 1.5819\n",
      "Epoch [37/100], Step [23500/6235], Loss: 0.1534\n",
      "Epoch [37/100], Step [23600/6235], Loss: 132.4228\n",
      "Epoch [37/100], Step [23700/6235], Loss: 3.0446\n",
      "Epoch [37/100], Step [23800/6235], Loss: 0.9295\n",
      "Epoch [37/100], Step [23900/6235], Loss: 3.4984\n",
      "Epoch [37/100], Step [24000/6235], Loss: 0.7871\n",
      "Epoch [37/100], Step [24100/6235], Loss: 0.3123\n",
      "Epoch [37/100], Step [24200/6235], Loss: 55.0929\n",
      "Epoch [37/100], Step [24300/6235], Loss: 0.6493\n",
      "Epoch [37/100], Step [24400/6235], Loss: 0.1193\n",
      "Epoch [37/100], Step [24500/6235], Loss: 3.4578\n",
      "Epoch [37/100], Step [24600/6235], Loss: 0.2758\n",
      "Epoch [37/100], Step [24700/6235], Loss: 0.1989\n",
      "Epoch [37/100], Step [24800/6235], Loss: 0.4095\n",
      "Epoch [37/100], Step [24900/6235], Loss: 8.7754\n",
      "Epoch [37/100], Step [25000/6235], Loss: 8.0519\n",
      "Epoch [37/100], Step [25100/6235], Loss: 7.3638\n",
      "Epoch [37/100], Step [25200/6235], Loss: 0.0200\n",
      "Epoch [37/100], Step [25300/6235], Loss: 1.7180\n",
      "Epoch [37/100], Step [25400/6235], Loss: 3.1200\n",
      "Epoch [37/100], Step [25500/6235], Loss: 8.9112\n",
      "Epoch [37/100], Step [25600/6235], Loss: 8.1716\n",
      "Epoch [37/100], Step [25700/6235], Loss: 0.0668\n",
      "Epoch [37/100], Step [25800/6235], Loss: 0.7941\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Step [25900/6235], Loss: 4.1513\n",
      "Epoch [37/100], Step [26000/6235], Loss: 0.3649\n",
      "Epoch [37/100], Step [26100/6235], Loss: 0.2628\n",
      "Epoch [37/100], Step [26200/6235], Loss: 1.1160\n",
      "Epoch [37/100], Step [26300/6235], Loss: 0.0962\n",
      "Epoch [37/100], Step [26400/6235], Loss: 1.5666\n",
      "Epoch [37/100], Step [26500/6235], Loss: 0.0268\n",
      "Epoch [37/100], Step [26600/6235], Loss: 0.0227\n",
      "Epoch [37/100], Step [26700/6235], Loss: 0.0319\n",
      "Epoch [37/100], Step [26800/6235], Loss: 0.0553\n",
      "Epoch [37/100], Step [26900/6235], Loss: 0.1551\n",
      "Epoch [37/100], Step [27000/6235], Loss: 15.1516\n",
      "Epoch [37/100], Step [27100/6235], Loss: 0.1106\n",
      "Epoch [37/100], Step [27200/6235], Loss: 0.0346\n",
      "Epoch [37/100], Step [27300/6235], Loss: 0.0053\n",
      "Epoch [37/100], Step [27400/6235], Loss: 0.4116\n",
      "Epoch [37/100], Step [27500/6235], Loss: 0.1693\n",
      "Epoch [37/100], Step [27600/6235], Loss: 0.0245\n",
      "Epoch [37/100], Step [27700/6235], Loss: 0.8798\n",
      "Epoch [37/100], Step [27800/6235], Loss: 0.2624\n",
      "Epoch [37/100], Step [27900/6235], Loss: 0.1489\n",
      "Epoch [37/100], Step [28000/6235], Loss: 20.0109\n",
      "Epoch [37/100], Step [28100/6235], Loss: 8.4357\n",
      "Epoch [37/100], Step [28200/6235], Loss: 41.2359\n",
      "Epoch [37/100], Step [28300/6235], Loss: 2.6847\n",
      "Epoch [37/100], Step [28400/6235], Loss: 22.2754\n",
      "Epoch [37/100], Step [28500/6235], Loss: 1.6695\n",
      "Epoch [37/100], Step [28600/6235], Loss: 1.4816\n",
      "Epoch [37/100], Step [28700/6235], Loss: 2.2842\n",
      "Epoch [37/100], Step [28800/6235], Loss: 0.6994\n",
      "Epoch [37/100], Step [28900/6235], Loss: 36.4536\n",
      "Epoch [37/100], Step [29000/6235], Loss: 1.5866\n",
      "Epoch [37/100], Step [29100/6235], Loss: 0.2372\n",
      "Epoch [37/100], Step [29200/6235], Loss: 5.9810\n",
      "Epoch [37/100], Step [29300/6235], Loss: 11.8010\n",
      "Epoch [37/100], Step [29400/6235], Loss: 0.3332\n",
      "Epoch [37/100], Step [29500/6235], Loss: 1.9559\n",
      "Epoch [37/100], Step [29600/6235], Loss: 0.4543\n",
      "Epoch [37/100], Step [29700/6235], Loss: 2.9528\n",
      "Epoch [37/100], Step [29800/6235], Loss: 0.3881\n",
      "Epoch [37/100], Step [29900/6235], Loss: 0.3892\n",
      "Epoch [37/100], Step [30000/6235], Loss: 5.6736\n",
      "Epoch [37/100], Step [30100/6235], Loss: 6.3414\n",
      "Epoch [37/100], Step [30200/6235], Loss: 1.6559\n",
      "Epoch [37/100], Step [30300/6235], Loss: 0.0796\n",
      "Epoch [37/100], Step [30400/6235], Loss: 3.2214\n",
      "Epoch [37/100], Step [30500/6235], Loss: 0.0127\n",
      "Epoch [37/100], Step [30600/6235], Loss: 0.6727\n",
      "Epoch [37/100], Step [30700/6235], Loss: 2.9963\n",
      "Epoch [37/100], Step [30800/6235], Loss: 0.4506\n",
      "Epoch [37/100], Step [30900/6235], Loss: 1.0483\n",
      "Epoch [37/100], Step [31000/6235], Loss: 0.1914\n",
      "Epoch [37/100], Step [31100/6235], Loss: 1.2102\n",
      "Epoch [37/100], Step [31200/6235], Loss: 2.9856\n",
      "Epoch [37/100], Step [31300/6235], Loss: 1.1615\n",
      "Epoch [37/100], Step [31400/6235], Loss: 5.0238\n",
      "Epoch [37/100], Step [31500/6235], Loss: 0.5135\n",
      "Epoch [37/100], Step [31600/6235], Loss: 5.5033\n",
      "Epoch [37/100], Step [31700/6235], Loss: 38.8107\n",
      "Epoch [37/100], Step [31800/6235], Loss: 0.4109\n",
      "Epoch [37/100], Step [31900/6235], Loss: 1815.2740\n",
      "Epoch [37/100], Step [32000/6235], Loss: 15.9780\n",
      "Epoch [37/100], Step [32100/6235], Loss: 0.2464\n",
      "Epoch [37/100], Step [32200/6235], Loss: 133.5783\n",
      "Epoch [37/100], Step [32300/6235], Loss: 1.6990\n",
      "Epoch [37/100], Step [32400/6235], Loss: 0.5947\n",
      "Epoch [37/100], Step [32500/6235], Loss: 2.4165\n",
      "Epoch [37/100], Step [32600/6235], Loss: 0.0081\n",
      "Epoch [37/100], Step [32700/6235], Loss: 133.0360\n",
      "Epoch [37/100], Step [32800/6235], Loss: 21.3212\n",
      "Epoch [37/100], Step [32900/6235], Loss: 3.9539\n",
      "Epoch [37/100], Step [33000/6235], Loss: 0.2522\n",
      "Epoch [37/100], Step [33100/6235], Loss: 0.2429\n",
      "Epoch [37/100], Step [33200/6235], Loss: 1.0481\n",
      "Epoch [37/100], Step [33300/6235], Loss: 6.1825\n",
      "Epoch [37/100], Step [33400/6235], Loss: 11.8173\n",
      "Epoch [37/100], Step [33500/6235], Loss: 2.3784\n",
      "Epoch [37/100], Step [33600/6235], Loss: 9.3796\n",
      "Epoch [37/100], Step [33700/6235], Loss: 10.2285\n",
      "Epoch [37/100], Step [33800/6235], Loss: 1.2882\n",
      "Epoch [37/100], Step [33900/6235], Loss: 29.4828\n",
      "Epoch [37/100], Step [34000/6235], Loss: 0.1558\n",
      "Epoch [37/100], Step [34100/6235], Loss: 0.6832\n",
      "Epoch [37/100], Step [34200/6235], Loss: 1.8168\n",
      "Epoch [37/100], Step [34300/6235], Loss: 2.9816\n",
      "Epoch [37/100], Step [34400/6235], Loss: 0.1623\n",
      "Epoch [37/100], Step [34500/6235], Loss: 60.3529\n",
      "Epoch [37/100], Step [34600/6235], Loss: 1.7365\n",
      "Epoch [37/100], Step [34700/6235], Loss: 1.8631\n",
      "Epoch [37/100], Step [34800/6235], Loss: 14.5388\n",
      "Epoch [37/100], Step [34900/6235], Loss: 67.2798\n",
      "Epoch [37/100], Step [35000/6235], Loss: 0.1860\n",
      "Epoch [37/100], Step [35100/6235], Loss: 0.8847\n",
      "Epoch [37/100], Step [35200/6235], Loss: 0.5119\n",
      "Epoch [37/100], Step [35300/6235], Loss: 2.9455\n",
      "Epoch [37/100], Step [35400/6235], Loss: 0.5427\n",
      "Epoch [37/100], Step [35500/6235], Loss: 0.1077\n",
      "Epoch [37/100], Step [35600/6235], Loss: 3.9458\n",
      "Epoch [37/100], Step [35700/6235], Loss: 3.8969\n",
      "Epoch [37/100], Step [35800/6235], Loss: 0.3845\n",
      "Epoch [37/100], Step [35900/6235], Loss: 0.5878\n",
      "Epoch [37/100], Step [36000/6235], Loss: 0.2606\n",
      "Epoch [37/100], Step [36100/6235], Loss: 0.1607\n",
      "Epoch [37/100], Step [36200/6235], Loss: 41.1427\n",
      "Epoch [37/100], Step [36300/6235], Loss: 0.5929\n",
      "Epoch [37/100], Step [36400/6235], Loss: 2.6802\n",
      "Epoch [37/100], Step [36500/6235], Loss: 6.4473\n",
      "Epoch [37/100], Step [36600/6235], Loss: 0.0699\n",
      "Epoch [37/100], Step [36700/6235], Loss: 0.4740\n",
      "Epoch [37/100], Step [36800/6235], Loss: 1.3109\n",
      "Epoch [37/100], Step [36900/6235], Loss: 11.8939\n",
      "Epoch [37/100], Step [37000/6235], Loss: 0.9731\n",
      "Epoch [37/100], Step [37100/6235], Loss: 2.4912\n",
      "Epoch [37/100], Step [37200/6235], Loss: 0.0353\n",
      "Epoch [37/100], Step [37300/6235], Loss: 0.2232\n",
      "Epoch [37/100], Step [37400/6235], Loss: 0.1782\n",
      "Epoch [37/100], Step [37500/6235], Loss: 8.6815\n",
      "Epoch [37/100], Step [37600/6235], Loss: 12.1577\n",
      "Epoch [37/100], Step [37700/6235], Loss: 2.7696\n",
      "Epoch [37/100], Step [37800/6235], Loss: 2.4715\n",
      "Epoch [37/100], Step [37900/6235], Loss: 5.5865\n",
      "Epoch [37/100], Step [38000/6235], Loss: 1.0458\n",
      "Epoch [37/100], Step [38100/6235], Loss: 3.4268\n",
      "Epoch [37/100], Step [38200/6235], Loss: 2.2250\n",
      "Epoch [37/100], Step [38300/6235], Loss: 0.2585\n",
      "Epoch [37/100], Step [38400/6235], Loss: 0.1917\n",
      "Epoch [37/100], Step [38500/6235], Loss: 1.3428\n",
      "Epoch [37/100], Step [38600/6235], Loss: 0.0808\n",
      "Epoch [37/100], Step [38700/6235], Loss: 0.4839\n",
      "Epoch [37/100], Step [38800/6235], Loss: 0.1539\n",
      "Epoch [37/100], Step [38900/6235], Loss: 8.7468\n",
      "Epoch [37/100], Step [39000/6235], Loss: 2.4968\n",
      "Epoch [37/100], Step [39100/6235], Loss: 21.2675\n",
      "Epoch [37/100], Step [39200/6235], Loss: 0.5763\n",
      "Epoch [37/100], Step [39300/6235], Loss: 87.2224\n",
      "Epoch [37/100], Step [39400/6235], Loss: 280.1245\n",
      "Epoch [37/100], Step [39500/6235], Loss: 7.0493\n",
      "Epoch [37/100], Step [39600/6235], Loss: 21.6855\n",
      "Epoch [37/100], Step [39700/6235], Loss: 573.6079\n",
      "Epoch [37/100], Step [39800/6235], Loss: 125.4277\n",
      "Epoch [37/100], Step [39900/6235], Loss: 18.3051\n",
      "Epoch [37/100], Step [40000/6235], Loss: 153.2647\n",
      "Epoch [37/100], Step [40100/6235], Loss: 27.9092\n",
      "Epoch [37/100], Step [40200/6235], Loss: 70.3732\n",
      "Epoch [37/100], Step [40300/6235], Loss: 0.3035\n",
      "Epoch [37/100], Step [40400/6235], Loss: 0.2062\n",
      "Epoch [37/100], Step [40500/6235], Loss: 0.3849\n",
      "Epoch [37/100], Step [40600/6235], Loss: 4.2612\n",
      "Epoch [37/100], Step [40700/6235], Loss: 6.1103\n",
      "Epoch [37/100], Step [40800/6235], Loss: 3.6309\n",
      "Epoch [37/100], Step [40900/6235], Loss: 0.7913\n",
      "Epoch [37/100], Step [41000/6235], Loss: 3.2031\n",
      "Epoch [37/100], Step [41100/6235], Loss: 4.9454\n",
      "Epoch [37/100], Step [41200/6235], Loss: 19.8537\n",
      "Epoch [37/100], Step [41300/6235], Loss: 2.8397\n",
      "Epoch [37/100], Step [41400/6235], Loss: 0.7415\n",
      "Epoch [37/100], Step [41500/6235], Loss: 0.3438\n",
      "Epoch [37/100], Step [41600/6235], Loss: 0.2596\n",
      "Epoch [37/100], Step [41700/6235], Loss: 1.7895\n",
      "Epoch [37/100], Step [41800/6235], Loss: 3.7567\n",
      "Epoch [37/100], Step [41900/6235], Loss: 3.4089\n",
      "Epoch [37/100], Step [42000/6235], Loss: 2.8799\n",
      "Epoch [37/100], Step [42100/6235], Loss: 6.3885\n",
      "Epoch [37/100], Step [42200/6235], Loss: 6.6808\n",
      "Epoch [37/100], Step [42300/6235], Loss: 1.3093\n",
      "Epoch [37/100], Step [42400/6235], Loss: 3.8337\n",
      "Epoch [37/100], Step [42500/6235], Loss: 0.7981\n",
      "Epoch [37/100], Step [42600/6235], Loss: 0.5719\n",
      "Epoch [37/100], Step [42700/6235], Loss: 0.2635\n",
      "Epoch [37/100], Step [42800/6235], Loss: 0.3739\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [37/100], Step [42900/6235], Loss: 4.1980\n",
      "Epoch [37/100], Step [43000/6235], Loss: 0.1565\n",
      "Epoch [37/100], Step [43100/6235], Loss: 1.5193\n",
      "Epoch [37/100], Step [43200/6235], Loss: 0.5287\n",
      "Epoch [37/100], Step [43300/6235], Loss: 10.3407\n",
      "Epoch [37/100], Step [43400/6235], Loss: 6.7018\n",
      "Epoch [37/100], Step [43500/6235], Loss: 7.8837\n",
      "Epoch [37/100], Step [43600/6235], Loss: 32.1320\n",
      "Epoch [37/100], Step [43700/6235], Loss: 33.6032\n",
      "Epoch [37/100], Step [43800/6235], Loss: 0.2257\n",
      "Epoch [37/100], Step [43900/6235], Loss: 1.1597\n",
      "Epoch [37/100], Step [44000/6235], Loss: 80.1342\n",
      "Epoch [37/100], Step [44100/6235], Loss: 5.0970\n",
      "Epoch [37/100], Step [44200/6235], Loss: 36.5249\n",
      "Epoch [37/100], Step [44300/6235], Loss: 56.7644\n",
      "Epoch [37/100], Step [44400/6235], Loss: 2.1929\n",
      "Epoch [37/100], Step [44500/6235], Loss: 2.8133\n",
      "Epoch [37/100], Step [44600/6235], Loss: 12.2300\n",
      "Epoch [37/100], Step [44700/6235], Loss: 5.4188\n",
      "Epoch [37/100], Step [44800/6235], Loss: 0.2985\n",
      "Epoch [37/100], Step [44900/6235], Loss: 0.7871\n",
      "Epoch [37/100], Step [45000/6235], Loss: 2.2616\n",
      "Epoch [37/100], Step [45100/6235], Loss: 26.3977\n",
      "Epoch [37/100], Step [45200/6235], Loss: 0.2573\n",
      "Epoch [37/100], Step [45300/6235], Loss: 6.3583\n",
      "Epoch [37/100], Step [45400/6235], Loss: 6.0853\n",
      "Epoch [37/100], Step [45500/6235], Loss: 0.1273\n",
      "Epoch [37/100], Step [45600/6235], Loss: 0.8658\n",
      "Epoch [37/100], Step [45700/6235], Loss: 3.6793\n",
      "Epoch [37/100], Step [45800/6235], Loss: 223.6561\n",
      "Epoch [37/100], Step [45900/6235], Loss: 7.7794\n",
      "Epoch [37/100], Step [46000/6235], Loss: 17.7527\n",
      "Epoch [37/100], Step [46100/6235], Loss: 50.6950\n",
      "Epoch [37/100], Step [46200/6235], Loss: 285.4457\n",
      "Epoch [37/100], Step [46300/6235], Loss: 142.3119\n",
      "Epoch [37/100], Step [46400/6235], Loss: 1.7848\n",
      "Epoch [37/100], Step [46500/6235], Loss: 5.8355\n",
      "Epoch [37/100], Step [46600/6235], Loss: 9.9468\n",
      "Epoch [37/100], Step [46700/6235], Loss: 1.4448\n",
      "Epoch [37/100], Step [46800/6235], Loss: 27.8816\n",
      "Epoch [37/100], Step [46900/6235], Loss: 23.0614\n",
      "Epoch [37/100], Step [47000/6235], Loss: 0.5857\n",
      "Epoch [37/100], Step [47100/6235], Loss: 59.1906\n",
      "Epoch [37/100], Step [47200/6235], Loss: 66.8244\n",
      "Epoch [37/100], Step [47300/6235], Loss: 0.6982\n",
      "Epoch [37/100], Step [47400/6235], Loss: 105.0969\n",
      "Epoch [37/100], Step [47500/6235], Loss: 5.7699\n",
      "Epoch [37/100], Step [47600/6235], Loss: 16.5970\n",
      "Epoch [37/100], Step [47700/6235], Loss: 14.7780\n",
      "Epoch [37/100], Step [47800/6235], Loss: 16.3134\n",
      "Epoch [37/100], Step [47900/6235], Loss: 18.5867\n",
      "Epoch [37/100], Step [48000/6235], Loss: 45.2296\n",
      "Epoch [37/100], Step [48100/6235], Loss: 4.7702\n",
      "Epoch [37/100], Step [48200/6235], Loss: 13.3495\n",
      "Epoch [37/100], Step [48300/6235], Loss: 315.9038\n",
      "Epoch [37/100], Step [48400/6235], Loss: 15.6495\n",
      "Epoch [37/100], Step [48500/6235], Loss: 41.2031\n",
      "Epoch [37/100], Step [48600/6235], Loss: 147.9703\n",
      "Epoch [37/100], Step [48700/6235], Loss: 3.5328\n",
      "Epoch [37/100], Step [48800/6235], Loss: 366.3463\n",
      "Epoch [37/100], Step [48900/6235], Loss: 693.3922\n",
      "Epoch [37/100], Step [49000/6235], Loss: 153.3453\n",
      "Epoch [37/100], Step [49100/6235], Loss: 3273.4133\n",
      "Epoch [37/100], Step [49200/6235], Loss: 655.4354\n",
      "Epoch [37/100], Step [49300/6235], Loss: 1028.0226\n",
      "Epoch [37/100], Step [49400/6235], Loss: 65.9853\n",
      "Epoch [37/100], Step [49500/6235], Loss: 15.1768\n",
      "Epoch [37/100], Step [49600/6235], Loss: 258.0622\n",
      "Epoch [37/100], Step [49700/6235], Loss: 810.0088\n",
      "Epoch [37/100], Step [49800/6235], Loss: 1546.6621\n",
      "Epoch [38/100], Step [100/6235], Loss: 6.7747\n",
      "Epoch [38/100], Step [200/6235], Loss: 0.1847\n",
      "Epoch [38/100], Step [300/6235], Loss: 0.0420\n",
      "Epoch [38/100], Step [400/6235], Loss: 0.0087\n",
      "Epoch [38/100], Step [500/6235], Loss: 7.8029\n",
      "Epoch [38/100], Step [600/6235], Loss: 0.0311\n",
      "Epoch [38/100], Step [700/6235], Loss: 0.4782\n",
      "Epoch [38/100], Step [800/6235], Loss: 0.1261\n",
      "Epoch [38/100], Step [900/6235], Loss: 0.0646\n",
      "Epoch [38/100], Step [1000/6235], Loss: 0.0334\n",
      "Epoch [38/100], Step [1100/6235], Loss: 0.2354\n",
      "Epoch [38/100], Step [1200/6235], Loss: 0.1790\n",
      "Epoch [38/100], Step [1300/6235], Loss: 0.0470\n",
      "Epoch [38/100], Step [1400/6235], Loss: 0.2391\n",
      "Epoch [38/100], Step [1500/6235], Loss: 0.0050\n",
      "Epoch [38/100], Step [1600/6235], Loss: 0.2197\n",
      "Epoch [38/100], Step [1700/6235], Loss: 0.0173\n",
      "Epoch [38/100], Step [1800/6235], Loss: 0.2000\n",
      "Epoch [38/100], Step [1900/6235], Loss: 0.5143\n",
      "Epoch [38/100], Step [2000/6235], Loss: 2.1722\n",
      "Epoch [38/100], Step [2100/6235], Loss: 1.1904\n",
      "Epoch [38/100], Step [2200/6235], Loss: 9.1481\n",
      "Epoch [38/100], Step [2300/6235], Loss: 8.9822\n",
      "Epoch [38/100], Step [2400/6235], Loss: 2.0748\n",
      "Epoch [38/100], Step [2500/6235], Loss: 45.0468\n",
      "Epoch [38/100], Step [2600/6235], Loss: 12.8458\n",
      "Epoch [38/100], Step [2700/6235], Loss: 4.8068\n",
      "Epoch [38/100], Step [2800/6235], Loss: 120.6228\n",
      "Epoch [38/100], Step [2900/6235], Loss: 16.1327\n",
      "Epoch [38/100], Step [3000/6235], Loss: 0.4174\n",
      "Epoch [38/100], Step [3100/6235], Loss: 74.9457\n",
      "Epoch [38/100], Step [3200/6235], Loss: 26.2494\n",
      "Epoch [38/100], Step [3300/6235], Loss: 4.8004\n",
      "Epoch [38/100], Step [3400/6235], Loss: 6.2565\n",
      "Epoch [38/100], Step [3500/6235], Loss: 57.3785\n",
      "Epoch [38/100], Step [3600/6235], Loss: 0.2437\n",
      "Epoch [38/100], Step [3700/6235], Loss: 0.1152\n",
      "Epoch [38/100], Step [3800/6235], Loss: 0.1051\n",
      "Epoch [38/100], Step [3900/6235], Loss: 0.1353\n",
      "Epoch [38/100], Step [4000/6235], Loss: 0.1534\n",
      "Epoch [38/100], Step [4100/6235], Loss: 9.5746\n",
      "Epoch [38/100], Step [4200/6235], Loss: 5.5983\n",
      "Epoch [38/100], Step [4300/6235], Loss: 2.9492\n",
      "Epoch [38/100], Step [4400/6235], Loss: 0.2044\n",
      "Epoch [38/100], Step [4500/6235], Loss: 41.8501\n",
      "Epoch [38/100], Step [4600/6235], Loss: 5.1038\n",
      "Epoch [38/100], Step [4700/6235], Loss: 0.2562\n",
      "Epoch [38/100], Step [4800/6235], Loss: 4.2336\n",
      "Epoch [38/100], Step [4900/6235], Loss: 4.6224\n",
      "Epoch [38/100], Step [5000/6235], Loss: 0.2214\n",
      "Epoch [38/100], Step [5100/6235], Loss: 0.4632\n",
      "Epoch [38/100], Step [5200/6235], Loss: 5.2087\n",
      "Epoch [38/100], Step [5300/6235], Loss: 13.0297\n",
      "Epoch [38/100], Step [5400/6235], Loss: 2.7707\n",
      "Epoch [38/100], Step [5500/6235], Loss: 0.0521\n",
      "Epoch [38/100], Step [5600/6235], Loss: 0.1037\n",
      "Epoch [38/100], Step [5700/6235], Loss: 0.0920\n",
      "Epoch [38/100], Step [5800/6235], Loss: 0.3178\n",
      "Epoch [38/100], Step [5900/6235], Loss: 0.0175\n",
      "Epoch [38/100], Step [6000/6235], Loss: 1.7239\n",
      "Epoch [38/100], Step [6100/6235], Loss: 0.0521\n",
      "Epoch [38/100], Step [6200/6235], Loss: 7.5429\n",
      "Epoch [38/100], Step [6300/6235], Loss: 0.8762\n",
      "Epoch [38/100], Step [6400/6235], Loss: 0.0586\n",
      "Epoch [38/100], Step [6500/6235], Loss: 1.1097\n",
      "Epoch [38/100], Step [6600/6235], Loss: 3.5093\n",
      "Epoch [38/100], Step [6700/6235], Loss: 0.3049\n",
      "Epoch [38/100], Step [6800/6235], Loss: 0.0608\n",
      "Epoch [38/100], Step [6900/6235], Loss: 0.4713\n",
      "Epoch [38/100], Step [7000/6235], Loss: 0.0230\n",
      "Epoch [38/100], Step [7100/6235], Loss: 0.6600\n",
      "Epoch [38/100], Step [7200/6235], Loss: 1.9331\n",
      "Epoch [38/100], Step [7300/6235], Loss: 2.3508\n",
      "Epoch [38/100], Step [7400/6235], Loss: 0.3109\n",
      "Epoch [38/100], Step [7500/6235], Loss: 0.3972\n",
      "Epoch [38/100], Step [7600/6235], Loss: 0.3180\n",
      "Epoch [38/100], Step [7700/6235], Loss: 3.0109\n",
      "Epoch [38/100], Step [7800/6235], Loss: 3.0821\n",
      "Epoch [38/100], Step [7900/6235], Loss: 5.4380\n",
      "Epoch [38/100], Step [8000/6235], Loss: 0.0961\n",
      "Epoch [38/100], Step [8100/6235], Loss: 1.9466\n",
      "Epoch [38/100], Step [8200/6235], Loss: 6.6459\n",
      "Epoch [38/100], Step [8300/6235], Loss: 19.7083\n",
      "Epoch [38/100], Step [8400/6235], Loss: 287.7599\n",
      "Epoch [38/100], Step [8500/6235], Loss: 4.2531\n",
      "Epoch [38/100], Step [8600/6235], Loss: 0.9963\n",
      "Epoch [38/100], Step [8700/6235], Loss: 128.3619\n",
      "Epoch [38/100], Step [8800/6235], Loss: 701.1974\n",
      "Epoch [38/100], Step [8900/6235], Loss: 41.5777\n",
      "Epoch [38/100], Step [9000/6235], Loss: 454.9698\n",
      "Epoch [38/100], Step [9100/6235], Loss: 675.4962\n",
      "Epoch [38/100], Step [9200/6235], Loss: 869.9510\n",
      "Epoch [38/100], Step [9300/6235], Loss: 48.1108\n",
      "Epoch [38/100], Step [9400/6235], Loss: 92.7703\n",
      "Epoch [38/100], Step [9500/6235], Loss: 563.8248\n",
      "Epoch [38/100], Step [9600/6235], Loss: 1796.6497\n",
      "Epoch [38/100], Step [9700/6235], Loss: 20.5613\n",
      "Epoch [38/100], Step [9800/6235], Loss: 1463.1942\n",
      "Epoch [38/100], Step [9900/6235], Loss: 28.0906\n",
      "Epoch [38/100], Step [10000/6235], Loss: 397.3987\n",
      "Epoch [38/100], Step [10100/6235], Loss: 2.7835\n",
      "Epoch [38/100], Step [10200/6235], Loss: 689.2611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Step [10300/6235], Loss: 8.2700\n",
      "Epoch [38/100], Step [10400/6235], Loss: 2.2312\n",
      "Epoch [38/100], Step [10500/6235], Loss: 5.3474\n",
      "Epoch [38/100], Step [10600/6235], Loss: 8.6824\n",
      "Epoch [38/100], Step [10700/6235], Loss: 210.4274\n",
      "Epoch [38/100], Step [10800/6235], Loss: 3.4416\n",
      "Epoch [38/100], Step [10900/6235], Loss: 8.4045\n",
      "Epoch [38/100], Step [11000/6235], Loss: 168.3409\n",
      "Epoch [38/100], Step [11100/6235], Loss: 1.5559\n",
      "Epoch [38/100], Step [11200/6235], Loss: 117.9997\n",
      "Epoch [38/100], Step [11300/6235], Loss: 244.7339\n",
      "Epoch [38/100], Step [11400/6235], Loss: 14.0643\n",
      "Epoch [38/100], Step [11500/6235], Loss: 1.3125\n",
      "Epoch [38/100], Step [11600/6235], Loss: 3.8133\n",
      "Epoch [38/100], Step [11700/6235], Loss: 57.5047\n",
      "Epoch [38/100], Step [11800/6235], Loss: 3.8443\n",
      "Epoch [38/100], Step [11900/6235], Loss: 16.8709\n",
      "Epoch [38/100], Step [12000/6235], Loss: 729.7232\n",
      "Epoch [38/100], Step [12100/6235], Loss: 165.9217\n",
      "Epoch [38/100], Step [12200/6235], Loss: 12.5799\n",
      "Epoch [38/100], Step [12300/6235], Loss: 12.7907\n",
      "Epoch [38/100], Step [12400/6235], Loss: 554.2200\n",
      "Epoch [38/100], Step [12500/6235], Loss: 48.5607\n",
      "Epoch [38/100], Step [12600/6235], Loss: 47.4220\n",
      "Epoch [38/100], Step [12700/6235], Loss: 4.4726\n",
      "Epoch [38/100], Step [12800/6235], Loss: 12.7065\n",
      "Epoch [38/100], Step [12900/6235], Loss: 45.9156\n",
      "Epoch [38/100], Step [13000/6235], Loss: 1.4431\n",
      "Epoch [38/100], Step [13100/6235], Loss: 74.7591\n",
      "Epoch [38/100], Step [13200/6235], Loss: 13.8570\n",
      "Epoch [38/100], Step [13300/6235], Loss: 20.2390\n",
      "Epoch [38/100], Step [13400/6235], Loss: 256.5030\n",
      "Epoch [38/100], Step [13500/6235], Loss: 3.8619\n",
      "Epoch [38/100], Step [13600/6235], Loss: 6.3031\n",
      "Epoch [38/100], Step [13700/6235], Loss: 193.5224\n",
      "Epoch [38/100], Step [13800/6235], Loss: 71.9205\n",
      "Epoch [38/100], Step [13900/6235], Loss: 28.8404\n",
      "Epoch [38/100], Step [14000/6235], Loss: 2.9812\n",
      "Epoch [38/100], Step [14100/6235], Loss: 25.9818\n",
      "Epoch [38/100], Step [14200/6235], Loss: 122.9600\n",
      "Epoch [38/100], Step [14300/6235], Loss: 58.4304\n",
      "Epoch [38/100], Step [14400/6235], Loss: 31.9420\n",
      "Epoch [38/100], Step [14500/6235], Loss: 31.4042\n",
      "Epoch [38/100], Step [14600/6235], Loss: 0.3559\n",
      "Epoch [38/100], Step [14700/6235], Loss: 38.3831\n",
      "Epoch [38/100], Step [14800/6235], Loss: 33.3583\n",
      "Epoch [38/100], Step [14900/6235], Loss: 1.0230\n",
      "Epoch [38/100], Step [15000/6235], Loss: 1.7341\n",
      "Epoch [38/100], Step [15100/6235], Loss: 0.4787\n",
      "Epoch [38/100], Step [15200/6235], Loss: 1.9950\n",
      "Epoch [38/100], Step [15300/6235], Loss: 25.6306\n",
      "Epoch [38/100], Step [15400/6235], Loss: 33.9204\n",
      "Epoch [38/100], Step [15500/6235], Loss: 15.6064\n",
      "Epoch [38/100], Step [15600/6235], Loss: 152.1109\n",
      "Epoch [38/100], Step [15700/6235], Loss: 162.4855\n",
      "Epoch [38/100], Step [15800/6235], Loss: 0.5092\n",
      "Epoch [38/100], Step [15900/6235], Loss: 0.8145\n",
      "Epoch [38/100], Step [16000/6235], Loss: 55.3589\n",
      "Epoch [38/100], Step [16100/6235], Loss: 0.8581\n",
      "Epoch [38/100], Step [16200/6235], Loss: 0.3475\n",
      "Epoch [38/100], Step [16300/6235], Loss: 10.8092\n",
      "Epoch [38/100], Step [16400/6235], Loss: 27.6430\n",
      "Epoch [38/100], Step [16500/6235], Loss: 439.9273\n",
      "Epoch [38/100], Step [16600/6235], Loss: 40.2021\n",
      "Epoch [38/100], Step [16700/6235], Loss: 0.2565\n",
      "Epoch [38/100], Step [16800/6235], Loss: 9.4502\n",
      "Epoch [38/100], Step [16900/6235], Loss: 0.4767\n",
      "Epoch [38/100], Step [17000/6235], Loss: 0.2042\n",
      "Epoch [38/100], Step [17100/6235], Loss: 0.0750\n",
      "Epoch [38/100], Step [17200/6235], Loss: 289.6146\n",
      "Epoch [38/100], Step [17300/6235], Loss: 32.4911\n",
      "Epoch [38/100], Step [17400/6235], Loss: 35.9795\n",
      "Epoch [38/100], Step [17500/6235], Loss: 1.1129\n",
      "Epoch [38/100], Step [17600/6235], Loss: 4.4062\n",
      "Epoch [38/100], Step [17700/6235], Loss: 0.9625\n",
      "Epoch [38/100], Step [17800/6235], Loss: 14.4074\n",
      "Epoch [38/100], Step [17900/6235], Loss: 19.1873\n",
      "Epoch [38/100], Step [18000/6235], Loss: 21.0562\n",
      "Epoch [38/100], Step [18100/6235], Loss: 20.4596\n",
      "Epoch [38/100], Step [18200/6235], Loss: 1.3576\n",
      "Epoch [38/100], Step [18300/6235], Loss: 3.2633\n",
      "Epoch [38/100], Step [18400/6235], Loss: 8.6479\n",
      "Epoch [38/100], Step [18500/6235], Loss: 26.8005\n",
      "Epoch [38/100], Step [18600/6235], Loss: 7.8614\n",
      "Epoch [38/100], Step [18700/6235], Loss: 2.9978\n",
      "Epoch [38/100], Step [18800/6235], Loss: 184.9743\n",
      "Epoch [38/100], Step [18900/6235], Loss: 21.6499\n",
      "Epoch [38/100], Step [19000/6235], Loss: 9.6588\n",
      "Epoch [38/100], Step [19100/6235], Loss: 0.8745\n",
      "Epoch [38/100], Step [19200/6235], Loss: 2.9392\n",
      "Epoch [38/100], Step [19300/6235], Loss: 1.7172\n",
      "Epoch [38/100], Step [19400/6235], Loss: 322.0868\n",
      "Epoch [38/100], Step [19500/6235], Loss: 93.4972\n",
      "Epoch [38/100], Step [19600/6235], Loss: 80.5707\n",
      "Epoch [38/100], Step [19700/6235], Loss: 9.0587\n",
      "Epoch [38/100], Step [19800/6235], Loss: 10.1412\n",
      "Epoch [38/100], Step [19900/6235], Loss: 0.1422\n",
      "Epoch [38/100], Step [20000/6235], Loss: 73.4390\n",
      "Epoch [38/100], Step [20100/6235], Loss: 0.6149\n",
      "Epoch [38/100], Step [20200/6235], Loss: 7.4565\n",
      "Epoch [38/100], Step [20300/6235], Loss: 1.0094\n",
      "Epoch [38/100], Step [20400/6235], Loss: 21.7596\n",
      "Epoch [38/100], Step [20500/6235], Loss: 46.2237\n",
      "Epoch [38/100], Step [20600/6235], Loss: 100.0959\n",
      "Epoch [38/100], Step [20700/6235], Loss: 26.8792\n",
      "Epoch [38/100], Step [20800/6235], Loss: 4.4100\n",
      "Epoch [38/100], Step [20900/6235], Loss: 7.5510\n",
      "Epoch [38/100], Step [21000/6235], Loss: 22.6309\n",
      "Epoch [38/100], Step [21100/6235], Loss: 8.1080\n",
      "Epoch [38/100], Step [21200/6235], Loss: 0.4421\n",
      "Epoch [38/100], Step [21300/6235], Loss: 0.5444\n",
      "Epoch [38/100], Step [21400/6235], Loss: 0.2833\n",
      "Epoch [38/100], Step [21500/6235], Loss: 0.2694\n",
      "Epoch [38/100], Step [21600/6235], Loss: 31.7718\n",
      "Epoch [38/100], Step [21700/6235], Loss: 0.2783\n",
      "Epoch [38/100], Step [21800/6235], Loss: 1.8330\n",
      "Epoch [38/100], Step [21900/6235], Loss: 1.5244\n",
      "Epoch [38/100], Step [22000/6235], Loss: 12.7290\n",
      "Epoch [38/100], Step [22100/6235], Loss: 0.9027\n",
      "Epoch [38/100], Step [22200/6235], Loss: 1.0927\n",
      "Epoch [38/100], Step [22300/6235], Loss: 1.6930\n",
      "Epoch [38/100], Step [22400/6235], Loss: 4.8777\n",
      "Epoch [38/100], Step [22500/6235], Loss: 59.4972\n",
      "Epoch [38/100], Step [22600/6235], Loss: 29.9876\n",
      "Epoch [38/100], Step [22700/6235], Loss: 2.4359\n",
      "Epoch [38/100], Step [22800/6235], Loss: 11.9853\n",
      "Epoch [38/100], Step [22900/6235], Loss: 25.2138\n",
      "Epoch [38/100], Step [23000/6235], Loss: 13.6056\n",
      "Epoch [38/100], Step [23100/6235], Loss: 4.1024\n",
      "Epoch [38/100], Step [23200/6235], Loss: 0.6968\n",
      "Epoch [38/100], Step [23300/6235], Loss: 14.8758\n",
      "Epoch [38/100], Step [23400/6235], Loss: 2.5648\n",
      "Epoch [38/100], Step [23500/6235], Loss: 0.3221\n",
      "Epoch [38/100], Step [23600/6235], Loss: 101.2602\n",
      "Epoch [38/100], Step [23700/6235], Loss: 2.5669\n",
      "Epoch [38/100], Step [23800/6235], Loss: 1.2033\n",
      "Epoch [38/100], Step [23900/6235], Loss: 3.6973\n",
      "Epoch [38/100], Step [24000/6235], Loss: 9.8861\n",
      "Epoch [38/100], Step [24100/6235], Loss: 12.2873\n",
      "Epoch [38/100], Step [24200/6235], Loss: 17.0540\n",
      "Epoch [38/100], Step [24300/6235], Loss: 0.0965\n",
      "Epoch [38/100], Step [24400/6235], Loss: 0.3973\n",
      "Epoch [38/100], Step [24500/6235], Loss: 9.2775\n",
      "Epoch [38/100], Step [24600/6235], Loss: 0.3048\n",
      "Epoch [38/100], Step [24700/6235], Loss: 0.1128\n",
      "Epoch [38/100], Step [24800/6235], Loss: 0.4078\n",
      "Epoch [38/100], Step [24900/6235], Loss: 19.1174\n",
      "Epoch [38/100], Step [25000/6235], Loss: 1.3515\n",
      "Epoch [38/100], Step [25100/6235], Loss: 14.7013\n",
      "Epoch [38/100], Step [25200/6235], Loss: 0.6964\n",
      "Epoch [38/100], Step [25300/6235], Loss: 5.8604\n",
      "Epoch [38/100], Step [25400/6235], Loss: 3.4764\n",
      "Epoch [38/100], Step [25500/6235], Loss: 7.2691\n",
      "Epoch [38/100], Step [25600/6235], Loss: 10.2514\n",
      "Epoch [38/100], Step [25700/6235], Loss: 2.2382\n",
      "Epoch [38/100], Step [25800/6235], Loss: 6.8298\n",
      "Epoch [38/100], Step [25900/6235], Loss: 0.2944\n",
      "Epoch [38/100], Step [26000/6235], Loss: 0.1526\n",
      "Epoch [38/100], Step [26100/6235], Loss: 0.7928\n",
      "Epoch [38/100], Step [26200/6235], Loss: 0.1959\n",
      "Epoch [38/100], Step [26300/6235], Loss: 0.7734\n",
      "Epoch [38/100], Step [26400/6235], Loss: 3.6084\n",
      "Epoch [38/100], Step [26500/6235], Loss: 0.1119\n",
      "Epoch [38/100], Step [26600/6235], Loss: 0.9914\n",
      "Epoch [38/100], Step [26700/6235], Loss: 0.1113\n",
      "Epoch [38/100], Step [26800/6235], Loss: 0.3727\n",
      "Epoch [38/100], Step [26900/6235], Loss: 0.1194\n",
      "Epoch [38/100], Step [27000/6235], Loss: 11.5828\n",
      "Epoch [38/100], Step [27100/6235], Loss: 0.1003\n",
      "Epoch [38/100], Step [27200/6235], Loss: 0.3537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Step [27300/6235], Loss: 0.0140\n",
      "Epoch [38/100], Step [27400/6235], Loss: 0.2479\n",
      "Epoch [38/100], Step [27500/6235], Loss: 0.7175\n",
      "Epoch [38/100], Step [27600/6235], Loss: 0.1101\n",
      "Epoch [38/100], Step [27700/6235], Loss: 0.9524\n",
      "Epoch [38/100], Step [27800/6235], Loss: 4.3791\n",
      "Epoch [38/100], Step [27900/6235], Loss: 1.3004\n",
      "Epoch [38/100], Step [28000/6235], Loss: 166.1219\n",
      "Epoch [38/100], Step [28100/6235], Loss: 9.7207\n",
      "Epoch [38/100], Step [28200/6235], Loss: 43.0763\n",
      "Epoch [38/100], Step [28300/6235], Loss: 0.3744\n",
      "Epoch [38/100], Step [28400/6235], Loss: 18.8266\n",
      "Epoch [38/100], Step [28500/6235], Loss: 2.4638\n",
      "Epoch [38/100], Step [28600/6235], Loss: 1.6104\n",
      "Epoch [38/100], Step [28700/6235], Loss: 2.2911\n",
      "Epoch [38/100], Step [28800/6235], Loss: 0.7405\n",
      "Epoch [38/100], Step [28900/6235], Loss: 33.3031\n",
      "Epoch [38/100], Step [29000/6235], Loss: 2.4244\n",
      "Epoch [38/100], Step [29100/6235], Loss: 0.1335\n",
      "Epoch [38/100], Step [29200/6235], Loss: 6.1700\n",
      "Epoch [38/100], Step [29300/6235], Loss: 1.2715\n",
      "Epoch [38/100], Step [29400/6235], Loss: 0.9102\n",
      "Epoch [38/100], Step [29500/6235], Loss: 1.2121\n",
      "Epoch [38/100], Step [29600/6235], Loss: 0.4554\n",
      "Epoch [38/100], Step [29700/6235], Loss: 3.0273\n",
      "Epoch [38/100], Step [29800/6235], Loss: 0.2779\n",
      "Epoch [38/100], Step [29900/6235], Loss: 3.5835\n",
      "Epoch [38/100], Step [30000/6235], Loss: 2.0783\n",
      "Epoch [38/100], Step [30100/6235], Loss: 6.7123\n",
      "Epoch [38/100], Step [30200/6235], Loss: 1.5917\n",
      "Epoch [38/100], Step [30300/6235], Loss: 0.0998\n",
      "Epoch [38/100], Step [30400/6235], Loss: 3.4953\n",
      "Epoch [38/100], Step [30500/6235], Loss: 0.1012\n",
      "Epoch [38/100], Step [30600/6235], Loss: 0.5731\n",
      "Epoch [38/100], Step [30700/6235], Loss: 3.0452\n",
      "Epoch [38/100], Step [30800/6235], Loss: 0.4436\n",
      "Epoch [38/100], Step [30900/6235], Loss: 1.0356\n",
      "Epoch [38/100], Step [31000/6235], Loss: 0.1770\n",
      "Epoch [38/100], Step [31100/6235], Loss: 1.3005\n",
      "Epoch [38/100], Step [31200/6235], Loss: 2.9741\n",
      "Epoch [38/100], Step [31300/6235], Loss: 1.7072\n",
      "Epoch [38/100], Step [31400/6235], Loss: 4.4534\n",
      "Epoch [38/100], Step [31500/6235], Loss: 0.5482\n",
      "Epoch [38/100], Step [31600/6235], Loss: 11.0533\n",
      "Epoch [38/100], Step [31700/6235], Loss: 1.3137\n",
      "Epoch [38/100], Step [31800/6235], Loss: 0.5798\n",
      "Epoch [38/100], Step [31900/6235], Loss: 1863.8706\n",
      "Epoch [38/100], Step [32000/6235], Loss: 68.7389\n",
      "Epoch [38/100], Step [32100/6235], Loss: 8.0997\n",
      "Epoch [38/100], Step [32200/6235], Loss: 122.0138\n",
      "Epoch [38/100], Step [32300/6235], Loss: 3.1036\n",
      "Epoch [38/100], Step [32400/6235], Loss: 0.5000\n",
      "Epoch [38/100], Step [32500/6235], Loss: 2.1468\n",
      "Epoch [38/100], Step [32600/6235], Loss: 0.0065\n",
      "Epoch [38/100], Step [32700/6235], Loss: 168.1206\n",
      "Epoch [38/100], Step [32800/6235], Loss: 16.5220\n",
      "Epoch [38/100], Step [32900/6235], Loss: 4.6044\n",
      "Epoch [38/100], Step [33000/6235], Loss: 0.5631\n",
      "Epoch [38/100], Step [33100/6235], Loss: 0.5267\n",
      "Epoch [38/100], Step [33200/6235], Loss: 0.8348\n",
      "Epoch [38/100], Step [33300/6235], Loss: 2.8511\n",
      "Epoch [38/100], Step [33400/6235], Loss: 2.4088\n",
      "Epoch [38/100], Step [33500/6235], Loss: 0.8319\n",
      "Epoch [38/100], Step [33600/6235], Loss: 9.3050\n",
      "Epoch [38/100], Step [33700/6235], Loss: 12.1608\n",
      "Epoch [38/100], Step [33800/6235], Loss: 0.6584\n",
      "Epoch [38/100], Step [33900/6235], Loss: 32.5175\n",
      "Epoch [38/100], Step [34000/6235], Loss: 0.1745\n",
      "Epoch [38/100], Step [34100/6235], Loss: 0.9486\n",
      "Epoch [38/100], Step [34200/6235], Loss: 2.5626\n",
      "Epoch [38/100], Step [34300/6235], Loss: 1.6002\n",
      "Epoch [38/100], Step [34400/6235], Loss: 0.1290\n",
      "Epoch [38/100], Step [34500/6235], Loss: 26.7061\n",
      "Epoch [38/100], Step [34600/6235], Loss: 2.1894\n",
      "Epoch [38/100], Step [34700/6235], Loss: 28.0846\n",
      "Epoch [38/100], Step [34800/6235], Loss: 9.6891\n",
      "Epoch [38/100], Step [34900/6235], Loss: 65.4624\n",
      "Epoch [38/100], Step [35000/6235], Loss: 1.1902\n",
      "Epoch [38/100], Step [35100/6235], Loss: 0.4496\n",
      "Epoch [38/100], Step [35200/6235], Loss: 0.6289\n",
      "Epoch [38/100], Step [35300/6235], Loss: 3.1836\n",
      "Epoch [38/100], Step [35400/6235], Loss: 0.5258\n",
      "Epoch [38/100], Step [35500/6235], Loss: 0.0884\n",
      "Epoch [38/100], Step [35600/6235], Loss: 1.9242\n",
      "Epoch [38/100], Step [35700/6235], Loss: 4.0339\n",
      "Epoch [38/100], Step [35800/6235], Loss: 0.1223\n",
      "Epoch [38/100], Step [35900/6235], Loss: 3.8142\n",
      "Epoch [38/100], Step [36000/6235], Loss: 0.1301\n",
      "Epoch [38/100], Step [36100/6235], Loss: 0.1330\n",
      "Epoch [38/100], Step [36200/6235], Loss: 41.5043\n",
      "Epoch [38/100], Step [36300/6235], Loss: 0.7296\n",
      "Epoch [38/100], Step [36400/6235], Loss: 2.9197\n",
      "Epoch [38/100], Step [36500/6235], Loss: 6.8089\n",
      "Epoch [38/100], Step [36600/6235], Loss: 0.0532\n",
      "Epoch [38/100], Step [36700/6235], Loss: 0.5538\n",
      "Epoch [38/100], Step [36800/6235], Loss: 2.5001\n",
      "Epoch [38/100], Step [36900/6235], Loss: 12.0363\n",
      "Epoch [38/100], Step [37000/6235], Loss: 0.9856\n",
      "Epoch [38/100], Step [37100/6235], Loss: 2.4423\n",
      "Epoch [38/100], Step [37200/6235], Loss: 0.0291\n",
      "Epoch [38/100], Step [37300/6235], Loss: 0.1257\n",
      "Epoch [38/100], Step [37400/6235], Loss: 0.1622\n",
      "Epoch [38/100], Step [37500/6235], Loss: 8.0940\n",
      "Epoch [38/100], Step [37600/6235], Loss: 12.0445\n",
      "Epoch [38/100], Step [37700/6235], Loss: 1.7614\n",
      "Epoch [38/100], Step [37800/6235], Loss: 2.7595\n",
      "Epoch [38/100], Step [37900/6235], Loss: 7.0925\n",
      "Epoch [38/100], Step [38000/6235], Loss: 0.5516\n",
      "Epoch [38/100], Step [38100/6235], Loss: 4.6350\n",
      "Epoch [38/100], Step [38200/6235], Loss: 2.9980\n",
      "Epoch [38/100], Step [38300/6235], Loss: 0.2068\n",
      "Epoch [38/100], Step [38400/6235], Loss: 0.1256\n",
      "Epoch [38/100], Step [38500/6235], Loss: 1.2484\n",
      "Epoch [38/100], Step [38600/6235], Loss: 0.6041\n",
      "Epoch [38/100], Step [38700/6235], Loss: 0.3622\n",
      "Epoch [38/100], Step [38800/6235], Loss: 0.1218\n",
      "Epoch [38/100], Step [38900/6235], Loss: 3.6604\n",
      "Epoch [38/100], Step [39000/6235], Loss: 0.5249\n",
      "Epoch [38/100], Step [39100/6235], Loss: 0.5438\n",
      "Epoch [38/100], Step [39200/6235], Loss: 0.5478\n",
      "Epoch [38/100], Step [39300/6235], Loss: 5.6577\n",
      "Epoch [38/100], Step [39400/6235], Loss: 431.3329\n",
      "Epoch [38/100], Step [39500/6235], Loss: 37.4726\n",
      "Epoch [38/100], Step [39600/6235], Loss: 45.8563\n",
      "Epoch [38/100], Step [39700/6235], Loss: 334.4328\n",
      "Epoch [38/100], Step [39800/6235], Loss: 215.6249\n",
      "Epoch [38/100], Step [39900/6235], Loss: 5.9786\n",
      "Epoch [38/100], Step [40000/6235], Loss: 6.4246\n",
      "Epoch [38/100], Step [40100/6235], Loss: 28.6976\n",
      "Epoch [38/100], Step [40200/6235], Loss: 34.2275\n",
      "Epoch [38/100], Step [40300/6235], Loss: 0.9309\n",
      "Epoch [38/100], Step [40400/6235], Loss: 1.4616\n",
      "Epoch [38/100], Step [40500/6235], Loss: 0.9153\n",
      "Epoch [38/100], Step [40600/6235], Loss: 2.3169\n",
      "Epoch [38/100], Step [40700/6235], Loss: 6.7757\n",
      "Epoch [38/100], Step [40800/6235], Loss: 3.5742\n",
      "Epoch [38/100], Step [40900/6235], Loss: 0.6664\n",
      "Epoch [38/100], Step [41000/6235], Loss: 14.8636\n",
      "Epoch [38/100], Step [41100/6235], Loss: 17.7767\n",
      "Epoch [38/100], Step [41200/6235], Loss: 33.4890\n",
      "Epoch [38/100], Step [41300/6235], Loss: 3.4431\n",
      "Epoch [38/100], Step [41400/6235], Loss: 0.0774\n",
      "Epoch [38/100], Step [41500/6235], Loss: 0.7322\n",
      "Epoch [38/100], Step [41600/6235], Loss: 0.5491\n",
      "Epoch [38/100], Step [41700/6235], Loss: 3.2262\n",
      "Epoch [38/100], Step [41800/6235], Loss: 2.9692\n",
      "Epoch [38/100], Step [41900/6235], Loss: 3.5621\n",
      "Epoch [38/100], Step [42000/6235], Loss: 2.9097\n",
      "Epoch [38/100], Step [42100/6235], Loss: 6.5693\n",
      "Epoch [38/100], Step [42200/6235], Loss: 6.8320\n",
      "Epoch [38/100], Step [42300/6235], Loss: 0.7269\n",
      "Epoch [38/100], Step [42400/6235], Loss: 3.6313\n",
      "Epoch [38/100], Step [42500/6235], Loss: 3.1524\n",
      "Epoch [38/100], Step [42600/6235], Loss: 0.4959\n",
      "Epoch [38/100], Step [42700/6235], Loss: 0.2184\n",
      "Epoch [38/100], Step [42800/6235], Loss: 0.8922\n",
      "Epoch [38/100], Step [42900/6235], Loss: 4.2666\n",
      "Epoch [38/100], Step [43000/6235], Loss: 0.2013\n",
      "Epoch [38/100], Step [43100/6235], Loss: 1.2855\n",
      "Epoch [38/100], Step [43200/6235], Loss: 0.6235\n",
      "Epoch [38/100], Step [43300/6235], Loss: 10.0334\n",
      "Epoch [38/100], Step [43400/6235], Loss: 6.1655\n",
      "Epoch [38/100], Step [43500/6235], Loss: 8.1202\n",
      "Epoch [38/100], Step [43600/6235], Loss: 29.1567\n",
      "Epoch [38/100], Step [43700/6235], Loss: 31.8096\n",
      "Epoch [38/100], Step [43800/6235], Loss: 0.1406\n",
      "Epoch [38/100], Step [43900/6235], Loss: 0.8691\n",
      "Epoch [38/100], Step [44000/6235], Loss: 23.8229\n",
      "Epoch [38/100], Step [44100/6235], Loss: 2.0058\n",
      "Epoch [38/100], Step [44200/6235], Loss: 9.2327\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [38/100], Step [44300/6235], Loss: 20.5961\n",
      "Epoch [38/100], Step [44400/6235], Loss: 5.2284\n",
      "Epoch [38/100], Step [44500/6235], Loss: 2.6673\n",
      "Epoch [38/100], Step [44600/6235], Loss: 22.8990\n",
      "Epoch [38/100], Step [44700/6235], Loss: 0.7813\n",
      "Epoch [38/100], Step [44800/6235], Loss: 1.1114\n",
      "Epoch [38/100], Step [44900/6235], Loss: 1.3028\n",
      "Epoch [38/100], Step [45000/6235], Loss: 4.5313\n",
      "Epoch [38/100], Step [45100/6235], Loss: 21.5917\n",
      "Epoch [38/100], Step [45200/6235], Loss: 0.4107\n",
      "Epoch [38/100], Step [45300/6235], Loss: 8.6169\n",
      "Epoch [38/100], Step [45400/6235], Loss: 7.8781\n",
      "Epoch [38/100], Step [45500/6235], Loss: 0.1404\n",
      "Epoch [38/100], Step [45600/6235], Loss: 0.2653\n",
      "Epoch [38/100], Step [45700/6235], Loss: 11.0158\n",
      "Epoch [38/100], Step [45800/6235], Loss: 326.4646\n",
      "Epoch [38/100], Step [45900/6235], Loss: 10.7064\n",
      "Epoch [38/100], Step [46000/6235], Loss: 38.2386\n",
      "Epoch [38/100], Step [46100/6235], Loss: 123.0550\n",
      "Epoch [38/100], Step [46200/6235], Loss: 14.8289\n",
      "Epoch [38/100], Step [46300/6235], Loss: 4.1829\n",
      "Epoch [38/100], Step [46400/6235], Loss: 9.6947\n",
      "Epoch [38/100], Step [46500/6235], Loss: 10.9948\n",
      "Epoch [38/100], Step [46600/6235], Loss: 18.8067\n",
      "Epoch [38/100], Step [46700/6235], Loss: 2.9183\n",
      "Epoch [38/100], Step [46800/6235], Loss: 23.4268\n",
      "Epoch [38/100], Step [46900/6235], Loss: 20.1838\n",
      "Epoch [38/100], Step [47000/6235], Loss: 0.7402\n",
      "Epoch [38/100], Step [47100/6235], Loss: 43.0462\n",
      "Epoch [38/100], Step [47200/6235], Loss: 68.5035\n",
      "Epoch [38/100], Step [47300/6235], Loss: 0.7129\n",
      "Epoch [38/100], Step [47400/6235], Loss: 138.0577\n",
      "Epoch [38/100], Step [47500/6235], Loss: 4.3114\n",
      "Epoch [38/100], Step [47600/6235], Loss: 13.4874\n",
      "Epoch [38/100], Step [47700/6235], Loss: 11.8048\n",
      "Epoch [38/100], Step [47800/6235], Loss: 12.9854\n",
      "Epoch [38/100], Step [47900/6235], Loss: 18.4039\n",
      "Epoch [38/100], Step [48000/6235], Loss: 42.0529\n",
      "Epoch [38/100], Step [48100/6235], Loss: 4.2569\n",
      "Epoch [38/100], Step [48200/6235], Loss: 17.7375\n",
      "Epoch [38/100], Step [48300/6235], Loss: 347.4446\n",
      "Epoch [38/100], Step [48400/6235], Loss: 17.2805\n",
      "Epoch [38/100], Step [48500/6235], Loss: 33.3672\n",
      "Epoch [38/100], Step [48600/6235], Loss: 151.7193\n",
      "Epoch [38/100], Step [48700/6235], Loss: 4.1570\n",
      "Epoch [38/100], Step [48800/6235], Loss: 305.9118\n",
      "Epoch [38/100], Step [48900/6235], Loss: 65.7264\n",
      "Epoch [38/100], Step [49000/6235], Loss: 223.8312\n",
      "Epoch [38/100], Step [49100/6235], Loss: 2734.9954\n",
      "Epoch [38/100], Step [49200/6235], Loss: 545.0269\n",
      "Epoch [38/100], Step [49300/6235], Loss: 1161.1600\n",
      "Epoch [38/100], Step [49400/6235], Loss: 208.0591\n",
      "Epoch [38/100], Step [49500/6235], Loss: 5.3413\n",
      "Epoch [38/100], Step [49600/6235], Loss: 145.1949\n",
      "Epoch [38/100], Step [49700/6235], Loss: 1210.3738\n",
      "Epoch [38/100], Step [49800/6235], Loss: 68.4654\n",
      "Epoch [39/100], Step [100/6235], Loss: 25.7323\n",
      "Epoch [39/100], Step [200/6235], Loss: 0.1912\n",
      "Epoch [39/100], Step [300/6235], Loss: 0.0040\n",
      "Epoch [39/100], Step [400/6235], Loss: 0.0017\n",
      "Epoch [39/100], Step [500/6235], Loss: 2.2060\n",
      "Epoch [39/100], Step [600/6235], Loss: 0.0231\n",
      "Epoch [39/100], Step [700/6235], Loss: 0.6127\n",
      "Epoch [39/100], Step [800/6235], Loss: 0.0580\n",
      "Epoch [39/100], Step [900/6235], Loss: 0.0608\n",
      "Epoch [39/100], Step [1000/6235], Loss: 0.0245\n",
      "Epoch [39/100], Step [1100/6235], Loss: 0.0433\n",
      "Epoch [39/100], Step [1200/6235], Loss: 0.1685\n",
      "Epoch [39/100], Step [1300/6235], Loss: 0.0067\n",
      "Epoch [39/100], Step [1400/6235], Loss: 0.0549\n",
      "Epoch [39/100], Step [1500/6235], Loss: 0.0070\n",
      "Epoch [39/100], Step [1600/6235], Loss: 0.2347\n",
      "Epoch [39/100], Step [1700/6235], Loss: 0.1224\n",
      "Epoch [39/100], Step [1800/6235], Loss: 0.2353\n",
      "Epoch [39/100], Step [1900/6235], Loss: 0.2642\n",
      "Epoch [39/100], Step [2000/6235], Loss: 2.2255\n",
      "Epoch [39/100], Step [2100/6235], Loss: 2.8898\n",
      "Epoch [39/100], Step [2200/6235], Loss: 6.1274\n",
      "Epoch [39/100], Step [2300/6235], Loss: 0.4924\n",
      "Epoch [39/100], Step [2400/6235], Loss: 1.0438\n",
      "Epoch [39/100], Step [2500/6235], Loss: 26.8677\n",
      "Epoch [39/100], Step [2600/6235], Loss: 13.3195\n",
      "Epoch [39/100], Step [2700/6235], Loss: 5.2106\n",
      "Epoch [39/100], Step [2800/6235], Loss: 92.8362\n",
      "Epoch [39/100], Step [2900/6235], Loss: 18.2525\n",
      "Epoch [39/100], Step [3000/6235], Loss: 1.3890\n",
      "Epoch [39/100], Step [3100/6235], Loss: 63.0139\n",
      "Epoch [39/100], Step [3200/6235], Loss: 62.6111\n",
      "Epoch [39/100], Step [3300/6235], Loss: 10.3985\n",
      "Epoch [39/100], Step [3400/6235], Loss: 2.2961\n",
      "Epoch [39/100], Step [3500/6235], Loss: 47.0796\n",
      "Epoch [39/100], Step [3600/6235], Loss: 5.2037\n",
      "Epoch [39/100], Step [3700/6235], Loss: 0.0804\n",
      "Epoch [39/100], Step [3800/6235], Loss: 0.0419\n",
      "Epoch [39/100], Step [3900/6235], Loss: 0.1913\n",
      "Epoch [39/100], Step [4000/6235], Loss: 0.0701\n",
      "Epoch [39/100], Step [4100/6235], Loss: 8.5817\n",
      "Epoch [39/100], Step [4200/6235], Loss: 1.6170\n",
      "Epoch [39/100], Step [4300/6235], Loss: 7.2823\n",
      "Epoch [39/100], Step [4400/6235], Loss: 1.5482\n",
      "Epoch [39/100], Step [4500/6235], Loss: 39.2138\n",
      "Epoch [39/100], Step [4600/6235], Loss: 1.3691\n",
      "Epoch [39/100], Step [4700/6235], Loss: 0.1217\n",
      "Epoch [39/100], Step [4800/6235], Loss: 10.3167\n",
      "Epoch [39/100], Step [4900/6235], Loss: 0.1009\n",
      "Epoch [39/100], Step [5000/6235], Loss: 0.1000\n",
      "Epoch [39/100], Step [5100/6235], Loss: 0.6692\n",
      "Epoch [39/100], Step [5200/6235], Loss: 1.3560\n",
      "Epoch [39/100], Step [5300/6235], Loss: 40.4320\n",
      "Epoch [39/100], Step [5400/6235], Loss: 1.4810\n",
      "Epoch [39/100], Step [5500/6235], Loss: 0.1318\n",
      "Epoch [39/100], Step [5600/6235], Loss: 0.2946\n",
      "Epoch [39/100], Step [5700/6235], Loss: 0.0558\n",
      "Epoch [39/100], Step [5800/6235], Loss: 0.3110\n",
      "Epoch [39/100], Step [5900/6235], Loss: 0.1134\n",
      "Epoch [39/100], Step [6000/6235], Loss: 2.2267\n",
      "Epoch [39/100], Step [6100/6235], Loss: 0.0349\n",
      "Epoch [39/100], Step [6200/6235], Loss: 3.3298\n",
      "Epoch [39/100], Step [6300/6235], Loss: 0.4648\n",
      "Epoch [39/100], Step [6400/6235], Loss: 0.0726\n",
      "Epoch [39/100], Step [6500/6235], Loss: 3.7991\n",
      "Epoch [39/100], Step [6600/6235], Loss: 7.1389\n",
      "Epoch [39/100], Step [6700/6235], Loss: 2.8087\n",
      "Epoch [39/100], Step [6800/6235], Loss: 1.6820\n",
      "Epoch [39/100], Step [6900/6235], Loss: 0.4435\n",
      "Epoch [39/100], Step [7000/6235], Loss: 0.1612\n",
      "Epoch [39/100], Step [7100/6235], Loss: 0.1833\n",
      "Epoch [39/100], Step [7200/6235], Loss: 0.2791\n",
      "Epoch [39/100], Step [7300/6235], Loss: 0.2446\n",
      "Epoch [39/100], Step [7400/6235], Loss: 0.1771\n",
      "Epoch [39/100], Step [7500/6235], Loss: 1.0313\n",
      "Epoch [39/100], Step [7600/6235], Loss: 0.1878\n",
      "Epoch [39/100], Step [7700/6235], Loss: 18.6016\n",
      "Epoch [39/100], Step [7800/6235], Loss: 3.5709\n",
      "Epoch [39/100], Step [7900/6235], Loss: 3.3742\n",
      "Epoch [39/100], Step [8000/6235], Loss: 0.2009\n",
      "Epoch [39/100], Step [8100/6235], Loss: 4.6890\n",
      "Epoch [39/100], Step [8200/6235], Loss: 15.0803\n",
      "Epoch [39/100], Step [8300/6235], Loss: 52.5624\n",
      "Epoch [39/100], Step [8400/6235], Loss: 184.4044\n",
      "Epoch [39/100], Step [8500/6235], Loss: 1.6724\n",
      "Epoch [39/100], Step [8600/6235], Loss: 152.5847\n",
      "Epoch [39/100], Step [8700/6235], Loss: 88.4428\n",
      "Epoch [39/100], Step [8800/6235], Loss: 564.2524\n",
      "Epoch [39/100], Step [8900/6235], Loss: 277.7274\n",
      "Epoch [39/100], Step [9000/6235], Loss: 667.2095\n",
      "Epoch [39/100], Step [9100/6235], Loss: 670.6570\n",
      "Epoch [39/100], Step [9200/6235], Loss: 2762.3796\n",
      "Epoch [39/100], Step [9300/6235], Loss: 80.5335\n",
      "Epoch [39/100], Step [9400/6235], Loss: 82.0907\n",
      "Epoch [39/100], Step [9500/6235], Loss: 1618.8989\n",
      "Epoch [39/100], Step [9600/6235], Loss: 335.1997\n",
      "Epoch [39/100], Step [9700/6235], Loss: 7.0727\n",
      "Epoch [39/100], Step [9800/6235], Loss: 396.8300\n",
      "Epoch [39/100], Step [9900/6235], Loss: 2.7484\n",
      "Epoch [39/100], Step [10000/6235], Loss: 293.4359\n",
      "Epoch [39/100], Step [10100/6235], Loss: 4.4322\n",
      "Epoch [39/100], Step [10200/6235], Loss: 519.8903\n",
      "Epoch [39/100], Step [10300/6235], Loss: 4.5133\n",
      "Epoch [39/100], Step [10400/6235], Loss: 1.4440\n",
      "Epoch [39/100], Step [10500/6235], Loss: 2.8839\n",
      "Epoch [39/100], Step [10600/6235], Loss: 15.0888\n",
      "Epoch [39/100], Step [10700/6235], Loss: 50.4354\n",
      "Epoch [39/100], Step [10800/6235], Loss: 22.3016\n",
      "Epoch [39/100], Step [10900/6235], Loss: 4.1997\n",
      "Epoch [39/100], Step [11000/6235], Loss: 267.4039\n",
      "Epoch [39/100], Step [11100/6235], Loss: 20.0429\n",
      "Epoch [39/100], Step [11200/6235], Loss: 66.6776\n",
      "Epoch [39/100], Step [11300/6235], Loss: 192.9877\n",
      "Epoch [39/100], Step [11400/6235], Loss: 6.6903\n",
      "Epoch [39/100], Step [11500/6235], Loss: 0.8253\n",
      "Epoch [39/100], Step [11600/6235], Loss: 0.8249\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Step [11700/6235], Loss: 41.2887\n",
      "Epoch [39/100], Step [11800/6235], Loss: 441.4300\n",
      "Epoch [39/100], Step [11900/6235], Loss: 411.6138\n",
      "Epoch [39/100], Step [12000/6235], Loss: 184.8167\n",
      "Epoch [39/100], Step [12100/6235], Loss: 154.2205\n",
      "Epoch [39/100], Step [12200/6235], Loss: 117.9166\n",
      "Epoch [39/100], Step [12300/6235], Loss: 21.5008\n",
      "Epoch [39/100], Step [12400/6235], Loss: 447.0194\n",
      "Epoch [39/100], Step [12500/6235], Loss: 0.3797\n",
      "Epoch [39/100], Step [12600/6235], Loss: 165.9940\n",
      "Epoch [39/100], Step [12700/6235], Loss: 2.7899\n",
      "Epoch [39/100], Step [12800/6235], Loss: 3.2513\n",
      "Epoch [39/100], Step [12900/6235], Loss: 49.3649\n",
      "Epoch [39/100], Step [13000/6235], Loss: 1.1530\n",
      "Epoch [39/100], Step [13100/6235], Loss: 74.7915\n",
      "Epoch [39/100], Step [13200/6235], Loss: 26.1280\n",
      "Epoch [39/100], Step [13300/6235], Loss: 57.3005\n",
      "Epoch [39/100], Step [13400/6235], Loss: 245.6060\n",
      "Epoch [39/100], Step [13500/6235], Loss: 25.2101\n",
      "Epoch [39/100], Step [13600/6235], Loss: 34.1149\n",
      "Epoch [39/100], Step [13700/6235], Loss: 75.4422\n",
      "Epoch [39/100], Step [13800/6235], Loss: 150.9778\n",
      "Epoch [39/100], Step [13900/6235], Loss: 17.6569\n",
      "Epoch [39/100], Step [14000/6235], Loss: 11.3591\n",
      "Epoch [39/100], Step [14100/6235], Loss: 5.2777\n",
      "Epoch [39/100], Step [14200/6235], Loss: 66.4771\n",
      "Epoch [39/100], Step [14300/6235], Loss: 88.6462\n",
      "Epoch [39/100], Step [14400/6235], Loss: 37.8234\n",
      "Epoch [39/100], Step [14500/6235], Loss: 107.5622\n",
      "Epoch [39/100], Step [14600/6235], Loss: 1.4638\n",
      "Epoch [39/100], Step [14700/6235], Loss: 39.4933\n",
      "Epoch [39/100], Step [14800/6235], Loss: 28.0645\n",
      "Epoch [39/100], Step [14900/6235], Loss: 6.0266\n",
      "Epoch [39/100], Step [15000/6235], Loss: 6.4612\n",
      "Epoch [39/100], Step [15100/6235], Loss: 0.0542\n",
      "Epoch [39/100], Step [15200/6235], Loss: 71.8227\n",
      "Epoch [39/100], Step [15300/6235], Loss: 24.9997\n",
      "Epoch [39/100], Step [15400/6235], Loss: 62.8885\n",
      "Epoch [39/100], Step [15500/6235], Loss: 9.1166\n",
      "Epoch [39/100], Step [15600/6235], Loss: 118.1671\n",
      "Epoch [39/100], Step [15700/6235], Loss: 11.1471\n",
      "Epoch [39/100], Step [15800/6235], Loss: 0.1542\n",
      "Epoch [39/100], Step [15900/6235], Loss: 2.0191\n",
      "Epoch [39/100], Step [16000/6235], Loss: 0.9872\n",
      "Epoch [39/100], Step [16100/6235], Loss: 17.0569\n",
      "Epoch [39/100], Step [16200/6235], Loss: 0.3848\n",
      "Epoch [39/100], Step [16300/6235], Loss: 10.7495\n",
      "Epoch [39/100], Step [16400/6235], Loss: 53.0667\n",
      "Epoch [39/100], Step [16500/6235], Loss: 132.2716\n",
      "Epoch [39/100], Step [16600/6235], Loss: 10.1875\n",
      "Epoch [39/100], Step [16700/6235], Loss: 0.6601\n",
      "Epoch [39/100], Step [16800/6235], Loss: 7.8646\n",
      "Epoch [39/100], Step [16900/6235], Loss: 0.0981\n",
      "Epoch [39/100], Step [17000/6235], Loss: 0.2500\n",
      "Epoch [39/100], Step [17100/6235], Loss: 0.3480\n",
      "Epoch [39/100], Step [17200/6235], Loss: 309.4197\n",
      "Epoch [39/100], Step [17300/6235], Loss: 64.2598\n",
      "Epoch [39/100], Step [17400/6235], Loss: 70.4787\n",
      "Epoch [39/100], Step [17500/6235], Loss: 0.7295\n",
      "Epoch [39/100], Step [17600/6235], Loss: 5.1162\n",
      "Epoch [39/100], Step [17700/6235], Loss: 108.6751\n",
      "Epoch [39/100], Step [17800/6235], Loss: 21.2977\n",
      "Epoch [39/100], Step [17900/6235], Loss: 3.9070\n",
      "Epoch [39/100], Step [18000/6235], Loss: 7.0052\n",
      "Epoch [39/100], Step [18100/6235], Loss: 20.0549\n",
      "Epoch [39/100], Step [18200/6235], Loss: 1.4312\n",
      "Epoch [39/100], Step [18300/6235], Loss: 1.8957\n",
      "Epoch [39/100], Step [18400/6235], Loss: 1.5692\n",
      "Epoch [39/100], Step [18500/6235], Loss: 25.2141\n",
      "Epoch [39/100], Step [18600/6235], Loss: 5.7896\n",
      "Epoch [39/100], Step [18700/6235], Loss: 2.8110\n",
      "Epoch [39/100], Step [18800/6235], Loss: 186.1319\n",
      "Epoch [39/100], Step [18900/6235], Loss: 31.3399\n",
      "Epoch [39/100], Step [19000/6235], Loss: 5.3408\n",
      "Epoch [39/100], Step [19100/6235], Loss: 2.5508\n",
      "Epoch [39/100], Step [19200/6235], Loss: 1.3484\n",
      "Epoch [39/100], Step [19300/6235], Loss: 1.6612\n",
      "Epoch [39/100], Step [19400/6235], Loss: 240.5657\n",
      "Epoch [39/100], Step [19500/6235], Loss: 67.7110\n",
      "Epoch [39/100], Step [19600/6235], Loss: 110.5566\n",
      "Epoch [39/100], Step [19700/6235], Loss: 7.8648\n",
      "Epoch [39/100], Step [19800/6235], Loss: 13.3323\n",
      "Epoch [39/100], Step [19900/6235], Loss: 0.0607\n",
      "Epoch [39/100], Step [20000/6235], Loss: 70.1254\n",
      "Epoch [39/100], Step [20100/6235], Loss: 1.7528\n",
      "Epoch [39/100], Step [20200/6235], Loss: 6.1622\n",
      "Epoch [39/100], Step [20300/6235], Loss: 2.6337\n",
      "Epoch [39/100], Step [20400/6235], Loss: 12.7948\n",
      "Epoch [39/100], Step [20500/6235], Loss: 57.4260\n",
      "Epoch [39/100], Step [20600/6235], Loss: 50.2701\n",
      "Epoch [39/100], Step [20700/6235], Loss: 11.7046\n",
      "Epoch [39/100], Step [20800/6235], Loss: 7.3449\n",
      "Epoch [39/100], Step [20900/6235], Loss: 19.5458\n",
      "Epoch [39/100], Step [21000/6235], Loss: 12.7607\n",
      "Epoch [39/100], Step [21100/6235], Loss: 3.9311\n",
      "Epoch [39/100], Step [21200/6235], Loss: 0.2726\n",
      "Epoch [39/100], Step [21300/6235], Loss: 0.2693\n",
      "Epoch [39/100], Step [21400/6235], Loss: 0.8115\n",
      "Epoch [39/100], Step [21500/6235], Loss: 0.6998\n",
      "Epoch [39/100], Step [21600/6235], Loss: 21.1760\n",
      "Epoch [39/100], Step [21700/6235], Loss: 0.2290\n",
      "Epoch [39/100], Step [21800/6235], Loss: 4.0482\n",
      "Epoch [39/100], Step [21900/6235], Loss: 1.6791\n",
      "Epoch [39/100], Step [22000/6235], Loss: 11.9256\n",
      "Epoch [39/100], Step [22100/6235], Loss: 0.1755\n",
      "Epoch [39/100], Step [22200/6235], Loss: 1.8029\n",
      "Epoch [39/100], Step [22300/6235], Loss: 0.7722\n",
      "Epoch [39/100], Step [22400/6235], Loss: 9.4926\n",
      "Epoch [39/100], Step [22500/6235], Loss: 177.9997\n",
      "Epoch [39/100], Step [22600/6235], Loss: 34.9520\n",
      "Epoch [39/100], Step [22700/6235], Loss: 0.7429\n",
      "Epoch [39/100], Step [22800/6235], Loss: 9.3975\n",
      "Epoch [39/100], Step [22900/6235], Loss: 20.8883\n",
      "Epoch [39/100], Step [23000/6235], Loss: 21.8379\n",
      "Epoch [39/100], Step [23100/6235], Loss: 5.4775\n",
      "Epoch [39/100], Step [23200/6235], Loss: 14.3337\n",
      "Epoch [39/100], Step [23300/6235], Loss: 16.5310\n",
      "Epoch [39/100], Step [23400/6235], Loss: 2.6830\n",
      "Epoch [39/100], Step [23500/6235], Loss: 0.5221\n",
      "Epoch [39/100], Step [23600/6235], Loss: 123.5004\n",
      "Epoch [39/100], Step [23700/6235], Loss: 3.9099\n",
      "Epoch [39/100], Step [23800/6235], Loss: 0.6913\n",
      "Epoch [39/100], Step [23900/6235], Loss: 0.5487\n",
      "Epoch [39/100], Step [24000/6235], Loss: 5.9973\n",
      "Epoch [39/100], Step [24100/6235], Loss: 1.0290\n",
      "Epoch [39/100], Step [24200/6235], Loss: 3.6939\n",
      "Epoch [39/100], Step [24300/6235], Loss: 0.1996\n",
      "Epoch [39/100], Step [24400/6235], Loss: 0.6354\n",
      "Epoch [39/100], Step [24500/6235], Loss: 6.5707\n",
      "Epoch [39/100], Step [24600/6235], Loss: 0.0953\n",
      "Epoch [39/100], Step [24700/6235], Loss: 0.0789\n",
      "Epoch [39/100], Step [24800/6235], Loss: 0.1551\n",
      "Epoch [39/100], Step [24900/6235], Loss: 6.4235\n",
      "Epoch [39/100], Step [25000/6235], Loss: 12.7697\n",
      "Epoch [39/100], Step [25100/6235], Loss: 12.7218\n",
      "Epoch [39/100], Step [25200/6235], Loss: 0.2425\n",
      "Epoch [39/100], Step [25300/6235], Loss: 4.1473\n",
      "Epoch [39/100], Step [25400/6235], Loss: 4.0169\n",
      "Epoch [39/100], Step [25500/6235], Loss: 8.4971\n",
      "Epoch [39/100], Step [25600/6235], Loss: 11.2262\n",
      "Epoch [39/100], Step [25700/6235], Loss: 1.2197\n",
      "Epoch [39/100], Step [25800/6235], Loss: 5.6130\n",
      "Epoch [39/100], Step [25900/6235], Loss: 0.0462\n",
      "Epoch [39/100], Step [26000/6235], Loss: 0.0147\n",
      "Epoch [39/100], Step [26100/6235], Loss: 0.7540\n",
      "Epoch [39/100], Step [26200/6235], Loss: 0.3481\n",
      "Epoch [39/100], Step [26300/6235], Loss: 0.4424\n",
      "Epoch [39/100], Step [26400/6235], Loss: 3.0192\n",
      "Epoch [39/100], Step [26500/6235], Loss: 0.0438\n",
      "Epoch [39/100], Step [26600/6235], Loss: 0.6184\n",
      "Epoch [39/100], Step [26700/6235], Loss: 0.0667\n",
      "Epoch [39/100], Step [26800/6235], Loss: 0.2553\n",
      "Epoch [39/100], Step [26900/6235], Loss: 0.1528\n",
      "Epoch [39/100], Step [27000/6235], Loss: 12.3651\n",
      "Epoch [39/100], Step [27100/6235], Loss: 0.0980\n",
      "Epoch [39/100], Step [27200/6235], Loss: 0.2631\n",
      "Epoch [39/100], Step [27300/6235], Loss: 0.0155\n",
      "Epoch [39/100], Step [27400/6235], Loss: 0.2736\n",
      "Epoch [39/100], Step [27500/6235], Loss: 0.1960\n",
      "Epoch [39/100], Step [27600/6235], Loss: 0.6477\n",
      "Epoch [39/100], Step [27700/6235], Loss: 0.8251\n",
      "Epoch [39/100], Step [27800/6235], Loss: 1.2875\n",
      "Epoch [39/100], Step [27900/6235], Loss: 0.0743\n",
      "Epoch [39/100], Step [28000/6235], Loss: 28.0041\n",
      "Epoch [39/100], Step [28100/6235], Loss: 1.3686\n",
      "Epoch [39/100], Step [28200/6235], Loss: 36.9422\n",
      "Epoch [39/100], Step [28300/6235], Loss: 2.6133\n",
      "Epoch [39/100], Step [28400/6235], Loss: 23.9607\n",
      "Epoch [39/100], Step [28500/6235], Loss: 2.1290\n",
      "Epoch [39/100], Step [28600/6235], Loss: 1.2717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Step [28700/6235], Loss: 2.7090\n",
      "Epoch [39/100], Step [28800/6235], Loss: 0.7026\n",
      "Epoch [39/100], Step [28900/6235], Loss: 36.3075\n",
      "Epoch [39/100], Step [29000/6235], Loss: 1.3159\n",
      "Epoch [39/100], Step [29100/6235], Loss: 0.3257\n",
      "Epoch [39/100], Step [29200/6235], Loss: 6.1399\n",
      "Epoch [39/100], Step [29300/6235], Loss: 4.2926\n",
      "Epoch [39/100], Step [29400/6235], Loss: 1.5772\n",
      "Epoch [39/100], Step [29500/6235], Loss: 1.2827\n",
      "Epoch [39/100], Step [29600/6235], Loss: 0.0587\n",
      "Epoch [39/100], Step [29700/6235], Loss: 3.0471\n",
      "Epoch [39/100], Step [29800/6235], Loss: 0.2622\n",
      "Epoch [39/100], Step [29900/6235], Loss: 6.2236\n",
      "Epoch [39/100], Step [30000/6235], Loss: 0.7511\n",
      "Epoch [39/100], Step [30100/6235], Loss: 7.0762\n",
      "Epoch [39/100], Step [30200/6235], Loss: 1.4689\n",
      "Epoch [39/100], Step [30300/6235], Loss: 0.1127\n",
      "Epoch [39/100], Step [30400/6235], Loss: 3.6191\n",
      "Epoch [39/100], Step [30500/6235], Loss: 0.1279\n",
      "Epoch [39/100], Step [30600/6235], Loss: 0.5651\n",
      "Epoch [39/100], Step [30700/6235], Loss: 3.0505\n",
      "Epoch [39/100], Step [30800/6235], Loss: 0.4420\n",
      "Epoch [39/100], Step [30900/6235], Loss: 1.0271\n",
      "Epoch [39/100], Step [31000/6235], Loss: 0.1806\n",
      "Epoch [39/100], Step [31100/6235], Loss: 1.2398\n",
      "Epoch [39/100], Step [31200/6235], Loss: 3.0458\n",
      "Epoch [39/100], Step [31300/6235], Loss: 1.4453\n",
      "Epoch [39/100], Step [31400/6235], Loss: 7.3334\n",
      "Epoch [39/100], Step [31500/6235], Loss: 0.6498\n",
      "Epoch [39/100], Step [31600/6235], Loss: 5.2628\n",
      "Epoch [39/100], Step [31700/6235], Loss: 28.9253\n",
      "Epoch [39/100], Step [31800/6235], Loss: 0.3791\n",
      "Epoch [39/100], Step [31900/6235], Loss: 1003.9463\n",
      "Epoch [39/100], Step [32000/6235], Loss: 1.9168\n",
      "Epoch [39/100], Step [32100/6235], Loss: 0.1593\n",
      "Epoch [39/100], Step [32200/6235], Loss: 157.8182\n",
      "Epoch [39/100], Step [32300/6235], Loss: 0.9179\n",
      "Epoch [39/100], Step [32400/6235], Loss: 0.8907\n",
      "Epoch [39/100], Step [32500/6235], Loss: 6.4765\n",
      "Epoch [39/100], Step [32600/6235], Loss: 0.1510\n",
      "Epoch [39/100], Step [32700/6235], Loss: 122.2224\n",
      "Epoch [39/100], Step [32800/6235], Loss: 10.3958\n",
      "Epoch [39/100], Step [32900/6235], Loss: 2.2535\n",
      "Epoch [39/100], Step [33000/6235], Loss: 0.5311\n",
      "Epoch [39/100], Step [33100/6235], Loss: 0.2456\n",
      "Epoch [39/100], Step [33200/6235], Loss: 1.1394\n",
      "Epoch [39/100], Step [33300/6235], Loss: 0.8789\n",
      "Epoch [39/100], Step [33400/6235], Loss: 135.2324\n",
      "Epoch [39/100], Step [33500/6235], Loss: 2.0693\n",
      "Epoch [39/100], Step [33600/6235], Loss: 0.4500\n",
      "Epoch [39/100], Step [33700/6235], Loss: 0.4090\n",
      "Epoch [39/100], Step [33800/6235], Loss: 0.3352\n",
      "Epoch [39/100], Step [33900/6235], Loss: 29.7221\n",
      "Epoch [39/100], Step [34000/6235], Loss: 0.1317\n",
      "Epoch [39/100], Step [34100/6235], Loss: 0.5816\n",
      "Epoch [39/100], Step [34200/6235], Loss: 2.1215\n",
      "Epoch [39/100], Step [34300/6235], Loss: 4.0451\n",
      "Epoch [39/100], Step [34400/6235], Loss: 0.1450\n",
      "Epoch [39/100], Step [34500/6235], Loss: 12.5422\n",
      "Epoch [39/100], Step [34600/6235], Loss: 2.6329\n",
      "Epoch [39/100], Step [34700/6235], Loss: 21.3855\n",
      "Epoch [39/100], Step [34800/6235], Loss: 10.9482\n",
      "Epoch [39/100], Step [34900/6235], Loss: 65.9865\n",
      "Epoch [39/100], Step [35000/6235], Loss: 0.0981\n",
      "Epoch [39/100], Step [35100/6235], Loss: 0.4726\n",
      "Epoch [39/100], Step [35200/6235], Loss: 0.6283\n",
      "Epoch [39/100], Step [35300/6235], Loss: 3.1818\n",
      "Epoch [39/100], Step [35400/6235], Loss: 0.5618\n",
      "Epoch [39/100], Step [35500/6235], Loss: 0.1551\n",
      "Epoch [39/100], Step [35600/6235], Loss: 3.4722\n",
      "Epoch [39/100], Step [35700/6235], Loss: 3.9943\n",
      "Epoch [39/100], Step [35800/6235], Loss: 0.7522\n",
      "Epoch [39/100], Step [35900/6235], Loss: 2.1578\n",
      "Epoch [39/100], Step [36000/6235], Loss: 0.2336\n",
      "Epoch [39/100], Step [36100/6235], Loss: 0.1613\n",
      "Epoch [39/100], Step [36200/6235], Loss: 38.5636\n",
      "Epoch [39/100], Step [36300/6235], Loss: 0.3366\n",
      "Epoch [39/100], Step [36400/6235], Loss: 2.9841\n",
      "Epoch [39/100], Step [36500/6235], Loss: 6.4966\n",
      "Epoch [39/100], Step [36600/6235], Loss: 0.0450\n",
      "Epoch [39/100], Step [36700/6235], Loss: 0.5005\n",
      "Epoch [39/100], Step [36800/6235], Loss: 1.6523\n",
      "Epoch [39/100], Step [36900/6235], Loss: 12.8157\n",
      "Epoch [39/100], Step [37000/6235], Loss: 1.0068\n",
      "Epoch [39/100], Step [37100/6235], Loss: 2.6098\n",
      "Epoch [39/100], Step [37200/6235], Loss: 0.0257\n",
      "Epoch [39/100], Step [37300/6235], Loss: 0.1756\n",
      "Epoch [39/100], Step [37400/6235], Loss: 0.1677\n",
      "Epoch [39/100], Step [37500/6235], Loss: 8.5341\n",
      "Epoch [39/100], Step [37600/6235], Loss: 11.8481\n",
      "Epoch [39/100], Step [37700/6235], Loss: 2.5201\n",
      "Epoch [39/100], Step [37800/6235], Loss: 1.5946\n",
      "Epoch [39/100], Step [37900/6235], Loss: 3.5497\n",
      "Epoch [39/100], Step [38000/6235], Loss: 1.0579\n",
      "Epoch [39/100], Step [38100/6235], Loss: 4.4763\n",
      "Epoch [39/100], Step [38200/6235], Loss: 2.7692\n",
      "Epoch [39/100], Step [38300/6235], Loss: 0.1395\n",
      "Epoch [39/100], Step [38400/6235], Loss: 0.1261\n",
      "Epoch [39/100], Step [38500/6235], Loss: 1.1909\n",
      "Epoch [39/100], Step [38600/6235], Loss: 0.5110\n",
      "Epoch [39/100], Step [38700/6235], Loss: 0.4645\n",
      "Epoch [39/100], Step [38800/6235], Loss: 0.1052\n",
      "Epoch [39/100], Step [38900/6235], Loss: 1.4112\n",
      "Epoch [39/100], Step [39000/6235], Loss: 21.1837\n",
      "Epoch [39/100], Step [39100/6235], Loss: 24.6481\n",
      "Epoch [39/100], Step [39200/6235], Loss: 0.5211\n",
      "Epoch [39/100], Step [39300/6235], Loss: 3.6079\n",
      "Epoch [39/100], Step [39400/6235], Loss: 167.6151\n",
      "Epoch [39/100], Step [39500/6235], Loss: 39.2211\n",
      "Epoch [39/100], Step [39600/6235], Loss: 10.4080\n",
      "Epoch [39/100], Step [39700/6235], Loss: 453.6524\n",
      "Epoch [39/100], Step [39800/6235], Loss: 111.3090\n",
      "Epoch [39/100], Step [39900/6235], Loss: 3.7611\n",
      "Epoch [39/100], Step [40000/6235], Loss: 22.2911\n",
      "Epoch [39/100], Step [40100/6235], Loss: 26.8579\n",
      "Epoch [39/100], Step [40200/6235], Loss: 38.1300\n",
      "Epoch [39/100], Step [40300/6235], Loss: 0.4506\n",
      "Epoch [39/100], Step [40400/6235], Loss: 1.5097\n",
      "Epoch [39/100], Step [40500/6235], Loss: 0.8701\n",
      "Epoch [39/100], Step [40600/6235], Loss: 2.2222\n",
      "Epoch [39/100], Step [40700/6235], Loss: 6.7465\n",
      "Epoch [39/100], Step [40800/6235], Loss: 3.5807\n",
      "Epoch [39/100], Step [40900/6235], Loss: 0.6447\n",
      "Epoch [39/100], Step [41000/6235], Loss: 13.5100\n",
      "Epoch [39/100], Step [41100/6235], Loss: 13.9055\n",
      "Epoch [39/100], Step [41200/6235], Loss: 16.3595\n",
      "Epoch [39/100], Step [41300/6235], Loss: 2.5262\n",
      "Epoch [39/100], Step [41400/6235], Loss: 2.0876\n",
      "Epoch [39/100], Step [41500/6235], Loss: 0.7479\n",
      "Epoch [39/100], Step [41600/6235], Loss: 0.4186\n",
      "Epoch [39/100], Step [41700/6235], Loss: 2.9047\n",
      "Epoch [39/100], Step [41800/6235], Loss: 4.1948\n",
      "Epoch [39/100], Step [41900/6235], Loss: 3.2915\n",
      "Epoch [39/100], Step [42000/6235], Loss: 3.0441\n",
      "Epoch [39/100], Step [42100/6235], Loss: 6.4297\n",
      "Epoch [39/100], Step [42200/6235], Loss: 5.5334\n",
      "Epoch [39/100], Step [42300/6235], Loss: 2.4195\n",
      "Epoch [39/100], Step [42400/6235], Loss: 5.4954\n",
      "Epoch [39/100], Step [42500/6235], Loss: 1.6995\n",
      "Epoch [39/100], Step [42600/6235], Loss: 0.6304\n",
      "Epoch [39/100], Step [42700/6235], Loss: 0.3060\n",
      "Epoch [39/100], Step [42800/6235], Loss: 1.4310\n",
      "Epoch [39/100], Step [42900/6235], Loss: 4.3164\n",
      "Epoch [39/100], Step [43000/6235], Loss: 0.2315\n",
      "Epoch [39/100], Step [43100/6235], Loss: 1.0991\n",
      "Epoch [39/100], Step [43200/6235], Loss: 0.6995\n",
      "Epoch [39/100], Step [43300/6235], Loss: 9.7569\n",
      "Epoch [39/100], Step [43400/6235], Loss: 7.3261\n",
      "Epoch [39/100], Step [43500/6235], Loss: 8.2396\n",
      "Epoch [39/100], Step [43600/6235], Loss: 28.7843\n",
      "Epoch [39/100], Step [43700/6235], Loss: 31.3098\n",
      "Epoch [39/100], Step [43800/6235], Loss: 0.3483\n",
      "Epoch [39/100], Step [43900/6235], Loss: 1.3247\n",
      "Epoch [39/100], Step [44000/6235], Loss: 48.0387\n",
      "Epoch [39/100], Step [44100/6235], Loss: 2.3753\n",
      "Epoch [39/100], Step [44200/6235], Loss: 40.4200\n",
      "Epoch [39/100], Step [44300/6235], Loss: 72.3144\n",
      "Epoch [39/100], Step [44400/6235], Loss: 4.4095\n",
      "Epoch [39/100], Step [44500/6235], Loss: 3.4237\n",
      "Epoch [39/100], Step [44600/6235], Loss: 25.9192\n",
      "Epoch [39/100], Step [44700/6235], Loss: 2.5861\n",
      "Epoch [39/100], Step [44800/6235], Loss: 0.4165\n",
      "Epoch [39/100], Step [44900/6235], Loss: 1.0246\n",
      "Epoch [39/100], Step [45000/6235], Loss: 3.4153\n",
      "Epoch [39/100], Step [45100/6235], Loss: 28.9324\n",
      "Epoch [39/100], Step [45200/6235], Loss: 0.3724\n",
      "Epoch [39/100], Step [45300/6235], Loss: 33.4797\n",
      "Epoch [39/100], Step [45400/6235], Loss: 6.4975\n",
      "Epoch [39/100], Step [45500/6235], Loss: 0.1575\n",
      "Epoch [39/100], Step [45600/6235], Loss: 0.6101\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [39/100], Step [45700/6235], Loss: 10.9224\n",
      "Epoch [39/100], Step [45800/6235], Loss: 228.5266\n",
      "Epoch [39/100], Step [45900/6235], Loss: 1.2631\n",
      "Epoch [39/100], Step [46000/6235], Loss: 16.9942\n",
      "Epoch [39/100], Step [46100/6235], Loss: 11.9176\n",
      "Epoch [39/100], Step [46200/6235], Loss: 33.0717\n",
      "Epoch [39/100], Step [46300/6235], Loss: 5.9872\n",
      "Epoch [39/100], Step [46400/6235], Loss: 1.1610\n",
      "Epoch [39/100], Step [46500/6235], Loss: 5.6759\n",
      "Epoch [39/100], Step [46600/6235], Loss: 11.6729\n",
      "Epoch [39/100], Step [46700/6235], Loss: 0.8750\n",
      "Epoch [39/100], Step [46800/6235], Loss: 24.6734\n",
      "Epoch [39/100], Step [46900/6235], Loss: 23.3152\n",
      "Epoch [39/100], Step [47000/6235], Loss: 0.5987\n",
      "Epoch [39/100], Step [47100/6235], Loss: 59.1129\n",
      "Epoch [39/100], Step [47200/6235], Loss: 68.3318\n",
      "Epoch [39/100], Step [47300/6235], Loss: 0.7043\n",
      "Epoch [39/100], Step [47400/6235], Loss: 136.4196\n",
      "Epoch [39/100], Step [47500/6235], Loss: 1.9280\n",
      "Epoch [39/100], Step [47600/6235], Loss: 16.0482\n",
      "Epoch [39/100], Step [47700/6235], Loss: 14.6379\n",
      "Epoch [39/100], Step [47800/6235], Loss: 19.2945\n",
      "Epoch [39/100], Step [47900/6235], Loss: 16.7242\n",
      "Epoch [39/100], Step [48000/6235], Loss: 62.0659\n",
      "Epoch [39/100], Step [48100/6235], Loss: 8.3652\n",
      "Epoch [39/100], Step [48200/6235], Loss: 16.8138\n",
      "Epoch [39/100], Step [48300/6235], Loss: 463.4380\n",
      "Epoch [39/100], Step [48400/6235], Loss: 12.3025\n",
      "Epoch [39/100], Step [48500/6235], Loss: 44.9127\n",
      "Epoch [39/100], Step [48600/6235], Loss: 118.1813\n",
      "Epoch [39/100], Step [48700/6235], Loss: 0.3066\n",
      "Epoch [39/100], Step [48800/6235], Loss: 245.5485\n",
      "Epoch [39/100], Step [48900/6235], Loss: 861.8132\n",
      "Epoch [39/100], Step [49000/6235], Loss: 262.3090\n",
      "Epoch [39/100], Step [49100/6235], Loss: 1963.5486\n",
      "Epoch [39/100], Step [49200/6235], Loss: 719.0248\n",
      "Epoch [39/100], Step [49300/6235], Loss: 1243.5736\n",
      "Epoch [39/100], Step [49400/6235], Loss: 21.7841\n",
      "Epoch [39/100], Step [49500/6235], Loss: 5.0457\n",
      "Epoch [39/100], Step [49600/6235], Loss: 217.4267\n",
      "Epoch [39/100], Step [49700/6235], Loss: 4186.6533\n",
      "Epoch [39/100], Step [49800/6235], Loss: 218.1308\n",
      "Epoch [40/100], Step [100/6235], Loss: 10.3572\n",
      "Epoch [40/100], Step [200/6235], Loss: 1.2973\n",
      "Epoch [40/100], Step [300/6235], Loss: 0.3668\n",
      "Epoch [40/100], Step [400/6235], Loss: 0.4162\n",
      "Epoch [40/100], Step [500/6235], Loss: 0.8197\n",
      "Epoch [40/100], Step [600/6235], Loss: 0.0944\n",
      "Epoch [40/100], Step [700/6235], Loss: 0.6005\n",
      "Epoch [40/100], Step [800/6235], Loss: 0.0448\n",
      "Epoch [40/100], Step [900/6235], Loss: 0.0838\n",
      "Epoch [40/100], Step [1000/6235], Loss: 0.0269\n",
      "Epoch [40/100], Step [1100/6235], Loss: 0.1346\n",
      "Epoch [40/100], Step [1200/6235], Loss: 0.1388\n",
      "Epoch [40/100], Step [1300/6235], Loss: 0.0232\n",
      "Epoch [40/100], Step [1400/6235], Loss: 0.3753\n",
      "Epoch [40/100], Step [1500/6235], Loss: 0.0098\n",
      "Epoch [40/100], Step [1600/6235], Loss: 0.2707\n",
      "Epoch [40/100], Step [1700/6235], Loss: 0.3208\n",
      "Epoch [40/100], Step [1800/6235], Loss: 0.4042\n",
      "Epoch [40/100], Step [1900/6235], Loss: 0.2623\n",
      "Epoch [40/100], Step [2000/6235], Loss: 2.0653\n",
      "Epoch [40/100], Step [2100/6235], Loss: 4.0834\n",
      "Epoch [40/100], Step [2200/6235], Loss: 2.9397\n",
      "Epoch [40/100], Step [2300/6235], Loss: 3.1287\n",
      "Epoch [40/100], Step [2400/6235], Loss: 8.1431\n",
      "Epoch [40/100], Step [2500/6235], Loss: 12.9984\n",
      "Epoch [40/100], Step [2600/6235], Loss: 16.0188\n",
      "Epoch [40/100], Step [2700/6235], Loss: 22.2405\n",
      "Epoch [40/100], Step [2800/6235], Loss: 10.8185\n",
      "Epoch [40/100], Step [2900/6235], Loss: 6.6043\n",
      "Epoch [40/100], Step [3000/6235], Loss: 3.0985\n",
      "Epoch [40/100], Step [3100/6235], Loss: 105.3409\n",
      "Epoch [40/100], Step [3200/6235], Loss: 7.1475\n",
      "Epoch [40/100], Step [3300/6235], Loss: 0.4592\n",
      "Epoch [40/100], Step [3400/6235], Loss: 7.3756\n",
      "Epoch [40/100], Step [3500/6235], Loss: 68.8334\n",
      "Epoch [40/100], Step [3600/6235], Loss: 2.2941\n",
      "Epoch [40/100], Step [3700/6235], Loss: 0.1248\n",
      "Epoch [40/100], Step [3800/6235], Loss: 0.2223\n",
      "Epoch [40/100], Step [3900/6235], Loss: 0.1624\n",
      "Epoch [40/100], Step [4000/6235], Loss: 0.4875\n",
      "Epoch [40/100], Step [4100/6235], Loss: 6.8448\n",
      "Epoch [40/100], Step [4200/6235], Loss: 1.9411\n",
      "Epoch [40/100], Step [4300/6235], Loss: 2.2342\n",
      "Epoch [40/100], Step [4400/6235], Loss: 0.0123\n",
      "Epoch [40/100], Step [4500/6235], Loss: 55.6048\n",
      "Epoch [40/100], Step [4600/6235], Loss: 14.8762\n",
      "Epoch [40/100], Step [4700/6235], Loss: 1.2403\n",
      "Epoch [40/100], Step [4800/6235], Loss: 2.2709\n",
      "Epoch [40/100], Step [4900/6235], Loss: 1.9418\n",
      "Epoch [40/100], Step [5000/6235], Loss: 0.1736\n",
      "Epoch [40/100], Step [5100/6235], Loss: 6.6357\n",
      "Epoch [40/100], Step [5200/6235], Loss: 1.8382\n",
      "Epoch [40/100], Step [5300/6235], Loss: 13.4608\n",
      "Epoch [40/100], Step [5400/6235], Loss: 3.8532\n",
      "Epoch [40/100], Step [5500/6235], Loss: 0.6419\n",
      "Epoch [40/100], Step [5600/6235], Loss: 0.4105\n",
      "Epoch [40/100], Step [5700/6235], Loss: 0.2082\n",
      "Epoch [40/100], Step [5800/6235], Loss: 0.7023\n",
      "Epoch [40/100], Step [5900/6235], Loss: 0.0179\n",
      "Epoch [40/100], Step [6000/6235], Loss: 1.0593\n",
      "Epoch [40/100], Step [6100/6235], Loss: 0.0307\n",
      "Epoch [40/100], Step [6200/6235], Loss: 5.9824\n",
      "Epoch [40/100], Step [6300/6235], Loss: 0.6839\n",
      "Epoch [40/100], Step [6400/6235], Loss: 0.0814\n",
      "Epoch [40/100], Step [6500/6235], Loss: 3.6968\n",
      "Epoch [40/100], Step [6600/6235], Loss: 3.7185\n",
      "Epoch [40/100], Step [6700/6235], Loss: 0.9408\n",
      "Epoch [40/100], Step [6800/6235], Loss: 0.3586\n",
      "Epoch [40/100], Step [6900/6235], Loss: 0.4316\n",
      "Epoch [40/100], Step [7000/6235], Loss: 0.0422\n",
      "Epoch [40/100], Step [7100/6235], Loss: 0.7382\n",
      "Epoch [40/100], Step [7200/6235], Loss: 1.2321\n",
      "Epoch [40/100], Step [7300/6235], Loss: 0.6302\n",
      "Epoch [40/100], Step [7400/6235], Loss: 0.0321\n",
      "Epoch [40/100], Step [7500/6235], Loss: 0.5455\n",
      "Epoch [40/100], Step [7600/6235], Loss: 4.6182\n",
      "Epoch [40/100], Step [7700/6235], Loss: 6.1965\n",
      "Epoch [40/100], Step [7800/6235], Loss: 4.9821\n",
      "Epoch [40/100], Step [7900/6235], Loss: 9.5088\n",
      "Epoch [40/100], Step [8000/6235], Loss: 0.9568\n",
      "Epoch [40/100], Step [8100/6235], Loss: 0.1227\n",
      "Epoch [40/100], Step [8200/6235], Loss: 11.1710\n",
      "Epoch [40/100], Step [8300/6235], Loss: 8.7396\n",
      "Epoch [40/100], Step [8400/6235], Loss: 603.5510\n",
      "Epoch [40/100], Step [8500/6235], Loss: 17.7461\n",
      "Epoch [40/100], Step [8600/6235], Loss: 40.6851\n",
      "Epoch [40/100], Step [8700/6235], Loss: 46.2546\n",
      "Epoch [40/100], Step [8800/6235], Loss: 795.7942\n",
      "Epoch [40/100], Step [8900/6235], Loss: 282.9380\n",
      "Epoch [40/100], Step [9000/6235], Loss: 437.7511\n",
      "Epoch [40/100], Step [9100/6235], Loss: 471.6114\n",
      "Epoch [40/100], Step [9200/6235], Loss: 2594.9285\n",
      "Epoch [40/100], Step [9300/6235], Loss: 41.6555\n",
      "Epoch [40/100], Step [9400/6235], Loss: 745.8282\n",
      "Epoch [40/100], Step [9500/6235], Loss: 1223.2783\n",
      "Epoch [40/100], Step [9600/6235], Loss: 537.7018\n",
      "Epoch [40/100], Step [9700/6235], Loss: 4.9369\n",
      "Epoch [40/100], Step [9800/6235], Loss: 50.8146\n",
      "Epoch [40/100], Step [9900/6235], Loss: 16.8420\n",
      "Epoch [40/100], Step [10000/6235], Loss: 28.8566\n",
      "Epoch [40/100], Step [10100/6235], Loss: 5.4387\n",
      "Epoch [40/100], Step [10200/6235], Loss: 1060.4114\n",
      "Epoch [40/100], Step [10300/6235], Loss: 7.6666\n",
      "Epoch [40/100], Step [10400/6235], Loss: 9.1848\n",
      "Epoch [40/100], Step [10500/6235], Loss: 107.0174\n",
      "Epoch [40/100], Step [10600/6235], Loss: 636.7121\n",
      "Epoch [40/100], Step [10700/6235], Loss: 21.2883\n",
      "Epoch [40/100], Step [10800/6235], Loss: 90.2497\n",
      "Epoch [40/100], Step [10900/6235], Loss: 98.6984\n",
      "Epoch [40/100], Step [11000/6235], Loss: 297.3624\n",
      "Epoch [40/100], Step [11100/6235], Loss: 31.2598\n",
      "Epoch [40/100], Step [11200/6235], Loss: 5.3137\n",
      "Epoch [40/100], Step [11300/6235], Loss: 108.8509\n",
      "Epoch [40/100], Step [11400/6235], Loss: 4.2933\n",
      "Epoch [40/100], Step [11500/6235], Loss: 7.4593\n",
      "Epoch [40/100], Step [11600/6235], Loss: 5.3680\n",
      "Epoch [40/100], Step [11700/6235], Loss: 41.6731\n",
      "Epoch [40/100], Step [11800/6235], Loss: 198.0913\n",
      "Epoch [40/100], Step [11900/6235], Loss: 29.7773\n",
      "Epoch [40/100], Step [12000/6235], Loss: 552.7816\n",
      "Epoch [40/100], Step [12100/6235], Loss: 171.2110\n",
      "Epoch [40/100], Step [12200/6235], Loss: 29.4493\n",
      "Epoch [40/100], Step [12300/6235], Loss: 12.8485\n",
      "Epoch [40/100], Step [12400/6235], Loss: 645.2410\n",
      "Epoch [40/100], Step [12500/6235], Loss: 33.1556\n",
      "Epoch [40/100], Step [12600/6235], Loss: 57.9249\n",
      "Epoch [40/100], Step [12700/6235], Loss: 2.2383\n",
      "Epoch [40/100], Step [12800/6235], Loss: 12.1501\n",
      "Epoch [40/100], Step [12900/6235], Loss: 39.9150\n",
      "Epoch [40/100], Step [13000/6235], Loss: 0.5527\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Step [13100/6235], Loss: 71.3294\n",
      "Epoch [40/100], Step [13200/6235], Loss: 14.6060\n",
      "Epoch [40/100], Step [13300/6235], Loss: 36.2201\n",
      "Epoch [40/100], Step [13400/6235], Loss: 253.4806\n",
      "Epoch [40/100], Step [13500/6235], Loss: 4.5417\n",
      "Epoch [40/100], Step [13600/6235], Loss: 0.5669\n",
      "Epoch [40/100], Step [13700/6235], Loss: 87.6489\n",
      "Epoch [40/100], Step [13800/6235], Loss: 141.6561\n",
      "Epoch [40/100], Step [13900/6235], Loss: 34.5178\n",
      "Epoch [40/100], Step [14000/6235], Loss: 14.9295\n",
      "Epoch [40/100], Step [14100/6235], Loss: 12.5078\n",
      "Epoch [40/100], Step [14200/6235], Loss: 81.6681\n",
      "Epoch [40/100], Step [14300/6235], Loss: 66.9440\n",
      "Epoch [40/100], Step [14400/6235], Loss: 38.4682\n",
      "Epoch [40/100], Step [14500/6235], Loss: 39.9096\n",
      "Epoch [40/100], Step [14600/6235], Loss: 0.1083\n",
      "Epoch [40/100], Step [14700/6235], Loss: 44.0742\n",
      "Epoch [40/100], Step [14800/6235], Loss: 33.4966\n",
      "Epoch [40/100], Step [14900/6235], Loss: 1.3523\n",
      "Epoch [40/100], Step [15000/6235], Loss: 2.1973\n",
      "Epoch [40/100], Step [15100/6235], Loss: 0.3443\n",
      "Epoch [40/100], Step [15200/6235], Loss: 2.6144\n",
      "Epoch [40/100], Step [15300/6235], Loss: 19.1536\n",
      "Epoch [40/100], Step [15400/6235], Loss: 31.8780\n",
      "Epoch [40/100], Step [15500/6235], Loss: 17.7943\n",
      "Epoch [40/100], Step [15600/6235], Loss: 71.6989\n",
      "Epoch [40/100], Step [15700/6235], Loss: 79.5035\n",
      "Epoch [40/100], Step [15800/6235], Loss: 10.0702\n",
      "Epoch [40/100], Step [15900/6235], Loss: 0.5291\n",
      "Epoch [40/100], Step [16000/6235], Loss: 123.9648\n",
      "Epoch [40/100], Step [16100/6235], Loss: 1.4596\n",
      "Epoch [40/100], Step [16200/6235], Loss: 1.1221\n",
      "Epoch [40/100], Step [16300/6235], Loss: 10.3702\n",
      "Epoch [40/100], Step [16400/6235], Loss: 32.0149\n",
      "Epoch [40/100], Step [16500/6235], Loss: 634.2854\n",
      "Epoch [40/100], Step [16600/6235], Loss: 21.5468\n",
      "Epoch [40/100], Step [16700/6235], Loss: 0.5997\n",
      "Epoch [40/100], Step [16800/6235], Loss: 7.9535\n",
      "Epoch [40/100], Step [16900/6235], Loss: 0.0761\n",
      "Epoch [40/100], Step [17000/6235], Loss: 0.2571\n",
      "Epoch [40/100], Step [17100/6235], Loss: 0.3892\n",
      "Epoch [40/100], Step [17200/6235], Loss: 307.9129\n",
      "Epoch [40/100], Step [17300/6235], Loss: 49.4793\n",
      "Epoch [40/100], Step [17400/6235], Loss: 39.2689\n",
      "Epoch [40/100], Step [17500/6235], Loss: 0.7130\n",
      "Epoch [40/100], Step [17600/6235], Loss: 4.3299\n",
      "Epoch [40/100], Step [17700/6235], Loss: 32.6840\n",
      "Epoch [40/100], Step [17800/6235], Loss: 15.4139\n",
      "Epoch [40/100], Step [17900/6235], Loss: 20.2073\n",
      "Epoch [40/100], Step [18000/6235], Loss: 10.8880\n",
      "Epoch [40/100], Step [18100/6235], Loss: 16.0163\n",
      "Epoch [40/100], Step [18200/6235], Loss: 0.5719\n",
      "Epoch [40/100], Step [18300/6235], Loss: 0.9404\n",
      "Epoch [40/100], Step [18400/6235], Loss: 1.2432\n",
      "Epoch [40/100], Step [18500/6235], Loss: 33.2219\n",
      "Epoch [40/100], Step [18600/6235], Loss: 4.9560\n",
      "Epoch [40/100], Step [18700/6235], Loss: 1.5070\n",
      "Epoch [40/100], Step [18800/6235], Loss: 174.0058\n",
      "Epoch [40/100], Step [18900/6235], Loss: 67.6340\n",
      "Epoch [40/100], Step [19000/6235], Loss: 11.4369\n",
      "Epoch [40/100], Step [19100/6235], Loss: 0.9978\n",
      "Epoch [40/100], Step [19200/6235], Loss: 5.0593\n",
      "Epoch [40/100], Step [19300/6235], Loss: 7.7938\n",
      "Epoch [40/100], Step [19400/6235], Loss: 306.4067\n",
      "Epoch [40/100], Step [19500/6235], Loss: 71.0647\n",
      "Epoch [40/100], Step [19600/6235], Loss: 63.3768\n",
      "Epoch [40/100], Step [19700/6235], Loss: 12.7587\n",
      "Epoch [40/100], Step [19800/6235], Loss: 5.2246\n",
      "Epoch [40/100], Step [19900/6235], Loss: 0.1254\n",
      "Epoch [40/100], Step [20000/6235], Loss: 69.8217\n",
      "Epoch [40/100], Step [20100/6235], Loss: 0.0391\n",
      "Epoch [40/100], Step [20200/6235], Loss: 7.3801\n",
      "Epoch [40/100], Step [20300/6235], Loss: 2.0255\n",
      "Epoch [40/100], Step [20400/6235], Loss: 19.2355\n",
      "Epoch [40/100], Step [20500/6235], Loss: 47.5618\n",
      "Epoch [40/100], Step [20600/6235], Loss: 128.6224\n",
      "Epoch [40/100], Step [20700/6235], Loss: 34.8900\n",
      "Epoch [40/100], Step [20800/6235], Loss: 6.3432\n",
      "Epoch [40/100], Step [20900/6235], Loss: 1.4374\n",
      "Epoch [40/100], Step [21000/6235], Loss: 12.6918\n",
      "Epoch [40/100], Step [21100/6235], Loss: 6.2310\n",
      "Epoch [40/100], Step [21200/6235], Loss: 0.3225\n",
      "Epoch [40/100], Step [21300/6235], Loss: 0.0365\n",
      "Epoch [40/100], Step [21400/6235], Loss: 3.0989\n",
      "Epoch [40/100], Step [21500/6235], Loss: 1.2668\n",
      "Epoch [40/100], Step [21600/6235], Loss: 32.0784\n",
      "Epoch [40/100], Step [21700/6235], Loss: 0.3427\n",
      "Epoch [40/100], Step [21800/6235], Loss: 5.3502\n",
      "Epoch [40/100], Step [21900/6235], Loss: 1.7087\n",
      "Epoch [40/100], Step [22000/6235], Loss: 9.6115\n",
      "Epoch [40/100], Step [22100/6235], Loss: 0.1297\n",
      "Epoch [40/100], Step [22200/6235], Loss: 4.9525\n",
      "Epoch [40/100], Step [22300/6235], Loss: 1.2777\n",
      "Epoch [40/100], Step [22400/6235], Loss: 12.6010\n",
      "Epoch [40/100], Step [22500/6235], Loss: 72.4308\n",
      "Epoch [40/100], Step [22600/6235], Loss: 35.6382\n",
      "Epoch [40/100], Step [22700/6235], Loss: 0.8190\n",
      "Epoch [40/100], Step [22800/6235], Loss: 10.9217\n",
      "Epoch [40/100], Step [22900/6235], Loss: 23.5484\n",
      "Epoch [40/100], Step [23000/6235], Loss: 20.4448\n",
      "Epoch [40/100], Step [23100/6235], Loss: 5.7345\n",
      "Epoch [40/100], Step [23200/6235], Loss: 3.8621\n",
      "Epoch [40/100], Step [23300/6235], Loss: 17.9123\n",
      "Epoch [40/100], Step [23400/6235], Loss: 2.0585\n",
      "Epoch [40/100], Step [23500/6235], Loss: 0.0798\n",
      "Epoch [40/100], Step [23600/6235], Loss: 131.9152\n",
      "Epoch [40/100], Step [23700/6235], Loss: 2.6368\n",
      "Epoch [40/100], Step [23800/6235], Loss: 0.8992\n",
      "Epoch [40/100], Step [23900/6235], Loss: 3.4623\n",
      "Epoch [40/100], Step [24000/6235], Loss: 0.8493\n",
      "Epoch [40/100], Step [24100/6235], Loss: 0.1087\n",
      "Epoch [40/100], Step [24200/6235], Loss: 34.5239\n",
      "Epoch [40/100], Step [24300/6235], Loss: 0.6047\n",
      "Epoch [40/100], Step [24400/6235], Loss: 0.3181\n",
      "Epoch [40/100], Step [24500/6235], Loss: 0.8895\n",
      "Epoch [40/100], Step [24600/6235], Loss: 0.1001\n",
      "Epoch [40/100], Step [24700/6235], Loss: 0.3433\n",
      "Epoch [40/100], Step [24800/6235], Loss: 0.4705\n",
      "Epoch [40/100], Step [24900/6235], Loss: 12.5506\n",
      "Epoch [40/100], Step [25000/6235], Loss: 14.6593\n",
      "Epoch [40/100], Step [25100/6235], Loss: 6.4041\n",
      "Epoch [40/100], Step [25200/6235], Loss: 0.2160\n",
      "Epoch [40/100], Step [25300/6235], Loss: 0.9023\n",
      "Epoch [40/100], Step [25400/6235], Loss: 3.8025\n",
      "Epoch [40/100], Step [25500/6235], Loss: 8.8661\n",
      "Epoch [40/100], Step [25600/6235], Loss: 7.5583\n",
      "Epoch [40/100], Step [25700/6235], Loss: 0.1476\n",
      "Epoch [40/100], Step [25800/6235], Loss: 0.1659\n",
      "Epoch [40/100], Step [25900/6235], Loss: 5.5732\n",
      "Epoch [40/100], Step [26000/6235], Loss: 1.5816\n",
      "Epoch [40/100], Step [26100/6235], Loss: 0.0581\n",
      "Epoch [40/100], Step [26200/6235], Loss: 1.4410\n",
      "Epoch [40/100], Step [26300/6235], Loss: 1.1177\n",
      "Epoch [40/100], Step [26400/6235], Loss: 0.5881\n",
      "Epoch [40/100], Step [26500/6235], Loss: 0.0479\n",
      "Epoch [40/100], Step [26600/6235], Loss: 0.2815\n",
      "Epoch [40/100], Step [26700/6235], Loss: 0.1351\n",
      "Epoch [40/100], Step [26800/6235], Loss: 0.0874\n",
      "Epoch [40/100], Step [26900/6235], Loss: 0.0660\n",
      "Epoch [40/100], Step [27000/6235], Loss: 16.2576\n",
      "Epoch [40/100], Step [27100/6235], Loss: 0.0706\n",
      "Epoch [40/100], Step [27200/6235], Loss: 0.0084\n",
      "Epoch [40/100], Step [27300/6235], Loss: 0.0391\n",
      "Epoch [40/100], Step [27400/6235], Loss: 0.5928\n",
      "Epoch [40/100], Step [27500/6235], Loss: 6.0238\n",
      "Epoch [40/100], Step [27600/6235], Loss: 0.6825\n",
      "Epoch [40/100], Step [27700/6235], Loss: 0.8113\n",
      "Epoch [40/100], Step [27800/6235], Loss: 5.8128\n",
      "Epoch [40/100], Step [27900/6235], Loss: 1.2270\n",
      "Epoch [40/100], Step [28000/6235], Loss: 55.0611\n",
      "Epoch [40/100], Step [28100/6235], Loss: 0.7984\n",
      "Epoch [40/100], Step [28200/6235], Loss: 28.5170\n",
      "Epoch [40/100], Step [28300/6235], Loss: 1.0244\n",
      "Epoch [40/100], Step [28400/6235], Loss: 16.6319\n",
      "Epoch [40/100], Step [28500/6235], Loss: 3.1461\n",
      "Epoch [40/100], Step [28600/6235], Loss: 1.2451\n",
      "Epoch [40/100], Step [28700/6235], Loss: 3.1469\n",
      "Epoch [40/100], Step [28800/6235], Loss: 0.6641\n",
      "Epoch [40/100], Step [28900/6235], Loss: 47.9491\n",
      "Epoch [40/100], Step [29000/6235], Loss: 7.7792\n",
      "Epoch [40/100], Step [29100/6235], Loss: 0.7904\n",
      "Epoch [40/100], Step [29200/6235], Loss: 5.3685\n",
      "Epoch [40/100], Step [29300/6235], Loss: 0.8380\n",
      "Epoch [40/100], Step [29400/6235], Loss: 0.0751\n",
      "Epoch [40/100], Step [29500/6235], Loss: 3.0181\n",
      "Epoch [40/100], Step [29600/6235], Loss: 0.3316\n",
      "Epoch [40/100], Step [29700/6235], Loss: 2.7544\n",
      "Epoch [40/100], Step [29800/6235], Loss: 0.7255\n",
      "Epoch [40/100], Step [29900/6235], Loss: 0.6785\n",
      "Epoch [40/100], Step [30000/6235], Loss: 2.0587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Step [30100/6235], Loss: 6.5703\n",
      "Epoch [40/100], Step [30200/6235], Loss: 1.8979\n",
      "Epoch [40/100], Step [30300/6235], Loss: 0.0626\n",
      "Epoch [40/100], Step [30400/6235], Loss: 2.3361\n",
      "Epoch [40/100], Step [30500/6235], Loss: 0.8360\n",
      "Epoch [40/100], Step [30600/6235], Loss: 1.3464\n",
      "Epoch [40/100], Step [30700/6235], Loss: 2.4325\n",
      "Epoch [40/100], Step [30800/6235], Loss: 0.5060\n",
      "Epoch [40/100], Step [30900/6235], Loss: 1.6381\n",
      "Epoch [40/100], Step [31000/6235], Loss: 0.3193\n",
      "Epoch [40/100], Step [31100/6235], Loss: 0.4129\n",
      "Epoch [40/100], Step [31200/6235], Loss: 5.3336\n",
      "Epoch [40/100], Step [31300/6235], Loss: 2.3484\n",
      "Epoch [40/100], Step [31400/6235], Loss: 9.0466\n",
      "Epoch [40/100], Step [31500/6235], Loss: 0.9373\n",
      "Epoch [40/100], Step [31600/6235], Loss: 6.1905\n",
      "Epoch [40/100], Step [31700/6235], Loss: 8.5605\n",
      "Epoch [40/100], Step [31800/6235], Loss: 0.1336\n",
      "Epoch [40/100], Step [31900/6235], Loss: 434.4103\n",
      "Epoch [40/100], Step [32000/6235], Loss: 114.0062\n",
      "Epoch [40/100], Step [32100/6235], Loss: 1.8238\n",
      "Epoch [40/100], Step [32200/6235], Loss: 86.9946\n",
      "Epoch [40/100], Step [32300/6235], Loss: 2.3136\n",
      "Epoch [40/100], Step [32400/6235], Loss: 1.5641\n",
      "Epoch [40/100], Step [32500/6235], Loss: 15.5700\n",
      "Epoch [40/100], Step [32600/6235], Loss: 0.5002\n",
      "Epoch [40/100], Step [32700/6235], Loss: 185.0365\n",
      "Epoch [40/100], Step [32800/6235], Loss: 7.7221\n",
      "Epoch [40/100], Step [32900/6235], Loss: 2.4325\n",
      "Epoch [40/100], Step [33000/6235], Loss: 1.1006\n",
      "Epoch [40/100], Step [33100/6235], Loss: 0.2708\n",
      "Epoch [40/100], Step [33200/6235], Loss: 6.3926\n",
      "Epoch [40/100], Step [33300/6235], Loss: 0.2628\n",
      "Epoch [40/100], Step [33400/6235], Loss: 16.9774\n",
      "Epoch [40/100], Step [33500/6235], Loss: 4.1495\n",
      "Epoch [40/100], Step [33600/6235], Loss: 10.3653\n",
      "Epoch [40/100], Step [33700/6235], Loss: 15.2760\n",
      "Epoch [40/100], Step [33800/6235], Loss: 0.6656\n",
      "Epoch [40/100], Step [33900/6235], Loss: 34.3730\n",
      "Epoch [40/100], Step [34000/6235], Loss: 0.1430\n",
      "Epoch [40/100], Step [34100/6235], Loss: 0.6953\n",
      "Epoch [40/100], Step [34200/6235], Loss: 2.1191\n",
      "Epoch [40/100], Step [34300/6235], Loss: 3.3688\n",
      "Epoch [40/100], Step [34400/6235], Loss: 0.1114\n",
      "Epoch [40/100], Step [34500/6235], Loss: 14.8125\n",
      "Epoch [40/100], Step [34600/6235], Loss: 2.5813\n",
      "Epoch [40/100], Step [34700/6235], Loss: 27.5979\n",
      "Epoch [40/100], Step [34800/6235], Loss: 9.4798\n",
      "Epoch [40/100], Step [34900/6235], Loss: 66.9968\n",
      "Epoch [40/100], Step [35000/6235], Loss: 0.1887\n",
      "Epoch [40/100], Step [35100/6235], Loss: 0.7572\n",
      "Epoch [40/100], Step [35200/6235], Loss: 0.5930\n",
      "Epoch [40/100], Step [35300/6235], Loss: 3.1268\n",
      "Epoch [40/100], Step [35400/6235], Loss: 0.6103\n",
      "Epoch [40/100], Step [35500/6235], Loss: 0.5984\n",
      "Epoch [40/100], Step [35600/6235], Loss: 1.9162\n",
      "Epoch [40/100], Step [35700/6235], Loss: 4.1523\n",
      "Epoch [40/100], Step [35800/6235], Loss: 1.5796\n",
      "Epoch [40/100], Step [35900/6235], Loss: 1.5162\n",
      "Epoch [40/100], Step [36000/6235], Loss: 0.0531\n",
      "Epoch [40/100], Step [36100/6235], Loss: 0.1064\n",
      "Epoch [40/100], Step [36200/6235], Loss: 26.3801\n",
      "Epoch [40/100], Step [36300/6235], Loss: 0.0666\n",
      "Epoch [40/100], Step [36400/6235], Loss: 3.0508\n",
      "Epoch [40/100], Step [36500/6235], Loss: 7.4546\n",
      "Epoch [40/100], Step [36600/6235], Loss: 0.1137\n",
      "Epoch [40/100], Step [36700/6235], Loss: 0.6159\n",
      "Epoch [40/100], Step [36800/6235], Loss: 4.6966\n",
      "Epoch [40/100], Step [36900/6235], Loss: 10.5264\n",
      "Epoch [40/100], Step [37000/6235], Loss: 0.9855\n",
      "Epoch [40/100], Step [37100/6235], Loss: 1.9660\n",
      "Epoch [40/100], Step [37200/6235], Loss: 0.0407\n",
      "Epoch [40/100], Step [37300/6235], Loss: 0.0453\n",
      "Epoch [40/100], Step [37400/6235], Loss: 0.1726\n",
      "Epoch [40/100], Step [37500/6235], Loss: 7.1841\n",
      "Epoch [40/100], Step [37600/6235], Loss: 12.2919\n",
      "Epoch [40/100], Step [37700/6235], Loss: 2.4820\n",
      "Epoch [40/100], Step [37800/6235], Loss: 3.3905\n",
      "Epoch [40/100], Step [37900/6235], Loss: 8.9965\n",
      "Epoch [40/100], Step [38000/6235], Loss: 0.7299\n",
      "Epoch [40/100], Step [38100/6235], Loss: 5.2834\n",
      "Epoch [40/100], Step [38200/6235], Loss: 2.4785\n",
      "Epoch [40/100], Step [38300/6235], Loss: 0.2621\n",
      "Epoch [40/100], Step [38400/6235], Loss: 0.0985\n",
      "Epoch [40/100], Step [38500/6235], Loss: 1.4102\n",
      "Epoch [40/100], Step [38600/6235], Loss: 0.3477\n",
      "Epoch [40/100], Step [38700/6235], Loss: 0.4380\n",
      "Epoch [40/100], Step [38800/6235], Loss: 0.1402\n",
      "Epoch [40/100], Step [38900/6235], Loss: 10.2258\n",
      "Epoch [40/100], Step [39000/6235], Loss: 0.3168\n",
      "Epoch [40/100], Step [39100/6235], Loss: 1.6706\n",
      "Epoch [40/100], Step [39200/6235], Loss: 0.3699\n",
      "Epoch [40/100], Step [39300/6235], Loss: 1.7778\n",
      "Epoch [40/100], Step [39400/6235], Loss: 401.3566\n",
      "Epoch [40/100], Step [39500/6235], Loss: 140.3510\n",
      "Epoch [40/100], Step [39600/6235], Loss: 33.4271\n",
      "Epoch [40/100], Step [39700/6235], Loss: 664.5388\n",
      "Epoch [40/100], Step [39800/6235], Loss: 28.0177\n",
      "Epoch [40/100], Step [39900/6235], Loss: 0.3717\n",
      "Epoch [40/100], Step [40000/6235], Loss: 2.2413\n",
      "Epoch [40/100], Step [40100/6235], Loss: 27.2104\n",
      "Epoch [40/100], Step [40200/6235], Loss: 10.4994\n",
      "Epoch [40/100], Step [40300/6235], Loss: 0.6475\n",
      "Epoch [40/100], Step [40400/6235], Loss: 3.1665\n",
      "Epoch [40/100], Step [40500/6235], Loss: 1.8845\n",
      "Epoch [40/100], Step [40600/6235], Loss: 0.6084\n",
      "Epoch [40/100], Step [40700/6235], Loss: 7.5457\n",
      "Epoch [40/100], Step [40800/6235], Loss: 2.5743\n",
      "Epoch [40/100], Step [40900/6235], Loss: 0.1592\n",
      "Epoch [40/100], Step [41000/6235], Loss: 35.1920\n",
      "Epoch [40/100], Step [41100/6235], Loss: 37.4583\n",
      "Epoch [40/100], Step [41200/6235], Loss: 7.4548\n",
      "Epoch [40/100], Step [41300/6235], Loss: 6.7021\n",
      "Epoch [40/100], Step [41400/6235], Loss: 1.2941\n",
      "Epoch [40/100], Step [41500/6235], Loss: 0.2077\n",
      "Epoch [40/100], Step [41600/6235], Loss: 2.3604\n",
      "Epoch [40/100], Step [41700/6235], Loss: 3.4721\n",
      "Epoch [40/100], Step [41800/6235], Loss: 17.4806\n",
      "Epoch [40/100], Step [41900/6235], Loss: 0.0544\n",
      "Epoch [40/100], Step [42000/6235], Loss: 24.1010\n",
      "Epoch [40/100], Step [42100/6235], Loss: 0.3034\n",
      "Epoch [40/100], Step [42200/6235], Loss: 123.6551\n",
      "Epoch [40/100], Step [42300/6235], Loss: 1.2221\n",
      "Epoch [40/100], Step [42400/6235], Loss: 1.4828\n",
      "Epoch [40/100], Step [42500/6235], Loss: 1.2933\n",
      "Epoch [40/100], Step [42600/6235], Loss: 0.4488\n",
      "Epoch [40/100], Step [42700/6235], Loss: 0.9366\n",
      "Epoch [40/100], Step [42800/6235], Loss: 2.6661\n",
      "Epoch [40/100], Step [42900/6235], Loss: 2.8998\n",
      "Epoch [40/100], Step [43000/6235], Loss: 1.7916\n",
      "Epoch [40/100], Step [43100/6235], Loss: 3.3104\n",
      "Epoch [40/100], Step [43200/6235], Loss: 0.3188\n",
      "Epoch [40/100], Step [43300/6235], Loss: 14.0608\n",
      "Epoch [40/100], Step [43400/6235], Loss: 0.2151\n",
      "Epoch [40/100], Step [43500/6235], Loss: 0.8115\n",
      "Epoch [40/100], Step [43600/6235], Loss: 35.5728\n",
      "Epoch [40/100], Step [43700/6235], Loss: 1.4848\n",
      "Epoch [40/100], Step [43800/6235], Loss: 9.0079\n",
      "Epoch [40/100], Step [43900/6235], Loss: 2.3962\n",
      "Epoch [40/100], Step [44000/6235], Loss: 67.3276\n",
      "Epoch [40/100], Step [44100/6235], Loss: 1.0829\n",
      "Epoch [40/100], Step [44200/6235], Loss: 31.4149\n",
      "Epoch [40/100], Step [44300/6235], Loss: 29.1313\n",
      "Epoch [40/100], Step [44400/6235], Loss: 0.4097\n",
      "Epoch [40/100], Step [44500/6235], Loss: 9.2891\n",
      "Epoch [40/100], Step [44600/6235], Loss: 10.7914\n",
      "Epoch [40/100], Step [44700/6235], Loss: 1.3060\n",
      "Epoch [40/100], Step [44800/6235], Loss: 6.5144\n",
      "Epoch [40/100], Step [44900/6235], Loss: 2.0478\n",
      "Epoch [40/100], Step [45000/6235], Loss: 0.3565\n",
      "Epoch [40/100], Step [45100/6235], Loss: 7.4606\n",
      "Epoch [40/100], Step [45200/6235], Loss: 31.5513\n",
      "Epoch [40/100], Step [45300/6235], Loss: 1.5597\n",
      "Epoch [40/100], Step [45400/6235], Loss: 0.5719\n",
      "Epoch [40/100], Step [45500/6235], Loss: 0.2924\n",
      "Epoch [40/100], Step [45600/6235], Loss: 2.6289\n",
      "Epoch [40/100], Step [45700/6235], Loss: 7.6395\n",
      "Epoch [40/100], Step [45800/6235], Loss: 595.9398\n",
      "Epoch [40/100], Step [45900/6235], Loss: 9.4446\n",
      "Epoch [40/100], Step [46000/6235], Loss: 78.6115\n",
      "Epoch [40/100], Step [46100/6235], Loss: 120.7128\n",
      "Epoch [40/100], Step [46200/6235], Loss: 273.4801\n",
      "Epoch [40/100], Step [46300/6235], Loss: 26.2652\n",
      "Epoch [40/100], Step [46400/6235], Loss: 1.0018\n",
      "Epoch [40/100], Step [46500/6235], Loss: 31.8661\n",
      "Epoch [40/100], Step [46600/6235], Loss: 27.0837\n",
      "Epoch [40/100], Step [46700/6235], Loss: 2.3241\n",
      "Epoch [40/100], Step [46800/6235], Loss: 34.4933\n",
      "Epoch [40/100], Step [46900/6235], Loss: 21.8889\n",
      "Epoch [40/100], Step [47000/6235], Loss: 2.1281\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [40/100], Step [47100/6235], Loss: 86.1419\n",
      "Epoch [40/100], Step [47200/6235], Loss: 98.6881\n",
      "Epoch [40/100], Step [47300/6235], Loss: 1.5827\n",
      "Epoch [40/100], Step [47400/6235], Loss: 367.2554\n",
      "Epoch [40/100], Step [47500/6235], Loss: 22.9273\n",
      "Epoch [40/100], Step [47600/6235], Loss: 7.1600\n",
      "Epoch [40/100], Step [47700/6235], Loss: 26.4080\n",
      "Epoch [40/100], Step [47800/6235], Loss: 53.2793\n",
      "Epoch [40/100], Step [47900/6235], Loss: 15.7804\n",
      "Epoch [40/100], Step [48000/6235], Loss: 93.8985\n",
      "Epoch [40/100], Step [48100/6235], Loss: 9.8907\n",
      "Epoch [40/100], Step [48200/6235], Loss: 28.8520\n",
      "Epoch [40/100], Step [48300/6235], Loss: 678.3929\n",
      "Epoch [40/100], Step [48400/6235], Loss: 1.8508\n",
      "Epoch [40/100], Step [48500/6235], Loss: 32.8963\n",
      "Epoch [40/100], Step [48600/6235], Loss: 35.3208\n",
      "Epoch [40/100], Step [48700/6235], Loss: 14.8538\n",
      "Epoch [40/100], Step [48800/6235], Loss: 299.9509\n",
      "Epoch [40/100], Step [48900/6235], Loss: 380.0498\n",
      "Epoch [40/100], Step [49000/6235], Loss: 132.6358\n",
      "Epoch [40/100], Step [49100/6235], Loss: 3299.2727\n",
      "Epoch [40/100], Step [49200/6235], Loss: 1131.8162\n",
      "Epoch [40/100], Step [49300/6235], Loss: 986.1771\n",
      "Epoch [40/100], Step [49400/6235], Loss: 79.0203\n",
      "Epoch [40/100], Step [49500/6235], Loss: 28.0202\n",
      "Epoch [40/100], Step [49600/6235], Loss: 177.6763\n",
      "Epoch [40/100], Step [49700/6235], Loss: 1186.6017\n",
      "Epoch [40/100], Step [49800/6235], Loss: 800.3431\n",
      "Epoch [41/100], Step [100/6235], Loss: 0.4816\n",
      "Epoch [41/100], Step [200/6235], Loss: 0.1372\n",
      "Epoch [41/100], Step [300/6235], Loss: 0.0401\n",
      "Epoch [41/100], Step [400/6235], Loss: 0.0163\n",
      "Epoch [41/100], Step [500/6235], Loss: 12.2442\n",
      "Epoch [41/100], Step [600/6235], Loss: 0.0527\n",
      "Epoch [41/100], Step [700/6235], Loss: 0.6158\n",
      "Epoch [41/100], Step [800/6235], Loss: 0.1641\n",
      "Epoch [41/100], Step [900/6235], Loss: 0.3091\n",
      "Epoch [41/100], Step [1000/6235], Loss: 0.0356\n",
      "Epoch [41/100], Step [1100/6235], Loss: 0.4675\n",
      "Epoch [41/100], Step [1200/6235], Loss: 0.1791\n",
      "Epoch [41/100], Step [1300/6235], Loss: 0.0932\n",
      "Epoch [41/100], Step [1400/6235], Loss: 1.3400\n",
      "Epoch [41/100], Step [1500/6235], Loss: 0.0140\n",
      "Epoch [41/100], Step [1600/6235], Loss: 0.2519\n",
      "Epoch [41/100], Step [1700/6235], Loss: 0.5287\n",
      "Epoch [41/100], Step [1800/6235], Loss: 0.4502\n",
      "Epoch [41/100], Step [1900/6235], Loss: 0.3177\n",
      "Epoch [41/100], Step [2000/6235], Loss: 2.3390\n",
      "Epoch [41/100], Step [2100/6235], Loss: 4.8596\n",
      "Epoch [41/100], Step [2200/6235], Loss: 3.7379\n",
      "Epoch [41/100], Step [2300/6235], Loss: 2.2716\n",
      "Epoch [41/100], Step [2400/6235], Loss: 3.9008\n",
      "Epoch [41/100], Step [2500/6235], Loss: 4.6679\n",
      "Epoch [41/100], Step [2600/6235], Loss: 17.8107\n",
      "Epoch [41/100], Step [2700/6235], Loss: 16.6029\n",
      "Epoch [41/100], Step [2800/6235], Loss: 7.9572\n",
      "Epoch [41/100], Step [2900/6235], Loss: 8.2371\n",
      "Epoch [41/100], Step [3000/6235], Loss: 5.6357\n",
      "Epoch [41/100], Step [3100/6235], Loss: 100.1464\n",
      "Epoch [41/100], Step [3200/6235], Loss: 2.4366\n",
      "Epoch [41/100], Step [3300/6235], Loss: 1.5859\n",
      "Epoch [41/100], Step [3400/6235], Loss: 6.4637\n",
      "Epoch [41/100], Step [3500/6235], Loss: 84.8833\n",
      "Epoch [41/100], Step [3600/6235], Loss: 5.4675\n",
      "Epoch [41/100], Step [3700/6235], Loss: 0.6855\n",
      "Epoch [41/100], Step [3800/6235], Loss: 0.5086\n",
      "Epoch [41/100], Step [3900/6235], Loss: 1.0730\n",
      "Epoch [41/100], Step [4000/6235], Loss: 0.8693\n",
      "Epoch [41/100], Step [4100/6235], Loss: 4.3861\n",
      "Epoch [41/100], Step [4200/6235], Loss: 0.1668\n",
      "Epoch [41/100], Step [4300/6235], Loss: 3.1843\n",
      "Epoch [41/100], Step [4400/6235], Loss: 0.1335\n",
      "Epoch [41/100], Step [4500/6235], Loss: 76.0323\n",
      "Epoch [41/100], Step [4600/6235], Loss: 21.7153\n",
      "Epoch [41/100], Step [4700/6235], Loss: 3.8968\n",
      "Epoch [41/100], Step [4800/6235], Loss: 1.8126\n",
      "Epoch [41/100], Step [4900/6235], Loss: 1.0821\n",
      "Epoch [41/100], Step [5000/6235], Loss: 0.8516\n",
      "Epoch [41/100], Step [5100/6235], Loss: 13.6423\n",
      "Epoch [41/100], Step [5200/6235], Loss: 2.8166\n",
      "Epoch [41/100], Step [5300/6235], Loss: 12.9933\n",
      "Epoch [41/100], Step [5400/6235], Loss: 4.6338\n",
      "Epoch [41/100], Step [5500/6235], Loss: 0.2429\n",
      "Epoch [41/100], Step [5600/6235], Loss: 0.6011\n",
      "Epoch [41/100], Step [5700/6235], Loss: 1.1077\n",
      "Epoch [41/100], Step [5800/6235], Loss: 1.1946\n",
      "Epoch [41/100], Step [5900/6235], Loss: 0.0262\n",
      "Epoch [41/100], Step [6000/6235], Loss: 0.2875\n",
      "Epoch [41/100], Step [6100/6235], Loss: 0.1367\n",
      "Epoch [41/100], Step [6200/6235], Loss: 3.2800\n",
      "Epoch [41/100], Step [6300/6235], Loss: 0.4735\n",
      "Epoch [41/100], Step [6400/6235], Loss: 0.0475\n",
      "Epoch [41/100], Step [6500/6235], Loss: 1.4442\n",
      "Epoch [41/100], Step [6600/6235], Loss: 10.2734\n",
      "Epoch [41/100], Step [6700/6235], Loss: 1.2204\n",
      "Epoch [41/100], Step [6800/6235], Loss: 0.6968\n",
      "Epoch [41/100], Step [6900/6235], Loss: 1.2127\n",
      "Epoch [41/100], Step [7000/6235], Loss: 0.0492\n",
      "Epoch [41/100], Step [7100/6235], Loss: 0.6335\n",
      "Epoch [41/100], Step [7200/6235], Loss: 0.1313\n",
      "Epoch [41/100], Step [7300/6235], Loss: 1.0150\n",
      "Epoch [41/100], Step [7400/6235], Loss: 0.5700\n",
      "Epoch [41/100], Step [7500/6235], Loss: 0.1647\n",
      "Epoch [41/100], Step [7600/6235], Loss: 1.4049\n",
      "Epoch [41/100], Step [7700/6235], Loss: 5.2945\n",
      "Epoch [41/100], Step [7800/6235], Loss: 0.3358\n",
      "Epoch [41/100], Step [7900/6235], Loss: 5.0242\n",
      "Epoch [41/100], Step [8000/6235], Loss: 0.2202\n",
      "Epoch [41/100], Step [8100/6235], Loss: 2.8647\n",
      "Epoch [41/100], Step [8200/6235], Loss: 6.4241\n",
      "Epoch [41/100], Step [8300/6235], Loss: 18.5513\n",
      "Epoch [41/100], Step [8400/6235], Loss: 335.4008\n",
      "Epoch [41/100], Step [8500/6235], Loss: 3.5873\n",
      "Epoch [41/100], Step [8600/6235], Loss: 0.6682\n",
      "Epoch [41/100], Step [8700/6235], Loss: 131.7207\n",
      "Epoch [41/100], Step [8800/6235], Loss: 52.3815\n",
      "Epoch [41/100], Step [8900/6235], Loss: 99.8167\n",
      "Epoch [41/100], Step [9000/6235], Loss: 596.3177\n",
      "Epoch [41/100], Step [9100/6235], Loss: 213.8848\n",
      "Epoch [41/100], Step [9200/6235], Loss: 2391.4812\n",
      "Epoch [41/100], Step [9300/6235], Loss: 378.0039\n",
      "Epoch [41/100], Step [9400/6235], Loss: 895.2570\n",
      "Epoch [41/100], Step [9500/6235], Loss: 2684.6724\n",
      "Epoch [41/100], Step [9600/6235], Loss: 273.4651\n",
      "Epoch [41/100], Step [9700/6235], Loss: 3.2998\n",
      "Epoch [41/100], Step [9800/6235], Loss: 157.1134\n",
      "Epoch [41/100], Step [9900/6235], Loss: 11.6973\n",
      "Epoch [41/100], Step [10000/6235], Loss: 27.8656\n",
      "Epoch [41/100], Step [10100/6235], Loss: 3.0781\n",
      "Epoch [41/100], Step [10200/6235], Loss: 966.7878\n",
      "Epoch [41/100], Step [10300/6235], Loss: 4.4748\n",
      "Epoch [41/100], Step [10400/6235], Loss: 3.7820\n",
      "Epoch [41/100], Step [10500/6235], Loss: 8.6833\n",
      "Epoch [41/100], Step [10600/6235], Loss: 72.0520\n",
      "Epoch [41/100], Step [10700/6235], Loss: 107.3725\n",
      "Epoch [41/100], Step [10800/6235], Loss: 19.1495\n",
      "Epoch [41/100], Step [10900/6235], Loss: 3.6765\n",
      "Epoch [41/100], Step [11000/6235], Loss: 272.1534\n",
      "Epoch [41/100], Step [11100/6235], Loss: 21.8844\n",
      "Epoch [41/100], Step [11200/6235], Loss: 62.1647\n",
      "Epoch [41/100], Step [11300/6235], Loss: 197.9346\n",
      "Epoch [41/100], Step [11400/6235], Loss: 2.8376\n",
      "Epoch [41/100], Step [11500/6235], Loss: 1.3099\n",
      "Epoch [41/100], Step [11600/6235], Loss: 0.6269\n",
      "Epoch [41/100], Step [11700/6235], Loss: 39.1100\n",
      "Epoch [41/100], Step [11800/6235], Loss: 2.6544\n",
      "Epoch [41/100], Step [11900/6235], Loss: 15.3809\n",
      "Epoch [41/100], Step [12000/6235], Loss: 719.7434\n",
      "Epoch [41/100], Step [12100/6235], Loss: 257.5003\n",
      "Epoch [41/100], Step [12200/6235], Loss: 21.4114\n",
      "Epoch [41/100], Step [12300/6235], Loss: 3.0442\n",
      "Epoch [41/100], Step [12400/6235], Loss: 412.4659\n",
      "Epoch [41/100], Step [12500/6235], Loss: 19.4855\n",
      "Epoch [41/100], Step [12600/6235], Loss: 39.4036\n",
      "Epoch [41/100], Step [12700/6235], Loss: 6.1654\n",
      "Epoch [41/100], Step [12800/6235], Loss: 11.6596\n",
      "Epoch [41/100], Step [12900/6235], Loss: 42.9357\n",
      "Epoch [41/100], Step [13000/6235], Loss: 1.0240\n",
      "Epoch [41/100], Step [13100/6235], Loss: 68.9856\n",
      "Epoch [41/100], Step [13200/6235], Loss: 10.5007\n",
      "Epoch [41/100], Step [13300/6235], Loss: 31.2186\n",
      "Epoch [41/100], Step [13400/6235], Loss: 252.0830\n",
      "Epoch [41/100], Step [13500/6235], Loss: 2.8268\n",
      "Epoch [41/100], Step [13600/6235], Loss: 1.1944\n",
      "Epoch [41/100], Step [13700/6235], Loss: 57.9581\n",
      "Epoch [41/100], Step [13800/6235], Loss: 152.5872\n",
      "Epoch [41/100], Step [13900/6235], Loss: 45.2019\n",
      "Epoch [41/100], Step [14000/6235], Loss: 14.3469\n",
      "Epoch [41/100], Step [14100/6235], Loss: 21.4783\n",
      "Epoch [41/100], Step [14200/6235], Loss: 100.3660\n",
      "Epoch [41/100], Step [14300/6235], Loss: 73.1622\n",
      "Epoch [41/100], Step [14400/6235], Loss: 37.9462\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Step [14500/6235], Loss: 60.2220\n",
      "Epoch [41/100], Step [14600/6235], Loss: 0.9038\n",
      "Epoch [41/100], Step [14700/6235], Loss: 44.6694\n",
      "Epoch [41/100], Step [14800/6235], Loss: 30.3388\n",
      "Epoch [41/100], Step [14900/6235], Loss: 2.6075\n",
      "Epoch [41/100], Step [15000/6235], Loss: 3.8144\n",
      "Epoch [41/100], Step [15100/6235], Loss: 0.1302\n",
      "Epoch [41/100], Step [15200/6235], Loss: 7.6382\n",
      "Epoch [41/100], Step [15300/6235], Loss: 22.4900\n",
      "Epoch [41/100], Step [15400/6235], Loss: 74.8445\n",
      "Epoch [41/100], Step [15500/6235], Loss: 14.4348\n",
      "Epoch [41/100], Step [15600/6235], Loss: 145.8635\n",
      "Epoch [41/100], Step [15700/6235], Loss: 43.5943\n",
      "Epoch [41/100], Step [15800/6235], Loss: 11.0883\n",
      "Epoch [41/100], Step [15900/6235], Loss: 0.2566\n",
      "Epoch [41/100], Step [16000/6235], Loss: 117.3139\n",
      "Epoch [41/100], Step [16100/6235], Loss: 0.3769\n",
      "Epoch [41/100], Step [16200/6235], Loss: 0.6580\n",
      "Epoch [41/100], Step [16300/6235], Loss: 9.9455\n",
      "Epoch [41/100], Step [16400/6235], Loss: 29.6139\n",
      "Epoch [41/100], Step [16500/6235], Loss: 661.6846\n",
      "Epoch [41/100], Step [16600/6235], Loss: 19.1657\n",
      "Epoch [41/100], Step [16700/6235], Loss: 0.7277\n",
      "Epoch [41/100], Step [16800/6235], Loss: 7.8124\n",
      "Epoch [41/100], Step [16900/6235], Loss: 0.0533\n",
      "Epoch [41/100], Step [17000/6235], Loss: 0.2760\n",
      "Epoch [41/100], Step [17100/6235], Loss: 0.3764\n",
      "Epoch [41/100], Step [17200/6235], Loss: 307.1143\n",
      "Epoch [41/100], Step [17300/6235], Loss: 27.5856\n",
      "Epoch [41/100], Step [17400/6235], Loss: 49.1277\n",
      "Epoch [41/100], Step [17500/6235], Loss: 0.6941\n",
      "Epoch [41/100], Step [17600/6235], Loss: 4.2681\n",
      "Epoch [41/100], Step [17700/6235], Loss: 1.8390\n",
      "Epoch [41/100], Step [17800/6235], Loss: 15.3238\n",
      "Epoch [41/100], Step [17900/6235], Loss: 22.8237\n",
      "Epoch [41/100], Step [18000/6235], Loss: 2.3242\n",
      "Epoch [41/100], Step [18100/6235], Loss: 14.0350\n",
      "Epoch [41/100], Step [18200/6235], Loss: 0.3543\n",
      "Epoch [41/100], Step [18300/6235], Loss: 0.7327\n",
      "Epoch [41/100], Step [18400/6235], Loss: 1.1674\n",
      "Epoch [41/100], Step [18500/6235], Loss: 34.2618\n",
      "Epoch [41/100], Step [18600/6235], Loss: 5.3311\n",
      "Epoch [41/100], Step [18700/6235], Loss: 1.3501\n",
      "Epoch [41/100], Step [18800/6235], Loss: 174.5934\n",
      "Epoch [41/100], Step [18900/6235], Loss: 61.6951\n",
      "Epoch [41/100], Step [19000/6235], Loss: 2.5054\n",
      "Epoch [41/100], Step [19100/6235], Loss: 38.6437\n",
      "Epoch [41/100], Step [19200/6235], Loss: 1.6189\n",
      "Epoch [41/100], Step [19300/6235], Loss: 6.5596\n",
      "Epoch [41/100], Step [19400/6235], Loss: 17.6221\n",
      "Epoch [41/100], Step [19500/6235], Loss: 157.5963\n",
      "Epoch [41/100], Step [19600/6235], Loss: 59.2553\n",
      "Epoch [41/100], Step [19700/6235], Loss: 2.7354\n",
      "Epoch [41/100], Step [19800/6235], Loss: 8.4751\n",
      "Epoch [41/100], Step [19900/6235], Loss: 0.0608\n",
      "Epoch [41/100], Step [20000/6235], Loss: 66.6767\n",
      "Epoch [41/100], Step [20100/6235], Loss: 4.9389\n",
      "Epoch [41/100], Step [20200/6235], Loss: 0.6396\n",
      "Epoch [41/100], Step [20300/6235], Loss: 0.3486\n",
      "Epoch [41/100], Step [20400/6235], Loss: 4.0982\n",
      "Epoch [41/100], Step [20500/6235], Loss: 60.1986\n",
      "Epoch [41/100], Step [20600/6235], Loss: 20.9147\n",
      "Epoch [41/100], Step [20700/6235], Loss: 11.8513\n",
      "Epoch [41/100], Step [20800/6235], Loss: 3.3784\n",
      "Epoch [41/100], Step [20900/6235], Loss: 2.2849\n",
      "Epoch [41/100], Step [21000/6235], Loss: 22.4056\n",
      "Epoch [41/100], Step [21100/6235], Loss: 6.8757\n",
      "Epoch [41/100], Step [21200/6235], Loss: 0.2507\n",
      "Epoch [41/100], Step [21300/6235], Loss: 0.0423\n",
      "Epoch [41/100], Step [21400/6235], Loss: 2.0038\n",
      "Epoch [41/100], Step [21500/6235], Loss: 1.6606\n",
      "Epoch [41/100], Step [21600/6235], Loss: 22.8386\n",
      "Epoch [41/100], Step [21700/6235], Loss: 0.3935\n",
      "Epoch [41/100], Step [21800/6235], Loss: 4.5727\n",
      "Epoch [41/100], Step [21900/6235], Loss: 1.7615\n",
      "Epoch [41/100], Step [22000/6235], Loss: 10.6536\n",
      "Epoch [41/100], Step [22100/6235], Loss: 0.0471\n",
      "Epoch [41/100], Step [22200/6235], Loss: 1.8720\n",
      "Epoch [41/100], Step [22300/6235], Loss: 0.5069\n",
      "Epoch [41/100], Step [22400/6235], Loss: 3.3438\n",
      "Epoch [41/100], Step [22500/6235], Loss: 165.1807\n",
      "Epoch [41/100], Step [22600/6235], Loss: 20.6610\n",
      "Epoch [41/100], Step [22700/6235], Loss: 1.2703\n",
      "Epoch [41/100], Step [22800/6235], Loss: 3.8378\n",
      "Epoch [41/100], Step [22900/6235], Loss: 3.6281\n",
      "Epoch [41/100], Step [23000/6235], Loss: 14.3312\n",
      "Epoch [41/100], Step [23100/6235], Loss: 5.9870\n",
      "Epoch [41/100], Step [23200/6235], Loss: 11.4510\n",
      "Epoch [41/100], Step [23300/6235], Loss: 19.9916\n",
      "Epoch [41/100], Step [23400/6235], Loss: 2.5961\n",
      "Epoch [41/100], Step [23500/6235], Loss: 0.0768\n",
      "Epoch [41/100], Step [23600/6235], Loss: 136.7371\n",
      "Epoch [41/100], Step [23700/6235], Loss: 1.7179\n",
      "Epoch [41/100], Step [23800/6235], Loss: 0.7213\n",
      "Epoch [41/100], Step [23900/6235], Loss: 1.6461\n",
      "Epoch [41/100], Step [24000/6235], Loss: 1.6572\n",
      "Epoch [41/100], Step [24100/6235], Loss: 2.4950\n",
      "Epoch [41/100], Step [24200/6235], Loss: 51.5276\n",
      "Epoch [41/100], Step [24300/6235], Loss: 0.6947\n",
      "Epoch [41/100], Step [24400/6235], Loss: 0.5868\n",
      "Epoch [41/100], Step [24500/6235], Loss: 0.3042\n",
      "Epoch [41/100], Step [24600/6235], Loss: 0.5791\n",
      "Epoch [41/100], Step [24700/6235], Loss: 0.1127\n",
      "Epoch [41/100], Step [24800/6235], Loss: 0.4766\n",
      "Epoch [41/100], Step [24900/6235], Loss: 8.8002\n",
      "Epoch [41/100], Step [25000/6235], Loss: 9.6700\n",
      "Epoch [41/100], Step [25100/6235], Loss: 6.6154\n",
      "Epoch [41/100], Step [25200/6235], Loss: 0.0225\n",
      "Epoch [41/100], Step [25300/6235], Loss: 1.1321\n",
      "Epoch [41/100], Step [25400/6235], Loss: 9.9621\n",
      "Epoch [41/100], Step [25500/6235], Loss: 9.2205\n",
      "Epoch [41/100], Step [25600/6235], Loss: 7.9462\n",
      "Epoch [41/100], Step [25700/6235], Loss: 0.1038\n",
      "Epoch [41/100], Step [25800/6235], Loss: 0.1841\n",
      "Epoch [41/100], Step [25900/6235], Loss: 4.9167\n",
      "Epoch [41/100], Step [26000/6235], Loss: 1.7719\n",
      "Epoch [41/100], Step [26100/6235], Loss: 0.0445\n",
      "Epoch [41/100], Step [26200/6235], Loss: 1.4527\n",
      "Epoch [41/100], Step [26300/6235], Loss: 1.7759\n",
      "Epoch [41/100], Step [26400/6235], Loss: 0.4475\n",
      "Epoch [41/100], Step [26500/6235], Loss: 0.0421\n",
      "Epoch [41/100], Step [26600/6235], Loss: 0.3752\n",
      "Epoch [41/100], Step [26700/6235], Loss: 0.1628\n",
      "Epoch [41/100], Step [26800/6235], Loss: 0.0920\n",
      "Epoch [41/100], Step [26900/6235], Loss: 0.0486\n",
      "Epoch [41/100], Step [27000/6235], Loss: 16.2612\n",
      "Epoch [41/100], Step [27100/6235], Loss: 0.0655\n",
      "Epoch [41/100], Step [27200/6235], Loss: 0.0088\n",
      "Epoch [41/100], Step [27300/6235], Loss: 0.0563\n",
      "Epoch [41/100], Step [27400/6235], Loss: 0.6269\n",
      "Epoch [41/100], Step [27500/6235], Loss: 4.3137\n",
      "Epoch [41/100], Step [27600/6235], Loss: 0.5815\n",
      "Epoch [41/100], Step [27700/6235], Loss: 0.9436\n",
      "Epoch [41/100], Step [27800/6235], Loss: 5.8865\n",
      "Epoch [41/100], Step [27900/6235], Loss: 2.9379\n",
      "Epoch [41/100], Step [28000/6235], Loss: 200.3547\n",
      "Epoch [41/100], Step [28100/6235], Loss: 10.6937\n",
      "Epoch [41/100], Step [28200/6235], Loss: 27.5810\n",
      "Epoch [41/100], Step [28300/6235], Loss: 1.7824\n",
      "Epoch [41/100], Step [28400/6235], Loss: 20.5025\n",
      "Epoch [41/100], Step [28500/6235], Loss: 4.5186\n",
      "Epoch [41/100], Step [28600/6235], Loss: 0.6699\n",
      "Epoch [41/100], Step [28700/6235], Loss: 4.1991\n",
      "Epoch [41/100], Step [28800/6235], Loss: 0.6618\n",
      "Epoch [41/100], Step [28900/6235], Loss: 56.4072\n",
      "Epoch [41/100], Step [29000/6235], Loss: 11.2696\n",
      "Epoch [41/100], Step [29100/6235], Loss: 0.0973\n",
      "Epoch [41/100], Step [29200/6235], Loss: 4.2752\n",
      "Epoch [41/100], Step [29300/6235], Loss: 12.5478\n",
      "Epoch [41/100], Step [29400/6235], Loss: 0.5888\n",
      "Epoch [41/100], Step [29500/6235], Loss: 2.0604\n",
      "Epoch [41/100], Step [29600/6235], Loss: 0.0242\n",
      "Epoch [41/100], Step [29700/6235], Loss: 2.6617\n",
      "Epoch [41/100], Step [29800/6235], Loss: 0.8934\n",
      "Epoch [41/100], Step [29900/6235], Loss: 0.3360\n",
      "Epoch [41/100], Step [30000/6235], Loss: 4.1716\n",
      "Epoch [41/100], Step [30100/6235], Loss: 8.0654\n",
      "Epoch [41/100], Step [30200/6235], Loss: 1.8376\n",
      "Epoch [41/100], Step [30300/6235], Loss: 0.0678\n",
      "Epoch [41/100], Step [30400/6235], Loss: 2.0786\n",
      "Epoch [41/100], Step [30500/6235], Loss: 0.9447\n",
      "Epoch [41/100], Step [30600/6235], Loss: 1.5563\n",
      "Epoch [41/100], Step [30700/6235], Loss: 2.0356\n",
      "Epoch [41/100], Step [30800/6235], Loss: 0.5410\n",
      "Epoch [41/100], Step [30900/6235], Loss: 2.0670\n",
      "Epoch [41/100], Step [31000/6235], Loss: 0.3374\n",
      "Epoch [41/100], Step [31100/6235], Loss: 0.1894\n",
      "Epoch [41/100], Step [31200/6235], Loss: 5.6867\n",
      "Epoch [41/100], Step [31300/6235], Loss: 1.9404\n",
      "Epoch [41/100], Step [31400/6235], Loss: 11.4703\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Step [31500/6235], Loss: 0.7316\n",
      "Epoch [41/100], Step [31600/6235], Loss: 7.1496\n",
      "Epoch [41/100], Step [31700/6235], Loss: 0.6064\n",
      "Epoch [41/100], Step [31800/6235], Loss: 1.7394\n",
      "Epoch [41/100], Step [31900/6235], Loss: 213.2536\n",
      "Epoch [41/100], Step [32000/6235], Loss: 26.6059\n",
      "Epoch [41/100], Step [32100/6235], Loss: 3.2108\n",
      "Epoch [41/100], Step [32200/6235], Loss: 86.0852\n",
      "Epoch [41/100], Step [32300/6235], Loss: 2.6207\n",
      "Epoch [41/100], Step [32400/6235], Loss: 0.9678\n",
      "Epoch [41/100], Step [32500/6235], Loss: 20.8369\n",
      "Epoch [41/100], Step [32600/6235], Loss: 0.6810\n",
      "Epoch [41/100], Step [32700/6235], Loss: 72.0319\n",
      "Epoch [41/100], Step [32800/6235], Loss: 23.8356\n",
      "Epoch [41/100], Step [32900/6235], Loss: 3.4003\n",
      "Epoch [41/100], Step [33000/6235], Loss: 0.1634\n",
      "Epoch [41/100], Step [33100/6235], Loss: 0.5484\n",
      "Epoch [41/100], Step [33200/6235], Loss: 1.1524\n",
      "Epoch [41/100], Step [33300/6235], Loss: 13.3467\n",
      "Epoch [41/100], Step [33400/6235], Loss: 81.5539\n",
      "Epoch [41/100], Step [33500/6235], Loss: 0.5519\n",
      "Epoch [41/100], Step [33600/6235], Loss: 1.3758\n",
      "Epoch [41/100], Step [33700/6235], Loss: 1.7180\n",
      "Epoch [41/100], Step [33800/6235], Loss: 0.3459\n",
      "Epoch [41/100], Step [33900/6235], Loss: 27.8072\n",
      "Epoch [41/100], Step [34000/6235], Loss: 0.0548\n",
      "Epoch [41/100], Step [34100/6235], Loss: 0.4650\n",
      "Epoch [41/100], Step [34200/6235], Loss: 2.5319\n",
      "Epoch [41/100], Step [34300/6235], Loss: 4.9614\n",
      "Epoch [41/100], Step [34400/6235], Loss: 0.2202\n",
      "Epoch [41/100], Step [34500/6235], Loss: 29.3458\n",
      "Epoch [41/100], Step [34600/6235], Loss: 0.5449\n",
      "Epoch [41/100], Step [34700/6235], Loss: 25.3233\n",
      "Epoch [41/100], Step [34800/6235], Loss: 12.9456\n",
      "Epoch [41/100], Step [34900/6235], Loss: 67.9203\n",
      "Epoch [41/100], Step [35000/6235], Loss: 0.4078\n",
      "Epoch [41/100], Step [35100/6235], Loss: 0.8851\n",
      "Epoch [41/100], Step [35200/6235], Loss: 0.4396\n",
      "Epoch [41/100], Step [35300/6235], Loss: 3.1159\n",
      "Epoch [41/100], Step [35400/6235], Loss: 0.5148\n",
      "Epoch [41/100], Step [35500/6235], Loss: 0.6219\n",
      "Epoch [41/100], Step [35600/6235], Loss: 9.1748\n",
      "Epoch [41/100], Step [35700/6235], Loss: 4.2429\n",
      "Epoch [41/100], Step [35800/6235], Loss: 0.2933\n",
      "Epoch [41/100], Step [35900/6235], Loss: 0.3603\n",
      "Epoch [41/100], Step [36000/6235], Loss: 0.1934\n",
      "Epoch [41/100], Step [36100/6235], Loss: 0.0527\n",
      "Epoch [41/100], Step [36200/6235], Loss: 24.5071\n",
      "Epoch [41/100], Step [36300/6235], Loss: 0.2228\n",
      "Epoch [41/100], Step [36400/6235], Loss: 2.8268\n",
      "Epoch [41/100], Step [36500/6235], Loss: 7.3819\n",
      "Epoch [41/100], Step [36600/6235], Loss: 0.0701\n",
      "Epoch [41/100], Step [36700/6235], Loss: 0.5725\n",
      "Epoch [41/100], Step [36800/6235], Loss: 4.0927\n",
      "Epoch [41/100], Step [36900/6235], Loss: 10.5263\n",
      "Epoch [41/100], Step [37000/6235], Loss: 0.9823\n",
      "Epoch [41/100], Step [37100/6235], Loss: 2.1077\n",
      "Epoch [41/100], Step [37200/6235], Loss: 0.0369\n",
      "Epoch [41/100], Step [37300/6235], Loss: 0.0571\n",
      "Epoch [41/100], Step [37400/6235], Loss: 0.1693\n",
      "Epoch [41/100], Step [37500/6235], Loss: 6.8130\n",
      "Epoch [41/100], Step [37600/6235], Loss: 12.1198\n",
      "Epoch [41/100], Step [37700/6235], Loss: 0.5965\n",
      "Epoch [41/100], Step [37800/6235], Loss: 3.2724\n",
      "Epoch [41/100], Step [37900/6235], Loss: 6.6200\n",
      "Epoch [41/100], Step [38000/6235], Loss: 0.5993\n",
      "Epoch [41/100], Step [38100/6235], Loss: 4.5221\n",
      "Epoch [41/100], Step [38200/6235], Loss: 3.0806\n",
      "Epoch [41/100], Step [38300/6235], Loss: 0.2785\n",
      "Epoch [41/100], Step [38400/6235], Loss: 0.0519\n",
      "Epoch [41/100], Step [38500/6235], Loss: 1.4726\n",
      "Epoch [41/100], Step [38600/6235], Loss: 0.2951\n",
      "Epoch [41/100], Step [38700/6235], Loss: 0.4119\n",
      "Epoch [41/100], Step [38800/6235], Loss: 0.1084\n",
      "Epoch [41/100], Step [38900/6235], Loss: 3.9187\n",
      "Epoch [41/100], Step [39000/6235], Loss: 16.4877\n",
      "Epoch [41/100], Step [39100/6235], Loss: 19.7003\n",
      "Epoch [41/100], Step [39200/6235], Loss: 0.5958\n",
      "Epoch [41/100], Step [39300/6235], Loss: 13.0031\n",
      "Epoch [41/100], Step [39400/6235], Loss: 111.5905\n",
      "Epoch [41/100], Step [39500/6235], Loss: 448.1805\n",
      "Epoch [41/100], Step [39600/6235], Loss: 9.2507\n",
      "Epoch [41/100], Step [39700/6235], Loss: 215.6393\n",
      "Epoch [41/100], Step [39800/6235], Loss: 185.9818\n",
      "Epoch [41/100], Step [39900/6235], Loss: 3.1002\n",
      "Epoch [41/100], Step [40000/6235], Loss: 9.3345\n",
      "Epoch [41/100], Step [40100/6235], Loss: 23.2011\n",
      "Epoch [41/100], Step [40200/6235], Loss: 2.0259\n",
      "Epoch [41/100], Step [40300/6235], Loss: 1.4726\n",
      "Epoch [41/100], Step [40400/6235], Loss: 1.6986\n",
      "Epoch [41/100], Step [40500/6235], Loss: 2.4992\n",
      "Epoch [41/100], Step [40600/6235], Loss: 0.1720\n",
      "Epoch [41/100], Step [40700/6235], Loss: 7.2230\n",
      "Epoch [41/100], Step [40800/6235], Loss: 0.6231\n",
      "Epoch [41/100], Step [40900/6235], Loss: 0.5063\n",
      "Epoch [41/100], Step [41000/6235], Loss: 47.6348\n",
      "Epoch [41/100], Step [41100/6235], Loss: 37.3015\n",
      "Epoch [41/100], Step [41200/6235], Loss: 3.4550\n",
      "Epoch [41/100], Step [41300/6235], Loss: 2.7263\n",
      "Epoch [41/100], Step [41400/6235], Loss: 2.5574\n",
      "Epoch [41/100], Step [41500/6235], Loss: 1.6942\n",
      "Epoch [41/100], Step [41600/6235], Loss: 0.1676\n",
      "Epoch [41/100], Step [41700/6235], Loss: 0.0853\n",
      "Epoch [41/100], Step [41800/6235], Loss: 1.3395\n",
      "Epoch [41/100], Step [41900/6235], Loss: 4.9933\n",
      "Epoch [41/100], Step [42000/6235], Loss: 4.6350\n",
      "Epoch [41/100], Step [42100/6235], Loss: 10.5162\n",
      "Epoch [41/100], Step [42200/6235], Loss: 41.9098\n",
      "Epoch [41/100], Step [42300/6235], Loss: 1.8264\n",
      "Epoch [41/100], Step [42400/6235], Loss: 3.2125\n",
      "Epoch [41/100], Step [42500/6235], Loss: 0.8560\n",
      "Epoch [41/100], Step [42600/6235], Loss: 0.8995\n",
      "Epoch [41/100], Step [42700/6235], Loss: 0.6121\n",
      "Epoch [41/100], Step [42800/6235], Loss: 6.0233\n",
      "Epoch [41/100], Step [42900/6235], Loss: 3.0264\n",
      "Epoch [41/100], Step [43000/6235], Loss: 0.1920\n",
      "Epoch [41/100], Step [43100/6235], Loss: 0.1909\n",
      "Epoch [41/100], Step [43200/6235], Loss: 1.0843\n",
      "Epoch [41/100], Step [43300/6235], Loss: 8.4588\n",
      "Epoch [41/100], Step [43400/6235], Loss: 12.2227\n",
      "Epoch [41/100], Step [43500/6235], Loss: 9.4281\n",
      "Epoch [41/100], Step [43600/6235], Loss: 12.9695\n",
      "Epoch [41/100], Step [43700/6235], Loss: 43.8844\n",
      "Epoch [41/100], Step [43800/6235], Loss: 0.6852\n",
      "Epoch [41/100], Step [43900/6235], Loss: 0.1983\n",
      "Epoch [41/100], Step [44000/6235], Loss: 55.0367\n",
      "Epoch [41/100], Step [44100/6235], Loss: 2.6497\n",
      "Epoch [41/100], Step [44200/6235], Loss: 3.1191\n",
      "Epoch [41/100], Step [44300/6235], Loss: 2.9620\n",
      "Epoch [41/100], Step [44400/6235], Loss: 0.6472\n",
      "Epoch [41/100], Step [44500/6235], Loss: 4.4718\n",
      "Epoch [41/100], Step [44600/6235], Loss: 36.3857\n",
      "Epoch [41/100], Step [44700/6235], Loss: 4.9762\n",
      "Epoch [41/100], Step [44800/6235], Loss: 4.3369\n",
      "Epoch [41/100], Step [44900/6235], Loss: 2.6259\n",
      "Epoch [41/100], Step [45000/6235], Loss: 5.2529\n",
      "Epoch [41/100], Step [45100/6235], Loss: 6.2223\n",
      "Epoch [41/100], Step [45200/6235], Loss: 0.3963\n",
      "Epoch [41/100], Step [45300/6235], Loss: 39.1035\n",
      "Epoch [41/100], Step [45400/6235], Loss: 12.6829\n",
      "Epoch [41/100], Step [45500/6235], Loss: 0.1539\n",
      "Epoch [41/100], Step [45600/6235], Loss: 0.2069\n",
      "Epoch [41/100], Step [45700/6235], Loss: 55.2204\n",
      "Epoch [41/100], Step [45800/6235], Loss: 405.2879\n",
      "Epoch [41/100], Step [45900/6235], Loss: 35.0363\n",
      "Epoch [41/100], Step [46000/6235], Loss: 1.6608\n",
      "Epoch [41/100], Step [46100/6235], Loss: 13.0460\n",
      "Epoch [41/100], Step [46200/6235], Loss: 26.7253\n",
      "Epoch [41/100], Step [46300/6235], Loss: 13.7094\n",
      "Epoch [41/100], Step [46400/6235], Loss: 5.4762\n",
      "Epoch [41/100], Step [46500/6235], Loss: 27.6965\n",
      "Epoch [41/100], Step [46600/6235], Loss: 26.4718\n",
      "Epoch [41/100], Step [46700/6235], Loss: 5.2165\n",
      "Epoch [41/100], Step [46800/6235], Loss: 6.8873\n",
      "Epoch [41/100], Step [46900/6235], Loss: 14.6183\n",
      "Epoch [41/100], Step [47000/6235], Loss: 1.6344\n",
      "Epoch [41/100], Step [47100/6235], Loss: 17.5559\n",
      "Epoch [41/100], Step [47200/6235], Loss: 16.0302\n",
      "Epoch [41/100], Step [47300/6235], Loss: 1.0739\n",
      "Epoch [41/100], Step [47400/6235], Loss: 15.1678\n",
      "Epoch [41/100], Step [47500/6235], Loss: 0.0804\n",
      "Epoch [41/100], Step [47600/6235], Loss: 16.8255\n",
      "Epoch [41/100], Step [47700/6235], Loss: 27.8199\n",
      "Epoch [41/100], Step [47800/6235], Loss: 14.7842\n",
      "Epoch [41/100], Step [47900/6235], Loss: 17.6930\n",
      "Epoch [41/100], Step [48000/6235], Loss: 13.2769\n",
      "Epoch [41/100], Step [48100/6235], Loss: 4.0012\n",
      "Epoch [41/100], Step [48200/6235], Loss: 21.2662\n",
      "Epoch [41/100], Step [48300/6235], Loss: 301.4813\n",
      "Epoch [41/100], Step [48400/6235], Loss: 24.5948\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [41/100], Step [48500/6235], Loss: 17.8467\n",
      "Epoch [41/100], Step [48600/6235], Loss: 167.0627\n",
      "Epoch [41/100], Step [48700/6235], Loss: 24.8299\n",
      "Epoch [41/100], Step [48800/6235], Loss: 243.7778\n",
      "Epoch [41/100], Step [48900/6235], Loss: 40.4668\n",
      "Epoch [41/100], Step [49000/6235], Loss: 287.8376\n",
      "Epoch [41/100], Step [49100/6235], Loss: 1412.9082\n",
      "Epoch [41/100], Step [49200/6235], Loss: 914.1584\n",
      "Epoch [41/100], Step [49300/6235], Loss: 1262.3785\n",
      "Epoch [41/100], Step [49400/6235], Loss: 1.8358\n",
      "Epoch [41/100], Step [49500/6235], Loss: 13.6445\n",
      "Epoch [41/100], Step [49600/6235], Loss: 76.0400\n",
      "Epoch [41/100], Step [49700/6235], Loss: 1855.7552\n",
      "Epoch [41/100], Step [49800/6235], Loss: 33.9758\n",
      "Epoch [42/100], Step [100/6235], Loss: 39.2278\n",
      "Epoch [42/100], Step [200/6235], Loss: 0.2270\n",
      "Epoch [42/100], Step [300/6235], Loss: 0.0082\n",
      "Epoch [42/100], Step [400/6235], Loss: 0.0036\n",
      "Epoch [42/100], Step [500/6235], Loss: 5.4161\n",
      "Epoch [42/100], Step [600/6235], Loss: 0.0216\n",
      "Epoch [42/100], Step [700/6235], Loss: 0.6213\n",
      "Epoch [42/100], Step [800/6235], Loss: 0.0909\n",
      "Epoch [42/100], Step [900/6235], Loss: 0.1043\n",
      "Epoch [42/100], Step [1000/6235], Loss: 0.0455\n",
      "Epoch [42/100], Step [1100/6235], Loss: 0.2396\n",
      "Epoch [42/100], Step [1200/6235], Loss: 0.1714\n",
      "Epoch [42/100], Step [1300/6235], Loss: 0.0508\n",
      "Epoch [42/100], Step [1400/6235], Loss: 0.5939\n",
      "Epoch [42/100], Step [1500/6235], Loss: 0.0153\n",
      "Epoch [42/100], Step [1600/6235], Loss: 0.2376\n",
      "Epoch [42/100], Step [1700/6235], Loss: 0.1984\n",
      "Epoch [42/100], Step [1800/6235], Loss: 0.2563\n",
      "Epoch [42/100], Step [1900/6235], Loss: 0.3404\n",
      "Epoch [42/100], Step [2000/6235], Loss: 2.3095\n",
      "Epoch [42/100], Step [2100/6235], Loss: 2.7997\n",
      "Epoch [42/100], Step [2200/6235], Loss: 5.7883\n",
      "Epoch [42/100], Step [2300/6235], Loss: 0.1157\n",
      "Epoch [42/100], Step [2400/6235], Loss: 0.5124\n",
      "Epoch [42/100], Step [2500/6235], Loss: 22.8903\n",
      "Epoch [42/100], Step [2600/6235], Loss: 13.6302\n",
      "Epoch [42/100], Step [2700/6235], Loss: 6.3529\n",
      "Epoch [42/100], Step [2800/6235], Loss: 39.4852\n",
      "Epoch [42/100], Step [2900/6235], Loss: 18.8073\n",
      "Epoch [42/100], Step [3000/6235], Loss: 0.7643\n",
      "Epoch [42/100], Step [3100/6235], Loss: 63.6652\n",
      "Epoch [42/100], Step [3200/6235], Loss: 43.8777\n",
      "Epoch [42/100], Step [3300/6235], Loss: 10.3471\n",
      "Epoch [42/100], Step [3400/6235], Loss: 3.6576\n",
      "Epoch [42/100], Step [3500/6235], Loss: 52.1261\n",
      "Epoch [42/100], Step [3600/6235], Loss: 1.4829\n",
      "Epoch [42/100], Step [3700/6235], Loss: 0.0717\n",
      "Epoch [42/100], Step [3800/6235], Loss: 0.0371\n",
      "Epoch [42/100], Step [3900/6235], Loss: 0.1484\n",
      "Epoch [42/100], Step [4000/6235], Loss: 0.1155\n",
      "Epoch [42/100], Step [4100/6235], Loss: 9.7775\n",
      "Epoch [42/100], Step [4200/6235], Loss: 3.5628\n",
      "Epoch [42/100], Step [4300/6235], Loss: 6.4166\n",
      "Epoch [42/100], Step [4400/6235], Loss: 0.5792\n",
      "Epoch [42/100], Step [4500/6235], Loss: 37.1785\n",
      "Epoch [42/100], Step [4600/6235], Loss: 1.7810\n",
      "Epoch [42/100], Step [4700/6235], Loss: 0.2399\n",
      "Epoch [42/100], Step [4800/6235], Loss: 7.7799\n",
      "Epoch [42/100], Step [4900/6235], Loss: 1.1704\n",
      "Epoch [42/100], Step [5000/6235], Loss: 0.0695\n",
      "Epoch [42/100], Step [5100/6235], Loss: 0.6276\n",
      "Epoch [42/100], Step [5200/6235], Loss: 3.3934\n",
      "Epoch [42/100], Step [5300/6235], Loss: 26.3782\n",
      "Epoch [42/100], Step [5400/6235], Loss: 0.2956\n",
      "Epoch [42/100], Step [5500/6235], Loss: 0.0887\n",
      "Epoch [42/100], Step [5600/6235], Loss: 0.3920\n",
      "Epoch [42/100], Step [5700/6235], Loss: 0.1433\n",
      "Epoch [42/100], Step [5800/6235], Loss: 0.1726\n",
      "Epoch [42/100], Step [5900/6235], Loss: 0.2322\n",
      "Epoch [42/100], Step [6000/6235], Loss: 0.2199\n",
      "Epoch [42/100], Step [6100/6235], Loss: 0.1141\n",
      "Epoch [42/100], Step [6200/6235], Loss: 6.1819\n",
      "Epoch [42/100], Step [6300/6235], Loss: 0.0991\n",
      "Epoch [42/100], Step [6400/6235], Loss: 0.0237\n",
      "Epoch [42/100], Step [6500/6235], Loss: 2.4799\n",
      "Epoch [42/100], Step [6600/6235], Loss: 5.4340\n",
      "Epoch [42/100], Step [6700/6235], Loss: 1.2987\n",
      "Epoch [42/100], Step [6800/6235], Loss: 0.3141\n",
      "Epoch [42/100], Step [6900/6235], Loss: 0.8686\n",
      "Epoch [42/100], Step [7000/6235], Loss: 0.1535\n",
      "Epoch [42/100], Step [7100/6235], Loss: 0.4425\n",
      "Epoch [42/100], Step [7200/6235], Loss: 0.1315\n",
      "Epoch [42/100], Step [7300/6235], Loss: 1.1028\n",
      "Epoch [42/100], Step [7400/6235], Loss: 0.0359\n",
      "Epoch [42/100], Step [7500/6235], Loss: 0.9949\n",
      "Epoch [42/100], Step [7600/6235], Loss: 5.0912\n",
      "Epoch [42/100], Step [7700/6235], Loss: 9.4695\n",
      "Epoch [42/100], Step [7800/6235], Loss: 1.7270\n",
      "Epoch [42/100], Step [7900/6235], Loss: 4.3993\n",
      "Epoch [42/100], Step [8000/6235], Loss: 0.3559\n",
      "Epoch [42/100], Step [8100/6235], Loss: 1.5526\n",
      "Epoch [42/100], Step [8200/6235], Loss: 10.2172\n",
      "Epoch [42/100], Step [8300/6235], Loss: 17.2987\n",
      "Epoch [42/100], Step [8400/6235], Loss: 512.6196\n",
      "Epoch [42/100], Step [8500/6235], Loss: 12.6749\n",
      "Epoch [42/100], Step [8600/6235], Loss: 42.5019\n",
      "Epoch [42/100], Step [8700/6235], Loss: 25.4144\n",
      "Epoch [42/100], Step [8800/6235], Loss: 467.9292\n",
      "Epoch [42/100], Step [8900/6235], Loss: 269.5374\n",
      "Epoch [42/100], Step [9000/6235], Loss: 597.0149\n",
      "Epoch [42/100], Step [9100/6235], Loss: 22.0680\n",
      "Epoch [42/100], Step [9200/6235], Loss: 2566.5469\n",
      "Epoch [42/100], Step [9300/6235], Loss: 334.0582\n",
      "Epoch [42/100], Step [9400/6235], Loss: 1099.4817\n",
      "Epoch [42/100], Step [9500/6235], Loss: 1185.4122\n",
      "Epoch [42/100], Step [9600/6235], Loss: 446.2530\n",
      "Epoch [42/100], Step [9700/6235], Loss: 10.5700\n",
      "Epoch [42/100], Step [9800/6235], Loss: 2566.6672\n",
      "Epoch [42/100], Step [9900/6235], Loss: 6.4009\n",
      "Epoch [42/100], Step [10000/6235], Loss: 222.9007\n",
      "Epoch [42/100], Step [10100/6235], Loss: 4.6705\n",
      "Epoch [42/100], Step [10200/6235], Loss: 845.9214\n",
      "Epoch [42/100], Step [10300/6235], Loss: 7.6729\n",
      "Epoch [42/100], Step [10400/6235], Loss: 0.8371\n",
      "Epoch [42/100], Step [10500/6235], Loss: 6.3702\n",
      "Epoch [42/100], Step [10600/6235], Loss: 2.8702\n",
      "Epoch [42/100], Step [10700/6235], Loss: 131.8201\n",
      "Epoch [42/100], Step [10800/6235], Loss: 2.5634\n",
      "Epoch [42/100], Step [10900/6235], Loss: 8.4642\n",
      "Epoch [42/100], Step [11000/6235], Loss: 190.8646\n",
      "Epoch [42/100], Step [11100/6235], Loss: 3.7055\n",
      "Epoch [42/100], Step [11200/6235], Loss: 112.5501\n",
      "Epoch [42/100], Step [11300/6235], Loss: 241.0291\n",
      "Epoch [42/100], Step [11400/6235], Loss: 5.5816\n",
      "Epoch [42/100], Step [11500/6235], Loss: 1.2121\n",
      "Epoch [42/100], Step [11600/6235], Loss: 4.1401\n",
      "Epoch [42/100], Step [11700/6235], Loss: 60.7463\n",
      "Epoch [42/100], Step [11800/6235], Loss: 85.1283\n",
      "Epoch [42/100], Step [11900/6235], Loss: 39.0253\n",
      "Epoch [42/100], Step [12000/6235], Loss: 610.4127\n",
      "Epoch [42/100], Step [12100/6235], Loss: 203.1755\n",
      "Epoch [42/100], Step [12200/6235], Loss: 28.0502\n",
      "Epoch [42/100], Step [12300/6235], Loss: 16.9591\n",
      "Epoch [42/100], Step [12400/6235], Loss: 557.3518\n",
      "Epoch [42/100], Step [12500/6235], Loss: 50.7007\n",
      "Epoch [42/100], Step [12600/6235], Loss: 12.3884\n",
      "Epoch [42/100], Step [12700/6235], Loss: 9.2707\n",
      "Epoch [42/100], Step [12800/6235], Loss: 13.1475\n",
      "Epoch [42/100], Step [12900/6235], Loss: 41.5616\n",
      "Epoch [42/100], Step [13000/6235], Loss: 1.2034\n",
      "Epoch [42/100], Step [13100/6235], Loss: 72.1325\n",
      "Epoch [42/100], Step [13200/6235], Loss: 8.2598\n",
      "Epoch [42/100], Step [13300/6235], Loss: 19.6713\n",
      "Epoch [42/100], Step [13400/6235], Loss: 253.3180\n",
      "Epoch [42/100], Step [13500/6235], Loss: 3.8565\n",
      "Epoch [42/100], Step [13600/6235], Loss: 4.5844\n",
      "Epoch [42/100], Step [13700/6235], Loss: 224.5482\n",
      "Epoch [42/100], Step [13800/6235], Loss: 127.1771\n",
      "Epoch [42/100], Step [13900/6235], Loss: 189.8173\n",
      "Epoch [42/100], Step [14000/6235], Loss: 0.9435\n",
      "Epoch [42/100], Step [14100/6235], Loss: 43.3177\n",
      "Epoch [42/100], Step [14200/6235], Loss: 9.2027\n",
      "Epoch [42/100], Step [14300/6235], Loss: 42.0544\n",
      "Epoch [42/100], Step [14400/6235], Loss: 31.3504\n",
      "Epoch [42/100], Step [14500/6235], Loss: 9.4290\n",
      "Epoch [42/100], Step [14600/6235], Loss: 2.2505\n",
      "Epoch [42/100], Step [14700/6235], Loss: 24.6399\n",
      "Epoch [42/100], Step [14800/6235], Loss: 27.3157\n",
      "Epoch [42/100], Step [14900/6235], Loss: 0.8033\n",
      "Epoch [42/100], Step [15000/6235], Loss: 1.3836\n",
      "Epoch [42/100], Step [15100/6235], Loss: 0.5522\n",
      "Epoch [42/100], Step [15200/6235], Loss: 0.5988\n",
      "Epoch [42/100], Step [15300/6235], Loss: 0.5993\n",
      "Epoch [42/100], Step [15400/6235], Loss: 1.0692\n",
      "Epoch [42/100], Step [15500/6235], Loss: 9.9785\n",
      "Epoch [42/100], Step [15600/6235], Loss: 17.7989\n",
      "Epoch [42/100], Step [15700/6235], Loss: 134.3680\n",
      "Epoch [42/100], Step [15800/6235], Loss: 8.0369\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Step [15900/6235], Loss: 2.0351\n",
      "Epoch [42/100], Step [16000/6235], Loss: 93.6160\n",
      "Epoch [42/100], Step [16100/6235], Loss: 0.9024\n",
      "Epoch [42/100], Step [16200/6235], Loss: 4.7129\n",
      "Epoch [42/100], Step [16300/6235], Loss: 8.6817\n",
      "Epoch [42/100], Step [16400/6235], Loss: 22.8310\n",
      "Epoch [42/100], Step [16500/6235], Loss: 574.7180\n",
      "Epoch [42/100], Step [16600/6235], Loss: 44.4418\n",
      "Epoch [42/100], Step [16700/6235], Loss: 0.3810\n",
      "Epoch [42/100], Step [16800/6235], Loss: 10.2819\n",
      "Epoch [42/100], Step [16900/6235], Loss: 0.5593\n",
      "Epoch [42/100], Step [17000/6235], Loss: 0.1759\n",
      "Epoch [42/100], Step [17100/6235], Loss: 0.0180\n",
      "Epoch [42/100], Step [17200/6235], Loss: 261.1558\n",
      "Epoch [42/100], Step [17300/6235], Loss: 61.1748\n",
      "Epoch [42/100], Step [17400/6235], Loss: 92.4503\n",
      "Epoch [42/100], Step [17500/6235], Loss: 1.1474\n",
      "Epoch [42/100], Step [17600/6235], Loss: 3.5143\n",
      "Epoch [42/100], Step [17700/6235], Loss: 3.4302\n",
      "Epoch [42/100], Step [17800/6235], Loss: 10.8568\n",
      "Epoch [42/100], Step [17900/6235], Loss: 23.7139\n",
      "Epoch [42/100], Step [18000/6235], Loss: 0.7717\n",
      "Epoch [42/100], Step [18100/6235], Loss: 18.7273\n",
      "Epoch [42/100], Step [18200/6235], Loss: 0.4472\n",
      "Epoch [42/100], Step [18300/6235], Loss: 0.7911\n",
      "Epoch [42/100], Step [18400/6235], Loss: 0.3759\n",
      "Epoch [42/100], Step [18500/6235], Loss: 9.4061\n",
      "Epoch [42/100], Step [18600/6235], Loss: 4.5675\n",
      "Epoch [42/100], Step [18700/6235], Loss: 1.4893\n",
      "Epoch [42/100], Step [18800/6235], Loss: 56.4652\n",
      "Epoch [42/100], Step [18900/6235], Loss: 43.2760\n",
      "Epoch [42/100], Step [19000/6235], Loss: 12.1996\n",
      "Epoch [42/100], Step [19100/6235], Loss: 3.2188\n",
      "Epoch [42/100], Step [19200/6235], Loss: 2.6740\n",
      "Epoch [42/100], Step [19300/6235], Loss: 3.0707\n",
      "Epoch [42/100], Step [19400/6235], Loss: 156.5911\n",
      "Epoch [42/100], Step [19500/6235], Loss: 115.7638\n",
      "Epoch [42/100], Step [19600/6235], Loss: 68.6054\n",
      "Epoch [42/100], Step [19700/6235], Loss: 13.2578\n",
      "Epoch [42/100], Step [19800/6235], Loss: 6.7770\n",
      "Epoch [42/100], Step [19900/6235], Loss: 0.2004\n",
      "Epoch [42/100], Step [20000/6235], Loss: 71.9345\n",
      "Epoch [42/100], Step [20100/6235], Loss: 0.0378\n",
      "Epoch [42/100], Step [20200/6235], Loss: 7.7476\n",
      "Epoch [42/100], Step [20300/6235], Loss: 1.4734\n",
      "Epoch [42/100], Step [20400/6235], Loss: 16.9784\n",
      "Epoch [42/100], Step [20500/6235], Loss: 53.4822\n",
      "Epoch [42/100], Step [20600/6235], Loss: 199.5812\n",
      "Epoch [42/100], Step [20700/6235], Loss: 17.8831\n",
      "Epoch [42/100], Step [20800/6235], Loss: 4.7569\n",
      "Epoch [42/100], Step [20900/6235], Loss: 1.1370\n",
      "Epoch [42/100], Step [21000/6235], Loss: 12.6825\n",
      "Epoch [42/100], Step [21100/6235], Loss: 3.6837\n",
      "Epoch [42/100], Step [21200/6235], Loss: 0.2620\n",
      "Epoch [42/100], Step [21300/6235], Loss: 0.0547\n",
      "Epoch [42/100], Step [21400/6235], Loss: 2.0193\n",
      "Epoch [42/100], Step [21500/6235], Loss: 5.2037\n",
      "Epoch [42/100], Step [21600/6235], Loss: 6.9542\n",
      "Epoch [42/100], Step [21700/6235], Loss: 0.3747\n",
      "Epoch [42/100], Step [21800/6235], Loss: 4.0476\n",
      "Epoch [42/100], Step [21900/6235], Loss: 1.6066\n",
      "Epoch [42/100], Step [22000/6235], Loss: 12.0310\n",
      "Epoch [42/100], Step [22100/6235], Loss: 0.2722\n",
      "Epoch [42/100], Step [22200/6235], Loss: 3.1734\n",
      "Epoch [42/100], Step [22300/6235], Loss: 2.8312\n",
      "Epoch [42/100], Step [22400/6235], Loss: 3.9285\n",
      "Epoch [42/100], Step [22500/6235], Loss: 204.8975\n",
      "Epoch [42/100], Step [22600/6235], Loss: 14.6584\n",
      "Epoch [42/100], Step [22700/6235], Loss: 0.3869\n",
      "Epoch [42/100], Step [22800/6235], Loss: 11.8913\n",
      "Epoch [42/100], Step [22900/6235], Loss: 20.7102\n",
      "Epoch [42/100], Step [23000/6235], Loss: 13.1408\n",
      "Epoch [42/100], Step [23100/6235], Loss: 6.0779\n",
      "Epoch [42/100], Step [23200/6235], Loss: 0.0846\n",
      "Epoch [42/100], Step [23300/6235], Loss: 20.4974\n",
      "Epoch [42/100], Step [23400/6235], Loss: 2.4655\n",
      "Epoch [42/100], Step [23500/6235], Loss: 0.5404\n",
      "Epoch [42/100], Step [23600/6235], Loss: 127.3987\n",
      "Epoch [42/100], Step [23700/6235], Loss: 2.8348\n",
      "Epoch [42/100], Step [23800/6235], Loss: 0.7820\n",
      "Epoch [42/100], Step [23900/6235], Loss: 0.4253\n",
      "Epoch [42/100], Step [24000/6235], Loss: 5.5801\n",
      "Epoch [42/100], Step [24100/6235], Loss: 1.0484\n",
      "Epoch [42/100], Step [24200/6235], Loss: 51.2236\n",
      "Epoch [42/100], Step [24300/6235], Loss: 0.1960\n",
      "Epoch [42/100], Step [24400/6235], Loss: 0.1194\n",
      "Epoch [42/100], Step [24500/6235], Loss: 3.7083\n",
      "Epoch [42/100], Step [24600/6235], Loss: 0.8822\n",
      "Epoch [42/100], Step [24700/6235], Loss: 0.2993\n",
      "Epoch [42/100], Step [24800/6235], Loss: 0.2934\n",
      "Epoch [42/100], Step [24900/6235], Loss: 8.1111\n",
      "Epoch [42/100], Step [25000/6235], Loss: 6.5244\n",
      "Epoch [42/100], Step [25100/6235], Loss: 10.6332\n",
      "Epoch [42/100], Step [25200/6235], Loss: 0.1506\n",
      "Epoch [42/100], Step [25300/6235], Loss: 3.1550\n",
      "Epoch [42/100], Step [25400/6235], Loss: 2.5293\n",
      "Epoch [42/100], Step [25500/6235], Loss: 9.2861\n",
      "Epoch [42/100], Step [25600/6235], Loss: 8.8759\n",
      "Epoch [42/100], Step [25700/6235], Loss: 0.4056\n",
      "Epoch [42/100], Step [25800/6235], Loss: 2.0449\n",
      "Epoch [42/100], Step [25900/6235], Loss: 0.7951\n",
      "Epoch [42/100], Step [26000/6235], Loss: 0.1142\n",
      "Epoch [42/100], Step [26100/6235], Loss: 0.4064\n",
      "Epoch [42/100], Step [26200/6235], Loss: 0.8422\n",
      "Epoch [42/100], Step [26300/6235], Loss: 0.1032\n",
      "Epoch [42/100], Step [26400/6235], Loss: 1.7973\n",
      "Epoch [42/100], Step [26500/6235], Loss: 0.0166\n",
      "Epoch [42/100], Step [26600/6235], Loss: 0.0681\n",
      "Epoch [42/100], Step [26700/6235], Loss: 0.0266\n",
      "Epoch [42/100], Step [26800/6235], Loss: 0.0561\n",
      "Epoch [42/100], Step [26900/6235], Loss: 0.1639\n",
      "Epoch [42/100], Step [27000/6235], Loss: 14.4397\n",
      "Epoch [42/100], Step [27100/6235], Loss: 0.1240\n",
      "Epoch [42/100], Step [27200/6235], Loss: 0.0940\n",
      "Epoch [42/100], Step [27300/6235], Loss: 0.0108\n",
      "Epoch [42/100], Step [27400/6235], Loss: 0.3822\n",
      "Epoch [42/100], Step [27500/6235], Loss: 1.2619\n",
      "Epoch [42/100], Step [27600/6235], Loss: 0.9574\n",
      "Epoch [42/100], Step [27700/6235], Loss: 0.9124\n",
      "Epoch [42/100], Step [27800/6235], Loss: 0.2372\n",
      "Epoch [42/100], Step [27900/6235], Loss: 2.5049\n",
      "Epoch [42/100], Step [28000/6235], Loss: 36.0455\n",
      "Epoch [42/100], Step [28100/6235], Loss: 2.3889\n",
      "Epoch [42/100], Step [28200/6235], Loss: 17.2227\n",
      "Epoch [42/100], Step [28300/6235], Loss: 1.4820\n",
      "Epoch [42/100], Step [28400/6235], Loss: 21.8308\n",
      "Epoch [42/100], Step [28500/6235], Loss: 4.4357\n",
      "Epoch [42/100], Step [28600/6235], Loss: 1.0179\n",
      "Epoch [42/100], Step [28700/6235], Loss: 3.1853\n",
      "Epoch [42/100], Step [28800/6235], Loss: 0.6786\n",
      "Epoch [42/100], Step [28900/6235], Loss: 44.5640\n",
      "Epoch [42/100], Step [29000/6235], Loss: 0.1368\n",
      "Epoch [42/100], Step [29100/6235], Loss: 0.4025\n",
      "Epoch [42/100], Step [29200/6235], Loss: 5.5889\n",
      "Epoch [42/100], Step [29300/6235], Loss: 12.0998\n",
      "Epoch [42/100], Step [29400/6235], Loss: 1.4583\n",
      "Epoch [42/100], Step [29500/6235], Loss: 1.7383\n",
      "Epoch [42/100], Step [29600/6235], Loss: 0.6432\n",
      "Epoch [42/100], Step [29700/6235], Loss: 2.9868\n",
      "Epoch [42/100], Step [29800/6235], Loss: 0.4779\n",
      "Epoch [42/100], Step [29900/6235], Loss: 1.0180\n",
      "Epoch [42/100], Step [30000/6235], Loss: 1.5873\n",
      "Epoch [42/100], Step [30100/6235], Loss: 6.4381\n",
      "Epoch [42/100], Step [30200/6235], Loss: 1.8663\n",
      "Epoch [42/100], Step [30300/6235], Loss: 0.0631\n",
      "Epoch [42/100], Step [30400/6235], Loss: 2.6889\n",
      "Epoch [42/100], Step [30500/6235], Loss: 0.1046\n",
      "Epoch [42/100], Step [30600/6235], Loss: 1.0568\n",
      "Epoch [42/100], Step [30700/6235], Loss: 2.6629\n",
      "Epoch [42/100], Step [30800/6235], Loss: 0.4888\n",
      "Epoch [42/100], Step [30900/6235], Loss: 1.4065\n",
      "Epoch [42/100], Step [31000/6235], Loss: 0.2957\n",
      "Epoch [42/100], Step [31100/6235], Loss: 0.5553\n",
      "Epoch [42/100], Step [31200/6235], Loss: 4.8370\n",
      "Epoch [42/100], Step [31300/6235], Loss: 1.7700\n",
      "Epoch [42/100], Step [31400/6235], Loss: 4.1116\n",
      "Epoch [42/100], Step [31500/6235], Loss: 0.8103\n",
      "Epoch [42/100], Step [31600/6235], Loss: 6.6092\n",
      "Epoch [42/100], Step [31700/6235], Loss: 14.6199\n",
      "Epoch [42/100], Step [31800/6235], Loss: 0.7780\n",
      "Epoch [42/100], Step [31900/6235], Loss: 76.2441\n",
      "Epoch [42/100], Step [32000/6235], Loss: 33.7581\n",
      "Epoch [42/100], Step [32100/6235], Loss: 0.6495\n",
      "Epoch [42/100], Step [32200/6235], Loss: 42.5823\n",
      "Epoch [42/100], Step [32300/6235], Loss: 1.2721\n",
      "Epoch [42/100], Step [32400/6235], Loss: 1.0381\n",
      "Epoch [42/100], Step [32500/6235], Loss: 6.5253\n",
      "Epoch [42/100], Step [32600/6235], Loss: 0.1869\n",
      "Epoch [42/100], Step [32700/6235], Loss: 128.3582\n",
      "Epoch [42/100], Step [32800/6235], Loss: 5.4680\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [42/100], Step [32900/6235], Loss: 0.5639\n",
      "Epoch [42/100], Step [33000/6235], Loss: 0.2788\n",
      "Epoch [42/100], Step [33100/6235], Loss: 0.3177\n",
      "Epoch [42/100], Step [33200/6235], Loss: 1.3457\n",
      "Epoch [42/100], Step [33300/6235], Loss: 5.9915\n",
      "Epoch [42/100], Step [33400/6235], Loss: 10.6017\n",
      "Epoch [42/100], Step [33500/6235], Loss: 1.0663\n",
      "Epoch [42/100], Step [33600/6235], Loss: 9.9083\n",
      "Epoch [42/100], Step [33700/6235], Loss: 15.0642\n",
      "Epoch [42/100], Step [33800/6235], Loss: 1.7024\n",
      "Epoch [42/100], Step [33900/6235], Loss: 27.5562\n",
      "Epoch [42/100], Step [34000/6235], Loss: 0.1204\n",
      "Epoch [42/100], Step [34100/6235], Loss: 0.6445\n",
      "Epoch [42/100], Step [34200/6235], Loss: 2.2724\n",
      "Epoch [42/100], Step [34300/6235], Loss: 2.9761\n",
      "Epoch [42/100], Step [34400/6235], Loss: 0.1390\n",
      "Epoch [42/100], Step [34500/6235], Loss: 14.6613\n",
      "Epoch [42/100], Step [34600/6235], Loss: 2.0082\n",
      "Epoch [42/100], Step [34700/6235], Loss: 4.9216\n",
      "Epoch [42/100], Step [34800/6235], Loss: 11.8709\n",
      "Epoch [42/100], Step [34900/6235], Loss: 67.6483\n",
      "Epoch [42/100], Step [35000/6235], Loss: 0.1929\n",
      "Epoch [42/100], Step [35100/6235], Loss: 1.0844\n",
      "Epoch [42/100], Step [35200/6235], Loss: 0.6541\n",
      "Epoch [42/100], Step [35300/6235], Loss: 2.9561\n",
      "Epoch [42/100], Step [35400/6235], Loss: 0.6285\n",
      "Epoch [42/100], Step [35500/6235], Loss: 0.8249\n",
      "Epoch [42/100], Step [35600/6235], Loss: 5.7768\n",
      "Epoch [42/100], Step [35700/6235], Loss: 4.3044\n",
      "Epoch [42/100], Step [35800/6235], Loss: 1.5984\n",
      "Epoch [42/100], Step [35900/6235], Loss: 0.6808\n",
      "Epoch [42/100], Step [36000/6235], Loss: 0.0334\n",
      "Epoch [42/100], Step [36100/6235], Loss: 0.0591\n",
      "Epoch [42/100], Step [36200/6235], Loss: 16.3364\n",
      "Epoch [42/100], Step [36300/6235], Loss: 0.8691\n",
      "Epoch [42/100], Step [36400/6235], Loss: 3.0843\n",
      "Epoch [42/100], Step [36500/6235], Loss: 7.4150\n",
      "Epoch [42/100], Step [36600/6235], Loss: 0.0952\n",
      "Epoch [42/100], Step [36700/6235], Loss: 0.6090\n",
      "Epoch [42/100], Step [36800/6235], Loss: 4.5020\n",
      "Epoch [42/100], Step [36900/6235], Loss: 11.5768\n",
      "Epoch [42/100], Step [37000/6235], Loss: 0.9815\n",
      "Epoch [42/100], Step [37100/6235], Loss: 1.9560\n",
      "Epoch [42/100], Step [37200/6235], Loss: 0.0396\n",
      "Epoch [42/100], Step [37300/6235], Loss: 0.0484\n",
      "Epoch [42/100], Step [37400/6235], Loss: 0.1712\n",
      "Epoch [42/100], Step [37500/6235], Loss: 7.2895\n",
      "Epoch [42/100], Step [37600/6235], Loss: 12.3753\n",
      "Epoch [42/100], Step [37700/6235], Loss: 2.6597\n",
      "Epoch [42/100], Step [37800/6235], Loss: 2.2243\n",
      "Epoch [42/100], Step [37900/6235], Loss: 5.2498\n",
      "Epoch [42/100], Step [38000/6235], Loss: 1.0205\n",
      "Epoch [42/100], Step [38100/6235], Loss: 4.5687\n",
      "Epoch [42/100], Step [38200/6235], Loss: 2.3097\n",
      "Epoch [42/100], Step [38300/6235], Loss: 0.3322\n",
      "Epoch [42/100], Step [38400/6235], Loss: 0.0860\n",
      "Epoch [42/100], Step [38500/6235], Loss: 1.4732\n",
      "Epoch [42/100], Step [38600/6235], Loss: 0.4124\n",
      "Epoch [42/100], Step [38700/6235], Loss: 0.0534\n",
      "Epoch [42/100], Step [38800/6235], Loss: 0.1335\n",
      "Epoch [42/100], Step [38900/6235], Loss: 3.1583\n",
      "Epoch [42/100], Step [39000/6235], Loss: 4.4094\n",
      "Epoch [42/100], Step [39100/6235], Loss: 16.8368\n",
      "Epoch [42/100], Step [39200/6235], Loss: 0.5855\n",
      "Epoch [42/100], Step [39300/6235], Loss: 15.7610\n",
      "Epoch [42/100], Step [39400/6235], Loss: 116.9579\n",
      "Epoch [42/100], Step [39500/6235], Loss: 143.8973\n",
      "Epoch [42/100], Step [39600/6235], Loss: 11.4662\n",
      "Epoch [42/100], Step [39700/6235], Loss: 86.3226\n",
      "Epoch [42/100], Step [39800/6235], Loss: 169.6636\n",
      "Epoch [42/100], Step [39900/6235], Loss: 0.4135\n",
      "Epoch [42/100], Step [40000/6235], Loss: 5.2124\n",
      "Epoch [42/100], Step [40100/6235], Loss: 31.1167\n",
      "Epoch [42/100], Step [40200/6235], Loss: 19.2062\n",
      "Epoch [42/100], Step [40300/6235], Loss: 0.7936\n",
      "Epoch [42/100], Step [40400/6235], Loss: 2.4007\n",
      "Epoch [42/100], Step [40500/6235], Loss: 1.3551\n",
      "Epoch [42/100], Step [40600/6235], Loss: 1.2563\n",
      "Epoch [42/100], Step [40700/6235], Loss: 7.1422\n",
      "Epoch [42/100], Step [40800/6235], Loss: 3.1773\n",
      "Epoch [42/100], Step [40900/6235], Loss: 0.4415\n",
      "Epoch [42/100], Step [41000/6235], Loss: 23.4029\n",
      "Epoch [42/100], Step [41100/6235], Loss: 3.9720\n",
      "Epoch [42/100], Step [41200/6235], Loss: 18.8659\n",
      "Epoch [42/100], Step [41300/6235], Loss: 2.7460\n",
      "Epoch [42/100], Step [41400/6235], Loss: 0.9531\n",
      "Epoch [42/100], Step [41500/6235], Loss: 0.5022\n",
      "Epoch [42/100], Step [41600/6235], Loss: 0.4677\n",
      "Epoch [42/100], Step [41700/6235], Loss: 2.6098\n",
      "Epoch [42/100], Step [41800/6235], Loss: 3.9698\n",
      "Epoch [42/100], Step [41900/6235], Loss: 3.2920\n",
      "Epoch [42/100], Step [42000/6235], Loss: 2.9438\n",
      "Epoch [42/100], Step [42100/6235], Loss: 6.3490\n",
      "Epoch [42/100], Step [42200/6235], Loss: 4.9150\n",
      "Epoch [42/100], Step [42300/6235], Loss: 0.5170\n",
      "Epoch [42/100], Step [42400/6235], Loss: 2.2284\n",
      "Epoch [42/100], Step [42500/6235], Loss: 1.3963\n",
      "Epoch [42/100], Step [42600/6235], Loss: 0.4622\n",
      "Epoch [42/100], Step [42700/6235], Loss: 0.1957\n",
      "Epoch [42/100], Step [42800/6235], Loss: 0.6995\n",
      "Epoch [42/100], Step [42900/6235], Loss: 4.2461\n",
      "Epoch [42/100], Step [43000/6235], Loss: 0.1721\n",
      "Epoch [42/100], Step [43100/6235], Loss: 1.3074\n",
      "Epoch [42/100], Step [43200/6235], Loss: 0.6027\n",
      "Epoch [42/100], Step [43300/6235], Loss: 10.1231\n",
      "Epoch [42/100], Step [43400/6235], Loss: 6.8959\n",
      "Epoch [42/100], Step [43500/6235], Loss: 7.8901\n",
      "Epoch [42/100], Step [43600/6235], Loss: 30.3738\n",
      "Epoch [42/100], Step [43700/6235], Loss: 30.7407\n",
      "Epoch [42/100], Step [43800/6235], Loss: 0.2846\n",
      "Epoch [42/100], Step [43900/6235], Loss: 1.2376\n",
      "Epoch [42/100], Step [44000/6235], Loss: 27.9093\n",
      "Epoch [42/100], Step [44100/6235], Loss: 2.0474\n",
      "Epoch [42/100], Step [44200/6235], Loss: 31.8930\n",
      "Epoch [42/100], Step [44300/6235], Loss: 72.3929\n",
      "Epoch [42/100], Step [44400/6235], Loss: 1.9412\n",
      "Epoch [42/100], Step [44500/6235], Loss: 3.1759\n",
      "Epoch [42/100], Step [44600/6235], Loss: 8.7730\n",
      "Epoch [42/100], Step [44700/6235], Loss: 3.0062\n",
      "Epoch [42/100], Step [44800/6235], Loss: 1.6812\n",
      "Epoch [42/100], Step [44900/6235], Loss: 0.7876\n",
      "Epoch [42/100], Step [45000/6235], Loss: 2.0337\n",
      "Epoch [42/100], Step [45100/6235], Loss: 22.1488\n",
      "Epoch [42/100], Step [45200/6235], Loss: 0.3197\n",
      "Epoch [42/100], Step [45300/6235], Loss: 3.6119\n",
      "Epoch [42/100], Step [45400/6235], Loss: 6.2058\n",
      "Epoch [42/100], Step [45500/6235], Loss: 0.1524\n",
      "Epoch [42/100], Step [45600/6235], Loss: 1.0725\n",
      "Epoch [42/100], Step [45700/6235], Loss: 4.8174\n",
      "Epoch [42/100], Step [45800/6235], Loss: 299.4690\n",
      "Epoch [42/100], Step [45900/6235], Loss: 10.4838\n",
      "Epoch [42/100], Step [46000/6235], Loss: 95.6054\n",
      "Epoch [42/100], Step [46100/6235], Loss: 30.7669\n",
      "Epoch [42/100], Step [46200/6235], Loss: 7.3396\n",
      "Epoch [42/100], Step [46300/6235], Loss: 7.8712\n",
      "Epoch [42/100], Step [46400/6235], Loss: 2.6678\n",
      "Epoch [42/100], Step [46500/6235], Loss: 7.8190\n",
      "Epoch [42/100], Step [46600/6235], Loss: 3.4446\n",
      "Epoch [42/100], Step [46700/6235], Loss: 1.4150\n",
      "Epoch [42/100], Step [46800/6235], Loss: 33.6248\n",
      "Epoch [42/100], Step [46900/6235], Loss: 20.1616\n",
      "Epoch [42/100], Step [47000/6235], Loss: 1.4478\n",
      "Epoch [42/100], Step [47100/6235], Loss: 92.5341\n",
      "Epoch [42/100], Step [47200/6235], Loss: 102.2796\n",
      "Epoch [42/100], Step [47300/6235], Loss: 3.2872\n",
      "Epoch [42/100], Step [47400/6235], Loss: 434.5576\n",
      "Epoch [42/100], Step [47500/6235], Loss: 6.6514\n",
      "Epoch [42/100], Step [47600/6235], Loss: 15.8680\n",
      "Epoch [42/100], Step [47700/6235], Loss: 23.7250\n",
      "Epoch [42/100], Step [47800/6235], Loss: 32.2659\n",
      "Epoch [42/100], Step [47900/6235], Loss: 15.4701\n",
      "Epoch [42/100], Step [48000/6235], Loss: 100.8744\n",
      "Epoch [42/100], Step [48100/6235], Loss: 6.6265\n",
      "Epoch [42/100], Step [48200/6235], Loss: 19.3793\n",
      "Epoch [42/100], Step [48300/6235], Loss: 558.0413\n",
      "Epoch [42/100], Step [48400/6235], Loss: 6.1120\n",
      "Epoch [42/100], Step [48500/6235], Loss: 47.3300\n",
      "Epoch [42/100], Step [48600/6235], Loss: 84.1962\n",
      "Epoch [42/100], Step [48700/6235], Loss: 2.1751\n",
      "Epoch [42/100], Step [48800/6235], Loss: 395.3456\n",
      "Epoch [42/100], Step [48900/6235], Loss: 833.9249\n",
      "Epoch [42/100], Step [49000/6235], Loss: 173.9485\n",
      "Epoch [42/100], Step [49100/6235], Loss: 1449.1113\n",
      "Epoch [42/100], Step [49200/6235], Loss: 1161.2058\n",
      "Epoch [42/100], Step [49300/6235], Loss: 1089.6379\n",
      "Epoch [42/100], Step [49400/6235], Loss: 137.8761\n",
      "Epoch [42/100], Step [49500/6235], Loss: 7.0504\n",
      "Epoch [42/100], Step [49600/6235], Loss: 339.2347\n",
      "Epoch [42/100], Step [49700/6235], Loss: 5779.6899\n",
      "Epoch [42/100], Step [49800/6235], Loss: 146.2302\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Step [100/6235], Loss: 0.8639\n",
      "Epoch [43/100], Step [200/6235], Loss: 0.8603\n",
      "Epoch [43/100], Step [300/6235], Loss: 0.1077\n",
      "Epoch [43/100], Step [400/6235], Loss: 0.0401\n",
      "Epoch [43/100], Step [500/6235], Loss: 0.1484\n",
      "Epoch [43/100], Step [600/6235], Loss: 0.0784\n",
      "Epoch [43/100], Step [700/6235], Loss: 0.5029\n",
      "Epoch [43/100], Step [800/6235], Loss: 0.0157\n",
      "Epoch [43/100], Step [900/6235], Loss: 0.0555\n",
      "Epoch [43/100], Step [1000/6235], Loss: 0.0152\n",
      "Epoch [43/100], Step [1100/6235], Loss: 0.0151\n",
      "Epoch [43/100], Step [1200/6235], Loss: 0.1382\n",
      "Epoch [43/100], Step [1300/6235], Loss: 0.0021\n",
      "Epoch [43/100], Step [1400/6235], Loss: 0.0519\n",
      "Epoch [43/100], Step [1500/6235], Loss: 0.0042\n",
      "Epoch [43/100], Step [1600/6235], Loss: 0.2430\n",
      "Epoch [43/100], Step [1700/6235], Loss: 0.3004\n",
      "Epoch [43/100], Step [1800/6235], Loss: 0.3738\n",
      "Epoch [43/100], Step [1900/6235], Loss: 0.2479\n",
      "Epoch [43/100], Step [2000/6235], Loss: 1.8884\n",
      "Epoch [43/100], Step [2100/6235], Loss: 3.1106\n",
      "Epoch [43/100], Step [2200/6235], Loss: 3.3763\n",
      "Epoch [43/100], Step [2300/6235], Loss: 3.0277\n",
      "Epoch [43/100], Step [2400/6235], Loss: 7.7329\n",
      "Epoch [43/100], Step [2500/6235], Loss: 18.6955\n",
      "Epoch [43/100], Step [2600/6235], Loss: 17.3403\n",
      "Epoch [43/100], Step [2700/6235], Loss: 20.1436\n",
      "Epoch [43/100], Step [2800/6235], Loss: 11.2366\n",
      "Epoch [43/100], Step [2900/6235], Loss: 6.7028\n",
      "Epoch [43/100], Step [3000/6235], Loss: 3.5347\n",
      "Epoch [43/100], Step [3100/6235], Loss: 105.0760\n",
      "Epoch [43/100], Step [3200/6235], Loss: 6.7782\n",
      "Epoch [43/100], Step [3300/6235], Loss: 0.6344\n",
      "Epoch [43/100], Step [3400/6235], Loss: 7.3560\n",
      "Epoch [43/100], Step [3500/6235], Loss: 70.2685\n",
      "Epoch [43/100], Step [3600/6235], Loss: 2.7353\n",
      "Epoch [43/100], Step [3700/6235], Loss: 0.1470\n",
      "Epoch [43/100], Step [3800/6235], Loss: 0.2391\n",
      "Epoch [43/100], Step [3900/6235], Loss: 0.2605\n",
      "Epoch [43/100], Step [4000/6235], Loss: 0.5202\n",
      "Epoch [43/100], Step [4100/6235], Loss: 6.6829\n",
      "Epoch [43/100], Step [4200/6235], Loss: 1.5521\n",
      "Epoch [43/100], Step [4300/6235], Loss: 1.9573\n",
      "Epoch [43/100], Step [4400/6235], Loss: 0.0295\n",
      "Epoch [43/100], Step [4500/6235], Loss: 56.9513\n",
      "Epoch [43/100], Step [4600/6235], Loss: 15.7887\n",
      "Epoch [43/100], Step [4700/6235], Loss: 1.1980\n",
      "Epoch [43/100], Step [4800/6235], Loss: 1.9293\n",
      "Epoch [43/100], Step [4900/6235], Loss: 1.6273\n",
      "Epoch [43/100], Step [5000/6235], Loss: 0.2489\n",
      "Epoch [43/100], Step [5100/6235], Loss: 7.6487\n",
      "Epoch [43/100], Step [5200/6235], Loss: 1.3918\n",
      "Epoch [43/100], Step [5300/6235], Loss: 14.0551\n",
      "Epoch [43/100], Step [5400/6235], Loss: 3.5877\n",
      "Epoch [43/100], Step [5500/6235], Loss: 0.8029\n",
      "Epoch [43/100], Step [5600/6235], Loss: 0.5589\n",
      "Epoch [43/100], Step [5700/6235], Loss: 0.3288\n",
      "Epoch [43/100], Step [5800/6235], Loss: 0.8405\n",
      "Epoch [43/100], Step [5900/6235], Loss: 0.0242\n",
      "Epoch [43/100], Step [6000/6235], Loss: 0.8838\n",
      "Epoch [43/100], Step [6100/6235], Loss: 0.0229\n",
      "Epoch [43/100], Step [6200/6235], Loss: 5.7423\n",
      "Epoch [43/100], Step [6300/6235], Loss: 0.5949\n",
      "Epoch [43/100], Step [6400/6235], Loss: 0.0662\n",
      "Epoch [43/100], Step [6500/6235], Loss: 1.7622\n",
      "Epoch [43/100], Step [6600/6235], Loss: 20.2812\n",
      "Epoch [43/100], Step [6700/6235], Loss: 1.7211\n",
      "Epoch [43/100], Step [6800/6235], Loss: 0.3027\n",
      "Epoch [43/100], Step [6900/6235], Loss: 0.2793\n",
      "Epoch [43/100], Step [7000/6235], Loss: 0.0603\n",
      "Epoch [43/100], Step [7100/6235], Loss: 0.5292\n",
      "Epoch [43/100], Step [7200/6235], Loss: 0.8548\n",
      "Epoch [43/100], Step [7300/6235], Loss: 2.0299\n",
      "Epoch [43/100], Step [7400/6235], Loss: 0.2118\n",
      "Epoch [43/100], Step [7500/6235], Loss: 0.5147\n",
      "Epoch [43/100], Step [7600/6235], Loss: 2.9023\n",
      "Epoch [43/100], Step [7700/6235], Loss: 3.5671\n",
      "Epoch [43/100], Step [7800/6235], Loss: 7.6991\n",
      "Epoch [43/100], Step [7900/6235], Loss: 8.7417\n",
      "Epoch [43/100], Step [8000/6235], Loss: 0.6581\n",
      "Epoch [43/100], Step [8100/6235], Loss: 0.0903\n",
      "Epoch [43/100], Step [8200/6235], Loss: 10.9462\n",
      "Epoch [43/100], Step [8300/6235], Loss: 7.5397\n",
      "Epoch [43/100], Step [8400/6235], Loss: 564.8061\n",
      "Epoch [43/100], Step [8500/6235], Loss: 14.5784\n",
      "Epoch [43/100], Step [8600/6235], Loss: 43.8306\n",
      "Epoch [43/100], Step [8700/6235], Loss: 45.2892\n",
      "Epoch [43/100], Step [8800/6235], Loss: 668.4462\n",
      "Epoch [43/100], Step [8900/6235], Loss: 76.6705\n",
      "Epoch [43/100], Step [9000/6235], Loss: 370.6615\n",
      "Epoch [43/100], Step [9100/6235], Loss: 759.6076\n",
      "Epoch [43/100], Step [9200/6235], Loss: 544.6158\n",
      "Epoch [43/100], Step [9300/6235], Loss: 559.8807\n",
      "Epoch [43/100], Step [9400/6235], Loss: 758.7101\n",
      "Epoch [43/100], Step [9500/6235], Loss: 477.2122\n",
      "Epoch [43/100], Step [9600/6235], Loss: 865.3449\n",
      "Epoch [43/100], Step [9700/6235], Loss: 1.5820\n",
      "Epoch [43/100], Step [9800/6235], Loss: 1039.8951\n",
      "Epoch [43/100], Step [9900/6235], Loss: 573.7082\n",
      "Epoch [43/100], Step [10000/6235], Loss: 153.1822\n",
      "Epoch [43/100], Step [10100/6235], Loss: 2.2131\n",
      "Epoch [43/100], Step [10200/6235], Loss: 605.6956\n",
      "Epoch [43/100], Step [10300/6235], Loss: 7.6434\n",
      "Epoch [43/100], Step [10400/6235], Loss: 1.4220\n",
      "Epoch [43/100], Step [10500/6235], Loss: 2.7258\n",
      "Epoch [43/100], Step [10600/6235], Loss: 21.1328\n",
      "Epoch [43/100], Step [10700/6235], Loss: 140.8830\n",
      "Epoch [43/100], Step [10800/6235], Loss: 1.7314\n",
      "Epoch [43/100], Step [10900/6235], Loss: 8.7463\n",
      "Epoch [43/100], Step [11000/6235], Loss: 203.1982\n",
      "Epoch [43/100], Step [11100/6235], Loss: 5.2198\n",
      "Epoch [43/100], Step [11200/6235], Loss: 107.2365\n",
      "Epoch [43/100], Step [11300/6235], Loss: 235.3735\n",
      "Epoch [43/100], Step [11400/6235], Loss: 4.1742\n",
      "Epoch [43/100], Step [11500/6235], Loss: 0.8473\n",
      "Epoch [43/100], Step [11600/6235], Loss: 3.2995\n",
      "Epoch [43/100], Step [11700/6235], Loss: 57.7276\n",
      "Epoch [43/100], Step [11800/6235], Loss: 87.1667\n",
      "Epoch [43/100], Step [11900/6235], Loss: 22.9782\n",
      "Epoch [43/100], Step [12000/6235], Loss: 530.3301\n",
      "Epoch [43/100], Step [12100/6235], Loss: 206.9210\n",
      "Epoch [43/100], Step [12200/6235], Loss: 24.0572\n",
      "Epoch [43/100], Step [12300/6235], Loss: 41.8859\n",
      "Epoch [43/100], Step [12400/6235], Loss: 591.1866\n",
      "Epoch [43/100], Step [12500/6235], Loss: 22.4731\n",
      "Epoch [43/100], Step [12600/6235], Loss: 49.4426\n",
      "Epoch [43/100], Step [12700/6235], Loss: 4.3153\n",
      "Epoch [43/100], Step [12800/6235], Loss: 6.4419\n",
      "Epoch [43/100], Step [12900/6235], Loss: 50.5651\n",
      "Epoch [43/100], Step [13000/6235], Loss: 1.3145\n",
      "Epoch [43/100], Step [13100/6235], Loss: 73.5365\n",
      "Epoch [43/100], Step [13200/6235], Loss: 17.3677\n",
      "Epoch [43/100], Step [13300/6235], Loss: 31.8678\n",
      "Epoch [43/100], Step [13400/6235], Loss: 253.6508\n",
      "Epoch [43/100], Step [13500/6235], Loss: 8.1606\n",
      "Epoch [43/100], Step [13600/6235], Loss: 13.7485\n",
      "Epoch [43/100], Step [13700/6235], Loss: 15.2194\n",
      "Epoch [43/100], Step [13800/6235], Loss: 167.5075\n",
      "Epoch [43/100], Step [13900/6235], Loss: 56.9346\n",
      "Epoch [43/100], Step [14000/6235], Loss: 10.0530\n",
      "Epoch [43/100], Step [14100/6235], Loss: 31.0024\n",
      "Epoch [43/100], Step [14200/6235], Loss: 121.0368\n",
      "Epoch [43/100], Step [14300/6235], Loss: 56.0238\n",
      "Epoch [43/100], Step [14400/6235], Loss: 37.1910\n",
      "Epoch [43/100], Step [14500/6235], Loss: 80.5094\n",
      "Epoch [43/100], Step [14600/6235], Loss: 0.8926\n",
      "Epoch [43/100], Step [14700/6235], Loss: 43.6177\n",
      "Epoch [43/100], Step [14800/6235], Loss: 29.0119\n",
      "Epoch [43/100], Step [14900/6235], Loss: 3.1166\n",
      "Epoch [43/100], Step [15000/6235], Loss: 4.5363\n",
      "Epoch [43/100], Step [15100/6235], Loss: 0.0875\n",
      "Epoch [43/100], Step [15200/6235], Loss: 5.4018\n",
      "Epoch [43/100], Step [15300/6235], Loss: 26.6255\n",
      "Epoch [43/100], Step [15400/6235], Loss: 61.0166\n",
      "Epoch [43/100], Step [15500/6235], Loss: 11.8392\n",
      "Epoch [43/100], Step [15600/6235], Loss: 154.2189\n",
      "Epoch [43/100], Step [15700/6235], Loss: 36.3599\n",
      "Epoch [43/100], Step [15800/6235], Loss: 2.4966\n",
      "Epoch [43/100], Step [15900/6235], Loss: 1.2304\n",
      "Epoch [43/100], Step [16000/6235], Loss: 8.8884\n",
      "Epoch [43/100], Step [16100/6235], Loss: 12.2157\n",
      "Epoch [43/100], Step [16200/6235], Loss: 0.2351\n",
      "Epoch [43/100], Step [16300/6235], Loss: 11.5704\n",
      "Epoch [43/100], Step [16400/6235], Loss: 44.4677\n",
      "Epoch [43/100], Step [16500/6235], Loss: 501.5832\n",
      "Epoch [43/100], Step [16600/6235], Loss: 13.1475\n",
      "Epoch [43/100], Step [16700/6235], Loss: 0.5987\n",
      "Epoch [43/100], Step [16800/6235], Loss: 9.3910\n",
      "Epoch [43/100], Step [16900/6235], Loss: 0.1064\n",
      "Epoch [43/100], Step [17000/6235], Loss: 0.2416\n",
      "Epoch [43/100], Step [17100/6235], Loss: 0.3332\n",
      "Epoch [43/100], Step [17200/6235], Loss: 287.9051\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Step [17300/6235], Loss: 1.0564\n",
      "Epoch [43/100], Step [17400/6235], Loss: 45.6470\n",
      "Epoch [43/100], Step [17500/6235], Loss: 0.8489\n",
      "Epoch [43/100], Step [17600/6235], Loss: 4.1597\n",
      "Epoch [43/100], Step [17700/6235], Loss: 20.8376\n",
      "Epoch [43/100], Step [17800/6235], Loss: 23.4158\n",
      "Epoch [43/100], Step [17900/6235], Loss: 16.9974\n",
      "Epoch [43/100], Step [18000/6235], Loss: 3.5476\n",
      "Epoch [43/100], Step [18100/6235], Loss: 17.5019\n",
      "Epoch [43/100], Step [18200/6235], Loss: 0.5965\n",
      "Epoch [43/100], Step [18300/6235], Loss: 1.2713\n",
      "Epoch [43/100], Step [18400/6235], Loss: 0.8449\n",
      "Epoch [43/100], Step [18500/6235], Loss: 31.5250\n",
      "Epoch [43/100], Step [18600/6235], Loss: 4.5378\n",
      "Epoch [43/100], Step [18700/6235], Loss: 1.3320\n",
      "Epoch [43/100], Step [18800/6235], Loss: 163.6381\n",
      "Epoch [43/100], Step [18900/6235], Loss: 3.8263\n",
      "Epoch [43/100], Step [19000/6235], Loss: 2.0359\n",
      "Epoch [43/100], Step [19100/6235], Loss: 38.7932\n",
      "Epoch [43/100], Step [19200/6235], Loss: 1.0032\n",
      "Epoch [43/100], Step [19300/6235], Loss: 16.2132\n",
      "Epoch [43/100], Step [19400/6235], Loss: 116.4704\n",
      "Epoch [43/100], Step [19500/6235], Loss: 22.2038\n",
      "Epoch [43/100], Step [19600/6235], Loss: 11.8511\n",
      "Epoch [43/100], Step [19700/6235], Loss: 3.9781\n",
      "Epoch [43/100], Step [19800/6235], Loss: 3.9917\n",
      "Epoch [43/100], Step [19900/6235], Loss: 0.0680\n",
      "Epoch [43/100], Step [20000/6235], Loss: 69.0961\n",
      "Epoch [43/100], Step [20100/6235], Loss: 4.9647\n",
      "Epoch [43/100], Step [20200/6235], Loss: 0.2748\n",
      "Epoch [43/100], Step [20300/6235], Loss: 0.6735\n",
      "Epoch [43/100], Step [20400/6235], Loss: 4.4437\n",
      "Epoch [43/100], Step [20500/6235], Loss: 61.6641\n",
      "Epoch [43/100], Step [20600/6235], Loss: 51.5246\n",
      "Epoch [43/100], Step [20700/6235], Loss: 16.6287\n",
      "Epoch [43/100], Step [20800/6235], Loss: 4.2726\n",
      "Epoch [43/100], Step [20900/6235], Loss: 1.7847\n",
      "Epoch [43/100], Step [21000/6235], Loss: 12.4117\n",
      "Epoch [43/100], Step [21100/6235], Loss: 3.1162\n",
      "Epoch [43/100], Step [21200/6235], Loss: 0.3424\n",
      "Epoch [43/100], Step [21300/6235], Loss: 0.0553\n",
      "Epoch [43/100], Step [21400/6235], Loss: 2.3508\n",
      "Epoch [43/100], Step [21500/6235], Loss: 7.6093\n",
      "Epoch [43/100], Step [21600/6235], Loss: 5.0081\n",
      "Epoch [43/100], Step [21700/6235], Loss: 0.2857\n",
      "Epoch [43/100], Step [21800/6235], Loss: 4.9985\n",
      "Epoch [43/100], Step [21900/6235], Loss: 1.7178\n",
      "Epoch [43/100], Step [22000/6235], Loss: 10.8929\n",
      "Epoch [43/100], Step [22100/6235], Loss: 0.0408\n",
      "Epoch [43/100], Step [22200/6235], Loss: 2.4005\n",
      "Epoch [43/100], Step [22300/6235], Loss: 11.4134\n",
      "Epoch [43/100], Step [22400/6235], Loss: 6.2654\n",
      "Epoch [43/100], Step [22500/6235], Loss: 112.0419\n",
      "Epoch [43/100], Step [22600/6235], Loss: 17.9485\n",
      "Epoch [43/100], Step [22700/6235], Loss: 1.7889\n",
      "Epoch [43/100], Step [22800/6235], Loss: 4.1121\n",
      "Epoch [43/100], Step [22900/6235], Loss: 17.9108\n",
      "Epoch [43/100], Step [23000/6235], Loss: 18.8405\n",
      "Epoch [43/100], Step [23100/6235], Loss: 5.3925\n",
      "Epoch [43/100], Step [23200/6235], Loss: 1.2301\n",
      "Epoch [43/100], Step [23300/6235], Loss: 20.6128\n",
      "Epoch [43/100], Step [23400/6235], Loss: 2.6402\n",
      "Epoch [43/100], Step [23500/6235], Loss: 0.4405\n",
      "Epoch [43/100], Step [23600/6235], Loss: 128.2625\n",
      "Epoch [43/100], Step [23700/6235], Loss: 5.9101\n",
      "Epoch [43/100], Step [23800/6235], Loss: 1.3068\n",
      "Epoch [43/100], Step [23900/6235], Loss: 0.3550\n",
      "Epoch [43/100], Step [24000/6235], Loss: 4.5121\n",
      "Epoch [43/100], Step [24100/6235], Loss: 0.3455\n",
      "Epoch [43/100], Step [24200/6235], Loss: 5.9227\n",
      "Epoch [43/100], Step [24300/6235], Loss: 0.2285\n",
      "Epoch [43/100], Step [24400/6235], Loss: 0.2306\n",
      "Epoch [43/100], Step [24500/6235], Loss: 3.9518\n",
      "Epoch [43/100], Step [24600/6235], Loss: 0.5243\n",
      "Epoch [43/100], Step [24700/6235], Loss: 0.0973\n",
      "Epoch [43/100], Step [24800/6235], Loss: 0.2490\n",
      "Epoch [43/100], Step [24900/6235], Loss: 8.1797\n",
      "Epoch [43/100], Step [25000/6235], Loss: 5.4240\n",
      "Epoch [43/100], Step [25100/6235], Loss: 9.7888\n",
      "Epoch [43/100], Step [25200/6235], Loss: 0.1223\n",
      "Epoch [43/100], Step [25300/6235], Loss: 2.9255\n",
      "Epoch [43/100], Step [25400/6235], Loss: 2.3284\n",
      "Epoch [43/100], Step [25500/6235], Loss: 9.6483\n",
      "Epoch [43/100], Step [25600/6235], Loss: 10.3072\n",
      "Epoch [43/100], Step [25700/6235], Loss: 0.2054\n",
      "Epoch [43/100], Step [25800/6235], Loss: 2.1417\n",
      "Epoch [43/100], Step [25900/6235], Loss: 1.3112\n",
      "Epoch [43/100], Step [26000/6235], Loss: 0.1004\n",
      "Epoch [43/100], Step [26100/6235], Loss: 0.2847\n",
      "Epoch [43/100], Step [26200/6235], Loss: 1.0504\n",
      "Epoch [43/100], Step [26300/6235], Loss: 0.1809\n",
      "Epoch [43/100], Step [26400/6235], Loss: 1.4557\n",
      "Epoch [43/100], Step [26500/6235], Loss: 0.0254\n",
      "Epoch [43/100], Step [26600/6235], Loss: 0.0297\n",
      "Epoch [43/100], Step [26700/6235], Loss: 0.0349\n",
      "Epoch [43/100], Step [26800/6235], Loss: 0.0512\n",
      "Epoch [43/100], Step [26900/6235], Loss: 0.1441\n",
      "Epoch [43/100], Step [27000/6235], Loss: 15.1877\n",
      "Epoch [43/100], Step [27100/6235], Loss: 0.1133\n",
      "Epoch [43/100], Step [27200/6235], Loss: 0.0442\n",
      "Epoch [43/100], Step [27300/6235], Loss: 0.0051\n",
      "Epoch [43/100], Step [27400/6235], Loss: 0.4361\n",
      "Epoch [43/100], Step [27500/6235], Loss: 0.1175\n",
      "Epoch [43/100], Step [27600/6235], Loss: 0.6353\n",
      "Epoch [43/100], Step [27700/6235], Loss: 0.8892\n",
      "Epoch [43/100], Step [27800/6235], Loss: 5.0246\n",
      "Epoch [43/100], Step [27900/6235], Loss: 1.3975\n",
      "Epoch [43/100], Step [28000/6235], Loss: 194.4227\n",
      "Epoch [43/100], Step [28100/6235], Loss: 5.3917\n",
      "Epoch [43/100], Step [28200/6235], Loss: 35.6593\n",
      "Epoch [43/100], Step [28300/6235], Loss: 2.1733\n",
      "Epoch [43/100], Step [28400/6235], Loss: 24.9562\n",
      "Epoch [43/100], Step [28500/6235], Loss: 2.9168\n",
      "Epoch [43/100], Step [28600/6235], Loss: 1.0447\n",
      "Epoch [43/100], Step [28700/6235], Loss: 3.3392\n",
      "Epoch [43/100], Step [28800/6235], Loss: 0.6679\n",
      "Epoch [43/100], Step [28900/6235], Loss: 46.5473\n",
      "Epoch [43/100], Step [29000/6235], Loss: 1.0546\n",
      "Epoch [43/100], Step [29100/6235], Loss: 0.5648\n",
      "Epoch [43/100], Step [29200/6235], Loss: 5.2425\n",
      "Epoch [43/100], Step [29300/6235], Loss: 11.4327\n",
      "Epoch [43/100], Step [29400/6235], Loss: 0.3841\n",
      "Epoch [43/100], Step [29500/6235], Loss: 1.1736\n",
      "Epoch [43/100], Step [29600/6235], Loss: 0.4520\n",
      "Epoch [43/100], Step [29700/6235], Loss: 2.9403\n",
      "Epoch [43/100], Step [29800/6235], Loss: 0.4385\n",
      "Epoch [43/100], Step [29900/6235], Loss: 3.7513\n",
      "Epoch [43/100], Step [30000/6235], Loss: 1.8696\n",
      "Epoch [43/100], Step [30100/6235], Loss: 6.5859\n",
      "Epoch [43/100], Step [30200/6235], Loss: 1.8571\n",
      "Epoch [43/100], Step [30300/6235], Loss: 0.0571\n",
      "Epoch [43/100], Step [30400/6235], Loss: 2.7581\n",
      "Epoch [43/100], Step [30500/6235], Loss: 0.4027\n",
      "Epoch [43/100], Step [30600/6235], Loss: 1.0622\n",
      "Epoch [43/100], Step [30700/6235], Loss: 2.6859\n",
      "Epoch [43/100], Step [30800/6235], Loss: 0.4839\n",
      "Epoch [43/100], Step [30900/6235], Loss: 1.4141\n",
      "Epoch [43/100], Step [31000/6235], Loss: 0.2922\n",
      "Epoch [43/100], Step [31100/6235], Loss: 0.5915\n",
      "Epoch [43/100], Step [31200/6235], Loss: 3.7402\n",
      "Epoch [43/100], Step [31300/6235], Loss: 1.9551\n",
      "Epoch [43/100], Step [31400/6235], Loss: 5.4075\n",
      "Epoch [43/100], Step [31500/6235], Loss: 0.7740\n",
      "Epoch [43/100], Step [31600/6235], Loss: 5.8352\n",
      "Epoch [43/100], Step [31700/6235], Loss: 25.3302\n",
      "Epoch [43/100], Step [31800/6235], Loss: 1.8644\n",
      "Epoch [43/100], Step [31900/6235], Loss: 141.0646\n",
      "Epoch [43/100], Step [32000/6235], Loss: 0.2644\n",
      "Epoch [43/100], Step [32100/6235], Loss: 0.1259\n",
      "Epoch [43/100], Step [32200/6235], Loss: 115.0565\n",
      "Epoch [43/100], Step [32300/6235], Loss: 2.2286\n",
      "Epoch [43/100], Step [32400/6235], Loss: 1.5107\n",
      "Epoch [43/100], Step [32500/6235], Loss: 11.9832\n",
      "Epoch [43/100], Step [32600/6235], Loss: 0.3547\n",
      "Epoch [43/100], Step [32700/6235], Loss: 150.8263\n",
      "Epoch [43/100], Step [32800/6235], Loss: 2.7505\n",
      "Epoch [43/100], Step [32900/6235], Loss: 0.3497\n",
      "Epoch [43/100], Step [33000/6235], Loss: 0.4910\n",
      "Epoch [43/100], Step [33100/6235], Loss: 0.7221\n",
      "Epoch [43/100], Step [33200/6235], Loss: 1.5421\n",
      "Epoch [43/100], Step [33300/6235], Loss: 4.8586\n",
      "Epoch [43/100], Step [33400/6235], Loss: 12.0815\n",
      "Epoch [43/100], Step [33500/6235], Loss: 0.3442\n",
      "Epoch [43/100], Step [33600/6235], Loss: 9.1579\n",
      "Epoch [43/100], Step [33700/6235], Loss: 10.8333\n",
      "Epoch [43/100], Step [33800/6235], Loss: 0.6393\n",
      "Epoch [43/100], Step [33900/6235], Loss: 27.9453\n",
      "Epoch [43/100], Step [34000/6235], Loss: 0.1775\n",
      "Epoch [43/100], Step [34100/6235], Loss: 0.8865\n",
      "Epoch [43/100], Step [34200/6235], Loss: 2.6004\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [43/100], Step [34300/6235], Loss: 1.4462\n",
      "Epoch [43/100], Step [34400/6235], Loss: 0.1211\n",
      "Epoch [43/100], Step [34500/6235], Loss: 47.2459\n",
      "Epoch [43/100], Step [34600/6235], Loss: 1.8505\n",
      "Epoch [43/100], Step [34700/6235], Loss: 9.9262\n",
      "Epoch [43/100], Step [34800/6235], Loss: 8.1169\n",
      "Epoch [43/100], Step [34900/6235], Loss: 62.8516\n",
      "Epoch [43/100], Step [35000/6235], Loss: 0.4385\n",
      "Epoch [43/100], Step [35100/6235], Loss: 0.4682\n",
      "Epoch [43/100], Step [35200/6235], Loss: 0.3957\n",
      "Epoch [43/100], Step [35300/6235], Loss: 3.0184\n",
      "Epoch [43/100], Step [35400/6235], Loss: 0.4893\n",
      "Epoch [43/100], Step [35500/6235], Loss: 0.5356\n",
      "Epoch [43/100], Step [35600/6235], Loss: 5.6055\n",
      "Epoch [43/100], Step [35700/6235], Loss: 4.4165\n",
      "Epoch [43/100], Step [35800/6235], Loss: 1.5681\n",
      "Epoch [43/100], Step [35900/6235], Loss: 1.1546\n",
      "Epoch [43/100], Step [36000/6235], Loss: 0.1100\n",
      "Epoch [43/100], Step [36100/6235], Loss: 0.1083\n",
      "Epoch [43/100], Step [36200/6235], Loss: 20.4331\n",
      "Epoch [43/100], Step [36300/6235], Loss: 0.8795\n",
      "Epoch [43/100], Step [36400/6235], Loss: 2.9613\n",
      "Epoch [43/100], Step [36500/6235], Loss: 7.6414\n",
      "Epoch [43/100], Step [36600/6235], Loss: 0.0916\n",
      "Epoch [43/100], Step [36700/6235], Loss: 0.5990\n",
      "Epoch [43/100], Step [36800/6235], Loss: 4.7412\n",
      "Epoch [43/100], Step [36900/6235], Loss: 6.9038\n",
      "Epoch [43/100], Step [37000/6235], Loss: 0.9405\n",
      "Epoch [43/100], Step [37100/6235], Loss: 1.9694\n",
      "Epoch [43/100], Step [37200/6235], Loss: 0.0416\n",
      "Epoch [43/100], Step [37300/6235], Loss: 0.0500\n",
      "Epoch [43/100], Step [37400/6235], Loss: 0.1694\n",
      "Epoch [43/100], Step [37500/6235], Loss: 7.2007\n",
      "Epoch [43/100], Step [37600/6235], Loss: 12.2276\n",
      "Epoch [43/100], Step [37700/6235], Loss: 1.4715\n",
      "Epoch [43/100], Step [37800/6235], Loss: 3.4566\n",
      "Epoch [43/100], Step [37900/6235], Loss: 5.4400\n",
      "Epoch [43/100], Step [38000/6235], Loss: 0.8442\n",
      "Epoch [43/100], Step [38100/6235], Loss: 4.5216\n",
      "Epoch [43/100], Step [38200/6235], Loss: 1.3845\n",
      "Epoch [43/100], Step [38300/6235], Loss: 0.2030\n",
      "Epoch [43/100], Step [38400/6235], Loss: 0.0654\n",
      "Epoch [43/100], Step [38500/6235], Loss: 1.3919\n",
      "Epoch [43/100], Step [38600/6235], Loss: 0.4593\n",
      "Epoch [43/100], Step [38700/6235], Loss: 0.4584\n",
      "Epoch [43/100], Step [38800/6235], Loss: 0.1255\n",
      "Epoch [43/100], Step [38900/6235], Loss: 7.6698\n",
      "Epoch [43/100], Step [39000/6235], Loss: 2.0883\n",
      "Epoch [43/100], Step [39100/6235], Loss: 12.1729\n",
      "Epoch [43/100], Step [39200/6235], Loss: 0.2075\n",
      "Epoch [43/100], Step [39300/6235], Loss: 35.5045\n",
      "Epoch [43/100], Step [39400/6235], Loss: 47.5889\n",
      "Epoch [43/100], Step [39500/6235], Loss: 326.1957\n",
      "Epoch [43/100], Step [39600/6235], Loss: 19.2573\n",
      "Epoch [43/100], Step [39700/6235], Loss: 126.4631\n",
      "Epoch [43/100], Step [39800/6235], Loss: 12.6586\n",
      "Epoch [43/100], Step [39900/6235], Loss: 2.4298\n",
      "Epoch [43/100], Step [40000/6235], Loss: 9.0907\n",
      "Epoch [43/100], Step [40100/6235], Loss: 21.6670\n",
      "Epoch [43/100], Step [40200/6235], Loss: 0.8742\n",
      "Epoch [43/100], Step [40300/6235], Loss: 1.1613\n",
      "Epoch [43/100], Step [40400/6235], Loss: 1.9167\n",
      "Epoch [43/100], Step [40500/6235], Loss: 2.5107\n",
      "Epoch [43/100], Step [40600/6235], Loss: 0.2466\n",
      "Epoch [43/100], Step [40700/6235], Loss: 7.4942\n",
      "Epoch [43/100], Step [40800/6235], Loss: 1.0514\n",
      "Epoch [43/100], Step [40900/6235], Loss: 0.2366\n",
      "Epoch [43/100], Step [41000/6235], Loss: 47.2546\n",
      "Epoch [43/100], Step [41100/6235], Loss: 36.9748\n",
      "Epoch [43/100], Step [41200/6235], Loss: 4.7081\n",
      "Epoch [43/100], Step [41300/6235], Loss: 4.4359\n",
      "Epoch [43/100], Step [41400/6235], Loss: 0.5918\n",
      "Epoch [43/100], Step [41500/6235], Loss: 0.7291\n",
      "Epoch [43/100], Step [41600/6235], Loss: 0.4751\n",
      "Epoch [43/100], Step [41700/6235], Loss: 1.8430\n",
      "Epoch [43/100], Step [41800/6235], Loss: 3.5522\n",
      "Epoch [43/100], Step [41900/6235], Loss: 3.5409\n",
      "Epoch [43/100], Step [42000/6235], Loss: 2.9021\n",
      "Epoch [43/100], Step [42100/6235], Loss: 6.5887\n",
      "Epoch [43/100], Step [42200/6235], Loss: 7.4327\n",
      "Epoch [43/100], Step [42300/6235], Loss: 0.7739\n",
      "Epoch [43/100], Step [42400/6235], Loss: 2.5070\n",
      "Epoch [43/100], Step [42500/6235], Loss: 2.8805\n",
      "Epoch [43/100], Step [42600/6235], Loss: 0.4770\n",
      "Epoch [43/100], Step [42700/6235], Loss: 0.1873\n",
      "Epoch [43/100], Step [42800/6235], Loss: 0.7778\n",
      "Epoch [43/100], Step [42900/6235], Loss: 4.2610\n",
      "Epoch [43/100], Step [43000/6235], Loss: 0.2107\n",
      "Epoch [43/100], Step [43100/6235], Loss: 1.1326\n",
      "Epoch [43/100], Step [43200/6235], Loss: 0.6819\n",
      "Epoch [43/100], Step [43300/6235], Loss: 9.6616\n",
      "Epoch [43/100], Step [43400/6235], Loss: 9.2093\n",
      "Epoch [43/100], Step [43500/6235], Loss: 8.9129\n",
      "Epoch [43/100], Step [43600/6235], Loss: 25.2383\n",
      "Epoch [43/100], Step [43700/6235], Loss: 40.2637\n",
      "Epoch [43/100], Step [43800/6235], Loss: 0.5212\n",
      "Epoch [43/100], Step [43900/6235], Loss: 0.9085\n",
      "Epoch [43/100], Step [44000/6235], Loss: 60.3384\n",
      "Epoch [43/100], Step [44100/6235], Loss: 2.1476\n",
      "Epoch [43/100], Step [44200/6235], Loss: 8.4330\n",
      "Epoch [43/100], Step [44300/6235], Loss: 38.7489\n",
      "Epoch [43/100], Step [44400/6235], Loss: 1.2311\n",
      "Epoch [43/100], Step [44500/6235], Loss: 3.1318\n",
      "Epoch [43/100], Step [44600/6235], Loss: 21.9451\n",
      "Epoch [43/100], Step [44700/6235], Loss: 3.6718\n",
      "Epoch [43/100], Step [44800/6235], Loss: 3.4673\n",
      "Epoch [43/100], Step [44900/6235], Loss: 2.1294\n",
      "Epoch [43/100], Step [45000/6235], Loss: 5.1654\n",
      "Epoch [43/100], Step [45100/6235], Loss: 42.9481\n",
      "Epoch [43/100], Step [45200/6235], Loss: 0.1896\n",
      "Epoch [43/100], Step [45300/6235], Loss: 41.5068\n",
      "Epoch [43/100], Step [45400/6235], Loss: 10.4950\n",
      "Epoch [43/100], Step [45500/6235], Loss: 0.1360\n",
      "Epoch [43/100], Step [45600/6235], Loss: 0.2068\n",
      "Epoch [43/100], Step [45700/6235], Loss: 47.3797\n",
      "Epoch [43/100], Step [45800/6235], Loss: 325.9474\n",
      "Epoch [43/100], Step [45900/6235], Loss: 30.9348\n",
      "Epoch [43/100], Step [46000/6235], Loss: 23.0285\n",
      "Epoch [43/100], Step [46100/6235], Loss: 12.2846\n",
      "Epoch [43/100], Step [46200/6235], Loss: 79.3895\n",
      "Epoch [43/100], Step [46300/6235], Loss: 51.1400\n",
      "Epoch [43/100], Step [46400/6235], Loss: 3.1051\n",
      "Epoch [43/100], Step [46500/6235], Loss: 1.3953\n",
      "Epoch [43/100], Step [46600/6235], Loss: 20.3139\n",
      "Epoch [43/100], Step [46700/6235], Loss: 7.7800\n",
      "Epoch [43/100], Step [46800/6235], Loss: 29.1702\n",
      "Epoch [43/100], Step [46900/6235], Loss: 20.7568\n",
      "Epoch [43/100], Step [47000/6235], Loss: 0.6302\n",
      "Epoch [43/100], Step [47100/6235], Loss: 53.6052\n",
      "Epoch [43/100], Step [47200/6235], Loss: 77.1780\n",
      "Epoch [43/100], Step [47300/6235], Loss: 0.8112\n",
      "Epoch [43/100], Step [47400/6235], Loss: 196.9297\n",
      "Epoch [43/100], Step [47500/6235], Loss: 3.1926\n",
      "Epoch [43/100], Step [47600/6235], Loss: 11.8235\n",
      "Epoch [43/100], Step [47700/6235], Loss: 8.6601\n",
      "Epoch [43/100], Step [47800/6235], Loss: 11.5551\n",
      "Epoch [43/100], Step [47900/6235], Loss: 19.0813\n",
      "Epoch [43/100], Step [48000/6235], Loss: 21.1336\n",
      "Epoch [43/100], Step [48100/6235], Loss: 5.2622\n",
      "Epoch [43/100], Step [48200/6235], Loss: 8.7595\n",
      "Epoch [43/100], Step [48300/6235], Loss: 466.5432\n",
      "Epoch [43/100], Step [48400/6235], Loss: 15.8547\n",
      "Epoch [43/100], Step [48500/6235], Loss: 38.3742\n",
      "Epoch [43/100], Step [48600/6235], Loss: 136.6302\n",
      "Epoch [43/100], Step [48700/6235], Loss: 1.4504\n",
      "Epoch [43/100], Step [48800/6235], Loss: 268.8733\n",
      "Epoch [43/100], Step [48900/6235], Loss: 594.1159\n",
      "Epoch [43/100], Step [49000/6235], Loss: 200.1385\n",
      "Epoch [43/100], Step [49100/6235], Loss: 3251.1533\n",
      "Epoch [43/100], Step [49200/6235], Loss: 786.3056\n",
      "Epoch [43/100], Step [49300/6235], Loss: 1113.3745\n",
      "Epoch [43/100], Step [49400/6235], Loss: 19.7102\n",
      "Epoch [43/100], Step [49500/6235], Loss: 6.0232\n",
      "Epoch [43/100], Step [49600/6235], Loss: 357.8474\n",
      "Epoch [43/100], Step [49700/6235], Loss: 1792.8429\n",
      "Epoch [43/100], Step [49800/6235], Loss: 1156.7534\n",
      "Epoch [44/100], Step [100/6235], Loss: 25.4160\n",
      "Epoch [44/100], Step [200/6235], Loss: 0.1649\n",
      "Epoch [44/100], Step [300/6235], Loss: 0.0143\n",
      "Epoch [44/100], Step [400/6235], Loss: 0.0083\n",
      "Epoch [44/100], Step [500/6235], Loss: 4.1416\n",
      "Epoch [44/100], Step [600/6235], Loss: 0.0424\n",
      "Epoch [44/100], Step [700/6235], Loss: 0.5024\n",
      "Epoch [44/100], Step [800/6235], Loss: 0.1463\n",
      "Epoch [44/100], Step [900/6235], Loss: 0.1208\n",
      "Epoch [44/100], Step [1000/6235], Loss: 0.0384\n",
      "Epoch [44/100], Step [1100/6235], Loss: 0.2288\n",
      "Epoch [44/100], Step [1200/6235], Loss: 0.1826\n",
      "Epoch [44/100], Step [1300/6235], Loss: 0.0704\n",
      "Epoch [44/100], Step [1400/6235], Loss: 0.2749\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Step [1500/6235], Loss: 0.0058\n",
      "Epoch [44/100], Step [1600/6235], Loss: 0.2419\n",
      "Epoch [44/100], Step [1700/6235], Loss: 0.0236\n",
      "Epoch [44/100], Step [1800/6235], Loss: 0.2031\n",
      "Epoch [44/100], Step [1900/6235], Loss: 0.5448\n",
      "Epoch [44/100], Step [2000/6235], Loss: 2.2466\n",
      "Epoch [44/100], Step [2100/6235], Loss: 3.6926\n",
      "Epoch [44/100], Step [2200/6235], Loss: 9.3202\n",
      "Epoch [44/100], Step [2300/6235], Loss: 11.7172\n",
      "Epoch [44/100], Step [2400/6235], Loss: 4.5094\n",
      "Epoch [44/100], Step [2500/6235], Loss: 38.1302\n",
      "Epoch [44/100], Step [2600/6235], Loss: 11.0497\n",
      "Epoch [44/100], Step [2700/6235], Loss: 18.1058\n",
      "Epoch [44/100], Step [2800/6235], Loss: 122.6979\n",
      "Epoch [44/100], Step [2900/6235], Loss: 9.8713\n",
      "Epoch [44/100], Step [3000/6235], Loss: 0.5587\n",
      "Epoch [44/100], Step [3100/6235], Loss: 68.4055\n",
      "Epoch [44/100], Step [3200/6235], Loss: 84.6682\n",
      "Epoch [44/100], Step [3300/6235], Loss: 5.3392\n",
      "Epoch [44/100], Step [3400/6235], Loss: 2.0414\n",
      "Epoch [44/100], Step [3500/6235], Loss: 34.4458\n",
      "Epoch [44/100], Step [3600/6235], Loss: 9.9347\n",
      "Epoch [44/100], Step [3700/6235], Loss: 0.2262\n",
      "Epoch [44/100], Step [3800/6235], Loss: 0.4825\n",
      "Epoch [44/100], Step [3900/6235], Loss: 1.2941\n",
      "Epoch [44/100], Step [4000/6235], Loss: 0.0178\n",
      "Epoch [44/100], Step [4100/6235], Loss: 6.3751\n",
      "Epoch [44/100], Step [4200/6235], Loss: 0.4159\n",
      "Epoch [44/100], Step [4300/6235], Loss: 9.8377\n",
      "Epoch [44/100], Step [4400/6235], Loss: 4.1249\n",
      "Epoch [44/100], Step [4500/6235], Loss: 46.3105\n",
      "Epoch [44/100], Step [4600/6235], Loss: 6.2434\n",
      "Epoch [44/100], Step [4700/6235], Loss: 0.2820\n",
      "Epoch [44/100], Step [4800/6235], Loss: 8.2893\n",
      "Epoch [44/100], Step [4900/6235], Loss: 0.2210\n",
      "Epoch [44/100], Step [5000/6235], Loss: 0.0661\n",
      "Epoch [44/100], Step [5100/6235], Loss: 6.5974\n",
      "Epoch [44/100], Step [5200/6235], Loss: 5.4224\n",
      "Epoch [44/100], Step [5300/6235], Loss: 39.2502\n",
      "Epoch [44/100], Step [5400/6235], Loss: 2.1718\n",
      "Epoch [44/100], Step [5500/6235], Loss: 0.2941\n",
      "Epoch [44/100], Step [5600/6235], Loss: 0.3351\n",
      "Epoch [44/100], Step [5700/6235], Loss: 0.3598\n",
      "Epoch [44/100], Step [5800/6235], Loss: 0.4213\n",
      "Epoch [44/100], Step [5900/6235], Loss: 0.4289\n",
      "Epoch [44/100], Step [6000/6235], Loss: 3.0833\n",
      "Epoch [44/100], Step [6100/6235], Loss: 0.2342\n",
      "Epoch [44/100], Step [6200/6235], Loss: 2.1181\n",
      "Epoch [44/100], Step [6300/6235], Loss: 2.1891\n",
      "Epoch [44/100], Step [6400/6235], Loss: 0.0184\n",
      "Epoch [44/100], Step [6500/6235], Loss: 1.7508\n",
      "Epoch [44/100], Step [6600/6235], Loss: 3.7017\n",
      "Epoch [44/100], Step [6700/6235], Loss: 3.1952\n",
      "Epoch [44/100], Step [6800/6235], Loss: 0.3245\n",
      "Epoch [44/100], Step [6900/6235], Loss: 1.1240\n",
      "Epoch [44/100], Step [7000/6235], Loss: 0.3995\n",
      "Epoch [44/100], Step [7100/6235], Loss: 0.2522\n",
      "Epoch [44/100], Step [7200/6235], Loss: 0.1386\n",
      "Epoch [44/100], Step [7300/6235], Loss: 1.0064\n",
      "Epoch [44/100], Step [7400/6235], Loss: 0.2632\n",
      "Epoch [44/100], Step [7500/6235], Loss: 0.4440\n",
      "Epoch [44/100], Step [7600/6235], Loss: 1.1812\n",
      "Epoch [44/100], Step [7700/6235], Loss: 19.2713\n",
      "Epoch [44/100], Step [7800/6235], Loss: 7.1949\n",
      "Epoch [44/100], Step [7900/6235], Loss: 13.2614\n",
      "Epoch [44/100], Step [8000/6235], Loss: 0.2122\n",
      "Epoch [44/100], Step [8100/6235], Loss: 4.5555\n",
      "Epoch [44/100], Step [8200/6235], Loss: 14.8871\n",
      "Epoch [44/100], Step [8300/6235], Loss: 40.1655\n",
      "Epoch [44/100], Step [8400/6235], Loss: 256.7517\n",
      "Epoch [44/100], Step [8500/6235], Loss: 2.3688\n",
      "Epoch [44/100], Step [8600/6235], Loss: 108.7805\n",
      "Epoch [44/100], Step [8700/6235], Loss: 40.2133\n",
      "Epoch [44/100], Step [8800/6235], Loss: 538.0112\n",
      "Epoch [44/100], Step [8900/6235], Loss: 317.1039\n",
      "Epoch [44/100], Step [9000/6235], Loss: 152.9563\n",
      "Epoch [44/100], Step [9100/6235], Loss: 1495.3291\n",
      "Epoch [44/100], Step [9200/6235], Loss: 2875.7908\n",
      "Epoch [44/100], Step [9300/6235], Loss: 55.4822\n",
      "Epoch [44/100], Step [9400/6235], Loss: 95.7100\n",
      "Epoch [44/100], Step [9500/6235], Loss: 2622.7585\n",
      "Epoch [44/100], Step [9600/6235], Loss: 715.9825\n",
      "Epoch [44/100], Step [9700/6235], Loss: 8.9943\n",
      "Epoch [44/100], Step [9800/6235], Loss: 3921.5588\n",
      "Epoch [44/100], Step [9900/6235], Loss: 153.0946\n",
      "Epoch [44/100], Step [10000/6235], Loss: 249.7323\n",
      "Epoch [44/100], Step [10100/6235], Loss: 4.9761\n",
      "Epoch [44/100], Step [10200/6235], Loss: 609.3992\n",
      "Epoch [44/100], Step [10300/6235], Loss: 7.3318\n",
      "Epoch [44/100], Step [10400/6235], Loss: 0.5430\n",
      "Epoch [44/100], Step [10500/6235], Loss: 2.0627\n",
      "Epoch [44/100], Step [10600/6235], Loss: 18.9730\n",
      "Epoch [44/100], Step [10700/6235], Loss: 109.7814\n",
      "Epoch [44/100], Step [10800/6235], Loss: 3.5782\n",
      "Epoch [44/100], Step [10900/6235], Loss: 8.6349\n",
      "Epoch [44/100], Step [11000/6235], Loss: 230.6437\n",
      "Epoch [44/100], Step [11100/6235], Loss: 7.3300\n",
      "Epoch [44/100], Step [11200/6235], Loss: 98.4327\n",
      "Epoch [44/100], Step [11300/6235], Loss: 224.2318\n",
      "Epoch [44/100], Step [11400/6235], Loss: 3.7293\n",
      "Epoch [44/100], Step [11500/6235], Loss: 0.6182\n",
      "Epoch [44/100], Step [11600/6235], Loss: 1.7586\n",
      "Epoch [44/100], Step [11700/6235], Loss: 47.0429\n",
      "Epoch [44/100], Step [11800/6235], Loss: 33.2144\n",
      "Epoch [44/100], Step [11900/6235], Loss: 16.3383\n",
      "Epoch [44/100], Step [12000/6235], Loss: 638.6877\n",
      "Epoch [44/100], Step [12100/6235], Loss: 227.5301\n",
      "Epoch [44/100], Step [12200/6235], Loss: 13.3686\n",
      "Epoch [44/100], Step [12300/6235], Loss: 16.3146\n",
      "Epoch [44/100], Step [12400/6235], Loss: 638.9951\n",
      "Epoch [44/100], Step [12500/6235], Loss: 15.3195\n",
      "Epoch [44/100], Step [12600/6235], Loss: 86.7938\n",
      "Epoch [44/100], Step [12700/6235], Loss: 4.5039\n",
      "Epoch [44/100], Step [12800/6235], Loss: 3.8212\n",
      "Epoch [44/100], Step [12900/6235], Loss: 43.5795\n",
      "Epoch [44/100], Step [13000/6235], Loss: 0.8844\n",
      "Epoch [44/100], Step [13100/6235], Loss: 71.3205\n",
      "Epoch [44/100], Step [13200/6235], Loss: 19.1107\n",
      "Epoch [44/100], Step [13300/6235], Loss: 61.1935\n",
      "Epoch [44/100], Step [13400/6235], Loss: 248.5204\n",
      "Epoch [44/100], Step [13500/6235], Loss: 6.3052\n",
      "Epoch [44/100], Step [13600/6235], Loss: 4.5162\n",
      "Epoch [44/100], Step [13700/6235], Loss: 123.9721\n",
      "Epoch [44/100], Step [13800/6235], Loss: 160.7650\n",
      "Epoch [44/100], Step [13900/6235], Loss: 14.9334\n",
      "Epoch [44/100], Step [14000/6235], Loss: 14.5291\n",
      "Epoch [44/100], Step [14100/6235], Loss: 2.5616\n",
      "Epoch [44/100], Step [14200/6235], Loss: 76.8398\n",
      "Epoch [44/100], Step [14300/6235], Loss: 67.1332\n",
      "Epoch [44/100], Step [14400/6235], Loss: 37.6445\n",
      "Epoch [44/100], Step [14500/6235], Loss: 76.3872\n",
      "Epoch [44/100], Step [14600/6235], Loss: 0.9469\n",
      "Epoch [44/100], Step [14700/6235], Loss: 43.2556\n",
      "Epoch [44/100], Step [14800/6235], Loss: 28.5155\n",
      "Epoch [44/100], Step [14900/6235], Loss: 3.3377\n",
      "Epoch [44/100], Step [15000/6235], Loss: 4.8286\n",
      "Epoch [44/100], Step [15100/6235], Loss: 0.0746\n",
      "Epoch [44/100], Step [15200/6235], Loss: 2.8750\n",
      "Epoch [44/100], Step [15300/6235], Loss: 5.5609\n",
      "Epoch [44/100], Step [15400/6235], Loss: 79.5597\n",
      "Epoch [44/100], Step [15500/6235], Loss: 9.5733\n",
      "Epoch [44/100], Step [15600/6235], Loss: 59.6076\n",
      "Epoch [44/100], Step [15700/6235], Loss: 146.7416\n",
      "Epoch [44/100], Step [15800/6235], Loss: 9.6737\n",
      "Epoch [44/100], Step [15900/6235], Loss: 0.4563\n",
      "Epoch [44/100], Step [16000/6235], Loss: 97.8623\n",
      "Epoch [44/100], Step [16100/6235], Loss: 22.9362\n",
      "Epoch [44/100], Step [16200/6235], Loss: 0.4649\n",
      "Epoch [44/100], Step [16300/6235], Loss: 12.5408\n",
      "Epoch [44/100], Step [16400/6235], Loss: 46.1321\n",
      "Epoch [44/100], Step [16500/6235], Loss: 548.7152\n",
      "Epoch [44/100], Step [16600/6235], Loss: 16.1861\n",
      "Epoch [44/100], Step [16700/6235], Loss: 0.5879\n",
      "Epoch [44/100], Step [16800/6235], Loss: 11.3881\n",
      "Epoch [44/100], Step [16900/6235], Loss: 0.1776\n",
      "Epoch [44/100], Step [17000/6235], Loss: 0.2914\n",
      "Epoch [44/100], Step [17100/6235], Loss: 0.6463\n",
      "Epoch [44/100], Step [17200/6235], Loss: 318.0606\n",
      "Epoch [44/100], Step [17300/6235], Loss: 42.0262\n",
      "Epoch [44/100], Step [17400/6235], Loss: 30.4413\n",
      "Epoch [44/100], Step [17500/6235], Loss: 1.3377\n",
      "Epoch [44/100], Step [17600/6235], Loss: 4.9984\n",
      "Epoch [44/100], Step [17700/6235], Loss: 0.5173\n",
      "Epoch [44/100], Step [17800/6235], Loss: 23.0795\n",
      "Epoch [44/100], Step [17900/6235], Loss: 4.2850\n",
      "Epoch [44/100], Step [18000/6235], Loss: 4.2547\n",
      "Epoch [44/100], Step [18100/6235], Loss: 17.0995\n",
      "Epoch [44/100], Step [18200/6235], Loss: 0.6647\n",
      "Epoch [44/100], Step [18300/6235], Loss: 0.7768\n",
      "Epoch [44/100], Step [18400/6235], Loss: 1.0361\n",
      "Epoch [44/100], Step [18500/6235], Loss: 25.5488\n",
      "Epoch [44/100], Step [18600/6235], Loss: 6.7741\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Step [18700/6235], Loss: 1.5647\n",
      "Epoch [44/100], Step [18800/6235], Loss: 124.9641\n",
      "Epoch [44/100], Step [18900/6235], Loss: 65.3776\n",
      "Epoch [44/100], Step [19000/6235], Loss: 4.1733\n",
      "Epoch [44/100], Step [19100/6235], Loss: 8.9456\n",
      "Epoch [44/100], Step [19200/6235], Loss: 3.4831\n",
      "Epoch [44/100], Step [19300/6235], Loss: 9.2316\n",
      "Epoch [44/100], Step [19400/6235], Loss: 243.7824\n",
      "Epoch [44/100], Step [19500/6235], Loss: 120.3029\n",
      "Epoch [44/100], Step [19600/6235], Loss: 102.4142\n",
      "Epoch [44/100], Step [19700/6235], Loss: 9.4826\n",
      "Epoch [44/100], Step [19800/6235], Loss: 1.6288\n",
      "Epoch [44/100], Step [19900/6235], Loss: 0.6838\n",
      "Epoch [44/100], Step [20000/6235], Loss: 97.5886\n",
      "Epoch [44/100], Step [20100/6235], Loss: 7.1196\n",
      "Epoch [44/100], Step [20200/6235], Loss: 3.0352\n",
      "Epoch [44/100], Step [20300/6235], Loss: 0.6354\n",
      "Epoch [44/100], Step [20400/6235], Loss: 27.4756\n",
      "Epoch [44/100], Step [20500/6235], Loss: 33.1288\n",
      "Epoch [44/100], Step [20600/6235], Loss: 80.9317\n",
      "Epoch [44/100], Step [20700/6235], Loss: 14.8098\n",
      "Epoch [44/100], Step [20800/6235], Loss: 0.7705\n",
      "Epoch [44/100], Step [20900/6235], Loss: 26.8042\n",
      "Epoch [44/100], Step [21000/6235], Loss: 24.1198\n",
      "Epoch [44/100], Step [21100/6235], Loss: 6.7901\n",
      "Epoch [44/100], Step [21200/6235], Loss: 0.2563\n",
      "Epoch [44/100], Step [21300/6235], Loss: 0.0880\n",
      "Epoch [44/100], Step [21400/6235], Loss: 4.5667\n",
      "Epoch [44/100], Step [21500/6235], Loss: 3.2660\n",
      "Epoch [44/100], Step [21600/6235], Loss: 13.3746\n",
      "Epoch [44/100], Step [21700/6235], Loss: 0.1492\n",
      "Epoch [44/100], Step [21800/6235], Loss: 4.7540\n",
      "Epoch [44/100], Step [21900/6235], Loss: 1.6099\n",
      "Epoch [44/100], Step [22000/6235], Loss: 9.1181\n",
      "Epoch [44/100], Step [22100/6235], Loss: 0.1807\n",
      "Epoch [44/100], Step [22200/6235], Loss: 3.9477\n",
      "Epoch [44/100], Step [22300/6235], Loss: 6.2668\n",
      "Epoch [44/100], Step [22400/6235], Loss: 0.5746\n",
      "Epoch [44/100], Step [22500/6235], Loss: 145.6261\n",
      "Epoch [44/100], Step [22600/6235], Loss: 4.8538\n",
      "Epoch [44/100], Step [22700/6235], Loss: 0.4306\n",
      "Epoch [44/100], Step [22800/6235], Loss: 4.1021\n",
      "Epoch [44/100], Step [22900/6235], Loss: 1.5051\n",
      "Epoch [44/100], Step [23000/6235], Loss: 8.7678\n",
      "Epoch [44/100], Step [23100/6235], Loss: 5.8887\n",
      "Epoch [44/100], Step [23200/6235], Loss: 12.0801\n",
      "Epoch [44/100], Step [23300/6235], Loss: 19.0520\n",
      "Epoch [44/100], Step [23400/6235], Loss: 2.5118\n",
      "Epoch [44/100], Step [23500/6235], Loss: 0.0715\n",
      "Epoch [44/100], Step [23600/6235], Loss: 134.7493\n",
      "Epoch [44/100], Step [23700/6235], Loss: 3.8292\n",
      "Epoch [44/100], Step [23800/6235], Loss: 0.9250\n",
      "Epoch [44/100], Step [23900/6235], Loss: 1.7761\n",
      "Epoch [44/100], Step [24000/6235], Loss: 1.6200\n",
      "Epoch [44/100], Step [24100/6235], Loss: 0.4954\n",
      "Epoch [44/100], Step [24200/6235], Loss: 32.1662\n",
      "Epoch [44/100], Step [24300/6235], Loss: 0.8026\n",
      "Epoch [44/100], Step [24400/6235], Loss: 2.0370\n",
      "Epoch [44/100], Step [24500/6235], Loss: 0.4421\n",
      "Epoch [44/100], Step [24600/6235], Loss: 0.5947\n",
      "Epoch [44/100], Step [24700/6235], Loss: 4.0461\n",
      "Epoch [44/100], Step [24800/6235], Loss: 0.3338\n",
      "Epoch [44/100], Step [24900/6235], Loss: 15.8338\n",
      "Epoch [44/100], Step [25000/6235], Loss: 13.9167\n",
      "Epoch [44/100], Step [25100/6235], Loss: 6.6883\n",
      "Epoch [44/100], Step [25200/6235], Loss: 0.1434\n",
      "Epoch [44/100], Step [25300/6235], Loss: 0.9722\n",
      "Epoch [44/100], Step [25400/6235], Loss: 9.1092\n",
      "Epoch [44/100], Step [25500/6235], Loss: 9.0764\n",
      "Epoch [44/100], Step [25600/6235], Loss: 7.5446\n",
      "Epoch [44/100], Step [25700/6235], Loss: 0.1232\n",
      "Epoch [44/100], Step [25800/6235], Loss: 0.1545\n",
      "Epoch [44/100], Step [25900/6235], Loss: 4.7446\n",
      "Epoch [44/100], Step [26000/6235], Loss: 0.7502\n",
      "Epoch [44/100], Step [26100/6235], Loss: 0.0378\n",
      "Epoch [44/100], Step [26200/6235], Loss: 1.4269\n",
      "Epoch [44/100], Step [26300/6235], Loss: 2.1735\n",
      "Epoch [44/100], Step [26400/6235], Loss: 0.3406\n",
      "Epoch [44/100], Step [26500/6235], Loss: 0.0394\n",
      "Epoch [44/100], Step [26600/6235], Loss: 0.4548\n",
      "Epoch [44/100], Step [26700/6235], Loss: 0.1828\n",
      "Epoch [44/100], Step [26800/6235], Loss: 0.0982\n",
      "Epoch [44/100], Step [26900/6235], Loss: 0.0372\n",
      "Epoch [44/100], Step [27000/6235], Loss: 16.2380\n",
      "Epoch [44/100], Step [27100/6235], Loss: 0.0557\n",
      "Epoch [44/100], Step [27200/6235], Loss: 0.0106\n",
      "Epoch [44/100], Step [27300/6235], Loss: 0.0653\n",
      "Epoch [44/100], Step [27400/6235], Loss: 0.6455\n",
      "Epoch [44/100], Step [27500/6235], Loss: 7.8573\n",
      "Epoch [44/100], Step [27600/6235], Loss: 0.3539\n",
      "Epoch [44/100], Step [27700/6235], Loss: 1.7602\n",
      "Epoch [44/100], Step [27800/6235], Loss: 5.8241\n",
      "Epoch [44/100], Step [27900/6235], Loss: 0.4535\n",
      "Epoch [44/100], Step [28000/6235], Loss: 109.7267\n",
      "Epoch [44/100], Step [28100/6235], Loss: 3.1773\n",
      "Epoch [44/100], Step [28200/6235], Loss: 33.6099\n",
      "Epoch [44/100], Step [28300/6235], Loss: 2.7383\n",
      "Epoch [44/100], Step [28400/6235], Loss: 17.9433\n",
      "Epoch [44/100], Step [28500/6235], Loss: 4.6302\n",
      "Epoch [44/100], Step [28600/6235], Loss: 0.7237\n",
      "Epoch [44/100], Step [28700/6235], Loss: 4.6002\n",
      "Epoch [44/100], Step [28800/6235], Loss: 0.6585\n",
      "Epoch [44/100], Step [28900/6235], Loss: 60.2705\n",
      "Epoch [44/100], Step [29000/6235], Loss: 13.8265\n",
      "Epoch [44/100], Step [29100/6235], Loss: 0.5400\n",
      "Epoch [44/100], Step [29200/6235], Loss: 3.1788\n",
      "Epoch [44/100], Step [29300/6235], Loss: 11.7007\n",
      "Epoch [44/100], Step [29400/6235], Loss: 0.0705\n",
      "Epoch [44/100], Step [29500/6235], Loss: 5.0477\n",
      "Epoch [44/100], Step [29600/6235], Loss: 0.0412\n",
      "Epoch [44/100], Step [29700/6235], Loss: 2.1311\n",
      "Epoch [44/100], Step [29800/6235], Loss: 1.2556\n",
      "Epoch [44/100], Step [29900/6235], Loss: 1.4203\n",
      "Epoch [44/100], Step [30000/6235], Loss: 5.8341\n",
      "Epoch [44/100], Step [30100/6235], Loss: 12.0545\n",
      "Epoch [44/100], Step [30200/6235], Loss: 1.5597\n",
      "Epoch [44/100], Step [30300/6235], Loss: 0.0597\n",
      "Epoch [44/100], Step [30400/6235], Loss: 1.5949\n",
      "Epoch [44/100], Step [30500/6235], Loss: 2.6321\n",
      "Epoch [44/100], Step [30600/6235], Loss: 1.9137\n",
      "Epoch [44/100], Step [30700/6235], Loss: 1.3149\n",
      "Epoch [44/100], Step [30800/6235], Loss: 0.5583\n",
      "Epoch [44/100], Step [30900/6235], Loss: 3.0497\n",
      "Epoch [44/100], Step [31000/6235], Loss: 0.2959\n",
      "Epoch [44/100], Step [31100/6235], Loss: 0.0525\n",
      "Epoch [44/100], Step [31200/6235], Loss: 6.8370\n",
      "Epoch [44/100], Step [31300/6235], Loss: 0.8903\n",
      "Epoch [44/100], Step [31400/6235], Loss: 0.7392\n",
      "Epoch [44/100], Step [31500/6235], Loss: 0.7174\n",
      "Epoch [44/100], Step [31600/6235], Loss: 16.8454\n",
      "Epoch [44/100], Step [31700/6235], Loss: 17.4658\n",
      "Epoch [44/100], Step [31800/6235], Loss: 0.7778\n",
      "Epoch [44/100], Step [31900/6235], Loss: 63.7185\n",
      "Epoch [44/100], Step [32000/6235], Loss: 78.5501\n",
      "Epoch [44/100], Step [32100/6235], Loss: 5.5719\n",
      "Epoch [44/100], Step [32200/6235], Loss: 73.7557\n",
      "Epoch [44/100], Step [32300/6235], Loss: 2.0860\n",
      "Epoch [44/100], Step [32400/6235], Loss: 0.9833\n",
      "Epoch [44/100], Step [32500/6235], Loss: 17.9602\n",
      "Epoch [44/100], Step [32600/6235], Loss: 0.5582\n",
      "Epoch [44/100], Step [32700/6235], Loss: 104.6091\n",
      "Epoch [44/100], Step [32800/6235], Loss: 24.7297\n",
      "Epoch [44/100], Step [32900/6235], Loss: 18.3566\n",
      "Epoch [44/100], Step [33000/6235], Loss: 0.3650\n",
      "Epoch [44/100], Step [33100/6235], Loss: 0.7922\n",
      "Epoch [44/100], Step [33200/6235], Loss: 1.4648\n",
      "Epoch [44/100], Step [33300/6235], Loss: 5.1462\n",
      "Epoch [44/100], Step [33400/6235], Loss: 96.8326\n",
      "Epoch [44/100], Step [33500/6235], Loss: 0.9823\n",
      "Epoch [44/100], Step [33600/6235], Loss: 0.7605\n",
      "Epoch [44/100], Step [33700/6235], Loss: 1.0821\n",
      "Epoch [44/100], Step [33800/6235], Loss: 0.4465\n",
      "Epoch [44/100], Step [33900/6235], Loss: 28.6419\n",
      "Epoch [44/100], Step [34000/6235], Loss: 0.0455\n",
      "Epoch [44/100], Step [34100/6235], Loss: 0.4479\n",
      "Epoch [44/100], Step [34200/6235], Loss: 2.6413\n",
      "Epoch [44/100], Step [34300/6235], Loss: 5.1287\n",
      "Epoch [44/100], Step [34400/6235], Loss: 0.2439\n",
      "Epoch [44/100], Step [34500/6235], Loss: 26.5200\n",
      "Epoch [44/100], Step [34600/6235], Loss: 1.0270\n",
      "Epoch [44/100], Step [34700/6235], Loss: 24.4446\n",
      "Epoch [44/100], Step [34800/6235], Loss: 9.7009\n",
      "Epoch [44/100], Step [34900/6235], Loss: 67.5229\n",
      "Epoch [44/100], Step [35000/6235], Loss: 0.2862\n",
      "Epoch [44/100], Step [35100/6235], Loss: 0.8427\n",
      "Epoch [44/100], Step [35200/6235], Loss: 0.2599\n",
      "Epoch [44/100], Step [35300/6235], Loss: 3.0377\n",
      "Epoch [44/100], Step [35400/6235], Loss: 0.5824\n",
      "Epoch [44/100], Step [35500/6235], Loss: 1.2455\n",
      "Epoch [44/100], Step [35600/6235], Loss: 3.6353\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [44/100], Step [35700/6235], Loss: 4.4999\n",
      "Epoch [44/100], Step [35800/6235], Loss: 1.0010\n",
      "Epoch [44/100], Step [35900/6235], Loss: 0.2535\n",
      "Epoch [44/100], Step [36000/6235], Loss: 0.0216\n",
      "Epoch [44/100], Step [36100/6235], Loss: 0.0646\n",
      "Epoch [44/100], Step [36200/6235], Loss: 24.9600\n",
      "Epoch [44/100], Step [36300/6235], Loss: 0.7979\n",
      "Epoch [44/100], Step [36400/6235], Loss: 3.0702\n",
      "Epoch [44/100], Step [36500/6235], Loss: 7.7284\n",
      "Epoch [44/100], Step [36600/6235], Loss: 0.1060\n",
      "Epoch [44/100], Step [36700/6235], Loss: 0.6173\n",
      "Epoch [44/100], Step [36800/6235], Loss: 5.5578\n",
      "Epoch [44/100], Step [36900/6235], Loss: 9.7049\n",
      "Epoch [44/100], Step [37000/6235], Loss: 0.9347\n",
      "Epoch [44/100], Step [37100/6235], Loss: 1.8324\n",
      "Epoch [44/100], Step [37200/6235], Loss: 0.0445\n",
      "Epoch [44/100], Step [37300/6235], Loss: 0.0359\n",
      "Epoch [44/100], Step [37400/6235], Loss: 0.1764\n",
      "Epoch [44/100], Step [37500/6235], Loss: 6.8606\n",
      "Epoch [44/100], Step [37600/6235], Loss: 12.2930\n",
      "Epoch [44/100], Step [37700/6235], Loss: 2.2421\n",
      "Epoch [44/100], Step [37800/6235], Loss: 6.8203\n",
      "Epoch [44/100], Step [37900/6235], Loss: 3.3894\n",
      "Epoch [44/100], Step [38000/6235], Loss: 0.6698\n",
      "Epoch [44/100], Step [38100/6235], Loss: 4.1575\n",
      "Epoch [44/100], Step [38200/6235], Loss: 1.7388\n",
      "Epoch [44/100], Step [38300/6235], Loss: 0.1511\n",
      "Epoch [44/100], Step [38400/6235], Loss: 0.0582\n",
      "Epoch [44/100], Step [38500/6235], Loss: 1.5035\n",
      "Epoch [44/100], Step [38600/6235], Loss: 0.3984\n",
      "Epoch [44/100], Step [38700/6235], Loss: 0.0880\n",
      "Epoch [44/100], Step [38800/6235], Loss: 0.1338\n",
      "Epoch [44/100], Step [38900/6235], Loss: 14.9995\n",
      "Epoch [44/100], Step [39000/6235], Loss: 15.1188\n",
      "Epoch [44/100], Step [39100/6235], Loss: 12.2083\n",
      "Epoch [44/100], Step [39200/6235], Loss: 0.3308\n",
      "Epoch [44/100], Step [39300/6235], Loss: 7.5418\n",
      "Epoch [44/100], Step [39400/6235], Loss: 330.6465\n",
      "Epoch [44/100], Step [39500/6235], Loss: 351.6566\n",
      "Epoch [44/100], Step [39600/6235], Loss: 32.6845\n",
      "Epoch [44/100], Step [39700/6235], Loss: 170.8219\n",
      "Epoch [44/100], Step [39800/6235], Loss: 159.3247\n",
      "Epoch [44/100], Step [39900/6235], Loss: 0.6494\n",
      "Epoch [44/100], Step [40000/6235], Loss: 0.6539\n",
      "Epoch [44/100], Step [40100/6235], Loss: 30.0983\n",
      "Epoch [44/100], Step [40200/6235], Loss: 12.5638\n",
      "Epoch [44/100], Step [40300/6235], Loss: 0.6932\n",
      "Epoch [44/100], Step [40400/6235], Loss: 2.5639\n",
      "Epoch [44/100], Step [40500/6235], Loss: 1.6214\n",
      "Epoch [44/100], Step [40600/6235], Loss: 0.8834\n",
      "Epoch [44/100], Step [40700/6235], Loss: 7.3495\n",
      "Epoch [44/100], Step [40800/6235], Loss: 2.8737\n",
      "Epoch [44/100], Step [40900/6235], Loss: 0.2812\n",
      "Epoch [44/100], Step [41000/6235], Loss: 30.3852\n",
      "Epoch [44/100], Step [41100/6235], Loss: 38.6148\n",
      "Epoch [44/100], Step [41200/6235], Loss: 3.9067\n",
      "Epoch [44/100], Step [41300/6235], Loss: 4.4663\n",
      "Epoch [44/100], Step [41400/6235], Loss: 2.5630\n",
      "Epoch [44/100], Step [41500/6235], Loss: 1.2917\n",
      "Epoch [44/100], Step [41600/6235], Loss: 1.7022\n",
      "Epoch [44/100], Step [41700/6235], Loss: 4.1073\n",
      "Epoch [44/100], Step [41800/6235], Loss: 0.3491\n",
      "Epoch [44/100], Step [41900/6235], Loss: 0.1428\n",
      "Epoch [44/100], Step [42000/6235], Loss: 2.4491\n",
      "Epoch [44/100], Step [42100/6235], Loss: 2.5207\n",
      "Epoch [44/100], Step [42200/6235], Loss: 23.4746\n",
      "Epoch [44/100], Step [42300/6235], Loss: 0.6966\n",
      "Epoch [44/100], Step [42400/6235], Loss: 3.9338\n",
      "Epoch [44/100], Step [42500/6235], Loss: 5.1860\n",
      "Epoch [44/100], Step [42600/6235], Loss: 0.4704\n",
      "Epoch [44/100], Step [42700/6235], Loss: 0.1514\n",
      "Epoch [44/100], Step [42800/6235], Loss: 0.2064\n",
      "Epoch [44/100], Step [42900/6235], Loss: 4.1128\n",
      "Epoch [44/100], Step [43000/6235], Loss: 0.3879\n",
      "Epoch [44/100], Step [43100/6235], Loss: 2.3079\n",
      "Epoch [44/100], Step [43200/6235], Loss: 0.3408\n",
      "Epoch [44/100], Step [43300/6235], Loss: 11.7437\n",
      "Epoch [44/100], Step [43400/6235], Loss: 6.2691\n",
      "Epoch [44/100], Step [43500/6235], Loss: 5.5807\n",
      "Epoch [44/100], Step [43600/6235], Loss: 41.3387\n",
      "Epoch [44/100], Step [43700/6235], Loss: 20.0009\n",
      "Epoch [44/100], Step [43800/6235], Loss: 1.4948\n",
      "Epoch [44/100], Step [43900/6235], Loss: 1.2269\n",
      "Epoch [44/100], Step [44000/6235], Loss: 60.1885\n",
      "Epoch [44/100], Step [44100/6235], Loss: 0.2465\n",
      "Epoch [44/100], Step [44200/6235], Loss: 21.0760\n",
      "Epoch [44/100], Step [44300/6235], Loss: 39.6409\n",
      "Epoch [44/100], Step [44400/6235], Loss: 4.4356\n",
      "Epoch [44/100], Step [44500/6235], Loss: 3.4654\n",
      "Epoch [44/100], Step [44600/6235], Loss: 17.3834\n",
      "Epoch [44/100], Step [44700/6235], Loss: 2.9410\n",
      "Epoch [44/100], Step [44800/6235], Loss: 0.4897\n",
      "Epoch [44/100], Step [44900/6235], Loss: 0.8279\n",
      "Epoch [44/100], Step [45000/6235], Loss: 2.5179\n",
      "Epoch [44/100], Step [45100/6235], Loss: 21.8987\n",
      "Epoch [44/100], Step [45200/6235], Loss: 0.5024\n",
      "Epoch [44/100], Step [45300/6235], Loss: 21.7199\n",
      "Epoch [44/100], Step [45400/6235], Loss: 5.9510\n",
      "Epoch [44/100], Step [45500/6235], Loss: 0.1373\n",
      "Epoch [44/100], Step [45600/6235], Loss: 0.9540\n",
      "Epoch [44/100], Step [45700/6235], Loss: 3.7955\n",
      "Epoch [44/100], Step [45800/6235], Loss: 317.7464\n",
      "Epoch [44/100], Step [45900/6235], Loss: 4.5017\n",
      "Epoch [44/100], Step [46000/6235], Loss: 34.8016\n",
      "Epoch [44/100], Step [46100/6235], Loss: 16.4598\n",
      "Epoch [44/100], Step [46200/6235], Loss: 10.8148\n",
      "Epoch [44/100], Step [46300/6235], Loss: 20.3341\n",
      "Epoch [44/100], Step [46400/6235], Loss: 1.5808\n",
      "Epoch [44/100], Step [46500/6235], Loss: 22.4917\n",
      "Epoch [44/100], Step [46600/6235], Loss: 26.9390\n",
      "Epoch [44/100], Step [46700/6235], Loss: 1.6297\n",
      "Epoch [44/100], Step [46800/6235], Loss: 20.4290\n",
      "Epoch [44/100], Step [46900/6235], Loss: 22.4780\n",
      "Epoch [44/100], Step [47000/6235], Loss: 0.5659\n",
      "Epoch [44/100], Step [47100/6235], Loss: 47.2405\n",
      "Epoch [44/100], Step [47200/6235], Loss: 50.5037\n",
      "Epoch [44/100], Step [47300/6235], Loss: 0.7614\n",
      "Epoch [44/100], Step [47400/6235], Loss: 88.2245\n",
      "Epoch [44/100], Step [47500/6235], Loss: 2.9123\n",
      "Epoch [44/100], Step [47600/6235], Loss: 13.5857\n",
      "Epoch [44/100], Step [47700/6235], Loss: 10.0467\n",
      "Epoch [44/100], Step [47800/6235], Loss: 13.4264\n",
      "Epoch [44/100], Step [47900/6235], Loss: 18.7632\n",
      "Epoch [44/100], Step [48000/6235], Loss: 35.9295\n",
      "Epoch [44/100], Step [48100/6235], Loss: 4.5364\n",
      "Epoch [44/100], Step [48200/6235], Loss: 10.7009\n",
      "Epoch [44/100], Step [48300/6235], Loss: 415.1782\n",
      "Epoch [44/100], Step [48400/6235], Loss: 15.5821\n",
      "Epoch [44/100], Step [48500/6235], Loss: 40.9455\n",
      "Epoch [44/100], Step [48600/6235], Loss: 129.4361\n",
      "Epoch [44/100], Step [48700/6235], Loss: 1.0056\n",
      "Epoch [44/100], Step [48800/6235], Loss: 346.4286\n",
      "Epoch [44/100], Step [48900/6235], Loss: 33.0949\n",
      "Epoch [44/100], Step [49000/6235], Loss: 233.2960\n",
      "Epoch [44/100], Step [49100/6235], Loss: 1925.8079\n",
      "Epoch [44/100], Step [49200/6235], Loss: 1597.2050\n",
      "Epoch [44/100], Step [49300/6235], Loss: 1216.0454\n",
      "Epoch [44/100], Step [49400/6235], Loss: 381.2344\n",
      "Epoch [44/100], Step [49500/6235], Loss: 14.4695\n",
      "Epoch [44/100], Step [49600/6235], Loss: 69.1476\n",
      "Epoch [44/100], Step [49700/6235], Loss: 11363.5098\n",
      "Epoch [44/100], Step [49800/6235], Loss: 235.7177\n",
      "Epoch [45/100], Step [100/6235], Loss: 20.1835\n",
      "Epoch [45/100], Step [200/6235], Loss: 0.2176\n",
      "Epoch [45/100], Step [300/6235], Loss: 0.0260\n",
      "Epoch [45/100], Step [400/6235], Loss: 0.0036\n",
      "Epoch [45/100], Step [500/6235], Loss: 2.9081\n",
      "Epoch [45/100], Step [600/6235], Loss: 0.0519\n",
      "Epoch [45/100], Step [700/6235], Loss: 0.5108\n",
      "Epoch [45/100], Step [800/6235], Loss: 0.0316\n",
      "Epoch [45/100], Step [900/6235], Loss: 0.1222\n",
      "Epoch [45/100], Step [1000/6235], Loss: 0.0175\n",
      "Epoch [45/100], Step [1100/6235], Loss: 0.0711\n",
      "Epoch [45/100], Step [1200/6235], Loss: 0.1429\n",
      "Epoch [45/100], Step [1300/6235], Loss: 0.0261\n",
      "Epoch [45/100], Step [1400/6235], Loss: 0.4648\n",
      "Epoch [45/100], Step [1500/6235], Loss: 0.0074\n",
      "Epoch [45/100], Step [1600/6235], Loss: 0.2588\n",
      "Epoch [45/100], Step [1700/6235], Loss: 0.3040\n",
      "Epoch [45/100], Step [1800/6235], Loss: 0.4760\n",
      "Epoch [45/100], Step [1900/6235], Loss: 0.2474\n",
      "Epoch [45/100], Step [2000/6235], Loss: 2.1720\n",
      "Epoch [45/100], Step [2100/6235], Loss: 6.7832\n",
      "Epoch [45/100], Step [2200/6235], Loss: 2.6091\n",
      "Epoch [45/100], Step [2300/6235], Loss: 2.2162\n",
      "Epoch [45/100], Step [2400/6235], Loss: 9.5971\n",
      "Epoch [45/100], Step [2500/6235], Loss: 2.0907\n",
      "Epoch [45/100], Step [2600/6235], Loss: 15.6404\n",
      "Epoch [45/100], Step [2700/6235], Loss: 22.4709\n",
      "Epoch [45/100], Step [2800/6235], Loss: 17.2672\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Step [2900/6235], Loss: 6.3691\n",
      "Epoch [45/100], Step [3000/6235], Loss: 3.2123\n",
      "Epoch [45/100], Step [3100/6235], Loss: 104.1933\n",
      "Epoch [45/100], Step [3200/6235], Loss: 7.5451\n",
      "Epoch [45/100], Step [3300/6235], Loss: 0.3803\n",
      "Epoch [45/100], Step [3400/6235], Loss: 7.4475\n",
      "Epoch [45/100], Step [3500/6235], Loss: 68.8354\n",
      "Epoch [45/100], Step [3600/6235], Loss: 2.3521\n",
      "Epoch [45/100], Step [3700/6235], Loss: 0.1525\n",
      "Epoch [45/100], Step [3800/6235], Loss: 0.2526\n",
      "Epoch [45/100], Step [3900/6235], Loss: 0.1852\n",
      "Epoch [45/100], Step [4000/6235], Loss: 0.5042\n",
      "Epoch [45/100], Step [4100/6235], Loss: 6.8086\n",
      "Epoch [45/100], Step [4200/6235], Loss: 2.0278\n",
      "Epoch [45/100], Step [4300/6235], Loss: 3.6929\n",
      "Epoch [45/100], Step [4400/6235], Loss: 0.0161\n",
      "Epoch [45/100], Step [4500/6235], Loss: 56.7051\n",
      "Epoch [45/100], Step [4600/6235], Loss: 15.5006\n",
      "Epoch [45/100], Step [4700/6235], Loss: 1.0288\n",
      "Epoch [45/100], Step [4800/6235], Loss: 1.7736\n",
      "Epoch [45/100], Step [4900/6235], Loss: 1.8764\n",
      "Epoch [45/100], Step [5000/6235], Loss: 0.1182\n",
      "Epoch [45/100], Step [5100/6235], Loss: 6.6957\n",
      "Epoch [45/100], Step [5200/6235], Loss: 2.2321\n",
      "Epoch [45/100], Step [5300/6235], Loss: 13.4886\n",
      "Epoch [45/100], Step [5400/6235], Loss: 3.4240\n",
      "Epoch [45/100], Step [5500/6235], Loss: 0.8661\n",
      "Epoch [45/100], Step [5600/6235], Loss: 0.5142\n",
      "Epoch [45/100], Step [5700/6235], Loss: 0.2086\n",
      "Epoch [45/100], Step [5800/6235], Loss: 0.8936\n",
      "Epoch [45/100], Step [5900/6235], Loss: 0.0065\n",
      "Epoch [45/100], Step [6000/6235], Loss: 1.1124\n",
      "Epoch [45/100], Step [6100/6235], Loss: 0.2072\n",
      "Epoch [45/100], Step [6200/6235], Loss: 5.8747\n",
      "Epoch [45/100], Step [6300/6235], Loss: 0.6833\n",
      "Epoch [45/100], Step [6400/6235], Loss: 0.0727\n",
      "Epoch [45/100], Step [6500/6235], Loss: 1.9273\n",
      "Epoch [45/100], Step [6600/6235], Loss: 0.6366\n",
      "Epoch [45/100], Step [6700/6235], Loss: 0.6807\n",
      "Epoch [45/100], Step [6800/6235], Loss: 0.4150\n",
      "Epoch [45/100], Step [6900/6235], Loss: 0.5694\n",
      "Epoch [45/100], Step [7000/6235], Loss: 0.0399\n",
      "Epoch [45/100], Step [7100/6235], Loss: 0.7114\n",
      "Epoch [45/100], Step [7200/6235], Loss: 1.5575\n",
      "Epoch [45/100], Step [7300/6235], Loss: 0.4330\n",
      "Epoch [45/100], Step [7400/6235], Loss: 0.0250\n",
      "Epoch [45/100], Step [7500/6235], Loss: 0.8456\n",
      "Epoch [45/100], Step [7600/6235], Loss: 5.8133\n",
      "Epoch [45/100], Step [7700/6235], Loss: 6.4321\n",
      "Epoch [45/100], Step [7800/6235], Loss: 2.5772\n",
      "Epoch [45/100], Step [7900/6235], Loss: 7.6190\n",
      "Epoch [45/100], Step [8000/6235], Loss: 0.6611\n",
      "Epoch [45/100], Step [8100/6235], Loss: 0.2984\n",
      "Epoch [45/100], Step [8200/6235], Loss: 10.3560\n",
      "Epoch [45/100], Step [8300/6235], Loss: 18.4524\n",
      "Epoch [45/100], Step [8400/6235], Loss: 647.7125\n",
      "Epoch [45/100], Step [8500/6235], Loss: 20.0007\n",
      "Epoch [45/100], Step [8600/6235], Loss: 19.3287\n",
      "Epoch [45/100], Step [8700/6235], Loss: 30.0987\n",
      "Epoch [45/100], Step [8800/6235], Loss: 317.9557\n",
      "Epoch [45/100], Step [8900/6235], Loss: 119.0263\n",
      "Epoch [45/100], Step [9000/6235], Loss: 184.0208\n",
      "Epoch [45/100], Step [9100/6235], Loss: 981.9898\n",
      "Epoch [45/100], Step [9200/6235], Loss: 2689.1592\n",
      "Epoch [45/100], Step [9300/6235], Loss: 232.0561\n",
      "Epoch [45/100], Step [9400/6235], Loss: 372.4002\n",
      "Epoch [45/100], Step [9500/6235], Loss: 9.6727\n",
      "Epoch [45/100], Step [9600/6235], Loss: 187.2446\n",
      "Epoch [45/100], Step [9700/6235], Loss: 177.3964\n",
      "Epoch [45/100], Step [9800/6235], Loss: 2080.7158\n",
      "Epoch [45/100], Step [9900/6235], Loss: 125.5802\n",
      "Epoch [45/100], Step [10000/6235], Loss: 218.5319\n",
      "Epoch [45/100], Step [10100/6235], Loss: 3.3486\n",
      "Epoch [45/100], Step [10200/6235], Loss: 763.3107\n",
      "Epoch [45/100], Step [10300/6235], Loss: 1.8513\n",
      "Epoch [45/100], Step [10400/6235], Loss: 4.9018\n",
      "Epoch [45/100], Step [10500/6235], Loss: 3.4453\n",
      "Epoch [45/100], Step [10600/6235], Loss: 8.0853\n",
      "Epoch [45/100], Step [10700/6235], Loss: 211.2018\n",
      "Epoch [45/100], Step [10800/6235], Loss: 0.9660\n",
      "Epoch [45/100], Step [10900/6235], Loss: 7.9647\n",
      "Epoch [45/100], Step [11000/6235], Loss: 170.1223\n",
      "Epoch [45/100], Step [11100/6235], Loss: 2.6546\n",
      "Epoch [45/100], Step [11200/6235], Loss: 115.8994\n",
      "Epoch [45/100], Step [11300/6235], Loss: 244.3549\n",
      "Epoch [45/100], Step [11400/6235], Loss: 25.3326\n",
      "Epoch [45/100], Step [11500/6235], Loss: 2.4272\n",
      "Epoch [45/100], Step [11600/6235], Loss: 4.6771\n",
      "Epoch [45/100], Step [11700/6235], Loss: 74.3797\n",
      "Epoch [45/100], Step [11800/6235], Loss: 88.8195\n",
      "Epoch [45/100], Step [11900/6235], Loss: 203.5242\n",
      "Epoch [45/100], Step [12000/6235], Loss: 308.9397\n",
      "Epoch [45/100], Step [12100/6235], Loss: 207.2269\n",
      "Epoch [45/100], Step [12200/6235], Loss: 9.0944\n",
      "Epoch [45/100], Step [12300/6235], Loss: 1.6381\n",
      "Epoch [45/100], Step [12400/6235], Loss: 339.0727\n",
      "Epoch [45/100], Step [12500/6235], Loss: 72.0700\n",
      "Epoch [45/100], Step [12600/6235], Loss: 6.7097\n",
      "Epoch [45/100], Step [12700/6235], Loss: 1.5118\n",
      "Epoch [45/100], Step [12800/6235], Loss: 13.4547\n",
      "Epoch [45/100], Step [12900/6235], Loss: 31.0547\n",
      "Epoch [45/100], Step [13000/6235], Loss: 0.0921\n",
      "Epoch [45/100], Step [13100/6235], Loss: 66.5658\n",
      "Epoch [45/100], Step [13200/6235], Loss: 8.9767\n",
      "Epoch [45/100], Step [13300/6235], Loss: 27.5120\n",
      "Epoch [45/100], Step [13400/6235], Loss: 248.0961\n",
      "Epoch [45/100], Step [13500/6235], Loss: 5.9128\n",
      "Epoch [45/100], Step [13600/6235], Loss: 2.3318\n",
      "Epoch [45/100], Step [13700/6235], Loss: 196.2786\n",
      "Epoch [45/100], Step [13800/6235], Loss: 101.0049\n",
      "Epoch [45/100], Step [13900/6235], Loss: 2.9714\n",
      "Epoch [45/100], Step [14000/6235], Loss: 9.6905\n",
      "Epoch [45/100], Step [14100/6235], Loss: 116.8653\n",
      "Epoch [45/100], Step [14200/6235], Loss: 34.7562\n",
      "Epoch [45/100], Step [14300/6235], Loss: 15.0013\n",
      "Epoch [45/100], Step [14400/6235], Loss: 39.3535\n",
      "Epoch [45/100], Step [14500/6235], Loss: 39.9863\n",
      "Epoch [45/100], Step [14600/6235], Loss: 0.1040\n",
      "Epoch [45/100], Step [14700/6235], Loss: 44.8185\n",
      "Epoch [45/100], Step [14800/6235], Loss: 32.2332\n",
      "Epoch [45/100], Step [14900/6235], Loss: 1.0703\n",
      "Epoch [45/100], Step [15000/6235], Loss: 2.3393\n",
      "Epoch [45/100], Step [15100/6235], Loss: 0.3588\n",
      "Epoch [45/100], Step [15200/6235], Loss: 12.2026\n",
      "Epoch [45/100], Step [15300/6235], Loss: 10.3807\n",
      "Epoch [45/100], Step [15400/6235], Loss: 92.3361\n",
      "Epoch [45/100], Step [15500/6235], Loss: 19.3618\n",
      "Epoch [45/100], Step [15600/6235], Loss: 49.0439\n",
      "Epoch [45/100], Step [15700/6235], Loss: 224.9676\n",
      "Epoch [45/100], Step [15800/6235], Loss: 7.7009\n",
      "Epoch [45/100], Step [15900/6235], Loss: 1.1345\n",
      "Epoch [45/100], Step [16000/6235], Loss: 141.2545\n",
      "Epoch [45/100], Step [16100/6235], Loss: 5.8617\n",
      "Epoch [45/100], Step [16200/6235], Loss: 0.4249\n",
      "Epoch [45/100], Step [16300/6235], Loss: 9.7707\n",
      "Epoch [45/100], Step [16400/6235], Loss: 32.3110\n",
      "Epoch [45/100], Step [16500/6235], Loss: 305.4443\n",
      "Epoch [45/100], Step [16600/6235], Loss: 27.1617\n",
      "Epoch [45/100], Step [16700/6235], Loss: 0.3611\n",
      "Epoch [45/100], Step [16800/6235], Loss: 13.0721\n",
      "Epoch [45/100], Step [16900/6235], Loss: 0.3830\n",
      "Epoch [45/100], Step [17000/6235], Loss: 0.1964\n",
      "Epoch [45/100], Step [17100/6235], Loss: 0.0617\n",
      "Epoch [45/100], Step [17200/6235], Loss: 237.2475\n",
      "Epoch [45/100], Step [17300/6235], Loss: 10.8088\n",
      "Epoch [45/100], Step [17400/6235], Loss: 34.8608\n",
      "Epoch [45/100], Step [17500/6235], Loss: 1.7131\n",
      "Epoch [45/100], Step [17600/6235], Loss: 3.0245\n",
      "Epoch [45/100], Step [17700/6235], Loss: 0.2583\n",
      "Epoch [45/100], Step [17800/6235], Loss: 13.7022\n",
      "Epoch [45/100], Step [17900/6235], Loss: 24.3919\n",
      "Epoch [45/100], Step [18000/6235], Loss: 1.4779\n",
      "Epoch [45/100], Step [18100/6235], Loss: 14.2079\n",
      "Epoch [45/100], Step [18200/6235], Loss: 0.5964\n",
      "Epoch [45/100], Step [18300/6235], Loss: 1.4702\n",
      "Epoch [45/100], Step [18400/6235], Loss: 0.2514\n",
      "Epoch [45/100], Step [18500/6235], Loss: 27.4999\n",
      "Epoch [45/100], Step [18600/6235], Loss: 3.9294\n",
      "Epoch [45/100], Step [18700/6235], Loss: 0.9937\n",
      "Epoch [45/100], Step [18800/6235], Loss: 93.8994\n",
      "Epoch [45/100], Step [18900/6235], Loss: 62.7491\n",
      "Epoch [45/100], Step [19000/6235], Loss: 3.2003\n",
      "Epoch [45/100], Step [19100/6235], Loss: 8.2500\n",
      "Epoch [45/100], Step [19200/6235], Loss: 1.7764\n",
      "Epoch [45/100], Step [19300/6235], Loss: 8.9583\n",
      "Epoch [45/100], Step [19400/6235], Loss: 63.4262\n",
      "Epoch [45/100], Step [19500/6235], Loss: 214.2138\n",
      "Epoch [45/100], Step [19600/6235], Loss: 140.5908\n",
      "Epoch [45/100], Step [19700/6235], Loss: 10.3830\n",
      "Epoch [45/100], Step [19800/6235], Loss: 0.9532\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Step [19900/6235], Loss: 1.3152\n",
      "Epoch [45/100], Step [20000/6235], Loss: 102.6234\n",
      "Epoch [45/100], Step [20100/6235], Loss: 17.3086\n",
      "Epoch [45/100], Step [20200/6235], Loss: 0.5140\n",
      "Epoch [45/100], Step [20300/6235], Loss: 0.1470\n",
      "Epoch [45/100], Step [20400/6235], Loss: 34.3964\n",
      "Epoch [45/100], Step [20500/6235], Loss: 27.0628\n",
      "Epoch [45/100], Step [20600/6235], Loss: 16.9661\n",
      "Epoch [45/100], Step [20700/6235], Loss: 25.9469\n",
      "Epoch [45/100], Step [20800/6235], Loss: 3.0737\n",
      "Epoch [45/100], Step [20900/6235], Loss: 9.7028\n",
      "Epoch [45/100], Step [21000/6235], Loss: 23.8276\n",
      "Epoch [45/100], Step [21100/6235], Loss: 6.9567\n",
      "Epoch [45/100], Step [21200/6235], Loss: 0.2881\n",
      "Epoch [45/100], Step [21300/6235], Loss: 0.0921\n",
      "Epoch [45/100], Step [21400/6235], Loss: 4.8897\n",
      "Epoch [45/100], Step [21500/6235], Loss: 1.2634\n",
      "Epoch [45/100], Step [21600/6235], Loss: 30.0396\n",
      "Epoch [45/100], Step [21700/6235], Loss: 0.1821\n",
      "Epoch [45/100], Step [21800/6235], Loss: 4.6796\n",
      "Epoch [45/100], Step [21900/6235], Loss: 1.6894\n",
      "Epoch [45/100], Step [22000/6235], Loss: 10.3920\n",
      "Epoch [45/100], Step [22100/6235], Loss: 0.0257\n",
      "Epoch [45/100], Step [22200/6235], Loss: 6.0408\n",
      "Epoch [45/100], Step [22300/6235], Loss: 2.0580\n",
      "Epoch [45/100], Step [22400/6235], Loss: 0.8782\n",
      "Epoch [45/100], Step [22500/6235], Loss: 110.3168\n",
      "Epoch [45/100], Step [22600/6235], Loss: 15.4553\n",
      "Epoch [45/100], Step [22700/6235], Loss: 0.0447\n",
      "Epoch [45/100], Step [22800/6235], Loss: 9.4616\n",
      "Epoch [45/100], Step [22900/6235], Loss: 19.0272\n",
      "Epoch [45/100], Step [23000/6235], Loss: 11.8002\n",
      "Epoch [45/100], Step [23100/6235], Loss: 0.9197\n",
      "Epoch [45/100], Step [23200/6235], Loss: 1.9761\n",
      "Epoch [45/100], Step [23300/6235], Loss: 7.8121\n",
      "Epoch [45/100], Step [23400/6235], Loss: 2.8313\n",
      "Epoch [45/100], Step [23500/6235], Loss: 0.2731\n",
      "Epoch [45/100], Step [23600/6235], Loss: 138.3249\n",
      "Epoch [45/100], Step [23700/6235], Loss: 2.1588\n",
      "Epoch [45/100], Step [23800/6235], Loss: 0.6554\n",
      "Epoch [45/100], Step [23900/6235], Loss: 0.5887\n",
      "Epoch [45/100], Step [24000/6235], Loss: 2.5136\n",
      "Epoch [45/100], Step [24100/6235], Loss: 0.0958\n",
      "Epoch [45/100], Step [24200/6235], Loss: 45.3948\n",
      "Epoch [45/100], Step [24300/6235], Loss: 0.5558\n",
      "Epoch [45/100], Step [24400/6235], Loss: 1.4623\n",
      "Epoch [45/100], Step [24500/6235], Loss: 0.2148\n",
      "Epoch [45/100], Step [24600/6235], Loss: 0.3239\n",
      "Epoch [45/100], Step [24700/6235], Loss: 2.8599\n",
      "Epoch [45/100], Step [24800/6235], Loss: 0.2983\n",
      "Epoch [45/100], Step [24900/6235], Loss: 13.1961\n",
      "Epoch [45/100], Step [25000/6235], Loss: 9.7504\n",
      "Epoch [45/100], Step [25100/6235], Loss: 7.1854\n",
      "Epoch [45/100], Step [25200/6235], Loss: 0.2244\n",
      "Epoch [45/100], Step [25300/6235], Loss: 0.8904\n",
      "Epoch [45/100], Step [25400/6235], Loss: 4.5455\n",
      "Epoch [45/100], Step [25500/6235], Loss: 9.5249\n",
      "Epoch [45/100], Step [25600/6235], Loss: 8.6419\n",
      "Epoch [45/100], Step [25700/6235], Loss: 0.0178\n",
      "Epoch [45/100], Step [25800/6235], Loss: 0.3387\n",
      "Epoch [45/100], Step [25900/6235], Loss: 3.1677\n",
      "Epoch [45/100], Step [26000/6235], Loss: 2.0361\n",
      "Epoch [45/100], Step [26100/6235], Loss: 0.0504\n",
      "Epoch [45/100], Step [26200/6235], Loss: 1.4408\n",
      "Epoch [45/100], Step [26300/6235], Loss: 1.5169\n",
      "Epoch [45/100], Step [26400/6235], Loss: 0.5144\n",
      "Epoch [45/100], Step [26500/6235], Loss: 0.0473\n",
      "Epoch [45/100], Step [26600/6235], Loss: 0.2367\n",
      "Epoch [45/100], Step [26700/6235], Loss: 0.1379\n",
      "Epoch [45/100], Step [26800/6235], Loss: 0.0860\n",
      "Epoch [45/100], Step [26900/6235], Loss: 0.0569\n",
      "Epoch [45/100], Step [27000/6235], Loss: 16.2159\n",
      "Epoch [45/100], Step [27100/6235], Loss: 0.0814\n",
      "Epoch [45/100], Step [27200/6235], Loss: 0.0092\n",
      "Epoch [45/100], Step [27300/6235], Loss: 0.0305\n",
      "Epoch [45/100], Step [27400/6235], Loss: 0.6057\n",
      "Epoch [45/100], Step [27500/6235], Loss: 4.5491\n",
      "Epoch [45/100], Step [27600/6235], Loss: 0.0180\n",
      "Epoch [45/100], Step [27700/6235], Loss: 0.8258\n",
      "Epoch [45/100], Step [27800/6235], Loss: 5.7877\n",
      "Epoch [45/100], Step [27900/6235], Loss: 0.3806\n",
      "Epoch [45/100], Step [28000/6235], Loss: 138.9462\n",
      "Epoch [45/100], Step [28100/6235], Loss: 9.8588\n",
      "Epoch [45/100], Step [28200/6235], Loss: 30.2687\n",
      "Epoch [45/100], Step [28300/6235], Loss: 2.2640\n",
      "Epoch [45/100], Step [28400/6235], Loss: 26.7399\n",
      "Epoch [45/100], Step [28500/6235], Loss: 4.4122\n",
      "Epoch [45/100], Step [28600/6235], Loss: 0.4183\n",
      "Epoch [45/100], Step [28700/6235], Loss: 4.6115\n",
      "Epoch [45/100], Step [28800/6235], Loss: 0.6528\n",
      "Epoch [45/100], Step [28900/6235], Loss: 60.4373\n",
      "Epoch [45/100], Step [29000/6235], Loss: 10.0922\n",
      "Epoch [45/100], Step [29100/6235], Loss: 0.5970\n",
      "Epoch [45/100], Step [29200/6235], Loss: 3.6598\n",
      "Epoch [45/100], Step [29300/6235], Loss: 15.7642\n",
      "Epoch [45/100], Step [29400/6235], Loss: 0.1856\n",
      "Epoch [45/100], Step [29500/6235], Loss: 2.7331\n",
      "Epoch [45/100], Step [29600/6235], Loss: 0.2134\n",
      "Epoch [45/100], Step [29700/6235], Loss: 2.5687\n",
      "Epoch [45/100], Step [29800/6235], Loss: 0.9151\n",
      "Epoch [45/100], Step [29900/6235], Loss: 1.8009\n",
      "Epoch [45/100], Step [30000/6235], Loss: 5.8362\n",
      "Epoch [45/100], Step [30100/6235], Loss: 7.7364\n",
      "Epoch [45/100], Step [30200/6235], Loss: 1.8357\n",
      "Epoch [45/100], Step [30300/6235], Loss: 0.0842\n",
      "Epoch [45/100], Step [30400/6235], Loss: 1.9339\n",
      "Epoch [45/100], Step [30500/6235], Loss: 1.3262\n",
      "Epoch [45/100], Step [30600/6235], Loss: 1.7046\n",
      "Epoch [45/100], Step [30700/6235], Loss: 1.7662\n",
      "Epoch [45/100], Step [30800/6235], Loss: 0.5569\n",
      "Epoch [45/100], Step [30900/6235], Loss: 2.6145\n",
      "Epoch [45/100], Step [31000/6235], Loss: 0.3274\n",
      "Epoch [45/100], Step [31100/6235], Loss: 0.0895\n",
      "Epoch [45/100], Step [31200/6235], Loss: 6.0331\n",
      "Epoch [45/100], Step [31300/6235], Loss: 1.6959\n",
      "Epoch [45/100], Step [31400/6235], Loss: 9.8814\n",
      "Epoch [45/100], Step [31500/6235], Loss: 0.8578\n",
      "Epoch [45/100], Step [31600/6235], Loss: 5.2380\n",
      "Epoch [45/100], Step [31700/6235], Loss: 13.9468\n",
      "Epoch [45/100], Step [31800/6235], Loss: 0.2655\n",
      "Epoch [45/100], Step [31900/6235], Loss: 783.1649\n",
      "Epoch [45/100], Step [32000/6235], Loss: 81.2106\n",
      "Epoch [45/100], Step [32100/6235], Loss: 6.3552\n",
      "Epoch [45/100], Step [32200/6235], Loss: 126.1952\n",
      "Epoch [45/100], Step [32300/6235], Loss: 1.5726\n",
      "Epoch [45/100], Step [32400/6235], Loss: 1.5425\n",
      "Epoch [45/100], Step [32500/6235], Loss: 12.4848\n",
      "Epoch [45/100], Step [32600/6235], Loss: 0.4174\n",
      "Epoch [45/100], Step [32700/6235], Loss: 75.5194\n",
      "Epoch [45/100], Step [32800/6235], Loss: 30.9572\n",
      "Epoch [45/100], Step [32900/6235], Loss: 1.5422\n",
      "Epoch [45/100], Step [33000/6235], Loss: 0.3556\n",
      "Epoch [45/100], Step [33100/6235], Loss: 0.5544\n",
      "Epoch [45/100], Step [33200/6235], Loss: 1.0489\n",
      "Epoch [45/100], Step [33300/6235], Loss: 0.7294\n",
      "Epoch [45/100], Step [33400/6235], Loss: 74.3540\n",
      "Epoch [45/100], Step [33500/6235], Loss: 1.9882\n",
      "Epoch [45/100], Step [33600/6235], Loss: 8.2720\n",
      "Epoch [45/100], Step [33700/6235], Loss: 11.8207\n",
      "Epoch [45/100], Step [33800/6235], Loss: 1.1565\n",
      "Epoch [45/100], Step [33900/6235], Loss: 28.9018\n",
      "Epoch [45/100], Step [34000/6235], Loss: 0.0593\n",
      "Epoch [45/100], Step [34100/6235], Loss: 0.4757\n",
      "Epoch [45/100], Step [34200/6235], Loss: 2.4789\n",
      "Epoch [45/100], Step [34300/6235], Loss: 4.3244\n",
      "Epoch [45/100], Step [34400/6235], Loss: 0.2264\n",
      "Epoch [45/100], Step [34500/6235], Loss: 62.3166\n",
      "Epoch [45/100], Step [34600/6235], Loss: 0.5228\n",
      "Epoch [45/100], Step [34700/6235], Loss: 6.9593\n",
      "Epoch [45/100], Step [34800/6235], Loss: 13.4988\n",
      "Epoch [45/100], Step [34900/6235], Loss: 68.4044\n",
      "Epoch [45/100], Step [35000/6235], Loss: 0.2259\n",
      "Epoch [45/100], Step [35100/6235], Loss: 0.4240\n",
      "Epoch [45/100], Step [35200/6235], Loss: 0.3089\n",
      "Epoch [45/100], Step [35300/6235], Loss: 2.5294\n",
      "Epoch [45/100], Step [35400/6235], Loss: 0.4762\n",
      "Epoch [45/100], Step [35500/6235], Loss: 2.1626\n",
      "Epoch [45/100], Step [35600/6235], Loss: 3.8653\n",
      "Epoch [45/100], Step [35700/6235], Loss: 5.1569\n",
      "Epoch [45/100], Step [35800/6235], Loss: 0.8369\n",
      "Epoch [45/100], Step [35900/6235], Loss: 1.0964\n",
      "Epoch [45/100], Step [36000/6235], Loss: 0.5318\n",
      "Epoch [45/100], Step [36100/6235], Loss: 0.0533\n",
      "Epoch [45/100], Step [36200/6235], Loss: 15.9972\n",
      "Epoch [45/100], Step [36300/6235], Loss: 0.1729\n",
      "Epoch [45/100], Step [36400/6235], Loss: 2.5030\n",
      "Epoch [45/100], Step [36500/6235], Loss: 8.8821\n",
      "Epoch [45/100], Step [36600/6235], Loss: 0.1577\n",
      "Epoch [45/100], Step [36700/6235], Loss: 0.4006\n",
      "Epoch [45/100], Step [36800/6235], Loss: 12.4155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [45/100], Step [36900/6235], Loss: 6.0256\n",
      "Epoch [45/100], Step [37000/6235], Loss: 0.4969\n",
      "Epoch [45/100], Step [37100/6235], Loss: 1.1292\n",
      "Epoch [45/100], Step [37200/6235], Loss: 0.0817\n",
      "Epoch [45/100], Step [37300/6235], Loss: 0.0450\n",
      "Epoch [45/100], Step [37400/6235], Loss: 0.2050\n",
      "Epoch [45/100], Step [37500/6235], Loss: 4.5911\n",
      "Epoch [45/100], Step [37600/6235], Loss: 11.6931\n",
      "Epoch [45/100], Step [37700/6235], Loss: 1.3033\n",
      "Epoch [45/100], Step [37800/6235], Loss: 4.1880\n",
      "Epoch [45/100], Step [37900/6235], Loss: 5.1274\n",
      "Epoch [45/100], Step [38000/6235], Loss: 0.7170\n",
      "Epoch [45/100], Step [38100/6235], Loss: 2.9225\n",
      "Epoch [45/100], Step [38200/6235], Loss: 1.9232\n",
      "Epoch [45/100], Step [38300/6235], Loss: 0.4475\n",
      "Epoch [45/100], Step [38400/6235], Loss: 0.1242\n",
      "Epoch [45/100], Step [38500/6235], Loss: 2.2714\n",
      "Epoch [45/100], Step [38600/6235], Loss: 0.0528\n",
      "Epoch [45/100], Step [38700/6235], Loss: 0.2389\n",
      "Epoch [45/100], Step [38800/6235], Loss: 0.2428\n",
      "Epoch [45/100], Step [38900/6235], Loss: 12.2460\n",
      "Epoch [45/100], Step [39000/6235], Loss: 8.5827\n",
      "Epoch [45/100], Step [39100/6235], Loss: 21.4232\n",
      "Epoch [45/100], Step [39200/6235], Loss: 0.3194\n",
      "Epoch [45/100], Step [39300/6235], Loss: 56.2437\n",
      "Epoch [45/100], Step [39400/6235], Loss: 141.4462\n",
      "Epoch [45/100], Step [39500/6235], Loss: 229.0815\n",
      "Epoch [45/100], Step [39600/6235], Loss: 13.7067\n",
      "Epoch [45/100], Step [39700/6235], Loss: 156.3595\n",
      "Epoch [45/100], Step [39800/6235], Loss: 112.4778\n",
      "Epoch [45/100], Step [39900/6235], Loss: 0.6598\n",
      "Epoch [45/100], Step [40000/6235], Loss: 8.6444\n",
      "Epoch [45/100], Step [40100/6235], Loss: 30.4964\n",
      "Epoch [45/100], Step [40200/6235], Loss: 3.2738\n",
      "Epoch [45/100], Step [40300/6235], Loss: 0.7827\n",
      "Epoch [45/100], Step [40400/6235], Loss: 2.5987\n",
      "Epoch [45/100], Step [40500/6235], Loss: 2.1368\n",
      "Epoch [45/100], Step [40600/6235], Loss: 0.4037\n",
      "Epoch [45/100], Step [40700/6235], Loss: 7.5999\n",
      "Epoch [45/100], Step [40800/6235], Loss: 1.8865\n",
      "Epoch [45/100], Step [40900/6235], Loss: 0.0652\n",
      "Epoch [45/100], Step [41000/6235], Loss: 45.9964\n",
      "Epoch [45/100], Step [41100/6235], Loss: 31.1813\n",
      "Epoch [45/100], Step [41200/6235], Loss: 4.0565\n",
      "Epoch [45/100], Step [41300/6235], Loss: 2.7860\n",
      "Epoch [45/100], Step [41400/6235], Loss: 2.3980\n",
      "Epoch [45/100], Step [41500/6235], Loss: 0.4956\n",
      "Epoch [45/100], Step [41600/6235], Loss: 0.1592\n",
      "Epoch [45/100], Step [41700/6235], Loss: 3.8237\n",
      "Epoch [45/100], Step [41800/6235], Loss: 3.3930\n",
      "Epoch [45/100], Step [41900/6235], Loss: 2.1406\n",
      "Epoch [45/100], Step [42000/6235], Loss: 2.0385\n",
      "Epoch [45/100], Step [42100/6235], Loss: 4.7148\n",
      "Epoch [45/100], Step [42200/6235], Loss: 3.5715\n",
      "Epoch [45/100], Step [42300/6235], Loss: 5.5764\n",
      "Epoch [45/100], Step [42400/6235], Loss: 0.2336\n",
      "Epoch [45/100], Step [42500/6235], Loss: 4.7179\n",
      "Epoch [45/100], Step [42600/6235], Loss: 0.4718\n",
      "Epoch [45/100], Step [42700/6235], Loss: 0.2111\n",
      "Epoch [45/100], Step [42800/6235], Loss: 0.3984\n",
      "Epoch [45/100], Step [42900/6235], Loss: 4.2673\n",
      "Epoch [45/100], Step [43000/6235], Loss: 0.1912\n",
      "Epoch [45/100], Step [43100/6235], Loss: 1.2826\n",
      "Epoch [45/100], Step [43200/6235], Loss: 0.6202\n",
      "Epoch [45/100], Step [43300/6235], Loss: 9.8629\n",
      "Epoch [45/100], Step [43400/6235], Loss: 7.7964\n",
      "Epoch [45/100], Step [43500/6235], Loss: 8.6482\n",
      "Epoch [45/100], Step [43600/6235], Loss: 26.5314\n",
      "Epoch [45/100], Step [43700/6235], Loss: 35.9004\n",
      "Epoch [45/100], Step [43800/6235], Loss: 0.4150\n",
      "Epoch [45/100], Step [43900/6235], Loss: 0.8640\n",
      "Epoch [45/100], Step [44000/6235], Loss: 38.4376\n",
      "Epoch [45/100], Step [44100/6235], Loss: 1.0214\n",
      "Epoch [45/100], Step [44200/6235], Loss: 2.0668\n",
      "Epoch [45/100], Step [44300/6235], Loss: 48.1232\n",
      "Epoch [45/100], Step [44400/6235], Loss: 3.4316\n",
      "Epoch [45/100], Step [44500/6235], Loss: 1.8805\n",
      "Epoch [45/100], Step [44600/6235], Loss: 15.4073\n",
      "Epoch [45/100], Step [44700/6235], Loss: 3.6212\n",
      "Epoch [45/100], Step [44800/6235], Loss: 3.6910\n",
      "Epoch [45/100], Step [44900/6235], Loss: 2.2731\n",
      "Epoch [45/100], Step [45000/6235], Loss: 5.3030\n",
      "Epoch [45/100], Step [45100/6235], Loss: 8.0000\n",
      "Epoch [45/100], Step [45200/6235], Loss: 0.5919\n",
      "Epoch [45/100], Step [45300/6235], Loss: 38.0514\n",
      "Epoch [45/100], Step [45400/6235], Loss: 10.0803\n",
      "Epoch [45/100], Step [45500/6235], Loss: 0.1376\n",
      "Epoch [45/100], Step [45600/6235], Loss: 0.2079\n",
      "Epoch [45/100], Step [45700/6235], Loss: 38.8277\n",
      "Epoch [45/100], Step [45800/6235], Loss: 714.9119\n",
      "Epoch [45/100], Step [45900/6235], Loss: 11.7701\n",
      "Epoch [45/100], Step [46000/6235], Loss: 0.5707\n",
      "Epoch [45/100], Step [46100/6235], Loss: 8.1188\n",
      "Epoch [45/100], Step [46200/6235], Loss: 24.6968\n",
      "Epoch [45/100], Step [46300/6235], Loss: 42.5934\n",
      "Epoch [45/100], Step [46400/6235], Loss: 0.9865\n",
      "Epoch [45/100], Step [46500/6235], Loss: 320.7458\n",
      "Epoch [45/100], Step [46600/6235], Loss: 25.7795\n",
      "Epoch [45/100], Step [46700/6235], Loss: 2.4604\n",
      "Epoch [45/100], Step [46800/6235], Loss: 16.3097\n",
      "Epoch [45/100], Step [46900/6235], Loss: 18.1670\n",
      "Epoch [45/100], Step [47000/6235], Loss: 1.0661\n",
      "Epoch [45/100], Step [47100/6235], Loss: 31.9375\n",
      "Epoch [45/100], Step [47200/6235], Loss: 44.9784\n",
      "Epoch [45/100], Step [47300/6235], Loss: 0.8646\n",
      "Epoch [45/100], Step [47400/6235], Loss: 81.4987\n",
      "Epoch [45/100], Step [47500/6235], Loss: 1.8893\n",
      "Epoch [45/100], Step [47600/6235], Loss: 8.8594\n",
      "Epoch [45/100], Step [47700/6235], Loss: 6.3719\n",
      "Epoch [45/100], Step [47800/6235], Loss: 8.6944\n",
      "Epoch [45/100], Step [47900/6235], Loss: 20.9152\n",
      "Epoch [45/100], Step [48000/6235], Loss: 11.0624\n",
      "Epoch [45/100], Step [48100/6235], Loss: 4.6005\n",
      "Epoch [45/100], Step [48200/6235], Loss: 7.1026\n",
      "Epoch [45/100], Step [48300/6235], Loss: 524.2661\n",
      "Epoch [45/100], Step [48400/6235], Loss: 12.5294\n",
      "Epoch [45/100], Step [48500/6235], Loss: 39.5363\n",
      "Epoch [45/100], Step [48600/6235], Loss: 132.1385\n",
      "Epoch [45/100], Step [48700/6235], Loss: 1.0554\n",
      "Epoch [45/100], Step [48800/6235], Loss: 205.7801\n",
      "Epoch [45/100], Step [48900/6235], Loss: 781.2245\n",
      "Epoch [45/100], Step [49000/6235], Loss: 273.2011\n",
      "Epoch [45/100], Step [49100/6235], Loss: 2515.0674\n",
      "Epoch [45/100], Step [49200/6235], Loss: 826.6588\n",
      "Epoch [45/100], Step [49300/6235], Loss: 993.4326\n",
      "Epoch [45/100], Step [49400/6235], Loss: 28.9040\n",
      "Epoch [45/100], Step [49500/6235], Loss: 15.4471\n",
      "Epoch [45/100], Step [49600/6235], Loss: 684.7213\n",
      "Epoch [45/100], Step [49700/6235], Loss: 2533.9758\n",
      "Epoch [45/100], Step [49800/6235], Loss: 166.0958\n",
      "Epoch [46/100], Step [100/6235], Loss: 25.7684\n",
      "Epoch [46/100], Step [200/6235], Loss: 0.1920\n",
      "Epoch [46/100], Step [300/6235], Loss: 0.0071\n",
      "Epoch [46/100], Step [400/6235], Loss: 0.0011\n",
      "Epoch [46/100], Step [500/6235], Loss: 0.7113\n",
      "Epoch [46/100], Step [600/6235], Loss: 0.0223\n",
      "Epoch [46/100], Step [700/6235], Loss: 0.6115\n",
      "Epoch [46/100], Step [800/6235], Loss: 0.0525\n",
      "Epoch [46/100], Step [900/6235], Loss: 0.0805\n",
      "Epoch [46/100], Step [1000/6235], Loss: 0.0229\n",
      "Epoch [46/100], Step [1100/6235], Loss: 0.0752\n",
      "Epoch [46/100], Step [1200/6235], Loss: 0.1606\n",
      "Epoch [46/100], Step [1300/6235], Loss: 0.0113\n",
      "Epoch [46/100], Step [1400/6235], Loss: 0.1501\n",
      "Epoch [46/100], Step [1500/6235], Loss: 0.0078\n",
      "Epoch [46/100], Step [1600/6235], Loss: 0.2455\n",
      "Epoch [46/100], Step [1700/6235], Loss: 0.2144\n",
      "Epoch [46/100], Step [1800/6235], Loss: 0.2735\n",
      "Epoch [46/100], Step [1900/6235], Loss: 0.3046\n",
      "Epoch [46/100], Step [2000/6235], Loss: 2.1443\n",
      "Epoch [46/100], Step [2100/6235], Loss: 4.2622\n",
      "Epoch [46/100], Step [2200/6235], Loss: 5.1893\n",
      "Epoch [46/100], Step [2300/6235], Loss: 0.3718\n",
      "Epoch [46/100], Step [2400/6235], Loss: 0.7236\n",
      "Epoch [46/100], Step [2500/6235], Loss: 21.3920\n",
      "Epoch [46/100], Step [2600/6235], Loss: 14.0816\n",
      "Epoch [46/100], Step [2700/6235], Loss: 7.8270\n",
      "Epoch [46/100], Step [2800/6235], Loss: 45.4226\n",
      "Epoch [46/100], Step [2900/6235], Loss: 17.3212\n",
      "Epoch [46/100], Step [3000/6235], Loss: 0.6121\n",
      "Epoch [46/100], Step [3100/6235], Loss: 66.4227\n",
      "Epoch [46/100], Step [3200/6235], Loss: 43.7544\n",
      "Epoch [46/100], Step [3300/6235], Loss: 12.4066\n",
      "Epoch [46/100], Step [3400/6235], Loss: 3.5073\n",
      "Epoch [46/100], Step [3500/6235], Loss: 53.2310\n",
      "Epoch [46/100], Step [3600/6235], Loss: 1.5210\n",
      "Epoch [46/100], Step [3700/6235], Loss: 0.0435\n",
      "Epoch [46/100], Step [3800/6235], Loss: 0.0680\n",
      "Epoch [46/100], Step [3900/6235], Loss: 0.1431\n",
      "Epoch [46/100], Step [4000/6235], Loss: 0.1140\n",
      "Epoch [46/100], Step [4100/6235], Loss: 9.8083\n",
      "Epoch [46/100], Step [4200/6235], Loss: 3.4673\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Step [4300/6235], Loss: 6.8156\n",
      "Epoch [46/100], Step [4400/6235], Loss: 0.6852\n",
      "Epoch [46/100], Step [4500/6235], Loss: 38.8979\n",
      "Epoch [46/100], Step [4600/6235], Loss: 0.9514\n",
      "Epoch [46/100], Step [4700/6235], Loss: 0.1671\n",
      "Epoch [46/100], Step [4800/6235], Loss: 7.6569\n",
      "Epoch [46/100], Step [4900/6235], Loss: 1.2104\n",
      "Epoch [46/100], Step [5000/6235], Loss: 0.0344\n",
      "Epoch [46/100], Step [5100/6235], Loss: 0.3596\n",
      "Epoch [46/100], Step [5200/6235], Loss: 4.5517\n",
      "Epoch [46/100], Step [5300/6235], Loss: 26.2350\n",
      "Epoch [46/100], Step [5400/6235], Loss: 1.5739\n",
      "Epoch [46/100], Step [5500/6235], Loss: 0.0798\n",
      "Epoch [46/100], Step [5600/6235], Loss: 0.3345\n",
      "Epoch [46/100], Step [5700/6235], Loss: 0.2793\n",
      "Epoch [46/100], Step [5800/6235], Loss: 0.1638\n",
      "Epoch [46/100], Step [5900/6235], Loss: 0.2037\n",
      "Epoch [46/100], Step [6000/6235], Loss: 0.0544\n",
      "Epoch [46/100], Step [6100/6235], Loss: 0.1365\n",
      "Epoch [46/100], Step [6200/6235], Loss: 5.7113\n",
      "Epoch [46/100], Step [6300/6235], Loss: 0.5713\n",
      "Epoch [46/100], Step [6400/6235], Loss: 0.0351\n",
      "Epoch [46/100], Step [6500/6235], Loss: 3.3779\n",
      "Epoch [46/100], Step [6600/6235], Loss: 5.7617\n",
      "Epoch [46/100], Step [6700/6235], Loss: 1.5035\n",
      "Epoch [46/100], Step [6800/6235], Loss: 0.4544\n",
      "Epoch [46/100], Step [6900/6235], Loss: 0.4219\n",
      "Epoch [46/100], Step [7000/6235], Loss: 0.0196\n",
      "Epoch [46/100], Step [7100/6235], Loss: 0.3191\n",
      "Epoch [46/100], Step [7200/6235], Loss: 0.2417\n",
      "Epoch [46/100], Step [7300/6235], Loss: 0.5908\n",
      "Epoch [46/100], Step [7400/6235], Loss: 0.2786\n",
      "Epoch [46/100], Step [7500/6235], Loss: 0.5915\n",
      "Epoch [46/100], Step [7600/6235], Loss: 2.6846\n",
      "Epoch [46/100], Step [7700/6235], Loss: 22.0458\n",
      "Epoch [46/100], Step [7800/6235], Loss: 6.8206\n",
      "Epoch [46/100], Step [7900/6235], Loss: 0.3634\n",
      "Epoch [46/100], Step [8000/6235], Loss: 0.0552\n",
      "Epoch [46/100], Step [8100/6235], Loss: 4.6731\n",
      "Epoch [46/100], Step [8200/6235], Loss: 13.3025\n",
      "Epoch [46/100], Step [8300/6235], Loss: 34.5548\n",
      "Epoch [46/100], Step [8400/6235], Loss: 249.3315\n",
      "Epoch [46/100], Step [8500/6235], Loss: 1.2882\n",
      "Epoch [46/100], Step [8600/6235], Loss: 110.9439\n",
      "Epoch [46/100], Step [8700/6235], Loss: 43.8426\n",
      "Epoch [46/100], Step [8800/6235], Loss: 543.6890\n",
      "Epoch [46/100], Step [8900/6235], Loss: 48.1712\n",
      "Epoch [46/100], Step [9000/6235], Loss: 641.5816\n",
      "Epoch [46/100], Step [9100/6235], Loss: 1604.8998\n",
      "Epoch [46/100], Step [9200/6235], Loss: 4122.7407\n",
      "Epoch [46/100], Step [9300/6235], Loss: 265.2937\n",
      "Epoch [46/100], Step [9400/6235], Loss: 43.9030\n",
      "Epoch [46/100], Step [9500/6235], Loss: 1630.6843\n",
      "Epoch [46/100], Step [9600/6235], Loss: 369.7716\n",
      "Epoch [46/100], Step [9700/6235], Loss: 1.9385\n",
      "Epoch [46/100], Step [9800/6235], Loss: 147.0738\n",
      "Epoch [46/100], Step [9900/6235], Loss: 136.8279\n",
      "Epoch [46/100], Step [10000/6235], Loss: 505.7012\n",
      "Epoch [46/100], Step [10100/6235], Loss: 4.1176\n",
      "Epoch [46/100], Step [10200/6235], Loss: 842.2181\n",
      "Epoch [46/100], Step [10300/6235], Loss: 3.7764\n",
      "Epoch [46/100], Step [10400/6235], Loss: 3.3053\n",
      "Epoch [46/100], Step [10500/6235], Loss: 7.6005\n",
      "Epoch [46/100], Step [10600/6235], Loss: 7.3938\n",
      "Epoch [46/100], Step [10700/6235], Loss: 59.9755\n",
      "Epoch [46/100], Step [10800/6235], Loss: 19.5487\n",
      "Epoch [46/100], Step [10900/6235], Loss: 5.5974\n",
      "Epoch [46/100], Step [11000/6235], Loss: 249.4002\n",
      "Epoch [46/100], Step [11100/6235], Loss: 15.3762\n",
      "Epoch [46/100], Step [11200/6235], Loss: 78.9431\n",
      "Epoch [46/100], Step [11300/6235], Loss: 207.6403\n",
      "Epoch [46/100], Step [11400/6235], Loss: 2.8590\n",
      "Epoch [46/100], Step [11500/6235], Loss: 0.6747\n",
      "Epoch [46/100], Step [11600/6235], Loss: 1.1631\n",
      "Epoch [46/100], Step [11700/6235], Loss: 45.2884\n",
      "Epoch [46/100], Step [11800/6235], Loss: 409.7396\n",
      "Epoch [46/100], Step [11900/6235], Loss: 25.5148\n",
      "Epoch [46/100], Step [12000/6235], Loss: 677.4074\n",
      "Epoch [46/100], Step [12100/6235], Loss: 256.2507\n",
      "Epoch [46/100], Step [12200/6235], Loss: 21.5899\n",
      "Epoch [46/100], Step [12300/6235], Loss: 16.2208\n",
      "Epoch [46/100], Step [12400/6235], Loss: 463.1790\n",
      "Epoch [46/100], Step [12500/6235], Loss: 12.3707\n",
      "Epoch [46/100], Step [12600/6235], Loss: 69.5104\n",
      "Epoch [46/100], Step [12700/6235], Loss: 3.3890\n",
      "Epoch [46/100], Step [12800/6235], Loss: 3.4956\n",
      "Epoch [46/100], Step [12900/6235], Loss: 39.6080\n",
      "Epoch [46/100], Step [13000/6235], Loss: 0.2963\n",
      "Epoch [46/100], Step [13100/6235], Loss: 67.5666\n",
      "Epoch [46/100], Step [13200/6235], Loss: 15.5289\n",
      "Epoch [46/100], Step [13300/6235], Loss: 67.1762\n",
      "Epoch [46/100], Step [13400/6235], Loss: 247.3445\n",
      "Epoch [46/100], Step [13500/6235], Loss: 9.5615\n",
      "Epoch [46/100], Step [13600/6235], Loss: 15.7073\n",
      "Epoch [46/100], Step [13700/6235], Loss: 18.7166\n",
      "Epoch [46/100], Step [13800/6235], Loss: 165.5618\n",
      "Epoch [46/100], Step [13900/6235], Loss: 53.0982\n",
      "Epoch [46/100], Step [14000/6235], Loss: 15.2331\n",
      "Epoch [46/100], Step [14100/6235], Loss: 6.5133\n",
      "Epoch [46/100], Step [14200/6235], Loss: 28.4097\n",
      "Epoch [46/100], Step [14300/6235], Loss: 8.2616\n",
      "Epoch [46/100], Step [14400/6235], Loss: 38.7674\n",
      "Epoch [46/100], Step [14500/6235], Loss: 65.7578\n",
      "Epoch [46/100], Step [14600/6235], Loss: 0.4763\n",
      "Epoch [46/100], Step [14700/6235], Loss: 45.2126\n",
      "Epoch [46/100], Step [14800/6235], Loss: 32.1000\n",
      "Epoch [46/100], Step [14900/6235], Loss: 1.9141\n",
      "Epoch [46/100], Step [15000/6235], Loss: 2.9612\n",
      "Epoch [46/100], Step [15100/6235], Loss: 0.1987\n",
      "Epoch [46/100], Step [15200/6235], Loss: 3.1573\n",
      "Epoch [46/100], Step [15300/6235], Loss: 28.4671\n",
      "Epoch [46/100], Step [15400/6235], Loss: 72.0396\n",
      "Epoch [46/100], Step [15500/6235], Loss: 9.5620\n",
      "Epoch [46/100], Step [15600/6235], Loss: 180.2977\n",
      "Epoch [46/100], Step [15700/6235], Loss: 184.5337\n",
      "Epoch [46/100], Step [15800/6235], Loss: 9.7512\n",
      "Epoch [46/100], Step [15900/6235], Loss: 0.2771\n",
      "Epoch [46/100], Step [16000/6235], Loss: 155.5679\n",
      "Epoch [46/100], Step [16100/6235], Loss: 0.7961\n",
      "Epoch [46/100], Step [16200/6235], Loss: 0.4136\n",
      "Epoch [46/100], Step [16300/6235], Loss: 10.3356\n",
      "Epoch [46/100], Step [16400/6235], Loss: 31.1456\n",
      "Epoch [46/100], Step [16500/6235], Loss: 759.2148\n",
      "Epoch [46/100], Step [16600/6235], Loss: 9.3336\n",
      "Epoch [46/100], Step [16700/6235], Loss: 0.5804\n",
      "Epoch [46/100], Step [16800/6235], Loss: 8.8179\n",
      "Epoch [46/100], Step [16900/6235], Loss: 0.2653\n",
      "Epoch [46/100], Step [17000/6235], Loss: 0.2406\n",
      "Epoch [46/100], Step [17100/6235], Loss: 0.2129\n",
      "Epoch [46/100], Step [17200/6235], Loss: 295.4196\n",
      "Epoch [46/100], Step [17300/6235], Loss: 21.1888\n",
      "Epoch [46/100], Step [17400/6235], Loss: 34.3583\n",
      "Epoch [46/100], Step [17500/6235], Loss: 0.7102\n",
      "Epoch [46/100], Step [17600/6235], Loss: 4.0535\n",
      "Epoch [46/100], Step [17700/6235], Loss: 6.9196\n",
      "Epoch [46/100], Step [17800/6235], Loss: 18.4539\n",
      "Epoch [46/100], Step [17900/6235], Loss: 9.6326\n",
      "Epoch [46/100], Step [18000/6235], Loss: 4.6585\n",
      "Epoch [46/100], Step [18100/6235], Loss: 14.7761\n",
      "Epoch [46/100], Step [18200/6235], Loss: 0.5072\n",
      "Epoch [46/100], Step [18300/6235], Loss: 2.4453\n",
      "Epoch [46/100], Step [18400/6235], Loss: 0.8630\n",
      "Epoch [46/100], Step [18500/6235], Loss: 21.4055\n",
      "Epoch [46/100], Step [18600/6235], Loss: 3.3223\n",
      "Epoch [46/100], Step [18700/6235], Loss: 0.8178\n",
      "Epoch [46/100], Step [18800/6235], Loss: 123.4479\n",
      "Epoch [46/100], Step [18900/6235], Loss: 24.4650\n",
      "Epoch [46/100], Step [19000/6235], Loss: 10.2121\n",
      "Epoch [46/100], Step [19100/6235], Loss: 2.5634\n",
      "Epoch [46/100], Step [19200/6235], Loss: 4.5599\n",
      "Epoch [46/100], Step [19300/6235], Loss: 2.2331\n",
      "Epoch [46/100], Step [19400/6235], Loss: 230.0349\n",
      "Epoch [46/100], Step [19500/6235], Loss: 85.6440\n",
      "Epoch [46/100], Step [19600/6235], Loss: 63.0205\n",
      "Epoch [46/100], Step [19700/6235], Loss: 11.4066\n",
      "Epoch [46/100], Step [19800/6235], Loss: 3.4966\n",
      "Epoch [46/100], Step [19900/6235], Loss: 0.1249\n",
      "Epoch [46/100], Step [20000/6235], Loss: 69.0244\n",
      "Epoch [46/100], Step [20100/6235], Loss: 0.8079\n",
      "Epoch [46/100], Step [20200/6235], Loss: 5.1264\n",
      "Epoch [46/100], Step [20300/6235], Loss: 2.5006\n",
      "Epoch [46/100], Step [20400/6235], Loss: 13.2097\n",
      "Epoch [46/100], Step [20500/6235], Loss: 52.9381\n",
      "Epoch [46/100], Step [20600/6235], Loss: 182.8193\n",
      "Epoch [46/100], Step [20700/6235], Loss: 0.3529\n",
      "Epoch [46/100], Step [20800/6235], Loss: 19.5624\n",
      "Epoch [46/100], Step [20900/6235], Loss: 26.4901\n",
      "Epoch [46/100], Step [21000/6235], Loss: 13.4069\n",
      "Epoch [46/100], Step [21100/6235], Loss: 6.7286\n",
      "Epoch [46/100], Step [21200/6235], Loss: 0.2643\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Step [21300/6235], Loss: 0.1722\n",
      "Epoch [46/100], Step [21400/6235], Loss: 5.3439\n",
      "Epoch [46/100], Step [21500/6235], Loss: 0.2244\n",
      "Epoch [46/100], Step [21600/6235], Loss: 25.1194\n",
      "Epoch [46/100], Step [21700/6235], Loss: 0.1867\n",
      "Epoch [46/100], Step [21800/6235], Loss: 2.5880\n",
      "Epoch [46/100], Step [21900/6235], Loss: 1.7437\n",
      "Epoch [46/100], Step [22000/6235], Loss: 9.2673\n",
      "Epoch [46/100], Step [22100/6235], Loss: 0.1000\n",
      "Epoch [46/100], Step [22200/6235], Loss: 2.1052\n",
      "Epoch [46/100], Step [22300/6235], Loss: 3.2408\n",
      "Epoch [46/100], Step [22400/6235], Loss: 2.7572\n",
      "Epoch [46/100], Step [22500/6235], Loss: 69.5271\n",
      "Epoch [46/100], Step [22600/6235], Loss: 21.1609\n",
      "Epoch [46/100], Step [22700/6235], Loss: 2.1551\n",
      "Epoch [46/100], Step [22800/6235], Loss: 9.0744\n",
      "Epoch [46/100], Step [22900/6235], Loss: 15.6794\n",
      "Epoch [46/100], Step [23000/6235], Loss: 14.9167\n",
      "Epoch [46/100], Step [23100/6235], Loss: 4.6825\n",
      "Epoch [46/100], Step [23200/6235], Loss: 27.0778\n",
      "Epoch [46/100], Step [23300/6235], Loss: 17.3600\n",
      "Epoch [46/100], Step [23400/6235], Loss: 2.6963\n",
      "Epoch [46/100], Step [23500/6235], Loss: 0.1989\n",
      "Epoch [46/100], Step [23600/6235], Loss: 137.1744\n",
      "Epoch [46/100], Step [23700/6235], Loss: 2.1433\n",
      "Epoch [46/100], Step [23800/6235], Loss: 0.7234\n",
      "Epoch [46/100], Step [23900/6235], Loss: 1.6610\n",
      "Epoch [46/100], Step [24000/6235], Loss: 1.0195\n",
      "Epoch [46/100], Step [24100/6235], Loss: 0.1434\n",
      "Epoch [46/100], Step [24200/6235], Loss: 50.9081\n",
      "Epoch [46/100], Step [24300/6235], Loss: 0.8436\n",
      "Epoch [46/100], Step [24400/6235], Loss: 1.8069\n",
      "Epoch [46/100], Step [24500/6235], Loss: 0.4418\n",
      "Epoch [46/100], Step [24600/6235], Loss: 0.1448\n",
      "Epoch [46/100], Step [24700/6235], Loss: 4.4267\n",
      "Epoch [46/100], Step [24800/6235], Loss: 0.2617\n",
      "Epoch [46/100], Step [24900/6235], Loss: 14.7564\n",
      "Epoch [46/100], Step [25000/6235], Loss: 11.1832\n",
      "Epoch [46/100], Step [25100/6235], Loss: 6.6359\n",
      "Epoch [46/100], Step [25200/6235], Loss: 0.6638\n",
      "Epoch [46/100], Step [25300/6235], Loss: 0.8043\n",
      "Epoch [46/100], Step [25400/6235], Loss: 10.3956\n",
      "Epoch [46/100], Step [25500/6235], Loss: 9.1302\n",
      "Epoch [46/100], Step [25600/6235], Loss: 6.0216\n",
      "Epoch [46/100], Step [25700/6235], Loss: 0.1095\n",
      "Epoch [46/100], Step [25800/6235], Loss: 0.0982\n",
      "Epoch [46/100], Step [25900/6235], Loss: 4.9767\n",
      "Epoch [46/100], Step [26000/6235], Loss: 2.8507\n",
      "Epoch [46/100], Step [26100/6235], Loss: 0.5134\n",
      "Epoch [46/100], Step [26200/6235], Loss: 0.4042\n",
      "Epoch [46/100], Step [26300/6235], Loss: 3.9219\n",
      "Epoch [46/100], Step [26400/6235], Loss: 0.2945\n",
      "Epoch [46/100], Step [26500/6235], Loss: 0.0261\n",
      "Epoch [46/100], Step [26600/6235], Loss: 0.6522\n",
      "Epoch [46/100], Step [26700/6235], Loss: 0.2333\n",
      "Epoch [46/100], Step [26800/6235], Loss: 0.0631\n",
      "Epoch [46/100], Step [26900/6235], Loss: 0.0205\n",
      "Epoch [46/100], Step [27000/6235], Loss: 16.0951\n",
      "Epoch [46/100], Step [27100/6235], Loss: 0.0572\n",
      "Epoch [46/100], Step [27200/6235], Loss: 0.0120\n",
      "Epoch [46/100], Step [27300/6235], Loss: 0.0961\n",
      "Epoch [46/100], Step [27400/6235], Loss: 0.6908\n",
      "Epoch [46/100], Step [27500/6235], Loss: 19.0438\n",
      "Epoch [46/100], Step [27600/6235], Loss: 1.4009\n",
      "Epoch [46/100], Step [27700/6235], Loss: 1.3435\n",
      "Epoch [46/100], Step [27800/6235], Loss: 6.6157\n",
      "Epoch [46/100], Step [27900/6235], Loss: 0.5208\n",
      "Epoch [46/100], Step [28000/6235], Loss: 110.2479\n",
      "Epoch [46/100], Step [28100/6235], Loss: 0.8701\n",
      "Epoch [46/100], Step [28200/6235], Loss: 35.4990\n",
      "Epoch [46/100], Step [28300/6235], Loss: 2.6690\n",
      "Epoch [46/100], Step [28400/6235], Loss: 25.9812\n",
      "Epoch [46/100], Step [28500/6235], Loss: 4.9387\n",
      "Epoch [46/100], Step [28600/6235], Loss: 0.1433\n",
      "Epoch [46/100], Step [28700/6235], Loss: 5.3775\n",
      "Epoch [46/100], Step [28800/6235], Loss: 0.6281\n",
      "Epoch [46/100], Step [28900/6235], Loss: 67.3976\n",
      "Epoch [46/100], Step [29000/6235], Loss: 9.9919\n",
      "Epoch [46/100], Step [29100/6235], Loss: 0.3677\n",
      "Epoch [46/100], Step [29200/6235], Loss: 2.0140\n",
      "Epoch [46/100], Step [29300/6235], Loss: 2.4474\n",
      "Epoch [46/100], Step [29400/6235], Loss: 0.2411\n",
      "Epoch [46/100], Step [29500/6235], Loss: 0.7077\n",
      "Epoch [46/100], Step [29600/6235], Loss: 0.1776\n",
      "Epoch [46/100], Step [29700/6235], Loss: 1.7899\n",
      "Epoch [46/100], Step [29800/6235], Loss: 1.4250\n",
      "Epoch [46/100], Step [29900/6235], Loss: 1.0494\n",
      "Epoch [46/100], Step [30000/6235], Loss: 6.9410\n",
      "Epoch [46/100], Step [30100/6235], Loss: 11.1960\n",
      "Epoch [46/100], Step [30200/6235], Loss: 1.3583\n",
      "Epoch [46/100], Step [30300/6235], Loss: 0.0339\n",
      "Epoch [46/100], Step [30400/6235], Loss: 1.2571\n",
      "Epoch [46/100], Step [30500/6235], Loss: 2.9724\n",
      "Epoch [46/100], Step [30600/6235], Loss: 1.8278\n",
      "Epoch [46/100], Step [30700/6235], Loss: 0.7068\n",
      "Epoch [46/100], Step [30800/6235], Loss: 0.5262\n",
      "Epoch [46/100], Step [30900/6235], Loss: 3.7428\n",
      "Epoch [46/100], Step [31000/6235], Loss: 0.1872\n",
      "Epoch [46/100], Step [31100/6235], Loss: 0.0670\n",
      "Epoch [46/100], Step [31200/6235], Loss: 6.4059\n",
      "Epoch [46/100], Step [31300/6235], Loss: 2.0671\n",
      "Epoch [46/100], Step [31400/6235], Loss: 8.2450\n",
      "Epoch [46/100], Step [31500/6235], Loss: 1.5538\n",
      "Epoch [46/100], Step [31600/6235], Loss: 5.9510\n",
      "Epoch [46/100], Step [31700/6235], Loss: 9.8927\n",
      "Epoch [46/100], Step [31800/6235], Loss: 1.6057\n",
      "Epoch [46/100], Step [31900/6235], Loss: 34.4045\n",
      "Epoch [46/100], Step [32000/6235], Loss: 17.6253\n",
      "Epoch [46/100], Step [32100/6235], Loss: 0.7432\n",
      "Epoch [46/100], Step [32200/6235], Loss: 152.2599\n",
      "Epoch [46/100], Step [32300/6235], Loss: 1.0920\n",
      "Epoch [46/100], Step [32400/6235], Loss: 1.4088\n",
      "Epoch [46/100], Step [32500/6235], Loss: 10.1838\n",
      "Epoch [46/100], Step [32600/6235], Loss: 0.3501\n",
      "Epoch [46/100], Step [32700/6235], Loss: 110.1227\n",
      "Epoch [46/100], Step [32800/6235], Loss: 2.5365\n",
      "Epoch [46/100], Step [32900/6235], Loss: 0.8696\n",
      "Epoch [46/100], Step [33000/6235], Loss: 0.4002\n",
      "Epoch [46/100], Step [33100/6235], Loss: 0.5595\n",
      "Epoch [46/100], Step [33200/6235], Loss: 0.9860\n",
      "Epoch [46/100], Step [33300/6235], Loss: 0.9632\n",
      "Epoch [46/100], Step [33400/6235], Loss: 135.7566\n",
      "Epoch [46/100], Step [33500/6235], Loss: 2.1266\n",
      "Epoch [46/100], Step [33600/6235], Loss: 6.7804\n",
      "Epoch [46/100], Step [33700/6235], Loss: 5.7678\n",
      "Epoch [46/100], Step [33800/6235], Loss: 1.8859\n",
      "Epoch [46/100], Step [33900/6235], Loss: 26.0431\n",
      "Epoch [46/100], Step [34000/6235], Loss: 0.0464\n",
      "Epoch [46/100], Step [34100/6235], Loss: 0.4428\n",
      "Epoch [46/100], Step [34200/6235], Loss: 2.5650\n",
      "Epoch [46/100], Step [34300/6235], Loss: 4.2732\n",
      "Epoch [46/100], Step [34400/6235], Loss: 0.2201\n",
      "Epoch [46/100], Step [34500/6235], Loss: 28.0485\n",
      "Epoch [46/100], Step [34600/6235], Loss: 0.5133\n",
      "Epoch [46/100], Step [34700/6235], Loss: 28.1591\n",
      "Epoch [46/100], Step [34800/6235], Loss: 7.6770\n",
      "Epoch [46/100], Step [34900/6235], Loss: 58.2391\n",
      "Epoch [46/100], Step [35000/6235], Loss: 0.1221\n",
      "Epoch [46/100], Step [35100/6235], Loss: 0.4865\n",
      "Epoch [46/100], Step [35200/6235], Loss: 0.2229\n",
      "Epoch [46/100], Step [35300/6235], Loss: 2.5363\n",
      "Epoch [46/100], Step [35400/6235], Loss: 0.4826\n",
      "Epoch [46/100], Step [35500/6235], Loss: 2.1030\n",
      "Epoch [46/100], Step [35600/6235], Loss: 1.3096\n",
      "Epoch [46/100], Step [35700/6235], Loss: 6.1582\n",
      "Epoch [46/100], Step [35800/6235], Loss: 2.8122\n",
      "Epoch [46/100], Step [35900/6235], Loss: 0.6880\n",
      "Epoch [46/100], Step [36000/6235], Loss: 0.0908\n",
      "Epoch [46/100], Step [36100/6235], Loss: 0.0502\n",
      "Epoch [46/100], Step [36200/6235], Loss: 23.2293\n",
      "Epoch [46/100], Step [36300/6235], Loss: 0.3463\n",
      "Epoch [46/100], Step [36400/6235], Loss: 2.6079\n",
      "Epoch [46/100], Step [36500/6235], Loss: 8.7606\n",
      "Epoch [46/100], Step [36600/6235], Loss: 0.1333\n",
      "Epoch [46/100], Step [36700/6235], Loss: 0.4549\n",
      "Epoch [46/100], Step [36800/6235], Loss: 11.3041\n",
      "Epoch [46/100], Step [36900/6235], Loss: 6.2566\n",
      "Epoch [46/100], Step [37000/6235], Loss: 0.5896\n",
      "Epoch [46/100], Step [37100/6235], Loss: 1.2210\n",
      "Epoch [46/100], Step [37200/6235], Loss: 0.0853\n",
      "Epoch [46/100], Step [37300/6235], Loss: 0.0403\n",
      "Epoch [46/100], Step [37400/6235], Loss: 0.2005\n",
      "Epoch [46/100], Step [37500/6235], Loss: 4.9973\n",
      "Epoch [46/100], Step [37600/6235], Loss: 11.8756\n",
      "Epoch [46/100], Step [37700/6235], Loss: 1.8243\n",
      "Epoch [46/100], Step [37800/6235], Loss: 4.0602\n",
      "Epoch [46/100], Step [37900/6235], Loss: 6.8178\n",
      "Epoch [46/100], Step [38000/6235], Loss: 0.5783\n",
      "Epoch [46/100], Step [38100/6235], Loss: 4.3047\n",
      "Epoch [46/100], Step [38200/6235], Loss: 1.3162\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [46/100], Step [38300/6235], Loss: 0.4048\n",
      "Epoch [46/100], Step [38400/6235], Loss: 0.0764\n",
      "Epoch [46/100], Step [38500/6235], Loss: 1.8880\n",
      "Epoch [46/100], Step [38600/6235], Loss: 0.1244\n",
      "Epoch [46/100], Step [38700/6235], Loss: 0.0841\n",
      "Epoch [46/100], Step [38800/6235], Loss: 0.1674\n",
      "Epoch [46/100], Step [38900/6235], Loss: 2.4380\n",
      "Epoch [46/100], Step [39000/6235], Loss: 13.3671\n",
      "Epoch [46/100], Step [39100/6235], Loss: 17.5582\n",
      "Epoch [46/100], Step [39200/6235], Loss: 0.7319\n",
      "Epoch [46/100], Step [39300/6235], Loss: 16.4389\n",
      "Epoch [46/100], Step [39400/6235], Loss: 406.8159\n",
      "Epoch [46/100], Step [39500/6235], Loss: 6.9100\n",
      "Epoch [46/100], Step [39600/6235], Loss: 17.7890\n",
      "Epoch [46/100], Step [39700/6235], Loss: 621.1299\n",
      "Epoch [46/100], Step [39800/6235], Loss: 197.1854\n",
      "Epoch [46/100], Step [39900/6235], Loss: 0.4610\n",
      "Epoch [46/100], Step [40000/6235], Loss: 3.4809\n",
      "Epoch [46/100], Step [40100/6235], Loss: 25.6386\n",
      "Epoch [46/100], Step [40200/6235], Loss: 3.3337\n",
      "Epoch [46/100], Step [40300/6235], Loss: 1.0403\n",
      "Epoch [46/100], Step [40400/6235], Loss: 2.5686\n",
      "Epoch [46/100], Step [40500/6235], Loss: 2.2429\n",
      "Epoch [46/100], Step [40600/6235], Loss: 0.2939\n",
      "Epoch [46/100], Step [40700/6235], Loss: 7.6474\n",
      "Epoch [46/100], Step [40800/6235], Loss: 1.5442\n",
      "Epoch [46/100], Step [40900/6235], Loss: 0.0904\n",
      "Epoch [46/100], Step [41000/6235], Loss: 45.9210\n",
      "Epoch [46/100], Step [41100/6235], Loss: 24.1003\n",
      "Epoch [46/100], Step [41200/6235], Loss: 28.5448\n",
      "Epoch [46/100], Step [41300/6235], Loss: 7.1978\n",
      "Epoch [46/100], Step [41400/6235], Loss: 2.8094\n",
      "Epoch [46/100], Step [41500/6235], Loss: 0.3040\n",
      "Epoch [46/100], Step [41600/6235], Loss: 0.7694\n",
      "Epoch [46/100], Step [41700/6235], Loss: 1.6838\n",
      "Epoch [46/100], Step [41800/6235], Loss: 0.5668\n",
      "Epoch [46/100], Step [41900/6235], Loss: 0.1648\n",
      "Epoch [46/100], Step [42000/6235], Loss: 4.7661\n",
      "Epoch [46/100], Step [42100/6235], Loss: 1.0353\n",
      "Epoch [46/100], Step [42200/6235], Loss: 83.6455\n",
      "Epoch [46/100], Step [42300/6235], Loss: 4.8567\n",
      "Epoch [46/100], Step [42400/6235], Loss: 0.3993\n",
      "Epoch [46/100], Step [42500/6235], Loss: 1.8455\n",
      "Epoch [46/100], Step [42600/6235], Loss: 0.4524\n",
      "Epoch [46/100], Step [42700/6235], Loss: 0.3562\n",
      "Epoch [46/100], Step [42800/6235], Loss: 0.1111\n",
      "Epoch [46/100], Step [42900/6235], Loss: 4.1062\n",
      "Epoch [46/100], Step [43000/6235], Loss: 0.4542\n",
      "Epoch [46/100], Step [43100/6235], Loss: 2.3992\n",
      "Epoch [46/100], Step [43200/6235], Loss: 0.3095\n",
      "Epoch [46/100], Step [43300/6235], Loss: 12.0216\n",
      "Epoch [46/100], Step [43400/6235], Loss: 5.8269\n",
      "Epoch [46/100], Step [43500/6235], Loss: 4.4287\n",
      "Epoch [46/100], Step [43600/6235], Loss: 42.5163\n",
      "Epoch [46/100], Step [43700/6235], Loss: 12.0696\n",
      "Epoch [46/100], Step [43800/6235], Loss: 2.7168\n",
      "Epoch [46/100], Step [43900/6235], Loss: 1.1165\n",
      "Epoch [46/100], Step [44000/6235], Loss: 29.3510\n",
      "Epoch [46/100], Step [44100/6235], Loss: 1.3914\n",
      "Epoch [46/100], Step [44200/6235], Loss: 35.7788\n",
      "Epoch [46/100], Step [44300/6235], Loss: 52.3533\n",
      "Epoch [46/100], Step [44400/6235], Loss: 1.7822\n",
      "Epoch [46/100], Step [44500/6235], Loss: 0.3965\n",
      "Epoch [46/100], Step [44600/6235], Loss: 11.8873\n",
      "Epoch [46/100], Step [44700/6235], Loss: 7.9738\n",
      "Epoch [46/100], Step [44800/6235], Loss: 2.9240\n",
      "Epoch [46/100], Step [44900/6235], Loss: 0.5442\n",
      "Epoch [46/100], Step [45000/6235], Loss: 1.5442\n",
      "Epoch [46/100], Step [45100/6235], Loss: 19.5173\n",
      "Epoch [46/100], Step [45200/6235], Loss: 0.5391\n",
      "Epoch [46/100], Step [45300/6235], Loss: 0.3369\n",
      "Epoch [46/100], Step [45400/6235], Loss: 4.6954\n",
      "Epoch [46/100], Step [45500/6235], Loss: 0.1311\n",
      "Epoch [46/100], Step [45600/6235], Loss: 1.5755\n",
      "Epoch [46/100], Step [45700/6235], Loss: 0.5386\n",
      "Epoch [46/100], Step [45800/6235], Loss: 345.4208\n",
      "Epoch [46/100], Step [45900/6235], Loss: 4.7148\n",
      "Epoch [46/100], Step [46000/6235], Loss: 25.1346\n",
      "Epoch [46/100], Step [46100/6235], Loss: 121.7682\n",
      "Epoch [46/100], Step [46200/6235], Loss: 8.5162\n",
      "Epoch [46/100], Step [46300/6235], Loss: 90.5791\n",
      "Epoch [46/100], Step [46400/6235], Loss: 1.7076\n",
      "Epoch [46/100], Step [46500/6235], Loss: 1.3056\n",
      "Epoch [46/100], Step [46600/6235], Loss: 19.5857\n",
      "Epoch [46/100], Step [46700/6235], Loss: 0.9452\n",
      "Epoch [46/100], Step [46800/6235], Loss: 25.7688\n",
      "Epoch [46/100], Step [46900/6235], Loss: 23.2593\n",
      "Epoch [46/100], Step [47000/6235], Loss: 0.6038\n",
      "Epoch [46/100], Step [47100/6235], Loss: 65.9874\n",
      "Epoch [46/100], Step [47200/6235], Loss: 86.1814\n",
      "Epoch [46/100], Step [47300/6235], Loss: 0.8625\n",
      "Epoch [46/100], Step [47400/6235], Loss: 286.6626\n",
      "Epoch [46/100], Step [47500/6235], Loss: 28.0511\n",
      "Epoch [46/100], Step [47600/6235], Loss: 16.2471\n",
      "Epoch [46/100], Step [47700/6235], Loss: 23.7171\n",
      "Epoch [46/100], Step [47800/6235], Loss: 35.0337\n",
      "Epoch [46/100], Step [47900/6235], Loss: 15.2993\n",
      "Epoch [46/100], Step [48000/6235], Loss: 78.6323\n",
      "Epoch [46/100], Step [48100/6235], Loss: 15.8254\n",
      "Epoch [46/100], Step [48200/6235], Loss: 111.9715\n",
      "Epoch [46/100], Step [48300/6235], Loss: 392.2502\n",
      "Epoch [46/100], Step [48400/6235], Loss: 25.2201\n",
      "Epoch [46/100], Step [48500/6235], Loss: 19.4051\n",
      "Epoch [46/100], Step [48600/6235], Loss: 17.8248\n",
      "Epoch [46/100], Step [48700/6235], Loss: 22.1290\n",
      "Epoch [46/100], Step [48800/6235], Loss: 247.7323\n",
      "Epoch [46/100], Step [48900/6235], Loss: 729.2451\n",
      "Epoch [46/100], Step [49000/6235], Loss: 224.2018\n",
      "Epoch [46/100], Step [49100/6235], Loss: 3527.4954\n",
      "Epoch [46/100], Step [49200/6235], Loss: 799.0332\n",
      "Epoch [46/100], Step [49300/6235], Loss: 1143.8441\n",
      "Epoch [46/100], Step [49400/6235], Loss: 144.8131\n",
      "Epoch [46/100], Step [49500/6235], Loss: 1.1733\n",
      "Epoch [46/100], Step [49600/6235], Loss: 1384.6132\n",
      "Epoch [46/100], Step [49700/6235], Loss: 179.4463\n",
      "Epoch [46/100], Step [49800/6235], Loss: 123.0034\n",
      "Epoch [47/100], Step [100/6235], Loss: 9.4296\n",
      "Epoch [47/100], Step [200/6235], Loss: 0.1364\n",
      "Epoch [47/100], Step [300/6235], Loss: 0.1006\n",
      "Epoch [47/100], Step [400/6235], Loss: 0.0172\n",
      "Epoch [47/100], Step [500/6235], Loss: 24.6283\n",
      "Epoch [47/100], Step [600/6235], Loss: 0.0514\n",
      "Epoch [47/100], Step [700/6235], Loss: 0.7175\n",
      "Epoch [47/100], Step [800/6235], Loss: 0.0608\n",
      "Epoch [47/100], Step [900/6235], Loss: 0.1038\n",
      "Epoch [47/100], Step [1000/6235], Loss: 0.0240\n",
      "Epoch [47/100], Step [1100/6235], Loss: 0.1133\n",
      "Epoch [47/100], Step [1200/6235], Loss: 0.1458\n",
      "Epoch [47/100], Step [1300/6235], Loss: 0.0100\n",
      "Epoch [47/100], Step [1400/6235], Loss: 0.0697\n",
      "Epoch [47/100], Step [1500/6235], Loss: 0.0053\n",
      "Epoch [47/100], Step [1600/6235], Loss: 0.2388\n",
      "Epoch [47/100], Step [1700/6235], Loss: 0.3007\n",
      "Epoch [47/100], Step [1800/6235], Loss: 0.3208\n",
      "Epoch [47/100], Step [1900/6235], Loss: 0.2795\n",
      "Epoch [47/100], Step [2000/6235], Loss: 1.9849\n",
      "Epoch [47/100], Step [2100/6235], Loss: 3.2985\n",
      "Epoch [47/100], Step [2200/6235], Loss: 4.0038\n",
      "Epoch [47/100], Step [2300/6235], Loss: 1.8228\n",
      "Epoch [47/100], Step [2400/6235], Loss: 2.5528\n",
      "Epoch [47/100], Step [2500/6235], Loss: 9.5567\n",
      "Epoch [47/100], Step [2600/6235], Loss: 17.4092\n",
      "Epoch [47/100], Step [2700/6235], Loss: 19.1801\n",
      "Epoch [47/100], Step [2800/6235], Loss: 367.6565\n",
      "Epoch [47/100], Step [2900/6235], Loss: 8.8057\n",
      "Epoch [47/100], Step [3000/6235], Loss: 0.4683\n",
      "Epoch [47/100], Step [3100/6235], Loss: 88.7648\n",
      "Epoch [47/100], Step [3200/6235], Loss: 18.9086\n",
      "Epoch [47/100], Step [3300/6235], Loss: 2.2598\n",
      "Epoch [47/100], Step [3400/6235], Loss: 7.2804\n",
      "Epoch [47/100], Step [3500/6235], Loss: 62.8167\n",
      "Epoch [47/100], Step [3600/6235], Loss: 0.3459\n",
      "Epoch [47/100], Step [3700/6235], Loss: 0.3735\n",
      "Epoch [47/100], Step [3800/6235], Loss: 0.1279\n",
      "Epoch [47/100], Step [3900/6235], Loss: 0.8117\n",
      "Epoch [47/100], Step [4000/6235], Loss: 0.2373\n",
      "Epoch [47/100], Step [4100/6235], Loss: 9.1835\n",
      "Epoch [47/100], Step [4200/6235], Loss: 5.4236\n",
      "Epoch [47/100], Step [4300/6235], Loss: 4.6937\n",
      "Epoch [47/100], Step [4400/6235], Loss: 0.3571\n",
      "Epoch [47/100], Step [4500/6235], Loss: 47.3081\n",
      "Epoch [47/100], Step [4600/6235], Loss: 11.6473\n",
      "Epoch [47/100], Step [4700/6235], Loss: 0.1456\n",
      "Epoch [47/100], Step [4800/6235], Loss: 3.4866\n",
      "Epoch [47/100], Step [4900/6235], Loss: 4.7753\n",
      "Epoch [47/100], Step [5000/6235], Loss: 0.1651\n",
      "Epoch [47/100], Step [5100/6235], Loss: 4.2721\n",
      "Epoch [47/100], Step [5200/6235], Loss: 8.9606\n",
      "Epoch [47/100], Step [5300/6235], Loss: 10.9126\n",
      "Epoch [47/100], Step [5400/6235], Loss: 2.4539\n",
      "Epoch [47/100], Step [5500/6235], Loss: 0.2755\n",
      "Epoch [47/100], Step [5600/6235], Loss: 0.1901\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Step [5700/6235], Loss: 0.1103\n",
      "Epoch [47/100], Step [5800/6235], Loss: 0.4012\n",
      "Epoch [47/100], Step [5900/6235], Loss: 0.0118\n",
      "Epoch [47/100], Step [6000/6235], Loss: 1.7920\n",
      "Epoch [47/100], Step [6100/6235], Loss: 0.1517\n",
      "Epoch [47/100], Step [6200/6235], Loss: 7.0099\n",
      "Epoch [47/100], Step [6300/6235], Loss: 1.1328\n",
      "Epoch [47/100], Step [6400/6235], Loss: 0.0390\n",
      "Epoch [47/100], Step [6500/6235], Loss: 0.6161\n",
      "Epoch [47/100], Step [6600/6235], Loss: 21.5765\n",
      "Epoch [47/100], Step [6700/6235], Loss: 0.9531\n",
      "Epoch [47/100], Step [6800/6235], Loss: 0.6125\n",
      "Epoch [47/100], Step [6900/6235], Loss: 0.3250\n",
      "Epoch [47/100], Step [7000/6235], Loss: 0.0833\n",
      "Epoch [47/100], Step [7100/6235], Loss: 0.5323\n",
      "Epoch [47/100], Step [7200/6235], Loss: 1.5363\n",
      "Epoch [47/100], Step [7300/6235], Loss: 0.4204\n",
      "Epoch [47/100], Step [7400/6235], Loss: 0.1125\n",
      "Epoch [47/100], Step [7500/6235], Loss: 0.7677\n",
      "Epoch [47/100], Step [7600/6235], Loss: 4.7297\n",
      "Epoch [47/100], Step [7700/6235], Loss: 10.0137\n",
      "Epoch [47/100], Step [7800/6235], Loss: 1.8638\n",
      "Epoch [47/100], Step [7900/6235], Loss: 22.8204\n",
      "Epoch [47/100], Step [8000/6235], Loss: 0.3494\n",
      "Epoch [47/100], Step [8100/6235], Loss: 0.6798\n",
      "Epoch [47/100], Step [8200/6235], Loss: 9.9670\n",
      "Epoch [47/100], Step [8300/6235], Loss: 23.4039\n",
      "Epoch [47/100], Step [8400/6235], Loss: 651.1852\n",
      "Epoch [47/100], Step [8500/6235], Loss: 19.8358\n",
      "Epoch [47/100], Step [8600/6235], Loss: 25.2253\n",
      "Epoch [47/100], Step [8700/6235], Loss: 45.8178\n",
      "Epoch [47/100], Step [8800/6235], Loss: 442.7196\n",
      "Epoch [47/100], Step [8900/6235], Loss: 328.1966\n",
      "Epoch [47/100], Step [9000/6235], Loss: 656.1250\n",
      "Epoch [47/100], Step [9100/6235], Loss: 455.2260\n",
      "Epoch [47/100], Step [9200/6235], Loss: 560.8000\n",
      "Epoch [47/100], Step [9300/6235], Loss: 303.2514\n",
      "Epoch [47/100], Step [9400/6235], Loss: 56.4492\n",
      "Epoch [47/100], Step [9500/6235], Loss: 2470.7280\n",
      "Epoch [47/100], Step [9600/6235], Loss: 564.8174\n",
      "Epoch [47/100], Step [9700/6235], Loss: 8.9910\n",
      "Epoch [47/100], Step [9800/6235], Loss: 3366.4697\n",
      "Epoch [47/100], Step [9900/6235], Loss: 17.4612\n",
      "Epoch [47/100], Step [10000/6235], Loss: 279.4507\n",
      "Epoch [47/100], Step [10100/6235], Loss: 3.9959\n",
      "Epoch [47/100], Step [10200/6235], Loss: 525.3673\n",
      "Epoch [47/100], Step [10300/6235], Loss: 5.7853\n",
      "Epoch [47/100], Step [10400/6235], Loss: 1.8003\n",
      "Epoch [47/100], Step [10500/6235], Loss: 3.0372\n",
      "Epoch [47/100], Step [10600/6235], Loss: 43.7290\n",
      "Epoch [47/100], Step [10700/6235], Loss: 68.8990\n",
      "Epoch [47/100], Step [10800/6235], Loss: 8.4647\n",
      "Epoch [47/100], Step [10900/6235], Loss: 7.9938\n",
      "Epoch [47/100], Step [11000/6235], Loss: 262.7978\n",
      "Epoch [47/100], Step [11100/6235], Loss: 13.3057\n",
      "Epoch [47/100], Step [11200/6235], Loss: 79.7451\n",
      "Epoch [47/100], Step [11300/6235], Loss: 204.7656\n",
      "Epoch [47/100], Step [11400/6235], Loss: 4.3930\n",
      "Epoch [47/100], Step [11500/6235], Loss: 0.9843\n",
      "Epoch [47/100], Step [11600/6235], Loss: 0.7297\n",
      "Epoch [47/100], Step [11700/6235], Loss: 39.4087\n",
      "Epoch [47/100], Step [11800/6235], Loss: 309.4268\n",
      "Epoch [47/100], Step [11900/6235], Loss: 161.1832\n",
      "Epoch [47/100], Step [12000/6235], Loss: 723.9786\n",
      "Epoch [47/100], Step [12100/6235], Loss: 239.6016\n",
      "Epoch [47/100], Step [12200/6235], Loss: 3.8391\n",
      "Epoch [47/100], Step [12300/6235], Loss: 1.3601\n",
      "Epoch [47/100], Step [12400/6235], Loss: 225.4763\n",
      "Epoch [47/100], Step [12500/6235], Loss: 58.9265\n",
      "Epoch [47/100], Step [12600/6235], Loss: 10.0683\n",
      "Epoch [47/100], Step [12700/6235], Loss: 9.1428\n",
      "Epoch [47/100], Step [12800/6235], Loss: 12.6986\n",
      "Epoch [47/100], Step [12900/6235], Loss: 38.0263\n",
      "Epoch [47/100], Step [13000/6235], Loss: 0.7956\n",
      "Epoch [47/100], Step [13100/6235], Loss: 66.1517\n",
      "Epoch [47/100], Step [13200/6235], Loss: 6.1300\n",
      "Epoch [47/100], Step [13300/6235], Loss: 17.6738\n",
      "Epoch [47/100], Step [13400/6235], Loss: 235.5506\n",
      "Epoch [47/100], Step [13500/6235], Loss: 0.4549\n",
      "Epoch [47/100], Step [13600/6235], Loss: 8.9290\n",
      "Epoch [47/100], Step [13700/6235], Loss: 213.0855\n",
      "Epoch [47/100], Step [13800/6235], Loss: 90.1203\n",
      "Epoch [47/100], Step [13900/6235], Loss: 113.3730\n",
      "Epoch [47/100], Step [14000/6235], Loss: 0.4944\n",
      "Epoch [47/100], Step [14100/6235], Loss: 44.2578\n",
      "Epoch [47/100], Step [14200/6235], Loss: 112.2806\n",
      "Epoch [47/100], Step [14300/6235], Loss: 16.1906\n",
      "Epoch [47/100], Step [14400/6235], Loss: 38.9067\n",
      "Epoch [47/100], Step [14500/6235], Loss: 31.7840\n",
      "Epoch [47/100], Step [14600/6235], Loss: 1.2231\n",
      "Epoch [47/100], Step [14700/6235], Loss: 34.2516\n",
      "Epoch [47/100], Step [14800/6235], Loss: 32.4715\n",
      "Epoch [47/100], Step [14900/6235], Loss: 0.7554\n",
      "Epoch [47/100], Step [15000/6235], Loss: 1.5244\n",
      "Epoch [47/100], Step [15100/6235], Loss: 0.5563\n",
      "Epoch [47/100], Step [15200/6235], Loss: 2.4722\n",
      "Epoch [47/100], Step [15300/6235], Loss: 29.4481\n",
      "Epoch [47/100], Step [15400/6235], Loss: 94.3254\n",
      "Epoch [47/100], Step [15500/6235], Loss: 16.8185\n",
      "Epoch [47/100], Step [15600/6235], Loss: 136.2123\n",
      "Epoch [47/100], Step [15700/6235], Loss: 142.9998\n",
      "Epoch [47/100], Step [15800/6235], Loss: 8.3963\n",
      "Epoch [47/100], Step [15900/6235], Loss: 1.2240\n",
      "Epoch [47/100], Step [16000/6235], Loss: 138.0846\n",
      "Epoch [47/100], Step [16100/6235], Loss: 0.4566\n",
      "Epoch [47/100], Step [16200/6235], Loss: 0.3120\n",
      "Epoch [47/100], Step [16300/6235], Loss: 9.6322\n",
      "Epoch [47/100], Step [16400/6235], Loss: 28.4343\n",
      "Epoch [47/100], Step [16500/6235], Loss: 568.9370\n",
      "Epoch [47/100], Step [16600/6235], Loss: 18.0417\n",
      "Epoch [47/100], Step [16700/6235], Loss: 0.3883\n",
      "Epoch [47/100], Step [16800/6235], Loss: 13.9193\n",
      "Epoch [47/100], Step [16900/6235], Loss: 0.1118\n",
      "Epoch [47/100], Step [17000/6235], Loss: 0.2601\n",
      "Epoch [47/100], Step [17100/6235], Loss: 0.4037\n",
      "Epoch [47/100], Step [17200/6235], Loss: 305.9569\n",
      "Epoch [47/100], Step [17300/6235], Loss: 28.5243\n",
      "Epoch [47/100], Step [17400/6235], Loss: 32.3263\n",
      "Epoch [47/100], Step [17500/6235], Loss: 0.6197\n",
      "Epoch [47/100], Step [17600/6235], Loss: 4.3374\n",
      "Epoch [47/100], Step [17700/6235], Loss: 0.9263\n",
      "Epoch [47/100], Step [17800/6235], Loss: 15.4616\n",
      "Epoch [47/100], Step [17900/6235], Loss: 6.8319\n",
      "Epoch [47/100], Step [18000/6235], Loss: 2.2517\n",
      "Epoch [47/100], Step [18100/6235], Loss: 15.2656\n",
      "Epoch [47/100], Step [18200/6235], Loss: 0.2877\n",
      "Epoch [47/100], Step [18300/6235], Loss: 0.8136\n",
      "Epoch [47/100], Step [18400/6235], Loss: 0.4373\n",
      "Epoch [47/100], Step [18500/6235], Loss: 18.2328\n",
      "Epoch [47/100], Step [18600/6235], Loss: 4.6832\n",
      "Epoch [47/100], Step [18700/6235], Loss: 1.0539\n",
      "Epoch [47/100], Step [18800/6235], Loss: 140.1131\n",
      "Epoch [47/100], Step [18900/6235], Loss: 65.2246\n",
      "Epoch [47/100], Step [19000/6235], Loss: 1.9454\n",
      "Epoch [47/100], Step [19100/6235], Loss: 5.5424\n",
      "Epoch [47/100], Step [19200/6235], Loss: 1.8667\n",
      "Epoch [47/100], Step [19300/6235], Loss: 3.0041\n",
      "Epoch [47/100], Step [19400/6235], Loss: 121.2773\n",
      "Epoch [47/100], Step [19500/6235], Loss: 174.8553\n",
      "Epoch [47/100], Step [19600/6235], Loss: 117.3949\n",
      "Epoch [47/100], Step [19700/6235], Loss: 7.9050\n",
      "Epoch [47/100], Step [19800/6235], Loss: 1.4709\n",
      "Epoch [47/100], Step [19900/6235], Loss: 0.5577\n",
      "Epoch [47/100], Step [20000/6235], Loss: 90.3290\n",
      "Epoch [47/100], Step [20100/6235], Loss: 5.6344\n",
      "Epoch [47/100], Step [20200/6235], Loss: 4.8636\n",
      "Epoch [47/100], Step [20300/6235], Loss: 0.6473\n",
      "Epoch [47/100], Step [20400/6235], Loss: 26.7790\n",
      "Epoch [47/100], Step [20500/6235], Loss: 34.4345\n",
      "Epoch [47/100], Step [20600/6235], Loss: 90.9908\n",
      "Epoch [47/100], Step [20700/6235], Loss: 2.7988\n",
      "Epoch [47/100], Step [20800/6235], Loss: 32.0423\n",
      "Epoch [47/100], Step [20900/6235], Loss: 24.0586\n",
      "Epoch [47/100], Step [21000/6235], Loss: 13.7025\n",
      "Epoch [47/100], Step [21100/6235], Loss: 3.9701\n",
      "Epoch [47/100], Step [21200/6235], Loss: 0.3542\n",
      "Epoch [47/100], Step [21300/6235], Loss: 0.1170\n",
      "Epoch [47/100], Step [21400/6235], Loss: 4.6101\n",
      "Epoch [47/100], Step [21500/6235], Loss: 2.2237\n",
      "Epoch [47/100], Step [21600/6235], Loss: 32.5511\n",
      "Epoch [47/100], Step [21700/6235], Loss: 0.1622\n",
      "Epoch [47/100], Step [21800/6235], Loss: 5.2231\n",
      "Epoch [47/100], Step [21900/6235], Loss: 1.6989\n",
      "Epoch [47/100], Step [22000/6235], Loss: 9.5827\n",
      "Epoch [47/100], Step [22100/6235], Loss: 0.0955\n",
      "Epoch [47/100], Step [22200/6235], Loss: 3.8978\n",
      "Epoch [47/100], Step [22300/6235], Loss: 1.8388\n",
      "Epoch [47/100], Step [22400/6235], Loss: 7.4444\n",
      "Epoch [47/100], Step [22500/6235], Loss: 169.6017\n",
      "Epoch [47/100], Step [22600/6235], Loss: 11.0396\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Step [22700/6235], Loss: 0.9643\n",
      "Epoch [47/100], Step [22800/6235], Loss: 6.6150\n",
      "Epoch [47/100], Step [22900/6235], Loss: 3.1533\n",
      "Epoch [47/100], Step [23000/6235], Loss: 7.1202\n",
      "Epoch [47/100], Step [23100/6235], Loss: 6.9453\n",
      "Epoch [47/100], Step [23200/6235], Loss: 6.2371\n",
      "Epoch [47/100], Step [23300/6235], Loss: 19.8604\n",
      "Epoch [47/100], Step [23400/6235], Loss: 2.5661\n",
      "Epoch [47/100], Step [23500/6235], Loss: 0.0703\n",
      "Epoch [47/100], Step [23600/6235], Loss: 133.4553\n",
      "Epoch [47/100], Step [23700/6235], Loss: 6.4106\n",
      "Epoch [47/100], Step [23800/6235], Loss: 1.1964\n",
      "Epoch [47/100], Step [23900/6235], Loss: 1.3952\n",
      "Epoch [47/100], Step [24000/6235], Loss: 1.7179\n",
      "Epoch [47/100], Step [24100/6235], Loss: 0.2077\n",
      "Epoch [47/100], Step [24200/6235], Loss: 34.5713\n",
      "Epoch [47/100], Step [24300/6235], Loss: 0.5999\n",
      "Epoch [47/100], Step [24400/6235], Loss: 1.1345\n",
      "Epoch [47/100], Step [24500/6235], Loss: 0.4445\n",
      "Epoch [47/100], Step [24600/6235], Loss: 0.0951\n",
      "Epoch [47/100], Step [24700/6235], Loss: 1.8016\n",
      "Epoch [47/100], Step [24800/6235], Loss: 0.4656\n",
      "Epoch [47/100], Step [24900/6235], Loss: 8.9555\n",
      "Epoch [47/100], Step [25000/6235], Loss: 8.7632\n",
      "Epoch [47/100], Step [25100/6235], Loss: 6.9131\n",
      "Epoch [47/100], Step [25200/6235], Loss: 0.0066\n",
      "Epoch [47/100], Step [25300/6235], Loss: 1.3021\n",
      "Epoch [47/100], Step [25400/6235], Loss: 8.3265\n",
      "Epoch [47/100], Step [25500/6235], Loss: 9.2683\n",
      "Epoch [47/100], Step [25600/6235], Loss: 7.4493\n",
      "Epoch [47/100], Step [25700/6235], Loss: 0.0511\n",
      "Epoch [47/100], Step [25800/6235], Loss: 0.4133\n",
      "Epoch [47/100], Step [25900/6235], Loss: 3.4477\n",
      "Epoch [47/100], Step [26000/6235], Loss: 0.2335\n",
      "Epoch [47/100], Step [26100/6235], Loss: 0.0809\n",
      "Epoch [47/100], Step [26200/6235], Loss: 1.4188\n",
      "Epoch [47/100], Step [26300/6235], Loss: 1.7012\n",
      "Epoch [47/100], Step [26400/6235], Loss: 0.5775\n",
      "Epoch [47/100], Step [26500/6235], Loss: 0.0522\n",
      "Epoch [47/100], Step [26600/6235], Loss: 0.2112\n",
      "Epoch [47/100], Step [26700/6235], Loss: 0.1215\n",
      "Epoch [47/100], Step [26800/6235], Loss: 0.0586\n",
      "Epoch [47/100], Step [26900/6235], Loss: 0.0655\n",
      "Epoch [47/100], Step [27000/6235], Loss: 16.2083\n",
      "Epoch [47/100], Step [27100/6235], Loss: 0.0670\n",
      "Epoch [47/100], Step [27200/6235], Loss: 0.0084\n",
      "Epoch [47/100], Step [27300/6235], Loss: 0.0233\n",
      "Epoch [47/100], Step [27400/6235], Loss: 0.5901\n",
      "Epoch [47/100], Step [27500/6235], Loss: 2.2750\n",
      "Epoch [47/100], Step [27600/6235], Loss: 0.7337\n",
      "Epoch [47/100], Step [27700/6235], Loss: 0.7436\n",
      "Epoch [47/100], Step [27800/6235], Loss: 6.1488\n",
      "Epoch [47/100], Step [27900/6235], Loss: 1.1142\n",
      "Epoch [47/100], Step [28000/6235], Loss: 197.7165\n",
      "Epoch [47/100], Step [28100/6235], Loss: 17.0357\n",
      "Epoch [47/100], Step [28200/6235], Loss: 38.7376\n",
      "Epoch [47/100], Step [28300/6235], Loss: 2.0111\n",
      "Epoch [47/100], Step [28400/6235], Loss: 20.2556\n",
      "Epoch [47/100], Step [28500/6235], Loss: 4.0488\n",
      "Epoch [47/100], Step [28600/6235], Loss: 1.0015\n",
      "Epoch [47/100], Step [28700/6235], Loss: 3.8330\n",
      "Epoch [47/100], Step [28800/6235], Loss: 0.6688\n",
      "Epoch [47/100], Step [28900/6235], Loss: 51.6883\n",
      "Epoch [47/100], Step [29000/6235], Loss: 0.0906\n",
      "Epoch [47/100], Step [29100/6235], Loss: 0.9992\n",
      "Epoch [47/100], Step [29200/6235], Loss: 4.8592\n",
      "Epoch [47/100], Step [29300/6235], Loss: 8.7581\n",
      "Epoch [47/100], Step [29400/6235], Loss: 0.1725\n",
      "Epoch [47/100], Step [29500/6235], Loss: 2.8090\n",
      "Epoch [47/100], Step [29600/6235], Loss: 0.4227\n",
      "Epoch [47/100], Step [29700/6235], Loss: 2.7151\n",
      "Epoch [47/100], Step [29800/6235], Loss: 0.8750\n",
      "Epoch [47/100], Step [29900/6235], Loss: 0.1285\n",
      "Epoch [47/100], Step [30000/6235], Loss: 6.5553\n",
      "Epoch [47/100], Step [30100/6235], Loss: 7.7819\n",
      "Epoch [47/100], Step [30200/6235], Loss: 1.8767\n",
      "Epoch [47/100], Step [30300/6235], Loss: 0.0904\n",
      "Epoch [47/100], Step [30400/6235], Loss: 2.0928\n",
      "Epoch [47/100], Step [30500/6235], Loss: 1.8469\n",
      "Epoch [47/100], Step [30600/6235], Loss: 1.7320\n",
      "Epoch [47/100], Step [30700/6235], Loss: 1.9779\n",
      "Epoch [47/100], Step [30800/6235], Loss: 0.5364\n",
      "Epoch [47/100], Step [30900/6235], Loss: 2.2896\n",
      "Epoch [47/100], Step [31000/6235], Loss: 0.3363\n",
      "Epoch [47/100], Step [31100/6235], Loss: 0.1149\n",
      "Epoch [47/100], Step [31200/6235], Loss: 3.1949\n",
      "Epoch [47/100], Step [31300/6235], Loss: 1.4506\n",
      "Epoch [47/100], Step [31400/6235], Loss: 9.0171\n",
      "Epoch [47/100], Step [31500/6235], Loss: 0.8992\n",
      "Epoch [47/100], Step [31600/6235], Loss: 4.2935\n",
      "Epoch [47/100], Step [31700/6235], Loss: 12.9470\n",
      "Epoch [47/100], Step [31800/6235], Loss: 1.4445\n",
      "Epoch [47/100], Step [31900/6235], Loss: 52.7708\n",
      "Epoch [47/100], Step [32000/6235], Loss: 32.1111\n",
      "Epoch [47/100], Step [32100/6235], Loss: 0.9749\n",
      "Epoch [47/100], Step [32200/6235], Loss: 23.6934\n",
      "Epoch [47/100], Step [32300/6235], Loss: 0.6409\n",
      "Epoch [47/100], Step [32400/6235], Loss: 1.0946\n",
      "Epoch [47/100], Step [32500/6235], Loss: 19.3663\n",
      "Epoch [47/100], Step [32600/6235], Loss: 0.5962\n",
      "Epoch [47/100], Step [32700/6235], Loss: 87.1531\n",
      "Epoch [47/100], Step [32800/6235], Loss: 0.7139\n",
      "Epoch [47/100], Step [32900/6235], Loss: 4.4043\n",
      "Epoch [47/100], Step [33000/6235], Loss: 0.4076\n",
      "Epoch [47/100], Step [33100/6235], Loss: 0.8687\n",
      "Epoch [47/100], Step [33200/6235], Loss: 1.0753\n",
      "Epoch [47/100], Step [33300/6235], Loss: 1.6122\n",
      "Epoch [47/100], Step [33400/6235], Loss: 37.4486\n",
      "Epoch [47/100], Step [33500/6235], Loss: 0.1865\n",
      "Epoch [47/100], Step [33600/6235], Loss: 10.0786\n",
      "Epoch [47/100], Step [33700/6235], Loss: 13.6573\n",
      "Epoch [47/100], Step [33800/6235], Loss: 0.7789\n",
      "Epoch [47/100], Step [33900/6235], Loss: 34.0165\n",
      "Epoch [47/100], Step [34000/6235], Loss: 0.1188\n",
      "Epoch [47/100], Step [34100/6235], Loss: 0.6342\n",
      "Epoch [47/100], Step [34200/6235], Loss: 2.7137\n",
      "Epoch [47/100], Step [34300/6235], Loss: 3.1572\n",
      "Epoch [47/100], Step [34400/6235], Loss: 0.2355\n",
      "Epoch [47/100], Step [34500/6235], Loss: 34.2269\n",
      "Epoch [47/100], Step [34600/6235], Loss: 1.2075\n",
      "Epoch [47/100], Step [34700/6235], Loss: 23.6760\n",
      "Epoch [47/100], Step [34800/6235], Loss: 8.0301\n",
      "Epoch [47/100], Step [34900/6235], Loss: 64.3244\n",
      "Epoch [47/100], Step [35000/6235], Loss: 0.1645\n",
      "Epoch [47/100], Step [35100/6235], Loss: 0.5878\n",
      "Epoch [47/100], Step [35200/6235], Loss: 0.4003\n",
      "Epoch [47/100], Step [35300/6235], Loss: 2.9585\n",
      "Epoch [47/100], Step [35400/6235], Loss: 0.5106\n",
      "Epoch [47/100], Step [35500/6235], Loss: 1.3753\n",
      "Epoch [47/100], Step [35600/6235], Loss: 0.8809\n",
      "Epoch [47/100], Step [35700/6235], Loss: 4.1672\n",
      "Epoch [47/100], Step [35800/6235], Loss: 1.7633\n",
      "Epoch [47/100], Step [35900/6235], Loss: 2.1561\n",
      "Epoch [47/100], Step [36000/6235], Loss: 0.0563\n",
      "Epoch [47/100], Step [36100/6235], Loss: 0.0283\n",
      "Epoch [47/100], Step [36200/6235], Loss: 16.4664\n",
      "Epoch [47/100], Step [36300/6235], Loss: 0.8979\n",
      "Epoch [47/100], Step [36400/6235], Loss: 2.9276\n",
      "Epoch [47/100], Step [36500/6235], Loss: 8.2579\n",
      "Epoch [47/100], Step [36600/6235], Loss: 0.1101\n",
      "Epoch [47/100], Step [36700/6235], Loss: 0.5604\n",
      "Epoch [47/100], Step [36800/6235], Loss: 8.3072\n",
      "Epoch [47/100], Step [36900/6235], Loss: 7.5406\n",
      "Epoch [47/100], Step [37000/6235], Loss: 0.7939\n",
      "Epoch [47/100], Step [37100/6235], Loss: 1.4626\n",
      "Epoch [47/100], Step [37200/6235], Loss: 0.0603\n",
      "Epoch [47/100], Step [37300/6235], Loss: 0.0295\n",
      "Epoch [47/100], Step [37400/6235], Loss: 0.1916\n",
      "Epoch [47/100], Step [37500/6235], Loss: 5.9140\n",
      "Epoch [47/100], Step [37600/6235], Loss: 12.1245\n",
      "Epoch [47/100], Step [37700/6235], Loss: 2.2081\n",
      "Epoch [47/100], Step [37800/6235], Loss: 4.2819\n",
      "Epoch [47/100], Step [37900/6235], Loss: 8.8833\n",
      "Epoch [47/100], Step [38000/6235], Loss: 0.5108\n",
      "Epoch [47/100], Step [38100/6235], Loss: 4.5191\n",
      "Epoch [47/100], Step [38200/6235], Loss: 1.9354\n",
      "Epoch [47/100], Step [38300/6235], Loss: 0.3727\n",
      "Epoch [47/100], Step [38400/6235], Loss: 0.0634\n",
      "Epoch [47/100], Step [38500/6235], Loss: 1.6898\n",
      "Epoch [47/100], Step [38600/6235], Loss: 0.1875\n",
      "Epoch [47/100], Step [38700/6235], Loss: 0.1231\n",
      "Epoch [47/100], Step [38800/6235], Loss: 0.1761\n",
      "Epoch [47/100], Step [38900/6235], Loss: 10.9349\n",
      "Epoch [47/100], Step [39000/6235], Loss: 23.7716\n",
      "Epoch [47/100], Step [39100/6235], Loss: 15.6429\n",
      "Epoch [47/100], Step [39200/6235], Loss: 0.7156\n",
      "Epoch [47/100], Step [39300/6235], Loss: 53.7432\n",
      "Epoch [47/100], Step [39400/6235], Loss: 517.0166\n",
      "Epoch [47/100], Step [39500/6235], Loss: 8.0884\n",
      "Epoch [47/100], Step [39600/6235], Loss: 26.4021\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [47/100], Step [39700/6235], Loss: 88.6446\n",
      "Epoch [47/100], Step [39800/6235], Loss: 149.9899\n",
      "Epoch [47/100], Step [39900/6235], Loss: 42.8615\n",
      "Epoch [47/100], Step [40000/6235], Loss: 128.5396\n",
      "Epoch [47/100], Step [40100/6235], Loss: 33.1794\n",
      "Epoch [47/100], Step [40200/6235], Loss: 42.8572\n",
      "Epoch [47/100], Step [40300/6235], Loss: 0.5143\n",
      "Epoch [47/100], Step [40400/6235], Loss: 3.1773\n",
      "Epoch [47/100], Step [40500/6235], Loss: 1.7840\n",
      "Epoch [47/100], Step [40600/6235], Loss: 0.9255\n",
      "Epoch [47/100], Step [40700/6235], Loss: 7.3575\n",
      "Epoch [47/100], Step [40800/6235], Loss: 2.1364\n",
      "Epoch [47/100], Step [40900/6235], Loss: 0.0796\n",
      "Epoch [47/100], Step [41000/6235], Loss: 26.0808\n",
      "Epoch [47/100], Step [41100/6235], Loss: 6.2141\n",
      "Epoch [47/100], Step [41200/6235], Loss: 28.2141\n",
      "Epoch [47/100], Step [41300/6235], Loss: 4.8766\n",
      "Epoch [47/100], Step [41400/6235], Loss: 5.1089\n",
      "Epoch [47/100], Step [41500/6235], Loss: 34.0561\n",
      "Epoch [47/100], Step [41600/6235], Loss: 2.3824\n",
      "Epoch [47/100], Step [41700/6235], Loss: 0.1158\n",
      "Epoch [47/100], Step [41800/6235], Loss: 0.6585\n",
      "Epoch [47/100], Step [41900/6235], Loss: 4.0710\n",
      "Epoch [47/100], Step [42000/6235], Loss: 4.4395\n",
      "Epoch [47/100], Step [42100/6235], Loss: 12.1118\n",
      "Epoch [47/100], Step [42200/6235], Loss: 90.7069\n",
      "Epoch [47/100], Step [42300/6235], Loss: 0.3218\n",
      "Epoch [47/100], Step [42400/6235], Loss: 5.3871\n",
      "Epoch [47/100], Step [42500/6235], Loss: 0.4049\n",
      "Epoch [47/100], Step [42600/6235], Loss: 0.5131\n",
      "Epoch [47/100], Step [42700/6235], Loss: 0.9187\n",
      "Epoch [47/100], Step [42800/6235], Loss: 8.9262\n",
      "Epoch [47/100], Step [42900/6235], Loss: 1.9384\n",
      "Epoch [47/100], Step [43000/6235], Loss: 0.1993\n",
      "Epoch [47/100], Step [43100/6235], Loss: 0.0413\n",
      "Epoch [47/100], Step [43200/6235], Loss: 0.9449\n",
      "Epoch [47/100], Step [43300/6235], Loss: 7.3671\n",
      "Epoch [47/100], Step [43400/6235], Loss: 8.2604\n",
      "Epoch [47/100], Step [43500/6235], Loss: 10.0880\n",
      "Epoch [47/100], Step [43600/6235], Loss: 6.5051\n",
      "Epoch [47/100], Step [43700/6235], Loss: 50.8044\n",
      "Epoch [47/100], Step [43800/6235], Loss: 0.3723\n",
      "Epoch [47/100], Step [43900/6235], Loss: 2.5614\n",
      "Epoch [47/100], Step [44000/6235], Loss: 47.7144\n",
      "Epoch [47/100], Step [44100/6235], Loss: 2.6534\n",
      "Epoch [47/100], Step [44200/6235], Loss: 4.9503\n",
      "Epoch [47/100], Step [44300/6235], Loss: 3.1762\n",
      "Epoch [47/100], Step [44400/6235], Loss: 0.8363\n",
      "Epoch [47/100], Step [44500/6235], Loss: 4.1717\n",
      "Epoch [47/100], Step [44600/6235], Loss: 27.0970\n",
      "Epoch [47/100], Step [44700/6235], Loss: 29.9323\n",
      "Epoch [47/100], Step [44800/6235], Loss: 3.0020\n",
      "Epoch [47/100], Step [44900/6235], Loss: 6.8562\n",
      "Epoch [47/100], Step [45000/6235], Loss: 5.1663\n",
      "Epoch [47/100], Step [45100/6235], Loss: 22.8199\n",
      "Epoch [47/100], Step [45200/6235], Loss: 1.2026\n",
      "Epoch [47/100], Step [45300/6235], Loss: 28.1236\n",
      "Epoch [47/100], Step [45400/6235], Loss: 11.8810\n",
      "Epoch [47/100], Step [45500/6235], Loss: 0.6177\n",
      "Epoch [47/100], Step [45600/6235], Loss: 0.2239\n",
      "Epoch [47/100], Step [45700/6235], Loss: 74.1107\n",
      "Epoch [47/100], Step [45800/6235], Loss: 343.1584\n",
      "Epoch [47/100], Step [45900/6235], Loss: 3.7901\n",
      "Epoch [47/100], Step [46000/6235], Loss: 4.0561\n",
      "Epoch [47/100], Step [46100/6235], Loss: 9.0945\n",
      "Epoch [47/100], Step [46200/6235], Loss: 18.8991\n",
      "Epoch [47/100], Step [46300/6235], Loss: 6.7600\n",
      "Epoch [47/100], Step [46400/6235], Loss: 14.2771\n",
      "Epoch [47/100], Step [46500/6235], Loss: 4.1495\n",
      "Epoch [47/100], Step [46600/6235], Loss: 23.8904\n",
      "Epoch [47/100], Step [46700/6235], Loss: 22.7148\n",
      "Epoch [47/100], Step [46800/6235], Loss: 8.3215\n",
      "Epoch [47/100], Step [46900/6235], Loss: 7.0036\n",
      "Epoch [47/100], Step [47000/6235], Loss: 4.2493\n",
      "Epoch [47/100], Step [47100/6235], Loss: 5.9818\n",
      "Epoch [47/100], Step [47200/6235], Loss: 28.9868\n",
      "Epoch [47/100], Step [47300/6235], Loss: 1.0222\n",
      "Epoch [47/100], Step [47400/6235], Loss: 39.3258\n",
      "Epoch [47/100], Step [47500/6235], Loss: 8.1632\n",
      "Epoch [47/100], Step [47600/6235], Loss: 7.1835\n",
      "Epoch [47/100], Step [47700/6235], Loss: 9.4469\n",
      "Epoch [47/100], Step [47800/6235], Loss: 8.0936\n",
      "Epoch [47/100], Step [47900/6235], Loss: 17.1812\n",
      "Epoch [47/100], Step [48000/6235], Loss: 134.5739\n",
      "Epoch [47/100], Step [48100/6235], Loss: 4.3409\n",
      "Epoch [47/100], Step [48200/6235], Loss: 16.4977\n",
      "Epoch [47/100], Step [48300/6235], Loss: 385.9913\n",
      "Epoch [47/100], Step [48400/6235], Loss: 23.1337\n",
      "Epoch [47/100], Step [48500/6235], Loss: 18.0386\n",
      "Epoch [47/100], Step [48600/6235], Loss: 166.3345\n",
      "Epoch [47/100], Step [48700/6235], Loss: 24.3585\n",
      "Epoch [47/100], Step [48800/6235], Loss: 464.3524\n",
      "Epoch [47/100], Step [48900/6235], Loss: 31.3421\n",
      "Epoch [47/100], Step [49000/6235], Loss: 221.5381\n",
      "Epoch [47/100], Step [49100/6235], Loss: 2435.8826\n",
      "Epoch [47/100], Step [49200/6235], Loss: 587.5949\n",
      "Epoch [47/100], Step [49300/6235], Loss: 1224.5107\n",
      "Epoch [47/100], Step [49400/6235], Loss: 71.6572\n",
      "Epoch [47/100], Step [49500/6235], Loss: 2.8229\n",
      "Epoch [47/100], Step [49600/6235], Loss: 473.6362\n",
      "Epoch [47/100], Step [49700/6235], Loss: 737.7568\n",
      "Epoch [47/100], Step [49800/6235], Loss: 1398.7743\n",
      "Epoch [48/100], Step [100/6235], Loss: 19.8706\n",
      "Epoch [48/100], Step [200/6235], Loss: 0.3970\n",
      "Epoch [48/100], Step [300/6235], Loss: 0.0700\n",
      "Epoch [48/100], Step [400/6235], Loss: 0.0288\n",
      "Epoch [48/100], Step [500/6235], Loss: 35.9036\n",
      "Epoch [48/100], Step [600/6235], Loss: 0.1418\n",
      "Epoch [48/100], Step [700/6235], Loss: 1.1283\n",
      "Epoch [48/100], Step [800/6235], Loss: 0.1972\n",
      "Epoch [48/100], Step [900/6235], Loss: 0.1887\n",
      "Epoch [48/100], Step [1000/6235], Loss: 0.1454\n",
      "Epoch [48/100], Step [1100/6235], Loss: 1.2915\n",
      "Epoch [48/100], Step [1200/6235], Loss: 0.2477\n",
      "Epoch [48/100], Step [1300/6235], Loss: 0.2034\n",
      "Epoch [48/100], Step [1400/6235], Loss: 2.0186\n",
      "Epoch [48/100], Step [1500/6235], Loss: 0.0139\n",
      "Epoch [48/100], Step [1600/6235], Loss: 0.2387\n",
      "Epoch [48/100], Step [1700/6235], Loss: 0.1568\n",
      "Epoch [48/100], Step [1800/6235], Loss: 0.3237\n",
      "Epoch [48/100], Step [1900/6235], Loss: 0.6248\n",
      "Epoch [48/100], Step [2000/6235], Loss: 2.4530\n",
      "Epoch [48/100], Step [2100/6235], Loss: 2.0069\n",
      "Epoch [48/100], Step [2200/6235], Loss: 9.3581\n",
      "Epoch [48/100], Step [2300/6235], Loss: 12.0925\n",
      "Epoch [48/100], Step [2400/6235], Loss: 5.6918\n",
      "Epoch [48/100], Step [2500/6235], Loss: 41.3483\n",
      "Epoch [48/100], Step [2600/6235], Loss: 11.4764\n",
      "Epoch [48/100], Step [2700/6235], Loss: 8.9076\n",
      "Epoch [48/100], Step [2800/6235], Loss: 127.6844\n",
      "Epoch [48/100], Step [2900/6235], Loss: 9.3582\n",
      "Epoch [48/100], Step [3000/6235], Loss: 0.5331\n",
      "Epoch [48/100], Step [3100/6235], Loss: 75.8414\n",
      "Epoch [48/100], Step [3200/6235], Loss: 83.9301\n",
      "Epoch [48/100], Step [3300/6235], Loss: 4.7375\n",
      "Epoch [48/100], Step [3400/6235], Loss: 1.9302\n",
      "Epoch [48/100], Step [3500/6235], Loss: 29.1694\n",
      "Epoch [48/100], Step [3600/6235], Loss: 10.1884\n",
      "Epoch [48/100], Step [3700/6235], Loss: 0.2387\n",
      "Epoch [48/100], Step [3800/6235], Loss: 0.4247\n",
      "Epoch [48/100], Step [3900/6235], Loss: 1.2813\n",
      "Epoch [48/100], Step [4000/6235], Loss: 0.0047\n",
      "Epoch [48/100], Step [4100/6235], Loss: 6.1227\n",
      "Epoch [48/100], Step [4200/6235], Loss: 0.3280\n",
      "Epoch [48/100], Step [4300/6235], Loss: 7.4374\n",
      "Epoch [48/100], Step [4400/6235], Loss: 4.1271\n",
      "Epoch [48/100], Step [4500/6235], Loss: 43.1795\n",
      "Epoch [48/100], Step [4600/6235], Loss: 2.8218\n",
      "Epoch [48/100], Step [4700/6235], Loss: 0.5044\n",
      "Epoch [48/100], Step [4800/6235], Loss: 8.0340\n",
      "Epoch [48/100], Step [4900/6235], Loss: 0.1447\n",
      "Epoch [48/100], Step [5000/6235], Loss: 0.2367\n",
      "Epoch [48/100], Step [5100/6235], Loss: 2.7670\n",
      "Epoch [48/100], Step [5200/6235], Loss: 0.7248\n",
      "Epoch [48/100], Step [5300/6235], Loss: 38.3444\n",
      "Epoch [48/100], Step [5400/6235], Loss: 1.6377\n",
      "Epoch [48/100], Step [5500/6235], Loss: 0.1251\n",
      "Epoch [48/100], Step [5600/6235], Loss: 0.3314\n",
      "Epoch [48/100], Step [5700/6235], Loss: 0.5604\n",
      "Epoch [48/100], Step [5800/6235], Loss: 0.3095\n",
      "Epoch [48/100], Step [5900/6235], Loss: 0.1575\n",
      "Epoch [48/100], Step [6000/6235], Loss: 2.5419\n",
      "Epoch [48/100], Step [6100/6235], Loss: 0.1599\n",
      "Epoch [48/100], Step [6200/6235], Loss: 1.6735\n",
      "Epoch [48/100], Step [6300/6235], Loss: 1.8497\n",
      "Epoch [48/100], Step [6400/6235], Loss: 0.0092\n",
      "Epoch [48/100], Step [6500/6235], Loss: 1.3045\n",
      "Epoch [48/100], Step [6600/6235], Loss: 8.3930\n",
      "Epoch [48/100], Step [6700/6235], Loss: 3.1456\n",
      "Epoch [48/100], Step [6800/6235], Loss: 0.1651\n",
      "Epoch [48/100], Step [6900/6235], Loss: 1.0217\n",
      "Epoch [48/100], Step [7000/6235], Loss: 0.5045\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Step [7100/6235], Loss: 0.2183\n",
      "Epoch [48/100], Step [7200/6235], Loss: 0.1523\n",
      "Epoch [48/100], Step [7300/6235], Loss: 0.0947\n",
      "Epoch [48/100], Step [7400/6235], Loss: 0.1254\n",
      "Epoch [48/100], Step [7500/6235], Loss: 0.1067\n",
      "Epoch [48/100], Step [7600/6235], Loss: 1.9279\n",
      "Epoch [48/100], Step [7700/6235], Loss: 17.7937\n",
      "Epoch [48/100], Step [7800/6235], Loss: 2.0019\n",
      "Epoch [48/100], Step [7900/6235], Loss: 0.5890\n",
      "Epoch [48/100], Step [8000/6235], Loss: 0.3193\n",
      "Epoch [48/100], Step [8100/6235], Loss: 4.3082\n",
      "Epoch [48/100], Step [8200/6235], Loss: 12.0476\n",
      "Epoch [48/100], Step [8300/6235], Loss: 26.6420\n",
      "Epoch [48/100], Step [8400/6235], Loss: 312.2315\n",
      "Epoch [48/100], Step [8500/6235], Loss: 3.6166\n",
      "Epoch [48/100], Step [8600/6235], Loss: 75.4124\n",
      "Epoch [48/100], Step [8700/6235], Loss: 40.2740\n",
      "Epoch [48/100], Step [8800/6235], Loss: 42.8784\n",
      "Epoch [48/100], Step [8900/6235], Loss: 56.8670\n",
      "Epoch [48/100], Step [9000/6235], Loss: 645.5557\n",
      "Epoch [48/100], Step [9100/6235], Loss: 1356.7869\n",
      "Epoch [48/100], Step [9200/6235], Loss: 3269.8613\n",
      "Epoch [48/100], Step [9300/6235], Loss: 99.2327\n",
      "Epoch [48/100], Step [9400/6235], Loss: 106.7681\n",
      "Epoch [48/100], Step [9500/6235], Loss: 559.4545\n",
      "Epoch [48/100], Step [9600/6235], Loss: 445.7599\n",
      "Epoch [48/100], Step [9700/6235], Loss: 1.8616\n",
      "Epoch [48/100], Step [9800/6235], Loss: 413.1253\n",
      "Epoch [48/100], Step [9900/6235], Loss: 33.1847\n",
      "Epoch [48/100], Step [10000/6235], Loss: 77.5126\n",
      "Epoch [48/100], Step [10100/6235], Loss: 2.1078\n",
      "Epoch [48/100], Step [10200/6235], Loss: 473.6247\n",
      "Epoch [48/100], Step [10300/6235], Loss: 5.1315\n",
      "Epoch [48/100], Step [10400/6235], Loss: 9.2753\n",
      "Epoch [48/100], Step [10500/6235], Loss: 2.5167\n",
      "Epoch [48/100], Step [10600/6235], Loss: 36.4810\n",
      "Epoch [48/100], Step [10700/6235], Loss: 17.2145\n",
      "Epoch [48/100], Step [10800/6235], Loss: 78.2314\n",
      "Epoch [48/100], Step [10900/6235], Loss: 16.5037\n",
      "Epoch [48/100], Step [11000/6235], Loss: 295.6523\n",
      "Epoch [48/100], Step [11100/6235], Loss: 46.4460\n",
      "Epoch [48/100], Step [11200/6235], Loss: 22.8810\n",
      "Epoch [48/100], Step [11300/6235], Loss: 138.3111\n",
      "Epoch [48/100], Step [11400/6235], Loss: 3.0297\n",
      "Epoch [48/100], Step [11500/6235], Loss: 4.3363\n",
      "Epoch [48/100], Step [11600/6235], Loss: 2.8064\n",
      "Epoch [48/100], Step [11700/6235], Loss: 39.3415\n",
      "Epoch [48/100], Step [11800/6235], Loss: 310.3137\n",
      "Epoch [48/100], Step [11900/6235], Loss: 18.8304\n",
      "Epoch [48/100], Step [12000/6235], Loss: 639.0162\n",
      "Epoch [48/100], Step [12100/6235], Loss: 262.9855\n",
      "Epoch [48/100], Step [12200/6235], Loss: 135.8731\n",
      "Epoch [48/100], Step [12300/6235], Loss: 21.6169\n",
      "Epoch [48/100], Step [12400/6235], Loss: 242.9753\n",
      "Epoch [48/100], Step [12500/6235], Loss: 3.4955\n",
      "Epoch [48/100], Step [12600/6235], Loss: 100.6206\n",
      "Epoch [48/100], Step [12700/6235], Loss: 2.9204\n",
      "Epoch [48/100], Step [12800/6235], Loss: 7.1483\n",
      "Epoch [48/100], Step [12900/6235], Loss: 41.9145\n",
      "Epoch [48/100], Step [13000/6235], Loss: 0.9213\n",
      "Epoch [48/100], Step [13100/6235], Loss: 69.5416\n",
      "Epoch [48/100], Step [13200/6235], Loss: 13.7811\n",
      "Epoch [48/100], Step [13300/6235], Loss: 42.6050\n",
      "Epoch [48/100], Step [13400/6235], Loss: 251.7718\n",
      "Epoch [48/100], Step [13500/6235], Loss: 18.3313\n",
      "Epoch [48/100], Step [13600/6235], Loss: 32.9735\n",
      "Epoch [48/100], Step [13700/6235], Loss: 0.8052\n",
      "Epoch [48/100], Step [13800/6235], Loss: 171.9505\n",
      "Epoch [48/100], Step [13900/6235], Loss: 61.8178\n",
      "Epoch [48/100], Step [14000/6235], Loss: 3.2476\n",
      "Epoch [48/100], Step [14100/6235], Loss: 8.7782\n",
      "Epoch [48/100], Step [14200/6235], Loss: 103.7933\n",
      "Epoch [48/100], Step [14300/6235], Loss: 49.4018\n",
      "Epoch [48/100], Step [14400/6235], Loss: 37.9979\n",
      "Epoch [48/100], Step [14500/6235], Loss: 66.5210\n",
      "Epoch [48/100], Step [14600/6235], Loss: 0.3343\n",
      "Epoch [48/100], Step [14700/6235], Loss: 45.3471\n",
      "Epoch [48/100], Step [14800/6235], Loss: 31.7561\n",
      "Epoch [48/100], Step [14900/6235], Loss: 1.6212\n",
      "Epoch [48/100], Step [15000/6235], Loss: 2.7406\n",
      "Epoch [48/100], Step [15100/6235], Loss: 0.2590\n",
      "Epoch [48/100], Step [15200/6235], Loss: 1.4613\n",
      "Epoch [48/100], Step [15300/6235], Loss: 34.9916\n",
      "Epoch [48/100], Step [15400/6235], Loss: 69.5958\n",
      "Epoch [48/100], Step [15500/6235], Loss: 9.8886\n",
      "Epoch [48/100], Step [15600/6235], Loss: 103.3472\n",
      "Epoch [48/100], Step [15700/6235], Loss: 97.8137\n",
      "Epoch [48/100], Step [15800/6235], Loss: 8.7019\n",
      "Epoch [48/100], Step [15900/6235], Loss: 0.3748\n",
      "Epoch [48/100], Step [16000/6235], Loss: 119.7041\n",
      "Epoch [48/100], Step [16100/6235], Loss: 9.5025\n",
      "Epoch [48/100], Step [16200/6235], Loss: 0.5006\n",
      "Epoch [48/100], Step [16300/6235], Loss: 10.5395\n",
      "Epoch [48/100], Step [16400/6235], Loss: 17.8935\n",
      "Epoch [48/100], Step [16500/6235], Loss: 399.8522\n",
      "Epoch [48/100], Step [16600/6235], Loss: 39.3216\n",
      "Epoch [48/100], Step [16700/6235], Loss: 0.2653\n",
      "Epoch [48/100], Step [16800/6235], Loss: 9.0434\n",
      "Epoch [48/100], Step [16900/6235], Loss: 0.2853\n",
      "Epoch [48/100], Step [17000/6235], Loss: 0.2174\n",
      "Epoch [48/100], Step [17100/6235], Loss: 0.1577\n",
      "Epoch [48/100], Step [17200/6235], Loss: 286.4527\n",
      "Epoch [48/100], Step [17300/6235], Loss: 38.2542\n",
      "Epoch [48/100], Step [17400/6235], Loss: 42.9916\n",
      "Epoch [48/100], Step [17500/6235], Loss: 0.5048\n",
      "Epoch [48/100], Step [17600/6235], Loss: 3.3295\n",
      "Epoch [48/100], Step [17700/6235], Loss: 111.1421\n",
      "Epoch [48/100], Step [17800/6235], Loss: 26.1209\n",
      "Epoch [48/100], Step [17900/6235], Loss: 12.9183\n",
      "Epoch [48/100], Step [18000/6235], Loss: 1.0458\n",
      "Epoch [48/100], Step [18100/6235], Loss: 15.3988\n",
      "Epoch [48/100], Step [18200/6235], Loss: 0.2950\n",
      "Epoch [48/100], Step [18300/6235], Loss: 2.2076\n",
      "Epoch [48/100], Step [18400/6235], Loss: 0.6148\n",
      "Epoch [48/100], Step [18500/6235], Loss: 18.5498\n",
      "Epoch [48/100], Step [18600/6235], Loss: 3.2838\n",
      "Epoch [48/100], Step [18700/6235], Loss: 0.8538\n",
      "Epoch [48/100], Step [18800/6235], Loss: 184.3225\n",
      "Epoch [48/100], Step [18900/6235], Loss: 22.5571\n",
      "Epoch [48/100], Step [19000/6235], Loss: 3.0051\n",
      "Epoch [48/100], Step [19100/6235], Loss: 38.8811\n",
      "Epoch [48/100], Step [19200/6235], Loss: 1.3913\n",
      "Epoch [48/100], Step [19300/6235], Loss: 1.1354\n",
      "Epoch [48/100], Step [19400/6235], Loss: 106.4427\n",
      "Epoch [48/100], Step [19500/6235], Loss: 66.3120\n",
      "Epoch [48/100], Step [19600/6235], Loss: 27.2863\n",
      "Epoch [48/100], Step [19700/6235], Loss: 10.4364\n",
      "Epoch [48/100], Step [19800/6235], Loss: 6.8095\n",
      "Epoch [48/100], Step [19900/6235], Loss: 0.0916\n",
      "Epoch [48/100], Step [20000/6235], Loss: 68.1529\n",
      "Epoch [48/100], Step [20100/6235], Loss: 4.4450\n",
      "Epoch [48/100], Step [20200/6235], Loss: 0.0974\n",
      "Epoch [48/100], Step [20300/6235], Loss: 0.8730\n",
      "Epoch [48/100], Step [20400/6235], Loss: 7.0805\n",
      "Epoch [48/100], Step [20500/6235], Loss: 58.0719\n",
      "Epoch [48/100], Step [20600/6235], Loss: 285.7429\n",
      "Epoch [48/100], Step [20700/6235], Loss: 6.3132\n",
      "Epoch [48/100], Step [20800/6235], Loss: 18.0520\n",
      "Epoch [48/100], Step [20900/6235], Loss: 24.6180\n",
      "Epoch [48/100], Step [21000/6235], Loss: 16.1968\n",
      "Epoch [48/100], Step [21100/6235], Loss: 7.0505\n",
      "Epoch [48/100], Step [21200/6235], Loss: 0.2966\n",
      "Epoch [48/100], Step [21300/6235], Loss: 0.1236\n",
      "Epoch [48/100], Step [21400/6235], Loss: 4.8197\n",
      "Epoch [48/100], Step [21500/6235], Loss: 0.5408\n",
      "Epoch [48/100], Step [21600/6235], Loss: 28.9927\n",
      "Epoch [48/100], Step [21700/6235], Loss: 0.2803\n",
      "Epoch [48/100], Step [21800/6235], Loss: 4.6895\n",
      "Epoch [48/100], Step [21900/6235], Loss: 1.5108\n",
      "Epoch [48/100], Step [22000/6235], Loss: 9.1338\n",
      "Epoch [48/100], Step [22100/6235], Loss: 0.1347\n",
      "Epoch [48/100], Step [22200/6235], Loss: 2.0254\n",
      "Epoch [48/100], Step [22300/6235], Loss: 1.0022\n",
      "Epoch [48/100], Step [22400/6235], Loss: 11.9247\n",
      "Epoch [48/100], Step [22500/6235], Loss: 144.4823\n",
      "Epoch [48/100], Step [22600/6235], Loss: 28.8388\n",
      "Epoch [48/100], Step [22700/6235], Loss: 0.2430\n",
      "Epoch [48/100], Step [22800/6235], Loss: 7.4956\n",
      "Epoch [48/100], Step [22900/6235], Loss: 3.9064\n",
      "Epoch [48/100], Step [23000/6235], Loss: 10.7815\n",
      "Epoch [48/100], Step [23100/6235], Loss: 2.6608\n",
      "Epoch [48/100], Step [23200/6235], Loss: 6.2628\n",
      "Epoch [48/100], Step [23300/6235], Loss: 19.8919\n",
      "Epoch [48/100], Step [23400/6235], Loss: 2.5371\n",
      "Epoch [48/100], Step [23500/6235], Loss: 0.0716\n",
      "Epoch [48/100], Step [23600/6235], Loss: 134.0314\n",
      "Epoch [48/100], Step [23700/6235], Loss: 4.3820\n",
      "Epoch [48/100], Step [23800/6235], Loss: 0.9432\n",
      "Epoch [48/100], Step [23900/6235], Loss: 3.3825\n",
      "Epoch [48/100], Step [24000/6235], Loss: 0.2955\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Step [24100/6235], Loss: 0.4925\n",
      "Epoch [48/100], Step [24200/6235], Loss: 34.5579\n",
      "Epoch [48/100], Step [24300/6235], Loss: 0.6964\n",
      "Epoch [48/100], Step [24400/6235], Loss: 1.5008\n",
      "Epoch [48/100], Step [24500/6235], Loss: 0.3497\n",
      "Epoch [48/100], Step [24600/6235], Loss: 0.0361\n",
      "Epoch [48/100], Step [24700/6235], Loss: 0.4727\n",
      "Epoch [48/100], Step [24800/6235], Loss: 0.4587\n",
      "Epoch [48/100], Step [24900/6235], Loss: 7.7252\n",
      "Epoch [48/100], Step [25000/6235], Loss: 10.4340\n",
      "Epoch [48/100], Step [25100/6235], Loss: 6.4967\n",
      "Epoch [48/100], Step [25200/6235], Loss: 0.1424\n",
      "Epoch [48/100], Step [25300/6235], Loss: 0.9847\n",
      "Epoch [48/100], Step [25400/6235], Loss: 9.4425\n",
      "Epoch [48/100], Step [25500/6235], Loss: 9.1548\n",
      "Epoch [48/100], Step [25600/6235], Loss: 7.3234\n",
      "Epoch [48/100], Step [25700/6235], Loss: 0.1371\n",
      "Epoch [48/100], Step [25800/6235], Loss: 0.1121\n",
      "Epoch [48/100], Step [25900/6235], Loss: 5.0089\n",
      "Epoch [48/100], Step [26000/6235], Loss: 1.9532\n",
      "Epoch [48/100], Step [26100/6235], Loss: 0.0323\n",
      "Epoch [48/100], Step [26200/6235], Loss: 1.4093\n",
      "Epoch [48/100], Step [26300/6235], Loss: 2.3413\n",
      "Epoch [48/100], Step [26400/6235], Loss: 0.3287\n",
      "Epoch [48/100], Step [26500/6235], Loss: 0.0382\n",
      "Epoch [48/100], Step [26600/6235], Loss: 0.4747\n",
      "Epoch [48/100], Step [26700/6235], Loss: 0.1859\n",
      "Epoch [48/100], Step [26800/6235], Loss: 0.0915\n",
      "Epoch [48/100], Step [26900/6235], Loss: 0.0356\n",
      "Epoch [48/100], Step [27000/6235], Loss: 16.2247\n",
      "Epoch [48/100], Step [27100/6235], Loss: 0.0492\n",
      "Epoch [48/100], Step [27200/6235], Loss: 0.0101\n",
      "Epoch [48/100], Step [27300/6235], Loss: 0.0680\n",
      "Epoch [48/100], Step [27400/6235], Loss: 0.6514\n",
      "Epoch [48/100], Step [27500/6235], Loss: 6.0544\n",
      "Epoch [48/100], Step [27600/6235], Loss: 0.8634\n",
      "Epoch [48/100], Step [27700/6235], Loss: 1.3512\n",
      "Epoch [48/100], Step [27800/6235], Loss: 5.5644\n",
      "Epoch [48/100], Step [27900/6235], Loss: 0.5348\n",
      "Epoch [48/100], Step [28000/6235], Loss: 172.3438\n",
      "Epoch [48/100], Step [28100/6235], Loss: 4.0160\n",
      "Epoch [48/100], Step [28200/6235], Loss: 30.0236\n",
      "Epoch [48/100], Step [28300/6235], Loss: 0.9814\n",
      "Epoch [48/100], Step [28400/6235], Loss: 26.7425\n",
      "Epoch [48/100], Step [28500/6235], Loss: 4.5799\n",
      "Epoch [48/100], Step [28600/6235], Loss: 0.5064\n",
      "Epoch [48/100], Step [28700/6235], Loss: 4.7442\n",
      "Epoch [48/100], Step [28800/6235], Loss: 0.6673\n",
      "Epoch [48/100], Step [28900/6235], Loss: 61.5956\n",
      "Epoch [48/100], Step [29000/6235], Loss: 14.8357\n",
      "Epoch [48/100], Step [29100/6235], Loss: 0.1964\n",
      "Epoch [48/100], Step [29200/6235], Loss: 3.3102\n",
      "Epoch [48/100], Step [29300/6235], Loss: 14.0477\n",
      "Epoch [48/100], Step [29400/6235], Loss: 2.6678\n",
      "Epoch [48/100], Step [29500/6235], Loss: 0.5823\n",
      "Epoch [48/100], Step [29600/6235], Loss: 0.7419\n",
      "Epoch [48/100], Step [29700/6235], Loss: 2.4431\n",
      "Epoch [48/100], Step [29800/6235], Loss: 1.0406\n",
      "Epoch [48/100], Step [29900/6235], Loss: 1.8821\n",
      "Epoch [48/100], Step [30000/6235], Loss: 7.2976\n",
      "Epoch [48/100], Step [30100/6235], Loss: 8.4295\n",
      "Epoch [48/100], Step [30200/6235], Loss: 1.7666\n",
      "Epoch [48/100], Step [30300/6235], Loss: 0.0710\n",
      "Epoch [48/100], Step [30400/6235], Loss: 1.8654\n",
      "Epoch [48/100], Step [30500/6235], Loss: 1.7318\n",
      "Epoch [48/100], Step [30600/6235], Loss: 1.7519\n",
      "Epoch [48/100], Step [30700/6235], Loss: 1.6448\n",
      "Epoch [48/100], Step [30800/6235], Loss: 0.5538\n",
      "Epoch [48/100], Step [30900/6235], Loss: 2.6511\n",
      "Epoch [48/100], Step [31000/6235], Loss: 0.3213\n",
      "Epoch [48/100], Step [31100/6235], Loss: 0.0594\n",
      "Epoch [48/100], Step [31200/6235], Loss: 5.9883\n",
      "Epoch [48/100], Step [31300/6235], Loss: 1.1297\n",
      "Epoch [48/100], Step [31400/6235], Loss: 3.0694\n",
      "Epoch [48/100], Step [31500/6235], Loss: 0.7334\n",
      "Epoch [48/100], Step [31600/6235], Loss: 11.5001\n",
      "Epoch [48/100], Step [31700/6235], Loss: 6.4096\n",
      "Epoch [48/100], Step [31800/6235], Loss: 0.2257\n",
      "Epoch [48/100], Step [31900/6235], Loss: 676.1077\n",
      "Epoch [48/100], Step [32000/6235], Loss: 57.6277\n",
      "Epoch [48/100], Step [32100/6235], Loss: 0.2762\n",
      "Epoch [48/100], Step [32200/6235], Loss: 147.3738\n",
      "Epoch [48/100], Step [32300/6235], Loss: 1.2727\n",
      "Epoch [48/100], Step [32400/6235], Loss: 1.6414\n",
      "Epoch [48/100], Step [32500/6235], Loss: 11.8917\n",
      "Epoch [48/100], Step [32600/6235], Loss: 0.4047\n",
      "Epoch [48/100], Step [32700/6235], Loss: 90.8048\n",
      "Epoch [48/100], Step [32800/6235], Loss: 5.0249\n",
      "Epoch [48/100], Step [32900/6235], Loss: 1.5183\n",
      "Epoch [48/100], Step [33000/6235], Loss: 0.4805\n",
      "Epoch [48/100], Step [33100/6235], Loss: 0.9273\n",
      "Epoch [48/100], Step [33200/6235], Loss: 1.4784\n",
      "Epoch [48/100], Step [33300/6235], Loss: 1.4439\n",
      "Epoch [48/100], Step [33400/6235], Loss: 47.6052\n",
      "Epoch [48/100], Step [33500/6235], Loss: 2.2102\n",
      "Epoch [48/100], Step [33600/6235], Loss: 7.0809\n",
      "Epoch [48/100], Step [33700/6235], Loss: 7.0988\n",
      "Epoch [48/100], Step [33800/6235], Loss: 1.6166\n",
      "Epoch [48/100], Step [33900/6235], Loss: 25.5467\n",
      "Epoch [48/100], Step [34000/6235], Loss: 0.0351\n",
      "Epoch [48/100], Step [34100/6235], Loss: 0.3900\n",
      "Epoch [48/100], Step [34200/6235], Loss: 2.3227\n",
      "Epoch [48/100], Step [34300/6235], Loss: 4.8523\n",
      "Epoch [48/100], Step [34400/6235], Loss: 0.2387\n",
      "Epoch [48/100], Step [34500/6235], Loss: 63.1266\n",
      "Epoch [48/100], Step [34600/6235], Loss: 1.1810\n",
      "Epoch [48/100], Step [34700/6235], Loss: 23.7337\n",
      "Epoch [48/100], Step [34800/6235], Loss: 8.1959\n",
      "Epoch [48/100], Step [34900/6235], Loss: 63.4349\n",
      "Epoch [48/100], Step [35000/6235], Loss: 1.1404\n",
      "Epoch [48/100], Step [35100/6235], Loss: 0.4725\n",
      "Epoch [48/100], Step [35200/6235], Loss: 0.2830\n",
      "Epoch [48/100], Step [35300/6235], Loss: 2.3869\n",
      "Epoch [48/100], Step [35400/6235], Loss: 0.3934\n",
      "Epoch [48/100], Step [35500/6235], Loss: 2.1057\n",
      "Epoch [48/100], Step [35600/6235], Loss: 5.5765\n",
      "Epoch [48/100], Step [35700/6235], Loss: 5.6438\n",
      "Epoch [48/100], Step [35800/6235], Loss: 0.1308\n",
      "Epoch [48/100], Step [35900/6235], Loss: 0.8409\n",
      "Epoch [48/100], Step [36000/6235], Loss: 0.2372\n",
      "Epoch [48/100], Step [36100/6235], Loss: 0.0524\n",
      "Epoch [48/100], Step [36200/6235], Loss: 17.8421\n",
      "Epoch [48/100], Step [36300/6235], Loss: 1.1028\n",
      "Epoch [48/100], Step [36400/6235], Loss: 2.3652\n",
      "Epoch [48/100], Step [36500/6235], Loss: 9.0421\n",
      "Epoch [48/100], Step [36600/6235], Loss: 0.1262\n",
      "Epoch [48/100], Step [36700/6235], Loss: 0.3722\n",
      "Epoch [48/100], Step [36800/6235], Loss: 13.4391\n",
      "Epoch [48/100], Step [36900/6235], Loss: 6.8707\n",
      "Epoch [48/100], Step [37000/6235], Loss: 0.4245\n",
      "Epoch [48/100], Step [37100/6235], Loss: 0.9825\n",
      "Epoch [48/100], Step [37200/6235], Loss: 0.0831\n",
      "Epoch [48/100], Step [37300/6235], Loss: 0.0569\n",
      "Epoch [48/100], Step [37400/6235], Loss: 0.2058\n",
      "Epoch [48/100], Step [37500/6235], Loss: 4.2952\n",
      "Epoch [48/100], Step [37600/6235], Loss: 11.6042\n",
      "Epoch [48/100], Step [37700/6235], Loss: 1.4177\n",
      "Epoch [48/100], Step [37800/6235], Loss: 5.1578\n",
      "Epoch [48/100], Step [37900/6235], Loss: 7.0713\n",
      "Epoch [48/100], Step [38000/6235], Loss: 0.6201\n",
      "Epoch [48/100], Step [38100/6235], Loss: 4.0965\n",
      "Epoch [48/100], Step [38200/6235], Loss: 2.1913\n",
      "Epoch [48/100], Step [38300/6235], Loss: 0.8198\n",
      "Epoch [48/100], Step [38400/6235], Loss: 0.1295\n",
      "Epoch [48/100], Step [38500/6235], Loss: 2.5447\n",
      "Epoch [48/100], Step [38600/6235], Loss: 0.0676\n",
      "Epoch [48/100], Step [38700/6235], Loss: 0.1015\n",
      "Epoch [48/100], Step [38800/6235], Loss: 0.2355\n",
      "Epoch [48/100], Step [38900/6235], Loss: 7.0911\n",
      "Epoch [48/100], Step [39000/6235], Loss: 4.1552\n",
      "Epoch [48/100], Step [39100/6235], Loss: 15.1150\n",
      "Epoch [48/100], Step [39200/6235], Loss: 0.2824\n",
      "Epoch [48/100], Step [39300/6235], Loss: 6.0175\n",
      "Epoch [48/100], Step [39400/6235], Loss: 233.7559\n",
      "Epoch [48/100], Step [39500/6235], Loss: 5.6711\n",
      "Epoch [48/100], Step [39600/6235], Loss: 21.2711\n",
      "Epoch [48/100], Step [39700/6235], Loss: 37.0927\n",
      "Epoch [48/100], Step [39800/6235], Loss: 229.1395\n",
      "Epoch [48/100], Step [39900/6235], Loss: 0.5015\n",
      "Epoch [48/100], Step [40000/6235], Loss: 13.3479\n",
      "Epoch [48/100], Step [40100/6235], Loss: 25.3713\n",
      "Epoch [48/100], Step [40200/6235], Loss: 1.0659\n",
      "Epoch [48/100], Step [40300/6235], Loss: 1.6833\n",
      "Epoch [48/100], Step [40400/6235], Loss: 1.6431\n",
      "Epoch [48/100], Step [40500/6235], Loss: 2.5696\n",
      "Epoch [48/100], Step [40600/6235], Loss: 0.2844\n",
      "Epoch [48/100], Step [40700/6235], Loss: 7.2640\n",
      "Epoch [48/100], Step [40800/6235], Loss: 0.6046\n",
      "Epoch [48/100], Step [40900/6235], Loss: 0.5694\n",
      "Epoch [48/100], Step [41000/6235], Loss: 46.4674\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [48/100], Step [41100/6235], Loss: 61.2460\n",
      "Epoch [48/100], Step [41200/6235], Loss: 9.8629\n",
      "Epoch [48/100], Step [41300/6235], Loss: 2.6488\n",
      "Epoch [48/100], Step [41400/6235], Loss: 0.2768\n",
      "Epoch [48/100], Step [41500/6235], Loss: 6.7962\n",
      "Epoch [48/100], Step [41600/6235], Loss: 1.8750\n",
      "Epoch [48/100], Step [41700/6235], Loss: 0.1207\n",
      "Epoch [48/100], Step [41800/6235], Loss: 0.5478\n",
      "Epoch [48/100], Step [41900/6235], Loss: 4.5734\n",
      "Epoch [48/100], Step [42000/6235], Loss: 4.2993\n",
      "Epoch [48/100], Step [42100/6235], Loss: 12.0449\n",
      "Epoch [48/100], Step [42200/6235], Loss: 31.1252\n",
      "Epoch [48/100], Step [42300/6235], Loss: 2.7406\n",
      "Epoch [48/100], Step [42400/6235], Loss: 4.5986\n",
      "Epoch [48/100], Step [42500/6235], Loss: 0.7625\n",
      "Epoch [48/100], Step [42600/6235], Loss: 1.5757\n",
      "Epoch [48/100], Step [42700/6235], Loss: 0.2714\n",
      "Epoch [48/100], Step [42800/6235], Loss: 16.2713\n",
      "Epoch [48/100], Step [42900/6235], Loss: 0.2364\n",
      "Epoch [48/100], Step [43000/6235], Loss: 0.3872\n",
      "Epoch [48/100], Step [43100/6235], Loss: 0.0428\n",
      "Epoch [48/100], Step [43200/6235], Loss: 0.2201\n",
      "Epoch [48/100], Step [43300/6235], Loss: 4.9934\n",
      "Epoch [48/100], Step [43400/6235], Loss: 5.7729\n",
      "Epoch [48/100], Step [43500/6235], Loss: 11.1367\n",
      "Epoch [48/100], Step [43600/6235], Loss: 2.2141\n",
      "Epoch [48/100], Step [43700/6235], Loss: 51.1061\n",
      "Epoch [48/100], Step [43800/6235], Loss: 0.4955\n",
      "Epoch [48/100], Step [43900/6235], Loss: 1.0647\n",
      "Epoch [48/100], Step [44000/6235], Loss: 52.8107\n",
      "Epoch [48/100], Step [44100/6235], Loss: 2.0827\n",
      "Epoch [48/100], Step [44200/6235], Loss: 2.0307\n",
      "Epoch [48/100], Step [44300/6235], Loss: 8.7549\n",
      "Epoch [48/100], Step [44400/6235], Loss: 0.7424\n",
      "Epoch [48/100], Step [44500/6235], Loss: 4.4473\n",
      "Epoch [48/100], Step [44600/6235], Loss: 13.7195\n",
      "Epoch [48/100], Step [44700/6235], Loss: 2.6136\n",
      "Epoch [48/100], Step [44800/6235], Loss: 5.1391\n",
      "Epoch [48/100], Step [44900/6235], Loss: 11.9007\n",
      "Epoch [48/100], Step [45000/6235], Loss: 6.4843\n",
      "Epoch [48/100], Step [45100/6235], Loss: 22.6351\n",
      "Epoch [48/100], Step [45200/6235], Loss: 1.2028\n",
      "Epoch [48/100], Step [45300/6235], Loss: 25.3800\n",
      "Epoch [48/100], Step [45400/6235], Loss: 8.1042\n",
      "Epoch [48/100], Step [45500/6235], Loss: 2.6989\n",
      "Epoch [48/100], Step [45600/6235], Loss: 0.8327\n",
      "Epoch [48/100], Step [45700/6235], Loss: 104.3978\n",
      "Epoch [48/100], Step [45800/6235], Loss: 324.1842\n",
      "Epoch [48/100], Step [45900/6235], Loss: 4.0586\n",
      "Epoch [48/100], Step [46000/6235], Loss: 4.0347\n",
      "Epoch [48/100], Step [46100/6235], Loss: 15.4882\n",
      "Epoch [48/100], Step [46200/6235], Loss: 113.6869\n",
      "Epoch [48/100], Step [46300/6235], Loss: 195.0103\n",
      "Epoch [48/100], Step [46400/6235], Loss: 11.5521\n",
      "Epoch [48/100], Step [46500/6235], Loss: 38.2288\n",
      "Epoch [48/100], Step [46600/6235], Loss: 6.8450\n",
      "Epoch [48/100], Step [46700/6235], Loss: 15.5338\n",
      "Epoch [48/100], Step [46800/6235], Loss: 74.4858\n",
      "Epoch [48/100], Step [46900/6235], Loss: 84.4474\n",
      "Epoch [48/100], Step [47000/6235], Loss: 0.4240\n",
      "Epoch [48/100], Step [47100/6235], Loss: 135.3735\n",
      "Epoch [48/100], Step [47200/6235], Loss: 4.5984\n",
      "Epoch [48/100], Step [47300/6235], Loss: 4.2462\n",
      "Epoch [48/100], Step [47400/6235], Loss: 289.5751\n",
      "Epoch [48/100], Step [47500/6235], Loss: 2.9111\n",
      "Epoch [48/100], Step [47600/6235], Loss: 1.1394\n",
      "Epoch [48/100], Step [47700/6235], Loss: 1.4539\n",
      "Epoch [48/100], Step [47800/6235], Loss: 68.4718\n",
      "Epoch [48/100], Step [47900/6235], Loss: 6.8436\n",
      "Epoch [48/100], Step [48000/6235], Loss: 97.4827\n",
      "Epoch [48/100], Step [48100/6235], Loss: 42.2666\n",
      "Epoch [48/100], Step [48200/6235], Loss: 229.6143\n",
      "Epoch [48/100], Step [48300/6235], Loss: 763.5800\n",
      "Epoch [48/100], Step [48400/6235], Loss: 3.3676\n",
      "Epoch [48/100], Step [48500/6235], Loss: 15.8698\n",
      "Epoch [48/100], Step [48600/6235], Loss: 20.1931\n",
      "Epoch [48/100], Step [48700/6235], Loss: 44.4544\n",
      "Epoch [48/100], Step [48800/6235], Loss: 639.5325\n",
      "Epoch [48/100], Step [48900/6235], Loss: 705.2236\n",
      "Epoch [48/100], Step [49000/6235], Loss: 207.4607\n",
      "Epoch [48/100], Step [49100/6235], Loss: 1405.5099\n",
      "Epoch [48/100], Step [49200/6235], Loss: 378.1353\n",
      "Epoch [48/100], Step [49300/6235], Loss: 654.0119\n",
      "Epoch [48/100], Step [49400/6235], Loss: 7.4850\n",
      "Epoch [48/100], Step [49500/6235], Loss: 22.0919\n",
      "Epoch [48/100], Step [49600/6235], Loss: 151.2744\n",
      "Epoch [48/100], Step [49700/6235], Loss: 2748.1897\n",
      "Epoch [48/100], Step [49800/6235], Loss: 570.5927\n",
      "Epoch [49/100], Step [100/6235], Loss: 33.9759\n",
      "Epoch [49/100], Step [200/6235], Loss: 0.7958\n",
      "Epoch [49/100], Step [300/6235], Loss: 0.1308\n",
      "Epoch [49/100], Step [400/6235], Loss: 0.0184\n",
      "Epoch [49/100], Step [500/6235], Loss: 8.3716\n",
      "Epoch [49/100], Step [600/6235], Loss: 0.1487\n",
      "Epoch [49/100], Step [700/6235], Loss: 0.7534\n",
      "Epoch [49/100], Step [800/6235], Loss: 0.0297\n",
      "Epoch [49/100], Step [900/6235], Loss: 0.0949\n",
      "Epoch [49/100], Step [1000/6235], Loss: 0.0381\n",
      "Epoch [49/100], Step [1100/6235], Loss: 0.5119\n",
      "Epoch [49/100], Step [1200/6235], Loss: 0.1751\n",
      "Epoch [49/100], Step [1300/6235], Loss: 0.0798\n",
      "Epoch [49/100], Step [1400/6235], Loss: 1.1434\n",
      "Epoch [49/100], Step [1500/6235], Loss: 0.0231\n",
      "Epoch [49/100], Step [1600/6235], Loss: 0.2487\n",
      "Epoch [49/100], Step [1700/6235], Loss: 0.2780\n",
      "Epoch [49/100], Step [1800/6235], Loss: 0.3070\n",
      "Epoch [49/100], Step [1900/6235], Loss: 0.3049\n",
      "Epoch [49/100], Step [2000/6235], Loss: 2.3940\n",
      "Epoch [49/100], Step [2100/6235], Loss: 2.9450\n",
      "Epoch [49/100], Step [2200/6235], Loss: 4.9392\n",
      "Epoch [49/100], Step [2300/6235], Loss: 0.7321\n",
      "Epoch [49/100], Step [2400/6235], Loss: 3.4516\n",
      "Epoch [49/100], Step [2500/6235], Loss: 8.8776\n",
      "Epoch [49/100], Step [2600/6235], Loss: 16.1990\n",
      "Epoch [49/100], Step [2700/6235], Loss: 14.0738\n",
      "Epoch [49/100], Step [2800/6235], Loss: 60.5237\n",
      "Epoch [49/100], Step [2900/6235], Loss: 8.2218\n",
      "Epoch [49/100], Step [3000/6235], Loss: 0.8163\n",
      "Epoch [49/100], Step [3100/6235], Loss: 92.4622\n",
      "Epoch [49/100], Step [3200/6235], Loss: 16.6236\n",
      "Epoch [49/100], Step [3300/6235], Loss: 0.7605\n",
      "Epoch [49/100], Step [3400/6235], Loss: 7.3605\n",
      "Epoch [49/100], Step [3500/6235], Loss: 64.3129\n",
      "Epoch [49/100], Step [3600/6235], Loss: 0.6240\n",
      "Epoch [49/100], Step [3700/6235], Loss: 0.1405\n",
      "Epoch [49/100], Step [3800/6235], Loss: 0.1378\n",
      "Epoch [49/100], Step [3900/6235], Loss: 0.1590\n",
      "Epoch [49/100], Step [4000/6235], Loss: 0.2401\n",
      "Epoch [49/100], Step [4100/6235], Loss: 8.5237\n",
      "Epoch [49/100], Step [4200/6235], Loss: 4.7995\n",
      "Epoch [49/100], Step [4300/6235], Loss: 2.4096\n",
      "Epoch [49/100], Step [4400/6235], Loss: 0.0397\n",
      "Epoch [49/100], Step [4500/6235], Loss: 48.5195\n",
      "Epoch [49/100], Step [4600/6235], Loss: 9.7251\n",
      "Epoch [49/100], Step [4700/6235], Loss: 0.8545\n",
      "Epoch [49/100], Step [4800/6235], Loss: 2.7751\n",
      "Epoch [49/100], Step [4900/6235], Loss: 4.1772\n",
      "Epoch [49/100], Step [5000/6235], Loss: 0.2081\n",
      "Epoch [49/100], Step [5100/6235], Loss: 3.3069\n",
      "Epoch [49/100], Step [5200/6235], Loss: 5.2807\n",
      "Epoch [49/100], Step [5300/6235], Loss: 10.6272\n",
      "Epoch [49/100], Step [5400/6235], Loss: 3.0537\n",
      "Epoch [49/100], Step [5500/6235], Loss: 0.1304\n",
      "Epoch [49/100], Step [5600/6235], Loss: 0.0134\n",
      "Epoch [49/100], Step [5700/6235], Loss: 0.1401\n",
      "Epoch [49/100], Step [5800/6235], Loss: 0.6870\n",
      "Epoch [49/100], Step [5900/6235], Loss: 0.0251\n",
      "Epoch [49/100], Step [6000/6235], Loss: 1.8844\n",
      "Epoch [49/100], Step [6100/6235], Loss: 0.1474\n",
      "Epoch [49/100], Step [6200/6235], Loss: 7.1671\n",
      "Epoch [49/100], Step [6300/6235], Loss: 1.1131\n",
      "Epoch [49/100], Step [6400/6235], Loss: 0.0836\n",
      "Epoch [49/100], Step [6500/6235], Loss: 1.5837\n",
      "Epoch [49/100], Step [6600/6235], Loss: 19.0157\n",
      "Epoch [49/100], Step [6700/6235], Loss: 0.2088\n",
      "Epoch [49/100], Step [6800/6235], Loss: 0.1155\n",
      "Epoch [49/100], Step [6900/6235], Loss: 0.2346\n",
      "Epoch [49/100], Step [7000/6235], Loss: 0.0668\n",
      "Epoch [49/100], Step [7100/6235], Loss: 0.6418\n",
      "Epoch [49/100], Step [7200/6235], Loss: 1.9449\n",
      "Epoch [49/100], Step [7300/6235], Loss: 1.1628\n",
      "Epoch [49/100], Step [7400/6235], Loss: 0.0374\n",
      "Epoch [49/100], Step [7500/6235], Loss: 0.2772\n",
      "Epoch [49/100], Step [7600/6235], Loss: 5.0663\n",
      "Epoch [49/100], Step [7700/6235], Loss: 4.2627\n",
      "Epoch [49/100], Step [7800/6235], Loss: 6.1362\n",
      "Epoch [49/100], Step [7900/6235], Loss: 11.5216\n",
      "Epoch [49/100], Step [8000/6235], Loss: 0.1948\n",
      "Epoch [49/100], Step [8100/6235], Loss: 0.1203\n",
      "Epoch [49/100], Step [8200/6235], Loss: 10.4898\n",
      "Epoch [49/100], Step [8300/6235], Loss: 10.3079\n",
      "Epoch [49/100], Step [8400/6235], Loss: 477.0334\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Step [8500/6235], Loss: 9.4265\n",
      "Epoch [49/100], Step [8600/6235], Loss: 70.0197\n",
      "Epoch [49/100], Step [8700/6235], Loss: 61.0297\n",
      "Epoch [49/100], Step [8800/6235], Loss: 130.1939\n",
      "Epoch [49/100], Step [8900/6235], Loss: 6.9299\n",
      "Epoch [49/100], Step [9000/6235], Loss: 575.4134\n",
      "Epoch [49/100], Step [9100/6235], Loss: 203.2547\n",
      "Epoch [49/100], Step [9200/6235], Loss: 1178.0343\n",
      "Epoch [49/100], Step [9300/6235], Loss: 124.7905\n",
      "Epoch [49/100], Step [9400/6235], Loss: 24.2360\n",
      "Epoch [49/100], Step [9500/6235], Loss: 559.7394\n",
      "Epoch [49/100], Step [9600/6235], Loss: 1138.7867\n",
      "Epoch [49/100], Step [9700/6235], Loss: 7.7799\n",
      "Epoch [49/100], Step [9800/6235], Loss: 5107.2441\n",
      "Epoch [49/100], Step [9900/6235], Loss: 2.9348\n",
      "Epoch [49/100], Step [10000/6235], Loss: 55.5584\n",
      "Epoch [49/100], Step [10100/6235], Loss: 3.2394\n",
      "Epoch [49/100], Step [10200/6235], Loss: 1134.6993\n",
      "Epoch [49/100], Step [10300/6235], Loss: 31.7618\n",
      "Epoch [49/100], Step [10400/6235], Loss: 8.7254\n",
      "Epoch [49/100], Step [10500/6235], Loss: 37.6902\n",
      "Epoch [49/100], Step [10600/6235], Loss: 23.0946\n",
      "Epoch [49/100], Step [10700/6235], Loss: 11.9869\n",
      "Epoch [49/100], Step [10800/6235], Loss: 118.5216\n",
      "Epoch [49/100], Step [10900/6235], Loss: 93.7732\n",
      "Epoch [49/100], Step [11000/6235], Loss: 296.5970\n",
      "Epoch [49/100], Step [11100/6235], Loss: 32.8195\n",
      "Epoch [49/100], Step [11200/6235], Loss: 5.2113\n",
      "Epoch [49/100], Step [11300/6235], Loss: 103.1587\n",
      "Epoch [49/100], Step [11400/6235], Loss: 12.0343\n",
      "Epoch [49/100], Step [11500/6235], Loss: 9.8216\n",
      "Epoch [49/100], Step [11600/6235], Loss: 7.0188\n",
      "Epoch [49/100], Step [11700/6235], Loss: 43.6759\n",
      "Epoch [49/100], Step [11800/6235], Loss: 404.0441\n",
      "Epoch [49/100], Step [11900/6235], Loss: 24.4100\n",
      "Epoch [49/100], Step [12000/6235], Loss: 736.9237\n",
      "Epoch [49/100], Step [12100/6235], Loss: 271.8766\n",
      "Epoch [49/100], Step [12200/6235], Loss: 3.2776\n",
      "Epoch [49/100], Step [12300/6235], Loss: 2.7168\n",
      "Epoch [49/100], Step [12400/6235], Loss: 349.7195\n",
      "Epoch [49/100], Step [12500/6235], Loss: 27.0903\n",
      "Epoch [49/100], Step [12600/6235], Loss: 31.3857\n",
      "Epoch [49/100], Step [12700/6235], Loss: 4.0134\n",
      "Epoch [49/100], Step [12800/6235], Loss: 10.1071\n",
      "Epoch [49/100], Step [12900/6235], Loss: 38.3134\n",
      "Epoch [49/100], Step [13000/6235], Loss: 0.5711\n",
      "Epoch [49/100], Step [13100/6235], Loss: 68.4558\n",
      "Epoch [49/100], Step [13200/6235], Loss: 10.1517\n",
      "Epoch [49/100], Step [13300/6235], Loss: 29.8497\n",
      "Epoch [49/100], Step [13400/6235], Loss: 251.6267\n",
      "Epoch [49/100], Step [13500/6235], Loss: 1.1516\n",
      "Epoch [49/100], Step [13600/6235], Loss: 4.4341\n",
      "Epoch [49/100], Step [13700/6235], Loss: 175.3982\n",
      "Epoch [49/100], Step [13800/6235], Loss: 85.0547\n",
      "Epoch [49/100], Step [13900/6235], Loss: 4.5981\n",
      "Epoch [49/100], Step [14000/6235], Loss: 8.7233\n",
      "Epoch [49/100], Step [14100/6235], Loss: 17.0804\n",
      "Epoch [49/100], Step [14200/6235], Loss: 125.0793\n",
      "Epoch [49/100], Step [14300/6235], Loss: 56.3655\n",
      "Epoch [49/100], Step [14400/6235], Loss: 39.1561\n",
      "Epoch [49/100], Step [14500/6235], Loss: 36.6678\n",
      "Epoch [49/100], Step [14600/6235], Loss: 0.2487\n",
      "Epoch [49/100], Step [14700/6235], Loss: 40.3963\n",
      "Epoch [49/100], Step [14800/6235], Loss: 33.9142\n",
      "Epoch [49/100], Step [14900/6235], Loss: 0.8974\n",
      "Epoch [49/100], Step [15000/6235], Loss: 1.7223\n",
      "Epoch [49/100], Step [15100/6235], Loss: 0.5000\n",
      "Epoch [49/100], Step [15200/6235], Loss: 0.1379\n",
      "Epoch [49/100], Step [15300/6235], Loss: 37.9510\n",
      "Epoch [49/100], Step [15400/6235], Loss: 61.4880\n",
      "Epoch [49/100], Step [15500/6235], Loss: 15.8966\n",
      "Epoch [49/100], Step [15600/6235], Loss: 193.9760\n",
      "Epoch [49/100], Step [15700/6235], Loss: 163.5055\n",
      "Epoch [49/100], Step [15800/6235], Loss: 4.3501\n",
      "Epoch [49/100], Step [15900/6235], Loss: 1.6819\n",
      "Epoch [49/100], Step [16000/6235], Loss: 168.0928\n",
      "Epoch [49/100], Step [16100/6235], Loss: 1.4028\n",
      "Epoch [49/100], Step [16200/6235], Loss: 0.3368\n",
      "Epoch [49/100], Step [16300/6235], Loss: 10.4669\n",
      "Epoch [49/100], Step [16400/6235], Loss: 27.7106\n",
      "Epoch [49/100], Step [16500/6235], Loss: 692.6333\n",
      "Epoch [49/100], Step [16600/6235], Loss: 19.1865\n",
      "Epoch [49/100], Step [16700/6235], Loss: 0.6308\n",
      "Epoch [49/100], Step [16800/6235], Loss: 8.0937\n",
      "Epoch [49/100], Step [16900/6235], Loss: 0.1028\n",
      "Epoch [49/100], Step [17000/6235], Loss: 0.2577\n",
      "Epoch [49/100], Step [17100/6235], Loss: 0.3849\n",
      "Epoch [49/100], Step [17200/6235], Loss: 307.0428\n",
      "Epoch [49/100], Step [17300/6235], Loss: 58.9748\n",
      "Epoch [49/100], Step [17400/6235], Loss: 69.1642\n",
      "Epoch [49/100], Step [17500/6235], Loss: 0.6084\n",
      "Epoch [49/100], Step [17600/6235], Loss: 4.4996\n",
      "Epoch [49/100], Step [17700/6235], Loss: 4.0065\n",
      "Epoch [49/100], Step [17800/6235], Loss: 16.2574\n",
      "Epoch [49/100], Step [17900/6235], Loss: 27.6114\n",
      "Epoch [49/100], Step [18000/6235], Loss: 11.1273\n",
      "Epoch [49/100], Step [18100/6235], Loss: 15.6317\n",
      "Epoch [49/100], Step [18200/6235], Loss: 0.3543\n",
      "Epoch [49/100], Step [18300/6235], Loss: 0.8173\n",
      "Epoch [49/100], Step [18400/6235], Loss: 0.2010\n",
      "Epoch [49/100], Step [18500/6235], Loss: 35.2411\n",
      "Epoch [49/100], Step [18600/6235], Loss: 4.4362\n",
      "Epoch [49/100], Step [18700/6235], Loss: 1.0198\n",
      "Epoch [49/100], Step [18800/6235], Loss: 146.9063\n",
      "Epoch [49/100], Step [18900/6235], Loss: 45.6636\n",
      "Epoch [49/100], Step [19000/6235], Loss: 7.7345\n",
      "Epoch [49/100], Step [19100/6235], Loss: 35.0131\n",
      "Epoch [49/100], Step [19200/6235], Loss: 1.1517\n",
      "Epoch [49/100], Step [19300/6235], Loss: 1.2804\n",
      "Epoch [49/100], Step [19400/6235], Loss: 14.0655\n",
      "Epoch [49/100], Step [19500/6235], Loss: 19.3855\n",
      "Epoch [49/100], Step [19600/6235], Loss: 25.2072\n",
      "Epoch [49/100], Step [19700/6235], Loss: 6.0541\n",
      "Epoch [49/100], Step [19800/6235], Loss: 5.1747\n",
      "Epoch [49/100], Step [19900/6235], Loss: 0.1103\n",
      "Epoch [49/100], Step [20000/6235], Loss: 68.5148\n",
      "Epoch [49/100], Step [20100/6235], Loss: 4.0190\n",
      "Epoch [49/100], Step [20200/6235], Loss: 0.1149\n",
      "Epoch [49/100], Step [20300/6235], Loss: 1.3251\n",
      "Epoch [49/100], Step [20400/6235], Loss: 8.3292\n",
      "Epoch [49/100], Step [20500/6235], Loss: 56.9442\n",
      "Epoch [49/100], Step [20600/6235], Loss: 248.4111\n",
      "Epoch [49/100], Step [20700/6235], Loss: 10.6158\n",
      "Epoch [49/100], Step [20800/6235], Loss: 1.8649\n",
      "Epoch [49/100], Step [20900/6235], Loss: 19.8796\n",
      "Epoch [49/100], Step [21000/6235], Loss: 18.1366\n",
      "Epoch [49/100], Step [21100/6235], Loss: 6.3813\n",
      "Epoch [49/100], Step [21200/6235], Loss: 0.3125\n",
      "Epoch [49/100], Step [21300/6235], Loss: 0.0996\n",
      "Epoch [49/100], Step [21400/6235], Loss: 4.8452\n",
      "Epoch [49/100], Step [21500/6235], Loss: 0.5889\n",
      "Epoch [49/100], Step [21600/6235], Loss: 29.0911\n",
      "Epoch [49/100], Step [21700/6235], Loss: 0.2970\n",
      "Epoch [49/100], Step [21800/6235], Loss: 0.6472\n",
      "Epoch [49/100], Step [21900/6235], Loss: 1.6359\n",
      "Epoch [49/100], Step [22000/6235], Loss: 8.3704\n",
      "Epoch [49/100], Step [22100/6235], Loss: 0.3600\n",
      "Epoch [49/100], Step [22200/6235], Loss: 3.9728\n",
      "Epoch [49/100], Step [22300/6235], Loss: 7.9403\n",
      "Epoch [49/100], Step [22400/6235], Loss: 1.0983\n",
      "Epoch [49/100], Step [22500/6235], Loss: 142.9407\n",
      "Epoch [49/100], Step [22600/6235], Loss: 29.3605\n",
      "Epoch [49/100], Step [22700/6235], Loss: 0.8386\n",
      "Epoch [49/100], Step [22800/6235], Loss: 10.2096\n",
      "Epoch [49/100], Step [22900/6235], Loss: 21.9387\n",
      "Epoch [49/100], Step [23000/6235], Loss: 4.2272\n",
      "Epoch [49/100], Step [23100/6235], Loss: 6.3709\n",
      "Epoch [49/100], Step [23200/6235], Loss: 4.4034\n",
      "Epoch [49/100], Step [23300/6235], Loss: 19.4547\n",
      "Epoch [49/100], Step [23400/6235], Loss: 1.7946\n",
      "Epoch [49/100], Step [23500/6235], Loss: 0.1021\n",
      "Epoch [49/100], Step [23600/6235], Loss: 126.9462\n",
      "Epoch [49/100], Step [23700/6235], Loss: 2.6476\n",
      "Epoch [49/100], Step [23800/6235], Loss: 1.0380\n",
      "Epoch [49/100], Step [23900/6235], Loss: 5.1824\n",
      "Epoch [49/100], Step [24000/6235], Loss: 0.2481\n",
      "Epoch [49/100], Step [24100/6235], Loss: 0.7476\n",
      "Epoch [49/100], Step [24200/6235], Loss: 30.3212\n",
      "Epoch [49/100], Step [24300/6235], Loss: 1.1224\n",
      "Epoch [49/100], Step [24400/6235], Loss: 2.0633\n",
      "Epoch [49/100], Step [24500/6235], Loss: 0.4740\n",
      "Epoch [49/100], Step [24600/6235], Loss: 0.0220\n",
      "Epoch [49/100], Step [24700/6235], Loss: 0.2341\n",
      "Epoch [49/100], Step [24800/6235], Loss: 0.3221\n",
      "Epoch [49/100], Step [24900/6235], Loss: 9.1402\n",
      "Epoch [49/100], Step [25000/6235], Loss: 14.1513\n",
      "Epoch [49/100], Step [25100/6235], Loss: 6.3324\n",
      "Epoch [49/100], Step [25200/6235], Loss: 0.2459\n",
      "Epoch [49/100], Step [25300/6235], Loss: 0.7123\n",
      "Epoch [49/100], Step [25400/6235], Loss: 6.0790\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Step [25500/6235], Loss: 7.9854\n",
      "Epoch [49/100], Step [25600/6235], Loss: 5.4764\n",
      "Epoch [49/100], Step [25700/6235], Loss: 0.3248\n",
      "Epoch [49/100], Step [25800/6235], Loss: 0.0986\n",
      "Epoch [49/100], Step [25900/6235], Loss: 7.7690\n",
      "Epoch [49/100], Step [26000/6235], Loss: 1.9952\n",
      "Epoch [49/100], Step [26100/6235], Loss: 0.0799\n",
      "Epoch [49/100], Step [26200/6235], Loss: 1.1199\n",
      "Epoch [49/100], Step [26300/6235], Loss: 3.2800\n",
      "Epoch [49/100], Step [26400/6235], Loss: 0.1162\n",
      "Epoch [49/100], Step [26500/6235], Loss: 0.0080\n",
      "Epoch [49/100], Step [26600/6235], Loss: 1.1952\n",
      "Epoch [49/100], Step [26700/6235], Loss: 0.3100\n",
      "Epoch [49/100], Step [26800/6235], Loss: 0.1571\n",
      "Epoch [49/100], Step [26900/6235], Loss: 0.0060\n",
      "Epoch [49/100], Step [27000/6235], Loss: 15.4850\n",
      "Epoch [49/100], Step [27100/6235], Loss: 0.0442\n",
      "Epoch [49/100], Step [27200/6235], Loss: 0.0207\n",
      "Epoch [49/100], Step [27300/6235], Loss: 0.1900\n",
      "Epoch [49/100], Step [27400/6235], Loss: 0.7333\n",
      "Epoch [49/100], Step [27500/6235], Loss: 4.6366\n",
      "Epoch [49/100], Step [27600/6235], Loss: 1.1175\n",
      "Epoch [49/100], Step [27700/6235], Loss: 1.3825\n",
      "Epoch [49/100], Step [27800/6235], Loss: 5.6297\n",
      "Epoch [49/100], Step [27900/6235], Loss: 0.5942\n",
      "Epoch [49/100], Step [28000/6235], Loss: 61.8354\n",
      "Epoch [49/100], Step [28100/6235], Loss: 3.2131\n",
      "Epoch [49/100], Step [28200/6235], Loss: 9.6039\n",
      "Epoch [49/100], Step [28300/6235], Loss: 2.9386\n",
      "Epoch [49/100], Step [28400/6235], Loss: 23.7997\n",
      "Epoch [49/100], Step [28500/6235], Loss: 4.4990\n",
      "Epoch [49/100], Step [28600/6235], Loss: 0.4647\n",
      "Epoch [49/100], Step [28700/6235], Loss: 5.0132\n",
      "Epoch [49/100], Step [28800/6235], Loss: 0.6547\n",
      "Epoch [49/100], Step [28900/6235], Loss: 65.3763\n",
      "Epoch [49/100], Step [29000/6235], Loss: 15.4074\n",
      "Epoch [49/100], Step [29100/6235], Loss: 0.3875\n",
      "Epoch [49/100], Step [29200/6235], Loss: 2.7747\n",
      "Epoch [49/100], Step [29300/6235], Loss: 3.6060\n",
      "Epoch [49/100], Step [29400/6235], Loss: 0.7888\n",
      "Epoch [49/100], Step [29500/6235], Loss: 3.6812\n",
      "Epoch [49/100], Step [29600/6235], Loss: 0.0220\n",
      "Epoch [49/100], Step [29700/6235], Loss: 1.7306\n",
      "Epoch [49/100], Step [29800/6235], Loss: 1.4384\n",
      "Epoch [49/100], Step [29900/6235], Loss: 1.4481\n",
      "Epoch [49/100], Step [30000/6235], Loss: 5.6274\n",
      "Epoch [49/100], Step [30100/6235], Loss: 9.1420\n",
      "Epoch [49/100], Step [30200/6235], Loss: 1.3982\n",
      "Epoch [49/100], Step [30300/6235], Loss: 0.0443\n",
      "Epoch [49/100], Step [30400/6235], Loss: 1.4028\n",
      "Epoch [49/100], Step [30500/6235], Loss: 2.6051\n",
      "Epoch [49/100], Step [30600/6235], Loss: 1.8671\n",
      "Epoch [49/100], Step [30700/6235], Loss: 1.0673\n",
      "Epoch [49/100], Step [30800/6235], Loss: 0.5514\n",
      "Epoch [49/100], Step [30900/6235], Loss: 3.2150\n",
      "Epoch [49/100], Step [31000/6235], Loss: 0.2775\n",
      "Epoch [49/100], Step [31100/6235], Loss: 0.0439\n",
      "Epoch [49/100], Step [31200/6235], Loss: 6.0246\n",
      "Epoch [49/100], Step [31300/6235], Loss: 1.6774\n",
      "Epoch [49/100], Step [31400/6235], Loss: 0.0463\n",
      "Epoch [49/100], Step [31500/6235], Loss: 0.7591\n",
      "Epoch [49/100], Step [31600/6235], Loss: 8.9318\n",
      "Epoch [49/100], Step [31700/6235], Loss: 6.6391\n",
      "Epoch [49/100], Step [31800/6235], Loss: 1.2944\n",
      "Epoch [49/100], Step [31900/6235], Loss: 1572.1857\n",
      "Epoch [49/100], Step [32000/6235], Loss: 10.9838\n",
      "Epoch [49/100], Step [32100/6235], Loss: 0.2774\n",
      "Epoch [49/100], Step [32200/6235], Loss: 131.8423\n",
      "Epoch [49/100], Step [32300/6235], Loss: 0.9612\n",
      "Epoch [49/100], Step [32400/6235], Loss: 1.3280\n",
      "Epoch [49/100], Step [32500/6235], Loss: 16.6463\n",
      "Epoch [49/100], Step [32600/6235], Loss: 0.4783\n",
      "Epoch [49/100], Step [32700/6235], Loss: 79.4893\n",
      "Epoch [49/100], Step [32800/6235], Loss: 14.9831\n",
      "Epoch [49/100], Step [32900/6235], Loss: 0.3136\n",
      "Epoch [49/100], Step [33000/6235], Loss: 0.2161\n",
      "Epoch [49/100], Step [33100/6235], Loss: 0.7617\n",
      "Epoch [49/100], Step [33200/6235], Loss: 1.0054\n",
      "Epoch [49/100], Step [33300/6235], Loss: 1.0995\n",
      "Epoch [49/100], Step [33400/6235], Loss: 135.2819\n",
      "Epoch [49/100], Step [33500/6235], Loss: 1.8113\n",
      "Epoch [49/100], Step [33600/6235], Loss: 6.9623\n",
      "Epoch [49/100], Step [33700/6235], Loss: 4.3633\n",
      "Epoch [49/100], Step [33800/6235], Loss: 1.2013\n",
      "Epoch [49/100], Step [33900/6235], Loss: 26.1467\n",
      "Epoch [49/100], Step [34000/6235], Loss: 0.0601\n",
      "Epoch [49/100], Step [34100/6235], Loss: 0.4544\n",
      "Epoch [49/100], Step [34200/6235], Loss: 1.9110\n",
      "Epoch [49/100], Step [34300/6235], Loss: 4.1299\n",
      "Epoch [49/100], Step [34400/6235], Loss: 0.1341\n",
      "Epoch [49/100], Step [34500/6235], Loss: 22.9903\n",
      "Epoch [49/100], Step [34600/6235], Loss: 1.3125\n",
      "Epoch [49/100], Step [34700/6235], Loss: 26.9511\n",
      "Epoch [49/100], Step [34800/6235], Loss: 9.4864\n",
      "Epoch [49/100], Step [34900/6235], Loss: 67.2242\n",
      "Epoch [49/100], Step [35000/6235], Loss: 0.2059\n",
      "Epoch [49/100], Step [35100/6235], Loss: 0.9933\n",
      "Epoch [49/100], Step [35200/6235], Loss: 0.5113\n",
      "Epoch [49/100], Step [35300/6235], Loss: 3.1168\n",
      "Epoch [49/100], Step [35400/6235], Loss: 0.4765\n",
      "Epoch [49/100], Step [35500/6235], Loss: 0.6741\n",
      "Epoch [49/100], Step [35600/6235], Loss: 1.6898\n",
      "Epoch [49/100], Step [35700/6235], Loss: 3.7151\n",
      "Epoch [49/100], Step [35800/6235], Loss: 0.8482\n",
      "Epoch [49/100], Step [35900/6235], Loss: 1.6237\n",
      "Epoch [49/100], Step [36000/6235], Loss: 0.3013\n",
      "Epoch [49/100], Step [36100/6235], Loss: 0.0451\n",
      "Epoch [49/100], Step [36200/6235], Loss: 14.7561\n",
      "Epoch [49/100], Step [36300/6235], Loss: 2.3010\n",
      "Epoch [49/100], Step [36400/6235], Loss: 3.0591\n",
      "Epoch [49/100], Step [36500/6235], Loss: 7.7120\n",
      "Epoch [49/100], Step [36600/6235], Loss: 0.1011\n",
      "Epoch [49/100], Step [36700/6235], Loss: 0.5976\n",
      "Epoch [49/100], Step [36800/6235], Loss: 5.6032\n",
      "Epoch [49/100], Step [36900/6235], Loss: 11.2742\n",
      "Epoch [49/100], Step [37000/6235], Loss: 0.9241\n",
      "Epoch [49/100], Step [37100/6235], Loss: 1.9430\n",
      "Epoch [49/100], Step [37200/6235], Loss: 0.0470\n",
      "Epoch [49/100], Step [37300/6235], Loss: 0.0367\n",
      "Epoch [49/100], Step [37400/6235], Loss: 0.1736\n",
      "Epoch [49/100], Step [37500/6235], Loss: 6.5286\n",
      "Epoch [49/100], Step [37600/6235], Loss: 12.1401\n",
      "Epoch [49/100], Step [37700/6235], Loss: 1.2084\n",
      "Epoch [49/100], Step [37800/6235], Loss: 4.5953\n",
      "Epoch [49/100], Step [37900/6235], Loss: 6.4960\n",
      "Epoch [49/100], Step [38000/6235], Loss: 0.8959\n",
      "Epoch [49/100], Step [38100/6235], Loss: 4.0466\n",
      "Epoch [49/100], Step [38200/6235], Loss: 1.7888\n",
      "Epoch [49/100], Step [38300/6235], Loss: 0.3161\n",
      "Epoch [49/100], Step [38400/6235], Loss: 0.0502\n",
      "Epoch [49/100], Step [38500/6235], Loss: 1.6495\n",
      "Epoch [49/100], Step [38600/6235], Loss: 0.4203\n",
      "Epoch [49/100], Step [38700/6235], Loss: 0.3237\n",
      "Epoch [49/100], Step [38800/6235], Loss: 0.1266\n",
      "Epoch [49/100], Step [38900/6235], Loss: 3.9970\n",
      "Epoch [49/100], Step [39000/6235], Loss: 8.3918\n",
      "Epoch [49/100], Step [39100/6235], Loss: 19.6417\n",
      "Epoch [49/100], Step [39200/6235], Loss: 0.3023\n",
      "Epoch [49/100], Step [39300/6235], Loss: 76.4938\n",
      "Epoch [49/100], Step [39400/6235], Loss: 77.5821\n",
      "Epoch [49/100], Step [39500/6235], Loss: 410.7360\n",
      "Epoch [49/100], Step [39600/6235], Loss: 27.1957\n",
      "Epoch [49/100], Step [39700/6235], Loss: 19.6876\n",
      "Epoch [49/100], Step [39800/6235], Loss: 149.2352\n",
      "Epoch [49/100], Step [39900/6235], Loss: 3.0087\n",
      "Epoch [49/100], Step [40000/6235], Loss: 18.9487\n",
      "Epoch [49/100], Step [40100/6235], Loss: 26.4415\n",
      "Epoch [49/100], Step [40200/6235], Loss: 1.0426\n",
      "Epoch [49/100], Step [40300/6235], Loss: 1.0530\n",
      "Epoch [49/100], Step [40400/6235], Loss: 2.4242\n",
      "Epoch [49/100], Step [40500/6235], Loss: 2.2916\n",
      "Epoch [49/100], Step [40600/6235], Loss: 0.4053\n",
      "Epoch [49/100], Step [40700/6235], Loss: 7.5813\n",
      "Epoch [49/100], Step [40800/6235], Loss: 1.6438\n",
      "Epoch [49/100], Step [40900/6235], Loss: 0.0795\n",
      "Epoch [49/100], Step [41000/6235], Loss: 43.9490\n",
      "Epoch [49/100], Step [41100/6235], Loss: 22.7803\n",
      "Epoch [49/100], Step [41200/6235], Loss: 2.7924\n",
      "Epoch [49/100], Step [41300/6235], Loss: 3.1340\n",
      "Epoch [49/100], Step [41400/6235], Loss: 0.4156\n",
      "Epoch [49/100], Step [41500/6235], Loss: 1.1326\n",
      "Epoch [49/100], Step [41600/6235], Loss: 0.4009\n",
      "Epoch [49/100], Step [41700/6235], Loss: 4.1210\n",
      "Epoch [49/100], Step [41800/6235], Loss: 4.3486\n",
      "Epoch [49/100], Step [41900/6235], Loss: 3.4347\n",
      "Epoch [49/100], Step [42000/6235], Loss: 3.0807\n",
      "Epoch [49/100], Step [42100/6235], Loss: 6.6937\n",
      "Epoch [49/100], Step [42200/6235], Loss: 6.4983\n",
      "Epoch [49/100], Step [42300/6235], Loss: 0.5424\n",
      "Epoch [49/100], Step [42400/6235], Loss: 2.2015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [49/100], Step [42500/6235], Loss: 3.7588\n",
      "Epoch [49/100], Step [42600/6235], Loss: 0.5746\n",
      "Epoch [49/100], Step [42700/6235], Loss: 0.2648\n",
      "Epoch [49/100], Step [42800/6235], Loss: 1.4593\n",
      "Epoch [49/100], Step [42900/6235], Loss: 4.2433\n",
      "Epoch [49/100], Step [43000/6235], Loss: 0.2524\n",
      "Epoch [49/100], Step [43100/6235], Loss: 0.9448\n",
      "Epoch [49/100], Step [43200/6235], Loss: 0.7769\n",
      "Epoch [49/100], Step [43300/6235], Loss: 9.4666\n",
      "Epoch [49/100], Step [43400/6235], Loss: 8.8017\n",
      "Epoch [49/100], Step [43500/6235], Loss: 8.8593\n",
      "Epoch [49/100], Step [43600/6235], Loss: 24.4456\n",
      "Epoch [49/100], Step [43700/6235], Loss: 37.2893\n",
      "Epoch [49/100], Step [43800/6235], Loss: 0.4577\n",
      "Epoch [49/100], Step [43900/6235], Loss: 1.1009\n",
      "Epoch [49/100], Step [44000/6235], Loss: 47.2136\n",
      "Epoch [49/100], Step [44100/6235], Loss: 2.0603\n",
      "Epoch [49/100], Step [44200/6235], Loss: 6.7380\n",
      "Epoch [49/100], Step [44300/6235], Loss: 4.3929\n",
      "Epoch [49/100], Step [44400/6235], Loss: 0.9375\n",
      "Epoch [49/100], Step [44500/6235], Loss: 0.3738\n",
      "Epoch [49/100], Step [44600/6235], Loss: 17.5131\n",
      "Epoch [49/100], Step [44700/6235], Loss: 32.9226\n",
      "Epoch [49/100], Step [44800/6235], Loss: 2.1982\n",
      "Epoch [49/100], Step [44900/6235], Loss: 1.4381\n",
      "Epoch [49/100], Step [45000/6235], Loss: 5.0780\n",
      "Epoch [49/100], Step [45100/6235], Loss: 43.4814\n",
      "Epoch [49/100], Step [45200/6235], Loss: 0.4796\n",
      "Epoch [49/100], Step [45300/6235], Loss: 45.6164\n",
      "Epoch [49/100], Step [45400/6235], Loss: 10.2715\n",
      "Epoch [49/100], Step [45500/6235], Loss: 0.1567\n",
      "Epoch [49/100], Step [45600/6235], Loss: 0.1927\n",
      "Epoch [49/100], Step [45700/6235], Loss: 22.4344\n",
      "Epoch [49/100], Step [45800/6235], Loss: 296.8080\n",
      "Epoch [49/100], Step [45900/6235], Loss: 9.1517\n",
      "Epoch [49/100], Step [46000/6235], Loss: 2.4117\n",
      "Epoch [49/100], Step [46100/6235], Loss: 32.0627\n",
      "Epoch [49/100], Step [46200/6235], Loss: 22.2201\n",
      "Epoch [49/100], Step [46300/6235], Loss: 19.9395\n",
      "Epoch [49/100], Step [46400/6235], Loss: 5.0470\n",
      "Epoch [49/100], Step [46500/6235], Loss: 0.8945\n",
      "Epoch [49/100], Step [46600/6235], Loss: 15.8781\n",
      "Epoch [49/100], Step [46700/6235], Loss: 2.8591\n",
      "Epoch [49/100], Step [46800/6235], Loss: 10.6640\n",
      "Epoch [49/100], Step [46900/6235], Loss: 19.0383\n",
      "Epoch [49/100], Step [47000/6235], Loss: 0.8875\n",
      "Epoch [49/100], Step [47100/6235], Loss: 33.4929\n",
      "Epoch [49/100], Step [47200/6235], Loss: 39.2972\n",
      "Epoch [49/100], Step [47300/6235], Loss: 0.8690\n",
      "Epoch [49/100], Step [47400/6235], Loss: 87.9933\n",
      "Epoch [49/100], Step [47500/6235], Loss: 22.8809\n",
      "Epoch [49/100], Step [47600/6235], Loss: 15.7266\n",
      "Epoch [49/100], Step [47700/6235], Loss: 16.2557\n",
      "Epoch [49/100], Step [47800/6235], Loss: 18.7491\n",
      "Epoch [49/100], Step [47900/6235], Loss: 13.8578\n",
      "Epoch [49/100], Step [48000/6235], Loss: 1.5478\n",
      "Epoch [49/100], Step [48100/6235], Loss: 5.1059\n",
      "Epoch [49/100], Step [48200/6235], Loss: 10.5291\n",
      "Epoch [49/100], Step [48300/6235], Loss: 463.4418\n",
      "Epoch [49/100], Step [48400/6235], Loss: 8.9429\n",
      "Epoch [49/100], Step [48500/6235], Loss: 46.6927\n",
      "Epoch [49/100], Step [48600/6235], Loss: 103.5802\n",
      "Epoch [49/100], Step [48700/6235], Loss: 0.5890\n",
      "Epoch [49/100], Step [48800/6235], Loss: 245.8826\n",
      "Epoch [49/100], Step [48900/6235], Loss: 440.8950\n",
      "Epoch [49/100], Step [49000/6235], Loss: 205.6743\n",
      "Epoch [49/100], Step [49100/6235], Loss: 1673.3065\n",
      "Epoch [49/100], Step [49200/6235], Loss: 572.8696\n",
      "Epoch [49/100], Step [49300/6235], Loss: 1252.6777\n",
      "Epoch [49/100], Step [49400/6235], Loss: 6.5150\n",
      "Epoch [49/100], Step [49500/6235], Loss: 7.2322\n",
      "Epoch [49/100], Step [49600/6235], Loss: 272.5534\n",
      "Epoch [49/100], Step [49700/6235], Loss: 1315.0035\n",
      "Epoch [49/100], Step [49800/6235], Loss: 3302.3931\n",
      "Epoch [50/100], Step [100/6235], Loss: 31.4229\n",
      "Epoch [50/100], Step [200/6235], Loss: 0.8540\n",
      "Epoch [50/100], Step [300/6235], Loss: 0.0230\n",
      "Epoch [50/100], Step [400/6235], Loss: 0.0014\n",
      "Epoch [50/100], Step [500/6235], Loss: 1.5091\n",
      "Epoch [50/100], Step [600/6235], Loss: 0.0263\n",
      "Epoch [50/100], Step [700/6235], Loss: 0.2930\n",
      "Epoch [50/100], Step [800/6235], Loss: 0.1432\n",
      "Epoch [50/100], Step [900/6235], Loss: 0.0320\n",
      "Epoch [50/100], Step [1000/6235], Loss: 0.0254\n",
      "Epoch [50/100], Step [1100/6235], Loss: 0.0829\n",
      "Epoch [50/100], Step [1200/6235], Loss: 0.1556\n",
      "Epoch [50/100], Step [1300/6235], Loss: 0.0689\n",
      "Epoch [50/100], Step [1400/6235], Loss: 0.2568\n",
      "Epoch [50/100], Step [1500/6235], Loss: 0.0082\n",
      "Epoch [50/100], Step [1600/6235], Loss: 0.2189\n",
      "Epoch [50/100], Step [1700/6235], Loss: 0.0685\n",
      "Epoch [50/100], Step [1800/6235], Loss: 0.2165\n",
      "Epoch [50/100], Step [1900/6235], Loss: 0.8424\n",
      "Epoch [50/100], Step [2000/6235], Loss: 2.5411\n",
      "Epoch [50/100], Step [2100/6235], Loss: 1.1876\n",
      "Epoch [50/100], Step [2200/6235], Loss: 10.6902\n",
      "Epoch [50/100], Step [2300/6235], Loss: 20.1702\n",
      "Epoch [50/100], Step [2400/6235], Loss: 8.6602\n",
      "Epoch [50/100], Step [2500/6235], Loss: 45.1898\n",
      "Epoch [50/100], Step [2600/6235], Loss: 10.6770\n",
      "Epoch [50/100], Step [2700/6235], Loss: 13.7342\n",
      "Epoch [50/100], Step [2800/6235], Loss: 141.1061\n",
      "Epoch [50/100], Step [2900/6235], Loss: 18.6118\n",
      "Epoch [50/100], Step [3000/6235], Loss: 1.9054\n",
      "Epoch [50/100], Step [3100/6235], Loss: 65.5370\n",
      "Epoch [50/100], Step [3200/6235], Loss: 54.7783\n",
      "Epoch [50/100], Step [3300/6235], Loss: 11.1315\n",
      "Epoch [50/100], Step [3400/6235], Loss: 2.7751\n",
      "Epoch [50/100], Step [3500/6235], Loss: 50.4607\n",
      "Epoch [50/100], Step [3600/6235], Loss: 3.1080\n",
      "Epoch [50/100], Step [3700/6235], Loss: 0.0153\n",
      "Epoch [50/100], Step [3800/6235], Loss: 0.0088\n",
      "Epoch [50/100], Step [3900/6235], Loss: 0.0637\n",
      "Epoch [50/100], Step [4000/6235], Loss: 0.1000\n",
      "Epoch [50/100], Step [4100/6235], Loss: 9.5391\n",
      "Epoch [50/100], Step [4200/6235], Loss: 2.6810\n",
      "Epoch [50/100], Step [4300/6235], Loss: 6.9820\n",
      "Epoch [50/100], Step [4400/6235], Loss: 0.7590\n",
      "Epoch [50/100], Step [4500/6235], Loss: 36.3698\n",
      "Epoch [50/100], Step [4600/6235], Loss: 3.5485\n",
      "Epoch [50/100], Step [4700/6235], Loss: 0.3538\n",
      "Epoch [50/100], Step [4800/6235], Loss: 9.1323\n",
      "Epoch [50/100], Step [4900/6235], Loss: 0.3251\n",
      "Epoch [50/100], Step [5000/6235], Loss: 0.0818\n",
      "Epoch [50/100], Step [5100/6235], Loss: 4.2845\n",
      "Epoch [50/100], Step [5200/6235], Loss: 8.3070\n",
      "Epoch [50/100], Step [5300/6235], Loss: 32.0234\n",
      "Epoch [50/100], Step [5400/6235], Loss: 1.3508\n",
      "Epoch [50/100], Step [5500/6235], Loss: 0.1486\n",
      "Epoch [50/100], Step [5600/6235], Loss: 0.2630\n",
      "Epoch [50/100], Step [5700/6235], Loss: 0.3425\n",
      "Epoch [50/100], Step [5800/6235], Loss: 0.4965\n",
      "Epoch [50/100], Step [5900/6235], Loss: 0.3276\n",
      "Epoch [50/100], Step [6000/6235], Loss: 0.2373\n",
      "Epoch [50/100], Step [6100/6235], Loss: 0.0877\n",
      "Epoch [50/100], Step [6200/6235], Loss: 5.3030\n",
      "Epoch [50/100], Step [6300/6235], Loss: 0.4336\n",
      "Epoch [50/100], Step [6400/6235], Loss: 0.1409\n",
      "Epoch [50/100], Step [6500/6235], Loss: 2.8079\n",
      "Epoch [50/100], Step [6600/6235], Loss: 5.9639\n",
      "Epoch [50/100], Step [6700/6235], Loss: 0.9805\n",
      "Epoch [50/100], Step [6800/6235], Loss: 0.1945\n",
      "Epoch [50/100], Step [6900/6235], Loss: 1.1015\n",
      "Epoch [50/100], Step [7000/6235], Loss: 0.4515\n",
      "Epoch [50/100], Step [7100/6235], Loss: 0.3743\n",
      "Epoch [50/100], Step [7200/6235], Loss: 0.2840\n",
      "Epoch [50/100], Step [7300/6235], Loss: 1.2228\n",
      "Epoch [50/100], Step [7400/6235], Loss: 0.0115\n",
      "Epoch [50/100], Step [7500/6235], Loss: 1.0021\n",
      "Epoch [50/100], Step [7600/6235], Loss: 5.7479\n",
      "Epoch [50/100], Step [7700/6235], Loss: 6.8226\n",
      "Epoch [50/100], Step [7800/6235], Loss: 2.0113\n",
      "Epoch [50/100], Step [7900/6235], Loss: 13.2137\n",
      "Epoch [50/100], Step [8000/6235], Loss: 0.3595\n",
      "Epoch [50/100], Step [8100/6235], Loss: 0.7779\n",
      "Epoch [50/100], Step [8200/6235], Loss: 9.9502\n",
      "Epoch [50/100], Step [8300/6235], Loss: 25.0383\n",
      "Epoch [50/100], Step [8400/6235], Loss: 644.6268\n",
      "Epoch [50/100], Step [8500/6235], Loss: 17.5486\n",
      "Epoch [50/100], Step [8600/6235], Loss: 24.6407\n",
      "Epoch [50/100], Step [8700/6235], Loss: 27.6372\n",
      "Epoch [50/100], Step [8800/6235], Loss: 207.3436\n",
      "Epoch [50/100], Step [8900/6235], Loss: 268.0019\n",
      "Epoch [50/100], Step [9000/6235], Loss: 258.0957\n",
      "Epoch [50/100], Step [9100/6235], Loss: 127.6878\n",
      "Epoch [50/100], Step [9200/6235], Loss: 2824.9614\n",
      "Epoch [50/100], Step [9300/6235], Loss: 165.1309\n",
      "Epoch [50/100], Step [9400/6235], Loss: 46.5048\n",
      "Epoch [50/100], Step [9500/6235], Loss: 2404.5918\n",
      "Epoch [50/100], Step [9600/6235], Loss: 670.4756\n",
      "Epoch [50/100], Step [9700/6235], Loss: 9.1074\n",
      "Epoch [50/100], Step [9800/6235], Loss: 900.0635\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Step [9900/6235], Loss: 85.5104\n",
      "Epoch [50/100], Step [10000/6235], Loss: 320.8766\n",
      "Epoch [50/100], Step [10100/6235], Loss: 3.3087\n",
      "Epoch [50/100], Step [10200/6235], Loss: 1010.9510\n",
      "Epoch [50/100], Step [10300/6235], Loss: 51.8364\n",
      "Epoch [50/100], Step [10400/6235], Loss: 9.0661\n",
      "Epoch [50/100], Step [10500/6235], Loss: 26.4727\n",
      "Epoch [50/100], Step [10600/6235], Loss: 83.2526\n",
      "Epoch [50/100], Step [10700/6235], Loss: 13.8351\n",
      "Epoch [50/100], Step [10800/6235], Loss: 124.9938\n",
      "Epoch [50/100], Step [10900/6235], Loss: 86.0939\n",
      "Epoch [50/100], Step [11000/6235], Loss: 297.3955\n",
      "Epoch [50/100], Step [11100/6235], Loss: 37.2895\n",
      "Epoch [50/100], Step [11200/6235], Loss: 7.6212\n",
      "Epoch [50/100], Step [11300/6235], Loss: 110.8128\n",
      "Epoch [50/100], Step [11400/6235], Loss: 2.9339\n",
      "Epoch [50/100], Step [11500/6235], Loss: 7.3574\n",
      "Epoch [50/100], Step [11600/6235], Loss: 5.0044\n",
      "Epoch [50/100], Step [11700/6235], Loss: 40.1278\n",
      "Epoch [50/100], Step [11800/6235], Loss: 364.4269\n",
      "Epoch [50/100], Step [11900/6235], Loss: 20.1588\n",
      "Epoch [50/100], Step [12000/6235], Loss: 714.5535\n",
      "Epoch [50/100], Step [12100/6235], Loss: 283.5768\n",
      "Epoch [50/100], Step [12200/6235], Loss: 12.9055\n",
      "Epoch [50/100], Step [12300/6235], Loss: 0.4799\n",
      "Epoch [50/100], Step [12400/6235], Loss: 228.1523\n",
      "Epoch [50/100], Step [12500/6235], Loss: 75.6058\n",
      "Epoch [50/100], Step [12600/6235], Loss: 4.7897\n",
      "Epoch [50/100], Step [12700/6235], Loss: 8.0549\n",
      "Epoch [50/100], Step [12800/6235], Loss: 12.5889\n",
      "Epoch [50/100], Step [12900/6235], Loss: 36.5588\n",
      "Epoch [50/100], Step [13000/6235], Loss: 0.4971\n",
      "Epoch [50/100], Step [13100/6235], Loss: 66.0083\n",
      "Epoch [50/100], Step [13200/6235], Loss: 8.5600\n",
      "Epoch [50/100], Step [13300/6235], Loss: 25.2156\n",
      "Epoch [50/100], Step [13400/6235], Loss: 247.4168\n",
      "Epoch [50/100], Step [13500/6235], Loss: 2.8099\n",
      "Epoch [50/100], Step [13600/6235], Loss: 0.3175\n",
      "Epoch [50/100], Step [13700/6235], Loss: 101.7888\n",
      "Epoch [50/100], Step [13800/6235], Loss: 119.2680\n",
      "Epoch [50/100], Step [13900/6235], Loss: 32.0570\n",
      "Epoch [50/100], Step [14000/6235], Loss: 14.0811\n",
      "Epoch [50/100], Step [14100/6235], Loss: 25.0793\n",
      "Epoch [50/100], Step [14200/6235], Loss: 120.9868\n",
      "Epoch [50/100], Step [14300/6235], Loss: 51.7919\n",
      "Epoch [50/100], Step [14400/6235], Loss: 39.4926\n",
      "Epoch [50/100], Step [14500/6235], Loss: 35.6618\n",
      "Epoch [50/100], Step [14600/6235], Loss: 0.2993\n",
      "Epoch [50/100], Step [14700/6235], Loss: 39.7733\n",
      "Epoch [50/100], Step [14800/6235], Loss: 33.8416\n",
      "Epoch [50/100], Step [14900/6235], Loss: 0.8547\n",
      "Epoch [50/100], Step [15000/6235], Loss: 1.6786\n",
      "Epoch [50/100], Step [15100/6235], Loss: 0.5192\n",
      "Epoch [50/100], Step [15200/6235], Loss: 0.3952\n",
      "Epoch [50/100], Step [15300/6235], Loss: 33.6380\n",
      "Epoch [50/100], Step [15400/6235], Loss: 99.7535\n",
      "Epoch [50/100], Step [15500/6235], Loss: 15.1990\n",
      "Epoch [50/100], Step [15600/6235], Loss: 100.1921\n",
      "Epoch [50/100], Step [15700/6235], Loss: 108.8586\n",
      "Epoch [50/100], Step [15800/6235], Loss: 9.3167\n",
      "Epoch [50/100], Step [15900/6235], Loss: 0.8485\n",
      "Epoch [50/100], Step [16000/6235], Loss: 54.8238\n",
      "Epoch [50/100], Step [16100/6235], Loss: 0.8501\n",
      "Epoch [50/100], Step [16200/6235], Loss: 0.9583\n",
      "Epoch [50/100], Step [16300/6235], Loss: 9.7885\n",
      "Epoch [50/100], Step [16400/6235], Loss: 27.4359\n",
      "Epoch [50/100], Step [16500/6235], Loss: 686.8809\n",
      "Epoch [50/100], Step [16600/6235], Loss: 33.0394\n",
      "Epoch [50/100], Step [16700/6235], Loss: 0.6686\n",
      "Epoch [50/100], Step [16800/6235], Loss: 9.6266\n",
      "Epoch [50/100], Step [16900/6235], Loss: 0.1984\n",
      "Epoch [50/100], Step [17000/6235], Loss: 0.3000\n",
      "Epoch [50/100], Step [17100/6235], Loss: 0.1532\n",
      "Epoch [50/100], Step [17200/6235], Loss: 272.4332\n",
      "Epoch [50/100], Step [17300/6235], Loss: 11.8868\n",
      "Epoch [50/100], Step [17400/6235], Loss: 32.8781\n",
      "Epoch [50/100], Step [17500/6235], Loss: 1.1448\n",
      "Epoch [50/100], Step [17600/6235], Loss: 3.3359\n",
      "Epoch [50/100], Step [17700/6235], Loss: 7.9554\n",
      "Epoch [50/100], Step [17800/6235], Loss: 14.9695\n",
      "Epoch [50/100], Step [17900/6235], Loss: 17.7017\n",
      "Epoch [50/100], Step [18000/6235], Loss: 2.5619\n",
      "Epoch [50/100], Step [18100/6235], Loss: 14.0662\n",
      "Epoch [50/100], Step [18200/6235], Loss: 0.3211\n",
      "Epoch [50/100], Step [18300/6235], Loss: 1.0511\n",
      "Epoch [50/100], Step [18400/6235], Loss: 0.4102\n",
      "Epoch [50/100], Step [18500/6235], Loss: 34.1534\n",
      "Epoch [50/100], Step [18600/6235], Loss: 3.6547\n",
      "Epoch [50/100], Step [18700/6235], Loss: 1.0774\n",
      "Epoch [50/100], Step [18800/6235], Loss: 62.9136\n",
      "Epoch [50/100], Step [18900/6235], Loss: 44.3968\n",
      "Epoch [50/100], Step [19000/6235], Loss: 27.0999\n",
      "Epoch [50/100], Step [19100/6235], Loss: 43.8152\n",
      "Epoch [50/100], Step [19200/6235], Loss: 2.4808\n",
      "Epoch [50/100], Step [19300/6235], Loss: 13.0205\n",
      "Epoch [50/100], Step [19400/6235], Loss: 21.0895\n",
      "Epoch [50/100], Step [19500/6235], Loss: 255.2884\n",
      "Epoch [50/100], Step [19600/6235], Loss: 22.8796\n",
      "Epoch [50/100], Step [19700/6235], Loss: 8.6122\n",
      "Epoch [50/100], Step [19800/6235], Loss: 3.7284\n",
      "Epoch [50/100], Step [19900/6235], Loss: 0.0272\n",
      "Epoch [50/100], Step [20000/6235], Loss: 65.5386\n",
      "Epoch [50/100], Step [20100/6235], Loss: 4.9994\n",
      "Epoch [50/100], Step [20200/6235], Loss: 1.9538\n",
      "Epoch [50/100], Step [20300/6235], Loss: 0.3235\n",
      "Epoch [50/100], Step [20400/6235], Loss: 20.7084\n",
      "Epoch [50/100], Step [20500/6235], Loss: 55.7554\n",
      "Epoch [50/100], Step [20600/6235], Loss: 291.4556\n",
      "Epoch [50/100], Step [20700/6235], Loss: 37.1904\n",
      "Epoch [50/100], Step [20800/6235], Loss: 3.7047\n",
      "Epoch [50/100], Step [20900/6235], Loss: 8.8798\n",
      "Epoch [50/100], Step [21000/6235], Loss: 23.7207\n",
      "Epoch [50/100], Step [21100/6235], Loss: 7.1065\n",
      "Epoch [50/100], Step [21200/6235], Loss: 0.2814\n",
      "Epoch [50/100], Step [21300/6235], Loss: 0.1009\n",
      "Epoch [50/100], Step [21400/6235], Loss: 3.2496\n",
      "Epoch [50/100], Step [21500/6235], Loss: 0.2109\n",
      "Epoch [50/100], Step [21600/6235], Loss: 25.8762\n",
      "Epoch [50/100], Step [21700/6235], Loss: 0.4367\n",
      "Epoch [50/100], Step [21800/6235], Loss: 4.2299\n",
      "Epoch [50/100], Step [21900/6235], Loss: 1.7223\n",
      "Epoch [50/100], Step [22000/6235], Loss: 11.1526\n",
      "Epoch [50/100], Step [22100/6235], Loss: 0.1677\n",
      "Epoch [50/100], Step [22200/6235], Loss: 0.5568\n",
      "Epoch [50/100], Step [22300/6235], Loss: 4.4220\n",
      "Epoch [50/100], Step [22400/6235], Loss: 0.2678\n",
      "Epoch [50/100], Step [22500/6235], Loss: 57.9847\n",
      "Epoch [50/100], Step [22600/6235], Loss: 18.3243\n",
      "Epoch [50/100], Step [22700/6235], Loss: 1.0352\n",
      "Epoch [50/100], Step [22800/6235], Loss: 2.5278\n",
      "Epoch [50/100], Step [22900/6235], Loss: 19.0184\n",
      "Epoch [50/100], Step [23000/6235], Loss: 7.7386\n",
      "Epoch [50/100], Step [23100/6235], Loss: 7.1519\n",
      "Epoch [50/100], Step [23200/6235], Loss: 0.1571\n",
      "Epoch [50/100], Step [23300/6235], Loss: 17.5971\n",
      "Epoch [50/100], Step [23400/6235], Loss: 2.5792\n",
      "Epoch [50/100], Step [23500/6235], Loss: 0.4868\n",
      "Epoch [50/100], Step [23600/6235], Loss: 136.7277\n",
      "Epoch [50/100], Step [23700/6235], Loss: 3.4291\n",
      "Epoch [50/100], Step [23800/6235], Loss: 0.7177\n",
      "Epoch [50/100], Step [23900/6235], Loss: 0.5545\n",
      "Epoch [50/100], Step [24000/6235], Loss: 0.6139\n",
      "Epoch [50/100], Step [24100/6235], Loss: 3.2628\n",
      "Epoch [50/100], Step [24200/6235], Loss: 28.1126\n",
      "Epoch [50/100], Step [24300/6235], Loss: 0.6073\n",
      "Epoch [50/100], Step [24400/6235], Loss: 1.2599\n",
      "Epoch [50/100], Step [24500/6235], Loss: 0.2047\n",
      "Epoch [50/100], Step [24600/6235], Loss: 0.2341\n",
      "Epoch [50/100], Step [24700/6235], Loss: 0.1880\n",
      "Epoch [50/100], Step [24800/6235], Loss: 0.5261\n",
      "Epoch [50/100], Step [24900/6235], Loss: 13.4877\n",
      "Epoch [50/100], Step [25000/6235], Loss: 7.7314\n",
      "Epoch [50/100], Step [25100/6235], Loss: 7.4749\n",
      "Epoch [50/100], Step [25200/6235], Loss: 0.0132\n",
      "Epoch [50/100], Step [25300/6235], Loss: 1.0535\n",
      "Epoch [50/100], Step [25400/6235], Loss: 5.3436\n",
      "Epoch [50/100], Step [25500/6235], Loss: 9.2506\n",
      "Epoch [50/100], Step [25600/6235], Loss: 7.6482\n",
      "Epoch [50/100], Step [25700/6235], Loss: 0.0434\n",
      "Epoch [50/100], Step [25800/6235], Loss: 0.4361\n",
      "Epoch [50/100], Step [25900/6235], Loss: 2.2765\n",
      "Epoch [50/100], Step [26000/6235], Loss: 1.2090\n",
      "Epoch [50/100], Step [26100/6235], Loss: 0.0603\n",
      "Epoch [50/100], Step [26200/6235], Loss: 1.4024\n",
      "Epoch [50/100], Step [26300/6235], Loss: 1.7841\n",
      "Epoch [50/100], Step [26400/6235], Loss: 0.5244\n",
      "Epoch [50/100], Step [26500/6235], Loss: 0.0467\n",
      "Epoch [50/100], Step [26600/6235], Loss: 0.1950\n",
      "Epoch [50/100], Step [26700/6235], Loss: 0.1247\n",
      "Epoch [50/100], Step [26800/6235], Loss: 0.0704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Step [26900/6235], Loss: 0.0596\n",
      "Epoch [50/100], Step [27000/6235], Loss: 16.1865\n",
      "Epoch [50/100], Step [27100/6235], Loss: 0.0859\n",
      "Epoch [50/100], Step [27200/6235], Loss: 0.0126\n",
      "Epoch [50/100], Step [27300/6235], Loss: 0.0216\n",
      "Epoch [50/100], Step [27400/6235], Loss: 0.5976\n",
      "Epoch [50/100], Step [27500/6235], Loss: 14.6901\n",
      "Epoch [50/100], Step [27600/6235], Loss: 0.7075\n",
      "Epoch [50/100], Step [27700/6235], Loss: 1.5560\n",
      "Epoch [50/100], Step [27800/6235], Loss: 6.7351\n",
      "Epoch [50/100], Step [27900/6235], Loss: 0.0645\n",
      "Epoch [50/100], Step [28000/6235], Loss: 133.3497\n",
      "Epoch [50/100], Step [28100/6235], Loss: 1.8320\n",
      "Epoch [50/100], Step [28200/6235], Loss: 25.3606\n",
      "Epoch [50/100], Step [28300/6235], Loss: 0.4848\n",
      "Epoch [50/100], Step [28400/6235], Loss: 27.2460\n",
      "Epoch [50/100], Step [28500/6235], Loss: 3.8098\n",
      "Epoch [50/100], Step [28600/6235], Loss: 0.5164\n",
      "Epoch [50/100], Step [28700/6235], Loss: 4.6491\n",
      "Epoch [50/100], Step [28800/6235], Loss: 0.6632\n",
      "Epoch [50/100], Step [28900/6235], Loss: 59.4585\n",
      "Epoch [50/100], Step [29000/6235], Loss: 2.3103\n",
      "Epoch [50/100], Step [29100/6235], Loss: 0.2003\n",
      "Epoch [50/100], Step [29200/6235], Loss: 3.6859\n",
      "Epoch [50/100], Step [29300/6235], Loss: 9.3281\n",
      "Epoch [50/100], Step [29400/6235], Loss: 0.6367\n",
      "Epoch [50/100], Step [29500/6235], Loss: 2.9572\n",
      "Epoch [50/100], Step [29600/6235], Loss: 0.0431\n",
      "Epoch [50/100], Step [29700/6235], Loss: 2.3003\n",
      "Epoch [50/100], Step [29800/6235], Loss: 1.1430\n",
      "Epoch [50/100], Step [29900/6235], Loss: 1.4611\n",
      "Epoch [50/100], Step [30000/6235], Loss: 5.3483\n",
      "Epoch [50/100], Step [30100/6235], Loss: 9.6864\n",
      "Epoch [50/100], Step [30200/6235], Loss: 1.6811\n",
      "Epoch [50/100], Step [30300/6235], Loss: 0.0686\n",
      "Epoch [50/100], Step [30400/6235], Loss: 1.5917\n",
      "Epoch [50/100], Step [30500/6235], Loss: 2.3655\n",
      "Epoch [50/100], Step [30600/6235], Loss: 1.8871\n",
      "Epoch [50/100], Step [30700/6235], Loss: 1.2226\n",
      "Epoch [50/100], Step [30800/6235], Loss: 0.5613\n",
      "Epoch [50/100], Step [30900/6235], Loss: 3.3174\n",
      "Epoch [50/100], Step [31000/6235], Loss: 0.2596\n",
      "Epoch [50/100], Step [31100/6235], Loss: 0.0717\n",
      "Epoch [50/100], Step [31200/6235], Loss: 6.0870\n",
      "Epoch [50/100], Step [31300/6235], Loss: 1.1020\n",
      "Epoch [50/100], Step [31400/6235], Loss: 11.0404\n",
      "Epoch [50/100], Step [31500/6235], Loss: 1.1135\n",
      "Epoch [50/100], Step [31600/6235], Loss: 0.6548\n",
      "Epoch [50/100], Step [31700/6235], Loss: 17.6653\n",
      "Epoch [50/100], Step [31800/6235], Loss: 3.7938\n",
      "Epoch [50/100], Step [31900/6235], Loss: 351.5455\n",
      "Epoch [50/100], Step [32000/6235], Loss: 34.8151\n",
      "Epoch [50/100], Step [32100/6235], Loss: 1.1374\n",
      "Epoch [50/100], Step [32200/6235], Loss: 83.1421\n",
      "Epoch [50/100], Step [32300/6235], Loss: 3.2264\n",
      "Epoch [50/100], Step [32400/6235], Loss: 0.4186\n",
      "Epoch [50/100], Step [32500/6235], Loss: 18.5276\n",
      "Epoch [50/100], Step [32600/6235], Loss: 0.5445\n",
      "Epoch [50/100], Step [32700/6235], Loss: 71.8953\n",
      "Epoch [50/100], Step [32800/6235], Loss: 9.4864\n",
      "Epoch [50/100], Step [32900/6235], Loss: 15.2589\n",
      "Epoch [50/100], Step [33000/6235], Loss: 0.4572\n",
      "Epoch [50/100], Step [33100/6235], Loss: 1.2524\n",
      "Epoch [50/100], Step [33200/6235], Loss: 1.6337\n",
      "Epoch [50/100], Step [33300/6235], Loss: 7.6901\n",
      "Epoch [50/100], Step [33400/6235], Loss: 149.8145\n",
      "Epoch [50/100], Step [33500/6235], Loss: 1.1742\n",
      "Epoch [50/100], Step [33600/6235], Loss: 0.4788\n",
      "Epoch [50/100], Step [33700/6235], Loss: 3.4957\n",
      "Epoch [50/100], Step [33800/6235], Loss: 0.6564\n",
      "Epoch [50/100], Step [33900/6235], Loss: 27.8369\n",
      "Epoch [50/100], Step [34000/6235], Loss: 0.0101\n",
      "Epoch [50/100], Step [34100/6235], Loss: 0.2987\n",
      "Epoch [50/100], Step [34200/6235], Loss: 2.8201\n",
      "Epoch [50/100], Step [34300/6235], Loss: 6.0315\n",
      "Epoch [50/100], Step [34400/6235], Loss: 0.1261\n",
      "Epoch [50/100], Step [34500/6235], Loss: 42.5133\n",
      "Epoch [50/100], Step [34600/6235], Loss: 0.8943\n",
      "Epoch [50/100], Step [34700/6235], Loss: 13.9238\n",
      "Epoch [50/100], Step [34800/6235], Loss: 11.9002\n",
      "Epoch [50/100], Step [34900/6235], Loss: 43.5864\n",
      "Epoch [50/100], Step [35000/6235], Loss: 1.8612\n",
      "Epoch [50/100], Step [35100/6235], Loss: 1.3862\n",
      "Epoch [50/100], Step [35200/6235], Loss: 0.8041\n",
      "Epoch [50/100], Step [35300/6235], Loss: 1.1529\n",
      "Epoch [50/100], Step [35400/6235], Loss: 0.5948\n",
      "Epoch [50/100], Step [35500/6235], Loss: 2.5767\n",
      "Epoch [50/100], Step [35600/6235], Loss: 2.0817\n",
      "Epoch [50/100], Step [35700/6235], Loss: 5.0159\n",
      "Epoch [50/100], Step [35800/6235], Loss: 0.0684\n",
      "Epoch [50/100], Step [35900/6235], Loss: 0.1822\n",
      "Epoch [50/100], Step [36000/6235], Loss: 0.8178\n",
      "Epoch [50/100], Step [36100/6235], Loss: 0.0248\n",
      "Epoch [50/100], Step [36200/6235], Loss: 15.1752\n",
      "Epoch [50/100], Step [36300/6235], Loss: 0.6776\n",
      "Epoch [50/100], Step [36400/6235], Loss: 1.7485\n",
      "Epoch [50/100], Step [36500/6235], Loss: 9.5482\n",
      "Epoch [50/100], Step [36600/6235], Loss: 0.1232\n",
      "Epoch [50/100], Step [36700/6235], Loss: 0.1552\n",
      "Epoch [50/100], Step [36800/6235], Loss: 19.1482\n",
      "Epoch [50/100], Step [36900/6235], Loss: 4.7115\n",
      "Epoch [50/100], Step [37000/6235], Loss: 0.1040\n",
      "Epoch [50/100], Step [37100/6235], Loss: 0.5539\n",
      "Epoch [50/100], Step [37200/6235], Loss: 0.0687\n",
      "Epoch [50/100], Step [37300/6235], Loss: 0.1119\n",
      "Epoch [50/100], Step [37400/6235], Loss: 0.2048\n",
      "Epoch [50/100], Step [37500/6235], Loss: 3.3091\n",
      "Epoch [50/100], Step [37600/6235], Loss: 10.9469\n",
      "Epoch [50/100], Step [37700/6235], Loss: 0.6941\n",
      "Epoch [50/100], Step [37800/6235], Loss: 7.1085\n",
      "Epoch [50/100], Step [37900/6235], Loss: 6.6111\n",
      "Epoch [50/100], Step [38000/6235], Loss: 0.3040\n",
      "Epoch [50/100], Step [38100/6235], Loss: 2.6760\n",
      "Epoch [50/100], Step [38200/6235], Loss: 2.2176\n",
      "Epoch [50/100], Step [38300/6235], Loss: 0.0914\n",
      "Epoch [50/100], Step [38400/6235], Loss: 0.1221\n",
      "Epoch [50/100], Step [38500/6235], Loss: 3.4069\n",
      "Epoch [50/100], Step [38600/6235], Loss: 0.3215\n",
      "Epoch [50/100], Step [38700/6235], Loss: 0.3346\n",
      "Epoch [50/100], Step [38800/6235], Loss: 0.3839\n",
      "Epoch [50/100], Step [38900/6235], Loss: 6.3587\n",
      "Epoch [50/100], Step [39000/6235], Loss: 14.1938\n",
      "Epoch [50/100], Step [39100/6235], Loss: 17.9309\n",
      "Epoch [50/100], Step [39200/6235], Loss: 0.4343\n",
      "Epoch [50/100], Step [39300/6235], Loss: 47.8449\n",
      "Epoch [50/100], Step [39400/6235], Loss: 59.9480\n",
      "Epoch [50/100], Step [39500/6235], Loss: 392.5028\n",
      "Epoch [50/100], Step [39600/6235], Loss: 30.3994\n",
      "Epoch [50/100], Step [39700/6235], Loss: 40.5833\n",
      "Epoch [50/100], Step [39800/6235], Loss: 103.1426\n",
      "Epoch [50/100], Step [39900/6235], Loss: 1.9640\n",
      "Epoch [50/100], Step [40000/6235], Loss: 16.6107\n",
      "Epoch [50/100], Step [40100/6235], Loss: 21.0837\n",
      "Epoch [50/100], Step [40200/6235], Loss: 4.6437\n",
      "Epoch [50/100], Step [40300/6235], Loss: 0.3583\n",
      "Epoch [50/100], Step [40400/6235], Loss: 0.9707\n",
      "Epoch [50/100], Step [40500/6235], Loss: 2.7648\n",
      "Epoch [50/100], Step [40600/6235], Loss: 0.2077\n",
      "Epoch [50/100], Step [40700/6235], Loss: 6.8847\n",
      "Epoch [50/100], Step [40800/6235], Loss: 0.5189\n",
      "Epoch [50/100], Step [40900/6235], Loss: 0.7950\n",
      "Epoch [50/100], Step [41000/6235], Loss: 47.1764\n",
      "Epoch [50/100], Step [41100/6235], Loss: 18.7872\n",
      "Epoch [50/100], Step [41200/6235], Loss: 3.2244\n",
      "Epoch [50/100], Step [41300/6235], Loss: 3.1950\n",
      "Epoch [50/100], Step [41400/6235], Loss: 0.1752\n",
      "Epoch [50/100], Step [41500/6235], Loss: 0.7487\n",
      "Epoch [50/100], Step [41600/6235], Loss: 0.2614\n",
      "Epoch [50/100], Step [41700/6235], Loss: 0.9189\n",
      "Epoch [50/100], Step [41800/6235], Loss: 3.5056\n",
      "Epoch [50/100], Step [41900/6235], Loss: 4.6718\n",
      "Epoch [50/100], Step [42000/6235], Loss: 4.7399\n",
      "Epoch [50/100], Step [42100/6235], Loss: 10.7995\n",
      "Epoch [50/100], Step [42200/6235], Loss: 25.2707\n",
      "Epoch [50/100], Step [42300/6235], Loss: 1.3927\n",
      "Epoch [50/100], Step [42400/6235], Loss: 3.5006\n",
      "Epoch [50/100], Step [42500/6235], Loss: 0.6841\n",
      "Epoch [50/100], Step [42600/6235], Loss: 2.0009\n",
      "Epoch [50/100], Step [42700/6235], Loss: 0.4451\n",
      "Epoch [50/100], Step [42800/6235], Loss: 15.0690\n",
      "Epoch [50/100], Step [42900/6235], Loss: 0.7072\n",
      "Epoch [50/100], Step [43000/6235], Loss: 0.2196\n",
      "Epoch [50/100], Step [43100/6235], Loss: 0.0243\n",
      "Epoch [50/100], Step [43200/6235], Loss: 0.5278\n",
      "Epoch [50/100], Step [43300/6235], Loss: 6.2389\n",
      "Epoch [50/100], Step [43400/6235], Loss: 7.7130\n",
      "Epoch [50/100], Step [43500/6235], Loss: 10.2472\n",
      "Epoch [50/100], Step [43600/6235], Loss: 4.8571\n",
      "Epoch [50/100], Step [43700/6235], Loss: 51.9918\n",
      "Epoch [50/100], Step [43800/6235], Loss: 0.3774\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [50/100], Step [43900/6235], Loss: 1.1669\n",
      "Epoch [50/100], Step [44000/6235], Loss: 78.5243\n",
      "Epoch [50/100], Step [44100/6235], Loss: 5.1375\n",
      "Epoch [50/100], Step [44200/6235], Loss: 2.1077\n",
      "Epoch [50/100], Step [44300/6235], Loss: 15.7038\n",
      "Epoch [50/100], Step [44400/6235], Loss: 0.8592\n",
      "Epoch [50/100], Step [44500/6235], Loss: 3.4892\n",
      "Epoch [50/100], Step [44600/6235], Loss: 19.3677\n",
      "Epoch [50/100], Step [44700/6235], Loss: 12.0640\n",
      "Epoch [50/100], Step [44800/6235], Loss: 3.4096\n",
      "Epoch [50/100], Step [44900/6235], Loss: 6.5563\n",
      "Epoch [50/100], Step [45000/6235], Loss: 5.0644\n",
      "Epoch [50/100], Step [45100/6235], Loss: 38.2273\n",
      "Epoch [50/100], Step [45200/6235], Loss: 0.3832\n",
      "Epoch [50/100], Step [45300/6235], Loss: 30.2163\n",
      "Epoch [50/100], Step [45400/6235], Loss: 11.6786\n",
      "Epoch [50/100], Step [45500/6235], Loss: 0.4100\n",
      "Epoch [50/100], Step [45600/6235], Loss: 0.2151\n",
      "Epoch [50/100], Step [45700/6235], Loss: 69.8347\n",
      "Epoch [50/100], Step [45800/6235], Loss: 333.4950\n",
      "Epoch [50/100], Step [45900/6235], Loss: 5.7608\n",
      "Epoch [50/100], Step [46000/6235], Loss: 2.3295\n",
      "Epoch [50/100], Step [46100/6235], Loss: 13.6303\n",
      "Epoch [50/100], Step [46200/6235], Loss: 2.6660\n",
      "Epoch [50/100], Step [46300/6235], Loss: 30.0511\n",
      "Epoch [50/100], Step [46400/6235], Loss: 3.0826\n",
      "Epoch [50/100], Step [46500/6235], Loss: 47.2053\n",
      "Epoch [50/100], Step [46600/6235], Loss: 14.2447\n",
      "Epoch [50/100], Step [46700/6235], Loss: 4.9619\n",
      "Epoch [50/100], Step [46800/6235], Loss: 0.9344\n",
      "Epoch [50/100], Step [46900/6235], Loss: 7.4460\n",
      "Epoch [50/100], Step [47000/6235], Loss: 3.5407\n",
      "Epoch [50/100], Step [47100/6235], Loss: 5.1049\n",
      "Epoch [50/100], Step [47200/6235], Loss: 9.0254\n",
      "Epoch [50/100], Step [47300/6235], Loss: 1.0909\n",
      "Epoch [50/100], Step [47400/6235], Loss: 9.9685\n",
      "Epoch [50/100], Step [47500/6235], Loss: 26.1361\n",
      "Epoch [50/100], Step [47600/6235], Loss: 3.8849\n",
      "Epoch [50/100], Step [47700/6235], Loss: 4.9268\n",
      "Epoch [50/100], Step [47800/6235], Loss: 3.8197\n",
      "Epoch [50/100], Step [47900/6235], Loss: 26.3866\n",
      "Epoch [50/100], Step [48000/6235], Loss: 98.5755\n",
      "Epoch [50/100], Step [48100/6235], Loss: 3.6207\n",
      "Epoch [50/100], Step [48200/6235], Loss: 9.5502\n",
      "Epoch [50/100], Step [48300/6235], Loss: 204.9480\n",
      "Epoch [50/100], Step [48400/6235], Loss: 18.7663\n",
      "Epoch [50/100], Step [48500/6235], Loss: 19.2202\n",
      "Epoch [50/100], Step [48600/6235], Loss: 166.2365\n",
      "Epoch [50/100], Step [48700/6235], Loss: 21.0339\n",
      "Epoch [50/100], Step [48800/6235], Loss: 618.8149\n",
      "Epoch [50/100], Step [48900/6235], Loss: 34.5196\n",
      "Epoch [50/100], Step [49000/6235], Loss: 247.0312\n",
      "Epoch [50/100], Step [49100/6235], Loss: 2832.6008\n",
      "Epoch [50/100], Step [49200/6235], Loss: 651.2238\n",
      "Epoch [50/100], Step [49300/6235], Loss: 1217.9176\n",
      "Epoch [50/100], Step [49400/6235], Loss: 205.8324\n",
      "Epoch [50/100], Step [49500/6235], Loss: 6.9848\n",
      "Epoch [50/100], Step [49600/6235], Loss: 54.4259\n",
      "Epoch [50/100], Step [49700/6235], Loss: 481.0247\n",
      "Epoch [50/100], Step [49800/6235], Loss: 132.1229\n",
      "Epoch [51/100], Step [100/6235], Loss: 21.5572\n",
      "Epoch [51/100], Step [200/6235], Loss: 0.1236\n",
      "Epoch [51/100], Step [300/6235], Loss: 0.0022\n",
      "Epoch [51/100], Step [400/6235], Loss: 0.0010\n",
      "Epoch [51/100], Step [500/6235], Loss: 0.2710\n",
      "Epoch [51/100], Step [600/6235], Loss: 0.0281\n",
      "Epoch [51/100], Step [700/6235], Loss: 0.4212\n",
      "Epoch [51/100], Step [800/6235], Loss: 0.1204\n",
      "Epoch [51/100], Step [900/6235], Loss: 0.0194\n",
      "Epoch [51/100], Step [1000/6235], Loss: 0.0271\n",
      "Epoch [51/100], Step [1100/6235], Loss: 0.0087\n",
      "Epoch [51/100], Step [1200/6235], Loss: 0.1675\n",
      "Epoch [51/100], Step [1300/6235], Loss: 0.0355\n",
      "Epoch [51/100], Step [1400/6235], Loss: 0.0289\n",
      "Epoch [51/100], Step [1500/6235], Loss: 0.0043\n",
      "Epoch [51/100], Step [1600/6235], Loss: 0.2198\n",
      "Epoch [51/100], Step [1700/6235], Loss: 0.0012\n",
      "Epoch [51/100], Step [1800/6235], Loss: 0.1857\n",
      "Epoch [51/100], Step [1900/6235], Loss: 0.5424\n",
      "Epoch [51/100], Step [2000/6235], Loss: 2.1748\n",
      "Epoch [51/100], Step [2100/6235], Loss: 1.7143\n",
      "Epoch [51/100], Step [2200/6235], Loss: 9.2969\n",
      "Epoch [51/100], Step [2300/6235], Loss: 11.6955\n",
      "Epoch [51/100], Step [2400/6235], Loss: 3.4018\n",
      "Epoch [51/100], Step [2500/6235], Loss: 36.6796\n",
      "Epoch [51/100], Step [2600/6235], Loss: 11.4096\n",
      "Epoch [51/100], Step [2700/6235], Loss: 9.0510\n",
      "Epoch [51/100], Step [2800/6235], Loss: 102.9605\n",
      "Epoch [51/100], Step [2900/6235], Loss: 12.5981\n",
      "Epoch [51/100], Step [3000/6235], Loss: 0.7523\n",
      "Epoch [51/100], Step [3100/6235], Loss: 67.7547\n",
      "Epoch [51/100], Step [3200/6235], Loss: 77.0255\n",
      "Epoch [51/100], Step [3300/6235], Loss: 7.4739\n",
      "Epoch [51/100], Step [3400/6235], Loss: 1.7446\n",
      "Epoch [51/100], Step [3500/6235], Loss: 33.7067\n",
      "Epoch [51/100], Step [3600/6235], Loss: 8.2919\n",
      "Epoch [51/100], Step [3700/6235], Loss: 0.0623\n",
      "Epoch [51/100], Step [3800/6235], Loss: 0.2250\n",
      "Epoch [51/100], Step [3900/6235], Loss: 0.5541\n",
      "Epoch [51/100], Step [4000/6235], Loss: 0.0430\n",
      "Epoch [51/100], Step [4100/6235], Loss: 7.2319\n",
      "Epoch [51/100], Step [4200/6235], Loss: 0.6751\n",
      "Epoch [51/100], Step [4300/6235], Loss: 8.7345\n",
      "Epoch [51/100], Step [4400/6235], Loss: 2.8220\n",
      "Epoch [51/100], Step [4500/6235], Loss: 40.3882\n",
      "Epoch [51/100], Step [4600/6235], Loss: 1.1801\n",
      "Epoch [51/100], Step [4700/6235], Loss: 0.1167\n",
      "Epoch [51/100], Step [4800/6235], Loss: 10.2137\n",
      "Epoch [51/100], Step [4900/6235], Loss: 0.2408\n",
      "Epoch [51/100], Step [5000/6235], Loss: 0.0123\n",
      "Epoch [51/100], Step [5100/6235], Loss: 1.2777\n",
      "Epoch [51/100], Step [5200/6235], Loss: 1.0436\n",
      "Epoch [51/100], Step [5300/6235], Loss: 42.1662\n",
      "Epoch [51/100], Step [5400/6235], Loss: 1.4749\n",
      "Epoch [51/100], Step [5500/6235], Loss: 0.1305\n",
      "Epoch [51/100], Step [5600/6235], Loss: 0.2657\n",
      "Epoch [51/100], Step [5700/6235], Loss: 0.0084\n",
      "Epoch [51/100], Step [5800/6235], Loss: 0.1895\n",
      "Epoch [51/100], Step [5900/6235], Loss: 0.0335\n",
      "Epoch [51/100], Step [6000/6235], Loss: 3.1522\n",
      "Epoch [51/100], Step [6100/6235], Loss: 0.1161\n",
      "Epoch [51/100], Step [6200/6235], Loss: 2.6599\n",
      "Epoch [51/100], Step [6300/6235], Loss: 0.7125\n",
      "Epoch [51/100], Step [6400/6235], Loss: 0.0229\n",
      "Epoch [51/100], Step [6500/6235], Loss: 2.6446\n",
      "Epoch [51/100], Step [6600/6235], Loss: 5.9502\n",
      "Epoch [51/100], Step [6700/6235], Loss: 3.0477\n",
      "Epoch [51/100], Step [6800/6235], Loss: 0.4798\n",
      "Epoch [51/100], Step [6900/6235], Loss: 0.5525\n",
      "Epoch [51/100], Step [7000/6235], Loss: 0.0080\n",
      "Epoch [51/100], Step [7100/6235], Loss: 0.3182\n",
      "Epoch [51/100], Step [7200/6235], Loss: 0.6377\n",
      "Epoch [51/100], Step [7300/6235], Loss: 1.2243\n",
      "Epoch [51/100], Step [7400/6235], Loss: 0.0134\n",
      "Epoch [51/100], Step [7500/6235], Loss: 1.0107\n",
      "Epoch [51/100], Step [7600/6235], Loss: 5.3157\n",
      "Epoch [51/100], Step [7700/6235], Loss: 8.9790\n",
      "Epoch [51/100], Step [7800/6235], Loss: 1.2752\n",
      "Epoch [51/100], Step [7900/6235], Loss: 1.5263\n",
      "Epoch [51/100], Step [8000/6235], Loss: 0.1580\n",
      "Epoch [51/100], Step [8100/6235], Loss: 2.7957\n",
      "Epoch [51/100], Step [8200/6235], Loss: 10.0317\n",
      "Epoch [51/100], Step [8300/6235], Loss: 15.5146\n",
      "Epoch [51/100], Step [8400/6235], Loss: 520.9393\n",
      "Epoch [51/100], Step [8500/6235], Loss: 7.3825\n",
      "Epoch [51/100], Step [8600/6235], Loss: 34.2085\n",
      "Epoch [51/100], Step [8700/6235], Loss: 23.2818\n",
      "Epoch [51/100], Step [8800/6235], Loss: 799.0572\n",
      "Epoch [51/100], Step [8900/6235], Loss: 480.6279\n",
      "Epoch [51/100], Step [9000/6235], Loss: 475.6887\n",
      "Epoch [51/100], Step [9100/6235], Loss: 1247.5200\n",
      "Epoch [51/100], Step [9200/6235], Loss: 2558.9414\n",
      "Epoch [51/100], Step [9300/6235], Loss: 536.3693\n",
      "Epoch [51/100], Step [9400/6235], Loss: 158.1446\n",
      "Epoch [51/100], Step [9500/6235], Loss: 1449.8732\n",
      "Epoch [51/100], Step [9600/6235], Loss: 263.0034\n",
      "Epoch [51/100], Step [9700/6235], Loss: 10.5730\n",
      "Epoch [51/100], Step [9800/6235], Loss: 1184.6549\n",
      "Epoch [51/100], Step [9900/6235], Loss: 26.5666\n",
      "Epoch [51/100], Step [10000/6235], Loss: 7.5500\n",
      "Epoch [51/100], Step [10100/6235], Loss: 0.8595\n",
      "Epoch [51/100], Step [10200/6235], Loss: 751.2451\n",
      "Epoch [51/100], Step [10300/6235], Loss: 66.7357\n",
      "Epoch [51/100], Step [10400/6235], Loss: 8.9106\n",
      "Epoch [51/100], Step [10500/6235], Loss: 1.7632\n",
      "Epoch [51/100], Step [10600/6235], Loss: 15.3973\n",
      "Epoch [51/100], Step [10700/6235], Loss: 12.1774\n",
      "Epoch [51/100], Step [10800/6235], Loss: 63.7346\n",
      "Epoch [51/100], Step [10900/6235], Loss: 27.0784\n",
      "Epoch [51/100], Step [11000/6235], Loss: 296.2481\n",
      "Epoch [51/100], Step [11100/6235], Loss: 51.5012\n",
      "Epoch [51/100], Step [11200/6235], Loss: 7.0554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Step [11300/6235], Loss: 103.1397\n",
      "Epoch [51/100], Step [11400/6235], Loss: 82.1074\n",
      "Epoch [51/100], Step [11500/6235], Loss: 12.9724\n",
      "Epoch [51/100], Step [11600/6235], Loss: 9.0835\n",
      "Epoch [51/100], Step [11700/6235], Loss: 58.9330\n",
      "Epoch [51/100], Step [11800/6235], Loss: 15.0505\n",
      "Epoch [51/100], Step [11900/6235], Loss: 16.8167\n",
      "Epoch [51/100], Step [12000/6235], Loss: 680.1126\n",
      "Epoch [51/100], Step [12100/6235], Loss: 272.4070\n",
      "Epoch [51/100], Step [12200/6235], Loss: 56.5662\n",
      "Epoch [51/100], Step [12300/6235], Loss: 9.4486\n",
      "Epoch [51/100], Step [12400/6235], Loss: 298.6726\n",
      "Epoch [51/100], Step [12500/6235], Loss: 182.2217\n",
      "Epoch [51/100], Step [12600/6235], Loss: 0.6518\n",
      "Epoch [51/100], Step [12700/6235], Loss: 9.9884\n",
      "Epoch [51/100], Step [12800/6235], Loss: 16.1093\n",
      "Epoch [51/100], Step [12900/6235], Loss: 34.0251\n",
      "Epoch [51/100], Step [13000/6235], Loss: 0.3545\n",
      "Epoch [51/100], Step [13100/6235], Loss: 62.8147\n",
      "Epoch [51/100], Step [13200/6235], Loss: 7.5666\n",
      "Epoch [51/100], Step [13300/6235], Loss: 17.7791\n",
      "Epoch [51/100], Step [13400/6235], Loss: 206.5815\n",
      "Epoch [51/100], Step [13500/6235], Loss: 3.9073\n",
      "Epoch [51/100], Step [13600/6235], Loss: 6.0423\n",
      "Epoch [51/100], Step [13700/6235], Loss: 182.3648\n",
      "Epoch [51/100], Step [13800/6235], Loss: 73.4710\n",
      "Epoch [51/100], Step [13900/6235], Loss: 3.8789\n",
      "Epoch [51/100], Step [14000/6235], Loss: 4.5467\n",
      "Epoch [51/100], Step [14100/6235], Loss: 53.2498\n",
      "Epoch [51/100], Step [14200/6235], Loss: 130.5383\n",
      "Epoch [51/100], Step [14300/6235], Loss: 28.5174\n",
      "Epoch [51/100], Step [14400/6235], Loss: 34.7453\n",
      "Epoch [51/100], Step [14500/6235], Loss: 21.0783\n",
      "Epoch [51/100], Step [14600/6235], Loss: 3.2879\n",
      "Epoch [51/100], Step [14700/6235], Loss: 19.0814\n",
      "Epoch [51/100], Step [14800/6235], Loss: 25.0612\n",
      "Epoch [51/100], Step [14900/6235], Loss: 0.8194\n",
      "Epoch [51/100], Step [15000/6235], Loss: 0.8675\n",
      "Epoch [51/100], Step [15100/6235], Loss: 0.2629\n",
      "Epoch [51/100], Step [15200/6235], Loss: 23.1173\n",
      "Epoch [51/100], Step [15300/6235], Loss: 43.3247\n",
      "Epoch [51/100], Step [15400/6235], Loss: 65.0484\n",
      "Epoch [51/100], Step [15500/6235], Loss: 14.0159\n",
      "Epoch [51/100], Step [15600/6235], Loss: 56.9359\n",
      "Epoch [51/100], Step [15700/6235], Loss: 111.8658\n",
      "Epoch [51/100], Step [15800/6235], Loss: 0.2387\n",
      "Epoch [51/100], Step [15900/6235], Loss: 1.2425\n",
      "Epoch [51/100], Step [16000/6235], Loss: 58.0850\n",
      "Epoch [51/100], Step [16100/6235], Loss: 3.0932\n",
      "Epoch [51/100], Step [16200/6235], Loss: 0.3245\n",
      "Epoch [51/100], Step [16300/6235], Loss: 10.3052\n",
      "Epoch [51/100], Step [16400/6235], Loss: 14.7433\n",
      "Epoch [51/100], Step [16500/6235], Loss: 38.3065\n",
      "Epoch [51/100], Step [16600/6235], Loss: 2.3985\n",
      "Epoch [51/100], Step [16700/6235], Loss: 1.8070\n",
      "Epoch [51/100], Step [16800/6235], Loss: 12.0376\n",
      "Epoch [51/100], Step [16900/6235], Loss: 0.3529\n",
      "Epoch [51/100], Step [17000/6235], Loss: 0.1917\n",
      "Epoch [51/100], Step [17100/6235], Loss: 0.1965\n",
      "Epoch [51/100], Step [17200/6235], Loss: 166.3526\n",
      "Epoch [51/100], Step [17300/6235], Loss: 103.9294\n",
      "Epoch [51/100], Step [17400/6235], Loss: 32.7780\n",
      "Epoch [51/100], Step [17500/6235], Loss: 1.3593\n",
      "Epoch [51/100], Step [17600/6235], Loss: 2.9914\n",
      "Epoch [51/100], Step [17700/6235], Loss: 2.0163\n",
      "Epoch [51/100], Step [17800/6235], Loss: 26.5580\n",
      "Epoch [51/100], Step [17900/6235], Loss: 9.3443\n",
      "Epoch [51/100], Step [18000/6235], Loss: 18.9375\n",
      "Epoch [51/100], Step [18100/6235], Loss: 14.3158\n",
      "Epoch [51/100], Step [18200/6235], Loss: 0.7466\n",
      "Epoch [51/100], Step [18300/6235], Loss: 3.6210\n",
      "Epoch [51/100], Step [18400/6235], Loss: 1.3033\n",
      "Epoch [51/100], Step [18500/6235], Loss: 9.2455\n",
      "Epoch [51/100], Step [18600/6235], Loss: 2.3705\n",
      "Epoch [51/100], Step [18700/6235], Loss: 0.6900\n",
      "Epoch [51/100], Step [18800/6235], Loss: 132.9406\n",
      "Epoch [51/100], Step [18900/6235], Loss: 68.2121\n",
      "Epoch [51/100], Step [19000/6235], Loss: 1.2551\n",
      "Epoch [51/100], Step [19100/6235], Loss: 5.2221\n",
      "Epoch [51/100], Step [19200/6235], Loss: 3.6031\n",
      "Epoch [51/100], Step [19300/6235], Loss: 4.1600\n",
      "Epoch [51/100], Step [19400/6235], Loss: 254.5609\n",
      "Epoch [51/100], Step [19500/6235], Loss: 131.2168\n",
      "Epoch [51/100], Step [19600/6235], Loss: 113.7839\n",
      "Epoch [51/100], Step [19700/6235], Loss: 5.8287\n",
      "Epoch [51/100], Step [19800/6235], Loss: 0.7922\n",
      "Epoch [51/100], Step [19900/6235], Loss: 1.2329\n",
      "Epoch [51/100], Step [20000/6235], Loss: 96.3249\n",
      "Epoch [51/100], Step [20100/6235], Loss: 7.6898\n",
      "Epoch [51/100], Step [20200/6235], Loss: 2.6372\n",
      "Epoch [51/100], Step [20300/6235], Loss: 0.7862\n",
      "Epoch [51/100], Step [20400/6235], Loss: 28.0774\n",
      "Epoch [51/100], Step [20500/6235], Loss: 30.8012\n",
      "Epoch [51/100], Step [20600/6235], Loss: 28.7147\n",
      "Epoch [51/100], Step [20700/6235], Loss: 3.6579\n",
      "Epoch [51/100], Step [20800/6235], Loss: 43.3268\n",
      "Epoch [51/100], Step [20900/6235], Loss: 24.7876\n",
      "Epoch [51/100], Step [21000/6235], Loss: 14.6314\n",
      "Epoch [51/100], Step [21100/6235], Loss: 5.2174\n",
      "Epoch [51/100], Step [21200/6235], Loss: 0.1820\n",
      "Epoch [51/100], Step [21300/6235], Loss: 0.1896\n",
      "Epoch [51/100], Step [21400/6235], Loss: 5.7994\n",
      "Epoch [51/100], Step [21500/6235], Loss: 1.6657\n",
      "Epoch [51/100], Step [21600/6235], Loss: 32.6882\n",
      "Epoch [51/100], Step [21700/6235], Loss: 0.1433\n",
      "Epoch [51/100], Step [21800/6235], Loss: 0.3231\n",
      "Epoch [51/100], Step [21900/6235], Loss: 0.1845\n",
      "Epoch [51/100], Step [22000/6235], Loss: 2.4209\n",
      "Epoch [51/100], Step [22100/6235], Loss: 4.7701\n",
      "Epoch [51/100], Step [22200/6235], Loss: 10.4622\n",
      "Epoch [51/100], Step [22300/6235], Loss: 0.3908\n",
      "Epoch [51/100], Step [22400/6235], Loss: 0.6991\n",
      "Epoch [51/100], Step [22500/6235], Loss: 85.0784\n",
      "Epoch [51/100], Step [22600/6235], Loss: 22.6405\n",
      "Epoch [51/100], Step [22700/6235], Loss: 1.1623\n",
      "Epoch [51/100], Step [22800/6235], Loss: 6.0899\n",
      "Epoch [51/100], Step [22900/6235], Loss: 0.9974\n",
      "Epoch [51/100], Step [23000/6235], Loss: 9.0131\n",
      "Epoch [51/100], Step [23100/6235], Loss: 1.0466\n",
      "Epoch [51/100], Step [23200/6235], Loss: 13.4064\n",
      "Epoch [51/100], Step [23300/6235], Loss: 15.3902\n",
      "Epoch [51/100], Step [23400/6235], Loss: 0.5059\n",
      "Epoch [51/100], Step [23500/6235], Loss: 0.3007\n",
      "Epoch [51/100], Step [23600/6235], Loss: 105.7640\n",
      "Epoch [51/100], Step [23700/6235], Loss: 3.4121\n",
      "Epoch [51/100], Step [23800/6235], Loss: 0.9661\n",
      "Epoch [51/100], Step [23900/6235], Loss: 7.8988\n",
      "Epoch [51/100], Step [24000/6235], Loss: 0.5813\n",
      "Epoch [51/100], Step [24100/6235], Loss: 0.3791\n",
      "Epoch [51/100], Step [24200/6235], Loss: 49.8047\n",
      "Epoch [51/100], Step [24300/6235], Loss: 2.1049\n",
      "Epoch [51/100], Step [24400/6235], Loss: 3.3880\n",
      "Epoch [51/100], Step [24500/6235], Loss: 1.8502\n",
      "Epoch [51/100], Step [24600/6235], Loss: 0.1022\n",
      "Epoch [51/100], Step [24700/6235], Loss: 0.4287\n",
      "Epoch [51/100], Step [24800/6235], Loss: 1.1885\n",
      "Epoch [51/100], Step [24900/6235], Loss: 8.2010\n",
      "Epoch [51/100], Step [25000/6235], Loss: 20.4648\n",
      "Epoch [51/100], Step [25100/6235], Loss: 8.0448\n",
      "Epoch [51/100], Step [25200/6235], Loss: 1.6594\n",
      "Epoch [51/100], Step [25300/6235], Loss: 0.6583\n",
      "Epoch [51/100], Step [25400/6235], Loss: 9.1718\n",
      "Epoch [51/100], Step [25500/6235], Loss: 5.1203\n",
      "Epoch [51/100], Step [25600/6235], Loss: 2.3273\n",
      "Epoch [51/100], Step [25700/6235], Loss: 0.3221\n",
      "Epoch [51/100], Step [25800/6235], Loss: 0.2113\n",
      "Epoch [51/100], Step [25900/6235], Loss: 10.3750\n",
      "Epoch [51/100], Step [26000/6235], Loss: 0.1122\n",
      "Epoch [51/100], Step [26100/6235], Loss: 0.3783\n",
      "Epoch [51/100], Step [26200/6235], Loss: 0.1756\n",
      "Epoch [51/100], Step [26300/6235], Loss: 4.7585\n",
      "Epoch [51/100], Step [26400/6235], Loss: 0.1423\n",
      "Epoch [51/100], Step [26500/6235], Loss: 0.1326\n",
      "Epoch [51/100], Step [26600/6235], Loss: 2.7725\n",
      "Epoch [51/100], Step [26700/6235], Loss: 0.5562\n",
      "Epoch [51/100], Step [26800/6235], Loss: 0.4256\n",
      "Epoch [51/100], Step [26900/6235], Loss: 0.0147\n",
      "Epoch [51/100], Step [27000/6235], Loss: 13.2424\n",
      "Epoch [51/100], Step [27100/6235], Loss: 0.1288\n",
      "Epoch [51/100], Step [27200/6235], Loss: 0.0538\n",
      "Epoch [51/100], Step [27300/6235], Loss: 0.2259\n",
      "Epoch [51/100], Step [27400/6235], Loss: 0.8640\n",
      "Epoch [51/100], Step [27500/6235], Loss: 25.1814\n",
      "Epoch [51/100], Step [27600/6235], Loss: 1.2175\n",
      "Epoch [51/100], Step [27700/6235], Loss: 1.4619\n",
      "Epoch [51/100], Step [27800/6235], Loss: 4.8281\n",
      "Epoch [51/100], Step [27900/6235], Loss: 1.3620\n",
      "Epoch [51/100], Step [28000/6235], Loss: 128.7359\n",
      "Epoch [51/100], Step [28100/6235], Loss: 2.5951\n",
      "Epoch [51/100], Step [28200/6235], Loss: 39.7317\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Step [28300/6235], Loss: 2.7054\n",
      "Epoch [51/100], Step [28400/6235], Loss: 27.2073\n",
      "Epoch [51/100], Step [28500/6235], Loss: 3.6860\n",
      "Epoch [51/100], Step [28600/6235], Loss: 0.0872\n",
      "Epoch [51/100], Step [28700/6235], Loss: 5.5928\n",
      "Epoch [51/100], Step [28800/6235], Loss: 0.6048\n",
      "Epoch [51/100], Step [28900/6235], Loss: 71.8946\n",
      "Epoch [51/100], Step [29000/6235], Loss: 12.2812\n",
      "Epoch [51/100], Step [29100/6235], Loss: 0.2155\n",
      "Epoch [51/100], Step [29200/6235], Loss: 0.9982\n",
      "Epoch [51/100], Step [29300/6235], Loss: 5.1199\n",
      "Epoch [51/100], Step [29400/6235], Loss: 1.7103\n",
      "Epoch [51/100], Step [29500/6235], Loss: 6.0970\n",
      "Epoch [51/100], Step [29600/6235], Loss: 0.0886\n",
      "Epoch [51/100], Step [29700/6235], Loss: 1.0184\n",
      "Epoch [51/100], Step [29800/6235], Loss: 1.6668\n",
      "Epoch [51/100], Step [29900/6235], Loss: 0.9558\n",
      "Epoch [51/100], Step [30000/6235], Loss: 5.0332\n",
      "Epoch [51/100], Step [30100/6235], Loss: 11.4756\n",
      "Epoch [51/100], Step [30200/6235], Loss: 0.8035\n",
      "Epoch [51/100], Step [30300/6235], Loss: 0.0122\n",
      "Epoch [51/100], Step [30400/6235], Loss: 0.8220\n",
      "Epoch [51/100], Step [30500/6235], Loss: 3.2109\n",
      "Epoch [51/100], Step [30600/6235], Loss: 1.6521\n",
      "Epoch [51/100], Step [30700/6235], Loss: 0.3251\n",
      "Epoch [51/100], Step [30800/6235], Loss: 0.4695\n",
      "Epoch [51/100], Step [30900/6235], Loss: 3.7212\n",
      "Epoch [51/100], Step [31000/6235], Loss: 0.1309\n",
      "Epoch [51/100], Step [31100/6235], Loss: 0.0768\n",
      "Epoch [51/100], Step [31200/6235], Loss: 5.8453\n",
      "Epoch [51/100], Step [31300/6235], Loss: 0.9267\n",
      "Epoch [51/100], Step [31400/6235], Loss: 0.4092\n",
      "Epoch [51/100], Step [31500/6235], Loss: 0.6900\n",
      "Epoch [51/100], Step [31600/6235], Loss: 7.5878\n",
      "Epoch [51/100], Step [31700/6235], Loss: 44.1660\n",
      "Epoch [51/100], Step [31800/6235], Loss: 0.6811\n",
      "Epoch [51/100], Step [31900/6235], Loss: 255.3277\n",
      "Epoch [51/100], Step [32000/6235], Loss: 8.9987\n",
      "Epoch [51/100], Step [32100/6235], Loss: 0.3040\n",
      "Epoch [51/100], Step [32200/6235], Loss: 113.3174\n",
      "Epoch [51/100], Step [32300/6235], Loss: 0.9622\n",
      "Epoch [51/100], Step [32400/6235], Loss: 1.6600\n",
      "Epoch [51/100], Step [32500/6235], Loss: 10.9860\n",
      "Epoch [51/100], Step [32600/6235], Loss: 0.3723\n",
      "Epoch [51/100], Step [32700/6235], Loss: 142.7728\n",
      "Epoch [51/100], Step [32800/6235], Loss: 0.3183\n",
      "Epoch [51/100], Step [32900/6235], Loss: 2.0397\n",
      "Epoch [51/100], Step [33000/6235], Loss: 0.6909\n",
      "Epoch [51/100], Step [33100/6235], Loss: 1.1162\n",
      "Epoch [51/100], Step [33200/6235], Loss: 1.6689\n",
      "Epoch [51/100], Step [33300/6235], Loss: 5.5473\n",
      "Epoch [51/100], Step [33400/6235], Loss: 15.3876\n",
      "Epoch [51/100], Step [33500/6235], Loss: 0.3581\n",
      "Epoch [51/100], Step [33600/6235], Loss: 10.1985\n",
      "Epoch [51/100], Step [33700/6235], Loss: 13.9491\n",
      "Epoch [51/100], Step [33800/6235], Loss: 0.7074\n",
      "Epoch [51/100], Step [33900/6235], Loss: 36.8186\n",
      "Epoch [51/100], Step [34000/6235], Loss: 0.1332\n",
      "Epoch [51/100], Step [34100/6235], Loss: 0.7459\n",
      "Epoch [51/100], Step [34200/6235], Loss: 3.2249\n",
      "Epoch [51/100], Step [34300/6235], Loss: 2.6210\n",
      "Epoch [51/100], Step [34400/6235], Loss: 0.2016\n",
      "Epoch [51/100], Step [34500/6235], Loss: 63.1493\n",
      "Epoch [51/100], Step [34600/6235], Loss: 1.8395\n",
      "Epoch [51/100], Step [34700/6235], Loss: 21.9446\n",
      "Epoch [51/100], Step [34800/6235], Loss: 8.4965\n",
      "Epoch [51/100], Step [34900/6235], Loss: 65.7877\n",
      "Epoch [51/100], Step [35000/6235], Loss: 0.2156\n",
      "Epoch [51/100], Step [35100/6235], Loss: 0.5337\n",
      "Epoch [51/100], Step [35200/6235], Loss: 0.5774\n",
      "Epoch [51/100], Step [35300/6235], Loss: 2.9922\n",
      "Epoch [51/100], Step [35400/6235], Loss: 0.5666\n",
      "Epoch [51/100], Step [35500/6235], Loss: 0.8476\n",
      "Epoch [51/100], Step [35600/6235], Loss: 1.9256\n",
      "Epoch [51/100], Step [35700/6235], Loss: 4.3184\n",
      "Epoch [51/100], Step [35800/6235], Loss: 1.5630\n",
      "Epoch [51/100], Step [35900/6235], Loss: 0.2495\n",
      "Epoch [51/100], Step [36000/6235], Loss: 0.0318\n",
      "Epoch [51/100], Step [36100/6235], Loss: 0.0418\n",
      "Epoch [51/100], Step [36200/6235], Loss: 28.1600\n",
      "Epoch [51/100], Step [36300/6235], Loss: 0.1623\n",
      "Epoch [51/100], Step [36400/6235], Loss: 3.0711\n",
      "Epoch [51/100], Step [36500/6235], Loss: 7.4905\n",
      "Epoch [51/100], Step [36600/6235], Loss: 0.0853\n",
      "Epoch [51/100], Step [36700/6235], Loss: 0.5971\n",
      "Epoch [51/100], Step [36800/6235], Loss: 4.9677\n",
      "Epoch [51/100], Step [36900/6235], Loss: 13.2888\n",
      "Epoch [51/100], Step [37000/6235], Loss: 0.9605\n",
      "Epoch [51/100], Step [37100/6235], Loss: 2.0019\n",
      "Epoch [51/100], Step [37200/6235], Loss: 0.0423\n",
      "Epoch [51/100], Step [37300/6235], Loss: 0.0412\n",
      "Epoch [51/100], Step [37400/6235], Loss: 0.1719\n",
      "Epoch [51/100], Step [37500/6235], Loss: 6.5248\n",
      "Epoch [51/100], Step [37600/6235], Loss: 12.0465\n",
      "Epoch [51/100], Step [37700/6235], Loss: 0.3425\n",
      "Epoch [51/100], Step [37800/6235], Loss: 1.7740\n",
      "Epoch [51/100], Step [37900/6235], Loss: 8.5993\n",
      "Epoch [51/100], Step [38000/6235], Loss: 0.9886\n",
      "Epoch [51/100], Step [38100/6235], Loss: 5.1169\n",
      "Epoch [51/100], Step [38200/6235], Loss: 2.2513\n",
      "Epoch [51/100], Step [38300/6235], Loss: 0.2747\n",
      "Epoch [51/100], Step [38400/6235], Loss: 0.0497\n",
      "Epoch [51/100], Step [38500/6235], Loss: 1.5226\n",
      "Epoch [51/100], Step [38600/6235], Loss: 0.5176\n",
      "Epoch [51/100], Step [38700/6235], Loss: 0.0936\n",
      "Epoch [51/100], Step [38800/6235], Loss: 0.1206\n",
      "Epoch [51/100], Step [38900/6235], Loss: 3.2869\n",
      "Epoch [51/100], Step [39000/6235], Loss: 20.7766\n",
      "Epoch [51/100], Step [39100/6235], Loss: 21.4622\n",
      "Epoch [51/100], Step [39200/6235], Loss: 0.5989\n",
      "Epoch [51/100], Step [39300/6235], Loss: 62.8196\n",
      "Epoch [51/100], Step [39400/6235], Loss: 146.9672\n",
      "Epoch [51/100], Step [39500/6235], Loss: 22.8957\n",
      "Epoch [51/100], Step [39600/6235], Loss: 14.7963\n",
      "Epoch [51/100], Step [39700/6235], Loss: 190.6551\n",
      "Epoch [51/100], Step [39800/6235], Loss: 231.2953\n",
      "Epoch [51/100], Step [39900/6235], Loss: 0.7723\n",
      "Epoch [51/100], Step [40000/6235], Loss: 13.0313\n",
      "Epoch [51/100], Step [40100/6235], Loss: 20.0000\n",
      "Epoch [51/100], Step [40200/6235], Loss: 0.9203\n",
      "Epoch [51/100], Step [40300/6235], Loss: 1.3526\n",
      "Epoch [51/100], Step [40400/6235], Loss: 1.7135\n",
      "Epoch [51/100], Step [40500/6235], Loss: 2.5308\n",
      "Epoch [51/100], Step [40600/6235], Loss: 0.2241\n",
      "Epoch [51/100], Step [40700/6235], Loss: 7.4082\n",
      "Epoch [51/100], Step [40800/6235], Loss: 0.8208\n",
      "Epoch [51/100], Step [40900/6235], Loss: 0.3801\n",
      "Epoch [51/100], Step [41000/6235], Loss: 48.2980\n",
      "Epoch [51/100], Step [41100/6235], Loss: 38.5724\n",
      "Epoch [51/100], Step [41200/6235], Loss: 13.0507\n",
      "Epoch [51/100], Step [41300/6235], Loss: 5.5566\n",
      "Epoch [51/100], Step [41400/6235], Loss: 2.3922\n",
      "Epoch [51/100], Step [41500/6235], Loss: 1.0206\n",
      "Epoch [51/100], Step [41600/6235], Loss: 0.4268\n",
      "Epoch [51/100], Step [41700/6235], Loss: 1.8346\n",
      "Epoch [51/100], Step [41800/6235], Loss: 4.3422\n",
      "Epoch [51/100], Step [41900/6235], Loss: 4.4943\n",
      "Epoch [51/100], Step [42000/6235], Loss: 4.6252\n",
      "Epoch [51/100], Step [42100/6235], Loss: 10.1031\n",
      "Epoch [51/100], Step [42200/6235], Loss: 15.9462\n",
      "Epoch [51/100], Step [42300/6235], Loss: 1.3440\n",
      "Epoch [51/100], Step [42400/6235], Loss: 4.9456\n",
      "Epoch [51/100], Step [42500/6235], Loss: 0.5417\n",
      "Epoch [51/100], Step [42600/6235], Loss: 2.0179\n",
      "Epoch [51/100], Step [42700/6235], Loss: 0.4900\n",
      "Epoch [51/100], Step [42800/6235], Loss: 15.2960\n",
      "Epoch [51/100], Step [42900/6235], Loss: 0.5720\n",
      "Epoch [51/100], Step [43000/6235], Loss: 0.2650\n",
      "Epoch [51/100], Step [43100/6235], Loss: 0.0241\n",
      "Epoch [51/100], Step [43200/6235], Loss: 0.4499\n",
      "Epoch [51/100], Step [43300/6235], Loss: 6.0712\n",
      "Epoch [51/100], Step [43400/6235], Loss: 8.3617\n",
      "Epoch [51/100], Step [43500/6235], Loss: 10.1145\n",
      "Epoch [51/100], Step [43600/6235], Loss: 4.6482\n",
      "Epoch [51/100], Step [43700/6235], Loss: 51.0311\n",
      "Epoch [51/100], Step [43800/6235], Loss: 0.4652\n",
      "Epoch [51/100], Step [43900/6235], Loss: 0.2285\n",
      "Epoch [51/100], Step [44000/6235], Loss: 53.1792\n",
      "Epoch [51/100], Step [44100/6235], Loss: 4.1816\n",
      "Epoch [51/100], Step [44200/6235], Loss: 4.5465\n",
      "Epoch [51/100], Step [44300/6235], Loss: 6.9825\n",
      "Epoch [51/100], Step [44400/6235], Loss: 0.5232\n",
      "Epoch [51/100], Step [44500/6235], Loss: 1.6247\n",
      "Epoch [51/100], Step [44600/6235], Loss: 22.9721\n",
      "Epoch [51/100], Step [44700/6235], Loss: 0.3621\n",
      "Epoch [51/100], Step [44800/6235], Loss: 3.9254\n",
      "Epoch [51/100], Step [44900/6235], Loss: 3.8493\n",
      "Epoch [51/100], Step [45000/6235], Loss: 4.9604\n",
      "Epoch [51/100], Step [45100/6235], Loss: 20.9576\n",
      "Epoch [51/100], Step [45200/6235], Loss: 0.4611\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [51/100], Step [45300/6235], Loss: 35.7663\n",
      "Epoch [51/100], Step [45400/6235], Loss: 12.5388\n",
      "Epoch [51/100], Step [45500/6235], Loss: 0.1791\n",
      "Epoch [51/100], Step [45600/6235], Loss: 0.2534\n",
      "Epoch [51/100], Step [45700/6235], Loss: 37.9694\n",
      "Epoch [51/100], Step [45800/6235], Loss: 471.4460\n",
      "Epoch [51/100], Step [45900/6235], Loss: 5.7305\n",
      "Epoch [51/100], Step [46000/6235], Loss: 104.3894\n",
      "Epoch [51/100], Step [46100/6235], Loss: 78.9942\n",
      "Epoch [51/100], Step [46200/6235], Loss: 5.2088\n",
      "Epoch [51/100], Step [46300/6235], Loss: 87.7222\n",
      "Epoch [51/100], Step [46400/6235], Loss: 8.1236\n",
      "Epoch [51/100], Step [46500/6235], Loss: 17.8473\n",
      "Epoch [51/100], Step [46600/6235], Loss: 6.2872\n",
      "Epoch [51/100], Step [46700/6235], Loss: 2.7130\n",
      "Epoch [51/100], Step [46800/6235], Loss: 26.5767\n",
      "Epoch [51/100], Step [46900/6235], Loss: 17.4131\n",
      "Epoch [51/100], Step [47000/6235], Loss: 0.8901\n",
      "Epoch [51/100], Step [47100/6235], Loss: 120.1158\n",
      "Epoch [51/100], Step [47200/6235], Loss: 46.7433\n",
      "Epoch [51/100], Step [47300/6235], Loss: 11.2933\n",
      "Epoch [51/100], Step [47400/6235], Loss: 478.0063\n",
      "Epoch [51/100], Step [47500/6235], Loss: 26.2846\n",
      "Epoch [51/100], Step [47600/6235], Loss: 15.4867\n",
      "Epoch [51/100], Step [47700/6235], Loss: 17.8916\n",
      "Epoch [51/100], Step [47800/6235], Loss: 19.9067\n",
      "Epoch [51/100], Step [47900/6235], Loss: 15.8351\n",
      "Epoch [51/100], Step [48000/6235], Loss: 20.3355\n",
      "Epoch [51/100], Step [48100/6235], Loss: 5.4415\n",
      "Epoch [51/100], Step [48200/6235], Loss: 19.7044\n",
      "Epoch [51/100], Step [48300/6235], Loss: 529.5629\n",
      "Epoch [51/100], Step [48400/6235], Loss: 11.6864\n",
      "Epoch [51/100], Step [48500/6235], Loss: 45.1119\n",
      "Epoch [51/100], Step [48600/6235], Loss: 105.1457\n",
      "Epoch [51/100], Step [48700/6235], Loss: 0.8594\n",
      "Epoch [51/100], Step [48800/6235], Loss: 174.4421\n",
      "Epoch [51/100], Step [48900/6235], Loss: 326.1517\n",
      "Epoch [51/100], Step [49000/6235], Loss: 187.6045\n",
      "Epoch [51/100], Step [49100/6235], Loss: 2915.0972\n",
      "Epoch [51/100], Step [49200/6235], Loss: 626.9462\n",
      "Epoch [51/100], Step [49300/6235], Loss: 1196.1097\n",
      "Epoch [51/100], Step [49400/6235], Loss: 19.6565\n",
      "Epoch [51/100], Step [49500/6235], Loss: 21.6429\n",
      "Epoch [51/100], Step [49600/6235], Loss: 209.0688\n",
      "Epoch [51/100], Step [49700/6235], Loss: 1545.7201\n",
      "Epoch [51/100], Step [49800/6235], Loss: 561.7256\n",
      "Epoch [52/100], Step [100/6235], Loss: 18.1156\n",
      "Epoch [52/100], Step [200/6235], Loss: 0.6953\n",
      "Epoch [52/100], Step [300/6235], Loss: 0.0576\n",
      "Epoch [52/100], Step [400/6235], Loss: 0.0248\n",
      "Epoch [52/100], Step [500/6235], Loss: 17.8713\n",
      "Epoch [52/100], Step [600/6235], Loss: 0.0380\n",
      "Epoch [52/100], Step [700/6235], Loss: 0.5232\n",
      "Epoch [52/100], Step [800/6235], Loss: 0.1498\n",
      "Epoch [52/100], Step [900/6235], Loss: 0.0390\n",
      "Epoch [52/100], Step [1000/6235], Loss: 0.0337\n",
      "Epoch [52/100], Step [1100/6235], Loss: 0.0611\n",
      "Epoch [52/100], Step [1200/6235], Loss: 0.1720\n",
      "Epoch [52/100], Step [1300/6235], Loss: 0.0349\n",
      "Epoch [52/100], Step [1400/6235], Loss: 0.0410\n",
      "Epoch [52/100], Step [1500/6235], Loss: 0.0056\n",
      "Epoch [52/100], Step [1600/6235], Loss: 0.2300\n",
      "Epoch [52/100], Step [1700/6235], Loss: 0.0123\n",
      "Epoch [52/100], Step [1800/6235], Loss: 0.1934\n",
      "Epoch [52/100], Step [1900/6235], Loss: 0.4902\n",
      "Epoch [52/100], Step [2000/6235], Loss: 2.2570\n",
      "Epoch [52/100], Step [2100/6235], Loss: 1.3811\n",
      "Epoch [52/100], Step [2200/6235], Loss: 8.8797\n",
      "Epoch [52/100], Step [2300/6235], Loss: 8.9508\n",
      "Epoch [52/100], Step [2400/6235], Loss: 2.2419\n",
      "Epoch [52/100], Step [2500/6235], Loss: 37.9123\n",
      "Epoch [52/100], Step [2600/6235], Loss: 12.1964\n",
      "Epoch [52/100], Step [2700/6235], Loss: 11.7988\n",
      "Epoch [52/100], Step [2800/6235], Loss: 150.0710\n",
      "Epoch [52/100], Step [2900/6235], Loss: 17.7636\n",
      "Epoch [52/100], Step [3000/6235], Loss: 1.4858\n",
      "Epoch [52/100], Step [3100/6235], Loss: 63.2574\n",
      "Epoch [52/100], Step [3200/6235], Loss: 63.9552\n",
      "Epoch [52/100], Step [3300/6235], Loss: 10.1075\n",
      "Epoch [52/100], Step [3400/6235], Loss: 2.1359\n",
      "Epoch [52/100], Step [3500/6235], Loss: 44.6403\n",
      "Epoch [52/100], Step [3600/6235], Loss: 4.9999\n",
      "Epoch [52/100], Step [3700/6235], Loss: 0.0107\n",
      "Epoch [52/100], Step [3800/6235], Loss: 0.0292\n",
      "Epoch [52/100], Step [3900/6235], Loss: 0.1236\n",
      "Epoch [52/100], Step [4000/6235], Loss: 0.0765\n",
      "Epoch [52/100], Step [4100/6235], Loss: 8.6766\n",
      "Epoch [52/100], Step [4200/6235], Loss: 1.7306\n",
      "Epoch [52/100], Step [4300/6235], Loss: 7.1014\n",
      "Epoch [52/100], Step [4400/6235], Loss: 1.4067\n",
      "Epoch [52/100], Step [4500/6235], Loss: 37.8293\n",
      "Epoch [52/100], Step [4600/6235], Loss: 1.5125\n",
      "Epoch [52/100], Step [4700/6235], Loss: 0.1242\n",
      "Epoch [52/100], Step [4800/6235], Loss: 10.0322\n",
      "Epoch [52/100], Step [4900/6235], Loss: 0.0332\n",
      "Epoch [52/100], Step [5000/6235], Loss: 0.1415\n",
      "Epoch [52/100], Step [5100/6235], Loss: 0.3335\n",
      "Epoch [52/100], Step [5200/6235], Loss: 1.2531\n",
      "Epoch [52/100], Step [5300/6235], Loss: 38.8833\n",
      "Epoch [52/100], Step [5400/6235], Loss: 0.6319\n",
      "Epoch [52/100], Step [5500/6235], Loss: 0.1593\n",
      "Epoch [52/100], Step [5600/6235], Loss: 0.2032\n",
      "Epoch [52/100], Step [5700/6235], Loss: 0.0958\n",
      "Epoch [52/100], Step [5800/6235], Loss: 0.3134\n",
      "Epoch [52/100], Step [5900/6235], Loss: 0.0992\n",
      "Epoch [52/100], Step [6000/6235], Loss: 1.5423\n",
      "Epoch [52/100], Step [6100/6235], Loss: 0.0520\n",
      "Epoch [52/100], Step [6200/6235], Loss: 3.9283\n",
      "Epoch [52/100], Step [6300/6235], Loss: 0.2917\n",
      "Epoch [52/100], Step [6400/6235], Loss: 0.0980\n",
      "Epoch [52/100], Step [6500/6235], Loss: 4.9213\n",
      "Epoch [52/100], Step [6600/6235], Loss: 7.7191\n",
      "Epoch [52/100], Step [6700/6235], Loss: 2.2706\n",
      "Epoch [52/100], Step [6800/6235], Loss: 1.3816\n",
      "Epoch [52/100], Step [6900/6235], Loss: 0.6476\n",
      "Epoch [52/100], Step [7000/6235], Loss: 0.0565\n",
      "Epoch [52/100], Step [7100/6235], Loss: 0.3527\n",
      "Epoch [52/100], Step [7200/6235], Loss: 0.5526\n",
      "Epoch [52/100], Step [7300/6235], Loss: 1.3484\n",
      "Epoch [52/100], Step [7400/6235], Loss: 0.0144\n",
      "Epoch [52/100], Step [7500/6235], Loss: 0.9341\n",
      "Epoch [52/100], Step [7600/6235], Loss: 5.7578\n",
      "Epoch [52/100], Step [7700/6235], Loss: 9.5765\n",
      "Epoch [52/100], Step [7800/6235], Loss: 1.2764\n",
      "Epoch [52/100], Step [7900/6235], Loss: 3.6611\n",
      "Epoch [52/100], Step [8000/6235], Loss: 0.0684\n",
      "Epoch [52/100], Step [8100/6235], Loss: 3.0337\n",
      "Epoch [52/100], Step [8200/6235], Loss: 10.2407\n",
      "Epoch [52/100], Step [8300/6235], Loss: 15.6020\n",
      "Epoch [52/100], Step [8400/6235], Loss: 428.0704\n",
      "Epoch [52/100], Step [8500/6235], Loss: 1.9446\n",
      "Epoch [52/100], Step [8600/6235], Loss: 22.8820\n",
      "Epoch [52/100], Step [8700/6235], Loss: 22.9141\n",
      "Epoch [52/100], Step [8800/6235], Loss: 369.8600\n",
      "Epoch [52/100], Step [8900/6235], Loss: 368.9325\n",
      "Epoch [52/100], Step [9000/6235], Loss: 502.2136\n",
      "Epoch [52/100], Step [9100/6235], Loss: 151.2593\n",
      "Epoch [52/100], Step [9200/6235], Loss: 2582.2075\n",
      "Epoch [52/100], Step [9300/6235], Loss: 14.1210\n",
      "Epoch [52/100], Step [9400/6235], Loss: 162.6706\n",
      "Epoch [52/100], Step [9500/6235], Loss: 2509.7307\n",
      "Epoch [52/100], Step [9600/6235], Loss: 435.9857\n",
      "Epoch [52/100], Step [9700/6235], Loss: 9.9572\n",
      "Epoch [52/100], Step [9800/6235], Loss: 3082.9602\n",
      "Epoch [52/100], Step [9900/6235], Loss: 210.4000\n",
      "Epoch [52/100], Step [10000/6235], Loss: 367.3176\n",
      "Epoch [52/100], Step [10100/6235], Loss: 4.3776\n",
      "Epoch [52/100], Step [10200/6235], Loss: 450.5158\n",
      "Epoch [52/100], Step [10300/6235], Loss: 8.4062\n",
      "Epoch [52/100], Step [10400/6235], Loss: 9.1492\n",
      "Epoch [52/100], Step [10500/6235], Loss: 4.8427\n",
      "Epoch [52/100], Step [10600/6235], Loss: 69.8734\n",
      "Epoch [52/100], Step [10700/6235], Loss: 44.2785\n",
      "Epoch [52/100], Step [10800/6235], Loss: 18.4638\n",
      "Epoch [52/100], Step [10900/6235], Loss: 5.7901\n",
      "Epoch [52/100], Step [11000/6235], Loss: 270.9220\n",
      "Epoch [52/100], Step [11100/6235], Loss: 16.5035\n",
      "Epoch [52/100], Step [11200/6235], Loss: 72.7099\n",
      "Epoch [52/100], Step [11300/6235], Loss: 198.2416\n",
      "Epoch [52/100], Step [11400/6235], Loss: 4.3251\n",
      "Epoch [52/100], Step [11500/6235], Loss: 2.0426\n",
      "Epoch [52/100], Step [11600/6235], Loss: 1.0393\n",
      "Epoch [52/100], Step [11700/6235], Loss: 38.3553\n",
      "Epoch [52/100], Step [11800/6235], Loss: 359.7263\n",
      "Epoch [52/100], Step [11900/6235], Loss: 81.2918\n",
      "Epoch [52/100], Step [12000/6235], Loss: 718.8471\n",
      "Epoch [52/100], Step [12100/6235], Loss: 260.9760\n",
      "Epoch [52/100], Step [12200/6235], Loss: 79.7251\n",
      "Epoch [52/100], Step [12300/6235], Loss: 22.8918\n",
      "Epoch [52/100], Step [12400/6235], Loss: 411.4378\n",
      "Epoch [52/100], Step [12500/6235], Loss: 84.9976\n",
      "Epoch [52/100], Step [12600/6235], Loss: 4.5035\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Step [12700/6235], Loss: 8.1217\n",
      "Epoch [52/100], Step [12800/6235], Loss: 17.9197\n",
      "Epoch [52/100], Step [12900/6235], Loss: 38.2687\n",
      "Epoch [52/100], Step [13000/6235], Loss: 1.0313\n",
      "Epoch [52/100], Step [13100/6235], Loss: 66.5092\n",
      "Epoch [52/100], Step [13200/6235], Loss: 6.7358\n",
      "Epoch [52/100], Step [13300/6235], Loss: 18.3657\n",
      "Epoch [52/100], Step [13400/6235], Loss: 230.5218\n",
      "Epoch [52/100], Step [13500/6235], Loss: 0.4026\n",
      "Epoch [52/100], Step [13600/6235], Loss: 11.6075\n",
      "Epoch [52/100], Step [13700/6235], Loss: 188.9576\n",
      "Epoch [52/100], Step [13800/6235], Loss: 75.4825\n",
      "Epoch [52/100], Step [13900/6235], Loss: 30.5746\n",
      "Epoch [52/100], Step [14000/6235], Loss: 2.4647\n",
      "Epoch [52/100], Step [14100/6235], Loss: 60.2765\n",
      "Epoch [52/100], Step [14200/6235], Loss: 80.2313\n",
      "Epoch [52/100], Step [14300/6235], Loss: 34.0672\n",
      "Epoch [52/100], Step [14400/6235], Loss: 35.1129\n",
      "Epoch [52/100], Step [14500/6235], Loss: 24.0699\n",
      "Epoch [52/100], Step [14600/6235], Loss: 3.0612\n",
      "Epoch [52/100], Step [14700/6235], Loss: 20.1209\n",
      "Epoch [52/100], Step [14800/6235], Loss: 25.6539\n",
      "Epoch [52/100], Step [14900/6235], Loss: 0.7997\n",
      "Epoch [52/100], Step [15000/6235], Loss: 0.9687\n",
      "Epoch [52/100], Step [15100/6235], Loss: 0.3209\n",
      "Epoch [52/100], Step [15200/6235], Loss: 19.4078\n",
      "Epoch [52/100], Step [15300/6235], Loss: 41.1215\n",
      "Epoch [52/100], Step [15400/6235], Loss: 72.6789\n",
      "Epoch [52/100], Step [15500/6235], Loss: 15.0183\n",
      "Epoch [52/100], Step [15600/6235], Loss: 106.4610\n",
      "Epoch [52/100], Step [15700/6235], Loss: 119.4036\n",
      "Epoch [52/100], Step [15800/6235], Loss: 0.1752\n",
      "Epoch [52/100], Step [15900/6235], Loss: 2.1710\n",
      "Epoch [52/100], Step [16000/6235], Loss: 105.1871\n",
      "Epoch [52/100], Step [16100/6235], Loss: 3.1941\n",
      "Epoch [52/100], Step [16200/6235], Loss: 0.4021\n",
      "Epoch [52/100], Step [16300/6235], Loss: 10.5294\n",
      "Epoch [52/100], Step [16400/6235], Loss: 26.5318\n",
      "Epoch [52/100], Step [16500/6235], Loss: 743.0721\n",
      "Epoch [52/100], Step [16600/6235], Loss: 14.5721\n",
      "Epoch [52/100], Step [16700/6235], Loss: 0.5194\n",
      "Epoch [52/100], Step [16800/6235], Loss: 12.7546\n",
      "Epoch [52/100], Step [16900/6235], Loss: 0.0905\n",
      "Epoch [52/100], Step [17000/6235], Loss: 0.2249\n",
      "Epoch [52/100], Step [17100/6235], Loss: 0.4256\n",
      "Epoch [52/100], Step [17200/6235], Loss: 305.4212\n",
      "Epoch [52/100], Step [17300/6235], Loss: 42.5576\n",
      "Epoch [52/100], Step [17400/6235], Loss: 32.0398\n",
      "Epoch [52/100], Step [17500/6235], Loss: 0.5086\n",
      "Epoch [52/100], Step [17600/6235], Loss: 3.7815\n",
      "Epoch [52/100], Step [17700/6235], Loss: 73.6321\n",
      "Epoch [52/100], Step [17800/6235], Loss: 17.4208\n",
      "Epoch [52/100], Step [17900/6235], Loss: 6.7818\n",
      "Epoch [52/100], Step [18000/6235], Loss: 3.4592\n",
      "Epoch [52/100], Step [18100/6235], Loss: 15.6162\n",
      "Epoch [52/100], Step [18200/6235], Loss: 0.4048\n",
      "Epoch [52/100], Step [18300/6235], Loss: 3.5752\n",
      "Epoch [52/100], Step [18400/6235], Loss: 1.6098\n",
      "Epoch [52/100], Step [18500/6235], Loss: 17.1823\n",
      "Epoch [52/100], Step [18600/6235], Loss: 2.4013\n",
      "Epoch [52/100], Step [18700/6235], Loss: 0.5515\n",
      "Epoch [52/100], Step [18800/6235], Loss: 143.3645\n",
      "Epoch [52/100], Step [18900/6235], Loss: 51.7258\n",
      "Epoch [52/100], Step [19000/6235], Loss: 5.4765\n",
      "Epoch [52/100], Step [19100/6235], Loss: 33.8632\n",
      "Epoch [52/100], Step [19200/6235], Loss: 2.0874\n",
      "Epoch [52/100], Step [19300/6235], Loss: 3.2958\n",
      "Epoch [52/100], Step [19400/6235], Loss: 226.5320\n",
      "Epoch [52/100], Step [19500/6235], Loss: 127.4419\n",
      "Epoch [52/100], Step [19600/6235], Loss: 76.8773\n",
      "Epoch [52/100], Step [19700/6235], Loss: 8.5187\n",
      "Epoch [52/100], Step [19800/6235], Loss: 5.7332\n",
      "Epoch [52/100], Step [19900/6235], Loss: 0.1001\n",
      "Epoch [52/100], Step [20000/6235], Loss: 67.3267\n",
      "Epoch [52/100], Step [20100/6235], Loss: 0.4775\n",
      "Epoch [52/100], Step [20200/6235], Loss: 4.5834\n",
      "Epoch [52/100], Step [20300/6235], Loss: 2.5015\n",
      "Epoch [52/100], Step [20400/6235], Loss: 17.0492\n",
      "Epoch [52/100], Step [20500/6235], Loss: 46.8627\n",
      "Epoch [52/100], Step [20600/6235], Loss: 117.9413\n",
      "Epoch [52/100], Step [20700/6235], Loss: 0.4581\n",
      "Epoch [52/100], Step [20800/6235], Loss: 6.9821\n",
      "Epoch [52/100], Step [20900/6235], Loss: 13.3683\n",
      "Epoch [52/100], Step [21000/6235], Loss: 17.6379\n",
      "Epoch [52/100], Step [21100/6235], Loss: 6.3164\n",
      "Epoch [52/100], Step [21200/6235], Loss: 0.2878\n",
      "Epoch [52/100], Step [21300/6235], Loss: 0.1931\n",
      "Epoch [52/100], Step [21400/6235], Loss: 6.9131\n",
      "Epoch [52/100], Step [21500/6235], Loss: 4.3940\n",
      "Epoch [52/100], Step [21600/6235], Loss: 8.9426\n",
      "Epoch [52/100], Step [21700/6235], Loss: 0.1828\n",
      "Epoch [52/100], Step [21800/6235], Loss: 2.4353\n",
      "Epoch [52/100], Step [21900/6235], Loss: 0.7776\n",
      "Epoch [52/100], Step [22000/6235], Loss: 4.5867\n",
      "Epoch [52/100], Step [22100/6235], Loss: 2.6889\n",
      "Epoch [52/100], Step [22200/6235], Loss: 9.7402\n",
      "Epoch [52/100], Step [22300/6235], Loss: 2.6178\n",
      "Epoch [52/100], Step [22400/6235], Loss: 6.2870\n",
      "Epoch [52/100], Step [22500/6235], Loss: 151.8056\n",
      "Epoch [52/100], Step [22600/6235], Loss: 14.6211\n",
      "Epoch [52/100], Step [22700/6235], Loss: 0.6228\n",
      "Epoch [52/100], Step [22800/6235], Loss: 2.6256\n",
      "Epoch [52/100], Step [22900/6235], Loss: 3.5065\n",
      "Epoch [52/100], Step [23000/6235], Loss: 12.7357\n",
      "Epoch [52/100], Step [23100/6235], Loss: 0.4629\n",
      "Epoch [52/100], Step [23200/6235], Loss: 20.2647\n",
      "Epoch [52/100], Step [23300/6235], Loss: 14.2977\n",
      "Epoch [52/100], Step [23400/6235], Loss: 0.5603\n",
      "Epoch [52/100], Step [23500/6235], Loss: 0.2843\n",
      "Epoch [52/100], Step [23600/6235], Loss: 97.5284\n",
      "Epoch [52/100], Step [23700/6235], Loss: 8.0000\n",
      "Epoch [52/100], Step [23800/6235], Loss: 0.6582\n",
      "Epoch [52/100], Step [23900/6235], Loss: 7.5885\n",
      "Epoch [52/100], Step [24000/6235], Loss: 0.7207\n",
      "Epoch [52/100], Step [24100/6235], Loss: 1.4103\n",
      "Epoch [52/100], Step [24200/6235], Loss: 17.3180\n",
      "Epoch [52/100], Step [24300/6235], Loss: 1.8260\n",
      "Epoch [52/100], Step [24400/6235], Loss: 4.2649\n",
      "Epoch [52/100], Step [24500/6235], Loss: 1.6985\n",
      "Epoch [52/100], Step [24600/6235], Loss: 0.1298\n",
      "Epoch [52/100], Step [24700/6235], Loss: 0.9062\n",
      "Epoch [52/100], Step [24800/6235], Loss: 0.1320\n",
      "Epoch [52/100], Step [24900/6235], Loss: 16.1997\n",
      "Epoch [52/100], Step [25000/6235], Loss: 19.7645\n",
      "Epoch [52/100], Step [25100/6235], Loss: 8.1348\n",
      "Epoch [52/100], Step [25200/6235], Loss: 1.7907\n",
      "Epoch [52/100], Step [25300/6235], Loss: 0.7029\n",
      "Epoch [52/100], Step [25400/6235], Loss: 9.6878\n",
      "Epoch [52/100], Step [25500/6235], Loss: 4.5032\n",
      "Epoch [52/100], Step [25600/6235], Loss: 1.7413\n",
      "Epoch [52/100], Step [25700/6235], Loss: 0.2597\n",
      "Epoch [52/100], Step [25800/6235], Loss: 0.1629\n",
      "Epoch [52/100], Step [25900/6235], Loss: 10.4907\n",
      "Epoch [52/100], Step [26000/6235], Loss: 0.4439\n",
      "Epoch [52/100], Step [26100/6235], Loss: 0.4288\n",
      "Epoch [52/100], Step [26200/6235], Loss: 0.0174\n",
      "Epoch [52/100], Step [26300/6235], Loss: 4.7964\n",
      "Epoch [52/100], Step [26400/6235], Loss: 0.1724\n",
      "Epoch [52/100], Step [26500/6235], Loss: 0.2327\n",
      "Epoch [52/100], Step [26600/6235], Loss: 3.4124\n",
      "Epoch [52/100], Step [26700/6235], Loss: 0.6723\n",
      "Epoch [52/100], Step [26800/6235], Loss: 0.6427\n",
      "Epoch [52/100], Step [26900/6235], Loss: 0.0421\n",
      "Epoch [52/100], Step [27000/6235], Loss: 12.1792\n",
      "Epoch [52/100], Step [27100/6235], Loss: 0.2183\n",
      "Epoch [52/100], Step [27200/6235], Loss: 0.0856\n",
      "Epoch [52/100], Step [27300/6235], Loss: 0.1796\n",
      "Epoch [52/100], Step [27400/6235], Loss: 0.9318\n",
      "Epoch [52/100], Step [27500/6235], Loss: 9.8887\n",
      "Epoch [52/100], Step [27600/6235], Loss: 0.2630\n",
      "Epoch [52/100], Step [27700/6235], Loss: 1.7025\n",
      "Epoch [52/100], Step [27800/6235], Loss: 6.4089\n",
      "Epoch [52/100], Step [27900/6235], Loss: 0.3855\n",
      "Epoch [52/100], Step [28000/6235], Loss: 141.6060\n",
      "Epoch [52/100], Step [28100/6235], Loss: 4.9731\n",
      "Epoch [52/100], Step [28200/6235], Loss: 31.9272\n",
      "Epoch [52/100], Step [28300/6235], Loss: 3.3043\n",
      "Epoch [52/100], Step [28400/6235], Loss: 25.5499\n",
      "Epoch [52/100], Step [28500/6235], Loss: 3.1282\n",
      "Epoch [52/100], Step [28600/6235], Loss: 0.0603\n",
      "Epoch [52/100], Step [28700/6235], Loss: 5.3311\n",
      "Epoch [52/100], Step [28800/6235], Loss: 0.5383\n",
      "Epoch [52/100], Step [28900/6235], Loss: 73.8261\n",
      "Epoch [52/100], Step [29000/6235], Loss: 10.9277\n",
      "Epoch [52/100], Step [29100/6235], Loss: 0.0461\n",
      "Epoch [52/100], Step [29200/6235], Loss: 0.1822\n",
      "Epoch [52/100], Step [29300/6235], Loss: 7.1905\n",
      "Epoch [52/100], Step [29400/6235], Loss: 0.3418\n",
      "Epoch [52/100], Step [29500/6235], Loss: 5.3192\n",
      "Epoch [52/100], Step [29600/6235], Loss: 0.7242\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Step [29700/6235], Loss: 0.2714\n",
      "Epoch [52/100], Step [29800/6235], Loss: 1.6967\n",
      "Epoch [52/100], Step [29900/6235], Loss: 0.4650\n",
      "Epoch [52/100], Step [30000/6235], Loss: 6.2272\n",
      "Epoch [52/100], Step [30100/6235], Loss: 0.0236\n",
      "Epoch [52/100], Step [30200/6235], Loss: 0.0725\n",
      "Epoch [52/100], Step [30300/6235], Loss: 0.4239\n",
      "Epoch [52/100], Step [30400/6235], Loss: 0.2654\n",
      "Epoch [52/100], Step [30500/6235], Loss: 2.4683\n",
      "Epoch [52/100], Step [30600/6235], Loss: 0.8702\n",
      "Epoch [52/100], Step [30700/6235], Loss: 0.0315\n",
      "Epoch [52/100], Step [30800/6235], Loss: 0.2974\n",
      "Epoch [52/100], Step [30900/6235], Loss: 3.5540\n",
      "Epoch [52/100], Step [31000/6235], Loss: 0.0160\n",
      "Epoch [52/100], Step [31100/6235], Loss: 0.0528\n",
      "Epoch [52/100], Step [31200/6235], Loss: 6.8722\n",
      "Epoch [52/100], Step [31300/6235], Loss: 2.1865\n",
      "Epoch [52/100], Step [31400/6235], Loss: 2.6247\n",
      "Epoch [52/100], Step [31500/6235], Loss: 1.2655\n",
      "Epoch [52/100], Step [31600/6235], Loss: 5.5641\n",
      "Epoch [52/100], Step [31700/6235], Loss: 33.6178\n",
      "Epoch [52/100], Step [31800/6235], Loss: 2.4936\n",
      "Epoch [52/100], Step [31900/6235], Loss: 255.7504\n",
      "Epoch [52/100], Step [32000/6235], Loss: 107.3398\n",
      "Epoch [52/100], Step [32100/6235], Loss: 2.8729\n",
      "Epoch [52/100], Step [32200/6235], Loss: 82.4604\n",
      "Epoch [52/100], Step [32300/6235], Loss: 0.2937\n",
      "Epoch [52/100], Step [32400/6235], Loss: 0.7998\n",
      "Epoch [52/100], Step [32500/6235], Loss: 21.5646\n",
      "Epoch [52/100], Step [32600/6235], Loss: 0.7547\n",
      "Epoch [52/100], Step [32700/6235], Loss: 79.6567\n",
      "Epoch [52/100], Step [32800/6235], Loss: 0.7088\n",
      "Epoch [52/100], Step [32900/6235], Loss: 0.5463\n",
      "Epoch [52/100], Step [33000/6235], Loss: 0.3306\n",
      "Epoch [52/100], Step [33100/6235], Loss: 0.6154\n",
      "Epoch [52/100], Step [33200/6235], Loss: 1.1857\n",
      "Epoch [52/100], Step [33300/6235], Loss: 0.3960\n",
      "Epoch [52/100], Step [33400/6235], Loss: 152.0758\n",
      "Epoch [52/100], Step [33500/6235], Loss: 1.5364\n",
      "Epoch [52/100], Step [33600/6235], Loss: 5.2163\n",
      "Epoch [52/100], Step [33700/6235], Loss: 0.8943\n",
      "Epoch [52/100], Step [33800/6235], Loss: 0.6110\n",
      "Epoch [52/100], Step [33900/6235], Loss: 30.2255\n",
      "Epoch [52/100], Step [34000/6235], Loss: 0.1299\n",
      "Epoch [52/100], Step [34100/6235], Loss: 0.6689\n",
      "Epoch [52/100], Step [34200/6235], Loss: 2.4886\n",
      "Epoch [52/100], Step [34300/6235], Loss: 2.8536\n",
      "Epoch [52/100], Step [34400/6235], Loss: 0.1502\n",
      "Epoch [52/100], Step [34500/6235], Loss: 17.2774\n",
      "Epoch [52/100], Step [34600/6235], Loss: 1.4268\n",
      "Epoch [52/100], Step [34700/6235], Loss: 18.0462\n",
      "Epoch [52/100], Step [34800/6235], Loss: 12.0577\n",
      "Epoch [52/100], Step [34900/6235], Loss: 68.0117\n",
      "Epoch [52/100], Step [35000/6235], Loss: 0.5275\n",
      "Epoch [52/100], Step [35100/6235], Loss: 0.6651\n",
      "Epoch [52/100], Step [35200/6235], Loss: 0.5300\n",
      "Epoch [52/100], Step [35300/6235], Loss: 3.0542\n",
      "Epoch [52/100], Step [35400/6235], Loss: 0.5656\n",
      "Epoch [52/100], Step [35500/6235], Loss: 0.8124\n",
      "Epoch [52/100], Step [35600/6235], Loss: 1.6443\n",
      "Epoch [52/100], Step [35700/6235], Loss: 4.2369\n",
      "Epoch [52/100], Step [35800/6235], Loss: 1.3404\n",
      "Epoch [52/100], Step [35900/6235], Loss: 0.9735\n",
      "Epoch [52/100], Step [36000/6235], Loss: 0.0619\n",
      "Epoch [52/100], Step [36100/6235], Loss: 0.0672\n",
      "Epoch [52/100], Step [36200/6235], Loss: 12.8830\n",
      "Epoch [52/100], Step [36300/6235], Loss: 0.3478\n",
      "Epoch [52/100], Step [36400/6235], Loss: 3.0732\n",
      "Epoch [52/100], Step [36500/6235], Loss: 7.6267\n",
      "Epoch [52/100], Step [36600/6235], Loss: 0.1291\n",
      "Epoch [52/100], Step [36700/6235], Loss: 0.5928\n",
      "Epoch [52/100], Step [36800/6235], Loss: 4.9856\n",
      "Epoch [52/100], Step [36900/6235], Loss: 11.1274\n",
      "Epoch [52/100], Step [37000/6235], Loss: 0.9430\n",
      "Epoch [52/100], Step [37100/6235], Loss: 2.0315\n",
      "Epoch [52/100], Step [37200/6235], Loss: 0.0594\n",
      "Epoch [52/100], Step [37300/6235], Loss: 0.0427\n",
      "Epoch [52/100], Step [37400/6235], Loss: 0.1785\n",
      "Epoch [52/100], Step [37500/6235], Loss: 6.6169\n",
      "Epoch [52/100], Step [37600/6235], Loss: 12.0639\n",
      "Epoch [52/100], Step [37700/6235], Loss: 0.5726\n",
      "Epoch [52/100], Step [37800/6235], Loss: 2.0957\n",
      "Epoch [52/100], Step [37900/6235], Loss: 5.2996\n",
      "Epoch [52/100], Step [38000/6235], Loss: 0.7730\n",
      "Epoch [52/100], Step [38100/6235], Loss: 4.2565\n",
      "Epoch [52/100], Step [38200/6235], Loss: 1.6549\n",
      "Epoch [52/100], Step [38300/6235], Loss: 0.2037\n",
      "Epoch [52/100], Step [38400/6235], Loss: 0.0622\n",
      "Epoch [52/100], Step [38500/6235], Loss: 1.4520\n",
      "Epoch [52/100], Step [38600/6235], Loss: 0.5783\n",
      "Epoch [52/100], Step [38700/6235], Loss: 0.0703\n",
      "Epoch [52/100], Step [38800/6235], Loss: 0.1023\n",
      "Epoch [52/100], Step [38900/6235], Loss: 0.6414\n",
      "Epoch [52/100], Step [39000/6235], Loss: 1.6821\n",
      "Epoch [52/100], Step [39100/6235], Loss: 0.1257\n",
      "Epoch [52/100], Step [39200/6235], Loss: 1.0004\n",
      "Epoch [52/100], Step [39300/6235], Loss: 102.0998\n",
      "Epoch [52/100], Step [39400/6235], Loss: 155.3021\n",
      "Epoch [52/100], Step [39500/6235], Loss: 290.7319\n",
      "Epoch [52/100], Step [39600/6235], Loss: 12.8502\n",
      "Epoch [52/100], Step [39700/6235], Loss: 40.1359\n",
      "Epoch [52/100], Step [39800/6235], Loss: 122.2994\n",
      "Epoch [52/100], Step [39900/6235], Loss: 0.7113\n",
      "Epoch [52/100], Step [40000/6235], Loss: 17.5389\n",
      "Epoch [52/100], Step [40100/6235], Loss: 26.0565\n",
      "Epoch [52/100], Step [40200/6235], Loss: 2.2667\n",
      "Epoch [52/100], Step [40300/6235], Loss: 0.9861\n",
      "Epoch [52/100], Step [40400/6235], Loss: 2.6961\n",
      "Epoch [52/100], Step [40500/6235], Loss: 2.2564\n",
      "Epoch [52/100], Step [40600/6235], Loss: 0.3581\n",
      "Epoch [52/100], Step [40700/6235], Loss: 7.5798\n",
      "Epoch [52/100], Step [40800/6235], Loss: 1.4925\n",
      "Epoch [52/100], Step [40900/6235], Loss: 0.0980\n",
      "Epoch [52/100], Step [41000/6235], Loss: 47.9135\n",
      "Epoch [52/100], Step [41100/6235], Loss: 35.7009\n",
      "Epoch [52/100], Step [41200/6235], Loss: 9.3485\n",
      "Epoch [52/100], Step [41300/6235], Loss: 6.1231\n",
      "Epoch [52/100], Step [41400/6235], Loss: 3.1690\n",
      "Epoch [52/100], Step [41500/6235], Loss: 1.2716\n",
      "Epoch [52/100], Step [41600/6235], Loss: 0.4547\n",
      "Epoch [52/100], Step [41700/6235], Loss: 2.3615\n",
      "Epoch [52/100], Step [41800/6235], Loss: 4.3801\n",
      "Epoch [52/100], Step [41900/6235], Loss: 4.2965\n",
      "Epoch [52/100], Step [42000/6235], Loss: 4.2925\n",
      "Epoch [52/100], Step [42100/6235], Loss: 9.2284\n",
      "Epoch [52/100], Step [42200/6235], Loss: 12.6776\n",
      "Epoch [52/100], Step [42300/6235], Loss: 3.0261\n",
      "Epoch [52/100], Step [42400/6235], Loss: 7.6126\n",
      "Epoch [52/100], Step [42500/6235], Loss: 0.7991\n",
      "Epoch [52/100], Step [42600/6235], Loss: 2.1625\n",
      "Epoch [52/100], Step [42700/6235], Loss: 0.7627\n",
      "Epoch [52/100], Step [42800/6235], Loss: 9.0524\n",
      "Epoch [52/100], Step [42900/6235], Loss: 2.2424\n",
      "Epoch [52/100], Step [43000/6235], Loss: 0.1941\n",
      "Epoch [52/100], Step [43100/6235], Loss: 0.0738\n",
      "Epoch [52/100], Step [43200/6235], Loss: 1.0126\n",
      "Epoch [52/100], Step [43300/6235], Loss: 8.0696\n",
      "Epoch [52/100], Step [43400/6235], Loss: 12.3934\n",
      "Epoch [52/100], Step [43500/6235], Loss: 9.4235\n",
      "Epoch [52/100], Step [43600/6235], Loss: 11.9108\n",
      "Epoch [52/100], Step [43700/6235], Loss: 43.1031\n",
      "Epoch [52/100], Step [43800/6235], Loss: 0.7063\n",
      "Epoch [52/100], Step [43900/6235], Loss: 1.1251\n",
      "Epoch [52/100], Step [44000/6235], Loss: 57.2967\n",
      "Epoch [52/100], Step [44100/6235], Loss: 1.6369\n",
      "Epoch [52/100], Step [44200/6235], Loss: 5.5100\n",
      "Epoch [52/100], Step [44300/6235], Loss: 14.4989\n",
      "Epoch [52/100], Step [44400/6235], Loss: 0.6521\n",
      "Epoch [52/100], Step [44500/6235], Loss: 3.9339\n",
      "Epoch [52/100], Step [44600/6235], Loss: 25.9460\n",
      "Epoch [52/100], Step [44700/6235], Loss: 0.5312\n",
      "Epoch [52/100], Step [44800/6235], Loss: 4.4468\n",
      "Epoch [52/100], Step [44900/6235], Loss: 3.9087\n",
      "Epoch [52/100], Step [45000/6235], Loss: 4.8722\n",
      "Epoch [52/100], Step [45100/6235], Loss: 75.2689\n",
      "Epoch [52/100], Step [45200/6235], Loss: 0.5374\n",
      "Epoch [52/100], Step [45300/6235], Loss: 32.6821\n",
      "Epoch [52/100], Step [45400/6235], Loss: 12.3151\n",
      "Epoch [52/100], Step [45500/6235], Loss: 0.2327\n",
      "Epoch [52/100], Step [45600/6235], Loss: 0.3173\n",
      "Epoch [52/100], Step [45700/6235], Loss: 64.6794\n",
      "Epoch [52/100], Step [45800/6235], Loss: 370.5251\n",
      "Epoch [52/100], Step [45900/6235], Loss: 7.1468\n",
      "Epoch [52/100], Step [46000/6235], Loss: 0.9183\n",
      "Epoch [52/100], Step [46100/6235], Loss: 15.1459\n",
      "Epoch [52/100], Step [46200/6235], Loss: 74.2788\n",
      "Epoch [52/100], Step [46300/6235], Loss: 25.0152\n",
      "Epoch [52/100], Step [46400/6235], Loss: 3.3982\n",
      "Epoch [52/100], Step [46500/6235], Loss: 28.5004\n",
      "Epoch [52/100], Step [46600/6235], Loss: 14.6696\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [52/100], Step [46700/6235], Loss: 7.1210\n",
      "Epoch [52/100], Step [46800/6235], Loss: 14.7875\n",
      "Epoch [52/100], Step [46900/6235], Loss: 14.2517\n",
      "Epoch [52/100], Step [47000/6235], Loss: 1.7956\n",
      "Epoch [52/100], Step [47100/6235], Loss: 24.3990\n",
      "Epoch [52/100], Step [47200/6235], Loss: 49.4748\n",
      "Epoch [52/100], Step [47300/6235], Loss: 0.8484\n",
      "Epoch [52/100], Step [47400/6235], Loss: 81.6269\n",
      "Epoch [52/100], Step [47500/6235], Loss: 1.5151\n",
      "Epoch [52/100], Step [47600/6235], Loss: 9.0975\n",
      "Epoch [52/100], Step [47700/6235], Loss: 7.6481\n",
      "Epoch [52/100], Step [47800/6235], Loss: 9.3705\n",
      "Epoch [52/100], Step [47900/6235], Loss: 18.7297\n",
      "Epoch [52/100], Step [48000/6235], Loss: 1.7542\n",
      "Epoch [52/100], Step [48100/6235], Loss: 4.3125\n",
      "Epoch [52/100], Step [48200/6235], Loss: 19.0567\n",
      "Epoch [52/100], Step [48300/6235], Loss: 381.1057\n",
      "Epoch [52/100], Step [48400/6235], Loss: 17.2473\n",
      "Epoch [52/100], Step [48500/6235], Loss: 37.9409\n",
      "Epoch [52/100], Step [48600/6235], Loss: 140.0096\n",
      "Epoch [52/100], Step [48700/6235], Loss: 1.8898\n",
      "Epoch [52/100], Step [48800/6235], Loss: 325.0945\n",
      "Epoch [52/100], Step [48900/6235], Loss: 348.0320\n",
      "Epoch [52/100], Step [49000/6235], Loss: 276.0611\n",
      "Epoch [52/100], Step [49100/6235], Loss: 2685.8564\n",
      "Epoch [52/100], Step [49200/6235], Loss: 1106.7667\n",
      "Epoch [52/100], Step [49300/6235], Loss: 1040.2281\n",
      "Epoch [52/100], Step [49400/6235], Loss: 121.4081\n",
      "Epoch [52/100], Step [49500/6235], Loss: 1.7047\n",
      "Epoch [52/100], Step [49600/6235], Loss: 326.6602\n",
      "Epoch [52/100], Step [49700/6235], Loss: 848.4296\n",
      "Epoch [52/100], Step [49800/6235], Loss: 105.1985\n",
      "Epoch [53/100], Step [100/6235], Loss: 31.7295\n",
      "Epoch [53/100], Step [200/6235], Loss: 0.2128\n",
      "Epoch [53/100], Step [300/6235], Loss: 0.0631\n",
      "Epoch [53/100], Step [400/6235], Loss: 0.0064\n",
      "Epoch [53/100], Step [500/6235], Loss: 36.1765\n",
      "Epoch [53/100], Step [600/6235], Loss: 0.1100\n",
      "Epoch [53/100], Step [700/6235], Loss: 0.6473\n",
      "Epoch [53/100], Step [800/6235], Loss: 0.0277\n",
      "Epoch [53/100], Step [900/6235], Loss: 0.4735\n",
      "Epoch [53/100], Step [1000/6235], Loss: 0.0715\n",
      "Epoch [53/100], Step [1100/6235], Loss: 1.8892\n",
      "Epoch [53/100], Step [1200/6235], Loss: 0.1864\n",
      "Epoch [53/100], Step [1300/6235], Loss: 0.0290\n",
      "Epoch [53/100], Step [1400/6235], Loss: 1.5414\n",
      "Epoch [53/100], Step [1500/6235], Loss: 0.0076\n",
      "Epoch [53/100], Step [1600/6235], Loss: 0.2398\n",
      "Epoch [53/100], Step [1700/6235], Loss: 0.3420\n",
      "Epoch [53/100], Step [1800/6235], Loss: 0.3328\n",
      "Epoch [53/100], Step [1900/6235], Loss: 0.2870\n",
      "Epoch [53/100], Step [2000/6235], Loss: 1.9940\n",
      "Epoch [53/100], Step [2100/6235], Loss: 3.0836\n",
      "Epoch [53/100], Step [2200/6235], Loss: 4.2866\n",
      "Epoch [53/100], Step [2300/6235], Loss: 1.7861\n",
      "Epoch [53/100], Step [2400/6235], Loss: 2.3417\n",
      "Epoch [53/100], Step [2500/6235], Loss: 20.9718\n",
      "Epoch [53/100], Step [2600/6235], Loss: 16.8592\n",
      "Epoch [53/100], Step [2700/6235], Loss: 11.0699\n",
      "Epoch [53/100], Step [2800/6235], Loss: 62.9342\n",
      "Epoch [53/100], Step [2900/6235], Loss: 9.3616\n",
      "Epoch [53/100], Step [3000/6235], Loss: 0.2520\n",
      "Epoch [53/100], Step [3100/6235], Loss: 86.2079\n",
      "Epoch [53/100], Step [3200/6235], Loss: 22.1040\n",
      "Epoch [53/100], Step [3300/6235], Loss: 2.5201\n",
      "Epoch [53/100], Step [3400/6235], Loss: 6.8230\n",
      "Epoch [53/100], Step [3500/6235], Loss: 59.8637\n",
      "Epoch [53/100], Step [3600/6235], Loss: 0.2344\n",
      "Epoch [53/100], Step [3700/6235], Loss: 0.1218\n",
      "Epoch [53/100], Step [3800/6235], Loss: 0.1222\n",
      "Epoch [53/100], Step [3900/6235], Loss: 0.0700\n",
      "Epoch [53/100], Step [4000/6235], Loss: 0.1843\n",
      "Epoch [53/100], Step [4100/6235], Loss: 9.2831\n",
      "Epoch [53/100], Step [4200/6235], Loss: 5.6847\n",
      "Epoch [53/100], Step [4300/6235], Loss: 2.7501\n",
      "Epoch [53/100], Step [4400/6235], Loss: 0.1386\n",
      "Epoch [53/100], Step [4500/6235], Loss: 47.6655\n",
      "Epoch [53/100], Step [4600/6235], Loss: 6.7127\n",
      "Epoch [53/100], Step [4700/6235], Loss: 0.2953\n",
      "Epoch [53/100], Step [4800/6235], Loss: 3.3839\n",
      "Epoch [53/100], Step [4900/6235], Loss: 4.6034\n",
      "Epoch [53/100], Step [5000/6235], Loss: 0.2908\n",
      "Epoch [53/100], Step [5100/6235], Loss: 1.0759\n",
      "Epoch [53/100], Step [5200/6235], Loss: 7.0623\n",
      "Epoch [53/100], Step [5300/6235], Loss: 11.3035\n",
      "Epoch [53/100], Step [5400/6235], Loss: 3.5076\n",
      "Epoch [53/100], Step [5500/6235], Loss: 0.0413\n",
      "Epoch [53/100], Step [5600/6235], Loss: 0.0771\n",
      "Epoch [53/100], Step [5700/6235], Loss: 0.0301\n",
      "Epoch [53/100], Step [5800/6235], Loss: 0.4082\n",
      "Epoch [53/100], Step [5900/6235], Loss: 0.0557\n",
      "Epoch [53/100], Step [6000/6235], Loss: 1.7346\n",
      "Epoch [53/100], Step [6100/6235], Loss: 0.0445\n",
      "Epoch [53/100], Step [6200/6235], Loss: 7.6375\n",
      "Epoch [53/100], Step [6300/6235], Loss: 0.9868\n",
      "Epoch [53/100], Step [6400/6235], Loss: 0.0125\n",
      "Epoch [53/100], Step [6500/6235], Loss: 0.3601\n",
      "Epoch [53/100], Step [6600/6235], Loss: 9.6818\n",
      "Epoch [53/100], Step [6700/6235], Loss: 1.1747\n",
      "Epoch [53/100], Step [6800/6235], Loss: 0.3544\n",
      "Epoch [53/100], Step [6900/6235], Loss: 0.6425\n",
      "Epoch [53/100], Step [7000/6235], Loss: 0.0070\n",
      "Epoch [53/100], Step [7100/6235], Loss: 0.5108\n",
      "Epoch [53/100], Step [7200/6235], Loss: 0.6559\n",
      "Epoch [53/100], Step [7300/6235], Loss: 0.0488\n",
      "Epoch [53/100], Step [7400/6235], Loss: 0.2262\n",
      "Epoch [53/100], Step [7500/6235], Loss: 0.1899\n",
      "Epoch [53/100], Step [7600/6235], Loss: 0.6357\n",
      "Epoch [53/100], Step [7700/6235], Loss: 15.2123\n",
      "Epoch [53/100], Step [7800/6235], Loss: 1.3217\n",
      "Epoch [53/100], Step [7900/6235], Loss: 2.4517\n",
      "Epoch [53/100], Step [8000/6235], Loss: 0.5465\n",
      "Epoch [53/100], Step [8100/6235], Loss: 0.8779\n",
      "Epoch [53/100], Step [8200/6235], Loss: 10.0995\n",
      "Epoch [53/100], Step [8300/6235], Loss: 20.3485\n",
      "Epoch [53/100], Step [8400/6235], Loss: 614.8354\n",
      "Epoch [53/100], Step [8500/6235], Loss: 21.1166\n",
      "Epoch [53/100], Step [8600/6235], Loss: 26.5144\n",
      "Epoch [53/100], Step [8700/6235], Loss: 18.4459\n",
      "Epoch [53/100], Step [8800/6235], Loss: 513.1402\n",
      "Epoch [53/100], Step [8900/6235], Loss: 130.3600\n",
      "Epoch [53/100], Step [9000/6235], Loss: 622.3660\n",
      "Epoch [53/100], Step [9100/6235], Loss: 1407.8009\n",
      "Epoch [53/100], Step [9200/6235], Loss: 4308.4697\n",
      "Epoch [53/100], Step [9300/6235], Loss: 21.6371\n",
      "Epoch [53/100], Step [9400/6235], Loss: 75.0973\n",
      "Epoch [53/100], Step [9500/6235], Loss: 2377.9966\n",
      "Epoch [53/100], Step [9600/6235], Loss: 715.4422\n",
      "Epoch [53/100], Step [9700/6235], Loss: 6.1372\n",
      "Epoch [53/100], Step [9800/6235], Loss: 2018.4844\n",
      "Epoch [53/100], Step [9900/6235], Loss: 91.4823\n",
      "Epoch [53/100], Step [10000/6235], Loss: 217.1641\n",
      "Epoch [53/100], Step [10100/6235], Loss: 3.3868\n",
      "Epoch [53/100], Step [10200/6235], Loss: 606.7688\n",
      "Epoch [53/100], Step [10300/6235], Loss: 6.3003\n",
      "Epoch [53/100], Step [10400/6235], Loss: 1.9453\n",
      "Epoch [53/100], Step [10500/6235], Loss: 1.9939\n",
      "Epoch [53/100], Step [10600/6235], Loss: 10.6248\n",
      "Epoch [53/100], Step [10700/6235], Loss: 36.2308\n",
      "Epoch [53/100], Step [10800/6235], Loss: 32.3666\n",
      "Epoch [53/100], Step [10900/6235], Loss: 2.6044\n",
      "Epoch [53/100], Step [11000/6235], Loss: 273.2433\n",
      "Epoch [53/100], Step [11100/6235], Loss: 24.1305\n",
      "Epoch [53/100], Step [11200/6235], Loss: 58.7905\n",
      "Epoch [53/100], Step [11300/6235], Loss: 191.4409\n",
      "Epoch [53/100], Step [11400/6235], Loss: 2.8361\n",
      "Epoch [53/100], Step [11500/6235], Loss: 1.1903\n",
      "Epoch [53/100], Step [11600/6235], Loss: 0.7157\n",
      "Epoch [53/100], Step [11700/6235], Loss: 39.1145\n",
      "Epoch [53/100], Step [11800/6235], Loss: 302.1490\n",
      "Epoch [53/100], Step [11900/6235], Loss: 178.0239\n",
      "Epoch [53/100], Step [12000/6235], Loss: 368.8238\n",
      "Epoch [53/100], Step [12100/6235], Loss: 152.6192\n",
      "Epoch [53/100], Step [12200/6235], Loss: 39.3652\n",
      "Epoch [53/100], Step [12300/6235], Loss: 21.5108\n",
      "Epoch [53/100], Step [12400/6235], Loss: 698.6424\n",
      "Epoch [53/100], Step [12500/6235], Loss: 61.5426\n",
      "Epoch [53/100], Step [12600/6235], Loss: 54.2203\n",
      "Epoch [53/100], Step [12700/6235], Loss: 3.9278\n",
      "Epoch [53/100], Step [12800/6235], Loss: 6.5301\n",
      "Epoch [53/100], Step [12900/6235], Loss: 38.3885\n",
      "Epoch [53/100], Step [13000/6235], Loss: 0.3015\n",
      "Epoch [53/100], Step [13100/6235], Loss: 67.6303\n",
      "Epoch [53/100], Step [13200/6235], Loss: 13.6465\n",
      "Epoch [53/100], Step [13300/6235], Loss: 52.2527\n",
      "Epoch [53/100], Step [13400/6235], Loss: 250.2301\n",
      "Epoch [53/100], Step [13500/6235], Loss: 3.0657\n",
      "Epoch [53/100], Step [13600/6235], Loss: 0.5159\n",
      "Epoch [53/100], Step [13700/6235], Loss: 128.7079\n",
      "Epoch [53/100], Step [13800/6235], Loss: 131.5293\n",
      "Epoch [53/100], Step [13900/6235], Loss: 24.1172\n",
      "Epoch [53/100], Step [14000/6235], Loss: 13.6998\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Step [14100/6235], Loss: 19.9079\n",
      "Epoch [53/100], Step [14200/6235], Loss: 125.9095\n",
      "Epoch [53/100], Step [14300/6235], Loss: 65.6803\n",
      "Epoch [53/100], Step [14400/6235], Loss: 38.5159\n",
      "Epoch [53/100], Step [14500/6235], Loss: 42.3639\n",
      "Epoch [53/100], Step [14600/6235], Loss: 0.1461\n",
      "Epoch [53/100], Step [14700/6235], Loss: 41.6905\n",
      "Epoch [53/100], Step [14800/6235], Loss: 33.9558\n",
      "Epoch [53/100], Step [14900/6235], Loss: 1.0247\n",
      "Epoch [53/100], Step [15000/6235], Loss: 1.8566\n",
      "Epoch [53/100], Step [15100/6235], Loss: 0.4483\n",
      "Epoch [53/100], Step [15200/6235], Loss: 0.3492\n",
      "Epoch [53/100], Step [15300/6235], Loss: 34.2374\n",
      "Epoch [53/100], Step [15400/6235], Loss: 41.7862\n",
      "Epoch [53/100], Step [15500/6235], Loss: 12.5965\n",
      "Epoch [53/100], Step [15600/6235], Loss: 186.8849\n",
      "Epoch [53/100], Step [15700/6235], Loss: 202.9174\n",
      "Epoch [53/100], Step [15800/6235], Loss: 2.9630\n",
      "Epoch [53/100], Step [15900/6235], Loss: 3.0596\n",
      "Epoch [53/100], Step [16000/6235], Loss: 112.1577\n",
      "Epoch [53/100], Step [16100/6235], Loss: 5.5036\n",
      "Epoch [53/100], Step [16200/6235], Loss: 8.0480\n",
      "Epoch [53/100], Step [16300/6235], Loss: 8.5314\n",
      "Epoch [53/100], Step [16400/6235], Loss: 17.5894\n",
      "Epoch [53/100], Step [16500/6235], Loss: 87.7708\n",
      "Epoch [53/100], Step [16600/6235], Loss: 4.5282\n",
      "Epoch [53/100], Step [16700/6235], Loss: 0.7853\n",
      "Epoch [53/100], Step [16800/6235], Loss: 9.6733\n",
      "Epoch [53/100], Step [16900/6235], Loss: 0.5133\n",
      "Epoch [53/100], Step [17000/6235], Loss: 0.2005\n",
      "Epoch [53/100], Step [17100/6235], Loss: 0.1114\n",
      "Epoch [53/100], Step [17200/6235], Loss: 282.7174\n",
      "Epoch [53/100], Step [17300/6235], Loss: 59.7471\n",
      "Epoch [53/100], Step [17400/6235], Loss: 71.9018\n",
      "Epoch [53/100], Step [17500/6235], Loss: 0.5986\n",
      "Epoch [53/100], Step [17600/6235], Loss: 3.6295\n",
      "Epoch [53/100], Step [17700/6235], Loss: 43.3969\n",
      "Epoch [53/100], Step [17800/6235], Loss: 21.7532\n",
      "Epoch [53/100], Step [17900/6235], Loss: 4.6644\n",
      "Epoch [53/100], Step [18000/6235], Loss: 10.4597\n",
      "Epoch [53/100], Step [18100/6235], Loss: 14.2115\n",
      "Epoch [53/100], Step [18200/6235], Loss: 0.2613\n",
      "Epoch [53/100], Step [18300/6235], Loss: 2.3503\n",
      "Epoch [53/100], Step [18400/6235], Loss: 1.1658\n",
      "Epoch [53/100], Step [18500/6235], Loss: 17.2167\n",
      "Epoch [53/100], Step [18600/6235], Loss: 3.5957\n",
      "Epoch [53/100], Step [18700/6235], Loss: 0.7073\n",
      "Epoch [53/100], Step [18800/6235], Loss: 43.9211\n",
      "Epoch [53/100], Step [18900/6235], Loss: 43.6035\n",
      "Epoch [53/100], Step [19000/6235], Loss: 11.7597\n",
      "Epoch [53/100], Step [19100/6235], Loss: 8.6792\n",
      "Epoch [53/100], Step [19200/6235], Loss: 4.4761\n",
      "Epoch [53/100], Step [19300/6235], Loss: 8.0680\n",
      "Epoch [53/100], Step [19400/6235], Loss: 276.4786\n",
      "Epoch [53/100], Step [19500/6235], Loss: 115.4470\n",
      "Epoch [53/100], Step [19600/6235], Loss: 92.2333\n",
      "Epoch [53/100], Step [19700/6235], Loss: 5.1626\n",
      "Epoch [53/100], Step [19800/6235], Loss: 1.5861\n",
      "Epoch [53/100], Step [19900/6235], Loss: 0.5156\n",
      "Epoch [53/100], Step [20000/6235], Loss: 84.1575\n",
      "Epoch [53/100], Step [20100/6235], Loss: 2.3227\n",
      "Epoch [53/100], Step [20200/6235], Loss: 6.1864\n",
      "Epoch [53/100], Step [20300/6235], Loss: 1.3989\n",
      "Epoch [53/100], Step [20400/6235], Loss: 24.6348\n",
      "Epoch [53/100], Step [20500/6235], Loss: 36.4731\n",
      "Epoch [53/100], Step [20600/6235], Loss: 45.9765\n",
      "Epoch [53/100], Step [20700/6235], Loss: 13.0250\n",
      "Epoch [53/100], Step [20800/6235], Loss: 1.4311\n",
      "Epoch [53/100], Step [20900/6235], Loss: 32.2317\n",
      "Epoch [53/100], Step [21000/6235], Loss: 13.6622\n",
      "Epoch [53/100], Step [21100/6235], Loss: 6.7137\n",
      "Epoch [53/100], Step [21200/6235], Loss: 0.2592\n",
      "Epoch [53/100], Step [21300/6235], Loss: 0.2130\n",
      "Epoch [53/100], Step [21400/6235], Loss: 6.3577\n",
      "Epoch [53/100], Step [21500/6235], Loss: 3.0216\n",
      "Epoch [53/100], Step [21600/6235], Loss: 33.0685\n",
      "Epoch [53/100], Step [21700/6235], Loss: 0.1122\n",
      "Epoch [53/100], Step [21800/6235], Loss: 0.8562\n",
      "Epoch [53/100], Step [21900/6235], Loss: 0.4394\n",
      "Epoch [53/100], Step [22000/6235], Loss: 3.8169\n",
      "Epoch [53/100], Step [22100/6235], Loss: 3.3122\n",
      "Epoch [53/100], Step [22200/6235], Loss: 6.7654\n",
      "Epoch [53/100], Step [22300/6235], Loss: 0.9742\n",
      "Epoch [53/100], Step [22400/6235], Loss: 7.2026\n",
      "Epoch [53/100], Step [22500/6235], Loss: 110.1915\n",
      "Epoch [53/100], Step [22600/6235], Loss: 9.8642\n",
      "Epoch [53/100], Step [22700/6235], Loss: 1.3148\n",
      "Epoch [53/100], Step [22800/6235], Loss: 4.5057\n",
      "Epoch [53/100], Step [22900/6235], Loss: 2.8016\n",
      "Epoch [53/100], Step [23000/6235], Loss: 13.2935\n",
      "Epoch [53/100], Step [23100/6235], Loss: 0.3962\n",
      "Epoch [53/100], Step [23200/6235], Loss: 10.0165\n",
      "Epoch [53/100], Step [23300/6235], Loss: 19.3094\n",
      "Epoch [53/100], Step [23400/6235], Loss: 1.1099\n",
      "Epoch [53/100], Step [23500/6235], Loss: 0.2203\n",
      "Epoch [53/100], Step [23600/6235], Loss: 112.8996\n",
      "Epoch [53/100], Step [23700/6235], Loss: 6.5914\n",
      "Epoch [53/100], Step [23800/6235], Loss: 1.1338\n",
      "Epoch [53/100], Step [23900/6235], Loss: 6.9649\n",
      "Epoch [53/100], Step [24000/6235], Loss: 0.3199\n",
      "Epoch [53/100], Step [24100/6235], Loss: 1.3849\n",
      "Epoch [53/100], Step [24200/6235], Loss: 38.6804\n",
      "Epoch [53/100], Step [24300/6235], Loss: 1.2784\n",
      "Epoch [53/100], Step [24400/6235], Loss: 3.2288\n",
      "Epoch [53/100], Step [24500/6235], Loss: 1.5470\n",
      "Epoch [53/100], Step [24600/6235], Loss: 0.0900\n",
      "Epoch [53/100], Step [24700/6235], Loss: 1.4696\n",
      "Epoch [53/100], Step [24800/6235], Loss: 0.1575\n",
      "Epoch [53/100], Step [24900/6235], Loss: 14.7287\n",
      "Epoch [53/100], Step [25000/6235], Loss: 18.6943\n",
      "Epoch [53/100], Step [25100/6235], Loss: 6.7450\n",
      "Epoch [53/100], Step [25200/6235], Loss: 1.1742\n",
      "Epoch [53/100], Step [25300/6235], Loss: 0.5764\n",
      "Epoch [53/100], Step [25400/6235], Loss: 9.0202\n",
      "Epoch [53/100], Step [25500/6235], Loss: 6.0967\n",
      "Epoch [53/100], Step [25600/6235], Loss: 2.8553\n",
      "Epoch [53/100], Step [25700/6235], Loss: 0.3636\n",
      "Epoch [53/100], Step [25800/6235], Loss: 0.1430\n",
      "Epoch [53/100], Step [25900/6235], Loss: 9.8757\n",
      "Epoch [53/100], Step [26000/6235], Loss: 0.9536\n",
      "Epoch [53/100], Step [26100/6235], Loss: 0.4657\n",
      "Epoch [53/100], Step [26200/6235], Loss: 0.1164\n",
      "Epoch [53/100], Step [26300/6235], Loss: 4.9693\n",
      "Epoch [53/100], Step [26400/6235], Loss: 0.1087\n",
      "Epoch [53/100], Step [26500/6235], Loss: 0.0871\n",
      "Epoch [53/100], Step [26600/6235], Loss: 2.4808\n",
      "Epoch [53/100], Step [26700/6235], Loss: 0.5227\n",
      "Epoch [53/100], Step [26800/6235], Loss: 0.3555\n",
      "Epoch [53/100], Step [26900/6235], Loss: 0.0100\n",
      "Epoch [53/100], Step [27000/6235], Loss: 13.6595\n",
      "Epoch [53/100], Step [27100/6235], Loss: 0.0919\n",
      "Epoch [53/100], Step [27200/6235], Loss: 0.0439\n",
      "Epoch [53/100], Step [27300/6235], Loss: 0.2315\n",
      "Epoch [53/100], Step [27400/6235], Loss: 0.8415\n",
      "Epoch [53/100], Step [27500/6235], Loss: 20.8462\n",
      "Epoch [53/100], Step [27600/6235], Loss: 0.8829\n",
      "Epoch [53/100], Step [27700/6235], Loss: 1.5882\n",
      "Epoch [53/100], Step [27800/6235], Loss: 0.5701\n",
      "Epoch [53/100], Step [27900/6235], Loss: 0.8020\n",
      "Epoch [53/100], Step [28000/6235], Loss: 152.1389\n",
      "Epoch [53/100], Step [28100/6235], Loss: 2.2751\n",
      "Epoch [53/100], Step [28200/6235], Loss: 26.6537\n",
      "Epoch [53/100], Step [28300/6235], Loss: 3.1702\n",
      "Epoch [53/100], Step [28400/6235], Loss: 25.0530\n",
      "Epoch [53/100], Step [28500/6235], Loss: 4.2309\n",
      "Epoch [53/100], Step [28600/6235], Loss: 0.0558\n",
      "Epoch [53/100], Step [28700/6235], Loss: 5.4129\n",
      "Epoch [53/100], Step [28800/6235], Loss: 0.5537\n",
      "Epoch [53/100], Step [28900/6235], Loss: 73.2131\n",
      "Epoch [53/100], Step [29000/6235], Loss: 9.1805\n",
      "Epoch [53/100], Step [29100/6235], Loss: 0.0538\n",
      "Epoch [53/100], Step [29200/6235], Loss: 0.4238\n",
      "Epoch [53/100], Step [29300/6235], Loss: 7.5835\n",
      "Epoch [53/100], Step [29400/6235], Loss: 0.5104\n",
      "Epoch [53/100], Step [29500/6235], Loss: 6.8324\n",
      "Epoch [53/100], Step [29600/6235], Loss: 0.3870\n",
      "Epoch [53/100], Step [29700/6235], Loss: 0.3261\n",
      "Epoch [53/100], Step [29800/6235], Loss: 1.5756\n",
      "Epoch [53/100], Step [29900/6235], Loss: 0.2994\n",
      "Epoch [53/100], Step [30000/6235], Loss: 6.9830\n",
      "Epoch [53/100], Step [30100/6235], Loss: 0.0667\n",
      "Epoch [53/100], Step [30200/6235], Loss: 0.2014\n",
      "Epoch [53/100], Step [30300/6235], Loss: 0.4543\n",
      "Epoch [53/100], Step [30400/6235], Loss: 0.3873\n",
      "Epoch [53/100], Step [30500/6235], Loss: 2.5058\n",
      "Epoch [53/100], Step [30600/6235], Loss: 1.0375\n",
      "Epoch [53/100], Step [30700/6235], Loss: 0.0129\n",
      "Epoch [53/100], Step [30800/6235], Loss: 0.3273\n",
      "Epoch [53/100], Step [30900/6235], Loss: 3.7031\n",
      "Epoch [53/100], Step [31000/6235], Loss: 0.0213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Step [31100/6235], Loss: 0.0400\n",
      "Epoch [53/100], Step [31200/6235], Loss: 6.6491\n",
      "Epoch [53/100], Step [31300/6235], Loss: 5.1582\n",
      "Epoch [53/100], Step [31400/6235], Loss: 0.7045\n",
      "Epoch [53/100], Step [31500/6235], Loss: 0.6958\n",
      "Epoch [53/100], Step [31600/6235], Loss: 0.3473\n",
      "Epoch [53/100], Step [31700/6235], Loss: 1.3465\n",
      "Epoch [53/100], Step [31800/6235], Loss: 6.0001\n",
      "Epoch [53/100], Step [31900/6235], Loss: 153.2237\n",
      "Epoch [53/100], Step [32000/6235], Loss: 33.7510\n",
      "Epoch [53/100], Step [32100/6235], Loss: 7.9844\n",
      "Epoch [53/100], Step [32200/6235], Loss: 63.0132\n",
      "Epoch [53/100], Step [32300/6235], Loss: 1.4098\n",
      "Epoch [53/100], Step [32400/6235], Loss: 1.4611\n",
      "Epoch [53/100], Step [32500/6235], Loss: 15.7253\n",
      "Epoch [53/100], Step [32600/6235], Loss: 0.5214\n",
      "Epoch [53/100], Step [32700/6235], Loss: 94.8384\n",
      "Epoch [53/100], Step [32800/6235], Loss: 0.5184\n",
      "Epoch [53/100], Step [32900/6235], Loss: 3.2486\n",
      "Epoch [53/100], Step [33000/6235], Loss: 0.4353\n",
      "Epoch [53/100], Step [33100/6235], Loss: 1.0762\n",
      "Epoch [53/100], Step [33200/6235], Loss: 1.4202\n",
      "Epoch [53/100], Step [33300/6235], Loss: 4.0951\n",
      "Epoch [53/100], Step [33400/6235], Loss: 10.3535\n",
      "Epoch [53/100], Step [33500/6235], Loss: 0.4361\n",
      "Epoch [53/100], Step [33600/6235], Loss: 10.0104\n",
      "Epoch [53/100], Step [33700/6235], Loss: 12.8622\n",
      "Epoch [53/100], Step [33800/6235], Loss: 0.5853\n",
      "Epoch [53/100], Step [33900/6235], Loss: 27.9568\n",
      "Epoch [53/100], Step [34000/6235], Loss: 0.1194\n",
      "Epoch [53/100], Step [34100/6235], Loss: 0.6748\n",
      "Epoch [53/100], Step [34200/6235], Loss: 2.6864\n",
      "Epoch [53/100], Step [34300/6235], Loss: 2.7911\n",
      "Epoch [53/100], Step [34400/6235], Loss: 0.1895\n",
      "Epoch [53/100], Step [34500/6235], Loss: 26.7139\n",
      "Epoch [53/100], Step [34600/6235], Loss: 0.6939\n",
      "Epoch [53/100], Step [34700/6235], Loss: 23.9595\n",
      "Epoch [53/100], Step [34800/6235], Loss: 9.0306\n",
      "Epoch [53/100], Step [34900/6235], Loss: 67.9420\n",
      "Epoch [53/100], Step [35000/6235], Loss: 0.2523\n",
      "Epoch [53/100], Step [35100/6235], Loss: 0.6154\n",
      "Epoch [53/100], Step [35200/6235], Loss: 0.3196\n",
      "Epoch [53/100], Step [35300/6235], Loss: 2.8507\n",
      "Epoch [53/100], Step [35400/6235], Loss: 0.5984\n",
      "Epoch [53/100], Step [35500/6235], Loss: 1.5478\n",
      "Epoch [53/100], Step [35600/6235], Loss: 2.2328\n",
      "Epoch [53/100], Step [35700/6235], Loss: 4.5802\n",
      "Epoch [53/100], Step [35800/6235], Loss: 1.8037\n",
      "Epoch [53/100], Step [35900/6235], Loss: 0.6040\n",
      "Epoch [53/100], Step [36000/6235], Loss: 0.4069\n",
      "Epoch [53/100], Step [36100/6235], Loss: 0.1308\n",
      "Epoch [53/100], Step [36200/6235], Loss: 13.7449\n",
      "Epoch [53/100], Step [36300/6235], Loss: 0.5965\n",
      "Epoch [53/100], Step [36400/6235], Loss: 2.8819\n",
      "Epoch [53/100], Step [36500/6235], Loss: 8.0798\n",
      "Epoch [53/100], Step [36600/6235], Loss: 0.0996\n",
      "Epoch [53/100], Step [36700/6235], Loss: 0.6061\n",
      "Epoch [53/100], Step [36800/6235], Loss: 6.5979\n",
      "Epoch [53/100], Step [36900/6235], Loss: 6.0598\n",
      "Epoch [53/100], Step [37000/6235], Loss: 0.8771\n",
      "Epoch [53/100], Step [37100/6235], Loss: 1.7614\n",
      "Epoch [53/100], Step [37200/6235], Loss: 0.0505\n",
      "Epoch [53/100], Step [37300/6235], Loss: 0.0326\n",
      "Epoch [53/100], Step [37400/6235], Loss: 0.1821\n",
      "Epoch [53/100], Step [37500/6235], Loss: 6.6589\n",
      "Epoch [53/100], Step [37600/6235], Loss: 12.2526\n",
      "Epoch [53/100], Step [37700/6235], Loss: 2.4403\n",
      "Epoch [53/100], Step [37800/6235], Loss: 5.7558\n",
      "Epoch [53/100], Step [37900/6235], Loss: 5.5317\n",
      "Epoch [53/100], Step [38000/6235], Loss: 1.0461\n",
      "Epoch [53/100], Step [38100/6235], Loss: 4.6969\n",
      "Epoch [53/100], Step [38200/6235], Loss: 2.0688\n",
      "Epoch [53/100], Step [38300/6235], Loss: 0.2693\n",
      "Epoch [53/100], Step [38400/6235], Loss: 0.0482\n",
      "Epoch [53/100], Step [38500/6235], Loss: 1.4898\n",
      "Epoch [53/100], Step [38600/6235], Loss: 0.4198\n",
      "Epoch [53/100], Step [38700/6235], Loss: 0.3908\n",
      "Epoch [53/100], Step [38800/6235], Loss: 0.1431\n",
      "Epoch [53/100], Step [38900/6235], Loss: 6.6781\n",
      "Epoch [53/100], Step [39000/6235], Loss: 14.9699\n",
      "Epoch [53/100], Step [39100/6235], Loss: 18.7754\n",
      "Epoch [53/100], Step [39200/6235], Loss: 0.1656\n",
      "Epoch [53/100], Step [39300/6235], Loss: 14.6635\n",
      "Epoch [53/100], Step [39400/6235], Loss: 98.9138\n",
      "Epoch [53/100], Step [39500/6235], Loss: 179.7484\n",
      "Epoch [53/100], Step [39600/6235], Loss: 8.8430\n",
      "Epoch [53/100], Step [39700/6235], Loss: 373.9628\n",
      "Epoch [53/100], Step [39800/6235], Loss: 106.4329\n",
      "Epoch [53/100], Step [39900/6235], Loss: 0.2294\n",
      "Epoch [53/100], Step [40000/6235], Loss: 17.1882\n",
      "Epoch [53/100], Step [40100/6235], Loss: 20.0039\n",
      "Epoch [53/100], Step [40200/6235], Loss: 2.1753\n",
      "Epoch [53/100], Step [40300/6235], Loss: 1.4242\n",
      "Epoch [53/100], Step [40400/6235], Loss: 0.9114\n",
      "Epoch [53/100], Step [40500/6235], Loss: 2.7592\n",
      "Epoch [53/100], Step [40600/6235], Loss: 0.2155\n",
      "Epoch [53/100], Step [40700/6235], Loss: 6.9847\n",
      "Epoch [53/100], Step [40800/6235], Loss: 0.4923\n",
      "Epoch [53/100], Step [40900/6235], Loss: 0.7724\n",
      "Epoch [53/100], Step [41000/6235], Loss: 46.7281\n",
      "Epoch [53/100], Step [41100/6235], Loss: 1.1040\n",
      "Epoch [53/100], Step [41200/6235], Loss: 26.0779\n",
      "Epoch [53/100], Step [41300/6235], Loss: 3.2862\n",
      "Epoch [53/100], Step [41400/6235], Loss: 0.0157\n",
      "Epoch [53/100], Step [41500/6235], Loss: 3.5248\n",
      "Epoch [53/100], Step [41600/6235], Loss: 1.3853\n",
      "Epoch [53/100], Step [41700/6235], Loss: 0.1107\n",
      "Epoch [53/100], Step [41800/6235], Loss: 0.7212\n",
      "Epoch [53/100], Step [41900/6235], Loss: 4.6036\n",
      "Epoch [53/100], Step [42000/6235], Loss: 4.5922\n",
      "Epoch [53/100], Step [42100/6235], Loss: 11.6827\n",
      "Epoch [53/100], Step [42200/6235], Loss: 54.5465\n",
      "Epoch [53/100], Step [42300/6235], Loss: 0.7030\n",
      "Epoch [53/100], Step [42400/6235], Loss: 3.7354\n",
      "Epoch [53/100], Step [42500/6235], Loss: 1.5823\n",
      "Epoch [53/100], Step [42600/6235], Loss: 1.1059\n",
      "Epoch [53/100], Step [42700/6235], Loss: 0.6332\n",
      "Epoch [53/100], Step [42800/6235], Loss: 12.4097\n",
      "Epoch [53/100], Step [42900/6235], Loss: 1.2107\n",
      "Epoch [53/100], Step [43000/6235], Loss: 0.1786\n",
      "Epoch [53/100], Step [43100/6235], Loss: 0.0166\n",
      "Epoch [53/100], Step [43200/6235], Loss: 0.7432\n",
      "Epoch [53/100], Step [43300/6235], Loss: 6.9912\n",
      "Epoch [53/100], Step [43400/6235], Loss: 8.7950\n",
      "Epoch [53/100], Step [43500/6235], Loss: 9.9852\n",
      "Epoch [53/100], Step [43600/6235], Loss: 6.3620\n",
      "Epoch [53/100], Step [43700/6235], Loss: 50.5329\n",
      "Epoch [53/100], Step [43800/6235], Loss: 0.4367\n",
      "Epoch [53/100], Step [43900/6235], Loss: 1.1593\n",
      "Epoch [53/100], Step [44000/6235], Loss: 60.3002\n",
      "Epoch [53/100], Step [44100/6235], Loss: 2.9731\n",
      "Epoch [53/100], Step [44200/6235], Loss: 3.6212\n",
      "Epoch [53/100], Step [44300/6235], Loss: 28.5824\n",
      "Epoch [53/100], Step [44400/6235], Loss: 1.6963\n",
      "Epoch [53/100], Step [44500/6235], Loss: 1.6913\n",
      "Epoch [53/100], Step [44600/6235], Loss: 27.1038\n",
      "Epoch [53/100], Step [44700/6235], Loss: 2.0583\n",
      "Epoch [53/100], Step [44800/6235], Loss: 5.1934\n",
      "Epoch [53/100], Step [44900/6235], Loss: 5.5014\n",
      "Epoch [53/100], Step [45000/6235], Loss: 4.9186\n",
      "Epoch [53/100], Step [45100/6235], Loss: 54.2679\n",
      "Epoch [53/100], Step [45200/6235], Loss: 0.8858\n",
      "Epoch [53/100], Step [45300/6235], Loss: 30.5520\n",
      "Epoch [53/100], Step [45400/6235], Loss: 11.8261\n",
      "Epoch [53/100], Step [45500/6235], Loss: 0.3269\n",
      "Epoch [53/100], Step [45600/6235], Loss: 0.2269\n",
      "Epoch [53/100], Step [45700/6235], Loss: 68.7402\n",
      "Epoch [53/100], Step [45800/6235], Loss: 283.4776\n",
      "Epoch [53/100], Step [45900/6235], Loss: 7.9523\n",
      "Epoch [53/100], Step [46000/6235], Loss: 3.1842\n",
      "Epoch [53/100], Step [46100/6235], Loss: 12.4494\n",
      "Epoch [53/100], Step [46200/6235], Loss: 20.8154\n",
      "Epoch [53/100], Step [46300/6235], Loss: 3.3088\n",
      "Epoch [53/100], Step [46400/6235], Loss: 7.2883\n",
      "Epoch [53/100], Step [46500/6235], Loss: 20.7797\n",
      "Epoch [53/100], Step [46600/6235], Loss: 5.6006\n",
      "Epoch [53/100], Step [46700/6235], Loss: 5.5380\n",
      "Epoch [53/100], Step [46800/6235], Loss: 14.0372\n",
      "Epoch [53/100], Step [46900/6235], Loss: 13.7630\n",
      "Epoch [53/100], Step [47000/6235], Loss: 1.8488\n",
      "Epoch [53/100], Step [47100/6235], Loss: 21.4349\n",
      "Epoch [53/100], Step [47200/6235], Loss: 39.3545\n",
      "Epoch [53/100], Step [47300/6235], Loss: 0.8850\n",
      "Epoch [53/100], Step [47400/6235], Loss: 59.2295\n",
      "Epoch [53/100], Step [47500/6235], Loss: 4.1742\n",
      "Epoch [53/100], Step [47600/6235], Loss: 6.3892\n",
      "Epoch [53/100], Step [47700/6235], Loss: 5.8753\n",
      "Epoch [53/100], Step [47800/6235], Loss: 6.1121\n",
      "Epoch [53/100], Step [47900/6235], Loss: 22.0257\n",
      "Epoch [53/100], Step [48000/6235], Loss: 20.3185\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [53/100], Step [48100/6235], Loss: 4.2471\n",
      "Epoch [53/100], Step [48200/6235], Loss: 14.7389\n",
      "Epoch [53/100], Step [48300/6235], Loss: 252.2936\n",
      "Epoch [53/100], Step [48400/6235], Loss: 17.9551\n",
      "Epoch [53/100], Step [48500/6235], Loss: 22.7902\n",
      "Epoch [53/100], Step [48600/6235], Loss: 163.9563\n",
      "Epoch [53/100], Step [48700/6235], Loss: 12.3003\n",
      "Epoch [53/100], Step [48800/6235], Loss: 329.2791\n",
      "Epoch [53/100], Step [48900/6235], Loss: 114.2960\n",
      "Epoch [53/100], Step [49000/6235], Loss: 189.7578\n",
      "Epoch [53/100], Step [49100/6235], Loss: 2618.9658\n",
      "Epoch [53/100], Step [49200/6235], Loss: 13.2325\n",
      "Epoch [53/100], Step [49300/6235], Loss: 1215.6075\n",
      "Epoch [53/100], Step [49400/6235], Loss: 2.4093\n",
      "Epoch [53/100], Step [49500/6235], Loss: 8.1100\n",
      "Epoch [53/100], Step [49600/6235], Loss: 326.5819\n",
      "Epoch [53/100], Step [49700/6235], Loss: 968.4569\n",
      "Epoch [53/100], Step [49800/6235], Loss: 1234.0443\n",
      "Epoch [54/100], Step [100/6235], Loss: 3.3822\n",
      "Epoch [54/100], Step [200/6235], Loss: 0.9537\n",
      "Epoch [54/100], Step [300/6235], Loss: 0.0330\n",
      "Epoch [54/100], Step [400/6235], Loss: 0.0120\n",
      "Epoch [54/100], Step [500/6235], Loss: 1.7754\n",
      "Epoch [54/100], Step [600/6235], Loss: 0.0343\n",
      "Epoch [54/100], Step [700/6235], Loss: 0.4928\n",
      "Epoch [54/100], Step [800/6235], Loss: 0.1366\n",
      "Epoch [54/100], Step [900/6235], Loss: 0.0749\n",
      "Epoch [54/100], Step [1000/6235], Loss: 0.0367\n",
      "Epoch [54/100], Step [1100/6235], Loss: 0.1575\n",
      "Epoch [54/100], Step [1200/6235], Loss: 0.1832\n",
      "Epoch [54/100], Step [1300/6235], Loss: 0.0464\n",
      "Epoch [54/100], Step [1400/6235], Loss: 0.2247\n",
      "Epoch [54/100], Step [1500/6235], Loss: 0.0085\n",
      "Epoch [54/100], Step [1600/6235], Loss: 0.2266\n",
      "Epoch [54/100], Step [1700/6235], Loss: 0.0360\n",
      "Epoch [54/100], Step [1800/6235], Loss: 0.1997\n",
      "Epoch [54/100], Step [1900/6235], Loss: 0.4277\n",
      "Epoch [54/100], Step [2000/6235], Loss: 2.2571\n",
      "Epoch [54/100], Step [2100/6235], Loss: 2.6854\n",
      "Epoch [54/100], Step [2200/6235], Loss: 8.4212\n",
      "Epoch [54/100], Step [2300/6235], Loss: 8.3472\n",
      "Epoch [54/100], Step [2400/6235], Loss: 2.2457\n",
      "Epoch [54/100], Step [2500/6235], Loss: 31.6641\n",
      "Epoch [54/100], Step [2600/6235], Loss: 12.4794\n",
      "Epoch [54/100], Step [2700/6235], Loss: 6.9452\n",
      "Epoch [54/100], Step [2800/6235], Loss: 368.9516\n",
      "Epoch [54/100], Step [2900/6235], Loss: 15.9039\n",
      "Epoch [54/100], Step [3000/6235], Loss: 1.7760\n",
      "Epoch [54/100], Step [3100/6235], Loss: 67.6138\n",
      "Epoch [54/100], Step [3200/6235], Loss: 67.7336\n",
      "Epoch [54/100], Step [3300/6235], Loss: 10.6150\n",
      "Epoch [54/100], Step [3400/6235], Loss: 1.7758\n",
      "Epoch [54/100], Step [3500/6235], Loss: 40.0308\n",
      "Epoch [54/100], Step [3600/6235], Loss: 5.8612\n",
      "Epoch [54/100], Step [3700/6235], Loss: 0.0110\n",
      "Epoch [54/100], Step [3800/6235], Loss: 0.0565\n",
      "Epoch [54/100], Step [3900/6235], Loss: 0.1537\n",
      "Epoch [54/100], Step [4000/6235], Loss: 0.0558\n",
      "Epoch [54/100], Step [4100/6235], Loss: 8.2424\n",
      "Epoch [54/100], Step [4200/6235], Loss: 1.3839\n",
      "Epoch [54/100], Step [4300/6235], Loss: 6.7696\n",
      "Epoch [54/100], Step [4400/6235], Loss: 1.7215\n",
      "Epoch [54/100], Step [4500/6235], Loss: 45.5689\n",
      "Epoch [54/100], Step [4600/6235], Loss: 1.8668\n",
      "Epoch [54/100], Step [4700/6235], Loss: 0.3151\n",
      "Epoch [54/100], Step [4800/6235], Loss: 10.4916\n",
      "Epoch [54/100], Step [4900/6235], Loss: 0.1311\n",
      "Epoch [54/100], Step [5000/6235], Loss: 0.1442\n",
      "Epoch [54/100], Step [5100/6235], Loss: 0.8952\n",
      "Epoch [54/100], Step [5200/6235], Loss: 1.3232\n",
      "Epoch [54/100], Step [5300/6235], Loss: 41.2716\n",
      "Epoch [54/100], Step [5400/6235], Loss: 1.3063\n",
      "Epoch [54/100], Step [5500/6235], Loss: 0.1015\n",
      "Epoch [54/100], Step [5600/6235], Loss: 0.2748\n",
      "Epoch [54/100], Step [5700/6235], Loss: 0.2248\n",
      "Epoch [54/100], Step [5800/6235], Loss: 0.6165\n",
      "Epoch [54/100], Step [5900/6235], Loss: 0.0890\n",
      "Epoch [54/100], Step [6000/6235], Loss: 2.5891\n",
      "Epoch [54/100], Step [6100/6235], Loss: 0.0787\n",
      "Epoch [54/100], Step [6200/6235], Loss: 3.7088\n",
      "Epoch [54/100], Step [6300/6235], Loss: 0.2240\n",
      "Epoch [54/100], Step [6400/6235], Loss: 0.0388\n",
      "Epoch [54/100], Step [6500/6235], Loss: 4.3992\n",
      "Epoch [54/100], Step [6600/6235], Loss: 16.8602\n",
      "Epoch [54/100], Step [6700/6235], Loss: 2.5643\n",
      "Epoch [54/100], Step [6800/6235], Loss: 0.3202\n",
      "Epoch [54/100], Step [6900/6235], Loss: 1.0807\n",
      "Epoch [54/100], Step [7000/6235], Loss: 0.0210\n",
      "Epoch [54/100], Step [7100/6235], Loss: 0.3304\n",
      "Epoch [54/100], Step [7200/6235], Loss: 0.3143\n",
      "Epoch [54/100], Step [7300/6235], Loss: 0.1285\n",
      "Epoch [54/100], Step [7400/6235], Loss: 0.1300\n",
      "Epoch [54/100], Step [7500/6235], Loss: 0.1273\n",
      "Epoch [54/100], Step [7600/6235], Loss: 3.7275\n",
      "Epoch [54/100], Step [7700/6235], Loss: 14.7571\n",
      "Epoch [54/100], Step [7800/6235], Loss: 1.4600\n",
      "Epoch [54/100], Step [7900/6235], Loss: 0.7528\n",
      "Epoch [54/100], Step [8000/6235], Loss: 0.1497\n",
      "Epoch [54/100], Step [8100/6235], Loss: 1.7873\n",
      "Epoch [54/100], Step [8200/6235], Loss: 10.4745\n",
      "Epoch [54/100], Step [8300/6235], Loss: 12.2304\n",
      "Epoch [54/100], Step [8400/6235], Loss: 529.1822\n",
      "Epoch [54/100], Step [8500/6235], Loss: 13.0431\n",
      "Epoch [54/100], Step [8600/6235], Loss: 36.5307\n",
      "Epoch [54/100], Step [8700/6235], Loss: 19.0846\n",
      "Epoch [54/100], Step [8800/6235], Loss: 327.9949\n",
      "Epoch [54/100], Step [8900/6235], Loss: 6.9088\n",
      "Epoch [54/100], Step [9000/6235], Loss: 474.6227\n",
      "Epoch [54/100], Step [9100/6235], Loss: 315.4714\n",
      "Epoch [54/100], Step [9200/6235], Loss: 1022.8364\n",
      "Epoch [54/100], Step [9300/6235], Loss: 196.0539\n",
      "Epoch [54/100], Step [9400/6235], Loss: 523.4392\n",
      "Epoch [54/100], Step [9500/6235], Loss: 2373.9880\n",
      "Epoch [54/100], Step [9600/6235], Loss: 382.7976\n",
      "Epoch [54/100], Step [9700/6235], Loss: 9.4681\n",
      "Epoch [54/100], Step [9800/6235], Loss: 2549.6709\n",
      "Epoch [54/100], Step [9900/6235], Loss: 16.0800\n",
      "Epoch [54/100], Step [10000/6235], Loss: 11.1267\n",
      "Epoch [54/100], Step [10100/6235], Loss: 3.7128\n",
      "Epoch [54/100], Step [10200/6235], Loss: 771.8225\n",
      "Epoch [54/100], Step [10300/6235], Loss: 47.5496\n",
      "Epoch [54/100], Step [10400/6235], Loss: 9.0050\n",
      "Epoch [54/100], Step [10500/6235], Loss: 23.1755\n",
      "Epoch [54/100], Step [10600/6235], Loss: 252.8970\n",
      "Epoch [54/100], Step [10700/6235], Loss: 12.9938\n",
      "Epoch [54/100], Step [10800/6235], Loss: 122.4146\n",
      "Epoch [54/100], Step [10900/6235], Loss: 63.1430\n",
      "Epoch [54/100], Step [11000/6235], Loss: 299.2620\n",
      "Epoch [54/100], Step [11100/6235], Loss: 43.0460\n",
      "Epoch [54/100], Step [11200/6235], Loss: 9.5870\n",
      "Epoch [54/100], Step [11300/6235], Loss: 122.8994\n",
      "Epoch [54/100], Step [11400/6235], Loss: 9.6533\n",
      "Epoch [54/100], Step [11500/6235], Loss: 6.6076\n",
      "Epoch [54/100], Step [11600/6235], Loss: 5.7539\n",
      "Epoch [54/100], Step [11700/6235], Loss: 42.0554\n",
      "Epoch [54/100], Step [11800/6235], Loss: 2.9787\n",
      "Epoch [54/100], Step [11900/6235], Loss: 10.6057\n",
      "Epoch [54/100], Step [12000/6235], Loss: 550.2524\n",
      "Epoch [54/100], Step [12100/6235], Loss: 262.4248\n",
      "Epoch [54/100], Step [12200/6235], Loss: 39.9220\n",
      "Epoch [54/100], Step [12300/6235], Loss: 2.0364\n",
      "Epoch [54/100], Step [12400/6235], Loss: 266.5826\n",
      "Epoch [54/100], Step [12500/6235], Loss: 139.2285\n",
      "Epoch [54/100], Step [12600/6235], Loss: 0.5565\n",
      "Epoch [54/100], Step [12700/6235], Loss: 4.8094\n",
      "Epoch [54/100], Step [12800/6235], Loss: 16.2059\n",
      "Epoch [54/100], Step [12900/6235], Loss: 34.9250\n",
      "Epoch [54/100], Step [13000/6235], Loss: 0.3483\n",
      "Epoch [54/100], Step [13100/6235], Loss: 65.1486\n",
      "Epoch [54/100], Step [13200/6235], Loss: 7.0556\n",
      "Epoch [54/100], Step [13300/6235], Loss: 20.7345\n",
      "Epoch [54/100], Step [13400/6235], Loss: 222.3680\n",
      "Epoch [54/100], Step [13500/6235], Loss: 0.4725\n",
      "Epoch [54/100], Step [13600/6235], Loss: 13.0477\n",
      "Epoch [54/100], Step [13700/6235], Loss: 191.3123\n",
      "Epoch [54/100], Step [13800/6235], Loss: 71.8634\n",
      "Epoch [54/100], Step [13900/6235], Loss: 2.3429\n",
      "Epoch [54/100], Step [14000/6235], Loss: 4.1997\n",
      "Epoch [54/100], Step [14100/6235], Loss: 44.1878\n",
      "Epoch [54/100], Step [14200/6235], Loss: 13.4749\n",
      "Epoch [54/100], Step [14300/6235], Loss: 4.3369\n",
      "Epoch [54/100], Step [14400/6235], Loss: 34.1612\n",
      "Epoch [54/100], Step [14500/6235], Loss: 28.6077\n",
      "Epoch [54/100], Step [14600/6235], Loss: 2.7613\n",
      "Epoch [54/100], Step [14700/6235], Loss: 23.2362\n",
      "Epoch [54/100], Step [14800/6235], Loss: 27.4763\n",
      "Epoch [54/100], Step [14900/6235], Loss: 0.7579\n",
      "Epoch [54/100], Step [15000/6235], Loss: 1.1374\n",
      "Epoch [54/100], Step [15100/6235], Loss: 0.4042\n",
      "Epoch [54/100], Step [15200/6235], Loss: 14.8366\n",
      "Epoch [54/100], Step [15300/6235], Loss: 2.6191\n",
      "Epoch [54/100], Step [15400/6235], Loss: 4.9808\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Step [15500/6235], Loss: 12.4045\n",
      "Epoch [54/100], Step [15600/6235], Loss: 4.3790\n",
      "Epoch [54/100], Step [15700/6235], Loss: 197.6788\n",
      "Epoch [54/100], Step [15800/6235], Loss: 4.4594\n",
      "Epoch [54/100], Step [15900/6235], Loss: 0.8224\n",
      "Epoch [54/100], Step [16000/6235], Loss: 132.7253\n",
      "Epoch [54/100], Step [16100/6235], Loss: 2.6213\n",
      "Epoch [54/100], Step [16200/6235], Loss: 0.9410\n",
      "Epoch [54/100], Step [16300/6235], Loss: 9.2363\n",
      "Epoch [54/100], Step [16400/6235], Loss: 20.3834\n",
      "Epoch [54/100], Step [16500/6235], Loss: 695.4977\n",
      "Epoch [54/100], Step [16600/6235], Loss: 36.4232\n",
      "Epoch [54/100], Step [16700/6235], Loss: 0.6156\n",
      "Epoch [54/100], Step [16800/6235], Loss: 9.4582\n",
      "Epoch [54/100], Step [16900/6235], Loss: 0.3878\n",
      "Epoch [54/100], Step [17000/6235], Loss: 0.2019\n",
      "Epoch [54/100], Step [17100/6235], Loss: 0.0429\n",
      "Epoch [54/100], Step [17200/6235], Loss: 259.4250\n",
      "Epoch [54/100], Step [17300/6235], Loss: 19.6338\n",
      "Epoch [54/100], Step [17400/6235], Loss: 29.4413\n",
      "Epoch [54/100], Step [17500/6235], Loss: 3.0866\n",
      "Epoch [54/100], Step [17600/6235], Loss: 2.9054\n",
      "Epoch [54/100], Step [17700/6235], Loss: 1.7450\n",
      "Epoch [54/100], Step [17800/6235], Loss: 20.4446\n",
      "Epoch [54/100], Step [17900/6235], Loss: 9.9082\n",
      "Epoch [54/100], Step [18000/6235], Loss: 8.4077\n",
      "Epoch [54/100], Step [18100/6235], Loss: 14.9448\n",
      "Epoch [54/100], Step [18200/6235], Loss: 0.2916\n",
      "Epoch [54/100], Step [18300/6235], Loss: 1.3461\n",
      "Epoch [54/100], Step [18400/6235], Loss: 0.1838\n",
      "Epoch [54/100], Step [18500/6235], Loss: 31.8673\n",
      "Epoch [54/100], Step [18600/6235], Loss: 3.7425\n",
      "Epoch [54/100], Step [18700/6235], Loss: 0.9355\n",
      "Epoch [54/100], Step [18800/6235], Loss: 147.6799\n",
      "Epoch [54/100], Step [18900/6235], Loss: 83.5644\n",
      "Epoch [54/100], Step [19000/6235], Loss: 1.4213\n",
      "Epoch [54/100], Step [19100/6235], Loss: 31.8283\n",
      "Epoch [54/100], Step [19200/6235], Loss: 1.4850\n",
      "Epoch [54/100], Step [19300/6235], Loss: 1.5135\n",
      "Epoch [54/100], Step [19400/6235], Loss: 5.1869\n",
      "Epoch [54/100], Step [19500/6235], Loss: 33.8007\n",
      "Epoch [54/100], Step [19600/6235], Loss: 34.6079\n",
      "Epoch [54/100], Step [19700/6235], Loss: 1.7069\n",
      "Epoch [54/100], Step [19800/6235], Loss: 9.4394\n",
      "Epoch [54/100], Step [19900/6235], Loss: 0.1033\n",
      "Epoch [54/100], Step [20000/6235], Loss: 67.9866\n",
      "Epoch [54/100], Step [20100/6235], Loss: 3.1995\n",
      "Epoch [54/100], Step [20200/6235], Loss: 0.8759\n",
      "Epoch [54/100], Step [20300/6235], Loss: 1.7005\n",
      "Epoch [54/100], Step [20400/6235], Loss: 10.5216\n",
      "Epoch [54/100], Step [20500/6235], Loss: 54.4418\n",
      "Epoch [54/100], Step [20600/6235], Loss: 162.0056\n",
      "Epoch [54/100], Step [20700/6235], Loss: 16.6133\n",
      "Epoch [54/100], Step [20800/6235], Loss: 6.4571\n",
      "Epoch [54/100], Step [20900/6235], Loss: 0.7665\n",
      "Epoch [54/100], Step [21000/6235], Loss: 13.2847\n",
      "Epoch [54/100], Step [21100/6235], Loss: 6.4545\n",
      "Epoch [54/100], Step [21200/6235], Loss: 0.3398\n",
      "Epoch [54/100], Step [21300/6235], Loss: 0.1063\n",
      "Epoch [54/100], Step [21400/6235], Loss: 4.9706\n",
      "Epoch [54/100], Step [21500/6235], Loss: 1.9468\n",
      "Epoch [54/100], Step [21600/6235], Loss: 32.5399\n",
      "Epoch [54/100], Step [21700/6235], Loss: 0.2288\n",
      "Epoch [54/100], Step [21800/6235], Loss: 5.5079\n",
      "Epoch [54/100], Step [21900/6235], Loss: 1.5264\n",
      "Epoch [54/100], Step [22000/6235], Loss: 7.8972\n",
      "Epoch [54/100], Step [22100/6235], Loss: 0.5620\n",
      "Epoch [54/100], Step [22200/6235], Loss: 5.9823\n",
      "Epoch [54/100], Step [22300/6235], Loss: 0.1921\n",
      "Epoch [54/100], Step [22400/6235], Loss: 4.4459\n",
      "Epoch [54/100], Step [22500/6235], Loss: 69.3447\n",
      "Epoch [54/100], Step [22600/6235], Loss: 28.1782\n",
      "Epoch [54/100], Step [22700/6235], Loss: 0.4933\n",
      "Epoch [54/100], Step [22800/6235], Loss: 3.4755\n",
      "Epoch [54/100], Step [22900/6235], Loss: 4.7099\n",
      "Epoch [54/100], Step [23000/6235], Loss: 8.0882\n",
      "Epoch [54/100], Step [23100/6235], Loss: 6.1071\n",
      "Epoch [54/100], Step [23200/6235], Loss: 6.9629\n",
      "Epoch [54/100], Step [23300/6235], Loss: 15.0000\n",
      "Epoch [54/100], Step [23400/6235], Loss: 1.3079\n",
      "Epoch [54/100], Step [23500/6235], Loss: 0.1736\n",
      "Epoch [54/100], Step [23600/6235], Loss: 120.8358\n",
      "Epoch [54/100], Step [23700/6235], Loss: 2.6397\n",
      "Epoch [54/100], Step [23800/6235], Loss: 1.0586\n",
      "Epoch [54/100], Step [23900/6235], Loss: 6.4368\n",
      "Epoch [54/100], Step [24000/6235], Loss: 0.1804\n",
      "Epoch [54/100], Step [24100/6235], Loss: 0.1698\n",
      "Epoch [54/100], Step [24200/6235], Loss: 43.9901\n",
      "Epoch [54/100], Step [24300/6235], Loss: 1.5945\n",
      "Epoch [54/100], Step [24400/6235], Loss: 1.9927\n",
      "Epoch [54/100], Step [24500/6235], Loss: 0.7826\n",
      "Epoch [54/100], Step [24600/6235], Loss: 0.0923\n",
      "Epoch [54/100], Step [24700/6235], Loss: 0.2626\n",
      "Epoch [54/100], Step [24800/6235], Loss: 0.2127\n",
      "Epoch [54/100], Step [24900/6235], Loss: 17.7960\n",
      "Epoch [54/100], Step [25000/6235], Loss: 18.6229\n",
      "Epoch [54/100], Step [25100/6235], Loss: 7.6845\n",
      "Epoch [54/100], Step [25200/6235], Loss: 0.7401\n",
      "Epoch [54/100], Step [25300/6235], Loss: 0.6345\n",
      "Epoch [54/100], Step [25400/6235], Loss: 6.4526\n",
      "Epoch [54/100], Step [25500/6235], Loss: 7.2110\n",
      "Epoch [54/100], Step [25600/6235], Loss: 4.4298\n",
      "Epoch [54/100], Step [25700/6235], Loss: 0.3750\n",
      "Epoch [54/100], Step [25800/6235], Loss: 0.1597\n",
      "Epoch [54/100], Step [25900/6235], Loss: 8.9551\n",
      "Epoch [54/100], Step [26000/6235], Loss: 1.1582\n",
      "Epoch [54/100], Step [26100/6235], Loss: 0.2458\n",
      "Epoch [54/100], Step [26200/6235], Loss: 0.8027\n",
      "Epoch [54/100], Step [26300/6235], Loss: 3.9143\n",
      "Epoch [54/100], Step [26400/6235], Loss: 0.0952\n",
      "Epoch [54/100], Step [26500/6235], Loss: 0.0155\n",
      "Epoch [54/100], Step [26600/6235], Loss: 1.5819\n",
      "Epoch [54/100], Step [26700/6235], Loss: 0.3671\n",
      "Epoch [54/100], Step [26800/6235], Loss: 0.1926\n",
      "Epoch [54/100], Step [26900/6235], Loss: 0.0012\n",
      "Epoch [54/100], Step [27000/6235], Loss: 14.9608\n",
      "Epoch [54/100], Step [27100/6235], Loss: 0.0515\n",
      "Epoch [54/100], Step [27200/6235], Loss: 0.0261\n",
      "Epoch [54/100], Step [27300/6235], Loss: 0.2263\n",
      "Epoch [54/100], Step [27400/6235], Loss: 0.7666\n",
      "Epoch [54/100], Step [27500/6235], Loss: 8.9480\n",
      "Epoch [54/100], Step [27600/6235], Loss: 0.6207\n",
      "Epoch [54/100], Step [27700/6235], Loss: 1.0065\n",
      "Epoch [54/100], Step [27800/6235], Loss: 4.2763\n",
      "Epoch [54/100], Step [27900/6235], Loss: 0.2000\n",
      "Epoch [54/100], Step [28000/6235], Loss: 84.0813\n",
      "Epoch [54/100], Step [28100/6235], Loss: 4.6059\n",
      "Epoch [54/100], Step [28200/6235], Loss: 29.2339\n",
      "Epoch [54/100], Step [28300/6235], Loss: 1.9164\n",
      "Epoch [54/100], Step [28400/6235], Loss: 27.7588\n",
      "Epoch [54/100], Step [28500/6235], Loss: 4.2566\n",
      "Epoch [54/100], Step [28600/6235], Loss: 0.3430\n",
      "Epoch [54/100], Step [28700/6235], Loss: 5.0199\n",
      "Epoch [54/100], Step [28800/6235], Loss: 0.6505\n",
      "Epoch [54/100], Step [28900/6235], Loss: 66.5452\n",
      "Epoch [54/100], Step [29000/6235], Loss: 6.7393\n",
      "Epoch [54/100], Step [29100/6235], Loss: 0.3812\n",
      "Epoch [54/100], Step [29200/6235], Loss: 2.1781\n",
      "Epoch [54/100], Step [29300/6235], Loss: 16.6727\n",
      "Epoch [54/100], Step [29400/6235], Loss: 1.1192\n",
      "Epoch [54/100], Step [29500/6235], Loss: 1.4086\n",
      "Epoch [54/100], Step [29600/6235], Loss: 0.6718\n",
      "Epoch [54/100], Step [29700/6235], Loss: 1.6858\n",
      "Epoch [54/100], Step [29800/6235], Loss: 1.4594\n",
      "Epoch [54/100], Step [29900/6235], Loss: 1.4668\n",
      "Epoch [54/100], Step [30000/6235], Loss: 5.7240\n",
      "Epoch [54/100], Step [30100/6235], Loss: 10.0503\n",
      "Epoch [54/100], Step [30200/6235], Loss: 1.3523\n",
      "Epoch [54/100], Step [30300/6235], Loss: 0.0395\n",
      "Epoch [54/100], Step [30400/6235], Loss: 1.3623\n",
      "Epoch [54/100], Step [30500/6235], Loss: 2.7308\n",
      "Epoch [54/100], Step [30600/6235], Loss: 1.8712\n",
      "Epoch [54/100], Step [30700/6235], Loss: 1.0657\n",
      "Epoch [54/100], Step [30800/6235], Loss: 0.5566\n",
      "Epoch [54/100], Step [30900/6235], Loss: 3.1842\n",
      "Epoch [54/100], Step [31000/6235], Loss: 0.2823\n",
      "Epoch [54/100], Step [31100/6235], Loss: 0.0630\n",
      "Epoch [54/100], Step [31200/6235], Loss: 4.5300\n",
      "Epoch [54/100], Step [31300/6235], Loss: 0.9688\n",
      "Epoch [54/100], Step [31400/6235], Loss: 0.2135\n",
      "Epoch [54/100], Step [31500/6235], Loss: 0.7713\n",
      "Epoch [54/100], Step [31600/6235], Loss: 5.2830\n",
      "Epoch [54/100], Step [31700/6235], Loss: 0.9073\n",
      "Epoch [54/100], Step [31800/6235], Loss: 1.5517\n",
      "Epoch [54/100], Step [31900/6235], Loss: 207.6490\n",
      "Epoch [54/100], Step [32000/6235], Loss: 16.4366\n",
      "Epoch [54/100], Step [32100/6235], Loss: 0.3735\n",
      "Epoch [54/100], Step [32200/6235], Loss: 148.8866\n",
      "Epoch [54/100], Step [32300/6235], Loss: 0.1074\n",
      "Epoch [54/100], Step [32400/6235], Loss: 0.7885\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Step [32500/6235], Loss: 4.3912\n",
      "Epoch [54/100], Step [32600/6235], Loss: 0.1006\n",
      "Epoch [54/100], Step [32700/6235], Loss: 189.4092\n",
      "Epoch [54/100], Step [32800/6235], Loss: 7.0923\n",
      "Epoch [54/100], Step [32900/6235], Loss: 0.6386\n",
      "Epoch [54/100], Step [33000/6235], Loss: 1.0374\n",
      "Epoch [54/100], Step [33100/6235], Loss: 0.9156\n",
      "Epoch [54/100], Step [33200/6235], Loss: 1.3651\n",
      "Epoch [54/100], Step [33300/6235], Loss: 1.9902\n",
      "Epoch [54/100], Step [33400/6235], Loss: 4.5775\n",
      "Epoch [54/100], Step [33500/6235], Loss: 2.5317\n",
      "Epoch [54/100], Step [33600/6235], Loss: 7.8943\n",
      "Epoch [54/100], Step [33700/6235], Loss: 7.1906\n",
      "Epoch [54/100], Step [33800/6235], Loss: 0.2623\n",
      "Epoch [54/100], Step [33900/6235], Loss: 28.5141\n",
      "Epoch [54/100], Step [34000/6235], Loss: 0.1482\n",
      "Epoch [54/100], Step [34100/6235], Loss: 0.7462\n",
      "Epoch [54/100], Step [34200/6235], Loss: 2.4406\n",
      "Epoch [54/100], Step [34300/6235], Loss: 2.4973\n",
      "Epoch [54/100], Step [34400/6235], Loss: 0.0977\n",
      "Epoch [54/100], Step [34500/6235], Loss: 17.9629\n",
      "Epoch [54/100], Step [34600/6235], Loss: 1.7180\n",
      "Epoch [54/100], Step [34700/6235], Loss: 20.3284\n",
      "Epoch [54/100], Step [34800/6235], Loss: 12.3975\n",
      "Epoch [54/100], Step [34900/6235], Loss: 67.7955\n",
      "Epoch [54/100], Step [35000/6235], Loss: 0.2451\n",
      "Epoch [54/100], Step [35100/6235], Loss: 1.1229\n",
      "Epoch [54/100], Step [35200/6235], Loss: 0.6166\n",
      "Epoch [54/100], Step [35300/6235], Loss: 3.1133\n",
      "Epoch [54/100], Step [35400/6235], Loss: 0.5464\n",
      "Epoch [54/100], Step [35500/6235], Loss: 0.4797\n",
      "Epoch [54/100], Step [35600/6235], Loss: 4.4229\n",
      "Epoch [54/100], Step [35700/6235], Loss: 4.3610\n",
      "Epoch [54/100], Step [35800/6235], Loss: 1.9633\n",
      "Epoch [54/100], Step [35900/6235], Loss: 0.2038\n",
      "Epoch [54/100], Step [36000/6235], Loss: 0.0153\n",
      "Epoch [54/100], Step [36100/6235], Loss: 0.0232\n",
      "Epoch [54/100], Step [36200/6235], Loss: 32.4174\n",
      "Epoch [54/100], Step [36300/6235], Loss: 0.9801\n",
      "Epoch [54/100], Step [36400/6235], Loss: 2.7320\n",
      "Epoch [54/100], Step [36500/6235], Loss: 7.5483\n",
      "Epoch [54/100], Step [36600/6235], Loss: 0.0803\n",
      "Epoch [54/100], Step [36700/6235], Loss: 0.6109\n",
      "Epoch [54/100], Step [36800/6235], Loss: 4.6807\n",
      "Epoch [54/100], Step [36900/6235], Loss: 10.6154\n",
      "Epoch [54/100], Step [37000/6235], Loss: 0.9383\n",
      "Epoch [54/100], Step [37100/6235], Loss: 1.9424\n",
      "Epoch [54/100], Step [37200/6235], Loss: 0.0405\n",
      "Epoch [54/100], Step [37300/6235], Loss: 0.0425\n",
      "Epoch [54/100], Step [37400/6235], Loss: 0.1699\n",
      "Epoch [54/100], Step [37500/6235], Loss: 6.9592\n",
      "Epoch [54/100], Step [37600/6235], Loss: 12.2464\n",
      "Epoch [54/100], Step [37700/6235], Loss: 1.5083\n",
      "Epoch [54/100], Step [37800/6235], Loss: 5.2239\n",
      "Epoch [54/100], Step [37900/6235], Loss: 5.7874\n",
      "Epoch [54/100], Step [38000/6235], Loss: 0.8638\n",
      "Epoch [54/100], Step [38100/6235], Loss: 3.6942\n",
      "Epoch [54/100], Step [38200/6235], Loss: 1.6939\n",
      "Epoch [54/100], Step [38300/6235], Loss: 0.2208\n",
      "Epoch [54/100], Step [38400/6235], Loss: 0.0539\n",
      "Epoch [54/100], Step [38500/6235], Loss: 1.5245\n",
      "Epoch [54/100], Step [38600/6235], Loss: 0.4129\n",
      "Epoch [54/100], Step [38700/6235], Loss: 0.0595\n",
      "Epoch [54/100], Step [38800/6235], Loss: 0.1269\n",
      "Epoch [54/100], Step [38900/6235], Loss: 4.0955\n",
      "Epoch [54/100], Step [39000/6235], Loss: 13.0799\n",
      "Epoch [54/100], Step [39100/6235], Loss: 20.3318\n",
      "Epoch [54/100], Step [39200/6235], Loss: 0.4929\n",
      "Epoch [54/100], Step [39300/6235], Loss: 20.4362\n",
      "Epoch [54/100], Step [39400/6235], Loss: 92.8070\n",
      "Epoch [54/100], Step [39500/6235], Loss: 101.3889\n",
      "Epoch [54/100], Step [39600/6235], Loss: 10.4817\n",
      "Epoch [54/100], Step [39700/6235], Loss: 76.1684\n",
      "Epoch [54/100], Step [39800/6235], Loss: 152.4029\n",
      "Epoch [54/100], Step [39900/6235], Loss: 39.0772\n",
      "Epoch [54/100], Step [40000/6235], Loss: 14.0433\n",
      "Epoch [54/100], Step [40100/6235], Loss: 22.9668\n",
      "Epoch [54/100], Step [40200/6235], Loss: 0.5235\n",
      "Epoch [54/100], Step [40300/6235], Loss: 1.1427\n",
      "Epoch [54/100], Step [40400/6235], Loss: 2.0741\n",
      "Epoch [54/100], Step [40500/6235], Loss: 2.4665\n",
      "Epoch [54/100], Step [40600/6235], Loss: 0.2385\n",
      "Epoch [54/100], Step [40700/6235], Loss: 7.5279\n",
      "Epoch [54/100], Step [40800/6235], Loss: 1.1142\n",
      "Epoch [54/100], Step [40900/6235], Loss: 0.2123\n",
      "Epoch [54/100], Step [41000/6235], Loss: 47.1300\n",
      "Epoch [54/100], Step [41100/6235], Loss: 18.7718\n",
      "Epoch [54/100], Step [41200/6235], Loss: 7.5861\n",
      "Epoch [54/100], Step [41300/6235], Loss: 2.6310\n",
      "Epoch [54/100], Step [41400/6235], Loss: 2.1478\n",
      "Epoch [54/100], Step [41500/6235], Loss: 0.4434\n",
      "Epoch [54/100], Step [41600/6235], Loss: 0.5311\n",
      "Epoch [54/100], Step [41700/6235], Loss: 3.3019\n",
      "Epoch [54/100], Step [41800/6235], Loss: 3.9525\n",
      "Epoch [54/100], Step [41900/6235], Loss: 2.8931\n",
      "Epoch [54/100], Step [42000/6235], Loss: 2.7832\n",
      "Epoch [54/100], Step [42100/6235], Loss: 5.9321\n",
      "Epoch [54/100], Step [42200/6235], Loss: 2.9972\n",
      "Epoch [54/100], Step [42300/6235], Loss: 0.6104\n",
      "Epoch [54/100], Step [42400/6235], Loss: 1.9923\n",
      "Epoch [54/100], Step [42500/6235], Loss: 1.6879\n",
      "Epoch [54/100], Step [42600/6235], Loss: 0.5464\n",
      "Epoch [54/100], Step [42700/6235], Loss: 0.2455\n",
      "Epoch [54/100], Step [42800/6235], Loss: 1.5246\n",
      "Epoch [54/100], Step [42900/6235], Loss: 4.3043\n",
      "Epoch [54/100], Step [43000/6235], Loss: 0.2383\n",
      "Epoch [54/100], Step [43100/6235], Loss: 1.0427\n",
      "Epoch [54/100], Step [43200/6235], Loss: 0.7343\n",
      "Epoch [54/100], Step [43300/6235], Loss: 9.6636\n",
      "Epoch [54/100], Step [43400/6235], Loss: 7.7905\n",
      "Epoch [54/100], Step [43500/6235], Loss: 8.3243\n",
      "Epoch [54/100], Step [43600/6235], Loss: 27.1472\n",
      "Epoch [54/100], Step [43700/6235], Loss: 32.8619\n",
      "Epoch [54/100], Step [43800/6235], Loss: 0.2781\n",
      "Epoch [54/100], Step [43900/6235], Loss: 1.1760\n",
      "Epoch [54/100], Step [44000/6235], Loss: 52.9354\n",
      "Epoch [54/100], Step [44100/6235], Loss: 0.8298\n",
      "Epoch [54/100], Step [44200/6235], Loss: 12.0987\n",
      "Epoch [54/100], Step [44300/6235], Loss: 31.4377\n",
      "Epoch [54/100], Step [44400/6235], Loss: 3.4354\n",
      "Epoch [54/100], Step [44500/6235], Loss: 2.2765\n",
      "Epoch [54/100], Step [44600/6235], Loss: 11.3278\n",
      "Epoch [54/100], Step [44700/6235], Loss: 18.7743\n",
      "Epoch [54/100], Step [44800/6235], Loss: 0.2833\n",
      "Epoch [54/100], Step [44900/6235], Loss: 0.9571\n",
      "Epoch [54/100], Step [45000/6235], Loss: 3.7012\n",
      "Epoch [54/100], Step [45100/6235], Loss: 28.5040\n",
      "Epoch [54/100], Step [45200/6235], Loss: 0.4039\n",
      "Epoch [54/100], Step [45300/6235], Loss: 25.0186\n",
      "Epoch [54/100], Step [45400/6235], Loss: 7.3811\n",
      "Epoch [54/100], Step [45500/6235], Loss: 0.1596\n",
      "Epoch [54/100], Step [45600/6235], Loss: 0.5862\n",
      "Epoch [54/100], Step [45700/6235], Loss: 8.3954\n",
      "Epoch [54/100], Step [45800/6235], Loss: 332.8144\n",
      "Epoch [54/100], Step [45900/6235], Loss: 29.6997\n",
      "Epoch [54/100], Step [46000/6235], Loss: 1.3804\n",
      "Epoch [54/100], Step [46100/6235], Loss: 10.0792\n",
      "Epoch [54/100], Step [46200/6235], Loss: 24.5645\n",
      "Epoch [54/100], Step [46300/6235], Loss: 84.9505\n",
      "Epoch [54/100], Step [46400/6235], Loss: 5.9574\n",
      "Epoch [54/100], Step [46500/6235], Loss: 6.5395\n",
      "Epoch [54/100], Step [46600/6235], Loss: 2.2659\n",
      "Epoch [54/100], Step [46700/6235], Loss: 4.1070\n",
      "Epoch [54/100], Step [46800/6235], Loss: 27.7211\n",
      "Epoch [54/100], Step [46900/6235], Loss: 20.1196\n",
      "Epoch [54/100], Step [47000/6235], Loss: 1.8589\n",
      "Epoch [54/100], Step [47100/6235], Loss: 110.8246\n",
      "Epoch [54/100], Step [47200/6235], Loss: 74.6264\n",
      "Epoch [54/100], Step [47300/6235], Loss: 9.9885\n",
      "Epoch [54/100], Step [47400/6235], Loss: 561.2687\n",
      "Epoch [54/100], Step [47500/6235], Loss: 4.3899\n",
      "Epoch [54/100], Step [47600/6235], Loss: 16.3830\n",
      "Epoch [54/100], Step [47700/6235], Loss: 23.8038\n",
      "Epoch [54/100], Step [47800/6235], Loss: 32.8791\n",
      "Epoch [54/100], Step [47900/6235], Loss: 15.1137\n",
      "Epoch [54/100], Step [48000/6235], Loss: 1.5429\n",
      "Epoch [54/100], Step [48100/6235], Loss: 7.2571\n",
      "Epoch [54/100], Step [48200/6235], Loss: 23.6576\n",
      "Epoch [54/100], Step [48300/6235], Loss: 673.6818\n",
      "Epoch [54/100], Step [48400/6235], Loss: 3.8386\n",
      "Epoch [54/100], Step [48500/6235], Loss: 40.4719\n",
      "Epoch [54/100], Step [48600/6235], Loss: 47.9475\n",
      "Epoch [54/100], Step [48700/6235], Loss: 8.6973\n",
      "Epoch [54/100], Step [48800/6235], Loss: 177.5383\n",
      "Epoch [54/100], Step [48900/6235], Loss: 782.8340\n",
      "Epoch [54/100], Step [49000/6235], Loss: 74.5210\n",
      "Epoch [54/100], Step [49100/6235], Loss: 1972.2051\n",
      "Epoch [54/100], Step [49200/6235], Loss: 1240.4867\n",
      "Epoch [54/100], Step [49300/6235], Loss: 1092.1965\n",
      "Epoch [54/100], Step [49400/6235], Loss: 237.5645\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [54/100], Step [49500/6235], Loss: 25.8173\n",
      "Epoch [54/100], Step [49600/6235], Loss: 45.1446\n",
      "Epoch [54/100], Step [49700/6235], Loss: 275.3940\n",
      "Epoch [54/100], Step [49800/6235], Loss: 981.3434\n",
      "Epoch [55/100], Step [100/6235], Loss: 17.9440\n",
      "Epoch [55/100], Step [200/6235], Loss: 0.1498\n",
      "Epoch [55/100], Step [300/6235], Loss: 0.0148\n",
      "Epoch [55/100], Step [400/6235], Loss: 0.0036\n",
      "Epoch [55/100], Step [500/6235], Loss: 0.5228\n",
      "Epoch [55/100], Step [600/6235], Loss: 0.0226\n",
      "Epoch [55/100], Step [700/6235], Loss: 0.3475\n",
      "Epoch [55/100], Step [800/6235], Loss: 0.1234\n",
      "Epoch [55/100], Step [900/6235], Loss: 0.0240\n",
      "Epoch [55/100], Step [1000/6235], Loss: 0.0284\n",
      "Epoch [55/100], Step [1100/6235], Loss: 0.0282\n",
      "Epoch [55/100], Step [1200/6235], Loss: 0.1600\n",
      "Epoch [55/100], Step [1300/6235], Loss: 0.0528\n",
      "Epoch [55/100], Step [1400/6235], Loss: 0.0762\n",
      "Epoch [55/100], Step [1500/6235], Loss: 0.0032\n",
      "Epoch [55/100], Step [1600/6235], Loss: 0.2131\n",
      "Epoch [55/100], Step [1700/6235], Loss: 0.0093\n",
      "Epoch [55/100], Step [1800/6235], Loss: 0.1855\n",
      "Epoch [55/100], Step [1900/6235], Loss: 0.6866\n",
      "Epoch [55/100], Step [2000/6235], Loss: 2.1472\n",
      "Epoch [55/100], Step [2100/6235], Loss: 1.8556\n",
      "Epoch [55/100], Step [2200/6235], Loss: 9.7874\n",
      "Epoch [55/100], Step [2300/6235], Loss: 12.5682\n",
      "Epoch [55/100], Step [2400/6235], Loss: 3.5177\n",
      "Epoch [55/100], Step [2500/6235], Loss: 35.9305\n",
      "Epoch [55/100], Step [2600/6235], Loss: 12.1467\n",
      "Epoch [55/100], Step [2700/6235], Loss: 5.8683\n",
      "Epoch [55/100], Step [2800/6235], Loss: 84.3117\n",
      "Epoch [55/100], Step [2900/6235], Loss: 15.3057\n",
      "Epoch [55/100], Step [3000/6235], Loss: 1.1954\n",
      "Epoch [55/100], Step [3100/6235], Loss: 64.6900\n",
      "Epoch [55/100], Step [3200/6235], Loss: 60.8824\n",
      "Epoch [55/100], Step [3300/6235], Loss: 10.7248\n",
      "Epoch [55/100], Step [3400/6235], Loss: 2.0922\n",
      "Epoch [55/100], Step [3500/6235], Loss: 40.7827\n",
      "Epoch [55/100], Step [3600/6235], Loss: 5.0560\n",
      "Epoch [55/100], Step [3700/6235], Loss: 0.0070\n",
      "Epoch [55/100], Step [3800/6235], Loss: 0.0725\n",
      "Epoch [55/100], Step [3900/6235], Loss: 0.0718\n",
      "Epoch [55/100], Step [4000/6235], Loss: 0.0730\n",
      "Epoch [55/100], Step [4100/6235], Loss: 8.8223\n",
      "Epoch [55/100], Step [4200/6235], Loss: 1.6601\n",
      "Epoch [55/100], Step [4300/6235], Loss: 7.4605\n",
      "Epoch [55/100], Step [4400/6235], Loss: 1.2996\n",
      "Epoch [55/100], Step [4500/6235], Loss: 39.4521\n",
      "Epoch [55/100], Step [4600/6235], Loss: 0.2605\n",
      "Epoch [55/100], Step [4700/6235], Loss: 0.1379\n",
      "Epoch [55/100], Step [4800/6235], Loss: 10.2613\n",
      "Epoch [55/100], Step [4900/6235], Loss: 0.0386\n",
      "Epoch [55/100], Step [5000/6235], Loss: 0.0858\n",
      "Epoch [55/100], Step [5100/6235], Loss: 0.6175\n",
      "Epoch [55/100], Step [5200/6235], Loss: 2.2107\n",
      "Epoch [55/100], Step [5300/6235], Loss: 39.2612\n",
      "Epoch [55/100], Step [5400/6235], Loss: 0.7022\n",
      "Epoch [55/100], Step [5500/6235], Loss: 0.1839\n",
      "Epoch [55/100], Step [5600/6235], Loss: 0.2522\n",
      "Epoch [55/100], Step [5700/6235], Loss: 0.1271\n",
      "Epoch [55/100], Step [5800/6235], Loss: 0.2911\n",
      "Epoch [55/100], Step [5900/6235], Loss: 0.0797\n",
      "Epoch [55/100], Step [6000/6235], Loss: 1.4073\n",
      "Epoch [55/100], Step [6100/6235], Loss: 0.1336\n",
      "Epoch [55/100], Step [6200/6235], Loss: 4.1493\n",
      "Epoch [55/100], Step [6300/6235], Loss: 0.1858\n",
      "Epoch [55/100], Step [6400/6235], Loss: 0.1213\n",
      "Epoch [55/100], Step [6500/6235], Loss: 4.7417\n",
      "Epoch [55/100], Step [6600/6235], Loss: 19.8881\n",
      "Epoch [55/100], Step [6700/6235], Loss: 1.4971\n",
      "Epoch [55/100], Step [6800/6235], Loss: 0.3291\n",
      "Epoch [55/100], Step [6900/6235], Loss: 0.5957\n",
      "Epoch [55/100], Step [7000/6235], Loss: 0.0057\n",
      "Epoch [55/100], Step [7100/6235], Loss: 0.3422\n",
      "Epoch [55/100], Step [7200/6235], Loss: 0.2441\n",
      "Epoch [55/100], Step [7300/6235], Loss: 1.3928\n",
      "Epoch [55/100], Step [7400/6235], Loss: 0.0170\n",
      "Epoch [55/100], Step [7500/6235], Loss: 1.0497\n",
      "Epoch [55/100], Step [7600/6235], Loss: 4.7357\n",
      "Epoch [55/100], Step [7700/6235], Loss: 5.4889\n",
      "Epoch [55/100], Step [7800/6235], Loss: 4.1121\n",
      "Epoch [55/100], Step [7900/6235], Loss: 8.8730\n",
      "Epoch [55/100], Step [8000/6235], Loss: 0.6089\n",
      "Epoch [55/100], Step [8100/6235], Loss: 0.3072\n",
      "Epoch [55/100], Step [8200/6235], Loss: 10.3564\n",
      "Epoch [55/100], Step [8300/6235], Loss: 14.5919\n",
      "Epoch [55/100], Step [8400/6235], Loss: 595.1477\n",
      "Epoch [55/100], Step [8500/6235], Loss: 19.0606\n",
      "Epoch [55/100], Step [8600/6235], Loss: 40.3660\n",
      "Epoch [55/100], Step [8700/6235], Loss: 54.1796\n",
      "Epoch [55/100], Step [8800/6235], Loss: 446.8600\n",
      "Epoch [55/100], Step [8900/6235], Loss: 115.6976\n",
      "Epoch [55/100], Step [9000/6235], Loss: 595.7520\n",
      "Epoch [55/100], Step [9100/6235], Loss: 932.8546\n",
      "Epoch [55/100], Step [9200/6235], Loss: 579.5965\n",
      "Epoch [55/100], Step [9300/6235], Loss: 161.9436\n",
      "Epoch [55/100], Step [9400/6235], Loss: 21.6746\n",
      "Epoch [55/100], Step [9500/6235], Loss: 1203.9160\n",
      "Epoch [55/100], Step [9600/6235], Loss: 325.0267\n",
      "Epoch [55/100], Step [9700/6235], Loss: 1.3901\n",
      "Epoch [55/100], Step [9800/6235], Loss: 3489.3601\n",
      "Epoch [55/100], Step [9900/6235], Loss: 519.8804\n",
      "Epoch [55/100], Step [10000/6235], Loss: 508.3963\n",
      "Epoch [55/100], Step [10100/6235], Loss: 4.4450\n",
      "Epoch [55/100], Step [10200/6235], Loss: 843.5607\n",
      "Epoch [55/100], Step [10300/6235], Loss: 0.8881\n",
      "Epoch [55/100], Step [10400/6235], Loss: 11.5308\n",
      "Epoch [55/100], Step [10500/6235], Loss: 10.8336\n",
      "Epoch [55/100], Step [10600/6235], Loss: 1.8040\n",
      "Epoch [55/100], Step [10700/6235], Loss: 293.9658\n",
      "Epoch [55/100], Step [10800/6235], Loss: 5.5759\n",
      "Epoch [55/100], Step [10900/6235], Loss: 7.7499\n",
      "Epoch [55/100], Step [11000/6235], Loss: 155.4567\n",
      "Epoch [55/100], Step [11100/6235], Loss: 1.0658\n",
      "Epoch [55/100], Step [11200/6235], Loss: 119.1791\n",
      "Epoch [55/100], Step [11300/6235], Loss: 248.1540\n",
      "Epoch [55/100], Step [11400/6235], Loss: 17.9459\n",
      "Epoch [55/100], Step [11500/6235], Loss: 2.0152\n",
      "Epoch [55/100], Step [11600/6235], Loss: 4.6768\n",
      "Epoch [55/100], Step [11700/6235], Loss: 70.0399\n",
      "Epoch [55/100], Step [11800/6235], Loss: 287.4727\n",
      "Epoch [55/100], Step [11900/6235], Loss: 21.5278\n",
      "Epoch [55/100], Step [12000/6235], Loss: 630.4465\n",
      "Epoch [55/100], Step [12100/6235], Loss: 141.1018\n",
      "Epoch [55/100], Step [12200/6235], Loss: 199.4686\n",
      "Epoch [55/100], Step [12300/6235], Loss: 40.8657\n",
      "Epoch [55/100], Step [12400/6235], Loss: 622.7875\n",
      "Epoch [55/100], Step [12500/6235], Loss: 6.1436\n",
      "Epoch [55/100], Step [12600/6235], Loss: 132.7956\n",
      "Epoch [55/100], Step [12700/6235], Loss: 4.2247\n",
      "Epoch [55/100], Step [12800/6235], Loss: 3.1540\n",
      "Epoch [55/100], Step [12900/6235], Loss: 48.6516\n",
      "Epoch [55/100], Step [13000/6235], Loss: 1.4183\n",
      "Epoch [55/100], Step [13100/6235], Loss: 75.0970\n",
      "Epoch [55/100], Step [13200/6235], Loss: 22.3051\n",
      "Epoch [55/100], Step [13300/6235], Loss: 57.0299\n",
      "Epoch [55/100], Step [13400/6235], Loss: 248.2190\n",
      "Epoch [55/100], Step [13500/6235], Loss: 14.1288\n",
      "Epoch [55/100], Step [13600/6235], Loss: 21.3586\n",
      "Epoch [55/100], Step [13700/6235], Loss: 0.5583\n",
      "Epoch [55/100], Step [13800/6235], Loss: 167.9095\n",
      "Epoch [55/100], Step [13900/6235], Loss: 57.5883\n",
      "Epoch [55/100], Step [14000/6235], Loss: 7.5998\n",
      "Epoch [55/100], Step [14100/6235], Loss: 34.5251\n",
      "Epoch [55/100], Step [14200/6235], Loss: 69.5454\n",
      "Epoch [55/100], Step [14300/6235], Loss: 27.7965\n",
      "Epoch [55/100], Step [14400/6235], Loss: 37.7706\n",
      "Epoch [55/100], Step [14500/6235], Loss: 63.8479\n",
      "Epoch [55/100], Step [14600/6235], Loss: 0.4133\n",
      "Epoch [55/100], Step [14700/6235], Loss: 45.2194\n",
      "Epoch [55/100], Step [14800/6235], Loss: 30.5407\n",
      "Epoch [55/100], Step [14900/6235], Loss: 1.9995\n",
      "Epoch [55/100], Step [15000/6235], Loss: 3.2616\n",
      "Epoch [55/100], Step [15100/6235], Loss: 0.1970\n",
      "Epoch [55/100], Step [15200/6235], Loss: 1.8326\n",
      "Epoch [55/100], Step [15300/6235], Loss: 30.8860\n",
      "Epoch [55/100], Step [15400/6235], Loss: 60.7437\n",
      "Epoch [55/100], Step [15500/6235], Loss: 10.5610\n",
      "Epoch [55/100], Step [15600/6235], Loss: 179.4319\n",
      "Epoch [55/100], Step [15700/6235], Loss: 245.5360\n",
      "Epoch [55/100], Step [15800/6235], Loss: 9.2120\n",
      "Epoch [55/100], Step [15900/6235], Loss: 0.4035\n",
      "Epoch [55/100], Step [16000/6235], Loss: 2.6101\n",
      "Epoch [55/100], Step [16100/6235], Loss: 13.0411\n",
      "Epoch [55/100], Step [16200/6235], Loss: 1.6224\n",
      "Epoch [55/100], Step [16300/6235], Loss: 11.3193\n",
      "Epoch [55/100], Step [16400/6235], Loss: 40.8672\n",
      "Epoch [55/100], Step [16500/6235], Loss: 420.5496\n",
      "Epoch [55/100], Step [16600/6235], Loss: 19.0457\n",
      "Epoch [55/100], Step [16700/6235], Loss: 0.7835\n",
      "Epoch [55/100], Step [16800/6235], Loss: 8.9911\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Step [16900/6235], Loss: 0.0845\n",
      "Epoch [55/100], Step [17000/6235], Loss: 0.2592\n",
      "Epoch [55/100], Step [17100/6235], Loss: 0.3814\n",
      "Epoch [55/100], Step [17200/6235], Loss: 307.1424\n",
      "Epoch [55/100], Step [17300/6235], Loss: 30.6699\n",
      "Epoch [55/100], Step [17400/6235], Loss: 31.8211\n",
      "Epoch [55/100], Step [17500/6235], Loss: 1.0292\n",
      "Epoch [55/100], Step [17600/6235], Loss: 4.5139\n",
      "Epoch [55/100], Step [17700/6235], Loss: 8.2805\n",
      "Epoch [55/100], Step [17800/6235], Loss: 14.6943\n",
      "Epoch [55/100], Step [17900/6235], Loss: 2.8842\n",
      "Epoch [55/100], Step [18000/6235], Loss: 1.4977\n",
      "Epoch [55/100], Step [18100/6235], Loss: 19.7391\n",
      "Epoch [55/100], Step [18200/6235], Loss: 0.4539\n",
      "Epoch [55/100], Step [18300/6235], Loss: 1.9939\n",
      "Epoch [55/100], Step [18400/6235], Loss: 0.1321\n",
      "Epoch [55/100], Step [18500/6235], Loss: 24.4540\n",
      "Epoch [55/100], Step [18600/6235], Loss: 4.5876\n",
      "Epoch [55/100], Step [18700/6235], Loss: 1.0646\n",
      "Epoch [55/100], Step [18800/6235], Loss: 129.1712\n",
      "Epoch [55/100], Step [18900/6235], Loss: 61.2035\n",
      "Epoch [55/100], Step [19000/6235], Loss: 7.2035\n",
      "Epoch [55/100], Step [19100/6235], Loss: 1.0000\n",
      "Epoch [55/100], Step [19200/6235], Loss: 1.4278\n",
      "Epoch [55/100], Step [19300/6235], Loss: 1.4398\n",
      "Epoch [55/100], Step [19400/6235], Loss: 175.3307\n",
      "Epoch [55/100], Step [19500/6235], Loss: 169.9327\n",
      "Epoch [55/100], Step [19600/6235], Loss: 110.0969\n",
      "Epoch [55/100], Step [19700/6235], Loss: 27.2713\n",
      "Epoch [55/100], Step [19800/6235], Loss: 1.5188\n",
      "Epoch [55/100], Step [19900/6235], Loss: 0.1303\n",
      "Epoch [55/100], Step [20000/6235], Loss: 78.0272\n",
      "Epoch [55/100], Step [20100/6235], Loss: 0.5055\n",
      "Epoch [55/100], Step [20200/6235], Loss: 1.6622\n",
      "Epoch [55/100], Step [20300/6235], Loss: 1.6835\n",
      "Epoch [55/100], Step [20400/6235], Loss: 13.3353\n",
      "Epoch [55/100], Step [20500/6235], Loss: 52.2310\n",
      "Epoch [55/100], Step [20600/6235], Loss: 197.8375\n",
      "Epoch [55/100], Step [20700/6235], Loss: 10.1411\n",
      "Epoch [55/100], Step [20800/6235], Loss: 2.7022\n",
      "Epoch [55/100], Step [20900/6235], Loss: 25.2812\n",
      "Epoch [55/100], Step [21000/6235], Loss: 13.0595\n",
      "Epoch [55/100], Step [21100/6235], Loss: 6.7020\n",
      "Epoch [55/100], Step [21200/6235], Loss: 0.3139\n",
      "Epoch [55/100], Step [21300/6235], Loss: 0.1374\n",
      "Epoch [55/100], Step [21400/6235], Loss: 5.3072\n",
      "Epoch [55/100], Step [21500/6235], Loss: 4.8097\n",
      "Epoch [55/100], Step [21600/6235], Loss: 0.6533\n",
      "Epoch [55/100], Step [21700/6235], Loss: 0.1695\n",
      "Epoch [55/100], Step [21800/6235], Loss: 3.9673\n",
      "Epoch [55/100], Step [21900/6235], Loss: 1.6417\n",
      "Epoch [55/100], Step [22000/6235], Loss: 9.2930\n",
      "Epoch [55/100], Step [22100/6235], Loss: 0.1090\n",
      "Epoch [55/100], Step [22200/6235], Loss: 2.1851\n",
      "Epoch [55/100], Step [22300/6235], Loss: 0.2913\n",
      "Epoch [55/100], Step [22400/6235], Loss: 2.7899\n",
      "Epoch [55/100], Step [22500/6235], Loss: 117.2422\n",
      "Epoch [55/100], Step [22600/6235], Loss: 17.9379\n",
      "Epoch [55/100], Step [22700/6235], Loss: 0.8481\n",
      "Epoch [55/100], Step [22800/6235], Loss: 7.3808\n",
      "Epoch [55/100], Step [22900/6235], Loss: 5.8488\n",
      "Epoch [55/100], Step [23000/6235], Loss: 16.4527\n",
      "Epoch [55/100], Step [23100/6235], Loss: 6.2929\n",
      "Epoch [55/100], Step [23200/6235], Loss: 34.0266\n",
      "Epoch [55/100], Step [23300/6235], Loss: 18.7740\n",
      "Epoch [55/100], Step [23400/6235], Loss: 2.6075\n",
      "Epoch [55/100], Step [23500/6235], Loss: 0.1080\n",
      "Epoch [55/100], Step [23600/6235], Loss: 132.0500\n",
      "Epoch [55/100], Step [23700/6235], Loss: 6.9386\n",
      "Epoch [55/100], Step [23800/6235], Loss: 1.6891\n",
      "Epoch [55/100], Step [23900/6235], Loss: 2.5273\n",
      "Epoch [55/100], Step [24000/6235], Loss: 1.9666\n",
      "Epoch [55/100], Step [24100/6235], Loss: 0.7458\n",
      "Epoch [55/100], Step [24200/6235], Loss: 25.8224\n",
      "Epoch [55/100], Step [24300/6235], Loss: 0.7947\n",
      "Epoch [55/100], Step [24400/6235], Loss: 1.7756\n",
      "Epoch [55/100], Step [24500/6235], Loss: 0.3874\n",
      "Epoch [55/100], Step [24600/6235], Loss: 0.4910\n",
      "Epoch [55/100], Step [24700/6235], Loss: 3.9643\n",
      "Epoch [55/100], Step [24800/6235], Loss: 0.3844\n",
      "Epoch [55/100], Step [24900/6235], Loss: 9.7987\n",
      "Epoch [55/100], Step [25000/6235], Loss: 9.7498\n",
      "Epoch [55/100], Step [25100/6235], Loss: 6.6882\n",
      "Epoch [55/100], Step [25200/6235], Loss: 0.0592\n",
      "Epoch [55/100], Step [25300/6235], Loss: 0.9707\n",
      "Epoch [55/100], Step [25400/6235], Loss: 10.2415\n",
      "Epoch [55/100], Step [25500/6235], Loss: 9.2157\n",
      "Epoch [55/100], Step [25600/6235], Loss: 7.8141\n",
      "Epoch [55/100], Step [25700/6235], Loss: 0.0658\n",
      "Epoch [55/100], Step [25800/6235], Loss: 0.1753\n",
      "Epoch [55/100], Step [25900/6235], Loss: 3.9364\n",
      "Epoch [55/100], Step [26000/6235], Loss: 1.0897\n",
      "Epoch [55/100], Step [26100/6235], Loss: 0.0399\n",
      "Epoch [55/100], Step [26200/6235], Loss: 1.4223\n",
      "Epoch [55/100], Step [26300/6235], Loss: 1.9557\n",
      "Epoch [55/100], Step [26400/6235], Loss: 0.3526\n",
      "Epoch [55/100], Step [26500/6235], Loss: 0.0415\n",
      "Epoch [55/100], Step [26600/6235], Loss: 0.4193\n",
      "Epoch [55/100], Step [26700/6235], Loss: 0.1809\n",
      "Epoch [55/100], Step [26800/6235], Loss: 0.0854\n",
      "Epoch [55/100], Step [26900/6235], Loss: 0.0372\n",
      "Epoch [55/100], Step [27000/6235], Loss: 16.2459\n",
      "Epoch [55/100], Step [27100/6235], Loss: 0.0593\n",
      "Epoch [55/100], Step [27200/6235], Loss: 0.0094\n",
      "Epoch [55/100], Step [27300/6235], Loss: 0.0583\n",
      "Epoch [55/100], Step [27400/6235], Loss: 0.6448\n",
      "Epoch [55/100], Step [27500/6235], Loss: 7.7401\n",
      "Epoch [55/100], Step [27600/6235], Loss: 0.6117\n",
      "Epoch [55/100], Step [27700/6235], Loss: 1.2886\n",
      "Epoch [55/100], Step [27800/6235], Loss: 5.4216\n",
      "Epoch [55/100], Step [27900/6235], Loss: 1.3385\n",
      "Epoch [55/100], Step [28000/6235], Loss: 107.3995\n",
      "Epoch [55/100], Step [28100/6235], Loss: 2.6239\n",
      "Epoch [55/100], Step [28200/6235], Loss: 31.5444\n",
      "Epoch [55/100], Step [28300/6235], Loss: 2.2220\n",
      "Epoch [55/100], Step [28400/6235], Loss: 25.5575\n",
      "Epoch [55/100], Step [28500/6235], Loss: 4.3791\n",
      "Epoch [55/100], Step [28600/6235], Loss: 0.3241\n",
      "Epoch [55/100], Step [28700/6235], Loss: 5.1681\n",
      "Epoch [55/100], Step [28800/6235], Loss: 0.6474\n",
      "Epoch [55/100], Step [28900/6235], Loss: 65.4678\n",
      "Epoch [55/100], Step [29000/6235], Loss: 11.2292\n",
      "Epoch [55/100], Step [29100/6235], Loss: 0.3471\n",
      "Epoch [55/100], Step [29200/6235], Loss: 2.4574\n",
      "Epoch [55/100], Step [29300/6235], Loss: 12.6799\n",
      "Epoch [55/100], Step [29400/6235], Loss: 0.3199\n",
      "Epoch [55/100], Step [29500/6235], Loss: 0.1009\n",
      "Epoch [55/100], Step [29600/6235], Loss: 0.0419\n",
      "Epoch [55/100], Step [29700/6235], Loss: 2.1468\n",
      "Epoch [55/100], Step [29800/6235], Loss: 1.2640\n",
      "Epoch [55/100], Step [29900/6235], Loss: 1.1442\n",
      "Epoch [55/100], Step [30000/6235], Loss: 6.7240\n",
      "Epoch [55/100], Step [30100/6235], Loss: 10.5559\n",
      "Epoch [55/100], Step [30200/6235], Loss: 1.5432\n",
      "Epoch [55/100], Step [30300/6235], Loss: 0.0600\n",
      "Epoch [55/100], Step [30400/6235], Loss: 1.5308\n",
      "Epoch [55/100], Step [30500/6235], Loss: 2.8522\n",
      "Epoch [55/100], Step [30600/6235], Loss: 1.9039\n",
      "Epoch [55/100], Step [30700/6235], Loss: 1.1254\n",
      "Epoch [55/100], Step [30800/6235], Loss: 0.5544\n",
      "Epoch [55/100], Step [30900/6235], Loss: 3.3223\n",
      "Epoch [55/100], Step [31000/6235], Loss: 0.2620\n",
      "Epoch [55/100], Step [31100/6235], Loss: 0.0456\n",
      "Epoch [55/100], Step [31200/6235], Loss: 2.8529\n",
      "Epoch [55/100], Step [31300/6235], Loss: 2.3259\n",
      "Epoch [55/100], Step [31400/6235], Loss: 9.1294\n",
      "Epoch [55/100], Step [31500/6235], Loss: 2.0334\n",
      "Epoch [55/100], Step [31600/6235], Loss: 4.9939\n",
      "Epoch [55/100], Step [31700/6235], Loss: 34.4413\n",
      "Epoch [55/100], Step [31800/6235], Loss: 0.6834\n",
      "Epoch [55/100], Step [31900/6235], Loss: 236.0705\n",
      "Epoch [55/100], Step [32000/6235], Loss: 59.9420\n",
      "Epoch [55/100], Step [32100/6235], Loss: 1.1295\n",
      "Epoch [55/100], Step [32200/6235], Loss: 135.4948\n",
      "Epoch [55/100], Step [32300/6235], Loss: 1.8863\n",
      "Epoch [55/100], Step [32400/6235], Loss: 1.5588\n",
      "Epoch [55/100], Step [32500/6235], Loss: 12.9222\n",
      "Epoch [55/100], Step [32600/6235], Loss: 0.4128\n",
      "Epoch [55/100], Step [32700/6235], Loss: 107.5851\n",
      "Epoch [55/100], Step [32800/6235], Loss: 0.9920\n",
      "Epoch [55/100], Step [32900/6235], Loss: 3.0147\n",
      "Epoch [55/100], Step [33000/6235], Loss: 0.5341\n",
      "Epoch [55/100], Step [33100/6235], Loss: 0.9248\n",
      "Epoch [55/100], Step [33200/6235], Loss: 1.4912\n",
      "Epoch [55/100], Step [33300/6235], Loss: 1.4388\n",
      "Epoch [55/100], Step [33400/6235], Loss: 138.1277\n",
      "Epoch [55/100], Step [33500/6235], Loss: 2.2749\n",
      "Epoch [55/100], Step [33600/6235], Loss: 9.0928\n",
      "Epoch [55/100], Step [33700/6235], Loss: 14.7409\n",
      "Epoch [55/100], Step [33800/6235], Loss: 1.0945\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [55/100], Step [33900/6235], Loss: 31.1627\n",
      "Epoch [55/100], Step [34000/6235], Loss: 0.1373\n",
      "Epoch [55/100], Step [34100/6235], Loss: 0.6695\n",
      "Epoch [55/100], Step [34200/6235], Loss: 2.1461\n",
      "Epoch [55/100], Step [34300/6235], Loss: 2.5260\n",
      "Epoch [55/100], Step [34400/6235], Loss: 0.1334\n",
      "Epoch [55/100], Step [34500/6235], Loss: 52.0116\n",
      "Epoch [55/100], Step [34600/6235], Loss: 1.2095\n",
      "Epoch [55/100], Step [34700/6235], Loss: 5.4725\n",
      "Epoch [55/100], Step [34800/6235], Loss: 13.3601\n",
      "Epoch [55/100], Step [34900/6235], Loss: 72.1023\n",
      "Epoch [55/100], Step [35000/6235], Loss: 0.5932\n",
      "Epoch [55/100], Step [35100/6235], Loss: 0.6487\n",
      "Epoch [55/100], Step [35200/6235], Loss: 0.4656\n",
      "Epoch [55/100], Step [35300/6235], Loss: 2.6706\n",
      "Epoch [55/100], Step [35400/6235], Loss: 0.6332\n",
      "Epoch [55/100], Step [35500/6235], Loss: 1.4219\n",
      "Epoch [55/100], Step [35600/6235], Loss: 7.0465\n",
      "Epoch [55/100], Step [35700/6235], Loss: 4.7381\n",
      "Epoch [55/100], Step [35800/6235], Loss: 0.4542\n",
      "Epoch [55/100], Step [35900/6235], Loss: 0.6380\n",
      "Epoch [55/100], Step [36000/6235], Loss: 0.1859\n",
      "Epoch [55/100], Step [36100/6235], Loss: 0.0984\n",
      "Epoch [55/100], Step [36200/6235], Loss: 14.8000\n",
      "Epoch [55/100], Step [36300/6235], Loss: 2.1456\n",
      "Epoch [55/100], Step [36400/6235], Loss: 3.0514\n",
      "Epoch [55/100], Step [36500/6235], Loss: 7.8115\n",
      "Epoch [55/100], Step [36600/6235], Loss: 0.1196\n",
      "Epoch [55/100], Step [36700/6235], Loss: 0.6230\n",
      "Epoch [55/100], Step [36800/6235], Loss: 5.7424\n",
      "Epoch [55/100], Step [36900/6235], Loss: 7.8018\n",
      "Epoch [55/100], Step [37000/6235], Loss: 0.9244\n",
      "Epoch [55/100], Step [37100/6235], Loss: 1.7806\n",
      "Epoch [55/100], Step [37200/6235], Loss: 0.0528\n",
      "Epoch [55/100], Step [37300/6235], Loss: 0.0322\n",
      "Epoch [55/100], Step [37400/6235], Loss: 0.1804\n",
      "Epoch [55/100], Step [37500/6235], Loss: 6.8231\n",
      "Epoch [55/100], Step [37600/6235], Loss: 12.3022\n",
      "Epoch [55/100], Step [37700/6235], Loss: 2.2067\n",
      "Epoch [55/100], Step [37800/6235], Loss: 4.3984\n",
      "Epoch [55/100], Step [37900/6235], Loss: 7.1016\n",
      "Epoch [55/100], Step [38000/6235], Loss: 0.8747\n",
      "Epoch [55/100], Step [38100/6235], Loss: 5.2551\n",
      "Epoch [55/100], Step [38200/6235], Loss: 2.3619\n",
      "Epoch [55/100], Step [38300/6235], Loss: 0.3130\n",
      "Epoch [55/100], Step [38400/6235], Loss: 0.0897\n",
      "Epoch [55/100], Step [38500/6235], Loss: 1.3930\n",
      "Epoch [55/100], Step [38600/6235], Loss: 0.3831\n",
      "Epoch [55/100], Step [38700/6235], Loss: 0.3765\n",
      "Epoch [55/100], Step [38800/6235], Loss: 0.1370\n",
      "Epoch [55/100], Step [38900/6235], Loss: 13.2911\n",
      "Epoch [55/100], Step [39000/6235], Loss: 2.1515\n",
      "Epoch [55/100], Step [39100/6235], Loss: 19.2750\n",
      "Epoch [55/100], Step [39200/6235], Loss: 1.1387\n",
      "Epoch [55/100], Step [39300/6235], Loss: 125.4188\n",
      "Epoch [55/100], Step [39400/6235], Loss: 192.8909\n",
      "Epoch [55/100], Step [39500/6235], Loss: 138.7871\n",
      "Epoch [55/100], Step [39600/6235], Loss: 11.4570\n",
      "Epoch [55/100], Step [39700/6235], Loss: 220.3490\n",
      "Epoch [55/100], Step [39800/6235], Loss: 149.9045\n",
      "Epoch [55/100], Step [39900/6235], Loss: 0.6305\n",
      "Epoch [55/100], Step [40000/6235], Loss: 11.8518\n",
      "Epoch [55/100], Step [40100/6235], Loss: 22.7070\n",
      "Epoch [55/100], Step [40200/6235], Loss: 0.4587\n",
      "Epoch [55/100], Step [40300/6235], Loss: 1.1771\n",
      "Epoch [55/100], Step [40400/6235], Loss: 2.1171\n",
      "Epoch [55/100], Step [40500/6235], Loss: 2.4169\n",
      "Epoch [55/100], Step [40600/6235], Loss: 0.2569\n",
      "Epoch [55/100], Step [40700/6235], Loss: 7.5775\n",
      "Epoch [55/100], Step [40800/6235], Loss: 1.1850\n",
      "Epoch [55/100], Step [40900/6235], Loss: 0.1915\n",
      "Epoch [55/100], Step [41000/6235], Loss: 48.1819\n",
      "Epoch [55/100], Step [41100/6235], Loss: 53.0566\n",
      "Epoch [55/100], Step [41200/6235], Loss: 6.1162\n",
      "Epoch [55/100], Step [41300/6235], Loss: 4.8402\n",
      "Epoch [55/100], Step [41400/6235], Loss: 1.4109\n",
      "Epoch [55/100], Step [41500/6235], Loss: 0.8096\n",
      "Epoch [55/100], Step [41600/6235], Loss: 0.4597\n",
      "Epoch [55/100], Step [41700/6235], Loss: 1.6956\n",
      "Epoch [55/100], Step [41800/6235], Loss: 3.9019\n",
      "Epoch [55/100], Step [41900/6235], Loss: 4.3448\n",
      "Epoch [55/100], Step [42000/6235], Loss: 4.3704\n",
      "Epoch [55/100], Step [42100/6235], Loss: 9.4132\n",
      "Epoch [55/100], Step [42200/6235], Loss: 17.5734\n",
      "Epoch [55/100], Step [42300/6235], Loss: 3.0866\n",
      "Epoch [55/100], Step [42400/6235], Loss: 7.3076\n",
      "Epoch [55/100], Step [42500/6235], Loss: 0.7097\n",
      "Epoch [55/100], Step [42600/6235], Loss: 2.3706\n",
      "Epoch [55/100], Step [42700/6235], Loss: 0.7306\n",
      "Epoch [55/100], Step [42800/6235], Loss: 12.6233\n",
      "Epoch [55/100], Step [42900/6235], Loss: 1.5612\n",
      "Epoch [55/100], Step [43000/6235], Loss: 0.1532\n",
      "Epoch [55/100], Step [43100/6235], Loss: 0.0373\n",
      "Epoch [55/100], Step [43200/6235], Loss: 0.8590\n",
      "Epoch [55/100], Step [43300/6235], Loss: 7.5483\n",
      "Epoch [55/100], Step [43400/6235], Loss: 11.5035\n",
      "Epoch [55/100], Step [43500/6235], Loss: 9.5488\n",
      "Epoch [55/100], Step [43600/6235], Loss: 9.3404\n",
      "Epoch [55/100], Step [43700/6235], Loss: 47.5090\n",
      "Epoch [55/100], Step [43800/6235], Loss: 0.8539\n",
      "Epoch [55/100], Step [43900/6235], Loss: 0.2500\n",
      "Epoch [55/100], Step [44000/6235], Loss: 58.6169\n",
      "Epoch [55/100], Step [44100/6235], Loss: 4.1739\n",
      "Epoch [55/100], Step [44200/6235], Loss: 3.4192\n",
      "Epoch [55/100], Step [44300/6235], Loss: 5.4998\n",
      "Epoch [55/100], Step [44400/6235], Loss: 0.4484\n",
      "Epoch [55/100], Step [44500/6235], Loss: 0.2394\n",
      "Epoch [55/100], Step [44600/6235], Loss: 8.8758\n",
      "Epoch [55/100], Step [44700/6235], Loss: 41.1435\n",
      "Epoch [55/100], Step [44800/6235], Loss: 3.7411\n",
      "Epoch [55/100], Step [44900/6235], Loss: 2.3451\n",
      "Epoch [55/100], Step [45000/6235], Loss: 5.1788\n",
      "Epoch [55/100], Step [45100/6235], Loss: 51.4730\n",
      "Epoch [55/100], Step [45200/6235], Loss: 0.4258\n",
      "Epoch [55/100], Step [45300/6235], Loss: 42.7437\n",
      "Epoch [55/100], Step [45400/6235], Loss: 11.5735\n",
      "Epoch [55/100], Step [45500/6235], Loss: 0.1522\n",
      "Epoch [55/100], Step [45600/6235], Loss: 0.1251\n",
      "Epoch [55/100], Step [45700/6235], Loss: 21.3180\n",
      "Epoch [55/100], Step [45800/6235], Loss: 553.0222\n",
      "Epoch [55/100], Step [45900/6235], Loss: 8.0936\n",
      "Epoch [55/100], Step [46000/6235], Loss: 23.3356\n",
      "Epoch [55/100], Step [46100/6235], Loss: 13.4688\n",
      "Epoch [55/100], Step [46200/6235], Loss: 4.0744\n",
      "Epoch [55/100], Step [46300/6235], Loss: 153.2869\n",
      "Epoch [55/100], Step [46400/6235], Loss: 1.6672\n",
      "Epoch [55/100], Step [46500/6235], Loss: 171.8722\n",
      "Epoch [55/100], Step [46600/6235], Loss: 13.9636\n",
      "Epoch [55/100], Step [46700/6235], Loss: 3.7423\n",
      "Epoch [55/100], Step [46800/6235], Loss: 7.5519\n",
      "Epoch [55/100], Step [46900/6235], Loss: 16.4320\n",
      "Epoch [55/100], Step [47000/6235], Loss: 1.2096\n",
      "Epoch [55/100], Step [47100/6235], Loss: 28.5194\n",
      "Epoch [55/100], Step [47200/6235], Loss: 38.1880\n",
      "Epoch [55/100], Step [47300/6235], Loss: 0.9044\n",
      "Epoch [55/100], Step [47400/6235], Loss: 74.9673\n",
      "Epoch [55/100], Step [47500/6235], Loss: 21.8324\n",
      "Epoch [55/100], Step [47600/6235], Loss: 12.2242\n",
      "Epoch [55/100], Step [47700/6235], Loss: 10.3225\n",
      "Epoch [55/100], Step [47800/6235], Loss: 12.7102\n",
      "Epoch [55/100], Step [47900/6235], Loss: 17.5348\n",
      "Epoch [55/100], Step [48000/6235], Loss: 68.6687\n",
      "Epoch [55/100], Step [48100/6235], Loss: 4.7390\n",
      "Epoch [55/100], Step [48200/6235], Loss: 11.1678\n",
      "Epoch [55/100], Step [48300/6235], Loss: 389.2180\n",
      "Epoch [55/100], Step [48400/6235], Loss: 14.7561\n",
      "Epoch [55/100], Step [48500/6235], Loss: 40.8217\n",
      "Epoch [55/100], Step [48600/6235], Loss: 127.4900\n",
      "Epoch [55/100], Step [48700/6235], Loss: 0.7642\n",
      "Epoch [55/100], Step [48800/6235], Loss: 206.2181\n",
      "Epoch [55/100], Step [48900/6235], Loss: 852.4438\n",
      "Epoch [55/100], Step [49000/6235], Loss: 225.3726\n",
      "Epoch [55/100], Step [49100/6235], Loss: 2644.6914\n",
      "Epoch [55/100], Step [49200/6235], Loss: 676.2539\n",
      "Epoch [55/100], Step [49300/6235], Loss: 1236.3931\n",
      "Epoch [55/100], Step [49400/6235], Loss: 255.9842\n",
      "Epoch [55/100], Step [49500/6235], Loss: 5.9036\n",
      "Epoch [55/100], Step [49600/6235], Loss: 230.2702\n",
      "Epoch [55/100], Step [49700/6235], Loss: 2657.8970\n",
      "Epoch [55/100], Step [49800/6235], Loss: 38.5411\n",
      "Epoch [56/100], Step [100/6235], Loss: 16.4055\n",
      "Epoch [56/100], Step [200/6235], Loss: 0.2056\n",
      "Epoch [56/100], Step [300/6235], Loss: 0.0073\n",
      "Epoch [56/100], Step [400/6235], Loss: 0.0077\n",
      "Epoch [56/100], Step [500/6235], Loss: 9.5357\n",
      "Epoch [56/100], Step [600/6235], Loss: 0.0402\n",
      "Epoch [56/100], Step [700/6235], Loss: 0.6395\n",
      "Epoch [56/100], Step [800/6235], Loss: 0.1004\n",
      "Epoch [56/100], Step [900/6235], Loss: 0.0847\n",
      "Epoch [56/100], Step [1000/6235], Loss: 0.0366\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Step [1100/6235], Loss: 0.1630\n",
      "Epoch [56/100], Step [1200/6235], Loss: 0.1717\n",
      "Epoch [56/100], Step [1300/6235], Loss: 0.0199\n",
      "Epoch [56/100], Step [1400/6235], Loss: 0.1583\n",
      "Epoch [56/100], Step [1500/6235], Loss: 0.0072\n",
      "Epoch [56/100], Step [1600/6235], Loss: 0.2326\n",
      "Epoch [56/100], Step [1700/6235], Loss: 0.0768\n",
      "Epoch [56/100], Step [1800/6235], Loss: 0.2195\n",
      "Epoch [56/100], Step [1900/6235], Loss: 0.2771\n",
      "Epoch [56/100], Step [2000/6235], Loss: 2.2420\n",
      "Epoch [56/100], Step [2100/6235], Loss: 1.7869\n",
      "Epoch [56/100], Step [2200/6235], Loss: 6.7328\n",
      "Epoch [56/100], Step [2300/6235], Loss: 1.2876\n",
      "Epoch [56/100], Step [2400/6235], Loss: 0.8086\n",
      "Epoch [56/100], Step [2500/6235], Loss: 30.6706\n",
      "Epoch [56/100], Step [2600/6235], Loss: 13.8369\n",
      "Epoch [56/100], Step [2700/6235], Loss: 6.9314\n",
      "Epoch [56/100], Step [2800/6235], Loss: 112.3344\n",
      "Epoch [56/100], Step [2900/6235], Loss: 17.8966\n",
      "Epoch [56/100], Step [3000/6235], Loss: 0.8167\n",
      "Epoch [56/100], Step [3100/6235], Loss: 67.7783\n",
      "Epoch [56/100], Step [3200/6235], Loss: 39.8189\n",
      "Epoch [56/100], Step [3300/6235], Loss: 9.9784\n",
      "Epoch [56/100], Step [3400/6235], Loss: 4.0404\n",
      "Epoch [56/100], Step [3500/6235], Loss: 53.8464\n",
      "Epoch [56/100], Step [3600/6235], Loss: 1.1280\n",
      "Epoch [56/100], Step [3700/6235], Loss: 0.1064\n",
      "Epoch [56/100], Step [3800/6235], Loss: 0.0400\n",
      "Epoch [56/100], Step [3900/6235], Loss: 0.0923\n",
      "Epoch [56/100], Step [4000/6235], Loss: 0.1112\n",
      "Epoch [56/100], Step [4100/6235], Loss: 9.8533\n",
      "Epoch [56/100], Step [4200/6235], Loss: 4.3239\n",
      "Epoch [56/100], Step [4300/6235], Loss: 4.7572\n",
      "Epoch [56/100], Step [4400/6235], Loss: 0.5621\n",
      "Epoch [56/100], Step [4500/6235], Loss: 37.8836\n",
      "Epoch [56/100], Step [4600/6235], Loss: 2.4417\n",
      "Epoch [56/100], Step [4700/6235], Loss: 0.2023\n",
      "Epoch [56/100], Step [4800/6235], Loss: 7.2856\n",
      "Epoch [56/100], Step [4900/6235], Loss: 1.4826\n",
      "Epoch [56/100], Step [5000/6235], Loss: 0.1056\n",
      "Epoch [56/100], Step [5100/6235], Loss: 0.2281\n",
      "Epoch [56/100], Step [5200/6235], Loss: 3.3850\n",
      "Epoch [56/100], Step [5300/6235], Loss: 26.0489\n",
      "Epoch [56/100], Step [5400/6235], Loss: 0.6717\n",
      "Epoch [56/100], Step [5500/6235], Loss: 0.0406\n",
      "Epoch [56/100], Step [5600/6235], Loss: 0.2671\n",
      "Epoch [56/100], Step [5700/6235], Loss: 0.1886\n",
      "Epoch [56/100], Step [5800/6235], Loss: 0.6233\n",
      "Epoch [56/100], Step [5900/6235], Loss: 0.2235\n",
      "Epoch [56/100], Step [6000/6235], Loss: 0.0617\n",
      "Epoch [56/100], Step [6100/6235], Loss: 0.0683\n",
      "Epoch [56/100], Step [6200/6235], Loss: 6.4417\n",
      "Epoch [56/100], Step [6300/6235], Loss: 0.1889\n",
      "Epoch [56/100], Step [6400/6235], Loss: 0.0106\n",
      "Epoch [56/100], Step [6500/6235], Loss: 1.9722\n",
      "Epoch [56/100], Step [6600/6235], Loss: 5.3380\n",
      "Epoch [56/100], Step [6700/6235], Loss: 1.4295\n",
      "Epoch [56/100], Step [6800/6235], Loss: 0.2880\n",
      "Epoch [56/100], Step [6900/6235], Loss: 0.3842\n",
      "Epoch [56/100], Step [7000/6235], Loss: 0.2850\n",
      "Epoch [56/100], Step [7100/6235], Loss: 0.2990\n",
      "Epoch [56/100], Step [7200/6235], Loss: 0.3922\n",
      "Epoch [56/100], Step [7300/6235], Loss: 0.4996\n",
      "Epoch [56/100], Step [7400/6235], Loss: 0.0982\n",
      "Epoch [56/100], Step [7500/6235], Loss: 0.6439\n",
      "Epoch [56/100], Step [7600/6235], Loss: 4.5102\n",
      "Epoch [56/100], Step [7700/6235], Loss: 10.0538\n",
      "Epoch [56/100], Step [7800/6235], Loss: 2.3767\n",
      "Epoch [56/100], Step [7900/6235], Loss: 2.4154\n",
      "Epoch [56/100], Step [8000/6235], Loss: 0.3613\n",
      "Epoch [56/100], Step [8100/6235], Loss: 0.7682\n",
      "Epoch [56/100], Step [8200/6235], Loss: 10.1609\n",
      "Epoch [56/100], Step [8300/6235], Loss: 16.9134\n",
      "Epoch [56/100], Step [8400/6235], Loss: 645.1460\n",
      "Epoch [56/100], Step [8500/6235], Loss: 18.6751\n",
      "Epoch [56/100], Step [8600/6235], Loss: 32.3755\n",
      "Epoch [56/100], Step [8700/6235], Loss: 42.9536\n",
      "Epoch [56/100], Step [8800/6235], Loss: 695.5759\n",
      "Epoch [56/100], Step [8900/6235], Loss: 342.9410\n",
      "Epoch [56/100], Step [9000/6235], Loss: 628.6776\n",
      "Epoch [56/100], Step [9100/6235], Loss: 884.7930\n",
      "Epoch [56/100], Step [9200/6235], Loss: 627.2410\n",
      "Epoch [56/100], Step [9300/6235], Loss: 208.4292\n",
      "Epoch [56/100], Step [9400/6235], Loss: 908.2053\n",
      "Epoch [56/100], Step [9500/6235], Loss: 1924.6677\n",
      "Epoch [56/100], Step [9600/6235], Loss: 509.1447\n",
      "Epoch [56/100], Step [9700/6235], Loss: 6.9676\n",
      "Epoch [56/100], Step [9800/6235], Loss: 2975.4785\n",
      "Epoch [56/100], Step [9900/6235], Loss: 14.5327\n",
      "Epoch [56/100], Step [10000/6235], Loss: 19.9796\n",
      "Epoch [56/100], Step [10100/6235], Loss: 3.3008\n",
      "Epoch [56/100], Step [10200/6235], Loss: 496.4213\n",
      "Epoch [56/100], Step [10300/6235], Loss: 1.0557\n",
      "Epoch [56/100], Step [10400/6235], Loss: 5.7320\n",
      "Epoch [56/100], Step [10500/6235], Loss: 1.4403\n",
      "Epoch [56/100], Step [10600/6235], Loss: 83.5146\n",
      "Epoch [56/100], Step [10700/6235], Loss: 39.4295\n",
      "Epoch [56/100], Step [10800/6235], Loss: 40.0508\n",
      "Epoch [56/100], Step [10900/6235], Loss: 1.8706\n",
      "Epoch [56/100], Step [11000/6235], Loss: 266.9192\n",
      "Epoch [56/100], Step [11100/6235], Loss: 25.1796\n",
      "Epoch [56/100], Step [11200/6235], Loss: 58.8832\n",
      "Epoch [56/100], Step [11300/6235], Loss: 203.8236\n",
      "Epoch [56/100], Step [11400/6235], Loss: 4.0842\n",
      "Epoch [56/100], Step [11500/6235], Loss: 2.1371\n",
      "Epoch [56/100], Step [11600/6235], Loss: 1.0937\n",
      "Epoch [56/100], Step [11700/6235], Loss: 38.2682\n",
      "Epoch [56/100], Step [11800/6235], Loss: 154.0347\n",
      "Epoch [56/100], Step [11900/6235], Loss: 133.2202\n",
      "Epoch [56/100], Step [12000/6235], Loss: 391.9543\n",
      "Epoch [56/100], Step [12100/6235], Loss: 207.1470\n",
      "Epoch [56/100], Step [12200/6235], Loss: 14.7670\n",
      "Epoch [56/100], Step [12300/6235], Loss: 8.1458\n",
      "Epoch [56/100], Step [12400/6235], Loss: 546.4910\n",
      "Epoch [56/100], Step [12500/6235], Loss: 30.5156\n",
      "Epoch [56/100], Step [12600/6235], Loss: 21.9283\n",
      "Epoch [56/100], Step [12700/6235], Loss: 4.5636\n",
      "Epoch [56/100], Step [12800/6235], Loss: 11.6199\n",
      "Epoch [56/100], Step [12900/6235], Loss: 33.6230\n",
      "Epoch [56/100], Step [13000/6235], Loss: 0.7390\n",
      "Epoch [56/100], Step [13100/6235], Loss: 68.9965\n",
      "Epoch [56/100], Step [13200/6235], Loss: 10.6621\n",
      "Epoch [56/100], Step [13300/6235], Loss: 28.5641\n",
      "Epoch [56/100], Step [13400/6235], Loss: 252.4011\n",
      "Epoch [56/100], Step [13500/6235], Loss: 4.6863\n",
      "Epoch [56/100], Step [13600/6235], Loss: 1.0952\n",
      "Epoch [56/100], Step [13700/6235], Loss: 95.3334\n",
      "Epoch [56/100], Step [13800/6235], Loss: 114.6476\n",
      "Epoch [56/100], Step [13900/6235], Loss: 36.1645\n",
      "Epoch [56/100], Step [14000/6235], Loss: 12.9071\n",
      "Epoch [56/100], Step [14100/6235], Loss: 50.8443\n",
      "Epoch [56/100], Step [14200/6235], Loss: 1.5237\n",
      "Epoch [56/100], Step [14300/6235], Loss: 47.8314\n",
      "Epoch [56/100], Step [14400/6235], Loss: 38.4946\n",
      "Epoch [56/100], Step [14500/6235], Loss: 30.3609\n",
      "Epoch [56/100], Step [14600/6235], Loss: 1.0192\n",
      "Epoch [56/100], Step [14700/6235], Loss: 34.1052\n",
      "Epoch [56/100], Step [14800/6235], Loss: 32.5344\n",
      "Epoch [56/100], Step [14900/6235], Loss: 0.7237\n",
      "Epoch [56/100], Step [15000/6235], Loss: 1.4754\n",
      "Epoch [56/100], Step [15100/6235], Loss: 0.5547\n",
      "Epoch [56/100], Step [15200/6235], Loss: 5.5641\n",
      "Epoch [56/100], Step [15300/6235], Loss: 3.8819\n",
      "Epoch [56/100], Step [15400/6235], Loss: 10.0371\n",
      "Epoch [56/100], Step [15500/6235], Loss: 7.8077\n",
      "Epoch [56/100], Step [15600/6235], Loss: 24.9880\n",
      "Epoch [56/100], Step [15700/6235], Loss: 62.6253\n",
      "Epoch [56/100], Step [15800/6235], Loss: 9.3804\n",
      "Epoch [56/100], Step [15900/6235], Loss: 0.6387\n",
      "Epoch [56/100], Step [16000/6235], Loss: 16.9068\n",
      "Epoch [56/100], Step [16100/6235], Loss: 4.5018\n",
      "Epoch [56/100], Step [16200/6235], Loss: 2.4973\n",
      "Epoch [56/100], Step [16300/6235], Loss: 9.2689\n",
      "Epoch [56/100], Step [16400/6235], Loss: 29.6296\n",
      "Epoch [56/100], Step [16500/6235], Loss: 350.0045\n",
      "Epoch [56/100], Step [16600/6235], Loss: 38.9356\n",
      "Epoch [56/100], Step [16700/6235], Loss: 0.3960\n",
      "Epoch [56/100], Step [16800/6235], Loss: 12.7408\n",
      "Epoch [56/100], Step [16900/6235], Loss: 0.2335\n",
      "Epoch [56/100], Step [17000/6235], Loss: 0.2216\n",
      "Epoch [56/100], Step [17100/6235], Loss: 0.1424\n",
      "Epoch [56/100], Step [17200/6235], Loss: 281.0250\n",
      "Epoch [56/100], Step [17300/6235], Loss: 2.5200\n",
      "Epoch [56/100], Step [17400/6235], Loss: 37.0325\n",
      "Epoch [56/100], Step [17500/6235], Loss: 5.3839\n",
      "Epoch [56/100], Step [17600/6235], Loss: 3.4242\n",
      "Epoch [56/100], Step [17700/6235], Loss: 1.0307\n",
      "Epoch [56/100], Step [17800/6235], Loss: 26.0165\n",
      "Epoch [56/100], Step [17900/6235], Loss: 9.4565\n",
      "Epoch [56/100], Step [18000/6235], Loss: 2.7665\n",
      "Epoch [56/100], Step [18100/6235], Loss: 13.2079\n",
      "Epoch [56/100], Step [18200/6235], Loss: 0.4978\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Step [18300/6235], Loss: 2.0711\n",
      "Epoch [56/100], Step [18400/6235], Loss: 1.3823\n",
      "Epoch [56/100], Step [18500/6235], Loss: 22.4032\n",
      "Epoch [56/100], Step [18600/6235], Loss: 3.0396\n",
      "Epoch [56/100], Step [18700/6235], Loss: 0.7514\n",
      "Epoch [56/100], Step [18800/6235], Loss: 154.4782\n",
      "Epoch [56/100], Step [18900/6235], Loss: 53.3668\n",
      "Epoch [56/100], Step [19000/6235], Loss: 0.3427\n",
      "Epoch [56/100], Step [19100/6235], Loss: 5.3134\n",
      "Epoch [56/100], Step [19200/6235], Loss: 1.4050\n",
      "Epoch [56/100], Step [19300/6235], Loss: 1.0277\n",
      "Epoch [56/100], Step [19400/6235], Loss: 97.1817\n",
      "Epoch [56/100], Step [19500/6235], Loss: 173.5435\n",
      "Epoch [56/100], Step [19600/6235], Loss: 115.8835\n",
      "Epoch [56/100], Step [19700/6235], Loss: 3.3566\n",
      "Epoch [56/100], Step [19800/6235], Loss: 0.8498\n",
      "Epoch [56/100], Step [19900/6235], Loss: 0.8686\n",
      "Epoch [56/100], Step [20000/6235], Loss: 95.4673\n",
      "Epoch [56/100], Step [20100/6235], Loss: 6.9189\n",
      "Epoch [56/100], Step [20200/6235], Loss: 2.9312\n",
      "Epoch [56/100], Step [20300/6235], Loss: 0.7593\n",
      "Epoch [56/100], Step [20400/6235], Loss: 27.1215\n",
      "Epoch [56/100], Step [20500/6235], Loss: 32.6836\n",
      "Epoch [56/100], Step [20600/6235], Loss: 35.2643\n",
      "Epoch [56/100], Step [20700/6235], Loss: 21.7540\n",
      "Epoch [56/100], Step [20800/6235], Loss: 1.4762\n",
      "Epoch [56/100], Step [20900/6235], Loss: 7.1215\n",
      "Epoch [56/100], Step [21000/6235], Loss: 13.7100\n",
      "Epoch [56/100], Step [21100/6235], Loss: 6.4721\n",
      "Epoch [56/100], Step [21200/6235], Loss: 0.2570\n",
      "Epoch [56/100], Step [21300/6235], Loss: 0.2006\n",
      "Epoch [56/100], Step [21400/6235], Loss: 6.6116\n",
      "Epoch [56/100], Step [21500/6235], Loss: 2.3186\n",
      "Epoch [56/100], Step [21600/6235], Loss: 27.5009\n",
      "Epoch [56/100], Step [21700/6235], Loss: 0.1472\n",
      "Epoch [56/100], Step [21800/6235], Loss: 0.9165\n",
      "Epoch [56/100], Step [21900/6235], Loss: 0.4971\n",
      "Epoch [56/100], Step [22000/6235], Loss: 3.5591\n",
      "Epoch [56/100], Step [22100/6235], Loss: 3.7158\n",
      "Epoch [56/100], Step [22200/6235], Loss: 8.0931\n",
      "Epoch [56/100], Step [22300/6235], Loss: 2.6490\n",
      "Epoch [56/100], Step [22400/6235], Loss: 1.0528\n",
      "Epoch [56/100], Step [22500/6235], Loss: 140.9634\n",
      "Epoch [56/100], Step [22600/6235], Loss: 11.3487\n",
      "Epoch [56/100], Step [22700/6235], Loss: 0.0651\n",
      "Epoch [56/100], Step [22800/6235], Loss: 2.8718\n",
      "Epoch [56/100], Step [22900/6235], Loss: 8.4827\n",
      "Epoch [56/100], Step [23000/6235], Loss: 32.1641\n",
      "Epoch [56/100], Step [23100/6235], Loss: 9.3942\n",
      "Epoch [56/100], Step [23200/6235], Loss: 15.7622\n",
      "Epoch [56/100], Step [23300/6235], Loss: 17.4458\n",
      "Epoch [56/100], Step [23400/6235], Loss: 0.4263\n",
      "Epoch [56/100], Step [23500/6235], Loss: 0.3096\n",
      "Epoch [56/100], Step [23600/6235], Loss: 103.7797\n",
      "Epoch [56/100], Step [23700/6235], Loss: 6.3665\n",
      "Epoch [56/100], Step [23800/6235], Loss: 0.9156\n",
      "Epoch [56/100], Step [23900/6235], Loss: 7.8421\n",
      "Epoch [56/100], Step [24000/6235], Loss: 0.5820\n",
      "Epoch [56/100], Step [24100/6235], Loss: 0.2806\n",
      "Epoch [56/100], Step [24200/6235], Loss: 36.5274\n",
      "Epoch [56/100], Step [24300/6235], Loss: 1.0930\n",
      "Epoch [56/100], Step [24400/6235], Loss: 2.6028\n",
      "Epoch [56/100], Step [24500/6235], Loss: 1.2145\n",
      "Epoch [56/100], Step [24600/6235], Loss: 0.0628\n",
      "Epoch [56/100], Step [24700/6235], Loss: 0.4634\n",
      "Epoch [56/100], Step [24800/6235], Loss: 0.1521\n",
      "Epoch [56/100], Step [24900/6235], Loss: 16.9214\n",
      "Epoch [56/100], Step [25000/6235], Loss: 20.7415\n",
      "Epoch [56/100], Step [25100/6235], Loss: 8.0878\n",
      "Epoch [56/100], Step [25200/6235], Loss: 1.4845\n",
      "Epoch [56/100], Step [25300/6235], Loss: 0.5860\n",
      "Epoch [56/100], Step [25400/6235], Loss: 8.8775\n",
      "Epoch [56/100], Step [25500/6235], Loss: 4.9485\n",
      "Epoch [56/100], Step [25600/6235], Loss: 2.2679\n",
      "Epoch [56/100], Step [25700/6235], Loss: 0.2950\n",
      "Epoch [56/100], Step [25800/6235], Loss: 0.1772\n",
      "Epoch [56/100], Step [25900/6235], Loss: 10.4799\n",
      "Epoch [56/100], Step [26000/6235], Loss: 6.7990\n",
      "Epoch [56/100], Step [26100/6235], Loss: 0.2835\n",
      "Epoch [56/100], Step [26200/6235], Loss: 0.3701\n",
      "Epoch [56/100], Step [26300/6235], Loss: 4.2625\n",
      "Epoch [56/100], Step [26400/6235], Loss: 0.1451\n",
      "Epoch [56/100], Step [26500/6235], Loss: 0.1495\n",
      "Epoch [56/100], Step [26600/6235], Loss: 3.0104\n",
      "Epoch [56/100], Step [26700/6235], Loss: 0.5935\n",
      "Epoch [56/100], Step [26800/6235], Loss: 0.4655\n",
      "Epoch [56/100], Step [26900/6235], Loss: 0.0199\n",
      "Epoch [56/100], Step [27000/6235], Loss: 12.8700\n",
      "Epoch [56/100], Step [27100/6235], Loss: 0.1650\n",
      "Epoch [56/100], Step [27200/6235], Loss: 0.0666\n",
      "Epoch [56/100], Step [27300/6235], Loss: 0.2090\n",
      "Epoch [56/100], Step [27400/6235], Loss: 0.8771\n",
      "Epoch [56/100], Step [27500/6235], Loss: 17.5603\n",
      "Epoch [56/100], Step [27600/6235], Loss: 0.1392\n",
      "Epoch [56/100], Step [27700/6235], Loss: 0.9270\n",
      "Epoch [56/100], Step [27800/6235], Loss: 2.5792\n",
      "Epoch [56/100], Step [27900/6235], Loss: 0.5866\n",
      "Epoch [56/100], Step [28000/6235], Loss: 128.2789\n",
      "Epoch [56/100], Step [28100/6235], Loss: 0.8778\n",
      "Epoch [56/100], Step [28200/6235], Loss: 33.3138\n",
      "Epoch [56/100], Step [28300/6235], Loss: 2.1172\n",
      "Epoch [56/100], Step [28400/6235], Loss: 28.7448\n",
      "Epoch [56/100], Step [28500/6235], Loss: 5.0196\n",
      "Epoch [56/100], Step [28600/6235], Loss: 0.0491\n",
      "Epoch [56/100], Step [28700/6235], Loss: 5.3470\n",
      "Epoch [56/100], Step [28800/6235], Loss: 0.6161\n",
      "Epoch [56/100], Step [28900/6235], Loss: 72.5643\n",
      "Epoch [56/100], Step [29000/6235], Loss: 7.2581\n",
      "Epoch [56/100], Step [29100/6235], Loss: 0.1205\n",
      "Epoch [56/100], Step [29200/6235], Loss: 0.7391\n",
      "Epoch [56/100], Step [29300/6235], Loss: 17.8243\n",
      "Epoch [56/100], Step [29400/6235], Loss: 0.1653\n",
      "Epoch [56/100], Step [29500/6235], Loss: 10.0045\n",
      "Epoch [56/100], Step [29600/6235], Loss: 0.4342\n",
      "Epoch [56/100], Step [29700/6235], Loss: 1.5012\n",
      "Epoch [56/100], Step [29800/6235], Loss: 1.5202\n",
      "Epoch [56/100], Step [29900/6235], Loss: 1.2614\n",
      "Epoch [56/100], Step [30000/6235], Loss: 3.0002\n",
      "Epoch [56/100], Step [30100/6235], Loss: 10.8296\n",
      "Epoch [56/100], Step [30200/6235], Loss: 1.0965\n",
      "Epoch [56/100], Step [30300/6235], Loss: 0.0136\n",
      "Epoch [56/100], Step [30400/6235], Loss: 1.0759\n",
      "Epoch [56/100], Step [30500/6235], Loss: 3.0770\n",
      "Epoch [56/100], Step [30600/6235], Loss: 1.8188\n",
      "Epoch [56/100], Step [30700/6235], Loss: 0.6392\n",
      "Epoch [56/100], Step [30800/6235], Loss: 0.5166\n",
      "Epoch [56/100], Step [30900/6235], Loss: 3.6230\n",
      "Epoch [56/100], Step [31000/6235], Loss: 0.2108\n",
      "Epoch [56/100], Step [31100/6235], Loss: 0.0427\n",
      "Epoch [56/100], Step [31200/6235], Loss: 6.4528\n",
      "Epoch [56/100], Step [31300/6235], Loss: 2.0976\n",
      "Epoch [56/100], Step [31400/6235], Loss: 0.5278\n",
      "Epoch [56/100], Step [31500/6235], Loss: 0.7456\n",
      "Epoch [56/100], Step [31600/6235], Loss: 14.9726\n",
      "Epoch [56/100], Step [31700/6235], Loss: 9.3780\n",
      "Epoch [56/100], Step [31800/6235], Loss: 1.4466\n",
      "Epoch [56/100], Step [31900/6235], Loss: 1136.4832\n",
      "Epoch [56/100], Step [32000/6235], Loss: 81.5546\n",
      "Epoch [56/100], Step [32100/6235], Loss: 0.1678\n",
      "Epoch [56/100], Step [32200/6235], Loss: 97.2613\n",
      "Epoch [56/100], Step [32300/6235], Loss: 0.5055\n",
      "Epoch [56/100], Step [32400/6235], Loss: 1.1588\n",
      "Epoch [56/100], Step [32500/6235], Loss: 7.6367\n",
      "Epoch [56/100], Step [32600/6235], Loss: 0.2482\n",
      "Epoch [56/100], Step [32700/6235], Loss: 169.6176\n",
      "Epoch [56/100], Step [32800/6235], Loss: 9.1992\n",
      "Epoch [56/100], Step [32900/6235], Loss: 2.2856\n",
      "Epoch [56/100], Step [33000/6235], Loss: 0.9406\n",
      "Epoch [56/100], Step [33100/6235], Loss: 1.2391\n",
      "Epoch [56/100], Step [33200/6235], Loss: 1.2839\n",
      "Epoch [56/100], Step [33300/6235], Loss: 1.0186\n",
      "Epoch [56/100], Step [33400/6235], Loss: 22.3863\n",
      "Epoch [56/100], Step [33500/6235], Loss: 2.5105\n",
      "Epoch [56/100], Step [33600/6235], Loss: 10.1754\n",
      "Epoch [56/100], Step [33700/6235], Loss: 9.8719\n",
      "Epoch [56/100], Step [33800/6235], Loss: 0.2388\n",
      "Epoch [56/100], Step [33900/6235], Loss: 34.8960\n",
      "Epoch [56/100], Step [34000/6235], Loss: 0.1624\n",
      "Epoch [56/100], Step [34100/6235], Loss: 0.8779\n",
      "Epoch [56/100], Step [34200/6235], Loss: 3.2807\n",
      "Epoch [56/100], Step [34300/6235], Loss: 2.0653\n",
      "Epoch [56/100], Step [34400/6235], Loss: 0.1336\n",
      "Epoch [56/100], Step [34500/6235], Loss: 44.7578\n",
      "Epoch [56/100], Step [34600/6235], Loss: 1.3707\n",
      "Epoch [56/100], Step [34700/6235], Loss: 22.2772\n",
      "Epoch [56/100], Step [34800/6235], Loss: 10.1425\n",
      "Epoch [56/100], Step [34900/6235], Loss: 66.4279\n",
      "Epoch [56/100], Step [35000/6235], Loss: 0.1926\n",
      "Epoch [56/100], Step [35100/6235], Loss: 0.5078\n",
      "Epoch [56/100], Step [35200/6235], Loss: 0.3709\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [56/100], Step [35300/6235], Loss: 3.0391\n",
      "Epoch [56/100], Step [35400/6235], Loss: 0.4622\n",
      "Epoch [56/100], Step [35500/6235], Loss: 0.4119\n",
      "Epoch [56/100], Step [35600/6235], Loss: 0.5859\n",
      "Epoch [56/100], Step [35700/6235], Loss: 3.6022\n",
      "Epoch [56/100], Step [35800/6235], Loss: 0.1298\n",
      "Epoch [56/100], Step [35900/6235], Loss: 2.2546\n",
      "Epoch [56/100], Step [36000/6235], Loss: 0.0699\n",
      "Epoch [56/100], Step [36100/6235], Loss: 0.1039\n",
      "Epoch [56/100], Step [36200/6235], Loss: 33.4860\n",
      "Epoch [56/100], Step [36300/6235], Loss: 2.0482\n",
      "Epoch [56/100], Step [36400/6235], Loss: 2.9948\n",
      "Epoch [56/100], Step [36500/6235], Loss: 7.1682\n",
      "Epoch [56/100], Step [36600/6235], Loss: 0.0747\n",
      "Epoch [56/100], Step [36700/6235], Loss: 0.5719\n",
      "Epoch [56/100], Step [36800/6235], Loss: 3.8240\n",
      "Epoch [56/100], Step [36900/6235], Loss: 13.5425\n",
      "Epoch [56/100], Step [37000/6235], Loss: 0.9537\n",
      "Epoch [56/100], Step [37100/6235], Loss: 2.2069\n",
      "Epoch [56/100], Step [37200/6235], Loss: 0.0375\n",
      "Epoch [56/100], Step [37300/6235], Loss: 0.0554\n",
      "Epoch [56/100], Step [37400/6235], Loss: 0.1663\n",
      "Epoch [56/100], Step [37500/6235], Loss: 7.3171\n",
      "Epoch [56/100], Step [37600/6235], Loss: 12.1235\n",
      "Epoch [56/100], Step [37700/6235], Loss: 2.0860\n",
      "Epoch [56/100], Step [37800/6235], Loss: 5.1652\n",
      "Epoch [56/100], Step [37900/6235], Loss: 3.7118\n",
      "Epoch [56/100], Step [38000/6235], Loss: 0.7970\n",
      "Epoch [56/100], Step [38100/6235], Loss: 4.4264\n",
      "Epoch [56/100], Step [38200/6235], Loss: 1.8512\n",
      "Epoch [56/100], Step [38300/6235], Loss: 0.2454\n",
      "Epoch [56/100], Step [38400/6235], Loss: 0.0473\n",
      "Epoch [56/100], Step [38500/6235], Loss: 1.4974\n",
      "Epoch [56/100], Step [38600/6235], Loss: 0.6561\n",
      "Epoch [56/100], Step [38700/6235], Loss: 0.0625\n",
      "Epoch [56/100], Step [38800/6235], Loss: 0.1033\n",
      "Epoch [56/100], Step [38900/6235], Loss: 3.7016\n",
      "Epoch [56/100], Step [39000/6235], Loss: 24.6607\n",
      "Epoch [56/100], Step [39100/6235], Loss: 16.8639\n",
      "Epoch [56/100], Step [39200/6235], Loss: 0.6999\n",
      "Epoch [56/100], Step [39300/6235], Loss: 19.5235\n",
      "Epoch [56/100], Step [39400/6235], Loss: 297.0821\n",
      "Epoch [56/100], Step [39500/6235], Loss: 80.8747\n",
      "Epoch [56/100], Step [39600/6235], Loss: 36.5382\n",
      "Epoch [56/100], Step [39700/6235], Loss: 174.5821\n",
      "Epoch [56/100], Step [39800/6235], Loss: 109.0132\n",
      "Epoch [56/100], Step [39900/6235], Loss: 0.7072\n",
      "Epoch [56/100], Step [40000/6235], Loss: 0.8653\n",
      "Epoch [56/100], Step [40100/6235], Loss: 28.3914\n",
      "Epoch [56/100], Step [40200/6235], Loss: 9.1798\n",
      "Epoch [56/100], Step [40300/6235], Loss: 0.7221\n",
      "Epoch [56/100], Step [40400/6235], Loss: 2.8359\n",
      "Epoch [56/100], Step [40500/6235], Loss: 1.9963\n",
      "Epoch [56/100], Step [40600/6235], Loss: 0.5287\n",
      "Epoch [56/100], Step [40700/6235], Loss: 7.5829\n",
      "Epoch [56/100], Step [40800/6235], Loss: 1.9915\n",
      "Epoch [56/100], Step [40900/6235], Loss: 0.0578\n",
      "Epoch [56/100], Step [41000/6235], Loss: 47.1520\n",
      "Epoch [56/100], Step [41100/6235], Loss: 30.7404\n",
      "Epoch [56/100], Step [41200/6235], Loss: 5.0213\n",
      "Epoch [56/100], Step [41300/6235], Loss: 3.0109\n",
      "Epoch [56/100], Step [41400/6235], Loss: 0.2374\n",
      "Epoch [56/100], Step [41500/6235], Loss: 1.4499\n",
      "Epoch [56/100], Step [41600/6235], Loss: 0.5523\n",
      "Epoch [56/100], Step [41700/6235], Loss: 5.1342\n",
      "Epoch [56/100], Step [41800/6235], Loss: 0.4372\n",
      "Epoch [56/100], Step [41900/6235], Loss: 0.7687\n",
      "Epoch [56/100], Step [42000/6235], Loss: 2.0288\n",
      "Epoch [56/100], Step [42100/6235], Loss: 3.5622\n",
      "Epoch [56/100], Step [42200/6235], Loss: 9.8236\n",
      "Epoch [56/100], Step [42300/6235], Loss: 0.5082\n",
      "Epoch [56/100], Step [42400/6235], Loss: 2.2976\n",
      "Epoch [56/100], Step [42500/6235], Loss: 4.1903\n",
      "Epoch [56/100], Step [42600/6235], Loss: 0.4167\n",
      "Epoch [56/100], Step [42700/6235], Loss: 0.1511\n",
      "Epoch [56/100], Step [42800/6235], Loss: 0.1507\n",
      "Epoch [56/100], Step [42900/6235], Loss: 4.1733\n",
      "Epoch [56/100], Step [43000/6235], Loss: 0.1772\n",
      "Epoch [56/100], Step [43100/6235], Loss: 1.9852\n",
      "Epoch [56/100], Step [43200/6235], Loss: 0.4147\n",
      "Epoch [56/100], Step [43300/6235], Loss: 11.1690\n",
      "Epoch [56/100], Step [43400/6235], Loss: 5.9961\n",
      "Epoch [56/100], Step [43500/6235], Loss: 6.5983\n",
      "Epoch [56/100], Step [43600/6235], Loss: 37.7041\n",
      "Epoch [56/100], Step [43700/6235], Loss: 24.7474\n",
      "Epoch [56/100], Step [43800/6235], Loss: 5.5836\n",
      "Epoch [56/100], Step [43900/6235], Loss: 1.9482\n",
      "Epoch [56/100], Step [44000/6235], Loss: 61.3604\n",
      "Epoch [56/100], Step [44100/6235], Loss: 2.8576\n",
      "Epoch [56/100], Step [44200/6235], Loss: 13.8030\n",
      "Epoch [56/100], Step [44300/6235], Loss: 48.3684\n",
      "Epoch [56/100], Step [44400/6235], Loss: 2.0294\n",
      "Epoch [56/100], Step [44500/6235], Loss: 3.4672\n",
      "Epoch [56/100], Step [44600/6235], Loss: 8.0865\n",
      "Epoch [56/100], Step [44700/6235], Loss: 4.5017\n",
      "Epoch [56/100], Step [44800/6235], Loss: 0.4053\n",
      "Epoch [56/100], Step [44900/6235], Loss: 0.8385\n",
      "Epoch [56/100], Step [45000/6235], Loss: 2.0399\n",
      "Epoch [56/100], Step [45100/6235], Loss: 15.0904\n",
      "Epoch [56/100], Step [45200/6235], Loss: 0.4573\n",
      "Epoch [56/100], Step [45300/6235], Loss: 17.6695\n",
      "Epoch [56/100], Step [45400/6235], Loss: 4.9257\n",
      "Epoch [56/100], Step [45500/6235], Loss: 0.1550\n",
      "Epoch [56/100], Step [45600/6235], Loss: 0.9166\n",
      "Epoch [56/100], Step [45700/6235], Loss: 3.4481\n",
      "Epoch [56/100], Step [45800/6235], Loss: 208.3533\n",
      "Epoch [56/100], Step [45900/6235], Loss: 19.1290\n",
      "Epoch [56/100], Step [46000/6235], Loss: 5.1252\n",
      "Epoch [56/100], Step [46100/6235], Loss: 30.1919\n",
      "Epoch [56/100], Step [46200/6235], Loss: 72.8352\n",
      "Epoch [56/100], Step [46300/6235], Loss: 22.5980\n",
      "Epoch [56/100], Step [46400/6235], Loss: 1.3710\n",
      "Epoch [56/100], Step [46500/6235], Loss: 23.6143\n",
      "Epoch [56/100], Step [46600/6235], Loss: 12.5601\n",
      "Epoch [56/100], Step [46700/6235], Loss: 3.4802\n",
      "Epoch [56/100], Step [46800/6235], Loss: 27.7578\n",
      "Epoch [56/100], Step [46900/6235], Loss: 22.0896\n",
      "Epoch [56/100], Step [47000/6235], Loss: 0.6558\n",
      "Epoch [56/100], Step [47100/6235], Loss: 64.4951\n",
      "Epoch [56/100], Step [47200/6235], Loss: 69.5861\n",
      "Epoch [56/100], Step [47300/6235], Loss: 0.6641\n",
      "Epoch [56/100], Step [47400/6235], Loss: 180.7109\n",
      "Epoch [56/100], Step [47500/6235], Loss: 10.9653\n",
      "Epoch [56/100], Step [47600/6235], Loss: 16.5691\n",
      "Epoch [56/100], Step [47700/6235], Loss: 13.5847\n",
      "Epoch [56/100], Step [47800/6235], Loss: 17.0046\n",
      "Epoch [56/100], Step [47900/6235], Loss: 18.2827\n",
      "Epoch [56/100], Step [48000/6235], Loss: 35.2426\n",
      "Epoch [56/100], Step [48100/6235], Loss: 49.2367\n",
      "Epoch [56/100], Step [48200/6235], Loss: 63.8035\n",
      "Epoch [56/100], Step [48300/6235], Loss: 418.0686\n",
      "Epoch [56/100], Step [48400/6235], Loss: 15.4899\n",
      "Epoch [56/100], Step [48500/6235], Loss: 41.5225\n",
      "Epoch [56/100], Step [48600/6235], Loss: 145.8529\n",
      "Epoch [56/100], Step [48700/6235], Loss: 3.1906\n",
      "Epoch [56/100], Step [48800/6235], Loss: 178.8279\n",
      "Epoch [56/100], Step [48900/6235], Loss: 943.4138\n",
      "Epoch [56/100], Step [49000/6235], Loss: 127.6242\n",
      "Epoch [56/100], Step [49100/6235], Loss: 1468.0315\n",
      "Epoch [56/100], Step [49200/6235], Loss: 981.1602\n",
      "Epoch [56/100], Step [49300/6235], Loss: 1084.3094\n",
      "Epoch [56/100], Step [49400/6235], Loss: 1.1484\n",
      "Epoch [56/100], Step [49500/6235], Loss: 12.2900\n",
      "Epoch [56/100], Step [49600/6235], Loss: 37.6491\n",
      "Epoch [56/100], Step [49700/6235], Loss: 7574.8193\n",
      "Epoch [56/100], Step [49800/6235], Loss: 248.2011\n",
      "Epoch [57/100], Step [100/6235], Loss: 18.0800\n",
      "Epoch [57/100], Step [200/6235], Loss: 0.1743\n",
      "Epoch [57/100], Step [300/6235], Loss: 0.0073\n",
      "Epoch [57/100], Step [400/6235], Loss: 0.0012\n",
      "Epoch [57/100], Step [500/6235], Loss: 0.0764\n",
      "Epoch [57/100], Step [600/6235], Loss: 0.0207\n",
      "Epoch [57/100], Step [700/6235], Loss: 0.6095\n",
      "Epoch [57/100], Step [800/6235], Loss: 0.0353\n",
      "Epoch [57/100], Step [900/6235], Loss: 0.0587\n",
      "Epoch [57/100], Step [1000/6235], Loss: 0.0220\n",
      "Epoch [57/100], Step [1100/6235], Loss: 0.0267\n",
      "Epoch [57/100], Step [1200/6235], Loss: 0.1634\n",
      "Epoch [57/100], Step [1300/6235], Loss: 0.0033\n",
      "Epoch [57/100], Step [1400/6235], Loss: 0.0528\n",
      "Epoch [57/100], Step [1500/6235], Loss: 0.0069\n",
      "Epoch [57/100], Step [1600/6235], Loss: 0.2344\n",
      "Epoch [57/100], Step [1700/6235], Loss: 0.1629\n",
      "Epoch [57/100], Step [1800/6235], Loss: 0.2496\n",
      "Epoch [57/100], Step [1900/6235], Loss: 0.2851\n",
      "Epoch [57/100], Step [2000/6235], Loss: 2.1845\n",
      "Epoch [57/100], Step [2100/6235], Loss: 2.4119\n",
      "Epoch [57/100], Step [2200/6235], Loss: 5.8191\n",
      "Epoch [57/100], Step [2300/6235], Loss: 2.2812\n",
      "Epoch [57/100], Step [2400/6235], Loss: 1.7265\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Step [2500/6235], Loss: 33.8650\n",
      "Epoch [57/100], Step [2600/6235], Loss: 13.4705\n",
      "Epoch [57/100], Step [2700/6235], Loss: 4.9153\n",
      "Epoch [57/100], Step [2800/6235], Loss: 123.3880\n",
      "Epoch [57/100], Step [2900/6235], Loss: 6.1482\n",
      "Epoch [57/100], Step [3000/6235], Loss: 3.2428\n",
      "Epoch [57/100], Step [3100/6235], Loss: 104.2822\n",
      "Epoch [57/100], Step [3200/6235], Loss: 6.1114\n",
      "Epoch [57/100], Step [3300/6235], Loss: 0.9742\n",
      "Epoch [57/100], Step [3400/6235], Loss: 7.0853\n",
      "Epoch [57/100], Step [3500/6235], Loss: 75.2383\n",
      "Epoch [57/100], Step [3600/6235], Loss: 3.9158\n",
      "Epoch [57/100], Step [3700/6235], Loss: 0.2529\n",
      "Epoch [57/100], Step [3800/6235], Loss: 0.3380\n",
      "Epoch [57/100], Step [3900/6235], Loss: 0.4860\n",
      "Epoch [57/100], Step [4000/6235], Loss: 0.6997\n",
      "Epoch [57/100], Step [4100/6235], Loss: 5.5192\n",
      "Epoch [57/100], Step [4200/6235], Loss: 0.4833\n",
      "Epoch [57/100], Step [4300/6235], Loss: 1.5796\n",
      "Epoch [57/100], Step [4400/6235], Loss: 0.0205\n",
      "Epoch [57/100], Step [4500/6235], Loss: 61.4768\n",
      "Epoch [57/100], Step [4600/6235], Loss: 20.3307\n",
      "Epoch [57/100], Step [4700/6235], Loss: 2.6857\n",
      "Epoch [57/100], Step [4800/6235], Loss: 1.8772\n",
      "Epoch [57/100], Step [4900/6235], Loss: 1.0535\n",
      "Epoch [57/100], Step [5000/6235], Loss: 0.7217\n",
      "Epoch [57/100], Step [5100/6235], Loss: 11.0533\n",
      "Epoch [57/100], Step [5200/6235], Loss: 0.5776\n",
      "Epoch [57/100], Step [5300/6235], Loss: 13.9986\n",
      "Epoch [57/100], Step [5400/6235], Loss: 1.7695\n",
      "Epoch [57/100], Step [5500/6235], Loss: 0.4660\n",
      "Epoch [57/100], Step [5600/6235], Loss: 0.7174\n",
      "Epoch [57/100], Step [5700/6235], Loss: 0.7310\n",
      "Epoch [57/100], Step [5800/6235], Loss: 1.0856\n",
      "Epoch [57/100], Step [5900/6235], Loss: 0.0211\n",
      "Epoch [57/100], Step [6000/6235], Loss: 0.3818\n",
      "Epoch [57/100], Step [6100/6235], Loss: 0.0489\n",
      "Epoch [57/100], Step [6200/6235], Loss: 4.1585\n",
      "Epoch [57/100], Step [6300/6235], Loss: 0.3762\n",
      "Epoch [57/100], Step [6400/6235], Loss: 0.0108\n",
      "Epoch [57/100], Step [6500/6235], Loss: 1.5800\n",
      "Epoch [57/100], Step [6600/6235], Loss: 5.4369\n",
      "Epoch [57/100], Step [6700/6235], Loss: 1.8763\n",
      "Epoch [57/100], Step [6800/6235], Loss: 0.4377\n",
      "Epoch [57/100], Step [6900/6235], Loss: 0.9245\n",
      "Epoch [57/100], Step [7000/6235], Loss: 0.0113\n",
      "Epoch [57/100], Step [7100/6235], Loss: 0.2416\n",
      "Epoch [57/100], Step [7200/6235], Loss: 0.1495\n",
      "Epoch [57/100], Step [7300/6235], Loss: 0.2662\n",
      "Epoch [57/100], Step [7400/6235], Loss: 0.6705\n",
      "Epoch [57/100], Step [7500/6235], Loss: 0.1901\n",
      "Epoch [57/100], Step [7600/6235], Loss: 1.6845\n",
      "Epoch [57/100], Step [7700/6235], Loss: 1.9782\n",
      "Epoch [57/100], Step [7800/6235], Loss: 0.8847\n",
      "Epoch [57/100], Step [7900/6235], Loss: 4.4132\n",
      "Epoch [57/100], Step [8000/6235], Loss: 0.0613\n",
      "Epoch [57/100], Step [8100/6235], Loss: 3.2074\n",
      "Epoch [57/100], Step [8200/6235], Loss: 5.1420\n",
      "Epoch [57/100], Step [8300/6235], Loss: 20.7976\n",
      "Epoch [57/100], Step [8400/6235], Loss: 310.8919\n",
      "Epoch [57/100], Step [8500/6235], Loss: 2.6934\n",
      "Epoch [57/100], Step [8600/6235], Loss: 0.6070\n",
      "Epoch [57/100], Step [8700/6235], Loss: 129.8937\n",
      "Epoch [57/100], Step [8800/6235], Loss: 995.5217\n",
      "Epoch [57/100], Step [8900/6235], Loss: 12.8395\n",
      "Epoch [57/100], Step [9000/6235], Loss: 420.8397\n",
      "Epoch [57/100], Step [9100/6235], Loss: 747.7676\n",
      "Epoch [57/100], Step [9200/6235], Loss: 396.0642\n",
      "Epoch [57/100], Step [9300/6235], Loss: 186.5072\n",
      "Epoch [57/100], Step [9400/6235], Loss: 1234.6497\n",
      "Epoch [57/100], Step [9500/6235], Loss: 1127.1589\n",
      "Epoch [57/100], Step [9600/6235], Loss: 277.9858\n",
      "Epoch [57/100], Step [9700/6235], Loss: 202.1954\n",
      "Epoch [57/100], Step [9800/6235], Loss: 2580.2383\n",
      "Epoch [57/100], Step [9900/6235], Loss: 253.6016\n",
      "Epoch [57/100], Step [10000/6235], Loss: 140.6150\n",
      "Epoch [57/100], Step [10100/6235], Loss: 3.4356\n",
      "Epoch [57/100], Step [10200/6235], Loss: 538.3536\n",
      "Epoch [57/100], Step [10300/6235], Loss: 7.5720\n",
      "Epoch [57/100], Step [10400/6235], Loss: 0.7272\n",
      "Epoch [57/100], Step [10500/6235], Loss: 1.2612\n",
      "Epoch [57/100], Step [10600/6235], Loss: 282.2028\n",
      "Epoch [57/100], Step [10700/6235], Loss: 62.6676\n",
      "Epoch [57/100], Step [10800/6235], Loss: 26.8013\n",
      "Epoch [57/100], Step [10900/6235], Loss: 5.6254\n",
      "Epoch [57/100], Step [11000/6235], Loss: 221.5297\n",
      "Epoch [57/100], Step [11100/6235], Loss: 11.7684\n",
      "Epoch [57/100], Step [11200/6235], Loss: 91.9746\n",
      "Epoch [57/100], Step [11300/6235], Loss: 223.4498\n",
      "Epoch [57/100], Step [11400/6235], Loss: 1.1651\n",
      "Epoch [57/100], Step [11500/6235], Loss: 1.0285\n",
      "Epoch [57/100], Step [11600/6235], Loss: 2.6968\n",
      "Epoch [57/100], Step [11700/6235], Loss: 56.1831\n",
      "Epoch [57/100], Step [11800/6235], Loss: 1.7164\n",
      "Epoch [57/100], Step [11900/6235], Loss: 221.8795\n",
      "Epoch [57/100], Step [12000/6235], Loss: 627.3019\n",
      "Epoch [57/100], Step [12100/6235], Loss: 346.2498\n",
      "Epoch [57/100], Step [12200/6235], Loss: 175.3041\n",
      "Epoch [57/100], Step [12300/6235], Loss: 54.6101\n",
      "Epoch [57/100], Step [12400/6235], Loss: 230.6655\n",
      "Epoch [57/100], Step [12500/6235], Loss: 256.2831\n",
      "Epoch [57/100], Step [12600/6235], Loss: 18.9309\n",
      "Epoch [57/100], Step [12700/6235], Loss: 5.1909\n",
      "Epoch [57/100], Step [12800/6235], Loss: 20.1456\n",
      "Epoch [57/100], Step [12900/6235], Loss: 29.5158\n",
      "Epoch [57/100], Step [13000/6235], Loss: 0.1519\n",
      "Epoch [57/100], Step [13100/6235], Loss: 60.6930\n",
      "Epoch [57/100], Step [13200/6235], Loss: 20.9882\n",
      "Epoch [57/100], Step [13300/6235], Loss: 2.2130\n",
      "Epoch [57/100], Step [13400/6235], Loss: 113.0568\n",
      "Epoch [57/100], Step [13500/6235], Loss: 1.8568\n",
      "Epoch [57/100], Step [13600/6235], Loss: 4.3985\n",
      "Epoch [57/100], Step [13700/6235], Loss: 183.6996\n",
      "Epoch [57/100], Step [13800/6235], Loss: 161.2979\n",
      "Epoch [57/100], Step [13900/6235], Loss: 172.9920\n",
      "Epoch [57/100], Step [14000/6235], Loss: 0.3578\n",
      "Epoch [57/100], Step [14100/6235], Loss: 54.2746\n",
      "Epoch [57/100], Step [14200/6235], Loss: 31.7856\n",
      "Epoch [57/100], Step [14300/6235], Loss: 0.6376\n",
      "Epoch [57/100], Step [14400/6235], Loss: 18.6526\n",
      "Epoch [57/100], Step [14500/6235], Loss: 17.2054\n",
      "Epoch [57/100], Step [14600/6235], Loss: 1.6852\n",
      "Epoch [57/100], Step [14700/6235], Loss: 9.2795\n",
      "Epoch [57/100], Step [14800/6235], Loss: 12.5945\n",
      "Epoch [57/100], Step [14900/6235], Loss: 0.4670\n",
      "Epoch [57/100], Step [15000/6235], Loss: 0.1421\n",
      "Epoch [57/100], Step [15100/6235], Loss: 0.0660\n",
      "Epoch [57/100], Step [15200/6235], Loss: 64.0888\n",
      "Epoch [57/100], Step [15300/6235], Loss: 24.8576\n",
      "Epoch [57/100], Step [15400/6235], Loss: 70.8613\n",
      "Epoch [57/100], Step [15500/6235], Loss: 16.6650\n",
      "Epoch [57/100], Step [15600/6235], Loss: 77.3910\n",
      "Epoch [57/100], Step [15700/6235], Loss: 6.0815\n",
      "Epoch [57/100], Step [15800/6235], Loss: 0.4803\n",
      "Epoch [57/100], Step [15900/6235], Loss: 2.7212\n",
      "Epoch [57/100], Step [16000/6235], Loss: 163.4066\n",
      "Epoch [57/100], Step [16100/6235], Loss: 14.0535\n",
      "Epoch [57/100], Step [16200/6235], Loss: 0.5661\n",
      "Epoch [57/100], Step [16300/6235], Loss: 10.9053\n",
      "Epoch [57/100], Step [16400/6235], Loss: 22.7727\n",
      "Epoch [57/100], Step [16500/6235], Loss: 629.2996\n",
      "Epoch [57/100], Step [16600/6235], Loss: 36.9486\n",
      "Epoch [57/100], Step [16700/6235], Loss: 0.4336\n",
      "Epoch [57/100], Step [16800/6235], Loss: 8.0869\n",
      "Epoch [57/100], Step [16900/6235], Loss: 0.0660\n",
      "Epoch [57/100], Step [17000/6235], Loss: 0.2611\n",
      "Epoch [57/100], Step [17100/6235], Loss: 0.5278\n",
      "Epoch [57/100], Step [17200/6235], Loss: 314.0759\n",
      "Epoch [57/100], Step [17300/6235], Loss: 35.0554\n",
      "Epoch [57/100], Step [17400/6235], Loss: 35.7434\n",
      "Epoch [57/100], Step [17500/6235], Loss: 2.0105\n",
      "Epoch [57/100], Step [17600/6235], Loss: 4.1606\n",
      "Epoch [57/100], Step [17700/6235], Loss: 7.8752\n",
      "Epoch [57/100], Step [17800/6235], Loss: 21.7478\n",
      "Epoch [57/100], Step [17900/6235], Loss: 22.7420\n",
      "Epoch [57/100], Step [18000/6235], Loss: 2.0939\n",
      "Epoch [57/100], Step [18100/6235], Loss: 14.7011\n",
      "Epoch [57/100], Step [18200/6235], Loss: 0.3569\n",
      "Epoch [57/100], Step [18300/6235], Loss: 2.3503\n",
      "Epoch [57/100], Step [18400/6235], Loss: 0.5257\n",
      "Epoch [57/100], Step [18500/6235], Loss: 21.2514\n",
      "Epoch [57/100], Step [18600/6235], Loss: 3.1953\n",
      "Epoch [57/100], Step [18700/6235], Loss: 0.6745\n",
      "Epoch [57/100], Step [18800/6235], Loss: 154.2994\n",
      "Epoch [57/100], Step [18900/6235], Loss: 81.7716\n",
      "Epoch [57/100], Step [19000/6235], Loss: 3.3819\n",
      "Epoch [57/100], Step [19100/6235], Loss: 33.4984\n",
      "Epoch [57/100], Step [19200/6235], Loss: 2.2096\n",
      "Epoch [57/100], Step [19300/6235], Loss: 11.0238\n",
      "Epoch [57/100], Step [19400/6235], Loss: 240.4123\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Step [19500/6235], Loss: 114.4195\n",
      "Epoch [57/100], Step [19600/6235], Loss: 58.3770\n",
      "Epoch [57/100], Step [19700/6235], Loss: 2.2822\n",
      "Epoch [57/100], Step [19800/6235], Loss: 8.4375\n",
      "Epoch [57/100], Step [19900/6235], Loss: 0.1211\n",
      "Epoch [57/100], Step [20000/6235], Loss: 67.6162\n",
      "Epoch [57/100], Step [20100/6235], Loss: 1.6847\n",
      "Epoch [57/100], Step [20200/6235], Loss: 3.1264\n",
      "Epoch [57/100], Step [20300/6235], Loss: 2.3070\n",
      "Epoch [57/100], Step [20400/6235], Loss: 13.7415\n",
      "Epoch [57/100], Step [20500/6235], Loss: 51.4865\n",
      "Epoch [57/100], Step [20600/6235], Loss: 185.2081\n",
      "Epoch [57/100], Step [20700/6235], Loss: 27.9600\n",
      "Epoch [57/100], Step [20800/6235], Loss: 6.1962\n",
      "Epoch [57/100], Step [20900/6235], Loss: 12.6618\n",
      "Epoch [57/100], Step [21000/6235], Loss: 14.3965\n",
      "Epoch [57/100], Step [21100/6235], Loss: 6.5600\n",
      "Epoch [57/100], Step [21200/6235], Loss: 0.3169\n",
      "Epoch [57/100], Step [21300/6235], Loss: 0.1377\n",
      "Epoch [57/100], Step [21400/6235], Loss: 5.8839\n",
      "Epoch [57/100], Step [21500/6235], Loss: 2.1927\n",
      "Epoch [57/100], Step [21600/6235], Loss: 32.3697\n",
      "Epoch [57/100], Step [21700/6235], Loss: 0.2773\n",
      "Epoch [57/100], Step [21800/6235], Loss: 2.9957\n",
      "Epoch [57/100], Step [21900/6235], Loss: 1.3363\n",
      "Epoch [57/100], Step [22000/6235], Loss: 6.6414\n",
      "Epoch [57/100], Step [22100/6235], Loss: 1.2092\n",
      "Epoch [57/100], Step [22200/6235], Loss: 8.9832\n",
      "Epoch [57/100], Step [22300/6235], Loss: 0.2334\n",
      "Epoch [57/100], Step [22400/6235], Loss: 10.2501\n",
      "Epoch [57/100], Step [22500/6235], Loss: 170.4782\n",
      "Epoch [57/100], Step [22600/6235], Loss: 21.0220\n",
      "Epoch [57/100], Step [22700/6235], Loss: 1.9975\n",
      "Epoch [57/100], Step [22800/6235], Loss: 11.2202\n",
      "Epoch [57/100], Step [22900/6235], Loss: 7.9365\n",
      "Epoch [57/100], Step [23000/6235], Loss: 8.3718\n",
      "Epoch [57/100], Step [23100/6235], Loss: 3.7651\n",
      "Epoch [57/100], Step [23200/6235], Loss: 14.6528\n",
      "Epoch [57/100], Step [23300/6235], Loss: 18.3410\n",
      "Epoch [57/100], Step [23400/6235], Loss: 1.1688\n",
      "Epoch [57/100], Step [23500/6235], Loss: 0.2093\n",
      "Epoch [57/100], Step [23600/6235], Loss: 119.1546\n",
      "Epoch [57/100], Step [23700/6235], Loss: 3.7372\n",
      "Epoch [57/100], Step [23800/6235], Loss: 1.0814\n",
      "Epoch [57/100], Step [23900/6235], Loss: 6.6818\n",
      "Epoch [57/100], Step [24000/6235], Loss: 0.1287\n",
      "Epoch [57/100], Step [24100/6235], Loss: 0.1604\n",
      "Epoch [57/100], Step [24200/6235], Loss: 20.5165\n",
      "Epoch [57/100], Step [24300/6235], Loss: 0.9132\n",
      "Epoch [57/100], Step [24400/6235], Loss: 2.0994\n",
      "Epoch [57/100], Step [24500/6235], Loss: 0.5763\n",
      "Epoch [57/100], Step [24600/6235], Loss: 0.0958\n",
      "Epoch [57/100], Step [24700/6235], Loss: 0.8502\n",
      "Epoch [57/100], Step [24800/6235], Loss: 0.2740\n",
      "Epoch [57/100], Step [24900/6235], Loss: 16.6755\n",
      "Epoch [57/100], Step [25000/6235], Loss: 18.1295\n",
      "Epoch [57/100], Step [25100/6235], Loss: 6.7380\n",
      "Epoch [57/100], Step [25200/6235], Loss: 0.5603\n",
      "Epoch [57/100], Step [25300/6235], Loss: 0.5737\n",
      "Epoch [57/100], Step [25400/6235], Loss: 8.2306\n",
      "Epoch [57/100], Step [25500/6235], Loss: 6.9125\n",
      "Epoch [57/100], Step [25600/6235], Loss: 4.1392\n",
      "Epoch [57/100], Step [25700/6235], Loss: 0.3860\n",
      "Epoch [57/100], Step [25800/6235], Loss: 0.1130\n",
      "Epoch [57/100], Step [25900/6235], Loss: 9.2877\n",
      "Epoch [57/100], Step [26000/6235], Loss: 7.0889\n",
      "Epoch [57/100], Step [26100/6235], Loss: 0.4548\n",
      "Epoch [57/100], Step [26200/6235], Loss: 0.3766\n",
      "Epoch [57/100], Step [26300/6235], Loss: 4.8919\n",
      "Epoch [57/100], Step [26400/6235], Loss: 0.0902\n",
      "Epoch [57/100], Step [26500/6235], Loss: 0.0209\n",
      "Epoch [57/100], Step [26600/6235], Loss: 1.7537\n",
      "Epoch [57/100], Step [26700/6235], Loss: 0.3963\n",
      "Epoch [57/100], Step [26800/6235], Loss: 0.2066\n",
      "Epoch [57/100], Step [26900/6235], Loss: 0.0005\n",
      "Epoch [57/100], Step [27000/6235], Loss: 14.7071\n",
      "Epoch [57/100], Step [27100/6235], Loss: 0.0565\n",
      "Epoch [57/100], Step [27200/6235], Loss: 0.0299\n",
      "Epoch [57/100], Step [27300/6235], Loss: 0.2339\n",
      "Epoch [57/100], Step [27400/6235], Loss: 0.7778\n",
      "Epoch [57/100], Step [27500/6235], Loss: 10.9507\n",
      "Epoch [57/100], Step [27600/6235], Loss: 0.8125\n",
      "Epoch [57/100], Step [27700/6235], Loss: 0.7805\n",
      "Epoch [57/100], Step [27800/6235], Loss: 6.3152\n",
      "Epoch [57/100], Step [27900/6235], Loss: 1.4433\n",
      "Epoch [57/100], Step [28000/6235], Loss: 111.4116\n",
      "Epoch [57/100], Step [28100/6235], Loss: 6.1074\n",
      "Epoch [57/100], Step [28200/6235], Loss: 33.8342\n",
      "Epoch [57/100], Step [28300/6235], Loss: 2.2295\n",
      "Epoch [57/100], Step [28400/6235], Loss: 28.2526\n",
      "Epoch [57/100], Step [28500/6235], Loss: 4.9090\n",
      "Epoch [57/100], Step [28600/6235], Loss: 0.1510\n",
      "Epoch [57/100], Step [28700/6235], Loss: 5.5180\n",
      "Epoch [57/100], Step [28800/6235], Loss: 0.6513\n",
      "Epoch [57/100], Step [28900/6235], Loss: 70.8766\n",
      "Epoch [57/100], Step [29000/6235], Loss: 12.6583\n",
      "Epoch [57/100], Step [29100/6235], Loss: 0.2458\n",
      "Epoch [57/100], Step [29200/6235], Loss: 1.1959\n",
      "Epoch [57/100], Step [29300/6235], Loss: 8.6924\n",
      "Epoch [57/100], Step [29400/6235], Loss: 0.2353\n",
      "Epoch [57/100], Step [29500/6235], Loss: 0.0650\n",
      "Epoch [57/100], Step [29600/6235], Loss: 0.8361\n",
      "Epoch [57/100], Step [29700/6235], Loss: 1.2125\n",
      "Epoch [57/100], Step [29800/6235], Loss: 1.6203\n",
      "Epoch [57/100], Step [29900/6235], Loss: 1.2026\n",
      "Epoch [57/100], Step [30000/6235], Loss: 3.6542\n",
      "Epoch [57/100], Step [30100/6235], Loss: 11.7198\n",
      "Epoch [57/100], Step [30200/6235], Loss: 0.9567\n",
      "Epoch [57/100], Step [30300/6235], Loss: 0.0084\n",
      "Epoch [57/100], Step [30400/6235], Loss: 0.9513\n",
      "Epoch [57/100], Step [30500/6235], Loss: 3.1770\n",
      "Epoch [57/100], Step [30600/6235], Loss: 1.7576\n",
      "Epoch [57/100], Step [30700/6235], Loss: 0.4912\n",
      "Epoch [57/100], Step [30800/6235], Loss: 0.4944\n",
      "Epoch [57/100], Step [30900/6235], Loss: 3.7233\n",
      "Epoch [57/100], Step [31000/6235], Loss: 0.1800\n",
      "Epoch [57/100], Step [31100/6235], Loss: 0.0363\n",
      "Epoch [57/100], Step [31200/6235], Loss: 5.4262\n",
      "Epoch [57/100], Step [31300/6235], Loss: 1.2819\n",
      "Epoch [57/100], Step [31400/6235], Loss: 0.3312\n",
      "Epoch [57/100], Step [31500/6235], Loss: 0.6545\n",
      "Epoch [57/100], Step [31600/6235], Loss: 16.4161\n",
      "Epoch [57/100], Step [31700/6235], Loss: 29.0398\n",
      "Epoch [57/100], Step [31800/6235], Loss: 0.1345\n",
      "Epoch [57/100], Step [31900/6235], Loss: 997.4611\n",
      "Epoch [57/100], Step [32000/6235], Loss: 113.8759\n",
      "Epoch [57/100], Step [32100/6235], Loss: 4.1627\n",
      "Epoch [57/100], Step [32200/6235], Loss: 143.3190\n",
      "Epoch [57/100], Step [32300/6235], Loss: 2.4317\n",
      "Epoch [57/100], Step [32400/6235], Loss: 1.6082\n",
      "Epoch [57/100], Step [32500/6235], Loss: 14.2508\n",
      "Epoch [57/100], Step [32600/6235], Loss: 0.4602\n",
      "Epoch [57/100], Step [32700/6235], Loss: 90.4404\n",
      "Epoch [57/100], Step [32800/6235], Loss: 6.2424\n",
      "Epoch [57/100], Step [32900/6235], Loss: 0.0842\n",
      "Epoch [57/100], Step [33000/6235], Loss: 0.2426\n",
      "Epoch [57/100], Step [33100/6235], Loss: 0.4666\n",
      "Epoch [57/100], Step [33200/6235], Loss: 1.0136\n",
      "Epoch [57/100], Step [33300/6235], Loss: 1.1423\n",
      "Epoch [57/100], Step [33400/6235], Loss: 155.3783\n",
      "Epoch [57/100], Step [33500/6235], Loss: 1.3554\n",
      "Epoch [57/100], Step [33600/6235], Loss: 8.0258\n",
      "Epoch [57/100], Step [33700/6235], Loss: 9.1213\n",
      "Epoch [57/100], Step [33800/6235], Loss: 1.1034\n",
      "Epoch [57/100], Step [33900/6235], Loss: 30.4025\n",
      "Epoch [57/100], Step [34000/6235], Loss: 0.1474\n",
      "Epoch [57/100], Step [34100/6235], Loss: 0.6648\n",
      "Epoch [57/100], Step [34200/6235], Loss: 2.1563\n",
      "Epoch [57/100], Step [34300/6235], Loss: 2.9088\n",
      "Epoch [57/100], Step [34400/6235], Loss: 0.1064\n",
      "Epoch [57/100], Step [34500/6235], Loss: 50.1787\n",
      "Epoch [57/100], Step [34600/6235], Loss: 1.7993\n",
      "Epoch [57/100], Step [34700/6235], Loss: 3.5042\n",
      "Epoch [57/100], Step [34800/6235], Loss: 11.0157\n",
      "Epoch [57/100], Step [34900/6235], Loss: 46.8331\n",
      "Epoch [57/100], Step [35000/6235], Loss: 2.1867\n",
      "Epoch [57/100], Step [35100/6235], Loss: 3.7518\n",
      "Epoch [57/100], Step [35200/6235], Loss: 0.2195\n",
      "Epoch [57/100], Step [35300/6235], Loss: 2.1626\n",
      "Epoch [57/100], Step [35400/6235], Loss: 0.3885\n",
      "Epoch [57/100], Step [35500/6235], Loss: 0.6052\n",
      "Epoch [57/100], Step [35600/6235], Loss: 1.6630\n",
      "Epoch [57/100], Step [35700/6235], Loss: 4.3865\n",
      "Epoch [57/100], Step [35800/6235], Loss: 0.9936\n",
      "Epoch [57/100], Step [35900/6235], Loss: 2.7711\n",
      "Epoch [57/100], Step [36000/6235], Loss: 0.0367\n",
      "Epoch [57/100], Step [36100/6235], Loss: 0.0505\n",
      "Epoch [57/100], Step [36200/6235], Loss: 33.6247\n",
      "Epoch [57/100], Step [36300/6235], Loss: 1.9835\n",
      "Epoch [57/100], Step [36400/6235], Loss: 3.1518\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [57/100], Step [36500/6235], Loss: 7.2176\n",
      "Epoch [57/100], Step [36600/6235], Loss: 0.0742\n",
      "Epoch [57/100], Step [36700/6235], Loss: 0.5796\n",
      "Epoch [57/100], Step [36800/6235], Loss: 3.6658\n",
      "Epoch [57/100], Step [36900/6235], Loss: 13.4278\n",
      "Epoch [57/100], Step [37000/6235], Loss: 0.9869\n",
      "Epoch [57/100], Step [37100/6235], Loss: 2.2314\n",
      "Epoch [57/100], Step [37200/6235], Loss: 0.0355\n",
      "Epoch [57/100], Step [37300/6235], Loss: 0.0641\n",
      "Epoch [57/100], Step [37400/6235], Loss: 0.1632\n",
      "Epoch [57/100], Step [37500/6235], Loss: 7.4955\n",
      "Epoch [57/100], Step [37600/6235], Loss: 12.1132\n",
      "Epoch [57/100], Step [37700/6235], Loss: 2.2995\n",
      "Epoch [57/100], Step [37800/6235], Loss: 5.2181\n",
      "Epoch [57/100], Step [37900/6235], Loss: 3.5460\n",
      "Epoch [57/100], Step [38000/6235], Loss: 0.6156\n",
      "Epoch [57/100], Step [38100/6235], Loss: 4.3208\n",
      "Epoch [57/100], Step [38200/6235], Loss: 1.7401\n",
      "Epoch [57/100], Step [38300/6235], Loss: 0.2976\n",
      "Epoch [57/100], Step [38400/6235], Loss: 0.0749\n",
      "Epoch [57/100], Step [38500/6235], Loss: 1.4517\n",
      "Epoch [57/100], Step [38600/6235], Loss: 0.3218\n",
      "Epoch [57/100], Step [38700/6235], Loss: 0.2517\n",
      "Epoch [57/100], Step [38800/6235], Loss: 0.1058\n",
      "Epoch [57/100], Step [38900/6235], Loss: 6.8922\n",
      "Epoch [57/100], Step [39000/6235], Loss: 6.2390\n",
      "Epoch [57/100], Step [39100/6235], Loss: 20.8918\n",
      "Epoch [57/100], Step [39200/6235], Loss: 0.6401\n",
      "Epoch [57/100], Step [39300/6235], Loss: 46.2285\n",
      "Epoch [57/100], Step [39400/6235], Loss: 20.9730\n",
      "Epoch [57/100], Step [39500/6235], Loss: 75.2142\n",
      "Epoch [57/100], Step [39600/6235], Loss: 8.2502\n",
      "Epoch [57/100], Step [39700/6235], Loss: 147.2901\n",
      "Epoch [57/100], Step [39800/6235], Loss: 140.8338\n",
      "Epoch [57/100], Step [39900/6235], Loss: 1.8471\n",
      "Epoch [57/100], Step [40000/6235], Loss: 0.8534\n",
      "Epoch [57/100], Step [40100/6235], Loss: 31.0084\n",
      "Epoch [57/100], Step [40200/6235], Loss: 0.5002\n",
      "Epoch [57/100], Step [40300/6235], Loss: 0.7194\n",
      "Epoch [57/100], Step [40400/6235], Loss: 2.0904\n",
      "Epoch [57/100], Step [40500/6235], Loss: 2.3730\n",
      "Epoch [57/100], Step [40600/6235], Loss: 0.2163\n",
      "Epoch [57/100], Step [40700/6235], Loss: 7.5765\n",
      "Epoch [57/100], Step [40800/6235], Loss: 1.1744\n",
      "Epoch [57/100], Step [40900/6235], Loss: 0.1761\n",
      "Epoch [57/100], Step [41000/6235], Loss: 46.6583\n",
      "Epoch [57/100], Step [41100/6235], Loss: 9.0320\n",
      "Epoch [57/100], Step [41200/6235], Loss: 15.0625\n",
      "Epoch [57/100], Step [41300/6235], Loss: 2.5729\n",
      "Epoch [57/100], Step [41400/6235], Loss: 1.1950\n",
      "Epoch [57/100], Step [41500/6235], Loss: 0.2962\n",
      "Epoch [57/100], Step [41600/6235], Loss: 0.4619\n",
      "Epoch [57/100], Step [41700/6235], Loss: 2.3075\n",
      "Epoch [57/100], Step [41800/6235], Loss: 3.9849\n",
      "Epoch [57/100], Step [41900/6235], Loss: 3.2715\n",
      "Epoch [57/100], Step [42000/6235], Loss: 2.9665\n",
      "Epoch [57/100], Step [42100/6235], Loss: 6.3614\n",
      "Epoch [57/100], Step [42200/6235], Loss: 5.2621\n",
      "Epoch [57/100], Step [42300/6235], Loss: 0.8656\n",
      "Epoch [57/100], Step [42400/6235], Loss: 2.1844\n",
      "Epoch [57/100], Step [42500/6235], Loss: 0.5344\n",
      "Epoch [57/100], Step [42600/6235], Loss: 0.6338\n",
      "Epoch [57/100], Step [42700/6235], Loss: 0.2788\n",
      "Epoch [57/100], Step [42800/6235], Loss: 1.8037\n",
      "Epoch [57/100], Step [42900/6235], Loss: 4.2857\n",
      "Epoch [57/100], Step [43000/6235], Loss: 0.2243\n",
      "Epoch [57/100], Step [43100/6235], Loss: 0.9719\n",
      "Epoch [57/100], Step [43200/6235], Loss: 0.7597\n",
      "Epoch [57/100], Step [43300/6235], Loss: 9.6003\n",
      "Epoch [57/100], Step [43400/6235], Loss: 8.0953\n",
      "Epoch [57/100], Step [43500/6235], Loss: 8.5127\n",
      "Epoch [57/100], Step [43600/6235], Loss: 26.6442\n",
      "Epoch [57/100], Step [43700/6235], Loss: 34.3321\n",
      "Epoch [57/100], Step [43800/6235], Loss: 0.3252\n",
      "Epoch [57/100], Step [43900/6235], Loss: 1.2038\n",
      "Epoch [57/100], Step [44000/6235], Loss: 20.0848\n",
      "Epoch [57/100], Step [44100/6235], Loss: 1.5386\n",
      "Epoch [57/100], Step [44200/6235], Loss: 37.1449\n",
      "Epoch [57/100], Step [44300/6235], Loss: 35.7921\n",
      "Epoch [57/100], Step [44400/6235], Loss: 3.2209\n",
      "Epoch [57/100], Step [44500/6235], Loss: 3.1731\n",
      "Epoch [57/100], Step [44600/6235], Loss: 14.4706\n",
      "Epoch [57/100], Step [44700/6235], Loss: 20.5270\n",
      "Epoch [57/100], Step [44800/6235], Loss: 0.6303\n",
      "Epoch [57/100], Step [44900/6235], Loss: 0.9442\n",
      "Epoch [57/100], Step [45000/6235], Loss: 3.5212\n",
      "Epoch [57/100], Step [45100/6235], Loss: 36.8185\n",
      "Epoch [57/100], Step [45200/6235], Loss: 0.3127\n",
      "Epoch [57/100], Step [45300/6235], Loss: 41.6263\n",
      "Epoch [57/100], Step [45400/6235], Loss: 8.2004\n",
      "Epoch [57/100], Step [45500/6235], Loss: 0.1479\n",
      "Epoch [57/100], Step [45600/6235], Loss: 0.5116\n",
      "Epoch [57/100], Step [45700/6235], Loss: 10.6058\n",
      "Epoch [57/100], Step [45800/6235], Loss: 321.7564\n",
      "Epoch [57/100], Step [45900/6235], Loss: 10.0772\n",
      "Epoch [57/100], Step [46000/6235], Loss: 2.2191\n",
      "Epoch [57/100], Step [46100/6235], Loss: 7.8157\n",
      "Epoch [57/100], Step [46200/6235], Loss: 4.1224\n",
      "Epoch [57/100], Step [46300/6235], Loss: 42.1386\n",
      "Epoch [57/100], Step [46400/6235], Loss: 2.1191\n",
      "Epoch [57/100], Step [46500/6235], Loss: 64.4934\n",
      "Epoch [57/100], Step [46600/6235], Loss: 5.2183\n",
      "Epoch [57/100], Step [46700/6235], Loss: 6.2494\n",
      "Epoch [57/100], Step [46800/6235], Loss: 27.0251\n",
      "Epoch [57/100], Step [46900/6235], Loss: 21.7191\n",
      "Epoch [57/100], Step [47000/6235], Loss: 2.4107\n",
      "Epoch [57/100], Step [47100/6235], Loss: 117.7048\n",
      "Epoch [57/100], Step [47200/6235], Loss: 52.3415\n",
      "Epoch [57/100], Step [47300/6235], Loss: 10.8453\n",
      "Epoch [57/100], Step [47400/6235], Loss: 468.0729\n",
      "Epoch [57/100], Step [47500/6235], Loss: 4.1113\n",
      "Epoch [57/100], Step [47600/6235], Loss: 17.4688\n",
      "Epoch [57/100], Step [47700/6235], Loss: 20.1354\n",
      "Epoch [57/100], Step [47800/6235], Loss: 27.0455\n",
      "Epoch [57/100], Step [47900/6235], Loss: 15.3798\n",
      "Epoch [57/100], Step [48000/6235], Loss: 22.7079\n",
      "Epoch [57/100], Step [48100/6235], Loss: 65.5244\n",
      "Epoch [57/100], Step [48200/6235], Loss: 155.7392\n",
      "Epoch [57/100], Step [48300/6235], Loss: 531.0804\n",
      "Epoch [57/100], Step [48400/6235], Loss: 11.0993\n",
      "Epoch [57/100], Step [48500/6235], Loss: 46.6976\n",
      "Epoch [57/100], Step [48600/6235], Loss: 100.3339\n",
      "Epoch [57/100], Step [48700/6235], Loss: 0.7583\n",
      "Epoch [57/100], Step [48800/6235], Loss: 237.4395\n",
      "Epoch [57/100], Step [48900/6235], Loss: 33.7733\n",
      "Epoch [57/100], Step [49000/6235], Loss: 245.4634\n",
      "Epoch [57/100], Step [49100/6235], Loss: 2105.4177\n",
      "Epoch [57/100], Step [49200/6235], Loss: 661.8470\n",
      "Epoch [57/100], Step [49300/6235], Loss: 1224.9280\n",
      "Epoch [57/100], Step [49400/6235], Loss: 8.6920\n",
      "Epoch [57/100], Step [49500/6235], Loss: 1.5466\n",
      "Epoch [57/100], Step [49600/6235], Loss: 510.6839\n",
      "Epoch [57/100], Step [49700/6235], Loss: 2074.4197\n",
      "Epoch [57/100], Step [49800/6235], Loss: 2566.9668\n",
      "Epoch [58/100], Step [100/6235], Loss: 40.4121\n",
      "Epoch [58/100], Step [200/6235], Loss: 0.1903\n",
      "Epoch [58/100], Step [300/6235], Loss: 0.0040\n",
      "Epoch [58/100], Step [400/6235], Loss: 0.0014\n",
      "Epoch [58/100], Step [500/6235], Loss: 2.2172\n",
      "Epoch [58/100], Step [600/6235], Loss: 0.0398\n",
      "Epoch [58/100], Step [700/6235], Loss: 0.6172\n",
      "Epoch [58/100], Step [800/6235], Loss: 0.0906\n",
      "Epoch [58/100], Step [900/6235], Loss: 0.0586\n",
      "Epoch [58/100], Step [1000/6235], Loss: 0.0369\n",
      "Epoch [58/100], Step [1100/6235], Loss: 0.1835\n",
      "Epoch [58/100], Step [1200/6235], Loss: 0.1776\n",
      "Epoch [58/100], Step [1300/6235], Loss: 0.0534\n",
      "Epoch [58/100], Step [1400/6235], Loss: 0.4886\n",
      "Epoch [58/100], Step [1500/6235], Loss: 0.0093\n",
      "Epoch [58/100], Step [1600/6235], Loss: 0.2733\n",
      "Epoch [58/100], Step [1700/6235], Loss: 0.1402\n",
      "Epoch [58/100], Step [1800/6235], Loss: 0.2902\n",
      "Epoch [58/100], Step [1900/6235], Loss: 0.4526\n",
      "Epoch [58/100], Step [2000/6235], Loss: 3.2988\n",
      "Epoch [58/100], Step [2100/6235], Loss: 5.2709\n",
      "Epoch [58/100], Step [2200/6235], Loss: 6.7529\n",
      "Epoch [58/100], Step [2300/6235], Loss: 3.0826\n",
      "Epoch [58/100], Step [2400/6235], Loss: 1.7847\n",
      "Epoch [58/100], Step [2500/6235], Loss: 75.2944\n",
      "Epoch [58/100], Step [2600/6235], Loss: 13.4290\n",
      "Epoch [58/100], Step [2700/6235], Loss: 6.9871\n",
      "Epoch [58/100], Step [2800/6235], Loss: 53.0101\n",
      "Epoch [58/100], Step [2900/6235], Loss: 18.8346\n",
      "Epoch [58/100], Step [3000/6235], Loss: 1.8590\n",
      "Epoch [58/100], Step [3100/6235], Loss: 63.5197\n",
      "Epoch [58/100], Step [3200/6235], Loss: 50.2120\n",
      "Epoch [58/100], Step [3300/6235], Loss: 11.1126\n",
      "Epoch [58/100], Step [3400/6235], Loss: 2.8964\n",
      "Epoch [58/100], Step [3500/6235], Loss: 51.5782\n",
      "Epoch [58/100], Step [3600/6235], Loss: 2.5220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Step [3700/6235], Loss: 0.0802\n",
      "Epoch [58/100], Step [3800/6235], Loss: 0.0462\n",
      "Epoch [58/100], Step [3900/6235], Loss: 0.0333\n",
      "Epoch [58/100], Step [4000/6235], Loss: 0.1014\n",
      "Epoch [58/100], Step [4100/6235], Loss: 9.4359\n",
      "Epoch [58/100], Step [4200/6235], Loss: 2.7164\n",
      "Epoch [58/100], Step [4300/6235], Loss: 6.9676\n",
      "Epoch [58/100], Step [4400/6235], Loss: 0.8717\n",
      "Epoch [58/100], Step [4500/6235], Loss: 53.8044\n",
      "Epoch [58/100], Step [4600/6235], Loss: 0.7227\n",
      "Epoch [58/100], Step [4700/6235], Loss: 0.2389\n",
      "Epoch [58/100], Step [4800/6235], Loss: 9.0029\n",
      "Epoch [58/100], Step [4900/6235], Loss: 0.3341\n",
      "Epoch [58/100], Step [5000/6235], Loss: 0.0608\n",
      "Epoch [58/100], Step [5100/6235], Loss: 1.9018\n",
      "Epoch [58/100], Step [5200/6235], Loss: 3.1428\n",
      "Epoch [58/100], Step [5300/6235], Loss: 33.1481\n",
      "Epoch [58/100], Step [5400/6235], Loss: 4.7454\n",
      "Epoch [58/100], Step [5500/6235], Loss: 0.4777\n",
      "Epoch [58/100], Step [5600/6235], Loss: 0.3947\n",
      "Epoch [58/100], Step [5700/6235], Loss: 0.2205\n",
      "Epoch [58/100], Step [5800/6235], Loss: 2.9400\n",
      "Epoch [58/100], Step [5900/6235], Loss: 0.4973\n",
      "Epoch [58/100], Step [6000/6235], Loss: 0.8940\n",
      "Epoch [58/100], Step [6100/6235], Loss: 0.5352\n",
      "Epoch [58/100], Step [6200/6235], Loss: 4.9296\n",
      "Epoch [58/100], Step [6300/6235], Loss: 0.4854\n",
      "Epoch [58/100], Step [6400/6235], Loss: 0.0873\n",
      "Epoch [58/100], Step [6500/6235], Loss: 4.2507\n",
      "Epoch [58/100], Step [6600/6235], Loss: 18.7505\n",
      "Epoch [58/100], Step [6700/6235], Loss: 1.4465\n",
      "Epoch [58/100], Step [6800/6235], Loss: 1.2350\n",
      "Epoch [58/100], Step [6900/6235], Loss: 0.9459\n",
      "Epoch [58/100], Step [7000/6235], Loss: 0.2636\n",
      "Epoch [58/100], Step [7100/6235], Loss: 0.6446\n",
      "Epoch [58/100], Step [7200/6235], Loss: 0.2737\n",
      "Epoch [58/100], Step [7300/6235], Loss: 0.6036\n",
      "Epoch [58/100], Step [7400/6235], Loss: 0.2415\n",
      "Epoch [58/100], Step [7500/6235], Loss: 0.2270\n",
      "Epoch [58/100], Step [7600/6235], Loss: 0.7252\n",
      "Epoch [58/100], Step [7700/6235], Loss: 18.0323\n",
      "Epoch [58/100], Step [7800/6235], Loss: 1.9925\n",
      "Epoch [58/100], Step [7900/6235], Loss: 0.9962\n",
      "Epoch [58/100], Step [8000/6235], Loss: 0.3917\n",
      "Epoch [58/100], Step [8100/6235], Loss: 1.9054\n",
      "Epoch [58/100], Step [8200/6235], Loss: 10.4720\n",
      "Epoch [58/100], Step [8300/6235], Loss: 10.0704\n",
      "Epoch [58/100], Step [8400/6235], Loss: 616.0100\n",
      "Epoch [58/100], Step [8500/6235], Loss: 16.9447\n",
      "Epoch [58/100], Step [8600/6235], Loss: 18.8206\n",
      "Epoch [58/100], Step [8700/6235], Loss: 33.2029\n",
      "Epoch [58/100], Step [8800/6235], Loss: 542.0996\n",
      "Epoch [58/100], Step [8900/6235], Loss: 116.6256\n",
      "Epoch [58/100], Step [9000/6235], Loss: 524.9582\n",
      "Epoch [58/100], Step [9100/6235], Loss: 1085.3444\n",
      "Epoch [58/100], Step [9200/6235], Loss: 2831.3462\n",
      "Epoch [58/100], Step [9300/6235], Loss: 295.8224\n",
      "Epoch [58/100], Step [9400/6235], Loss: 20.9077\n",
      "Epoch [58/100], Step [9500/6235], Loss: 2439.4602\n",
      "Epoch [58/100], Step [9600/6235], Loss: 508.0417\n",
      "Epoch [58/100], Step [9700/6235], Loss: 4.4475\n",
      "Epoch [58/100], Step [9800/6235], Loss: 3389.5215\n",
      "Epoch [58/100], Step [9900/6235], Loss: 83.6057\n",
      "Epoch [58/100], Step [10000/6235], Loss: 321.0805\n",
      "Epoch [58/100], Step [10100/6235], Loss: 2.1106\n",
      "Epoch [58/100], Step [10200/6235], Loss: 1242.2531\n",
      "Epoch [58/100], Step [10300/6235], Loss: 54.4008\n",
      "Epoch [58/100], Step [10400/6235], Loss: 9.8712\n",
      "Epoch [58/100], Step [10500/6235], Loss: 1.5348\n",
      "Epoch [58/100], Step [10600/6235], Loss: 519.1792\n",
      "Epoch [58/100], Step [10700/6235], Loss: 16.4879\n",
      "Epoch [58/100], Step [10800/6235], Loss: 115.5831\n",
      "Epoch [58/100], Step [10900/6235], Loss: 91.6274\n",
      "Epoch [58/100], Step [11000/6235], Loss: 298.2290\n",
      "Epoch [58/100], Step [11100/6235], Loss: 34.6382\n",
      "Epoch [58/100], Step [11200/6235], Loss: 6.7733\n",
      "Epoch [58/100], Step [11300/6235], Loss: 107.7734\n",
      "Epoch [58/100], Step [11400/6235], Loss: 4.3385\n",
      "Epoch [58/100], Step [11500/6235], Loss: 7.5621\n",
      "Epoch [58/100], Step [11600/6235], Loss: 5.0207\n",
      "Epoch [58/100], Step [11700/6235], Loss: 40.6620\n",
      "Epoch [58/100], Step [11800/6235], Loss: 392.1096\n",
      "Epoch [58/100], Step [11900/6235], Loss: 13.6069\n",
      "Epoch [58/100], Step [12000/6235], Loss: 768.4435\n",
      "Epoch [58/100], Step [12100/6235], Loss: 242.1388\n",
      "Epoch [58/100], Step [12200/6235], Loss: 6.7398\n",
      "Epoch [58/100], Step [12300/6235], Loss: 2.5523\n",
      "Epoch [58/100], Step [12400/6235], Loss: 320.7122\n",
      "Epoch [58/100], Step [12500/6235], Loss: 27.5138\n",
      "Epoch [58/100], Step [12600/6235], Loss: 32.7830\n",
      "Epoch [58/100], Step [12700/6235], Loss: 9.1212\n",
      "Epoch [58/100], Step [12800/6235], Loss: 7.7361\n",
      "Epoch [58/100], Step [12900/6235], Loss: 46.1856\n",
      "Epoch [58/100], Step [13000/6235], Loss: 1.5106\n",
      "Epoch [58/100], Step [13100/6235], Loss: 72.6107\n",
      "Epoch [58/100], Step [13200/6235], Loss: 14.3743\n",
      "Epoch [58/100], Step [13300/6235], Loss: 36.2782\n",
      "Epoch [58/100], Step [13400/6235], Loss: 253.0696\n",
      "Epoch [58/100], Step [13500/6235], Loss: 2.7543\n",
      "Epoch [58/100], Step [13600/6235], Loss: 2.4038\n",
      "Epoch [58/100], Step [13700/6235], Loss: 173.1523\n",
      "Epoch [58/100], Step [13800/6235], Loss: 98.1216\n",
      "Epoch [58/100], Step [13900/6235], Loss: 3.6952\n",
      "Epoch [58/100], Step [14000/6235], Loss: 9.2716\n",
      "Epoch [58/100], Step [14100/6235], Loss: 22.2461\n",
      "Epoch [58/100], Step [14200/6235], Loss: 117.9844\n",
      "Epoch [58/100], Step [14300/6235], Loss: 76.9842\n",
      "Epoch [58/100], Step [14400/6235], Loss: 38.4356\n",
      "Epoch [58/100], Step [14500/6235], Loss: 38.4396\n",
      "Epoch [58/100], Step [14600/6235], Loss: 0.2688\n",
      "Epoch [58/100], Step [14700/6235], Loss: 39.8288\n",
      "Epoch [58/100], Step [14800/6235], Loss: 33.8319\n",
      "Epoch [58/100], Step [14900/6235], Loss: 0.9255\n",
      "Epoch [58/100], Step [15000/6235], Loss: 1.7205\n",
      "Epoch [58/100], Step [15100/6235], Loss: 0.5035\n",
      "Epoch [58/100], Step [15200/6235], Loss: 0.1027\n",
      "Epoch [58/100], Step [15300/6235], Loss: 33.2935\n",
      "Epoch [58/100], Step [15400/6235], Loss: 94.4364\n",
      "Epoch [58/100], Step [15500/6235], Loss: 10.8153\n",
      "Epoch [58/100], Step [15600/6235], Loss: 16.3611\n",
      "Epoch [58/100], Step [15700/6235], Loss: 95.4066\n",
      "Epoch [58/100], Step [15800/6235], Loss: 9.6509\n",
      "Epoch [58/100], Step [15900/6235], Loss: 0.3511\n",
      "Epoch [58/100], Step [16000/6235], Loss: 130.4565\n",
      "Epoch [58/100], Step [16100/6235], Loss: 1.0566\n",
      "Epoch [58/100], Step [16200/6235], Loss: 0.8123\n",
      "Epoch [58/100], Step [16300/6235], Loss: 10.9861\n",
      "Epoch [58/100], Step [16400/6235], Loss: 36.2497\n",
      "Epoch [58/100], Step [16500/6235], Loss: 698.9771\n",
      "Epoch [58/100], Step [16600/6235], Loss: 13.0990\n",
      "Epoch [58/100], Step [16700/6235], Loss: 0.5961\n",
      "Epoch [58/100], Step [16800/6235], Loss: 10.8333\n",
      "Epoch [58/100], Step [16900/6235], Loss: 0.1705\n",
      "Epoch [58/100], Step [17000/6235], Loss: 0.2604\n",
      "Epoch [58/100], Step [17100/6235], Loss: 0.5163\n",
      "Epoch [58/100], Step [17200/6235], Loss: 310.2979\n",
      "Epoch [58/100], Step [17300/6235], Loss: 20.3561\n",
      "Epoch [58/100], Step [17400/6235], Loss: 34.1145\n",
      "Epoch [58/100], Step [17500/6235], Loss: 0.8478\n",
      "Epoch [58/100], Step [17600/6235], Loss: 4.7524\n",
      "Epoch [58/100], Step [17700/6235], Loss: 6.7149\n",
      "Epoch [58/100], Step [17800/6235], Loss: 21.8003\n",
      "Epoch [58/100], Step [17900/6235], Loss: 10.8390\n",
      "Epoch [58/100], Step [18000/6235], Loss: 20.8576\n",
      "Epoch [58/100], Step [18100/6235], Loss: 15.2716\n",
      "Epoch [58/100], Step [18200/6235], Loss: 0.4716\n",
      "Epoch [58/100], Step [18300/6235], Loss: 1.2080\n",
      "Epoch [58/100], Step [18400/6235], Loss: 1.4569\n",
      "Epoch [58/100], Step [18500/6235], Loss: 29.4878\n",
      "Epoch [58/100], Step [18600/6235], Loss: 4.6136\n",
      "Epoch [58/100], Step [18700/6235], Loss: 1.2763\n",
      "Epoch [58/100], Step [18800/6235], Loss: 137.9246\n",
      "Epoch [58/100], Step [18900/6235], Loss: 72.0282\n",
      "Epoch [58/100], Step [19000/6235], Loss: 3.0040\n",
      "Epoch [58/100], Step [19100/6235], Loss: 38.2773\n",
      "Epoch [58/100], Step [19200/6235], Loss: 1.7319\n",
      "Epoch [58/100], Step [19300/6235], Loss: 1.0771\n",
      "Epoch [58/100], Step [19400/6235], Loss: 226.7238\n",
      "Epoch [58/100], Step [19500/6235], Loss: 40.2421\n",
      "Epoch [58/100], Step [19600/6235], Loss: 34.9900\n",
      "Epoch [58/100], Step [19700/6235], Loss: 4.2848\n",
      "Epoch [58/100], Step [19800/6235], Loss: 5.0892\n",
      "Epoch [58/100], Step [19900/6235], Loss: 0.0798\n",
      "Epoch [58/100], Step [20000/6235], Loss: 68.5329\n",
      "Epoch [58/100], Step [20100/6235], Loss: 4.2665\n",
      "Epoch [58/100], Step [20200/6235], Loss: 0.6755\n",
      "Epoch [58/100], Step [20300/6235], Loss: 1.2705\n",
      "Epoch [58/100], Step [20400/6235], Loss: 7.8695\n",
      "Epoch [58/100], Step [20500/6235], Loss: 58.6430\n",
      "Epoch [58/100], Step [20600/6235], Loss: 326.1417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Step [20700/6235], Loss: 22.8521\n",
      "Epoch [58/100], Step [20800/6235], Loss: 3.2651\n",
      "Epoch [58/100], Step [20900/6235], Loss: 24.1470\n",
      "Epoch [58/100], Step [21000/6235], Loss: 13.2865\n",
      "Epoch [58/100], Step [21100/6235], Loss: 5.3072\n",
      "Epoch [58/100], Step [21200/6235], Loss: 0.3208\n",
      "Epoch [58/100], Step [21300/6235], Loss: 0.0508\n",
      "Epoch [58/100], Step [21400/6235], Loss: 3.6873\n",
      "Epoch [58/100], Step [21500/6235], Loss: 0.4731\n",
      "Epoch [58/100], Step [21600/6235], Loss: 29.1753\n",
      "Epoch [58/100], Step [21700/6235], Loss: 0.1883\n",
      "Epoch [58/100], Step [21800/6235], Loss: 4.1424\n",
      "Epoch [58/100], Step [21900/6235], Loss: 1.5499\n",
      "Epoch [58/100], Step [22000/6235], Loss: 9.4826\n",
      "Epoch [58/100], Step [22100/6235], Loss: 0.1162\n",
      "Epoch [58/100], Step [22200/6235], Loss: 2.6503\n",
      "Epoch [58/100], Step [22300/6235], Loss: 0.2159\n",
      "Epoch [58/100], Step [22400/6235], Loss: 1.8745\n",
      "Epoch [58/100], Step [22500/6235], Loss: 152.6440\n",
      "Epoch [58/100], Step [22600/6235], Loss: 33.8258\n",
      "Epoch [58/100], Step [22700/6235], Loss: 1.5329\n",
      "Epoch [58/100], Step [22800/6235], Loss: 10.9642\n",
      "Epoch [58/100], Step [22900/6235], Loss: 16.6748\n",
      "Epoch [58/100], Step [23000/6235], Loss: 5.8298\n",
      "Epoch [58/100], Step [23100/6235], Loss: 9.2476\n",
      "Epoch [58/100], Step [23200/6235], Loss: 8.4271\n",
      "Epoch [58/100], Step [23300/6235], Loss: 19.2919\n",
      "Epoch [58/100], Step [23400/6235], Loss: 2.0549\n",
      "Epoch [58/100], Step [23500/6235], Loss: 0.0617\n",
      "Epoch [58/100], Step [23600/6235], Loss: 130.0577\n",
      "Epoch [58/100], Step [23700/6235], Loss: 2.4712\n",
      "Epoch [58/100], Step [23800/6235], Loss: 0.9500\n",
      "Epoch [58/100], Step [23900/6235], Loss: 4.2459\n",
      "Epoch [58/100], Step [24000/6235], Loss: 0.4080\n",
      "Epoch [58/100], Step [24100/6235], Loss: 0.5784\n",
      "Epoch [58/100], Step [24200/6235], Loss: 20.9900\n",
      "Epoch [58/100], Step [24300/6235], Loss: 0.8400\n",
      "Epoch [58/100], Step [24400/6235], Loss: 1.1981\n",
      "Epoch [58/100], Step [24500/6235], Loss: 0.3845\n",
      "Epoch [58/100], Step [24600/6235], Loss: 0.0373\n",
      "Epoch [58/100], Step [24700/6235], Loss: 0.2484\n",
      "Epoch [58/100], Step [24800/6235], Loss: 0.3166\n",
      "Epoch [58/100], Step [24900/6235], Loss: 9.8394\n",
      "Epoch [58/100], Step [25000/6235], Loss: 12.1306\n",
      "Epoch [58/100], Step [25100/6235], Loss: 6.2600\n",
      "Epoch [58/100], Step [25200/6235], Loss: 0.4983\n",
      "Epoch [58/100], Step [25300/6235], Loss: 0.7685\n",
      "Epoch [58/100], Step [25400/6235], Loss: 6.4340\n",
      "Epoch [58/100], Step [25500/6235], Loss: 8.3694\n",
      "Epoch [58/100], Step [25600/6235], Loss: 6.4179\n",
      "Epoch [58/100], Step [25700/6235], Loss: 0.2499\n",
      "Epoch [58/100], Step [25800/6235], Loss: 0.0524\n",
      "Epoch [58/100], Step [25900/6235], Loss: 6.7097\n",
      "Epoch [58/100], Step [26000/6235], Loss: 2.9692\n",
      "Epoch [58/100], Step [26100/6235], Loss: 0.0416\n",
      "Epoch [58/100], Step [26200/6235], Loss: 1.2915\n",
      "Epoch [58/100], Step [26300/6235], Loss: 2.5548\n",
      "Epoch [58/100], Step [26400/6235], Loss: 0.2157\n",
      "Epoch [58/100], Step [26500/6235], Loss: 0.0208\n",
      "Epoch [58/100], Step [26600/6235], Loss: 0.7954\n",
      "Epoch [58/100], Step [26700/6235], Loss: 0.2435\n",
      "Epoch [58/100], Step [26800/6235], Loss: 0.1297\n",
      "Epoch [58/100], Step [26900/6235], Loss: 0.0197\n",
      "Epoch [58/100], Step [27000/6235], Loss: 15.9641\n",
      "Epoch [58/100], Step [27100/6235], Loss: 0.0486\n",
      "Epoch [58/100], Step [27200/6235], Loss: 0.0157\n",
      "Epoch [58/100], Step [27300/6235], Loss: 0.1323\n",
      "Epoch [58/100], Step [27400/6235], Loss: 0.6900\n",
      "Epoch [58/100], Step [27500/6235], Loss: 1.5931\n",
      "Epoch [58/100], Step [27600/6235], Loss: 0.9213\n",
      "Epoch [58/100], Step [27700/6235], Loss: 0.8892\n",
      "Epoch [58/100], Step [27800/6235], Loss: 5.2764\n",
      "Epoch [58/100], Step [27900/6235], Loss: 1.4399\n",
      "Epoch [58/100], Step [28000/6235], Loss: 191.8128\n",
      "Epoch [58/100], Step [28100/6235], Loss: 2.6353\n",
      "Epoch [58/100], Step [28200/6235], Loss: 22.8737\n",
      "Epoch [58/100], Step [28300/6235], Loss: 3.1005\n",
      "Epoch [58/100], Step [28400/6235], Loss: 27.6535\n",
      "Epoch [58/100], Step [28500/6235], Loss: 4.2060\n",
      "Epoch [58/100], Step [28600/6235], Loss: 0.5011\n",
      "Epoch [58/100], Step [28700/6235], Loss: 4.5203\n",
      "Epoch [58/100], Step [28800/6235], Loss: 0.6709\n",
      "Epoch [58/100], Step [28900/6235], Loss: 61.5592\n",
      "Epoch [58/100], Step [29000/6235], Loss: 2.3783\n",
      "Epoch [58/100], Step [29100/6235], Loss: 0.1939\n",
      "Epoch [58/100], Step [29200/6235], Loss: 3.0626\n",
      "Epoch [58/100], Step [29300/6235], Loss: 0.0350\n",
      "Epoch [58/100], Step [29400/6235], Loss: 0.3495\n",
      "Epoch [58/100], Step [29500/6235], Loss: 1.5423\n",
      "Epoch [58/100], Step [29600/6235], Loss: 0.0149\n",
      "Epoch [58/100], Step [29700/6235], Loss: 1.9174\n",
      "Epoch [58/100], Step [29800/6235], Loss: 1.3495\n",
      "Epoch [58/100], Step [29900/6235], Loss: 1.6353\n",
      "Epoch [58/100], Step [30000/6235], Loss: 5.5764\n",
      "Epoch [58/100], Step [30100/6235], Loss: 8.2804\n",
      "Epoch [58/100], Step [30200/6235], Loss: 1.5039\n",
      "Epoch [58/100], Step [30300/6235], Loss: 0.0548\n",
      "Epoch [58/100], Step [30400/6235], Loss: 1.5372\n",
      "Epoch [58/100], Step [30500/6235], Loss: 2.2069\n",
      "Epoch [58/100], Step [30600/6235], Loss: 1.8405\n",
      "Epoch [58/100], Step [30700/6235], Loss: 1.3349\n",
      "Epoch [58/100], Step [30800/6235], Loss: 0.5598\n",
      "Epoch [58/100], Step [30900/6235], Loss: 2.8314\n",
      "Epoch [58/100], Step [31000/6235], Loss: 0.3148\n",
      "Epoch [58/100], Step [31100/6235], Loss: 0.0568\n",
      "Epoch [58/100], Step [31200/6235], Loss: 5.4250\n",
      "Epoch [58/100], Step [31300/6235], Loss: 1.0967\n",
      "Epoch [58/100], Step [31400/6235], Loss: 4.6747\n",
      "Epoch [58/100], Step [31500/6235], Loss: 0.6640\n",
      "Epoch [58/100], Step [31600/6235], Loss: 0.8979\n",
      "Epoch [58/100], Step [31700/6235], Loss: 0.6696\n",
      "Epoch [58/100], Step [31800/6235], Loss: 1.3072\n",
      "Epoch [58/100], Step [31900/6235], Loss: 67.3805\n",
      "Epoch [58/100], Step [32000/6235], Loss: 55.7805\n",
      "Epoch [58/100], Step [32100/6235], Loss: 0.1150\n",
      "Epoch [58/100], Step [32200/6235], Loss: 134.2688\n",
      "Epoch [58/100], Step [32300/6235], Loss: 2.1331\n",
      "Epoch [58/100], Step [32400/6235], Loss: 1.5452\n",
      "Epoch [58/100], Step [32500/6235], Loss: 13.2285\n",
      "Epoch [58/100], Step [32600/6235], Loss: 0.4518\n",
      "Epoch [58/100], Step [32700/6235], Loss: 102.0221\n",
      "Epoch [58/100], Step [32800/6235], Loss: 10.7034\n",
      "Epoch [58/100], Step [32900/6235], Loss: 0.3494\n",
      "Epoch [58/100], Step [33000/6235], Loss: 0.0874\n",
      "Epoch [58/100], Step [33100/6235], Loss: 0.5263\n",
      "Epoch [58/100], Step [33200/6235], Loss: 1.1001\n",
      "Epoch [58/100], Step [33300/6235], Loss: 4.0555\n",
      "Epoch [58/100], Step [33400/6235], Loss: 17.1010\n",
      "Epoch [58/100], Step [33500/6235], Loss: 1.3333\n",
      "Epoch [58/100], Step [33600/6235], Loss: 9.6130\n",
      "Epoch [58/100], Step [33700/6235], Loss: 14.4410\n",
      "Epoch [58/100], Step [33800/6235], Loss: 0.4333\n",
      "Epoch [58/100], Step [33900/6235], Loss: 28.5651\n",
      "Epoch [58/100], Step [34000/6235], Loss: 0.1607\n",
      "Epoch [58/100], Step [34100/6235], Loss: 0.8201\n",
      "Epoch [58/100], Step [34200/6235], Loss: 2.1781\n",
      "Epoch [58/100], Step [34300/6235], Loss: 2.0146\n",
      "Epoch [58/100], Step [34400/6235], Loss: 0.0765\n",
      "Epoch [58/100], Step [34500/6235], Loss: 36.8110\n",
      "Epoch [58/100], Step [34600/6235], Loss: 2.9191\n",
      "Epoch [58/100], Step [34700/6235], Loss: 6.5719\n",
      "Epoch [58/100], Step [34800/6235], Loss: 13.6918\n",
      "Epoch [58/100], Step [34900/6235], Loss: 73.2595\n",
      "Epoch [58/100], Step [35000/6235], Loss: 0.2083\n",
      "Epoch [58/100], Step [35100/6235], Loss: 0.8099\n",
      "Epoch [58/100], Step [35200/6235], Loss: 0.6054\n",
      "Epoch [58/100], Step [35300/6235], Loss: 3.1007\n",
      "Epoch [58/100], Step [35400/6235], Loss: 0.5133\n",
      "Epoch [58/100], Step [35500/6235], Loss: 0.0994\n",
      "Epoch [58/100], Step [35600/6235], Loss: 5.7921\n",
      "Epoch [58/100], Step [35700/6235], Loss: 4.4341\n",
      "Epoch [58/100], Step [35800/6235], Loss: 0.6062\n",
      "Epoch [58/100], Step [35900/6235], Loss: 0.6027\n",
      "Epoch [58/100], Step [36000/6235], Loss: 0.0381\n",
      "Epoch [58/100], Step [36100/6235], Loss: 0.0696\n",
      "Epoch [58/100], Step [36200/6235], Loss: 33.6571\n",
      "Epoch [58/100], Step [36300/6235], Loss: 1.2085\n",
      "Epoch [58/100], Step [36400/6235], Loss: 3.0464\n",
      "Epoch [58/100], Step [36500/6235], Loss: 6.8483\n",
      "Epoch [58/100], Step [36600/6235], Loss: 0.0937\n",
      "Epoch [58/100], Step [36700/6235], Loss: 0.5500\n",
      "Epoch [58/100], Step [36800/6235], Loss: 2.6334\n",
      "Epoch [58/100], Step [36900/6235], Loss: 12.7825\n",
      "Epoch [58/100], Step [37000/6235], Loss: 0.9889\n",
      "Epoch [58/100], Step [37100/6235], Loss: 2.3859\n",
      "Epoch [58/100], Step [37200/6235], Loss: 0.0357\n",
      "Epoch [58/100], Step [37300/6235], Loss: 0.0951\n",
      "Epoch [58/100], Step [37400/6235], Loss: 0.1617\n",
      "Epoch [58/100], Step [37500/6235], Loss: 7.8529\n",
      "Epoch [58/100], Step [37600/6235], Loss: 12.0244\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [58/100], Step [37700/6235], Loss: 1.9427\n",
      "Epoch [58/100], Step [37800/6235], Loss: 4.0723\n",
      "Epoch [58/100], Step [37900/6235], Loss: 3.9858\n",
      "Epoch [58/100], Step [38000/6235], Loss: 0.9108\n",
      "Epoch [58/100], Step [38100/6235], Loss: 4.5751\n",
      "Epoch [58/100], Step [38200/6235], Loss: 1.7226\n",
      "Epoch [58/100], Step [38300/6235], Loss: 0.1760\n",
      "Epoch [58/100], Step [38400/6235], Loss: 0.0871\n",
      "Epoch [58/100], Step [38500/6235], Loss: 1.3403\n",
      "Epoch [58/100], Step [38600/6235], Loss: 0.7316\n",
      "Epoch [58/100], Step [38700/6235], Loss: 0.0867\n",
      "Epoch [58/100], Step [38800/6235], Loss: 0.0937\n",
      "Epoch [58/100], Step [38900/6235], Loss: 7.2038\n",
      "Epoch [58/100], Step [39000/6235], Loss: 4.5276\n",
      "Epoch [58/100], Step [39100/6235], Loss: 16.4644\n",
      "Epoch [58/100], Step [39200/6235], Loss: 0.4468\n",
      "Epoch [58/100], Step [39300/6235], Loss: 12.8781\n",
      "Epoch [58/100], Step [39400/6235], Loss: 55.4716\n",
      "Epoch [58/100], Step [39500/6235], Loss: 309.5430\n",
      "Epoch [58/100], Step [39600/6235], Loss: 42.7706\n",
      "Epoch [58/100], Step [39700/6235], Loss: 261.7126\n",
      "Epoch [58/100], Step [39800/6235], Loss: 223.2288\n",
      "Epoch [58/100], Step [39900/6235], Loss: 8.5964\n",
      "Epoch [58/100], Step [40000/6235], Loss: 7.6600\n",
      "Epoch [58/100], Step [40100/6235], Loss: 15.7939\n",
      "Epoch [58/100], Step [40200/6235], Loss: 3.9556\n",
      "Epoch [58/100], Step [40300/6235], Loss: 1.0152\n",
      "Epoch [58/100], Step [40400/6235], Loss: 0.6482\n",
      "Epoch [58/100], Step [40500/6235], Loss: 2.8295\n",
      "Epoch [58/100], Step [40600/6235], Loss: 0.2570\n",
      "Epoch [58/100], Step [40700/6235], Loss: 6.8064\n",
      "Epoch [58/100], Step [40800/6235], Loss: 0.5843\n",
      "Epoch [58/100], Step [40900/6235], Loss: 0.8215\n",
      "Epoch [58/100], Step [41000/6235], Loss: 47.2693\n",
      "Epoch [58/100], Step [41100/6235], Loss: 25.4961\n",
      "Epoch [58/100], Step [41200/6235], Loss: 3.1816\n",
      "Epoch [58/100], Step [41300/6235], Loss: 4.3200\n",
      "Epoch [58/100], Step [41400/6235], Loss: 1.1101\n",
      "Epoch [58/100], Step [41500/6235], Loss: 0.8207\n",
      "Epoch [58/100], Step [41600/6235], Loss: 0.5619\n",
      "Epoch [58/100], Step [41700/6235], Loss: 1.9756\n",
      "Epoch [58/100], Step [41800/6235], Loss: 4.0856\n",
      "Epoch [58/100], Step [41900/6235], Loss: 4.5589\n",
      "Epoch [58/100], Step [42000/6235], Loss: 4.4525\n",
      "Epoch [58/100], Step [42100/6235], Loss: 9.9115\n",
      "Epoch [58/100], Step [42200/6235], Loss: 23.2440\n",
      "Epoch [58/100], Step [42300/6235], Loss: 2.2352\n",
      "Epoch [58/100], Step [42400/6235], Loss: 4.8930\n",
      "Epoch [58/100], Step [42500/6235], Loss: 1.5550\n",
      "Epoch [58/100], Step [42600/6235], Loss: 2.2667\n",
      "Epoch [58/100], Step [42700/6235], Loss: 0.7157\n",
      "Epoch [58/100], Step [42800/6235], Loss: 9.4616\n",
      "Epoch [58/100], Step [42900/6235], Loss: 2.0490\n",
      "Epoch [58/100], Step [43000/6235], Loss: 0.1780\n",
      "Epoch [58/100], Step [43100/6235], Loss: 0.0486\n",
      "Epoch [58/100], Step [43200/6235], Loss: 0.9587\n",
      "Epoch [58/100], Step [43300/6235], Loss: 7.7175\n",
      "Epoch [58/100], Step [43400/6235], Loss: 10.7699\n",
      "Epoch [58/100], Step [43500/6235], Loss: 9.6310\n",
      "Epoch [58/100], Step [43600/6235], Loss: 9.4286\n",
      "Epoch [58/100], Step [43700/6235], Loss: 34.9530\n",
      "Epoch [58/100], Step [43800/6235], Loss: 0.3658\n",
      "Epoch [58/100], Step [43900/6235], Loss: 0.6137\n",
      "Epoch [58/100], Step [44000/6235], Loss: 51.0306\n",
      "Epoch [58/100], Step [44100/6235], Loss: 2.7183\n",
      "Epoch [58/100], Step [44200/6235], Loss: 4.1747\n",
      "Epoch [58/100], Step [44300/6235], Loss: 57.1335\n",
      "Epoch [58/100], Step [44400/6235], Loss: 1.2228\n",
      "Epoch [58/100], Step [44500/6235], Loss: 1.7267\n",
      "Epoch [58/100], Step [44600/6235], Loss: 16.5843\n",
      "Epoch [58/100], Step [44700/6235], Loss: 5.5825\n",
      "Epoch [58/100], Step [44800/6235], Loss: 4.4158\n",
      "Epoch [58/100], Step [44900/6235], Loss: 4.2131\n",
      "Epoch [58/100], Step [45000/6235], Loss: 4.8551\n",
      "Epoch [58/100], Step [45100/6235], Loss: 76.0361\n",
      "Epoch [58/100], Step [45200/6235], Loss: 0.7576\n",
      "Epoch [58/100], Step [45300/6235], Loss: 31.6259\n",
      "Epoch [58/100], Step [45400/6235], Loss: 12.3621\n",
      "Epoch [58/100], Step [45500/6235], Loss: 0.2674\n",
      "Epoch [58/100], Step [45600/6235], Loss: 0.2171\n",
      "Epoch [58/100], Step [45700/6235], Loss: 68.4702\n",
      "Epoch [58/100], Step [45800/6235], Loss: 549.2892\n",
      "Epoch [58/100], Step [45900/6235], Loss: 7.1938\n",
      "Epoch [58/100], Step [46000/6235], Loss: 1.2408\n",
      "Epoch [58/100], Step [46100/6235], Loss: 10.7308\n",
      "Epoch [58/100], Step [46200/6235], Loss: 63.7737\n",
      "Epoch [58/100], Step [46300/6235], Loss: 19.1966\n",
      "Epoch [58/100], Step [46400/6235], Loss: 10.5641\n",
      "Epoch [58/100], Step [46500/6235], Loss: 0.3965\n",
      "Epoch [58/100], Step [46600/6235], Loss: 16.8168\n",
      "Epoch [58/100], Step [46700/6235], Loss: 3.1198\n",
      "Epoch [58/100], Step [46800/6235], Loss: 2.0296\n",
      "Epoch [58/100], Step [46900/6235], Loss: 9.7094\n",
      "Epoch [58/100], Step [47000/6235], Loss: 2.7834\n",
      "Epoch [58/100], Step [47100/6235], Loss: 8.4605\n",
      "Epoch [58/100], Step [47200/6235], Loss: 11.4758\n",
      "Epoch [58/100], Step [47300/6235], Loss: 1.0902\n",
      "Epoch [58/100], Step [47400/6235], Loss: 11.8269\n",
      "Epoch [58/100], Step [47500/6235], Loss: 25.1470\n",
      "Epoch [58/100], Step [47600/6235], Loss: 14.0898\n",
      "Epoch [58/100], Step [47700/6235], Loss: 17.9342\n",
      "Epoch [58/100], Step [47800/6235], Loss: 11.4989\n",
      "Epoch [58/100], Step [47900/6235], Loss: 17.9789\n",
      "Epoch [58/100], Step [48000/6235], Loss: 91.1204\n",
      "Epoch [58/100], Step [48100/6235], Loss: 14.5283\n",
      "Epoch [58/100], Step [48200/6235], Loss: 164.8615\n",
      "Epoch [58/100], Step [48300/6235], Loss: 444.7367\n",
      "Epoch [58/100], Step [48400/6235], Loss: 22.0149\n",
      "Epoch [58/100], Step [48500/6235], Loss: 17.2938\n",
      "Epoch [58/100], Step [48600/6235], Loss: 166.1284\n",
      "Epoch [58/100], Step [48700/6235], Loss: 25.5365\n",
      "Epoch [58/100], Step [48800/6235], Loss: 429.2644\n",
      "Epoch [58/100], Step [48900/6235], Loss: 9.7941\n",
      "Epoch [58/100], Step [49000/6235], Loss: 166.1899\n",
      "Epoch [58/100], Step [49100/6235], Loss: 1731.4247\n",
      "Epoch [58/100], Step [49200/6235], Loss: 597.6459\n",
      "Epoch [58/100], Step [49300/6235], Loss: 1212.5103\n",
      "Epoch [58/100], Step [49400/6235], Loss: 77.2831\n",
      "Epoch [58/100], Step [49500/6235], Loss: 3.5511\n",
      "Epoch [58/100], Step [49600/6235], Loss: 1054.2495\n",
      "Epoch [58/100], Step [49700/6235], Loss: 1436.2593\n",
      "Epoch [58/100], Step [49800/6235], Loss: 476.0605\n",
      "Epoch [59/100], Step [100/6235], Loss: 33.8883\n",
      "Epoch [59/100], Step [200/6235], Loss: 0.1984\n",
      "Epoch [59/100], Step [300/6235], Loss: 0.0133\n",
      "Epoch [59/100], Step [400/6235], Loss: 0.0093\n",
      "Epoch [59/100], Step [500/6235], Loss: 0.1821\n",
      "Epoch [59/100], Step [600/6235], Loss: 0.0201\n",
      "Epoch [59/100], Step [700/6235], Loss: 0.6138\n",
      "Epoch [59/100], Step [800/6235], Loss: 0.0459\n",
      "Epoch [59/100], Step [900/6235], Loss: 0.0555\n",
      "Epoch [59/100], Step [1000/6235], Loss: 0.0227\n",
      "Epoch [59/100], Step [1100/6235], Loss: 0.0302\n",
      "Epoch [59/100], Step [1200/6235], Loss: 0.1694\n",
      "Epoch [59/100], Step [1300/6235], Loss: 0.0054\n",
      "Epoch [59/100], Step [1400/6235], Loss: 0.0659\n",
      "Epoch [59/100], Step [1500/6235], Loss: 0.0072\n",
      "Epoch [59/100], Step [1600/6235], Loss: 0.2336\n",
      "Epoch [59/100], Step [1700/6235], Loss: 0.1475\n",
      "Epoch [59/100], Step [1800/6235], Loss: 0.2454\n",
      "Epoch [59/100], Step [1900/6235], Loss: 0.2665\n",
      "Epoch [59/100], Step [2000/6235], Loss: 2.2014\n",
      "Epoch [59/100], Step [2100/6235], Loss: 2.1660\n",
      "Epoch [59/100], Step [2200/6235], Loss: 5.5347\n",
      "Epoch [59/100], Step [2300/6235], Loss: 0.3680\n",
      "Epoch [59/100], Step [2400/6235], Loss: 1.8743\n",
      "Epoch [59/100], Step [2500/6235], Loss: 23.8042\n",
      "Epoch [59/100], Step [2600/6235], Loss: 14.4623\n",
      "Epoch [59/100], Step [2700/6235], Loss: 8.8223\n",
      "Epoch [59/100], Step [2800/6235], Loss: 42.4303\n",
      "Epoch [59/100], Step [2900/6235], Loss: 16.4216\n",
      "Epoch [59/100], Step [3000/6235], Loss: 0.7935\n",
      "Epoch [59/100], Step [3100/6235], Loss: 71.0093\n",
      "Epoch [59/100], Step [3200/6235], Loss: 33.1436\n",
      "Epoch [59/100], Step [3300/6235], Loss: 8.2127\n",
      "Epoch [59/100], Step [3400/6235], Loss: 4.9633\n",
      "Epoch [59/100], Step [3500/6235], Loss: 54.9291\n",
      "Epoch [59/100], Step [3600/6235], Loss: 0.6875\n",
      "Epoch [59/100], Step [3700/6235], Loss: 0.0929\n",
      "Epoch [59/100], Step [3800/6235], Loss: 0.0664\n",
      "Epoch [59/100], Step [3900/6235], Loss: 0.2035\n",
      "Epoch [59/100], Step [4000/6235], Loss: 0.1142\n",
      "Epoch [59/100], Step [4100/6235], Loss: 10.0262\n",
      "Epoch [59/100], Step [4200/6235], Loss: 4.6988\n",
      "Epoch [59/100], Step [4300/6235], Loss: 3.8993\n",
      "Epoch [59/100], Step [4400/6235], Loss: 0.4156\n",
      "Epoch [59/100], Step [4500/6235], Loss: 38.0686\n",
      "Epoch [59/100], Step [4600/6235], Loss: 1.9970\n",
      "Epoch [59/100], Step [4700/6235], Loss: 0.2832\n",
      "Epoch [59/100], Step [4800/6235], Loss: 6.2888\n",
      "Epoch [59/100], Step [4900/6235], Loss: 2.5350\n",
      "Epoch [59/100], Step [5000/6235], Loss: 0.0764\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Step [5100/6235], Loss: 0.1108\n",
      "Epoch [59/100], Step [5200/6235], Loss: 3.8250\n",
      "Epoch [59/100], Step [5300/6235], Loss: 21.0613\n",
      "Epoch [59/100], Step [5400/6235], Loss: 1.5865\n",
      "Epoch [59/100], Step [5500/6235], Loss: 0.0609\n",
      "Epoch [59/100], Step [5600/6235], Loss: 0.2804\n",
      "Epoch [59/100], Step [5700/6235], Loss: 0.0843\n",
      "Epoch [59/100], Step [5800/6235], Loss: 0.0869\n",
      "Epoch [59/100], Step [5900/6235], Loss: 0.1294\n",
      "Epoch [59/100], Step [6000/6235], Loss: 0.2891\n",
      "Epoch [59/100], Step [6100/6235], Loss: 0.0516\n",
      "Epoch [59/100], Step [6200/6235], Loss: 7.4646\n",
      "Epoch [59/100], Step [6300/6235], Loss: 0.4873\n",
      "Epoch [59/100], Step [6400/6235], Loss: 0.0239\n",
      "Epoch [59/100], Step [6500/6235], Loss: 0.9030\n",
      "Epoch [59/100], Step [6600/6235], Loss: 8.0245\n",
      "Epoch [59/100], Step [6700/6235], Loss: 1.1878\n",
      "Epoch [59/100], Step [6800/6235], Loss: 0.5580\n",
      "Epoch [59/100], Step [6900/6235], Loss: 0.2558\n",
      "Epoch [59/100], Step [7000/6235], Loss: 0.3492\n",
      "Epoch [59/100], Step [7100/6235], Loss: 0.2600\n",
      "Epoch [59/100], Step [7200/6235], Loss: 0.0372\n",
      "Epoch [59/100], Step [7300/6235], Loss: 0.7726\n",
      "Epoch [59/100], Step [7400/6235], Loss: 0.0794\n",
      "Epoch [59/100], Step [7500/6235], Loss: 0.1231\n",
      "Epoch [59/100], Step [7600/6235], Loss: 5.6253\n",
      "Epoch [59/100], Step [7700/6235], Loss: 7.8810\n",
      "Epoch [59/100], Step [7800/6235], Loss: 2.3909\n",
      "Epoch [59/100], Step [7900/6235], Loss: 4.3843\n",
      "Epoch [59/100], Step [8000/6235], Loss: 0.5381\n",
      "Epoch [59/100], Step [8100/6235], Loss: 0.4667\n",
      "Epoch [59/100], Step [8200/6235], Loss: 10.2590\n",
      "Epoch [59/100], Step [8300/6235], Loss: 19.9577\n",
      "Epoch [59/100], Step [8400/6235], Loss: 638.1587\n",
      "Epoch [59/100], Step [8500/6235], Loss: 19.6179\n",
      "Epoch [59/100], Step [8600/6235], Loss: 33.0615\n",
      "Epoch [59/100], Step [8700/6235], Loss: 44.3099\n",
      "Epoch [59/100], Step [8800/6235], Loss: 605.4791\n",
      "Epoch [59/100], Step [8900/6235], Loss: 3.4502\n",
      "Epoch [59/100], Step [9000/6235], Loss: 595.7969\n",
      "Epoch [59/100], Step [9100/6235], Loss: 876.3998\n",
      "Epoch [59/100], Step [9200/6235], Loss: 1596.2836\n",
      "Epoch [59/100], Step [9300/6235], Loss: 36.0919\n",
      "Epoch [59/100], Step [9400/6235], Loss: 1084.3649\n",
      "Epoch [59/100], Step [9500/6235], Loss: 2714.9075\n",
      "Epoch [59/100], Step [9600/6235], Loss: 616.9496\n",
      "Epoch [59/100], Step [9700/6235], Loss: 1.9851\n",
      "Epoch [59/100], Step [9800/6235], Loss: 4177.2954\n",
      "Epoch [59/100], Step [9900/6235], Loss: 22.1775\n",
      "Epoch [59/100], Step [10000/6235], Loss: 28.1002\n",
      "Epoch [59/100], Step [10100/6235], Loss: 3.6465\n",
      "Epoch [59/100], Step [10200/6235], Loss: 797.5292\n",
      "Epoch [59/100], Step [10300/6235], Loss: 88.8956\n",
      "Epoch [59/100], Step [10400/6235], Loss: 7.4954\n",
      "Epoch [59/100], Step [10500/6235], Loss: 17.4257\n",
      "Epoch [59/100], Step [10600/6235], Loss: 133.8034\n",
      "Epoch [59/100], Step [10700/6235], Loss: 25.2732\n",
      "Epoch [59/100], Step [10800/6235], Loss: 55.5827\n",
      "Epoch [59/100], Step [10900/6235], Loss: 1.8437\n",
      "Epoch [59/100], Step [11000/6235], Loss: 295.3074\n",
      "Epoch [59/100], Step [11100/6235], Loss: 37.8585\n",
      "Epoch [59/100], Step [11200/6235], Loss: 36.1946\n",
      "Epoch [59/100], Step [11300/6235], Loss: 158.2229\n",
      "Epoch [59/100], Step [11400/6235], Loss: 5.7724\n",
      "Epoch [59/100], Step [11500/6235], Loss: 8.3422\n",
      "Epoch [59/100], Step [11600/6235], Loss: 4.6899\n",
      "Epoch [59/100], Step [11700/6235], Loss: 43.8958\n",
      "Epoch [59/100], Step [11800/6235], Loss: 4.4459\n",
      "Epoch [59/100], Step [11900/6235], Loss: 74.2620\n",
      "Epoch [59/100], Step [12000/6235], Loss: 497.6645\n",
      "Epoch [59/100], Step [12100/6235], Loss: 403.8542\n",
      "Epoch [59/100], Step [12200/6235], Loss: 91.4661\n",
      "Epoch [59/100], Step [12300/6235], Loss: 9.6984\n",
      "Epoch [59/100], Step [12400/6235], Loss: 411.1056\n",
      "Epoch [59/100], Step [12500/6235], Loss: 247.6172\n",
      "Epoch [59/100], Step [12600/6235], Loss: 6.2969\n",
      "Epoch [59/100], Step [12700/6235], Loss: 11.3265\n",
      "Epoch [59/100], Step [12800/6235], Loss: 16.6771\n",
      "Epoch [59/100], Step [12900/6235], Loss: 29.9248\n",
      "Epoch [59/100], Step [13000/6235], Loss: 0.0716\n",
      "Epoch [59/100], Step [13100/6235], Loss: 61.2891\n",
      "Epoch [59/100], Step [13200/6235], Loss: 9.1650\n",
      "Epoch [59/100], Step [13300/6235], Loss: 19.1089\n",
      "Epoch [59/100], Step [13400/6235], Loss: 181.2314\n",
      "Epoch [59/100], Step [13500/6235], Loss: 3.2346\n",
      "Epoch [59/100], Step [13600/6235], Loss: 17.5230\n",
      "Epoch [59/100], Step [13700/6235], Loss: 184.2369\n",
      "Epoch [59/100], Step [13800/6235], Loss: 73.0444\n",
      "Epoch [59/100], Step [13900/6235], Loss: 6.6413\n",
      "Epoch [59/100], Step [14000/6235], Loss: 5.7837\n",
      "Epoch [59/100], Step [14100/6235], Loss: 3.2237\n",
      "Epoch [59/100], Step [14200/6235], Loss: 94.5134\n",
      "Epoch [59/100], Step [14300/6235], Loss: 14.2888\n",
      "Epoch [59/100], Step [14400/6235], Loss: 30.5418\n",
      "Epoch [59/100], Step [14500/6235], Loss: 17.4918\n",
      "Epoch [59/100], Step [14600/6235], Loss: 3.2002\n",
      "Epoch [59/100], Step [14700/6235], Loss: 17.0173\n",
      "Epoch [59/100], Step [14800/6235], Loss: 24.0957\n",
      "Epoch [59/100], Step [14900/6235], Loss: 0.8459\n",
      "Epoch [59/100], Step [15000/6235], Loss: 0.7273\n",
      "Epoch [59/100], Step [15100/6235], Loss: 0.1868\n",
      "Epoch [59/100], Step [15200/6235], Loss: 38.3488\n",
      "Epoch [59/100], Step [15300/6235], Loss: 0.4094\n",
      "Epoch [59/100], Step [15400/6235], Loss: 0.7465\n",
      "Epoch [59/100], Step [15500/6235], Loss: 2.2700\n",
      "Epoch [59/100], Step [15600/6235], Loss: 24.5333\n",
      "Epoch [59/100], Step [15700/6235], Loss: 19.2288\n",
      "Epoch [59/100], Step [15800/6235], Loss: 3.5395\n",
      "Epoch [59/100], Step [15900/6235], Loss: 0.9617\n",
      "Epoch [59/100], Step [16000/6235], Loss: 20.5768\n",
      "Epoch [59/100], Step [16100/6235], Loss: 4.1717\n",
      "Epoch [59/100], Step [16200/6235], Loss: 0.9957\n",
      "Epoch [59/100], Step [16300/6235], Loss: 8.8912\n",
      "Epoch [59/100], Step [16400/6235], Loss: 23.1707\n",
      "Epoch [59/100], Step [16500/6235], Loss: 459.9439\n",
      "Epoch [59/100], Step [16600/6235], Loss: 38.2016\n",
      "Epoch [59/100], Step [16700/6235], Loss: 0.7292\n",
      "Epoch [59/100], Step [16800/6235], Loss: 8.6586\n",
      "Epoch [59/100], Step [16900/6235], Loss: 0.1971\n",
      "Epoch [59/100], Step [17000/6235], Loss: 0.2487\n",
      "Epoch [59/100], Step [17100/6235], Loss: 0.2581\n",
      "Epoch [59/100], Step [17200/6235], Loss: 281.7793\n",
      "Epoch [59/100], Step [17300/6235], Loss: 1.2287\n",
      "Epoch [59/100], Step [17400/6235], Loss: 37.7771\n",
      "Epoch [59/100], Step [17500/6235], Loss: 1.5059\n",
      "Epoch [59/100], Step [17600/6235], Loss: 3.2849\n",
      "Epoch [59/100], Step [17700/6235], Loss: 6.0799\n",
      "Epoch [59/100], Step [17800/6235], Loss: 16.5304\n",
      "Epoch [59/100], Step [17900/6235], Loss: 14.9849\n",
      "Epoch [59/100], Step [18000/6235], Loss: 9.1526\n",
      "Epoch [59/100], Step [18100/6235], Loss: 16.3075\n",
      "Epoch [59/100], Step [18200/6235], Loss: 0.5572\n",
      "Epoch [59/100], Step [18300/6235], Loss: 3.4848\n",
      "Epoch [59/100], Step [18400/6235], Loss: 0.4232\n",
      "Epoch [59/100], Step [18500/6235], Loss: 16.2632\n",
      "Epoch [59/100], Step [18600/6235], Loss: 2.3430\n",
      "Epoch [59/100], Step [18700/6235], Loss: 0.5030\n",
      "Epoch [59/100], Step [18800/6235], Loss: 74.0646\n",
      "Epoch [59/100], Step [18900/6235], Loss: 33.8020\n",
      "Epoch [59/100], Step [19000/6235], Loss: 0.5851\n",
      "Epoch [59/100], Step [19100/6235], Loss: 12.6532\n",
      "Epoch [59/100], Step [19200/6235], Loss: 1.7768\n",
      "Epoch [59/100], Step [19300/6235], Loss: 8.7378\n",
      "Epoch [59/100], Step [19400/6235], Loss: 60.4546\n",
      "Epoch [59/100], Step [19500/6235], Loss: 54.8360\n",
      "Epoch [59/100], Step [19600/6235], Loss: 56.5077\n",
      "Epoch [59/100], Step [19700/6235], Loss: 7.3818\n",
      "Epoch [59/100], Step [19800/6235], Loss: 2.2644\n",
      "Epoch [59/100], Step [19900/6235], Loss: 0.1258\n",
      "Epoch [59/100], Step [20000/6235], Loss: 67.3557\n",
      "Epoch [59/100], Step [20100/6235], Loss: 0.8098\n",
      "Epoch [59/100], Step [20200/6235], Loss: 8.0275\n",
      "Epoch [59/100], Step [20300/6235], Loss: 2.6383\n",
      "Epoch [59/100], Step [20400/6235], Loss: 15.6607\n",
      "Epoch [59/100], Step [20500/6235], Loss: 48.8678\n",
      "Epoch [59/100], Step [20600/6235], Loss: 136.4710\n",
      "Epoch [59/100], Step [20700/6235], Loss: 17.6455\n",
      "Epoch [59/100], Step [20800/6235], Loss: 3.3476\n",
      "Epoch [59/100], Step [20900/6235], Loss: 20.2885\n",
      "Epoch [59/100], Step [21000/6235], Loss: 17.5440\n",
      "Epoch [59/100], Step [21100/6235], Loss: 6.4768\n",
      "Epoch [59/100], Step [21200/6235], Loss: 0.2874\n",
      "Epoch [59/100], Step [21300/6235], Loss: 0.1738\n",
      "Epoch [59/100], Step [21400/6235], Loss: 6.4033\n",
      "Epoch [59/100], Step [21500/6235], Loss: 2.6844\n",
      "Epoch [59/100], Step [21600/6235], Loss: 22.3278\n",
      "Epoch [59/100], Step [21700/6235], Loss: 0.2794\n",
      "Epoch [59/100], Step [21800/6235], Loss: 2.3394\n",
      "Epoch [59/100], Step [21900/6235], Loss: 1.2263\n",
      "Epoch [59/100], Step [22000/6235], Loss: 6.2452\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Step [22100/6235], Loss: 1.3758\n",
      "Epoch [59/100], Step [22200/6235], Loss: 5.4849\n",
      "Epoch [59/100], Step [22300/6235], Loss: 0.4606\n",
      "Epoch [59/100], Step [22400/6235], Loss: 10.8409\n",
      "Epoch [59/100], Step [22500/6235], Loss: 110.6108\n",
      "Epoch [59/100], Step [22600/6235], Loss: 25.1848\n",
      "Epoch [59/100], Step [22700/6235], Loss: 1.0265\n",
      "Epoch [59/100], Step [22800/6235], Loss: 3.1336\n",
      "Epoch [59/100], Step [22900/6235], Loss: 2.2954\n",
      "Epoch [59/100], Step [23000/6235], Loss: 14.6162\n",
      "Epoch [59/100], Step [23100/6235], Loss: 1.7976\n",
      "Epoch [59/100], Step [23200/6235], Loss: 8.5511\n",
      "Epoch [59/100], Step [23300/6235], Loss: 9.8280\n",
      "Epoch [59/100], Step [23400/6235], Loss: 1.3124\n",
      "Epoch [59/100], Step [23500/6235], Loss: 0.1734\n",
      "Epoch [59/100], Step [23600/6235], Loss: 120.4809\n",
      "Epoch [59/100], Step [23700/6235], Loss: 3.2096\n",
      "Epoch [59/100], Step [23800/6235], Loss: 1.0494\n",
      "Epoch [59/100], Step [23900/6235], Loss: 7.0032\n",
      "Epoch [59/100], Step [24000/6235], Loss: 0.1711\n",
      "Epoch [59/100], Step [24100/6235], Loss: 0.2028\n",
      "Epoch [59/100], Step [24200/6235], Loss: 19.9633\n",
      "Epoch [59/100], Step [24300/6235], Loss: 1.0809\n",
      "Epoch [59/100], Step [24400/6235], Loss: 2.2880\n",
      "Epoch [59/100], Step [24500/6235], Loss: 0.7851\n",
      "Epoch [59/100], Step [24600/6235], Loss: 0.0500\n",
      "Epoch [59/100], Step [24700/6235], Loss: 0.4655\n",
      "Epoch [59/100], Step [24800/6235], Loss: 0.2381\n",
      "Epoch [59/100], Step [24900/6235], Loss: 17.5178\n",
      "Epoch [59/100], Step [25000/6235], Loss: 18.5203\n",
      "Epoch [59/100], Step [25100/6235], Loss: 6.9222\n",
      "Epoch [59/100], Step [25200/6235], Loss: 0.7820\n",
      "Epoch [59/100], Step [25300/6235], Loss: 0.6151\n",
      "Epoch [59/100], Step [25400/6235], Loss: 7.2977\n",
      "Epoch [59/100], Step [25500/6235], Loss: 7.0930\n",
      "Epoch [59/100], Step [25600/6235], Loss: 4.2169\n",
      "Epoch [59/100], Step [25700/6235], Loss: 0.3796\n",
      "Epoch [59/100], Step [25800/6235], Loss: 0.1677\n",
      "Epoch [59/100], Step [25900/6235], Loss: 9.0689\n",
      "Epoch [59/100], Step [26000/6235], Loss: 6.7861\n",
      "Epoch [59/100], Step [26100/6235], Loss: 0.4146\n",
      "Epoch [59/100], Step [26200/6235], Loss: 0.4238\n",
      "Epoch [59/100], Step [26300/6235], Loss: 4.6436\n",
      "Epoch [59/100], Step [26400/6235], Loss: 0.0949\n",
      "Epoch [59/100], Step [26500/6235], Loss: 0.0283\n",
      "Epoch [59/100], Step [26600/6235], Loss: 1.7672\n",
      "Epoch [59/100], Step [26700/6235], Loss: 0.3955\n",
      "Epoch [59/100], Step [26800/6235], Loss: 0.1952\n",
      "Epoch [59/100], Step [26900/6235], Loss: 0.0005\n",
      "Epoch [59/100], Step [27000/6235], Loss: 14.7490\n",
      "Epoch [59/100], Step [27100/6235], Loss: 0.0565\n",
      "Epoch [59/100], Step [27200/6235], Loss: 0.0277\n",
      "Epoch [59/100], Step [27300/6235], Loss: 0.2343\n",
      "Epoch [59/100], Step [27400/6235], Loss: 0.7804\n",
      "Epoch [59/100], Step [27500/6235], Loss: 12.5326\n",
      "Epoch [59/100], Step [27600/6235], Loss: 0.8273\n",
      "Epoch [59/100], Step [27700/6235], Loss: 0.8800\n",
      "Epoch [59/100], Step [27800/6235], Loss: 5.5039\n",
      "Epoch [59/100], Step [27900/6235], Loss: 2.1888\n",
      "Epoch [59/100], Step [28000/6235], Loss: 174.0202\n",
      "Epoch [59/100], Step [28100/6235], Loss: 5.8888\n",
      "Epoch [59/100], Step [28200/6235], Loss: 13.8419\n",
      "Epoch [59/100], Step [28300/6235], Loss: 2.8184\n",
      "Epoch [59/100], Step [28400/6235], Loss: 28.5447\n",
      "Epoch [59/100], Step [28500/6235], Loss: 4.2206\n",
      "Epoch [59/100], Step [28600/6235], Loss: 0.4127\n",
      "Epoch [59/100], Step [28700/6235], Loss: 5.1613\n",
      "Epoch [59/100], Step [28800/6235], Loss: 0.6492\n",
      "Epoch [59/100], Step [28900/6235], Loss: 67.4915\n",
      "Epoch [59/100], Step [29000/6235], Loss: 11.4065\n",
      "Epoch [59/100], Step [29100/6235], Loss: 0.3519\n",
      "Epoch [59/100], Step [29200/6235], Loss: 2.0271\n",
      "Epoch [59/100], Step [29300/6235], Loss: 16.4261\n",
      "Epoch [59/100], Step [29400/6235], Loss: 0.8410\n",
      "Epoch [59/100], Step [29500/6235], Loss: 2.8728\n",
      "Epoch [59/100], Step [29600/6235], Loss: 0.0332\n",
      "Epoch [59/100], Step [29700/6235], Loss: 1.8401\n",
      "Epoch [59/100], Step [29800/6235], Loss: 1.3943\n",
      "Epoch [59/100], Step [29900/6235], Loss: 1.3610\n",
      "Epoch [59/100], Step [30000/6235], Loss: 7.8762\n",
      "Epoch [59/100], Step [30100/6235], Loss: 10.4092\n",
      "Epoch [59/100], Step [30200/6235], Loss: 1.3632\n",
      "Epoch [59/100], Step [30300/6235], Loss: 0.0136\n",
      "Epoch [59/100], Step [30400/6235], Loss: 1.3467\n",
      "Epoch [59/100], Step [30500/6235], Loss: 0.2899\n",
      "Epoch [59/100], Step [30600/6235], Loss: 0.7553\n",
      "Epoch [59/100], Step [30700/6235], Loss: 0.9672\n",
      "Epoch [59/100], Step [30800/6235], Loss: 0.5480\n",
      "Epoch [59/100], Step [30900/6235], Loss: 3.3248\n",
      "Epoch [59/100], Step [31000/6235], Loss: 0.2623\n",
      "Epoch [59/100], Step [31100/6235], Loss: 0.0503\n",
      "Epoch [59/100], Step [31200/6235], Loss: 6.6953\n",
      "Epoch [59/100], Step [31300/6235], Loss: 1.0980\n",
      "Epoch [59/100], Step [31400/6235], Loss: 7.8813\n",
      "Epoch [59/100], Step [31500/6235], Loss: 0.9590\n",
      "Epoch [59/100], Step [31600/6235], Loss: 4.8522\n",
      "Epoch [59/100], Step [31700/6235], Loss: 10.8898\n",
      "Epoch [59/100], Step [31800/6235], Loss: 3.3851\n",
      "Epoch [59/100], Step [31900/6235], Loss: 609.4156\n",
      "Epoch [59/100], Step [32000/6235], Loss: 4.9578\n",
      "Epoch [59/100], Step [32100/6235], Loss: 0.1257\n",
      "Epoch [59/100], Step [32200/6235], Loss: 103.2683\n",
      "Epoch [59/100], Step [32300/6235], Loss: 0.1510\n",
      "Epoch [59/100], Step [32400/6235], Loss: 1.0665\n",
      "Epoch [59/100], Step [32500/6235], Loss: 5.4542\n",
      "Epoch [59/100], Step [32600/6235], Loss: 0.1508\n",
      "Epoch [59/100], Step [32700/6235], Loss: 176.6360\n",
      "Epoch [59/100], Step [32800/6235], Loss: 2.2934\n",
      "Epoch [59/100], Step [32900/6235], Loss: 0.7567\n",
      "Epoch [59/100], Step [33000/6235], Loss: 0.5331\n",
      "Epoch [59/100], Step [33100/6235], Loss: 0.5874\n",
      "Epoch [59/100], Step [33200/6235], Loss: 1.2586\n",
      "Epoch [59/100], Step [33300/6235], Loss: 3.4032\n",
      "Epoch [59/100], Step [33400/6235], Loss: 20.2456\n",
      "Epoch [59/100], Step [33500/6235], Loss: 0.2596\n",
      "Epoch [59/100], Step [33600/6235], Loss: 9.8880\n",
      "Epoch [59/100], Step [33700/6235], Loss: 14.8876\n",
      "Epoch [59/100], Step [33800/6235], Loss: 0.7744\n",
      "Epoch [59/100], Step [33900/6235], Loss: 37.5055\n",
      "Epoch [59/100], Step [34000/6235], Loss: 0.1884\n",
      "Epoch [59/100], Step [34100/6235], Loss: 0.9215\n",
      "Epoch [59/100], Step [34200/6235], Loss: 2.7795\n",
      "Epoch [59/100], Step [34300/6235], Loss: 1.1575\n",
      "Epoch [59/100], Step [34400/6235], Loss: 0.0976\n",
      "Epoch [59/100], Step [34500/6235], Loss: 19.2023\n",
      "Epoch [59/100], Step [34600/6235], Loss: 2.1903\n",
      "Epoch [59/100], Step [34700/6235], Loss: 25.8316\n",
      "Epoch [59/100], Step [34800/6235], Loss: 12.1480\n",
      "Epoch [59/100], Step [34900/6235], Loss: 70.4667\n",
      "Epoch [59/100], Step [35000/6235], Loss: 0.5321\n",
      "Epoch [59/100], Step [35100/6235], Loss: 0.8970\n",
      "Epoch [59/100], Step [35200/6235], Loss: 0.6589\n",
      "Epoch [59/100], Step [35300/6235], Loss: 3.1373\n",
      "Epoch [59/100], Step [35400/6235], Loss: 0.5837\n",
      "Epoch [59/100], Step [35500/6235], Loss: 0.3861\n",
      "Epoch [59/100], Step [35600/6235], Loss: 0.8595\n",
      "Epoch [59/100], Step [35700/6235], Loss: 4.2742\n",
      "Epoch [59/100], Step [35800/6235], Loss: 0.4130\n",
      "Epoch [59/100], Step [35900/6235], Loss: 0.1846\n",
      "Epoch [59/100], Step [36000/6235], Loss: 0.0385\n",
      "Epoch [59/100], Step [36100/6235], Loss: 0.0795\n",
      "Epoch [59/100], Step [36200/6235], Loss: 33.3963\n",
      "Epoch [59/100], Step [36300/6235], Loss: 0.5388\n",
      "Epoch [59/100], Step [36400/6235], Loss: 3.0779\n",
      "Epoch [59/100], Step [36500/6235], Loss: 7.3151\n",
      "Epoch [59/100], Step [36600/6235], Loss: 0.0939\n",
      "Epoch [59/100], Step [36700/6235], Loss: 0.5867\n",
      "Epoch [59/100], Step [36800/6235], Loss: 4.3185\n",
      "Epoch [59/100], Step [36900/6235], Loss: 13.2249\n",
      "Epoch [59/100], Step [37000/6235], Loss: 0.9433\n",
      "Epoch [59/100], Step [37100/6235], Loss: 2.0884\n",
      "Epoch [59/100], Step [37200/6235], Loss: 0.0396\n",
      "Epoch [59/100], Step [37300/6235], Loss: 0.0453\n",
      "Epoch [59/100], Step [37400/6235], Loss: 0.1670\n",
      "Epoch [59/100], Step [37500/6235], Loss: 7.1203\n",
      "Epoch [59/100], Step [37600/6235], Loss: 12.1662\n",
      "Epoch [59/100], Step [37700/6235], Loss: 2.3078\n",
      "Epoch [59/100], Step [37800/6235], Loss: 3.5730\n",
      "Epoch [59/100], Step [37900/6235], Loss: 6.2939\n",
      "Epoch [59/100], Step [38000/6235], Loss: 0.9719\n",
      "Epoch [59/100], Step [38100/6235], Loss: 4.5152\n",
      "Epoch [59/100], Step [38200/6235], Loss: 1.8624\n",
      "Epoch [59/100], Step [38300/6235], Loss: 0.3599\n",
      "Epoch [59/100], Step [38400/6235], Loss: 0.0527\n",
      "Epoch [59/100], Step [38500/6235], Loss: 1.5101\n",
      "Epoch [59/100], Step [38600/6235], Loss: 0.3780\n",
      "Epoch [59/100], Step [38700/6235], Loss: 0.2865\n",
      "Epoch [59/100], Step [38800/6235], Loss: 0.1140\n",
      "Epoch [59/100], Step [38900/6235], Loss: 0.9029\n",
      "Epoch [59/100], Step [39000/6235], Loss: 1.2613\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [59/100], Step [39100/6235], Loss: 9.2964\n",
      "Epoch [59/100], Step [39200/6235], Loss: 0.8954\n",
      "Epoch [59/100], Step [39300/6235], Loss: 76.7804\n",
      "Epoch [59/100], Step [39400/6235], Loss: 367.9918\n",
      "Epoch [59/100], Step [39500/6235], Loss: 389.5577\n",
      "Epoch [59/100], Step [39600/6235], Loss: 24.2165\n",
      "Epoch [59/100], Step [39700/6235], Loss: 80.7412\n",
      "Epoch [59/100], Step [39800/6235], Loss: 183.5893\n",
      "Epoch [59/100], Step [39900/6235], Loss: 3.4557\n",
      "Epoch [59/100], Step [40000/6235], Loss: 9.8396\n",
      "Epoch [59/100], Step [40100/6235], Loss: 26.4077\n",
      "Epoch [59/100], Step [40200/6235], Loss: 1.2450\n",
      "Epoch [59/100], Step [40300/6235], Loss: 0.9933\n",
      "Epoch [59/100], Step [40400/6235], Loss: 2.4354\n",
      "Epoch [59/100], Step [40500/6235], Loss: 2.3213\n",
      "Epoch [59/100], Step [40600/6235], Loss: 0.2879\n",
      "Epoch [59/100], Step [40700/6235], Loss: 7.5502\n",
      "Epoch [59/100], Step [40800/6235], Loss: 1.3206\n",
      "Epoch [59/100], Step [40900/6235], Loss: 0.1368\n",
      "Epoch [59/100], Step [41000/6235], Loss: 48.1630\n",
      "Epoch [59/100], Step [41100/6235], Loss: 34.4587\n",
      "Epoch [59/100], Step [41200/6235], Loss: 3.2555\n",
      "Epoch [59/100], Step [41300/6235], Loss: 3.2320\n",
      "Epoch [59/100], Step [41400/6235], Loss: 0.0038\n",
      "Epoch [59/100], Step [41500/6235], Loss: 0.7304\n",
      "Epoch [59/100], Step [41600/6235], Loss: 0.3273\n",
      "Epoch [59/100], Step [41700/6235], Loss: 1.1054\n",
      "Epoch [59/100], Step [41800/6235], Loss: 3.1012\n",
      "Epoch [59/100], Step [41900/6235], Loss: 4.1975\n",
      "Epoch [59/100], Step [42000/6235], Loss: 3.5461\n",
      "Epoch [59/100], Step [42100/6235], Loss: 8.1294\n",
      "Epoch [59/100], Step [42200/6235], Loss: 11.0560\n",
      "Epoch [59/100], Step [42300/6235], Loss: 1.9937\n",
      "Epoch [59/100], Step [42400/6235], Loss: 0.3452\n",
      "Epoch [59/100], Step [42500/6235], Loss: 4.3341\n",
      "Epoch [59/100], Step [42600/6235], Loss: 0.5102\n",
      "Epoch [59/100], Step [42700/6235], Loss: 0.2209\n",
      "Epoch [59/100], Step [42800/6235], Loss: 3.2186\n",
      "Epoch [59/100], Step [42900/6235], Loss: 3.8533\n",
      "Epoch [59/100], Step [43000/6235], Loss: 0.2136\n",
      "Epoch [59/100], Step [43100/6235], Loss: 0.4747\n",
      "Epoch [59/100], Step [43200/6235], Loss: 1.0077\n",
      "Epoch [59/100], Step [43300/6235], Loss: 8.9446\n",
      "Epoch [59/100], Step [43400/6235], Loss: 8.9162\n",
      "Epoch [59/100], Step [43500/6235], Loss: 9.4318\n",
      "Epoch [59/100], Step [43600/6235], Loss: 18.2106\n",
      "Epoch [59/100], Step [43700/6235], Loss: 40.0852\n",
      "Epoch [59/100], Step [43800/6235], Loss: 0.6332\n",
      "Epoch [59/100], Step [43900/6235], Loss: 0.6261\n",
      "Epoch [59/100], Step [44000/6235], Loss: 66.2787\n",
      "Epoch [59/100], Step [44100/6235], Loss: 2.8871\n",
      "Epoch [59/100], Step [44200/6235], Loss: 6.5314\n",
      "Epoch [59/100], Step [44300/6235], Loss: 22.8121\n",
      "Epoch [59/100], Step [44400/6235], Loss: 1.0320\n",
      "Epoch [59/100], Step [44500/6235], Loss: 1.8587\n",
      "Epoch [59/100], Step [44600/6235], Loss: 16.2414\n",
      "Epoch [59/100], Step [44700/6235], Loss: 6.0314\n",
      "Epoch [59/100], Step [44800/6235], Loss: 4.3707\n",
      "Epoch [59/100], Step [44900/6235], Loss: 2.9433\n",
      "Epoch [59/100], Step [45000/6235], Loss: 4.9847\n",
      "Epoch [59/100], Step [45100/6235], Loss: 25.0888\n",
      "Epoch [59/100], Step [45200/6235], Loss: 0.3444\n",
      "Epoch [59/100], Step [45300/6235], Loss: 39.5213\n",
      "Epoch [59/100], Step [45400/6235], Loss: 11.3323\n",
      "Epoch [59/100], Step [45500/6235], Loss: 0.1494\n",
      "Epoch [59/100], Step [45600/6235], Loss: 0.3030\n",
      "Epoch [59/100], Step [45700/6235], Loss: 42.3458\n",
      "Epoch [59/100], Step [45800/6235], Loss: 313.8704\n",
      "Epoch [59/100], Step [45900/6235], Loss: 6.2852\n",
      "Epoch [59/100], Step [46000/6235], Loss: 165.2588\n",
      "Epoch [59/100], Step [46100/6235], Loss: 71.9585\n",
      "Epoch [59/100], Step [46200/6235], Loss: 92.4398\n",
      "Epoch [59/100], Step [46300/6235], Loss: 2.9181\n",
      "Epoch [59/100], Step [46400/6235], Loss: 8.5558\n",
      "Epoch [59/100], Step [46500/6235], Loss: 2.7305\n",
      "Epoch [59/100], Step [46600/6235], Loss: 26.2122\n",
      "Epoch [59/100], Step [46700/6235], Loss: 4.5520\n",
      "Epoch [59/100], Step [46800/6235], Loss: 15.3312\n",
      "Epoch [59/100], Step [46900/6235], Loss: 17.6366\n",
      "Epoch [59/100], Step [47000/6235], Loss: 1.0666\n",
      "Epoch [59/100], Step [47100/6235], Loss: 33.2313\n",
      "Epoch [59/100], Step [47200/6235], Loss: 61.5265\n",
      "Epoch [59/100], Step [47300/6235], Loss: 0.6862\n",
      "Epoch [59/100], Step [47400/6235], Loss: 178.8716\n",
      "Epoch [59/100], Step [47500/6235], Loss: 6.0831\n",
      "Epoch [59/100], Step [47600/6235], Loss: 11.5092\n",
      "Epoch [59/100], Step [47700/6235], Loss: 8.4961\n",
      "Epoch [59/100], Step [47800/6235], Loss: 11.4240\n",
      "Epoch [59/100], Step [47900/6235], Loss: 17.7621\n",
      "Epoch [59/100], Step [48000/6235], Loss: 33.4381\n",
      "Epoch [59/100], Step [48100/6235], Loss: 4.4746\n",
      "Epoch [59/100], Step [48200/6235], Loss: 13.3823\n",
      "Epoch [59/100], Step [48300/6235], Loss: 486.8531\n",
      "Epoch [59/100], Step [48400/6235], Loss: 13.6748\n",
      "Epoch [59/100], Step [48500/6235], Loss: 44.0829\n",
      "Epoch [59/100], Step [48600/6235], Loss: 118.2713\n",
      "Epoch [59/100], Step [48700/6235], Loss: 0.3717\n",
      "Epoch [59/100], Step [48800/6235], Loss: 426.4106\n",
      "Epoch [59/100], Step [48900/6235], Loss: 253.3221\n",
      "Epoch [59/100], Step [49000/6235], Loss: 131.8405\n",
      "Epoch [59/100], Step [49100/6235], Loss: 2151.4382\n",
      "Epoch [59/100], Step [49200/6235], Loss: 683.4022\n",
      "Epoch [59/100], Step [49300/6235], Loss: 963.2997\n",
      "Epoch [59/100], Step [49400/6235], Loss: 54.5859\n",
      "Epoch [59/100], Step [49500/6235], Loss: 43.9365\n",
      "Epoch [59/100], Step [49600/6235], Loss: 365.8294\n",
      "Epoch [59/100], Step [49700/6235], Loss: 171.7332\n",
      "Epoch [59/100], Step [49800/6235], Loss: 887.3337\n",
      "Epoch [60/100], Step [100/6235], Loss: 1.2320\n",
      "Epoch [60/100], Step [200/6235], Loss: 0.1436\n",
      "Epoch [60/100], Step [300/6235], Loss: 0.0128\n",
      "Epoch [60/100], Step [400/6235], Loss: 0.0021\n",
      "Epoch [60/100], Step [500/6235], Loss: 5.1848\n",
      "Epoch [60/100], Step [600/6235], Loss: 0.0269\n",
      "Epoch [60/100], Step [700/6235], Loss: 0.5280\n",
      "Epoch [60/100], Step [800/6235], Loss: 0.0916\n",
      "Epoch [60/100], Step [900/6235], Loss: 0.0375\n",
      "Epoch [60/100], Step [1000/6235], Loss: 0.0276\n",
      "Epoch [60/100], Step [1100/6235], Loss: 0.0533\n",
      "Epoch [60/100], Step [1200/6235], Loss: 0.1729\n",
      "Epoch [60/100], Step [1300/6235], Loss: 0.0207\n",
      "Epoch [60/100], Step [1400/6235], Loss: 0.0425\n",
      "Epoch [60/100], Step [1500/6235], Loss: 0.0063\n",
      "Epoch [60/100], Step [1600/6235], Loss: 0.2308\n",
      "Epoch [60/100], Step [1700/6235], Loss: 0.0321\n",
      "Epoch [60/100], Step [1800/6235], Loss: 0.2133\n",
      "Epoch [60/100], Step [1900/6235], Loss: 0.3653\n",
      "Epoch [60/100], Step [2000/6235], Loss: 2.2405\n",
      "Epoch [60/100], Step [2100/6235], Loss: 2.1914\n",
      "Epoch [60/100], Step [2200/6235], Loss: 7.8981\n",
      "Epoch [60/100], Step [2300/6235], Loss: 5.0529\n",
      "Epoch [60/100], Step [2400/6235], Loss: 1.2877\n",
      "Epoch [60/100], Step [2500/6235], Loss: 34.1648\n",
      "Epoch [60/100], Step [2600/6235], Loss: 12.4860\n",
      "Epoch [60/100], Step [2700/6235], Loss: 9.9432\n",
      "Epoch [60/100], Step [2800/6235], Loss: 142.5529\n",
      "Epoch [60/100], Step [2900/6235], Loss: 14.4433\n",
      "Epoch [60/100], Step [3000/6235], Loss: 1.0401\n",
      "Epoch [60/100], Step [3100/6235], Loss: 66.2232\n",
      "Epoch [60/100], Step [3200/6235], Loss: 76.0278\n",
      "Epoch [60/100], Step [3300/6235], Loss: 7.7538\n",
      "Epoch [60/100], Step [3400/6235], Loss: 1.9484\n",
      "Epoch [60/100], Step [3500/6235], Loss: 40.1090\n",
      "Epoch [60/100], Step [3600/6235], Loss: 8.1011\n",
      "Epoch [60/100], Step [3700/6235], Loss: 0.0338\n",
      "Epoch [60/100], Step [3800/6235], Loss: 0.1735\n",
      "Epoch [60/100], Step [3900/6235], Loss: 0.5363\n",
      "Epoch [60/100], Step [4000/6235], Loss: 0.0312\n",
      "Epoch [60/100], Step [4100/6235], Loss: 7.3681\n",
      "Epoch [60/100], Step [4200/6235], Loss: 0.9561\n",
      "Epoch [60/100], Step [4300/6235], Loss: 7.8312\n",
      "Epoch [60/100], Step [4400/6235], Loss: 2.7315\n",
      "Epoch [60/100], Step [4500/6235], Loss: 40.7737\n",
      "Epoch [60/100], Step [4600/6235], Loss: 1.4664\n",
      "Epoch [60/100], Step [4700/6235], Loss: 0.0569\n",
      "Epoch [60/100], Step [4800/6235], Loss: 10.3059\n",
      "Epoch [60/100], Step [4900/6235], Loss: 0.2350\n",
      "Epoch [60/100], Step [5000/6235], Loss: 0.0474\n",
      "Epoch [60/100], Step [5100/6235], Loss: 0.8803\n",
      "Epoch [60/100], Step [5200/6235], Loss: 0.3694\n",
      "Epoch [60/100], Step [5300/6235], Loss: 42.5459\n",
      "Epoch [60/100], Step [5400/6235], Loss: 1.7569\n",
      "Epoch [60/100], Step [5500/6235], Loss: 0.1894\n",
      "Epoch [60/100], Step [5600/6235], Loss: 0.3074\n",
      "Epoch [60/100], Step [5700/6235], Loss: 0.0514\n",
      "Epoch [60/100], Step [5800/6235], Loss: 0.1846\n",
      "Epoch [60/100], Step [5900/6235], Loss: 0.0866\n",
      "Epoch [60/100], Step [6000/6235], Loss: 3.4249\n",
      "Epoch [60/100], Step [6100/6235], Loss: 0.0112\n",
      "Epoch [60/100], Step [6200/6235], Loss: 2.5620\n",
      "Epoch [60/100], Step [6300/6235], Loss: 0.9532\n",
      "Epoch [60/100], Step [6400/6235], Loss: 0.0362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Step [6500/6235], Loss: 2.4923\n",
      "Epoch [60/100], Step [6600/6235], Loss: 5.2015\n",
      "Epoch [60/100], Step [6700/6235], Loss: 3.2228\n",
      "Epoch [60/100], Step [6800/6235], Loss: 1.4412\n",
      "Epoch [60/100], Step [6900/6235], Loss: 0.4460\n",
      "Epoch [60/100], Step [7000/6235], Loss: 0.0731\n",
      "Epoch [60/100], Step [7100/6235], Loss: 0.5599\n",
      "Epoch [60/100], Step [7200/6235], Loss: 0.1311\n",
      "Epoch [60/100], Step [7300/6235], Loss: 0.1203\n",
      "Epoch [60/100], Step [7400/6235], Loss: 0.0702\n",
      "Epoch [60/100], Step [7500/6235], Loss: 0.9126\n",
      "Epoch [60/100], Step [7600/6235], Loss: 3.0291\n",
      "Epoch [60/100], Step [7700/6235], Loss: 14.1897\n",
      "Epoch [60/100], Step [7800/6235], Loss: 1.7480\n",
      "Epoch [60/100], Step [7900/6235], Loss: 4.5155\n",
      "Epoch [60/100], Step [8000/6235], Loss: 0.2113\n",
      "Epoch [60/100], Step [8100/6235], Loss: 4.5549\n",
      "Epoch [60/100], Step [8200/6235], Loss: 12.9597\n",
      "Epoch [60/100], Step [8300/6235], Loss: 43.3991\n",
      "Epoch [60/100], Step [8400/6235], Loss: 241.7282\n",
      "Epoch [60/100], Step [8500/6235], Loss: 1.4003\n",
      "Epoch [60/100], Step [8600/6235], Loss: 115.1200\n",
      "Epoch [60/100], Step [8700/6235], Loss: 47.6225\n",
      "Epoch [60/100], Step [8800/6235], Loss: 404.3608\n",
      "Epoch [60/100], Step [8900/6235], Loss: 353.4308\n",
      "Epoch [60/100], Step [9000/6235], Loss: 335.3785\n",
      "Epoch [60/100], Step [9100/6235], Loss: 1573.1494\n",
      "Epoch [60/100], Step [9200/6235], Loss: 2908.7117\n",
      "Epoch [60/100], Step [9300/6235], Loss: 106.6196\n",
      "Epoch [60/100], Step [9400/6235], Loss: 32.0354\n",
      "Epoch [60/100], Step [9500/6235], Loss: 2712.3523\n",
      "Epoch [60/100], Step [9600/6235], Loss: 498.6205\n",
      "Epoch [60/100], Step [9700/6235], Loss: 8.7111\n",
      "Epoch [60/100], Step [9800/6235], Loss: 3066.2253\n",
      "Epoch [60/100], Step [9900/6235], Loss: 491.6113\n",
      "Epoch [60/100], Step [10000/6235], Loss: 668.6854\n",
      "Epoch [60/100], Step [10100/6235], Loss: 3.7641\n",
      "Epoch [60/100], Step [10200/6235], Loss: 564.4692\n",
      "Epoch [60/100], Step [10300/6235], Loss: 5.3590\n",
      "Epoch [60/100], Step [10400/6235], Loss: 0.7900\n",
      "Epoch [60/100], Step [10500/6235], Loss: 2.9625\n",
      "Epoch [60/100], Step [10600/6235], Loss: 20.3354\n",
      "Epoch [60/100], Step [10700/6235], Loss: 58.6796\n",
      "Epoch [60/100], Step [10800/6235], Loss: 12.0164\n",
      "Epoch [60/100], Step [10900/6235], Loss: 6.6845\n",
      "Epoch [60/100], Step [11000/6235], Loss: 269.2036\n",
      "Epoch [60/100], Step [11100/6235], Loss: 15.2523\n",
      "Epoch [60/100], Step [11200/6235], Loss: 75.1208\n",
      "Epoch [60/100], Step [11300/6235], Loss: 197.9715\n",
      "Epoch [60/100], Step [11400/6235], Loss: 7.4800\n",
      "Epoch [60/100], Step [11500/6235], Loss: 1.3389\n",
      "Epoch [60/100], Step [11600/6235], Loss: 0.8304\n",
      "Epoch [60/100], Step [11700/6235], Loss: 38.5472\n",
      "Epoch [60/100], Step [11800/6235], Loss: 392.0629\n",
      "Epoch [60/100], Step [11900/6235], Loss: 420.1954\n",
      "Epoch [60/100], Step [12000/6235], Loss: 321.1318\n",
      "Epoch [60/100], Step [12100/6235], Loss: 181.6228\n",
      "Epoch [60/100], Step [12200/6235], Loss: 127.1636\n",
      "Epoch [60/100], Step [12300/6235], Loss: 24.9103\n",
      "Epoch [60/100], Step [12400/6235], Loss: 255.4844\n",
      "Epoch [60/100], Step [12500/6235], Loss: 5.0705\n",
      "Epoch [60/100], Step [12600/6235], Loss: 121.0490\n",
      "Epoch [60/100], Step [12700/6235], Loss: 3.5449\n",
      "Epoch [60/100], Step [12800/6235], Loss: 7.0169\n",
      "Epoch [60/100], Step [12900/6235], Loss: 43.1013\n",
      "Epoch [60/100], Step [13000/6235], Loss: 0.8899\n",
      "Epoch [60/100], Step [13100/6235], Loss: 70.5613\n",
      "Epoch [60/100], Step [13200/6235], Loss: 16.9522\n",
      "Epoch [60/100], Step [13300/6235], Loss: 57.4547\n",
      "Epoch [60/100], Step [13400/6235], Loss: 250.3799\n",
      "Epoch [60/100], Step [13500/6235], Loss: 3.5018\n",
      "Epoch [60/100], Step [13600/6235], Loss: 1.3230\n",
      "Epoch [60/100], Step [13700/6235], Loss: 122.4837\n",
      "Epoch [60/100], Step [13800/6235], Loss: 153.5437\n",
      "Epoch [60/100], Step [13900/6235], Loss: 26.7082\n",
      "Epoch [60/100], Step [14000/6235], Loss: 14.6289\n",
      "Epoch [60/100], Step [14100/6235], Loss: 41.7356\n",
      "Epoch [60/100], Step [14200/6235], Loss: 130.0346\n",
      "Epoch [60/100], Step [14300/6235], Loss: 60.2849\n",
      "Epoch [60/100], Step [14400/6235], Loss: 38.2885\n",
      "Epoch [60/100], Step [14500/6235], Loss: 57.8276\n",
      "Epoch [60/100], Step [14600/6235], Loss: 0.1432\n",
      "Epoch [60/100], Step [14700/6235], Loss: 45.1245\n",
      "Epoch [60/100], Step [14800/6235], Loss: 32.6011\n",
      "Epoch [60/100], Step [14900/6235], Loss: 1.3232\n",
      "Epoch [60/100], Step [15000/6235], Loss: 2.3580\n",
      "Epoch [60/100], Step [15100/6235], Loss: 0.3321\n",
      "Epoch [60/100], Step [15200/6235], Loss: 1.4708\n",
      "Epoch [60/100], Step [15300/6235], Loss: 38.2549\n",
      "Epoch [60/100], Step [15400/6235], Loss: 51.0406\n",
      "Epoch [60/100], Step [15500/6235], Loss: 10.2396\n",
      "Epoch [60/100], Step [15600/6235], Loss: 51.1769\n",
      "Epoch [60/100], Step [15700/6235], Loss: 3.0621\n",
      "Epoch [60/100], Step [15800/6235], Loss: 1.4270\n",
      "Epoch [60/100], Step [15900/6235], Loss: 1.3728\n",
      "Epoch [60/100], Step [16000/6235], Loss: 13.6023\n",
      "Epoch [60/100], Step [16100/6235], Loss: 18.0491\n",
      "Epoch [60/100], Step [16200/6235], Loss: 0.3620\n",
      "Epoch [60/100], Step [16300/6235], Loss: 11.7271\n",
      "Epoch [60/100], Step [16400/6235], Loss: 35.8708\n",
      "Epoch [60/100], Step [16500/6235], Loss: 713.1722\n",
      "Epoch [60/100], Step [16600/6235], Loss: 18.6535\n",
      "Epoch [60/100], Step [16700/6235], Loss: 0.7363\n",
      "Epoch [60/100], Step [16800/6235], Loss: 8.5643\n",
      "Epoch [60/100], Step [16900/6235], Loss: 0.0985\n",
      "Epoch [60/100], Step [17000/6235], Loss: 0.2843\n",
      "Epoch [60/100], Step [17100/6235], Loss: 0.5078\n",
      "Epoch [60/100], Step [17200/6235], Loss: 309.9534\n",
      "Epoch [60/100], Step [17300/6235], Loss: 44.4837\n",
      "Epoch [60/100], Step [17400/6235], Loss: 32.4615\n",
      "Epoch [60/100], Step [17500/6235], Loss: 0.5829\n",
      "Epoch [60/100], Step [17600/6235], Loss: 3.9555\n",
      "Epoch [60/100], Step [17700/6235], Loss: 40.5017\n",
      "Epoch [60/100], Step [17800/6235], Loss: 19.4331\n",
      "Epoch [60/100], Step [17900/6235], Loss: 9.4392\n",
      "Epoch [60/100], Step [18000/6235], Loss: 9.0779\n",
      "Epoch [60/100], Step [18100/6235], Loss: 16.1682\n",
      "Epoch [60/100], Step [18200/6235], Loss: 0.3805\n",
      "Epoch [60/100], Step [18300/6235], Loss: 1.9363\n",
      "Epoch [60/100], Step [18400/6235], Loss: 0.4560\n",
      "Epoch [60/100], Step [18500/6235], Loss: 17.9589\n",
      "Epoch [60/100], Step [18600/6235], Loss: 3.4689\n",
      "Epoch [60/100], Step [18700/6235], Loss: 0.8915\n",
      "Epoch [60/100], Step [18800/6235], Loss: 93.0174\n",
      "Epoch [60/100], Step [18900/6235], Loss: 35.9038\n",
      "Epoch [60/100], Step [19000/6235], Loss: 2.9201\n",
      "Epoch [60/100], Step [19100/6235], Loss: 1.3812\n",
      "Epoch [60/100], Step [19200/6235], Loss: 4.6038\n",
      "Epoch [60/100], Step [19300/6235], Loss: 8.9535\n",
      "Epoch [60/100], Step [19400/6235], Loss: 78.0817\n",
      "Epoch [60/100], Step [19500/6235], Loss: 148.2291\n",
      "Epoch [60/100], Step [19600/6235], Loss: 99.4427\n",
      "Epoch [60/100], Step [19700/6235], Loss: 9.5816\n",
      "Epoch [60/100], Step [19800/6235], Loss: 1.3778\n",
      "Epoch [60/100], Step [19900/6235], Loss: 0.1624\n",
      "Epoch [60/100], Step [20000/6235], Loss: 84.5707\n",
      "Epoch [60/100], Step [20100/6235], Loss: 0.5012\n",
      "Epoch [60/100], Step [20200/6235], Loss: 7.2130\n",
      "Epoch [60/100], Step [20300/6235], Loss: 2.0074\n",
      "Epoch [60/100], Step [20400/6235], Loss: 18.6809\n",
      "Epoch [60/100], Step [20500/6235], Loss: 47.1824\n",
      "Epoch [60/100], Step [20600/6235], Loss: 110.2428\n",
      "Epoch [60/100], Step [20700/6235], Loss: 5.0736\n",
      "Epoch [60/100], Step [20800/6235], Loss: 4.7144\n",
      "Epoch [60/100], Step [20900/6235], Loss: 18.5734\n",
      "Epoch [60/100], Step [21000/6235], Loss: 13.2973\n",
      "Epoch [60/100], Step [21100/6235], Loss: 6.7063\n",
      "Epoch [60/100], Step [21200/6235], Loss: 0.2544\n",
      "Epoch [60/100], Step [21300/6235], Loss: 0.1645\n",
      "Epoch [60/100], Step [21400/6235], Loss: 5.6248\n",
      "Epoch [60/100], Step [21500/6235], Loss: 2.6788\n",
      "Epoch [60/100], Step [21600/6235], Loss: 31.2818\n",
      "Epoch [60/100], Step [21700/6235], Loss: 0.2308\n",
      "Epoch [60/100], Step [21800/6235], Loss: 0.4723\n",
      "Epoch [60/100], Step [21900/6235], Loss: 1.6182\n",
      "Epoch [60/100], Step [22000/6235], Loss: 8.3740\n",
      "Epoch [60/100], Step [22100/6235], Loss: 0.2816\n",
      "Epoch [60/100], Step [22200/6235], Loss: 2.4952\n",
      "Epoch [60/100], Step [22300/6235], Loss: 2.0933\n",
      "Epoch [60/100], Step [22400/6235], Loss: 8.0404\n",
      "Epoch [60/100], Step [22500/6235], Loss: 76.1867\n",
      "Epoch [60/100], Step [22600/6235], Loss: 20.6625\n",
      "Epoch [60/100], Step [22700/6235], Loss: 2.2050\n",
      "Epoch [60/100], Step [22800/6235], Loss: 4.4291\n",
      "Epoch [60/100], Step [22900/6235], Loss: 9.8670\n",
      "Epoch [60/100], Step [23000/6235], Loss: 13.8811\n",
      "Epoch [60/100], Step [23100/6235], Loss: 7.9850\n",
      "Epoch [60/100], Step [23200/6235], Loss: 10.1700\n",
      "Epoch [60/100], Step [23300/6235], Loss: 17.5993\n",
      "Epoch [60/100], Step [23400/6235], Loss: 2.6834\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Step [23500/6235], Loss: 0.1394\n",
      "Epoch [60/100], Step [23600/6235], Loss: 131.5035\n",
      "Epoch [60/100], Step [23700/6235], Loss: 3.5018\n",
      "Epoch [60/100], Step [23800/6235], Loss: 0.8662\n",
      "Epoch [60/100], Step [23900/6235], Loss: 1.3765\n",
      "Epoch [60/100], Step [24000/6235], Loss: 0.9258\n",
      "Epoch [60/100], Step [24100/6235], Loss: 0.3900\n",
      "Epoch [60/100], Step [24200/6235], Loss: 15.4328\n",
      "Epoch [60/100], Step [24300/6235], Loss: 1.1903\n",
      "Epoch [60/100], Step [24400/6235], Loss: 3.0591\n",
      "Epoch [60/100], Step [24500/6235], Loss: 0.4543\n",
      "Epoch [60/100], Step [24600/6235], Loss: 0.1881\n",
      "Epoch [60/100], Step [24700/6235], Loss: 0.7599\n",
      "Epoch [60/100], Step [24800/6235], Loss: 0.2937\n",
      "Epoch [60/100], Step [24900/6235], Loss: 8.1013\n",
      "Epoch [60/100], Step [25000/6235], Loss: 11.3304\n",
      "Epoch [60/100], Step [25100/6235], Loss: 6.4727\n",
      "Epoch [60/100], Step [25200/6235], Loss: 0.1191\n",
      "Epoch [60/100], Step [25300/6235], Loss: 0.8147\n",
      "Epoch [60/100], Step [25400/6235], Loss: 8.7939\n",
      "Epoch [60/100], Step [25500/6235], Loss: 9.1595\n",
      "Epoch [60/100], Step [25600/6235], Loss: 6.8517\n",
      "Epoch [60/100], Step [25700/6235], Loss: 0.1073\n",
      "Epoch [60/100], Step [25800/6235], Loss: 0.0724\n",
      "Epoch [60/100], Step [25900/6235], Loss: 4.9598\n",
      "Epoch [60/100], Step [26000/6235], Loss: 0.1352\n",
      "Epoch [60/100], Step [26100/6235], Loss: 0.0777\n",
      "Epoch [60/100], Step [26200/6235], Loss: 1.2219\n",
      "Epoch [60/100], Step [26300/6235], Loss: 2.7693\n",
      "Epoch [60/100], Step [26400/6235], Loss: 0.2203\n",
      "Epoch [60/100], Step [26500/6235], Loss: 0.0226\n",
      "Epoch [60/100], Step [26600/6235], Loss: 0.6456\n",
      "Epoch [60/100], Step [26700/6235], Loss: 0.2291\n",
      "Epoch [60/100], Step [26800/6235], Loss: 0.1169\n",
      "Epoch [60/100], Step [26900/6235], Loss: 0.0195\n",
      "Epoch [60/100], Step [27000/6235], Loss: 16.0895\n",
      "Epoch [60/100], Step [27100/6235], Loss: 0.0547\n",
      "Epoch [60/100], Step [27200/6235], Loss: 0.0115\n",
      "Epoch [60/100], Step [27300/6235], Loss: 0.1013\n",
      "Epoch [60/100], Step [27400/6235], Loss: 0.6884\n",
      "Epoch [60/100], Step [27500/6235], Loss: 9.5768\n",
      "Epoch [60/100], Step [27600/6235], Loss: 1.1546\n",
      "Epoch [60/100], Step [27700/6235], Loss: 1.6470\n",
      "Epoch [60/100], Step [27800/6235], Loss: 6.2672\n",
      "Epoch [60/100], Step [27900/6235], Loss: 4.4491\n",
      "Epoch [60/100], Step [28000/6235], Loss: 102.1045\n",
      "Epoch [60/100], Step [28100/6235], Loss: 9.6126\n",
      "Epoch [60/100], Step [28200/6235], Loss: 35.3025\n",
      "Epoch [60/100], Step [28300/6235], Loss: 2.6905\n",
      "Epoch [60/100], Step [28400/6235], Loss: 25.5036\n",
      "Epoch [60/100], Step [28500/6235], Loss: 4.6166\n",
      "Epoch [60/100], Step [28600/6235], Loss: 0.0715\n",
      "Epoch [60/100], Step [28700/6235], Loss: 5.3240\n",
      "Epoch [60/100], Step [28800/6235], Loss: 0.6394\n",
      "Epoch [60/100], Step [28900/6235], Loss: 67.4668\n",
      "Epoch [60/100], Step [29000/6235], Loss: 8.8096\n",
      "Epoch [60/100], Step [29100/6235], Loss: 0.2740\n",
      "Epoch [60/100], Step [29200/6235], Loss: 2.0207\n",
      "Epoch [60/100], Step [29300/6235], Loss: 5.3802\n",
      "Epoch [60/100], Step [29400/6235], Loss: 0.4589\n",
      "Epoch [60/100], Step [29500/6235], Loss: 3.8667\n",
      "Epoch [60/100], Step [29600/6235], Loss: 0.1496\n",
      "Epoch [60/100], Step [29700/6235], Loss: 1.5688\n",
      "Epoch [60/100], Step [29800/6235], Loss: 1.5376\n",
      "Epoch [60/100], Step [29900/6235], Loss: 0.7847\n",
      "Epoch [60/100], Step [30000/6235], Loss: 5.1090\n",
      "Epoch [60/100], Step [30100/6235], Loss: 11.6885\n",
      "Epoch [60/100], Step [30200/6235], Loss: 1.2247\n",
      "Epoch [60/100], Step [30300/6235], Loss: 0.0181\n",
      "Epoch [60/100], Step [30400/6235], Loss: 1.1470\n",
      "Epoch [60/100], Step [30500/6235], Loss: 3.1196\n",
      "Epoch [60/100], Step [30600/6235], Loss: 1.7796\n",
      "Epoch [60/100], Step [30700/6235], Loss: 0.5754\n",
      "Epoch [60/100], Step [30800/6235], Loss: 0.5094\n",
      "Epoch [60/100], Step [30900/6235], Loss: 3.8131\n",
      "Epoch [60/100], Step [31000/6235], Loss: 0.1599\n",
      "Epoch [60/100], Step [31100/6235], Loss: 0.0609\n",
      "Epoch [60/100], Step [31200/6235], Loss: 6.3629\n",
      "Epoch [60/100], Step [31300/6235], Loss: 0.9816\n",
      "Epoch [60/100], Step [31400/6235], Loss: 4.7026\n",
      "Epoch [60/100], Step [31500/6235], Loss: 0.8764\n",
      "Epoch [60/100], Step [31600/6235], Loss: 5.8996\n",
      "Epoch [60/100], Step [31700/6235], Loss: 15.1784\n",
      "Epoch [60/100], Step [31800/6235], Loss: 1.1083\n",
      "Epoch [60/100], Step [31900/6235], Loss: 1285.6338\n",
      "Epoch [60/100], Step [32000/6235], Loss: 1.4405\n",
      "Epoch [60/100], Step [32100/6235], Loss: 0.3033\n",
      "Epoch [60/100], Step [32200/6235], Loss: 77.4653\n",
      "Epoch [60/100], Step [32300/6235], Loss: 0.8755\n",
      "Epoch [60/100], Step [32400/6235], Loss: 1.1879\n",
      "Epoch [60/100], Step [32500/6235], Loss: 12.7627\n",
      "Epoch [60/100], Step [32600/6235], Loss: 0.4261\n",
      "Epoch [60/100], Step [32700/6235], Loss: 96.5670\n",
      "Epoch [60/100], Step [32800/6235], Loss: 3.8065\n",
      "Epoch [60/100], Step [32900/6235], Loss: 0.9557\n",
      "Epoch [60/100], Step [33000/6235], Loss: 0.3804\n",
      "Epoch [60/100], Step [33100/6235], Loss: 1.0275\n",
      "Epoch [60/100], Step [33200/6235], Loss: 0.8345\n",
      "Epoch [60/100], Step [33300/6235], Loss: 5.2340\n",
      "Epoch [60/100], Step [33400/6235], Loss: 22.9795\n",
      "Epoch [60/100], Step [33500/6235], Loss: 1.6232\n",
      "Epoch [60/100], Step [33600/6235], Loss: 9.6755\n",
      "Epoch [60/100], Step [33700/6235], Loss: 15.1708\n",
      "Epoch [60/100], Step [33800/6235], Loss: 0.4230\n",
      "Epoch [60/100], Step [33900/6235], Loss: 33.3698\n",
      "Epoch [60/100], Step [34000/6235], Loss: 0.1021\n",
      "Epoch [60/100], Step [34100/6235], Loss: 0.6085\n",
      "Epoch [60/100], Step [34200/6235], Loss: 3.0922\n",
      "Epoch [60/100], Step [34300/6235], Loss: 3.5668\n",
      "Epoch [60/100], Step [34400/6235], Loss: 0.1986\n",
      "Epoch [60/100], Step [34500/6235], Loss: 44.1300\n",
      "Epoch [60/100], Step [34600/6235], Loss: 0.0698\n",
      "Epoch [60/100], Step [34700/6235], Loss: 2.1728\n",
      "Epoch [60/100], Step [34800/6235], Loss: 9.7900\n",
      "Epoch [60/100], Step [34900/6235], Loss: 47.3021\n",
      "Epoch [60/100], Step [35000/6235], Loss: 2.4967\n",
      "Epoch [60/100], Step [35100/6235], Loss: 4.4789\n",
      "Epoch [60/100], Step [35200/6235], Loss: 1.2054\n",
      "Epoch [60/100], Step [35300/6235], Loss: 0.5929\n",
      "Epoch [60/100], Step [35400/6235], Loss: 0.4828\n",
      "Epoch [60/100], Step [35500/6235], Loss: 1.8528\n",
      "Epoch [60/100], Step [35600/6235], Loss: 4.2895\n",
      "Epoch [60/100], Step [35700/6235], Loss: 4.4602\n",
      "Epoch [60/100], Step [35800/6235], Loss: 0.6235\n",
      "Epoch [60/100], Step [35900/6235], Loss: 2.7415\n",
      "Epoch [60/100], Step [36000/6235], Loss: 0.1275\n",
      "Epoch [60/100], Step [36100/6235], Loss: 0.0223\n",
      "Epoch [60/100], Step [36200/6235], Loss: 21.9454\n",
      "Epoch [60/100], Step [36300/6235], Loss: 0.3663\n",
      "Epoch [60/100], Step [36400/6235], Loss: 2.6492\n",
      "Epoch [60/100], Step [36500/6235], Loss: 8.4902\n",
      "Epoch [60/100], Step [36600/6235], Loss: 0.1207\n",
      "Epoch [60/100], Step [36700/6235], Loss: 0.5108\n",
      "Epoch [60/100], Step [36800/6235], Loss: 9.6718\n",
      "Epoch [60/100], Step [36900/6235], Loss: 11.0640\n",
      "Epoch [60/100], Step [37000/6235], Loss: 0.6938\n",
      "Epoch [60/100], Step [37100/6235], Loss: 1.4158\n",
      "Epoch [60/100], Step [37200/6235], Loss: 0.0676\n",
      "Epoch [60/100], Step [37300/6235], Loss: 0.0352\n",
      "Epoch [60/100], Step [37400/6235], Loss: 0.1996\n",
      "Epoch [60/100], Step [37500/6235], Loss: 5.4232\n",
      "Epoch [60/100], Step [37600/6235], Loss: 11.9968\n",
      "Epoch [60/100], Step [37700/6235], Loss: 2.0451\n",
      "Epoch [60/100], Step [37800/6235], Loss: 3.5659\n",
      "Epoch [60/100], Step [37900/6235], Loss: 8.2475\n",
      "Epoch [60/100], Step [38000/6235], Loss: 0.7949\n",
      "Epoch [60/100], Step [38100/6235], Loss: 4.0585\n",
      "Epoch [60/100], Step [38200/6235], Loss: 1.4075\n",
      "Epoch [60/100], Step [38300/6235], Loss: 0.4618\n",
      "Epoch [60/100], Step [38400/6235], Loss: 0.0440\n",
      "Epoch [60/100], Step [38500/6235], Loss: 1.9762\n",
      "Epoch [60/100], Step [38600/6235], Loss: 0.2998\n",
      "Epoch [60/100], Step [38700/6235], Loss: 0.0287\n",
      "Epoch [60/100], Step [38800/6235], Loss: 0.1612\n",
      "Epoch [60/100], Step [38900/6235], Loss: 1.4015\n",
      "Epoch [60/100], Step [39000/6235], Loss: 15.8511\n",
      "Epoch [60/100], Step [39100/6235], Loss: 18.6123\n",
      "Epoch [60/100], Step [39200/6235], Loss: 0.3912\n",
      "Epoch [60/100], Step [39300/6235], Loss: 57.9114\n",
      "Epoch [60/100], Step [39400/6235], Loss: 47.4814\n",
      "Epoch [60/100], Step [39500/6235], Loss: 61.1114\n",
      "Epoch [60/100], Step [39600/6235], Loss: 16.0041\n",
      "Epoch [60/100], Step [39700/6235], Loss: 67.0396\n",
      "Epoch [60/100], Step [39800/6235], Loss: 185.3863\n",
      "Epoch [60/100], Step [39900/6235], Loss: 0.5773\n",
      "Epoch [60/100], Step [40000/6235], Loss: 10.8263\n",
      "Epoch [60/100], Step [40100/6235], Loss: 18.1254\n",
      "Epoch [60/100], Step [40200/6235], Loss: 3.4111\n",
      "Epoch [60/100], Step [40300/6235], Loss: 0.3393\n",
      "Epoch [60/100], Step [40400/6235], Loss: 1.5380\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [60/100], Step [40500/6235], Loss: 2.6496\n",
      "Epoch [60/100], Step [40600/6235], Loss: 0.1725\n",
      "Epoch [60/100], Step [40700/6235], Loss: 7.0802\n",
      "Epoch [60/100], Step [40800/6235], Loss: 0.5293\n",
      "Epoch [60/100], Step [40900/6235], Loss: 0.6538\n",
      "Epoch [60/100], Step [41000/6235], Loss: 46.5209\n",
      "Epoch [60/100], Step [41100/6235], Loss: 50.3864\n",
      "Epoch [60/100], Step [41200/6235], Loss: 3.1257\n",
      "Epoch [60/100], Step [41300/6235], Loss: 3.8003\n",
      "Epoch [60/100], Step [41400/6235], Loss: 0.0408\n",
      "Epoch [60/100], Step [41500/6235], Loss: 0.7931\n",
      "Epoch [60/100], Step [41600/6235], Loss: 0.6627\n",
      "Epoch [60/100], Step [41700/6235], Loss: 2.6265\n",
      "Epoch [60/100], Step [41800/6235], Loss: 3.2132\n",
      "Epoch [60/100], Step [41900/6235], Loss: 3.8896\n",
      "Epoch [60/100], Step [42000/6235], Loss: 3.2266\n",
      "Epoch [60/100], Step [42100/6235], Loss: 7.5334\n",
      "Epoch [60/100], Step [42200/6235], Loss: 3.8703\n",
      "Epoch [60/100], Step [42300/6235], Loss: 3.4052\n",
      "Epoch [60/100], Step [42400/6235], Loss: 0.3025\n",
      "Epoch [60/100], Step [42500/6235], Loss: 2.8694\n",
      "Epoch [60/100], Step [42600/6235], Loss: 0.7531\n",
      "Epoch [60/100], Step [42700/6235], Loss: 0.3789\n",
      "Epoch [60/100], Step [42800/6235], Loss: 3.2205\n",
      "Epoch [60/100], Step [42900/6235], Loss: 3.4600\n",
      "Epoch [60/100], Step [43000/6235], Loss: 0.2173\n",
      "Epoch [60/100], Step [43100/6235], Loss: 0.2913\n",
      "Epoch [60/100], Step [43200/6235], Loss: 1.0850\n",
      "Epoch [60/100], Step [43300/6235], Loss: 8.5553\n",
      "Epoch [60/100], Step [43400/6235], Loss: 10.6267\n",
      "Epoch [60/100], Step [43500/6235], Loss: 9.5450\n",
      "Epoch [60/100], Step [43600/6235], Loss: 12.5905\n",
      "Epoch [60/100], Step [43700/6235], Loss: 25.5008\n",
      "Epoch [60/100], Step [43800/6235], Loss: 7.8520\n",
      "Epoch [60/100], Step [43900/6235], Loss: 2.3925\n",
      "Epoch [60/100], Step [44000/6235], Loss: 34.0986\n",
      "Epoch [60/100], Step [44100/6235], Loss: 1.4856\n",
      "Epoch [60/100], Step [44200/6235], Loss: 2.4873\n",
      "Epoch [60/100], Step [44300/6235], Loss: 44.3083\n",
      "Epoch [60/100], Step [44400/6235], Loss: 3.4427\n",
      "Epoch [60/100], Step [44500/6235], Loss: 0.4599\n",
      "Epoch [60/100], Step [44600/6235], Loss: 25.8080\n",
      "Epoch [60/100], Step [44700/6235], Loss: 7.2935\n",
      "Epoch [60/100], Step [44800/6235], Loss: 2.1033\n",
      "Epoch [60/100], Step [44900/6235], Loss: 10.0190\n",
      "Epoch [60/100], Step [45000/6235], Loss: 6.3175\n",
      "Epoch [60/100], Step [45100/6235], Loss: 47.4232\n",
      "Epoch [60/100], Step [45200/6235], Loss: 1.2173\n",
      "Epoch [60/100], Step [45300/6235], Loss: 24.4912\n",
      "Epoch [60/100], Step [45400/6235], Loss: 12.2942\n",
      "Epoch [60/100], Step [45500/6235], Loss: 2.7330\n",
      "Epoch [60/100], Step [45600/6235], Loss: 0.9292\n",
      "Epoch [60/100], Step [45700/6235], Loss: 129.6490\n",
      "Epoch [60/100], Step [45800/6235], Loss: 231.3153\n",
      "Epoch [60/100], Step [45900/6235], Loss: 3.1989\n",
      "Epoch [60/100], Step [46000/6235], Loss: 30.8384\n",
      "Epoch [60/100], Step [46100/6235], Loss: 164.2199\n",
      "Epoch [60/100], Step [46200/6235], Loss: 17.9523\n",
      "Epoch [60/100], Step [46300/6235], Loss: 7.8440\n",
      "Epoch [60/100], Step [46400/6235], Loss: 14.5283\n",
      "Epoch [60/100], Step [46500/6235], Loss: 5.2162\n",
      "Epoch [60/100], Step [46600/6235], Loss: 9.4745\n",
      "Epoch [60/100], Step [46700/6235], Loss: 1.6424\n",
      "Epoch [60/100], Step [46800/6235], Loss: 1.8080\n",
      "Epoch [60/100], Step [46900/6235], Loss: 1.4357\n",
      "Epoch [60/100], Step [47000/6235], Loss: 8.1650\n",
      "Epoch [60/100], Step [47100/6235], Loss: 2.7638\n",
      "Epoch [60/100], Step [47200/6235], Loss: 11.6865\n",
      "Epoch [60/100], Step [47300/6235], Loss: 1.1804\n",
      "Epoch [60/100], Step [47400/6235], Loss: 75.4007\n",
      "Epoch [60/100], Step [47500/6235], Loss: 33.4525\n",
      "Epoch [60/100], Step [47600/6235], Loss: 8.0087\n",
      "Epoch [60/100], Step [47700/6235], Loss: 21.6313\n",
      "Epoch [60/100], Step [47800/6235], Loss: 10.1692\n",
      "Epoch [60/100], Step [47900/6235], Loss: 4.4759\n",
      "Epoch [60/100], Step [48000/6235], Loss: 131.8973\n",
      "Epoch [60/100], Step [48100/6235], Loss: 73.1369\n",
      "Epoch [60/100], Step [48200/6235], Loss: 64.7346\n",
      "Epoch [60/100], Step [48300/6235], Loss: 938.0610\n",
      "Epoch [60/100], Step [48400/6235], Loss: 8.7949\n",
      "Epoch [60/100], Step [48500/6235], Loss: 13.3429\n",
      "Epoch [60/100], Step [48600/6235], Loss: 21.0700\n",
      "Epoch [60/100], Step [48700/6235], Loss: 44.3430\n",
      "Epoch [60/100], Step [48800/6235], Loss: 129.9334\n",
      "Epoch [60/100], Step [48900/6235], Loss: 240.7691\n",
      "Epoch [60/100], Step [49000/6235], Loss: 201.9729\n",
      "Epoch [60/100], Step [49100/6235], Loss: 3250.5847\n",
      "Epoch [60/100], Step [49200/6235], Loss: 584.9721\n",
      "Epoch [60/100], Step [49300/6235], Loss: 879.7958\n",
      "Epoch [60/100], Step [49400/6235], Loss: 118.6897\n",
      "Epoch [60/100], Step [49500/6235], Loss: 11.4553\n",
      "Epoch [60/100], Step [49600/6235], Loss: 189.2791\n",
      "Epoch [60/100], Step [49700/6235], Loss: 1559.1003\n",
      "Epoch [60/100], Step [49800/6235], Loss: 424.8343\n",
      "Epoch [61/100], Step [100/6235], Loss: 33.2327\n",
      "Epoch [61/100], Step [200/6235], Loss: 0.1688\n",
      "Epoch [61/100], Step [300/6235], Loss: 0.0056\n",
      "Epoch [61/100], Step [400/6235], Loss: 0.0023\n",
      "Epoch [61/100], Step [500/6235], Loss: 0.3462\n",
      "Epoch [61/100], Step [600/6235], Loss: 0.0219\n",
      "Epoch [61/100], Step [700/6235], Loss: 0.6001\n",
      "Epoch [61/100], Step [800/6235], Loss: 0.0275\n",
      "Epoch [61/100], Step [900/6235], Loss: 0.0674\n",
      "Epoch [61/100], Step [1000/6235], Loss: 0.0221\n",
      "Epoch [61/100], Step [1100/6235], Loss: 0.0618\n",
      "Epoch [61/100], Step [1200/6235], Loss: 0.1591\n",
      "Epoch [61/100], Step [1300/6235], Loss: 0.0084\n",
      "Epoch [61/100], Step [1400/6235], Loss: 0.1483\n",
      "Epoch [61/100], Step [1500/6235], Loss: 0.0070\n",
      "Epoch [61/100], Step [1600/6235], Loss: 0.2459\n",
      "Epoch [61/100], Step [1700/6235], Loss: 0.2262\n",
      "Epoch [61/100], Step [1800/6235], Loss: 0.2812\n",
      "Epoch [61/100], Step [1900/6235], Loss: 0.2838\n",
      "Epoch [61/100], Step [2000/6235], Loss: 2.1625\n",
      "Epoch [61/100], Step [2100/6235], Loss: 2.5868\n",
      "Epoch [61/100], Step [2200/6235], Loss: 4.9771\n",
      "Epoch [61/100], Step [2300/6235], Loss: 0.6872\n",
      "Epoch [61/100], Step [2400/6235], Loss: 1.8116\n",
      "Epoch [61/100], Step [2500/6235], Loss: 27.5772\n",
      "Epoch [61/100], Step [2600/6235], Loss: 15.6156\n",
      "Epoch [61/100], Step [2700/6235], Loss: 9.4462\n",
      "Epoch [61/100], Step [2800/6235], Loss: 129.3448\n",
      "Epoch [61/100], Step [2900/6235], Loss: 16.8620\n",
      "Epoch [61/100], Step [3000/6235], Loss: 0.7390\n",
      "Epoch [61/100], Step [3100/6235], Loss: 69.0563\n",
      "Epoch [61/100], Step [3200/6235], Loss: 38.3948\n",
      "Epoch [61/100], Step [3300/6235], Loss: 9.8165\n",
      "Epoch [61/100], Step [3400/6235], Loss: 4.2005\n",
      "Epoch [61/100], Step [3500/6235], Loss: 53.8856\n",
      "Epoch [61/100], Step [3600/6235], Loss: 0.8581\n",
      "Epoch [61/100], Step [3700/6235], Loss: 0.0935\n",
      "Epoch [61/100], Step [3800/6235], Loss: 0.0502\n",
      "Epoch [61/100], Step [3900/6235], Loss: 0.1124\n",
      "Epoch [61/100], Step [4000/6235], Loss: 0.1020\n",
      "Epoch [61/100], Step [4100/6235], Loss: 9.8437\n",
      "Epoch [61/100], Step [4200/6235], Loss: 4.1895\n",
      "Epoch [61/100], Step [4300/6235], Loss: 4.5019\n",
      "Epoch [61/100], Step [4400/6235], Loss: 0.5490\n",
      "Epoch [61/100], Step [4500/6235], Loss: 41.4279\n",
      "Epoch [61/100], Step [4600/6235], Loss: 1.5775\n",
      "Epoch [61/100], Step [4700/6235], Loss: 0.2763\n",
      "Epoch [61/100], Step [4800/6235], Loss: 7.2064\n",
      "Epoch [61/100], Step [4900/6235], Loss: 1.5048\n",
      "Epoch [61/100], Step [5000/6235], Loss: 0.0445\n",
      "Epoch [61/100], Step [5100/6235], Loss: 0.6131\n",
      "Epoch [61/100], Step [5200/6235], Loss: 3.8773\n",
      "Epoch [61/100], Step [5300/6235], Loss: 25.8560\n",
      "Epoch [61/100], Step [5400/6235], Loss: 1.1817\n",
      "Epoch [61/100], Step [5500/6235], Loss: 0.0294\n",
      "Epoch [61/100], Step [5600/6235], Loss: 0.3113\n",
      "Epoch [61/100], Step [5700/6235], Loss: 0.1989\n",
      "Epoch [61/100], Step [5800/6235], Loss: 0.1479\n",
      "Epoch [61/100], Step [5900/6235], Loss: 0.2818\n",
      "Epoch [61/100], Step [6000/6235], Loss: 0.4501\n",
      "Epoch [61/100], Step [6100/6235], Loss: 0.1078\n",
      "Epoch [61/100], Step [6200/6235], Loss: 6.3657\n",
      "Epoch [61/100], Step [6300/6235], Loss: 0.1952\n",
      "Epoch [61/100], Step [6400/6235], Loss: 0.0213\n",
      "Epoch [61/100], Step [6500/6235], Loss: 2.4752\n",
      "Epoch [61/100], Step [6600/6235], Loss: 9.1735\n",
      "Epoch [61/100], Step [6700/6235], Loss: 1.5793\n",
      "Epoch [61/100], Step [6800/6235], Loss: 0.4175\n",
      "Epoch [61/100], Step [6900/6235], Loss: 0.7867\n",
      "Epoch [61/100], Step [7000/6235], Loss: 0.1015\n",
      "Epoch [61/100], Step [7100/6235], Loss: 0.5440\n",
      "Epoch [61/100], Step [7200/6235], Loss: 0.1174\n",
      "Epoch [61/100], Step [7300/6235], Loss: 0.3906\n",
      "Epoch [61/100], Step [7400/6235], Loss: 0.2359\n",
      "Epoch [61/100], Step [7500/6235], Loss: 0.2456\n",
      "Epoch [61/100], Step [7600/6235], Loss: 0.1692\n",
      "Epoch [61/100], Step [7700/6235], Loss: 16.6021\n",
      "Epoch [61/100], Step [7800/6235], Loss: 1.6447\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Step [7900/6235], Loss: 0.5609\n",
      "Epoch [61/100], Step [8000/6235], Loss: 0.3291\n",
      "Epoch [61/100], Step [8100/6235], Loss: 3.0238\n",
      "Epoch [61/100], Step [8200/6235], Loss: 10.1510\n",
      "Epoch [61/100], Step [8300/6235], Loss: 19.6963\n",
      "Epoch [61/100], Step [8400/6235], Loss: 565.4257\n",
      "Epoch [61/100], Step [8500/6235], Loss: 8.8735\n",
      "Epoch [61/100], Step [8600/6235], Loss: 39.6945\n",
      "Epoch [61/100], Step [8700/6235], Loss: 20.2144\n",
      "Epoch [61/100], Step [8800/6235], Loss: 512.2097\n",
      "Epoch [61/100], Step [8900/6235], Loss: 251.1470\n",
      "Epoch [61/100], Step [9000/6235], Loss: 408.7224\n",
      "Epoch [61/100], Step [9100/6235], Loss: 2418.3269\n",
      "Epoch [61/100], Step [9200/6235], Loss: 3762.1040\n",
      "Epoch [61/100], Step [9300/6235], Loss: 386.3430\n",
      "Epoch [61/100], Step [9400/6235], Loss: 147.4901\n",
      "Epoch [61/100], Step [9500/6235], Loss: 2953.9941\n",
      "Epoch [61/100], Step [9600/6235], Loss: 836.7036\n",
      "Epoch [61/100], Step [9700/6235], Loss: 2.0118\n",
      "Epoch [61/100], Step [9800/6235], Loss: 3461.5679\n",
      "Epoch [61/100], Step [9900/6235], Loss: 317.0316\n",
      "Epoch [61/100], Step [10000/6235], Loss: 594.7192\n",
      "Epoch [61/100], Step [10100/6235], Loss: 4.5239\n",
      "Epoch [61/100], Step [10200/6235], Loss: 748.5594\n",
      "Epoch [61/100], Step [10300/6235], Loss: 8.2099\n",
      "Epoch [61/100], Step [10400/6235], Loss: 3.9524\n",
      "Epoch [61/100], Step [10500/6235], Loss: 7.1213\n",
      "Epoch [61/100], Step [10600/6235], Loss: 117.9224\n",
      "Epoch [61/100], Step [10700/6235], Loss: 165.5797\n",
      "Epoch [61/100], Step [10800/6235], Loss: 0.6799\n",
      "Epoch [61/100], Step [10900/6235], Loss: 10.3232\n",
      "Epoch [61/100], Step [11000/6235], Loss: 252.7146\n",
      "Epoch [61/100], Step [11100/6235], Loss: 6.1836\n",
      "Epoch [61/100], Step [11200/6235], Loss: 95.9927\n",
      "Epoch [61/100], Step [11300/6235], Loss: 213.9017\n",
      "Epoch [61/100], Step [11400/6235], Loss: 1.2066\n",
      "Epoch [61/100], Step [11500/6235], Loss: 2.4520\n",
      "Epoch [61/100], Step [11600/6235], Loss: 1.1133\n",
      "Epoch [61/100], Step [11700/6235], Loss: 39.3847\n",
      "Epoch [61/100], Step [11800/6235], Loss: 398.2672\n",
      "Epoch [61/100], Step [11900/6235], Loss: 517.5980\n",
      "Epoch [61/100], Step [12000/6235], Loss: 217.0417\n",
      "Epoch [61/100], Step [12100/6235], Loss: 160.0601\n",
      "Epoch [61/100], Step [12200/6235], Loss: 254.3708\n",
      "Epoch [61/100], Step [12300/6235], Loss: 82.7586\n",
      "Epoch [61/100], Step [12400/6235], Loss: 48.5131\n",
      "Epoch [61/100], Step [12500/6235], Loss: 8.7850\n",
      "Epoch [61/100], Step [12600/6235], Loss: 119.6665\n",
      "Epoch [61/100], Step [12700/6235], Loss: 1.3241\n",
      "Epoch [61/100], Step [12800/6235], Loss: 7.7769\n",
      "Epoch [61/100], Step [12900/6235], Loss: 34.1236\n",
      "Epoch [61/100], Step [13000/6235], Loss: 0.1403\n",
      "Epoch [61/100], Step [13100/6235], Loss: 64.5983\n",
      "Epoch [61/100], Step [13200/6235], Loss: 10.4457\n",
      "Epoch [61/100], Step [13300/6235], Loss: 40.9557\n",
      "Epoch [61/100], Step [13400/6235], Loss: 248.5568\n",
      "Epoch [61/100], Step [13500/6235], Loss: 1.4461\n",
      "Epoch [61/100], Step [13600/6235], Loss: 0.4034\n",
      "Epoch [61/100], Step [13700/6235], Loss: 95.1751\n",
      "Epoch [61/100], Step [13800/6235], Loss: 164.7032\n",
      "Epoch [61/100], Step [13900/6235], Loss: 45.9846\n",
      "Epoch [61/100], Step [14000/6235], Loss: 14.3201\n",
      "Epoch [61/100], Step [14100/6235], Loss: 31.8342\n",
      "Epoch [61/100], Step [14200/6235], Loss: 135.4874\n",
      "Epoch [61/100], Step [14300/6235], Loss: 46.2835\n",
      "Epoch [61/100], Step [14400/6235], Loss: 38.6844\n",
      "Epoch [61/100], Step [14500/6235], Loss: 60.2783\n",
      "Epoch [61/100], Step [14600/6235], Loss: 0.2131\n",
      "Epoch [61/100], Step [14700/6235], Loss: 45.6414\n",
      "Epoch [61/100], Step [14800/6235], Loss: 31.3687\n",
      "Epoch [61/100], Step [14900/6235], Loss: 1.2886\n",
      "Epoch [61/100], Step [15000/6235], Loss: 2.4910\n",
      "Epoch [61/100], Step [15100/6235], Loss: 0.3311\n",
      "Epoch [61/100], Step [15200/6235], Loss: 0.5868\n",
      "Epoch [61/100], Step [15300/6235], Loss: 44.7951\n",
      "Epoch [61/100], Step [15400/6235], Loss: 0.3925\n",
      "Epoch [61/100], Step [15500/6235], Loss: 9.9736\n",
      "Epoch [61/100], Step [15600/6235], Loss: 190.0925\n",
      "Epoch [61/100], Step [15700/6235], Loss: 65.1280\n",
      "Epoch [61/100], Step [15800/6235], Loss: 5.2261\n",
      "Epoch [61/100], Step [15900/6235], Loss: 0.6566\n",
      "Epoch [61/100], Step [16000/6235], Loss: 76.4866\n",
      "Epoch [61/100], Step [16100/6235], Loss: 13.6279\n",
      "Epoch [61/100], Step [16200/6235], Loss: 0.4059\n",
      "Epoch [61/100], Step [16300/6235], Loss: 9.4355\n",
      "Epoch [61/100], Step [16400/6235], Loss: 22.4920\n",
      "Epoch [61/100], Step [16500/6235], Loss: 692.8544\n",
      "Epoch [61/100], Step [16600/6235], Loss: 19.6498\n",
      "Epoch [61/100], Step [16700/6235], Loss: 0.4042\n",
      "Epoch [61/100], Step [16800/6235], Loss: 12.3250\n",
      "Epoch [61/100], Step [16900/6235], Loss: 0.1886\n",
      "Epoch [61/100], Step [17000/6235], Loss: 0.2101\n",
      "Epoch [61/100], Step [17100/6235], Loss: 0.1823\n",
      "Epoch [61/100], Step [17200/6235], Loss: 279.6061\n",
      "Epoch [61/100], Step [17300/6235], Loss: 4.7996\n",
      "Epoch [61/100], Step [17400/6235], Loss: 31.5885\n",
      "Epoch [61/100], Step [17500/6235], Loss: 0.9177\n",
      "Epoch [61/100], Step [17600/6235], Loss: 2.8702\n",
      "Epoch [61/100], Step [17700/6235], Loss: 18.1341\n",
      "Epoch [61/100], Step [17800/6235], Loss: 24.5309\n",
      "Epoch [61/100], Step [17900/6235], Loss: 2.4700\n",
      "Epoch [61/100], Step [18000/6235], Loss: 3.8571\n",
      "Epoch [61/100], Step [18100/6235], Loss: 17.2316\n",
      "Epoch [61/100], Step [18200/6235], Loss: 0.5461\n",
      "Epoch [61/100], Step [18300/6235], Loss: 3.3708\n",
      "Epoch [61/100], Step [18400/6235], Loss: 2.2454\n",
      "Epoch [61/100], Step [18500/6235], Loss: 22.0141\n",
      "Epoch [61/100], Step [18600/6235], Loss: 2.8081\n",
      "Epoch [61/100], Step [18700/6235], Loss: 0.6640\n",
      "Epoch [61/100], Step [18800/6235], Loss: 92.2350\n",
      "Epoch [61/100], Step [18900/6235], Loss: 6.7848\n",
      "Epoch [61/100], Step [19000/6235], Loss: 1.9790\n",
      "Epoch [61/100], Step [19100/6235], Loss: 2.9401\n",
      "Epoch [61/100], Step [19200/6235], Loss: 4.7320\n",
      "Epoch [61/100], Step [19300/6235], Loss: 10.7070\n",
      "Epoch [61/100], Step [19400/6235], Loss: 142.2310\n",
      "Epoch [61/100], Step [19500/6235], Loss: 112.1045\n",
      "Epoch [61/100], Step [19600/6235], Loss: 99.9611\n",
      "Epoch [61/100], Step [19700/6235], Loss: 3.3243\n",
      "Epoch [61/100], Step [19800/6235], Loss: 1.7386\n",
      "Epoch [61/100], Step [19900/6235], Loss: 0.3965\n",
      "Epoch [61/100], Step [20000/6235], Loss: 79.9598\n",
      "Epoch [61/100], Step [20100/6235], Loss: 1.0678\n",
      "Epoch [61/100], Step [20200/6235], Loss: 6.8093\n",
      "Epoch [61/100], Step [20300/6235], Loss: 1.8614\n",
      "Epoch [61/100], Step [20400/6235], Loss: 21.8551\n",
      "Epoch [61/100], Step [20500/6235], Loss: 40.4702\n",
      "Epoch [61/100], Step [20600/6235], Loss: 36.7358\n",
      "Epoch [61/100], Step [20700/6235], Loss: 1.0646\n",
      "Epoch [61/100], Step [20800/6235], Loss: 0.8665\n",
      "Epoch [61/100], Step [20900/6235], Loss: 34.5474\n",
      "Epoch [61/100], Step [21000/6235], Loss: 14.9794\n",
      "Epoch [61/100], Step [21100/6235], Loss: 2.5498\n",
      "Epoch [61/100], Step [21200/6235], Loss: 0.2497\n",
      "Epoch [61/100], Step [21300/6235], Loss: 0.2273\n",
      "Epoch [61/100], Step [21400/6235], Loss: 6.0717\n",
      "Epoch [61/100], Step [21500/6235], Loss: 1.3732\n",
      "Epoch [61/100], Step [21600/6235], Loss: 31.8024\n",
      "Epoch [61/100], Step [21700/6235], Loss: 0.1529\n",
      "Epoch [61/100], Step [21800/6235], Loss: 1.0220\n",
      "Epoch [61/100], Step [21900/6235], Loss: 1.2104\n",
      "Epoch [61/100], Step [22000/6235], Loss: 6.6480\n",
      "Epoch [61/100], Step [22100/6235], Loss: 0.9225\n",
      "Epoch [61/100], Step [22200/6235], Loss: 6.8717\n",
      "Epoch [61/100], Step [22300/6235], Loss: 4.5681\n",
      "Epoch [61/100], Step [22400/6235], Loss: 17.1370\n",
      "Epoch [61/100], Step [22500/6235], Loss: 90.9022\n",
      "Epoch [61/100], Step [22600/6235], Loss: 18.3154\n",
      "Epoch [61/100], Step [22700/6235], Loss: 0.2034\n",
      "Epoch [61/100], Step [22800/6235], Loss: 5.3225\n",
      "Epoch [61/100], Step [22900/6235], Loss: 11.3776\n",
      "Epoch [61/100], Step [23000/6235], Loss: 17.7668\n",
      "Epoch [61/100], Step [23100/6235], Loss: 9.4008\n",
      "Epoch [61/100], Step [23200/6235], Loss: 22.7184\n",
      "Epoch [61/100], Step [23300/6235], Loss: 18.0475\n",
      "Epoch [61/100], Step [23400/6235], Loss: 2.3828\n",
      "Epoch [61/100], Step [23500/6235], Loss: 0.0721\n",
      "Epoch [61/100], Step [23600/6235], Loss: 125.0623\n",
      "Epoch [61/100], Step [23700/6235], Loss: 6.9981\n",
      "Epoch [61/100], Step [23800/6235], Loss: 1.4498\n",
      "Epoch [61/100], Step [23900/6235], Loss: 3.4580\n",
      "Epoch [61/100], Step [24000/6235], Loss: 0.6474\n",
      "Epoch [61/100], Step [24100/6235], Loss: 0.4273\n",
      "Epoch [61/100], Step [24200/6235], Loss: 52.0914\n",
      "Epoch [61/100], Step [24300/6235], Loss: 2.6436\n",
      "Epoch [61/100], Step [24400/6235], Loss: 3.4111\n",
      "Epoch [61/100], Step [24500/6235], Loss: 1.3492\n",
      "Epoch [61/100], Step [24600/6235], Loss: 0.0968\n",
      "Epoch [61/100], Step [24700/6235], Loss: 1.9388\n",
      "Epoch [61/100], Step [24800/6235], Loss: 0.1820\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Step [24900/6235], Loss: 15.1922\n",
      "Epoch [61/100], Step [25000/6235], Loss: 15.4446\n",
      "Epoch [61/100], Step [25100/6235], Loss: 6.7367\n",
      "Epoch [61/100], Step [25200/6235], Loss: 1.3652\n",
      "Epoch [61/100], Step [25300/6235], Loss: 0.5668\n",
      "Epoch [61/100], Step [25400/6235], Loss: 10.1549\n",
      "Epoch [61/100], Step [25500/6235], Loss: 7.2927\n",
      "Epoch [61/100], Step [25600/6235], Loss: 3.3697\n",
      "Epoch [61/100], Step [25700/6235], Loss: 0.3116\n",
      "Epoch [61/100], Step [25800/6235], Loss: 0.1219\n",
      "Epoch [61/100], Step [25900/6235], Loss: 7.2257\n",
      "Epoch [61/100], Step [26000/6235], Loss: 2.5899\n",
      "Epoch [61/100], Step [26100/6235], Loss: 0.0997\n",
      "Epoch [61/100], Step [26200/6235], Loss: 0.7317\n",
      "Epoch [61/100], Step [26300/6235], Loss: 4.4288\n",
      "Epoch [61/100], Step [26400/6235], Loss: 0.0780\n",
      "Epoch [61/100], Step [26500/6235], Loss: 0.0255\n",
      "Epoch [61/100], Step [26600/6235], Loss: 1.5843\n",
      "Epoch [61/100], Step [26700/6235], Loss: 0.3880\n",
      "Epoch [61/100], Step [26800/6235], Loss: 0.4695\n",
      "Epoch [61/100], Step [26900/6235], Loss: 0.0019\n",
      "Epoch [61/100], Step [27000/6235], Loss: 15.0535\n",
      "Epoch [61/100], Step [27100/6235], Loss: 0.0433\n",
      "Epoch [61/100], Step [27200/6235], Loss: 0.0234\n",
      "Epoch [61/100], Step [27300/6235], Loss: 0.2132\n",
      "Epoch [61/100], Step [27400/6235], Loss: 0.7813\n",
      "Epoch [61/100], Step [27500/6235], Loss: 22.6149\n",
      "Epoch [61/100], Step [27600/6235], Loss: 0.0743\n",
      "Epoch [61/100], Step [27700/6235], Loss: 1.5546\n",
      "Epoch [61/100], Step [27800/6235], Loss: 0.5297\n",
      "Epoch [61/100], Step [27900/6235], Loss: 0.9994\n",
      "Epoch [61/100], Step [28000/6235], Loss: 186.0148\n",
      "Epoch [61/100], Step [28100/6235], Loss: 1.1616\n",
      "Epoch [61/100], Step [28200/6235], Loss: 34.7766\n",
      "Epoch [61/100], Step [28300/6235], Loss: 3.1366\n",
      "Epoch [61/100], Step [28400/6235], Loss: 23.5534\n",
      "Epoch [61/100], Step [28500/6235], Loss: 3.9116\n",
      "Epoch [61/100], Step [28600/6235], Loss: 0.1895\n",
      "Epoch [61/100], Step [28700/6235], Loss: 4.9979\n",
      "Epoch [61/100], Step [28800/6235], Loss: 0.4993\n",
      "Epoch [61/100], Step [28900/6235], Loss: 70.5150\n",
      "Epoch [61/100], Step [29000/6235], Loss: 8.2709\n",
      "Epoch [61/100], Step [29100/6235], Loss: 0.0913\n",
      "Epoch [61/100], Step [29200/6235], Loss: 0.6555\n",
      "Epoch [61/100], Step [29300/6235], Loss: 0.2427\n",
      "Epoch [61/100], Step [29400/6235], Loss: 0.1052\n",
      "Epoch [61/100], Step [29500/6235], Loss: 4.4629\n",
      "Epoch [61/100], Step [29600/6235], Loss: 0.5286\n",
      "Epoch [61/100], Step [29700/6235], Loss: 0.4535\n",
      "Epoch [61/100], Step [29800/6235], Loss: 1.7282\n",
      "Epoch [61/100], Step [29900/6235], Loss: 0.2656\n",
      "Epoch [61/100], Step [30000/6235], Loss: 4.8694\n",
      "Epoch [61/100], Step [30100/6235], Loss: 3.9239\n",
      "Epoch [61/100], Step [30200/6235], Loss: 0.2511\n",
      "Epoch [61/100], Step [30300/6235], Loss: 0.4371\n",
      "Epoch [61/100], Step [30400/6235], Loss: 0.4002\n",
      "Epoch [61/100], Step [30500/6235], Loss: 2.5413\n",
      "Epoch [61/100], Step [30600/6235], Loss: 0.9141\n",
      "Epoch [61/100], Step [30700/6235], Loss: 0.0189\n",
      "Epoch [61/100], Step [30800/6235], Loss: 0.3095\n",
      "Epoch [61/100], Step [30900/6235], Loss: 3.3798\n",
      "Epoch [61/100], Step [31000/6235], Loss: 0.0147\n",
      "Epoch [61/100], Step [31100/6235], Loss: 0.0882\n",
      "Epoch [61/100], Step [31200/6235], Loss: 5.8685\n",
      "Epoch [61/100], Step [31300/6235], Loss: 0.5564\n",
      "Epoch [61/100], Step [31400/6235], Loss: 1.6124\n",
      "Epoch [61/100], Step [31500/6235], Loss: 0.5833\n",
      "Epoch [61/100], Step [31600/6235], Loss: 1.4069\n",
      "Epoch [61/100], Step [31700/6235], Loss: 0.7684\n",
      "Epoch [61/100], Step [31800/6235], Loss: 1.7741\n",
      "Epoch [61/100], Step [31900/6235], Loss: 644.8779\n",
      "Epoch [61/100], Step [32000/6235], Loss: 0.2212\n",
      "Epoch [61/100], Step [32100/6235], Loss: 4.4049\n",
      "Epoch [61/100], Step [32200/6235], Loss: 60.3647\n",
      "Epoch [61/100], Step [32300/6235], Loss: 0.6354\n",
      "Epoch [61/100], Step [32400/6235], Loss: 0.1409\n",
      "Epoch [61/100], Step [32500/6235], Loss: 20.8845\n",
      "Epoch [61/100], Step [32600/6235], Loss: 1.0080\n",
      "Epoch [61/100], Step [32700/6235], Loss: 304.9540\n",
      "Epoch [61/100], Step [32800/6235], Loss: 6.6495\n",
      "Epoch [61/100], Step [32900/6235], Loss: 13.8510\n",
      "Epoch [61/100], Step [33000/6235], Loss: 0.4355\n",
      "Epoch [61/100], Step [33100/6235], Loss: 1.0934\n",
      "Epoch [61/100], Step [33200/6235], Loss: 1.5059\n",
      "Epoch [61/100], Step [33300/6235], Loss: 3.4665\n",
      "Epoch [61/100], Step [33400/6235], Loss: 124.2274\n",
      "Epoch [61/100], Step [33500/6235], Loss: 2.6058\n",
      "Epoch [61/100], Step [33600/6235], Loss: 0.3912\n",
      "Epoch [61/100], Step [33700/6235], Loss: 0.9048\n",
      "Epoch [61/100], Step [33800/6235], Loss: 1.5698\n",
      "Epoch [61/100], Step [33900/6235], Loss: 24.1912\n",
      "Epoch [61/100], Step [34000/6235], Loss: 0.0326\n",
      "Epoch [61/100], Step [34100/6235], Loss: 0.1760\n",
      "Epoch [61/100], Step [34200/6235], Loss: 2.4987\n",
      "Epoch [61/100], Step [34300/6235], Loss: 7.1275\n",
      "Epoch [61/100], Step [34400/6235], Loss: 0.0578\n",
      "Epoch [61/100], Step [34500/6235], Loss: 48.6478\n",
      "Epoch [61/100], Step [34600/6235], Loss: 0.1711\n",
      "Epoch [61/100], Step [34700/6235], Loss: 0.1977\n",
      "Epoch [61/100], Step [34800/6235], Loss: 16.1693\n",
      "Epoch [61/100], Step [34900/6235], Loss: 68.1463\n",
      "Epoch [61/100], Step [35000/6235], Loss: 1.5428\n",
      "Epoch [61/100], Step [35100/6235], Loss: 0.5211\n",
      "Epoch [61/100], Step [35200/6235], Loss: 0.4076\n",
      "Epoch [61/100], Step [35300/6235], Loss: 1.8193\n",
      "Epoch [61/100], Step [35400/6235], Loss: 0.6324\n",
      "Epoch [61/100], Step [35500/6235], Loss: 2.6913\n",
      "Epoch [61/100], Step [35600/6235], Loss: 3.8874\n",
      "Epoch [61/100], Step [35700/6235], Loss: 6.0744\n",
      "Epoch [61/100], Step [35800/6235], Loss: 0.2931\n",
      "Epoch [61/100], Step [35900/6235], Loss: 3.1797\n",
      "Epoch [61/100], Step [36000/6235], Loss: 0.1588\n",
      "Epoch [61/100], Step [36100/6235], Loss: 0.0361\n",
      "Epoch [61/100], Step [36200/6235], Loss: 18.6105\n",
      "Epoch [61/100], Step [36300/6235], Loss: 0.5280\n",
      "Epoch [61/100], Step [36400/6235], Loss: 1.8334\n",
      "Epoch [61/100], Step [36500/6235], Loss: 9.4115\n",
      "Epoch [61/100], Step [36600/6235], Loss: 0.1258\n",
      "Epoch [61/100], Step [36700/6235], Loss: 0.2016\n",
      "Epoch [61/100], Step [36800/6235], Loss: 17.1559\n",
      "Epoch [61/100], Step [36900/6235], Loss: 6.8767\n",
      "Epoch [61/100], Step [37000/6235], Loss: 0.2110\n",
      "Epoch [61/100], Step [37100/6235], Loss: 0.7382\n",
      "Epoch [61/100], Step [37200/6235], Loss: 0.0759\n",
      "Epoch [61/100], Step [37300/6235], Loss: 0.0888\n",
      "Epoch [61/100], Step [37400/6235], Loss: 0.2059\n",
      "Epoch [61/100], Step [37500/6235], Loss: 3.7419\n",
      "Epoch [61/100], Step [37600/6235], Loss: 11.3176\n",
      "Epoch [61/100], Step [37700/6235], Loss: 1.1096\n",
      "Epoch [61/100], Step [37800/6235], Loss: 6.0162\n",
      "Epoch [61/100], Step [37900/6235], Loss: 7.6061\n",
      "Epoch [61/100], Step [38000/6235], Loss: 0.4842\n",
      "Epoch [61/100], Step [38100/6235], Loss: 3.5095\n",
      "Epoch [61/100], Step [38200/6235], Loss: 2.1727\n",
      "Epoch [61/100], Step [38300/6235], Loss: 0.6059\n",
      "Epoch [61/100], Step [38400/6235], Loss: 0.1426\n",
      "Epoch [61/100], Step [38500/6235], Loss: 2.7542\n",
      "Epoch [61/100], Step [38600/6235], Loss: 0.1406\n",
      "Epoch [61/100], Step [38700/6235], Loss: 0.2698\n",
      "Epoch [61/100], Step [38800/6235], Loss: 0.2773\n",
      "Epoch [61/100], Step [38900/6235], Loss: 4.5048\n",
      "Epoch [61/100], Step [39000/6235], Loss: 2.6365\n",
      "Epoch [61/100], Step [39100/6235], Loss: 17.3941\n",
      "Epoch [61/100], Step [39200/6235], Loss: 0.3605\n",
      "Epoch [61/100], Step [39300/6235], Loss: 20.8766\n",
      "Epoch [61/100], Step [39400/6235], Loss: 66.6098\n",
      "Epoch [61/100], Step [39500/6235], Loss: 160.2924\n",
      "Epoch [61/100], Step [39600/6235], Loss: 9.7564\n",
      "Epoch [61/100], Step [39700/6235], Loss: 536.6488\n",
      "Epoch [61/100], Step [39800/6235], Loss: 239.2152\n",
      "Epoch [61/100], Step [39900/6235], Loss: 6.4789\n",
      "Epoch [61/100], Step [40000/6235], Loss: 9.1313\n",
      "Epoch [61/100], Step [40100/6235], Loss: 19.2243\n",
      "Epoch [61/100], Step [40200/6235], Loss: 2.8225\n",
      "Epoch [61/100], Step [40300/6235], Loss: 1.1986\n",
      "Epoch [61/100], Step [40400/6235], Loss: 1.5939\n",
      "Epoch [61/100], Step [40500/6235], Loss: 2.6231\n",
      "Epoch [61/100], Step [40600/6235], Loss: 0.1803\n",
      "Epoch [61/100], Step [40700/6235], Loss: 7.2238\n",
      "Epoch [61/100], Step [40800/6235], Loss: 0.5854\n",
      "Epoch [61/100], Step [40900/6235], Loss: 0.5683\n",
      "Epoch [61/100], Step [41000/6235], Loss: 47.2159\n",
      "Epoch [61/100], Step [41100/6235], Loss: 37.9120\n",
      "Epoch [61/100], Step [41200/6235], Loss: 15.5712\n",
      "Epoch [61/100], Step [41300/6235], Loss: 5.4478\n",
      "Epoch [61/100], Step [41400/6235], Loss: 1.8899\n",
      "Epoch [61/100], Step [41500/6235], Loss: 1.1738\n",
      "Epoch [61/100], Step [41600/6235], Loss: 0.0099\n",
      "Epoch [61/100], Step [41700/6235], Loss: 4.4062\n",
      "Epoch [61/100], Step [41800/6235], Loss: 0.7745\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [61/100], Step [41900/6235], Loss: 2.7758\n",
      "Epoch [61/100], Step [42000/6235], Loss: 2.3181\n",
      "Epoch [61/100], Step [42100/6235], Loss: 5.9085\n",
      "Epoch [61/100], Step [42200/6235], Loss: 1.4720\n",
      "Epoch [61/100], Step [42300/6235], Loss: 6.1178\n",
      "Epoch [61/100], Step [42400/6235], Loss: 0.2166\n",
      "Epoch [61/100], Step [42500/6235], Loss: 3.5630\n",
      "Epoch [61/100], Step [42600/6235], Loss: 0.6346\n",
      "Epoch [61/100], Step [42700/6235], Loss: 0.3020\n",
      "Epoch [61/100], Step [42800/6235], Loss: 0.2205\n",
      "Epoch [61/100], Step [42900/6235], Loss: 3.9999\n",
      "Epoch [61/100], Step [43000/6235], Loss: 0.2177\n",
      "Epoch [61/100], Step [43100/6235], Loss: 0.8057\n",
      "Epoch [61/100], Step [43200/6235], Loss: 0.8438\n",
      "Epoch [61/100], Step [43300/6235], Loss: 9.1384\n",
      "Epoch [61/100], Step [43400/6235], Loss: 10.0834\n",
      "Epoch [61/100], Step [43500/6235], Loss: 9.4501\n",
      "Epoch [61/100], Step [43600/6235], Loss: 16.1967\n",
      "Epoch [61/100], Step [43700/6235], Loss: 17.4154\n",
      "Epoch [61/100], Step [43800/6235], Loss: 10.0987\n",
      "Epoch [61/100], Step [43900/6235], Loss: 5.2524\n",
      "Epoch [61/100], Step [44000/6235], Loss: 39.1016\n",
      "Epoch [61/100], Step [44100/6235], Loss: 0.7522\n",
      "Epoch [61/100], Step [44200/6235], Loss: 1.5724\n",
      "Epoch [61/100], Step [44300/6235], Loss: 26.3527\n",
      "Epoch [61/100], Step [44400/6235], Loss: 2.9379\n",
      "Epoch [61/100], Step [44500/6235], Loss: 0.4683\n",
      "Epoch [61/100], Step [44600/6235], Loss: 6.5101\n",
      "Epoch [61/100], Step [44700/6235], Loss: 11.5553\n",
      "Epoch [61/100], Step [44800/6235], Loss: 3.0106\n",
      "Epoch [61/100], Step [44900/6235], Loss: 10.4877\n",
      "Epoch [61/100], Step [45000/6235], Loss: 5.8465\n",
      "Epoch [61/100], Step [45100/6235], Loss: 28.9433\n",
      "Epoch [61/100], Step [45200/6235], Loss: 0.4884\n",
      "Epoch [61/100], Step [45300/6235], Loss: 26.6709\n",
      "Epoch [61/100], Step [45400/6235], Loss: 12.7294\n",
      "Epoch [61/100], Step [45500/6235], Loss: 0.5636\n",
      "Epoch [61/100], Step [45600/6235], Loss: 0.3484\n",
      "Epoch [61/100], Step [45700/6235], Loss: 72.6746\n",
      "Epoch [61/100], Step [45800/6235], Loss: 561.6033\n",
      "Epoch [61/100], Step [45900/6235], Loss: 23.9014\n",
      "Epoch [61/100], Step [46000/6235], Loss: 111.6888\n",
      "Epoch [61/100], Step [46100/6235], Loss: 166.1679\n",
      "Epoch [61/100], Step [46200/6235], Loss: 64.6509\n",
      "Epoch [61/100], Step [46300/6235], Loss: 12.0593\n",
      "Epoch [61/100], Step [46400/6235], Loss: 12.6852\n",
      "Epoch [61/100], Step [46500/6235], Loss: 16.4579\n",
      "Epoch [61/100], Step [46600/6235], Loss: 13.0438\n",
      "Epoch [61/100], Step [46700/6235], Loss: 11.2842\n",
      "Epoch [61/100], Step [46800/6235], Loss: 34.1157\n",
      "Epoch [61/100], Step [46900/6235], Loss: 4.9976\n",
      "Epoch [61/100], Step [47000/6235], Loss: 7.3267\n",
      "Epoch [61/100], Step [47100/6235], Loss: 7.2903\n",
      "Epoch [61/100], Step [47200/6235], Loss: 110.8094\n",
      "Epoch [61/100], Step [47300/6235], Loss: 2.7134\n",
      "Epoch [61/100], Step [47400/6235], Loss: 544.4553\n",
      "Epoch [61/100], Step [47500/6235], Loss: 2.2771\n",
      "Epoch [61/100], Step [47600/6235], Loss: 15.9401\n",
      "Epoch [61/100], Step [47700/6235], Loss: 34.9409\n",
      "Epoch [61/100], Step [47800/6235], Loss: 31.7094\n",
      "Epoch [61/100], Step [47900/6235], Loss: 5.4517\n",
      "Epoch [61/100], Step [48000/6235], Loss: 44.2416\n",
      "Epoch [61/100], Step [48100/6235], Loss: 52.2110\n",
      "Epoch [61/100], Step [48200/6235], Loss: 232.7685\n",
      "Epoch [61/100], Step [48300/6235], Loss: 731.6088\n",
      "Epoch [61/100], Step [48400/6235], Loss: 2.2054\n",
      "Epoch [61/100], Step [48500/6235], Loss: 21.0605\n",
      "Epoch [61/100], Step [48600/6235], Loss: 12.2997\n",
      "Epoch [61/100], Step [48700/6235], Loss: 36.8925\n",
      "Epoch [61/100], Step [48800/6235], Loss: 891.8065\n",
      "Epoch [61/100], Step [48900/6235], Loss: 262.3540\n",
      "Epoch [61/100], Step [49000/6235], Loss: 147.1397\n",
      "Epoch [61/100], Step [49100/6235], Loss: 1994.8199\n",
      "Epoch [61/100], Step [49200/6235], Loss: 127.7453\n",
      "Epoch [61/100], Step [49300/6235], Loss: 855.5674\n",
      "Epoch [61/100], Step [49400/6235], Loss: 1.0640\n",
      "Epoch [61/100], Step [49500/6235], Loss: 47.9911\n",
      "Epoch [61/100], Step [49600/6235], Loss: 86.8833\n",
      "Epoch [61/100], Step [49700/6235], Loss: 45.9709\n",
      "Epoch [61/100], Step [49800/6235], Loss: 436.2556\n",
      "Epoch [62/100], Step [100/6235], Loss: 16.2556\n",
      "Epoch [62/100], Step [200/6235], Loss: 0.1813\n",
      "Epoch [62/100], Step [300/6235], Loss: 0.0276\n",
      "Epoch [62/100], Step [400/6235], Loss: 0.0033\n",
      "Epoch [62/100], Step [500/6235], Loss: 0.7813\n",
      "Epoch [62/100], Step [600/6235], Loss: 0.0517\n",
      "Epoch [62/100], Step [700/6235], Loss: 0.5589\n",
      "Epoch [62/100], Step [800/6235], Loss: 0.1822\n",
      "Epoch [62/100], Step [900/6235], Loss: 0.0300\n",
      "Epoch [62/100], Step [1000/6235], Loss: 0.0329\n",
      "Epoch [62/100], Step [1100/6235], Loss: 0.0284\n",
      "Epoch [62/100], Step [1200/6235], Loss: 0.1961\n",
      "Epoch [62/100], Step [1300/6235], Loss: 0.0443\n",
      "Epoch [62/100], Step [1400/6235], Loss: 0.0933\n",
      "Epoch [62/100], Step [1500/6235], Loss: 0.0080\n",
      "Epoch [62/100], Step [1600/6235], Loss: 0.2239\n",
      "Epoch [62/100], Step [1700/6235], Loss: 0.0328\n",
      "Epoch [62/100], Step [1800/6235], Loss: 0.2340\n",
      "Epoch [62/100], Step [1900/6235], Loss: 0.5555\n",
      "Epoch [62/100], Step [2000/6235], Loss: 2.2347\n",
      "Epoch [62/100], Step [2100/6235], Loss: 2.1362\n",
      "Epoch [62/100], Step [2200/6235], Loss: 8.8685\n",
      "Epoch [62/100], Step [2300/6235], Loss: 12.6404\n",
      "Epoch [62/100], Step [2400/6235], Loss: 6.3170\n",
      "Epoch [62/100], Step [2500/6235], Loss: 36.0382\n",
      "Epoch [62/100], Step [2600/6235], Loss: 10.3955\n",
      "Epoch [62/100], Step [2700/6235], Loss: 17.8545\n",
      "Epoch [62/100], Step [2800/6235], Loss: 108.3157\n",
      "Epoch [62/100], Step [2900/6235], Loss: 14.2551\n",
      "Epoch [62/100], Step [3000/6235], Loss: 1.0955\n",
      "Epoch [62/100], Step [3100/6235], Loss: 70.8163\n",
      "Epoch [62/100], Step [3200/6235], Loss: 75.3739\n",
      "Epoch [62/100], Step [3300/6235], Loss: 7.9306\n",
      "Epoch [62/100], Step [3400/6235], Loss: 1.7021\n",
      "Epoch [62/100], Step [3500/6235], Loss: 36.7661\n",
      "Epoch [62/100], Step [3600/6235], Loss: 7.7395\n",
      "Epoch [62/100], Step [3700/6235], Loss: 0.0174\n",
      "Epoch [62/100], Step [3800/6235], Loss: 0.1498\n",
      "Epoch [62/100], Step [3900/6235], Loss: 0.3878\n",
      "Epoch [62/100], Step [4000/6235], Loss: 0.0383\n",
      "Epoch [62/100], Step [4100/6235], Loss: 7.2902\n",
      "Epoch [62/100], Step [4200/6235], Loss: 0.8356\n",
      "Epoch [62/100], Step [4300/6235], Loss: 6.5572\n",
      "Epoch [62/100], Step [4400/6235], Loss: 2.5410\n",
      "Epoch [62/100], Step [4500/6235], Loss: 39.7828\n",
      "Epoch [62/100], Step [4600/6235], Loss: 3.4837\n",
      "Epoch [62/100], Step [4700/6235], Loss: 0.1918\n",
      "Epoch [62/100], Step [4800/6235], Loss: 10.4339\n",
      "Epoch [62/100], Step [4900/6235], Loss: 0.2525\n",
      "Epoch [62/100], Step [5000/6235], Loss: 0.0507\n",
      "Epoch [62/100], Step [5100/6235], Loss: 0.9886\n",
      "Epoch [62/100], Step [5200/6235], Loss: 0.3695\n",
      "Epoch [62/100], Step [5300/6235], Loss: 42.5570\n",
      "Epoch [62/100], Step [5400/6235], Loss: 1.3969\n",
      "Epoch [62/100], Step [5500/6235], Loss: 0.0994\n",
      "Epoch [62/100], Step [5600/6235], Loss: 0.3000\n",
      "Epoch [62/100], Step [5700/6235], Loss: 0.0851\n",
      "Epoch [62/100], Step [5800/6235], Loss: 0.2100\n",
      "Epoch [62/100], Step [5900/6235], Loss: 0.0272\n",
      "Epoch [62/100], Step [6000/6235], Loss: 2.9350\n",
      "Epoch [62/100], Step [6100/6235], Loss: 0.0120\n",
      "Epoch [62/100], Step [6200/6235], Loss: 2.8074\n",
      "Epoch [62/100], Step [6300/6235], Loss: 0.5839\n",
      "Epoch [62/100], Step [6400/6235], Loss: 0.0113\n",
      "Epoch [62/100], Step [6500/6235], Loss: 2.7626\n",
      "Epoch [62/100], Step [6600/6235], Loss: 6.2390\n",
      "Epoch [62/100], Step [6700/6235], Loss: 3.0231\n",
      "Epoch [62/100], Step [6800/6235], Loss: 0.3472\n",
      "Epoch [62/100], Step [6900/6235], Loss: 0.1724\n",
      "Epoch [62/100], Step [7000/6235], Loss: 0.0048\n",
      "Epoch [62/100], Step [7100/6235], Loss: 0.2223\n",
      "Epoch [62/100], Step [7200/6235], Loss: 0.1296\n",
      "Epoch [62/100], Step [7300/6235], Loss: 0.7287\n",
      "Epoch [62/100], Step [7400/6235], Loss: 0.0617\n",
      "Epoch [62/100], Step [7500/6235], Loss: 0.8656\n",
      "Epoch [62/100], Step [7600/6235], Loss: 4.2801\n",
      "Epoch [62/100], Step [7700/6235], Loss: 12.8488\n",
      "Epoch [62/100], Step [7800/6235], Loss: 1.5299\n",
      "Epoch [62/100], Step [7900/6235], Loss: 0.5034\n",
      "Epoch [62/100], Step [8000/6235], Loss: 0.0509\n",
      "Epoch [62/100], Step [8100/6235], Loss: 4.0145\n",
      "Epoch [62/100], Step [8200/6235], Loss: 11.0315\n",
      "Epoch [62/100], Step [8300/6235], Loss: 21.0662\n",
      "Epoch [62/100], Step [8400/6235], Loss: 363.4204\n",
      "Epoch [62/100], Step [8500/6235], Loss: 2.9465\n",
      "Epoch [62/100], Step [8600/6235], Loss: 4.7722\n",
      "Epoch [62/100], Step [8700/6235], Loss: 20.0292\n",
      "Epoch [62/100], Step [8800/6235], Loss: 139.5160\n",
      "Epoch [62/100], Step [8900/6235], Loss: 283.5854\n",
      "Epoch [62/100], Step [9000/6235], Loss: 439.2446\n",
      "Epoch [62/100], Step [9100/6235], Loss: 2113.6021\n",
      "Epoch [62/100], Step [9200/6235], Loss: 3254.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Step [9300/6235], Loss: 197.1844\n",
      "Epoch [62/100], Step [9400/6235], Loss: 54.8294\n",
      "Epoch [62/100], Step [9500/6235], Loss: 2341.9055\n",
      "Epoch [62/100], Step [9600/6235], Loss: 1136.2330\n",
      "Epoch [62/100], Step [9700/6235], Loss: 1.2168\n",
      "Epoch [62/100], Step [9800/6235], Loss: 4389.5547\n",
      "Epoch [62/100], Step [9900/6235], Loss: 3.4459\n",
      "Epoch [62/100], Step [10000/6235], Loss: 163.5013\n",
      "Epoch [62/100], Step [10100/6235], Loss: 0.9193\n",
      "Epoch [62/100], Step [10200/6235], Loss: 738.8224\n",
      "Epoch [62/100], Step [10300/6235], Loss: 26.1770\n",
      "Epoch [62/100], Step [10400/6235], Loss: 8.8651\n",
      "Epoch [62/100], Step [10500/6235], Loss: 15.3404\n",
      "Epoch [62/100], Step [10600/6235], Loss: 550.6322\n",
      "Epoch [62/100], Step [10700/6235], Loss: 24.2654\n",
      "Epoch [62/100], Step [10800/6235], Loss: 72.9343\n",
      "Epoch [62/100], Step [10900/6235], Loss: 109.3471\n",
      "Epoch [62/100], Step [11000/6235], Loss: 298.6499\n",
      "Epoch [62/100], Step [11100/6235], Loss: 22.8090\n",
      "Epoch [62/100], Step [11200/6235], Loss: 3.3105\n",
      "Epoch [62/100], Step [11300/6235], Loss: 100.3024\n",
      "Epoch [62/100], Step [11400/6235], Loss: 7.7604\n",
      "Epoch [62/100], Step [11500/6235], Loss: 9.7585\n",
      "Epoch [62/100], Step [11600/6235], Loss: 7.3860\n",
      "Epoch [62/100], Step [11700/6235], Loss: 44.0328\n",
      "Epoch [62/100], Step [11800/6235], Loss: 374.5280\n",
      "Epoch [62/100], Step [11900/6235], Loss: 61.9220\n",
      "Epoch [62/100], Step [12000/6235], Loss: 643.4793\n",
      "Epoch [62/100], Step [12100/6235], Loss: 225.7357\n",
      "Epoch [62/100], Step [12200/6235], Loss: 3.8160\n",
      "Epoch [62/100], Step [12300/6235], Loss: 0.8124\n",
      "Epoch [62/100], Step [12400/6235], Loss: 311.5383\n",
      "Epoch [62/100], Step [12500/6235], Loss: 45.1959\n",
      "Epoch [62/100], Step [12600/6235], Loss: 17.8462\n",
      "Epoch [62/100], Step [12700/6235], Loss: 5.1322\n",
      "Epoch [62/100], Step [12800/6235], Loss: 7.8023\n",
      "Epoch [62/100], Step [12900/6235], Loss: 36.3241\n",
      "Epoch [62/100], Step [13000/6235], Loss: 0.2488\n",
      "Epoch [62/100], Step [13100/6235], Loss: 64.1572\n",
      "Epoch [62/100], Step [13200/6235], Loss: 8.2082\n",
      "Epoch [62/100], Step [13300/6235], Loss: 29.8509\n",
      "Epoch [62/100], Step [13400/6235], Loss: 232.6423\n",
      "Epoch [62/100], Step [13500/6235], Loss: 2.4513\n",
      "Epoch [62/100], Step [13600/6235], Loss: 6.4304\n",
      "Epoch [62/100], Step [13700/6235], Loss: 15.7646\n",
      "Epoch [62/100], Step [13800/6235], Loss: 145.5082\n",
      "Epoch [62/100], Step [13900/6235], Loss: 65.1865\n",
      "Epoch [62/100], Step [14000/6235], Loss: 5.9552\n",
      "Epoch [62/100], Step [14100/6235], Loss: 27.4881\n",
      "Epoch [62/100], Step [14200/6235], Loss: 69.0882\n",
      "Epoch [62/100], Step [14300/6235], Loss: 21.5060\n",
      "Epoch [62/100], Step [14400/6235], Loss: 37.6736\n",
      "Epoch [62/100], Step [14500/6235], Loss: 33.8649\n",
      "Epoch [62/100], Step [14600/6235], Loss: 0.6694\n",
      "Epoch [62/100], Step [14700/6235], Loss: 38.7759\n",
      "Epoch [62/100], Step [14800/6235], Loss: 33.8356\n",
      "Epoch [62/100], Step [14900/6235], Loss: 0.6653\n",
      "Epoch [62/100], Step [15000/6235], Loss: 1.5675\n",
      "Epoch [62/100], Step [15100/6235], Loss: 0.5708\n",
      "Epoch [62/100], Step [15200/6235], Loss: 11.5531\n",
      "Epoch [62/100], Step [15300/6235], Loss: 38.9803\n",
      "Epoch [62/100], Step [15400/6235], Loss: 73.6415\n",
      "Epoch [62/100], Step [15500/6235], Loss: 15.4780\n",
      "Epoch [62/100], Step [15600/6235], Loss: 175.1105\n",
      "Epoch [62/100], Step [15700/6235], Loss: 16.9333\n",
      "Epoch [62/100], Step [15800/6235], Loss: 2.3337\n",
      "Epoch [62/100], Step [15900/6235], Loss: 2.1781\n",
      "Epoch [62/100], Step [16000/6235], Loss: 166.3132\n",
      "Epoch [62/100], Step [16100/6235], Loss: 1.1672\n",
      "Epoch [62/100], Step [16200/6235], Loss: 0.3352\n",
      "Epoch [62/100], Step [16300/6235], Loss: 8.4525\n",
      "Epoch [62/100], Step [16400/6235], Loss: 18.2208\n",
      "Epoch [62/100], Step [16500/6235], Loss: 647.3021\n",
      "Epoch [62/100], Step [16600/6235], Loss: 30.9083\n",
      "Epoch [62/100], Step [16700/6235], Loss: 0.5797\n",
      "Epoch [62/100], Step [16800/6235], Loss: 9.6248\n",
      "Epoch [62/100], Step [16900/6235], Loss: 0.2203\n",
      "Epoch [62/100], Step [17000/6235], Loss: 0.2004\n",
      "Epoch [62/100], Step [17100/6235], Loss: 0.1261\n",
      "Epoch [62/100], Step [17200/6235], Loss: 267.3790\n",
      "Epoch [62/100], Step [17300/6235], Loss: 1.5600\n",
      "Epoch [62/100], Step [17400/6235], Loss: 31.8444\n",
      "Epoch [62/100], Step [17500/6235], Loss: 1.2141\n",
      "Epoch [62/100], Step [17600/6235], Loss: 2.5944\n",
      "Epoch [62/100], Step [17700/6235], Loss: 16.9263\n",
      "Epoch [62/100], Step [17800/6235], Loss: 50.6660\n",
      "Epoch [62/100], Step [17900/6235], Loss: 2.7777\n",
      "Epoch [62/100], Step [18000/6235], Loss: 6.1126\n",
      "Epoch [62/100], Step [18100/6235], Loss: 16.8177\n",
      "Epoch [62/100], Step [18200/6235], Loss: 0.7406\n",
      "Epoch [62/100], Step [18300/6235], Loss: 6.4291\n",
      "Epoch [62/100], Step [18400/6235], Loss: 4.7388\n",
      "Epoch [62/100], Step [18500/6235], Loss: 9.4151\n",
      "Epoch [62/100], Step [18600/6235], Loss: 1.2369\n",
      "Epoch [62/100], Step [18700/6235], Loss: 0.4154\n",
      "Epoch [62/100], Step [18800/6235], Loss: 136.2882\n",
      "Epoch [62/100], Step [18900/6235], Loss: 1.0599\n",
      "Epoch [62/100], Step [19000/6235], Loss: 5.3369\n",
      "Epoch [62/100], Step [19100/6235], Loss: 7.7464\n",
      "Epoch [62/100], Step [19200/6235], Loss: 3.5981\n",
      "Epoch [62/100], Step [19300/6235], Loss: 3.5731\n",
      "Epoch [62/100], Step [19400/6235], Loss: 65.6801\n",
      "Epoch [62/100], Step [19500/6235], Loss: 143.1153\n",
      "Epoch [62/100], Step [19600/6235], Loss: 151.6199\n",
      "Epoch [62/100], Step [19700/6235], Loss: 4.9475\n",
      "Epoch [62/100], Step [19800/6235], Loss: 1.6049\n",
      "Epoch [62/100], Step [19900/6235], Loss: 0.4085\n",
      "Epoch [62/100], Step [20000/6235], Loss: 66.9832\n",
      "Epoch [62/100], Step [20100/6235], Loss: 0.0491\n",
      "Epoch [62/100], Step [20200/6235], Loss: 5.2146\n",
      "Epoch [62/100], Step [20300/6235], Loss: 2.3844\n",
      "Epoch [62/100], Step [20400/6235], Loss: 19.7133\n",
      "Epoch [62/100], Step [20500/6235], Loss: 40.4745\n",
      "Epoch [62/100], Step [20600/6235], Loss: 9.7520\n",
      "Epoch [62/100], Step [20700/6235], Loss: 5.6440\n",
      "Epoch [62/100], Step [20800/6235], Loss: 1.4054\n",
      "Epoch [62/100], Step [20900/6235], Loss: 24.8717\n",
      "Epoch [62/100], Step [21000/6235], Loss: 19.6983\n",
      "Epoch [62/100], Step [21100/6235], Loss: 0.4886\n",
      "Epoch [62/100], Step [21200/6235], Loss: 0.1396\n",
      "Epoch [62/100], Step [21300/6235], Loss: 0.1236\n",
      "Epoch [62/100], Step [21400/6235], Loss: 5.3208\n",
      "Epoch [62/100], Step [21500/6235], Loss: 4.5944\n",
      "Epoch [62/100], Step [21600/6235], Loss: 32.9146\n",
      "Epoch [62/100], Step [21700/6235], Loss: 1.5998\n",
      "Epoch [62/100], Step [21800/6235], Loss: 5.7847\n",
      "Epoch [62/100], Step [21900/6235], Loss: 0.2070\n",
      "Epoch [62/100], Step [22000/6235], Loss: 3.2255\n",
      "Epoch [62/100], Step [22100/6235], Loss: 3.6968\n",
      "Epoch [62/100], Step [22200/6235], Loss: 7.4498\n",
      "Epoch [62/100], Step [22300/6235], Loss: 12.8450\n",
      "Epoch [62/100], Step [22400/6235], Loss: 9.1747\n",
      "Epoch [62/100], Step [22500/6235], Loss: 72.2770\n",
      "Epoch [62/100], Step [22600/6235], Loss: 19.6096\n",
      "Epoch [62/100], Step [22700/6235], Loss: 2.0256\n",
      "Epoch [62/100], Step [22800/6235], Loss: 2.9656\n",
      "Epoch [62/100], Step [22900/6235], Loss: 1.8553\n",
      "Epoch [62/100], Step [23000/6235], Loss: 0.3011\n",
      "Epoch [62/100], Step [23100/6235], Loss: 7.4244\n",
      "Epoch [62/100], Step [23200/6235], Loss: 10.8960\n",
      "Epoch [62/100], Step [23300/6235], Loss: 9.8593\n",
      "Epoch [62/100], Step [23400/6235], Loss: 0.7997\n",
      "Epoch [62/100], Step [23500/6235], Loss: 0.2441\n",
      "Epoch [62/100], Step [23600/6235], Loss: 102.9425\n",
      "Epoch [62/100], Step [23700/6235], Loss: 5.5769\n",
      "Epoch [62/100], Step [23800/6235], Loss: 0.9827\n",
      "Epoch [62/100], Step [23900/6235], Loss: 7.9064\n",
      "Epoch [62/100], Step [24000/6235], Loss: 0.3295\n",
      "Epoch [62/100], Step [24100/6235], Loss: 0.8796\n",
      "Epoch [62/100], Step [24200/6235], Loss: 45.2380\n",
      "Epoch [62/100], Step [24300/6235], Loss: 1.7719\n",
      "Epoch [62/100], Step [24400/6235], Loss: 5.5317\n",
      "Epoch [62/100], Step [24500/6235], Loss: 3.0804\n",
      "Epoch [62/100], Step [24600/6235], Loss: 0.1812\n",
      "Epoch [62/100], Step [24700/6235], Loss: 0.4329\n",
      "Epoch [62/100], Step [24800/6235], Loss: 0.0740\n",
      "Epoch [62/100], Step [24900/6235], Loss: 0.9378\n",
      "Epoch [62/100], Step [25000/6235], Loss: 17.8202\n",
      "Epoch [62/100], Step [25100/6235], Loss: 8.3916\n",
      "Epoch [62/100], Step [25200/6235], Loss: 1.9500\n",
      "Epoch [62/100], Step [25300/6235], Loss: 0.8268\n",
      "Epoch [62/100], Step [25400/6235], Loss: 9.8609\n",
      "Epoch [62/100], Step [25500/6235], Loss: 5.3057\n",
      "Epoch [62/100], Step [25600/6235], Loss: 1.9790\n",
      "Epoch [62/100], Step [25700/6235], Loss: 0.3163\n",
      "Epoch [62/100], Step [25800/6235], Loss: 0.1569\n",
      "Epoch [62/100], Step [25900/6235], Loss: 10.2406\n",
      "Epoch [62/100], Step [26000/6235], Loss: 3.8573\n",
      "Epoch [62/100], Step [26100/6235], Loss: 0.3417\n",
      "Epoch [62/100], Step [26200/6235], Loss: 0.0206\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Step [26300/6235], Loss: 4.7941\n",
      "Epoch [62/100], Step [26400/6235], Loss: 0.1898\n",
      "Epoch [62/100], Step [26500/6235], Loss: 0.2794\n",
      "Epoch [62/100], Step [26600/6235], Loss: 3.6331\n",
      "Epoch [62/100], Step [26700/6235], Loss: 0.7301\n",
      "Epoch [62/100], Step [26800/6235], Loss: 0.9327\n",
      "Epoch [62/100], Step [26900/6235], Loss: 0.0698\n",
      "Epoch [62/100], Step [27000/6235], Loss: 11.9664\n",
      "Epoch [62/100], Step [27100/6235], Loss: 0.2010\n",
      "Epoch [62/100], Step [27200/6235], Loss: 0.0819\n",
      "Epoch [62/100], Step [27300/6235], Loss: 0.1696\n",
      "Epoch [62/100], Step [27400/6235], Loss: 0.9694\n",
      "Epoch [62/100], Step [27500/6235], Loss: 23.3446\n",
      "Epoch [62/100], Step [27600/6235], Loss: 0.2062\n",
      "Epoch [62/100], Step [27700/6235], Loss: 0.4564\n",
      "Epoch [62/100], Step [27800/6235], Loss: 5.1806\n",
      "Epoch [62/100], Step [27900/6235], Loss: 1.6242\n",
      "Epoch [62/100], Step [28000/6235], Loss: 166.8650\n",
      "Epoch [62/100], Step [28100/6235], Loss: 3.4820\n",
      "Epoch [62/100], Step [28200/6235], Loss: 33.3004\n",
      "Epoch [62/100], Step [28300/6235], Loss: 3.2901\n",
      "Epoch [62/100], Step [28400/6235], Loss: 22.9617\n",
      "Epoch [62/100], Step [28500/6235], Loss: 3.3019\n",
      "Epoch [62/100], Step [28600/6235], Loss: 0.7512\n",
      "Epoch [62/100], Step [28700/6235], Loss: 4.3733\n",
      "Epoch [62/100], Step [28800/6235], Loss: 0.3318\n",
      "Epoch [62/100], Step [28900/6235], Loss: 71.1499\n",
      "Epoch [62/100], Step [29000/6235], Loss: 6.2824\n",
      "Epoch [62/100], Step [29100/6235], Loss: 0.0776\n",
      "Epoch [62/100], Step [29200/6235], Loss: 0.0477\n",
      "Epoch [62/100], Step [29300/6235], Loss: 2.8704\n",
      "Epoch [62/100], Step [29400/6235], Loss: 0.1773\n",
      "Epoch [62/100], Step [29500/6235], Loss: 0.3311\n",
      "Epoch [62/100], Step [29600/6235], Loss: 1.1068\n",
      "Epoch [62/100], Step [29700/6235], Loss: 0.0892\n",
      "Epoch [62/100], Step [29800/6235], Loss: 1.5187\n",
      "Epoch [62/100], Step [29900/6235], Loss: 0.1671\n",
      "Epoch [62/100], Step [30000/6235], Loss: 5.3064\n",
      "Epoch [62/100], Step [30100/6235], Loss: 0.0848\n",
      "Epoch [62/100], Step [30200/6235], Loss: 0.1704\n",
      "Epoch [62/100], Step [30300/6235], Loss: 1.0856\n",
      "Epoch [62/100], Step [30400/6235], Loss: 0.0609\n",
      "Epoch [62/100], Step [30500/6235], Loss: 1.0036\n",
      "Epoch [62/100], Step [30600/6235], Loss: 0.1006\n",
      "Epoch [62/100], Step [30700/6235], Loss: 0.4491\n",
      "Epoch [62/100], Step [30800/6235], Loss: 0.1599\n",
      "Epoch [62/100], Step [30900/6235], Loss: 1.7462\n",
      "Epoch [62/100], Step [31000/6235], Loss: 0.1192\n",
      "Epoch [62/100], Step [31100/6235], Loss: 0.0754\n",
      "Epoch [62/100], Step [31200/6235], Loss: 6.4787\n",
      "Epoch [62/100], Step [31300/6235], Loss: 1.4307\n",
      "Epoch [62/100], Step [31400/6235], Loss: 0.5134\n",
      "Epoch [62/100], Step [31500/6235], Loss: 1.2329\n",
      "Epoch [62/100], Step [31600/6235], Loss: 4.9142\n",
      "Epoch [62/100], Step [31700/6235], Loss: 6.2079\n",
      "Epoch [62/100], Step [31800/6235], Loss: 1.6559\n",
      "Epoch [62/100], Step [31900/6235], Loss: 909.2230\n",
      "Epoch [62/100], Step [32000/6235], Loss: 20.8369\n",
      "Epoch [62/100], Step [32100/6235], Loss: 4.3931\n",
      "Epoch [62/100], Step [32200/6235], Loss: 33.1821\n",
      "Epoch [62/100], Step [32300/6235], Loss: 0.2683\n",
      "Epoch [62/100], Step [32400/6235], Loss: 0.0914\n",
      "Epoch [62/100], Step [32500/6235], Loss: 20.7703\n",
      "Epoch [62/100], Step [32600/6235], Loss: 1.1959\n",
      "Epoch [62/100], Step [32700/6235], Loss: 79.6292\n",
      "Epoch [62/100], Step [32800/6235], Loss: 8.8377\n",
      "Epoch [62/100], Step [32900/6235], Loss: 14.0470\n",
      "Epoch [62/100], Step [33000/6235], Loss: 0.1265\n",
      "Epoch [62/100], Step [33100/6235], Loss: 1.0974\n",
      "Epoch [62/100], Step [33200/6235], Loss: 1.7477\n",
      "Epoch [62/100], Step [33300/6235], Loss: 0.1143\n",
      "Epoch [62/100], Step [33400/6235], Loss: 34.5703\n",
      "Epoch [62/100], Step [33500/6235], Loss: 1.8691\n",
      "Epoch [62/100], Step [33600/6235], Loss: 4.5917\n",
      "Epoch [62/100], Step [33700/6235], Loss: 6.4543\n",
      "Epoch [62/100], Step [33800/6235], Loss: 1.3792\n",
      "Epoch [62/100], Step [33900/6235], Loss: 23.6828\n",
      "Epoch [62/100], Step [34000/6235], Loss: 0.0767\n",
      "Epoch [62/100], Step [34100/6235], Loss: 0.0862\n",
      "Epoch [62/100], Step [34200/6235], Loss: 2.9269\n",
      "Epoch [62/100], Step [34300/6235], Loss: 7.5061\n",
      "Epoch [62/100], Step [34400/6235], Loss: 0.3474\n",
      "Epoch [62/100], Step [34500/6235], Loss: 108.6579\n",
      "Epoch [62/100], Step [34600/6235], Loss: 1.6012\n",
      "Epoch [62/100], Step [34700/6235], Loss: 0.6757\n",
      "Epoch [62/100], Step [34800/6235], Loss: 13.0116\n",
      "Epoch [62/100], Step [34900/6235], Loss: 64.9635\n",
      "Epoch [62/100], Step [35000/6235], Loss: 0.0708\n",
      "Epoch [62/100], Step [35100/6235], Loss: 2.0619\n",
      "Epoch [62/100], Step [35200/6235], Loss: 3.3194\n",
      "Epoch [62/100], Step [35300/6235], Loss: 0.0062\n",
      "Epoch [62/100], Step [35400/6235], Loss: 1.0177\n",
      "Epoch [62/100], Step [35500/6235], Loss: 2.0585\n",
      "Epoch [62/100], Step [35600/6235], Loss: 3.4062\n",
      "Epoch [62/100], Step [35700/6235], Loss: 3.8015\n",
      "Epoch [62/100], Step [35800/6235], Loss: 0.1811\n",
      "Epoch [62/100], Step [35900/6235], Loss: 0.3475\n",
      "Epoch [62/100], Step [36000/6235], Loss: 1.6739\n",
      "Epoch [62/100], Step [36100/6235], Loss: 0.1356\n",
      "Epoch [62/100], Step [36200/6235], Loss: 15.0269\n",
      "Epoch [62/100], Step [36300/6235], Loss: 0.3244\n",
      "Epoch [62/100], Step [36400/6235], Loss: 0.5938\n",
      "Epoch [62/100], Step [36500/6235], Loss: 9.9769\n",
      "Epoch [62/100], Step [36600/6235], Loss: 0.0644\n",
      "Epoch [62/100], Step [36700/6235], Loss: 0.1234\n",
      "Epoch [62/100], Step [36800/6235], Loss: 28.6179\n",
      "Epoch [62/100], Step [36900/6235], Loss: 3.7162\n",
      "Epoch [62/100], Step [37000/6235], Loss: 0.0597\n",
      "Epoch [62/100], Step [37100/6235], Loss: 0.0995\n",
      "Epoch [62/100], Step [37200/6235], Loss: 0.0467\n",
      "Epoch [62/100], Step [37300/6235], Loss: 0.3076\n",
      "Epoch [62/100], Step [37400/6235], Loss: 0.2002\n",
      "Epoch [62/100], Step [37500/6235], Loss: 2.6915\n",
      "Epoch [62/100], Step [37600/6235], Loss: 9.9053\n",
      "Epoch [62/100], Step [37700/6235], Loss: 0.0363\n",
      "Epoch [62/100], Step [37800/6235], Loss: 9.0975\n",
      "Epoch [62/100], Step [37900/6235], Loss: 7.2417\n",
      "Epoch [62/100], Step [38000/6235], Loss: 0.1776\n",
      "Epoch [62/100], Step [38100/6235], Loss: 2.2581\n",
      "Epoch [62/100], Step [38200/6235], Loss: 1.5481\n",
      "Epoch [62/100], Step [38300/6235], Loss: 0.4114\n",
      "Epoch [62/100], Step [38400/6235], Loss: 0.0905\n",
      "Epoch [62/100], Step [38500/6235], Loss: 4.0943\n",
      "Epoch [62/100], Step [38600/6235], Loss: 0.2880\n",
      "Epoch [62/100], Step [38700/6235], Loss: 0.2212\n",
      "Epoch [62/100], Step [38800/6235], Loss: 0.4339\n",
      "Epoch [62/100], Step [38900/6235], Loss: 2.7006\n",
      "Epoch [62/100], Step [39000/6235], Loss: 7.9831\n",
      "Epoch [62/100], Step [39100/6235], Loss: 18.6211\n",
      "Epoch [62/100], Step [39200/6235], Loss: 0.1748\n",
      "Epoch [62/100], Step [39300/6235], Loss: 41.1193\n",
      "Epoch [62/100], Step [39400/6235], Loss: 39.6800\n",
      "Epoch [62/100], Step [39500/6235], Loss: 279.8346\n",
      "Epoch [62/100], Step [39600/6235], Loss: 9.1413\n",
      "Epoch [62/100], Step [39700/6235], Loss: 149.2064\n",
      "Epoch [62/100], Step [39800/6235], Loss: 212.3181\n",
      "Epoch [62/100], Step [39900/6235], Loss: 1.1662\n",
      "Epoch [62/100], Step [40000/6235], Loss: 11.9848\n",
      "Epoch [62/100], Step [40100/6235], Loss: 19.4733\n",
      "Epoch [62/100], Step [40200/6235], Loss: 7.3867\n",
      "Epoch [62/100], Step [40300/6235], Loss: 0.7796\n",
      "Epoch [62/100], Step [40400/6235], Loss: 1.4140\n",
      "Epoch [62/100], Step [40500/6235], Loss: 3.0354\n",
      "Epoch [62/100], Step [40600/6235], Loss: 0.2200\n",
      "Epoch [62/100], Step [40700/6235], Loss: 5.7794\n",
      "Epoch [62/100], Step [40800/6235], Loss: 0.8174\n",
      "Epoch [62/100], Step [40900/6235], Loss: 1.2871\n",
      "Epoch [62/100], Step [41000/6235], Loss: 42.1589\n",
      "Epoch [62/100], Step [41100/6235], Loss: 30.1950\n",
      "Epoch [62/100], Step [41200/6235], Loss: 3.1112\n",
      "Epoch [62/100], Step [41300/6235], Loss: 2.6065\n",
      "Epoch [62/100], Step [41400/6235], Loss: 1.8936\n",
      "Epoch [62/100], Step [41500/6235], Loss: 2.6511\n",
      "Epoch [62/100], Step [41600/6235], Loss: 0.8748\n",
      "Epoch [62/100], Step [41700/6235], Loss: 0.0842\n",
      "Epoch [62/100], Step [41800/6235], Loss: 0.9461\n",
      "Epoch [62/100], Step [41900/6235], Loss: 5.0559\n",
      "Epoch [62/100], Step [42000/6235], Loss: 4.7972\n",
      "Epoch [62/100], Step [42100/6235], Loss: 11.7174\n",
      "Epoch [62/100], Step [42200/6235], Loss: 31.2571\n",
      "Epoch [62/100], Step [42300/6235], Loss: 1.2023\n",
      "Epoch [62/100], Step [42400/6235], Loss: 4.1896\n",
      "Epoch [62/100], Step [42500/6235], Loss: 1.4540\n",
      "Epoch [62/100], Step [42600/6235], Loss: 1.4247\n",
      "Epoch [62/100], Step [42700/6235], Loss: 0.7258\n",
      "Epoch [62/100], Step [42800/6235], Loss: 14.6752\n",
      "Epoch [62/100], Step [42900/6235], Loss: 0.5088\n",
      "Epoch [62/100], Step [43000/6235], Loss: 0.3209\n",
      "Epoch [62/100], Step [43100/6235], Loss: 0.0430\n",
      "Epoch [62/100], Step [43200/6235], Loss: 0.3393\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [62/100], Step [43300/6235], Loss: 5.5491\n",
      "Epoch [62/100], Step [43400/6235], Loss: 7.5081\n",
      "Epoch [62/100], Step [43500/6235], Loss: 10.5773\n",
      "Epoch [62/100], Step [43600/6235], Loss: 3.4919\n",
      "Epoch [62/100], Step [43700/6235], Loss: 51.8435\n",
      "Epoch [62/100], Step [43800/6235], Loss: 0.5447\n",
      "Epoch [62/100], Step [43900/6235], Loss: 0.9164\n",
      "Epoch [62/100], Step [44000/6235], Loss: 54.7699\n",
      "Epoch [62/100], Step [44100/6235], Loss: 2.1260\n",
      "Epoch [62/100], Step [44200/6235], Loss: 2.9419\n",
      "Epoch [62/100], Step [44300/6235], Loss: 40.9643\n",
      "Epoch [62/100], Step [44400/6235], Loss: 1.3851\n",
      "Epoch [62/100], Step [44500/6235], Loss: 2.7607\n",
      "Epoch [62/100], Step [44600/6235], Loss: 24.1070\n",
      "Epoch [62/100], Step [44700/6235], Loss: 6.7718\n",
      "Epoch [62/100], Step [44800/6235], Loss: 5.7588\n",
      "Epoch [62/100], Step [44900/6235], Loss: 11.4900\n",
      "Epoch [62/100], Step [45000/6235], Loss: 6.4664\n",
      "Epoch [62/100], Step [45100/6235], Loss: 58.4047\n",
      "Epoch [62/100], Step [45200/6235], Loss: 2.8457\n",
      "Epoch [62/100], Step [45300/6235], Loss: 24.2531\n",
      "Epoch [62/100], Step [45400/6235], Loss: 5.2262\n",
      "Epoch [62/100], Step [45500/6235], Loss: 2.7672\n",
      "Epoch [62/100], Step [45600/6235], Loss: 0.8831\n",
      "Epoch [62/100], Step [45700/6235], Loss: 108.1624\n",
      "Epoch [62/100], Step [45800/6235], Loss: 365.8887\n",
      "Epoch [62/100], Step [45900/6235], Loss: 4.6259\n",
      "Epoch [62/100], Step [46000/6235], Loss: 13.4485\n",
      "Epoch [62/100], Step [46100/6235], Loss: 17.1055\n",
      "Epoch [62/100], Step [46200/6235], Loss: 105.0734\n",
      "Epoch [62/100], Step [46300/6235], Loss: 59.4377\n",
      "Epoch [62/100], Step [46400/6235], Loss: 10.3603\n",
      "Epoch [62/100], Step [46500/6235], Loss: 69.4336\n",
      "Epoch [62/100], Step [46600/6235], Loss: 21.1688\n",
      "Epoch [62/100], Step [46700/6235], Loss: 1.8894\n",
      "Epoch [62/100], Step [46800/6235], Loss: 29.7628\n",
      "Epoch [62/100], Step [46900/6235], Loss: 11.7402\n",
      "Epoch [62/100], Step [47000/6235], Loss: 3.4233\n",
      "Epoch [62/100], Step [47100/6235], Loss: 25.4017\n",
      "Epoch [62/100], Step [47200/6235], Loss: 107.8573\n",
      "Epoch [62/100], Step [47300/6235], Loss: 1.2437\n",
      "Epoch [62/100], Step [47400/6235], Loss: 354.2146\n",
      "Epoch [62/100], Step [47500/6235], Loss: 28.9188\n",
      "Epoch [62/100], Step [47600/6235], Loss: 5.5608\n",
      "Epoch [62/100], Step [47700/6235], Loss: 10.0150\n",
      "Epoch [62/100], Step [47800/6235], Loss: 6.4595\n",
      "Epoch [62/100], Step [47900/6235], Loss: 17.4586\n",
      "Epoch [62/100], Step [48000/6235], Loss: 3.8941\n",
      "Epoch [62/100], Step [48100/6235], Loss: 4.0661\n",
      "Epoch [62/100], Step [48200/6235], Loss: 5.6767\n",
      "Epoch [62/100], Step [48300/6235], Loss: 572.9077\n",
      "Epoch [62/100], Step [48400/6235], Loss: 19.9024\n",
      "Epoch [62/100], Step [48500/6235], Loss: 19.3698\n",
      "Epoch [62/100], Step [48600/6235], Loss: 164.1031\n",
      "Epoch [62/100], Step [48700/6235], Loss: 14.0655\n",
      "Epoch [62/100], Step [48800/6235], Loss: 257.5596\n",
      "Epoch [62/100], Step [48900/6235], Loss: 447.4890\n",
      "Epoch [62/100], Step [49000/6235], Loss: 151.8362\n",
      "Epoch [62/100], Step [49100/6235], Loss: 2701.7258\n",
      "Epoch [62/100], Step [49200/6235], Loss: 1184.6183\n",
      "Epoch [62/100], Step [49300/6235], Loss: 1011.5881\n",
      "Epoch [62/100], Step [49400/6235], Loss: 39.8290\n",
      "Epoch [62/100], Step [49500/6235], Loss: 10.1999\n",
      "Epoch [62/100], Step [49600/6235], Loss: 90.0522\n",
      "Epoch [62/100], Step [49700/6235], Loss: 1733.8770\n",
      "Epoch [62/100], Step [49800/6235], Loss: 1228.0269\n",
      "Epoch [63/100], Step [100/6235], Loss: 14.4829\n",
      "Epoch [63/100], Step [200/6235], Loss: 0.1563\n",
      "Epoch [63/100], Step [300/6235], Loss: 0.0533\n",
      "Epoch [63/100], Step [400/6235], Loss: 0.0231\n",
      "Epoch [63/100], Step [500/6235], Loss: 19.8058\n",
      "Epoch [63/100], Step [600/6235], Loss: 0.0434\n",
      "Epoch [63/100], Step [700/6235], Loss: 0.5767\n",
      "Epoch [63/100], Step [800/6235], Loss: 0.1254\n",
      "Epoch [63/100], Step [900/6235], Loss: 0.2287\n",
      "Epoch [63/100], Step [1000/6235], Loss: 0.1252\n",
      "Epoch [63/100], Step [1100/6235], Loss: 0.6082\n",
      "Epoch [63/100], Step [1200/6235], Loss: 0.1790\n",
      "Epoch [63/100], Step [1300/6235], Loss: 0.2180\n",
      "Epoch [63/100], Step [1400/6235], Loss: 0.8462\n",
      "Epoch [63/100], Step [1500/6235], Loss: 0.0137\n",
      "Epoch [63/100], Step [1600/6235], Loss: 0.2296\n",
      "Epoch [63/100], Step [1700/6235], Loss: 0.1214\n",
      "Epoch [63/100], Step [1800/6235], Loss: 0.2198\n",
      "Epoch [63/100], Step [1900/6235], Loss: 0.4426\n",
      "Epoch [63/100], Step [2000/6235], Loss: 2.3079\n",
      "Epoch [63/100], Step [2100/6235], Loss: 1.6892\n",
      "Epoch [63/100], Step [2200/6235], Loss: 8.2712\n",
      "Epoch [63/100], Step [2300/6235], Loss: 5.7021\n",
      "Epoch [63/100], Step [2400/6235], Loss: 1.4373\n",
      "Epoch [63/100], Step [2500/6235], Loss: 35.4573\n",
      "Epoch [63/100], Step [2600/6235], Loss: 12.7261\n",
      "Epoch [63/100], Step [2700/6235], Loss: 11.5449\n",
      "Epoch [63/100], Step [2800/6235], Loss: 302.4149\n",
      "Epoch [63/100], Step [2900/6235], Loss: 11.3991\n",
      "Epoch [63/100], Step [3000/6235], Loss: 0.5121\n",
      "Epoch [63/100], Step [3100/6235], Loss: 68.9117\n",
      "Epoch [63/100], Step [3200/6235], Loss: 83.1777\n",
      "Epoch [63/100], Step [3300/6235], Loss: 6.8782\n",
      "Epoch [63/100], Step [3400/6235], Loss: 1.9136\n",
      "Epoch [63/100], Step [3500/6235], Loss: 37.8998\n",
      "Epoch [63/100], Step [3600/6235], Loss: 9.7449\n",
      "Epoch [63/100], Step [3700/6235], Loss: 0.1519\n",
      "Epoch [63/100], Step [3800/6235], Loss: 0.3792\n",
      "Epoch [63/100], Step [3900/6235], Loss: 1.2093\n",
      "Epoch [63/100], Step [4000/6235], Loss: 0.0309\n",
      "Epoch [63/100], Step [4100/6235], Loss: 6.5921\n",
      "Epoch [63/100], Step [4200/6235], Loss: 0.4341\n",
      "Epoch [63/100], Step [4300/6235], Loss: 9.3638\n",
      "Epoch [63/100], Step [4400/6235], Loss: 3.9044\n",
      "Epoch [63/100], Step [4500/6235], Loss: 41.9877\n",
      "Epoch [63/100], Step [4600/6235], Loss: 7.5414\n",
      "Epoch [63/100], Step [4700/6235], Loss: 0.2729\n",
      "Epoch [63/100], Step [4800/6235], Loss: 9.0919\n",
      "Epoch [63/100], Step [4900/6235], Loss: 0.1984\n",
      "Epoch [63/100], Step [5000/6235], Loss: 0.1261\n",
      "Epoch [63/100], Step [5100/6235], Loss: 4.2428\n",
      "Epoch [63/100], Step [5200/6235], Loss: 4.7635\n",
      "Epoch [63/100], Step [5300/6235], Loss: 39.6531\n",
      "Epoch [63/100], Step [5400/6235], Loss: 2.4402\n",
      "Epoch [63/100], Step [5500/6235], Loss: 0.1441\n",
      "Epoch [63/100], Step [5600/6235], Loss: 0.3433\n",
      "Epoch [63/100], Step [5700/6235], Loss: 0.3633\n",
      "Epoch [63/100], Step [5800/6235], Loss: 0.1810\n",
      "Epoch [63/100], Step [5900/6235], Loss: 0.1917\n",
      "Epoch [63/100], Step [6000/6235], Loss: 2.7608\n",
      "Epoch [63/100], Step [6100/6235], Loss: 0.1744\n",
      "Epoch [63/100], Step [6200/6235], Loss: 1.9425\n",
      "Epoch [63/100], Step [6300/6235], Loss: 1.9050\n",
      "Epoch [63/100], Step [6400/6235], Loss: 0.1143\n",
      "Epoch [63/100], Step [6500/6235], Loss: 1.7716\n",
      "Epoch [63/100], Step [6600/6235], Loss: 5.6720\n",
      "Epoch [63/100], Step [6700/6235], Loss: 3.2805\n",
      "Epoch [63/100], Step [6800/6235], Loss: 0.6635\n",
      "Epoch [63/100], Step [6900/6235], Loss: 0.7031\n",
      "Epoch [63/100], Step [7000/6235], Loss: 0.4175\n",
      "Epoch [63/100], Step [7100/6235], Loss: 0.2068\n",
      "Epoch [63/100], Step [7200/6235], Loss: 0.1527\n",
      "Epoch [63/100], Step [7300/6235], Loss: 0.2171\n",
      "Epoch [63/100], Step [7400/6235], Loss: 0.2405\n",
      "Epoch [63/100], Step [7500/6235], Loss: 0.8873\n",
      "Epoch [63/100], Step [7600/6235], Loss: 0.4589\n",
      "Epoch [63/100], Step [7700/6235], Loss: 20.4184\n",
      "Epoch [63/100], Step [7800/6235], Loss: 4.0824\n",
      "Epoch [63/100], Step [7900/6235], Loss: 4.8435\n",
      "Epoch [63/100], Step [8000/6235], Loss: 0.0535\n",
      "Epoch [63/100], Step [8100/6235], Loss: 4.7362\n",
      "Epoch [63/100], Step [8200/6235], Loss: 14.0062\n",
      "Epoch [63/100], Step [8300/6235], Loss: 45.8026\n",
      "Epoch [63/100], Step [8400/6235], Loss: 244.9429\n",
      "Epoch [63/100], Step [8500/6235], Loss: 1.9889\n",
      "Epoch [63/100], Step [8600/6235], Loss: 140.5183\n",
      "Epoch [63/100], Step [8700/6235], Loss: 64.7679\n",
      "Epoch [63/100], Step [8800/6235], Loss: 336.4040\n",
      "Epoch [63/100], Step [8900/6235], Loss: 92.6967\n",
      "Epoch [63/100], Step [9000/6235], Loss: 581.7667\n",
      "Epoch [63/100], Step [9100/6235], Loss: 3394.6677\n",
      "Epoch [63/100], Step [9200/6235], Loss: 6240.5337\n",
      "Epoch [63/100], Step [9300/6235], Loss: 135.6956\n",
      "Epoch [63/100], Step [9400/6235], Loss: 70.5714\n",
      "Epoch [63/100], Step [9500/6235], Loss: 2404.1008\n",
      "Epoch [63/100], Step [9600/6235], Loss: 683.7665\n",
      "Epoch [63/100], Step [9700/6235], Loss: 5.0032\n",
      "Epoch [63/100], Step [9800/6235], Loss: 3064.8835\n",
      "Epoch [63/100], Step [9900/6235], Loss: 305.0125\n",
      "Epoch [63/100], Step [10000/6235], Loss: 250.4100\n",
      "Epoch [63/100], Step [10100/6235], Loss: 4.7358\n",
      "Epoch [63/100], Step [10200/6235], Loss: 458.2797\n",
      "Epoch [63/100], Step [10300/6235], Loss: 6.2130\n",
      "Epoch [63/100], Step [10400/6235], Loss: 9.4553\n",
      "Epoch [63/100], Step [10500/6235], Loss: 5.7341\n",
      "Epoch [63/100], Step [10600/6235], Loss: 24.7592\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Step [10700/6235], Loss: 21.8629\n",
      "Epoch [63/100], Step [10800/6235], Loss: 50.5690\n",
      "Epoch [63/100], Step [10900/6235], Loss: 2.3591\n",
      "Epoch [63/100], Step [11000/6235], Loss: 290.5358\n",
      "Epoch [63/100], Step [11100/6235], Loss: 38.5456\n",
      "Epoch [63/100], Step [11200/6235], Loss: 35.2326\n",
      "Epoch [63/100], Step [11300/6235], Loss: 157.0517\n",
      "Epoch [63/100], Step [11400/6235], Loss: 3.2388\n",
      "Epoch [63/100], Step [11500/6235], Loss: 2.7996\n",
      "Epoch [63/100], Step [11600/6235], Loss: 2.2551\n",
      "Epoch [63/100], Step [11700/6235], Loss: 38.9474\n",
      "Epoch [63/100], Step [11800/6235], Loss: 368.9023\n",
      "Epoch [63/100], Step [11900/6235], Loss: 98.6888\n",
      "Epoch [63/100], Step [12000/6235], Loss: 720.2545\n",
      "Epoch [63/100], Step [12100/6235], Loss: 315.6786\n",
      "Epoch [63/100], Step [12200/6235], Loss: 1.7716\n",
      "Epoch [63/100], Step [12300/6235], Loss: 5.8305\n",
      "Epoch [63/100], Step [12400/6235], Loss: 679.2554\n",
      "Epoch [63/100], Step [12500/6235], Loss: 60.5000\n",
      "Epoch [63/100], Step [12600/6235], Loss: 23.4969\n",
      "Epoch [63/100], Step [12700/6235], Loss: 6.7671\n",
      "Epoch [63/100], Step [12800/6235], Loss: 6.4814\n",
      "Epoch [63/100], Step [12900/6235], Loss: 37.0025\n",
      "Epoch [63/100], Step [13000/6235], Loss: 0.3388\n",
      "Epoch [63/100], Step [13100/6235], Loss: 65.3931\n",
      "Epoch [63/100], Step [13200/6235], Loss: 9.8331\n",
      "Epoch [63/100], Step [13300/6235], Loss: 42.1568\n",
      "Epoch [63/100], Step [13400/6235], Loss: 245.6319\n",
      "Epoch [63/100], Step [13500/6235], Loss: 1.3242\n",
      "Epoch [63/100], Step [13600/6235], Loss: 4.0293\n",
      "Epoch [63/100], Step [13700/6235], Loss: 156.1382\n",
      "Epoch [63/100], Step [13800/6235], Loss: 106.3915\n",
      "Epoch [63/100], Step [13900/6235], Loss: 17.7297\n",
      "Epoch [63/100], Step [14000/6235], Loss: 12.2314\n",
      "Epoch [63/100], Step [14100/6235], Loss: 22.5704\n",
      "Epoch [63/100], Step [14200/6235], Loss: 113.9824\n",
      "Epoch [63/100], Step [14300/6235], Loss: 49.6120\n",
      "Epoch [63/100], Step [14400/6235], Loss: 39.0567\n",
      "Epoch [63/100], Step [14500/6235], Loss: 40.2376\n",
      "Epoch [63/100], Step [14600/6235], Loss: 0.5462\n",
      "Epoch [63/100], Step [14700/6235], Loss: 37.7617\n",
      "Epoch [63/100], Step [14800/6235], Loss: 33.5712\n",
      "Epoch [63/100], Step [14900/6235], Loss: 0.7385\n",
      "Epoch [63/100], Step [15000/6235], Loss: 1.5853\n",
      "Epoch [63/100], Step [15100/6235], Loss: 0.5501\n",
      "Epoch [63/100], Step [15200/6235], Loss: 3.5202\n",
      "Epoch [63/100], Step [15300/6235], Loss: 39.1843\n",
      "Epoch [63/100], Step [15400/6235], Loss: 82.3384\n",
      "Epoch [63/100], Step [15500/6235], Loss: 12.9349\n",
      "Epoch [63/100], Step [15600/6235], Loss: 168.4588\n",
      "Epoch [63/100], Step [15700/6235], Loss: 35.5647\n",
      "Epoch [63/100], Step [15800/6235], Loss: 7.2400\n",
      "Epoch [63/100], Step [15900/6235], Loss: 0.4179\n",
      "Epoch [63/100], Step [16000/6235], Loss: 22.8688\n",
      "Epoch [63/100], Step [16100/6235], Loss: 14.2526\n",
      "Epoch [63/100], Step [16200/6235], Loss: 0.5171\n",
      "Epoch [63/100], Step [16300/6235], Loss: 9.6332\n",
      "Epoch [63/100], Step [16400/6235], Loss: 21.6592\n",
      "Epoch [63/100], Step [16500/6235], Loss: 680.5875\n",
      "Epoch [63/100], Step [16600/6235], Loss: 27.5171\n",
      "Epoch [63/100], Step [16700/6235], Loss: 0.6361\n",
      "Epoch [63/100], Step [16800/6235], Loss: 8.6896\n",
      "Epoch [63/100], Step [16900/6235], Loss: 0.1620\n",
      "Epoch [63/100], Step [17000/6235], Loss: 0.2210\n",
      "Epoch [63/100], Step [17100/6235], Loss: 0.1896\n",
      "Epoch [63/100], Step [17200/6235], Loss: 281.8115\n",
      "Epoch [63/100], Step [17300/6235], Loss: 34.8755\n",
      "Epoch [63/100], Step [17400/6235], Loss: 74.8623\n",
      "Epoch [63/100], Step [17500/6235], Loss: 0.5488\n",
      "Epoch [63/100], Step [17600/6235], Loss: 3.0142\n",
      "Epoch [63/100], Step [17700/6235], Loss: 35.9044\n",
      "Epoch [63/100], Step [17800/6235], Loss: 19.5141\n",
      "Epoch [63/100], Step [17900/6235], Loss: 5.7411\n",
      "Epoch [63/100], Step [18000/6235], Loss: 15.8252\n",
      "Epoch [63/100], Step [18100/6235], Loss: 19.6095\n",
      "Epoch [63/100], Step [18200/6235], Loss: 0.6732\n",
      "Epoch [63/100], Step [18300/6235], Loss: 5.8233\n",
      "Epoch [63/100], Step [18400/6235], Loss: 3.9930\n",
      "Epoch [63/100], Step [18500/6235], Loss: 13.8030\n",
      "Epoch [63/100], Step [18600/6235], Loss: 2.1133\n",
      "Epoch [63/100], Step [18700/6235], Loss: 0.4834\n",
      "Epoch [63/100], Step [18800/6235], Loss: 127.1832\n",
      "Epoch [63/100], Step [18900/6235], Loss: 36.1592\n",
      "Epoch [63/100], Step [19000/6235], Loss: 1.6015\n",
      "Epoch [63/100], Step [19100/6235], Loss: 43.4735\n",
      "Epoch [63/100], Step [19200/6235], Loss: 1.1765\n",
      "Epoch [63/100], Step [19300/6235], Loss: 2.3229\n",
      "Epoch [63/100], Step [19400/6235], Loss: 234.5748\n",
      "Epoch [63/100], Step [19500/6235], Loss: 112.4884\n",
      "Epoch [63/100], Step [19600/6235], Loss: 74.3009\n",
      "Epoch [63/100], Step [19700/6235], Loss: 5.2763\n",
      "Epoch [63/100], Step [19800/6235], Loss: 4.3573\n",
      "Epoch [63/100], Step [19900/6235], Loss: 0.0998\n",
      "Epoch [63/100], Step [20000/6235], Loss: 66.3468\n",
      "Epoch [63/100], Step [20100/6235], Loss: 0.9761\n",
      "Epoch [63/100], Step [20200/6235], Loss: 2.8215\n",
      "Epoch [63/100], Step [20300/6235], Loss: 2.2519\n",
      "Epoch [63/100], Step [20400/6235], Loss: 15.4269\n",
      "Epoch [63/100], Step [20500/6235], Loss: 47.7539\n",
      "Epoch [63/100], Step [20600/6235], Loss: 56.3782\n",
      "Epoch [63/100], Step [20700/6235], Loss: 4.4349\n",
      "Epoch [63/100], Step [20800/6235], Loss: 7.6836\n",
      "Epoch [63/100], Step [20900/6235], Loss: 34.2326\n",
      "Epoch [63/100], Step [21000/6235], Loss: 13.7673\n",
      "Epoch [63/100], Step [21100/6235], Loss: 6.3943\n",
      "Epoch [63/100], Step [21200/6235], Loss: 0.2422\n",
      "Epoch [63/100], Step [21300/6235], Loss: 0.2023\n",
      "Epoch [63/100], Step [21400/6235], Loss: 6.4081\n",
      "Epoch [63/100], Step [21500/6235], Loss: 1.8915\n",
      "Epoch [63/100], Step [21600/6235], Loss: 32.3675\n",
      "Epoch [63/100], Step [21700/6235], Loss: 0.1292\n",
      "Epoch [63/100], Step [21800/6235], Loss: 1.2301\n",
      "Epoch [63/100], Step [21900/6235], Loss: 0.9861\n",
      "Epoch [63/100], Step [22000/6235], Loss: 5.7018\n",
      "Epoch [63/100], Step [22100/6235], Loss: 1.6860\n",
      "Epoch [63/100], Step [22200/6235], Loss: 6.9717\n",
      "Epoch [63/100], Step [22300/6235], Loss: 3.2845\n",
      "Epoch [63/100], Step [22400/6235], Loss: 7.7598\n",
      "Epoch [63/100], Step [22500/6235], Loss: 113.2739\n",
      "Epoch [63/100], Step [22600/6235], Loss: 15.6635\n",
      "Epoch [63/100], Step [22700/6235], Loss: 0.7397\n",
      "Epoch [63/100], Step [22800/6235], Loss: 10.9950\n",
      "Epoch [63/100], Step [22900/6235], Loss: 15.8976\n",
      "Epoch [63/100], Step [23000/6235], Loss: 9.0764\n",
      "Epoch [63/100], Step [23100/6235], Loss: 7.5688\n",
      "Epoch [63/100], Step [23200/6235], Loss: 8.0586\n",
      "Epoch [63/100], Step [23300/6235], Loss: 16.0525\n",
      "Epoch [63/100], Step [23400/6235], Loss: 1.2109\n",
      "Epoch [63/100], Step [23500/6235], Loss: 0.1954\n",
      "Epoch [63/100], Step [23600/6235], Loss: 114.3585\n",
      "Epoch [63/100], Step [23700/6235], Loss: 4.5873\n",
      "Epoch [63/100], Step [23800/6235], Loss: 1.1071\n",
      "Epoch [63/100], Step [23900/6235], Loss: 6.7961\n",
      "Epoch [63/100], Step [24000/6235], Loss: 0.3196\n",
      "Epoch [63/100], Step [24100/6235], Loss: 0.2187\n",
      "Epoch [63/100], Step [24200/6235], Loss: 44.4168\n",
      "Epoch [63/100], Step [24300/6235], Loss: 2.6603\n",
      "Epoch [63/100], Step [24400/6235], Loss: 3.8613\n",
      "Epoch [63/100], Step [24500/6235], Loss: 2.0336\n",
      "Epoch [63/100], Step [24600/6235], Loss: 0.1126\n",
      "Epoch [63/100], Step [24700/6235], Loss: 0.1282\n",
      "Epoch [63/100], Step [24800/6235], Loss: 0.0947\n",
      "Epoch [63/100], Step [24900/6235], Loss: 16.8856\n",
      "Epoch [63/100], Step [25000/6235], Loss: 17.9357\n",
      "Epoch [63/100], Step [25100/6235], Loss: 6.7769\n",
      "Epoch [63/100], Step [25200/6235], Loss: 1.3835\n",
      "Epoch [63/100], Step [25300/6235], Loss: 0.6068\n",
      "Epoch [63/100], Step [25400/6235], Loss: 9.9353\n",
      "Epoch [63/100], Step [25500/6235], Loss: 6.1689\n",
      "Epoch [63/100], Step [25600/6235], Loss: 2.9730\n",
      "Epoch [63/100], Step [25700/6235], Loss: 0.3687\n",
      "Epoch [63/100], Step [25800/6235], Loss: 0.1596\n",
      "Epoch [63/100], Step [25900/6235], Loss: 9.8237\n",
      "Epoch [63/100], Step [26000/6235], Loss: 6.0767\n",
      "Epoch [63/100], Step [26100/6235], Loss: 1.1011\n",
      "Epoch [63/100], Step [26200/6235], Loss: 0.0922\n",
      "Epoch [63/100], Step [26300/6235], Loss: 4.6349\n",
      "Epoch [63/100], Step [26400/6235], Loss: 0.1247\n",
      "Epoch [63/100], Step [26500/6235], Loss: 0.1261\n",
      "Epoch [63/100], Step [26600/6235], Loss: 2.7153\n",
      "Epoch [63/100], Step [26700/6235], Loss: 0.5654\n",
      "Epoch [63/100], Step [26800/6235], Loss: 0.4343\n",
      "Epoch [63/100], Step [26900/6235], Loss: 0.0181\n",
      "Epoch [63/100], Step [27000/6235], Loss: 13.3357\n",
      "Epoch [63/100], Step [27100/6235], Loss: 0.1097\n",
      "Epoch [63/100], Step [27200/6235], Loss: 0.0481\n",
      "Epoch [63/100], Step [27300/6235], Loss: 0.2245\n",
      "Epoch [63/100], Step [27400/6235], Loss: 0.8628\n",
      "Epoch [63/100], Step [27500/6235], Loss: 20.6751\n",
      "Epoch [63/100], Step [27600/6235], Loss: 1.3760\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Step [27700/6235], Loss: 1.3468\n",
      "Epoch [63/100], Step [27800/6235], Loss: 3.4935\n",
      "Epoch [63/100], Step [27900/6235], Loss: 0.0861\n",
      "Epoch [63/100], Step [28000/6235], Loss: 175.6135\n",
      "Epoch [63/100], Step [28100/6235], Loss: 3.5651\n",
      "Epoch [63/100], Step [28200/6235], Loss: 29.2226\n",
      "Epoch [63/100], Step [28300/6235], Loss: 3.5809\n",
      "Epoch [63/100], Step [28400/6235], Loss: 25.9925\n",
      "Epoch [63/100], Step [28500/6235], Loss: 4.5754\n",
      "Epoch [63/100], Step [28600/6235], Loss: 0.1524\n",
      "Epoch [63/100], Step [28700/6235], Loss: 5.1753\n",
      "Epoch [63/100], Step [28800/6235], Loss: 0.5106\n",
      "Epoch [63/100], Step [28900/6235], Loss: 73.1859\n",
      "Epoch [63/100], Step [29000/6235], Loss: 6.0665\n",
      "Epoch [63/100], Step [29100/6235], Loss: 0.0230\n",
      "Epoch [63/100], Step [29200/6235], Loss: 0.1976\n",
      "Epoch [63/100], Step [29300/6235], Loss: 13.5809\n",
      "Epoch [63/100], Step [29400/6235], Loss: 0.0603\n",
      "Epoch [63/100], Step [29500/6235], Loss: 0.8180\n",
      "Epoch [63/100], Step [29600/6235], Loss: 0.3831\n",
      "Epoch [63/100], Step [29700/6235], Loss: 0.6822\n",
      "Epoch [63/100], Step [29800/6235], Loss: 1.7393\n",
      "Epoch [63/100], Step [29900/6235], Loss: 0.6212\n",
      "Epoch [63/100], Step [30000/6235], Loss: 5.9681\n",
      "Epoch [63/100], Step [30100/6235], Loss: 12.1740\n",
      "Epoch [63/100], Step [30200/6235], Loss: 0.3359\n",
      "Epoch [63/100], Step [30300/6235], Loss: 0.1882\n",
      "Epoch [63/100], Step [30400/6235], Loss: 0.4370\n",
      "Epoch [63/100], Step [30500/6235], Loss: 2.2149\n",
      "Epoch [63/100], Step [30600/6235], Loss: 1.0459\n",
      "Epoch [63/100], Step [30700/6235], Loss: 0.0158\n",
      "Epoch [63/100], Step [30800/6235], Loss: 0.3239\n",
      "Epoch [63/100], Step [30900/6235], Loss: 3.6381\n",
      "Epoch [63/100], Step [31000/6235], Loss: 0.0187\n",
      "Epoch [63/100], Step [31100/6235], Loss: 0.0355\n",
      "Epoch [63/100], Step [31200/6235], Loss: 6.7254\n",
      "Epoch [63/100], Step [31300/6235], Loss: 3.6797\n",
      "Epoch [63/100], Step [31400/6235], Loss: 7.9582\n",
      "Epoch [63/100], Step [31500/6235], Loss: 0.5702\n",
      "Epoch [63/100], Step [31600/6235], Loss: 6.6434\n",
      "Epoch [63/100], Step [31700/6235], Loss: 0.5836\n",
      "Epoch [63/100], Step [31800/6235], Loss: 1.3381\n",
      "Epoch [63/100], Step [31900/6235], Loss: 42.2024\n",
      "Epoch [63/100], Step [32000/6235], Loss: 10.8309\n",
      "Epoch [63/100], Step [32100/6235], Loss: 1.5295\n",
      "Epoch [63/100], Step [32200/6235], Loss: 45.2593\n",
      "Epoch [63/100], Step [32300/6235], Loss: 0.5614\n",
      "Epoch [63/100], Step [32400/6235], Loss: 0.3182\n",
      "Epoch [63/100], Step [32500/6235], Loss: 22.1152\n",
      "Epoch [63/100], Step [32600/6235], Loss: 1.0151\n",
      "Epoch [63/100], Step [32700/6235], Loss: 51.9746\n",
      "Epoch [63/100], Step [32800/6235], Loss: 2.0284\n",
      "Epoch [63/100], Step [32900/6235], Loss: 10.9197\n",
      "Epoch [63/100], Step [33000/6235], Loss: 0.3460\n",
      "Epoch [63/100], Step [33100/6235], Loss: 1.0450\n",
      "Epoch [63/100], Step [33200/6235], Loss: 1.0657\n",
      "Epoch [63/100], Step [33300/6235], Loss: 12.4762\n",
      "Epoch [63/100], Step [33400/6235], Loss: 68.6070\n",
      "Epoch [63/100], Step [33500/6235], Loss: 0.4104\n",
      "Epoch [63/100], Step [33600/6235], Loss: 2.5508\n",
      "Epoch [63/100], Step [33700/6235], Loss: 1.2998\n",
      "Epoch [63/100], Step [33800/6235], Loss: 0.4672\n",
      "Epoch [63/100], Step [33900/6235], Loss: 26.1324\n",
      "Epoch [63/100], Step [34000/6235], Loss: 0.0203\n",
      "Epoch [63/100], Step [34100/6235], Loss: 0.2133\n",
      "Epoch [63/100], Step [34200/6235], Loss: 2.5267\n",
      "Epoch [63/100], Step [34300/6235], Loss: 6.9193\n",
      "Epoch [63/100], Step [34400/6235], Loss: 0.0651\n",
      "Epoch [63/100], Step [34500/6235], Loss: 48.4473\n",
      "Epoch [63/100], Step [34600/6235], Loss: 1.0925\n",
      "Epoch [63/100], Step [34700/6235], Loss: 28.1505\n",
      "Epoch [63/100], Step [34800/6235], Loss: 13.6891\n",
      "Epoch [63/100], Step [34900/6235], Loss: 24.1903\n",
      "Epoch [63/100], Step [35000/6235], Loss: 1.9145\n",
      "Epoch [63/100], Step [35100/6235], Loss: 6.1701\n",
      "Epoch [63/100], Step [35200/6235], Loss: 4.9048\n",
      "Epoch [63/100], Step [35300/6235], Loss: 2.0466\n",
      "Epoch [63/100], Step [35400/6235], Loss: 0.8625\n",
      "Epoch [63/100], Step [35500/6235], Loss: 1.8133\n",
      "Epoch [63/100], Step [35600/6235], Loss: 2.5896\n",
      "Epoch [63/100], Step [35700/6235], Loss: 6.3993\n",
      "Epoch [63/100], Step [35800/6235], Loss: 0.6028\n",
      "Epoch [63/100], Step [35900/6235], Loss: 0.2321\n",
      "Epoch [63/100], Step [36000/6235], Loss: 0.8979\n",
      "Epoch [63/100], Step [36100/6235], Loss: 0.0191\n",
      "Epoch [63/100], Step [36200/6235], Loss: 15.1363\n",
      "Epoch [63/100], Step [36300/6235], Loss: 0.5493\n",
      "Epoch [63/100], Step [36400/6235], Loss: 1.6372\n",
      "Epoch [63/100], Step [36500/6235], Loss: 9.5187\n",
      "Epoch [63/100], Step [36600/6235], Loss: 0.1241\n",
      "Epoch [63/100], Step [36700/6235], Loss: 0.1330\n",
      "Epoch [63/100], Step [36800/6235], Loss: 18.9199\n",
      "Epoch [63/100], Step [36900/6235], Loss: 7.4906\n",
      "Epoch [63/100], Step [37000/6235], Loss: 0.1156\n",
      "Epoch [63/100], Step [37100/6235], Loss: 0.6851\n",
      "Epoch [63/100], Step [37200/6235], Loss: 0.0723\n",
      "Epoch [63/100], Step [37300/6235], Loss: 0.1063\n",
      "Epoch [63/100], Step [37400/6235], Loss: 0.2000\n",
      "Epoch [63/100], Step [37500/6235], Loss: 3.4407\n",
      "Epoch [63/100], Step [37600/6235], Loss: 11.1583\n",
      "Epoch [63/100], Step [37700/6235], Loss: 0.8673\n",
      "Epoch [63/100], Step [37800/6235], Loss: 6.8041\n",
      "Epoch [63/100], Step [37900/6235], Loss: 6.4176\n",
      "Epoch [63/100], Step [38000/6235], Loss: 0.3872\n",
      "Epoch [63/100], Step [38100/6235], Loss: 2.5505\n",
      "Epoch [63/100], Step [38200/6235], Loss: 1.9334\n",
      "Epoch [63/100], Step [38300/6235], Loss: 0.1718\n",
      "Epoch [63/100], Step [38400/6235], Loss: 0.1666\n",
      "Epoch [63/100], Step [38500/6235], Loss: 3.3031\n",
      "Epoch [63/100], Step [38600/6235], Loss: 0.0735\n",
      "Epoch [63/100], Step [38700/6235], Loss: 0.1340\n",
      "Epoch [63/100], Step [38800/6235], Loss: 0.2981\n",
      "Epoch [63/100], Step [38900/6235], Loss: 4.6262\n",
      "Epoch [63/100], Step [39000/6235], Loss: 20.8709\n",
      "Epoch [63/100], Step [39100/6235], Loss: 15.9617\n",
      "Epoch [63/100], Step [39200/6235], Loss: 0.4442\n",
      "Epoch [63/100], Step [39300/6235], Loss: 3.2119\n",
      "Epoch [63/100], Step [39400/6235], Loss: 378.6414\n",
      "Epoch [63/100], Step [39500/6235], Loss: 6.8638\n",
      "Epoch [63/100], Step [39600/6235], Loss: 6.9020\n",
      "Epoch [63/100], Step [39700/6235], Loss: 48.2870\n",
      "Epoch [63/100], Step [39800/6235], Loss: 128.4705\n",
      "Epoch [63/100], Step [39900/6235], Loss: 1.5891\n",
      "Epoch [63/100], Step [40000/6235], Loss: 3.1846\n",
      "Epoch [63/100], Step [40100/6235], Loss: 11.5740\n",
      "Epoch [63/100], Step [40200/6235], Loss: 8.6170\n",
      "Epoch [63/100], Step [40300/6235], Loss: 1.5358\n",
      "Epoch [63/100], Step [40400/6235], Loss: 0.6459\n",
      "Epoch [63/100], Step [40500/6235], Loss: 2.9735\n",
      "Epoch [63/100], Step [40600/6235], Loss: 0.2034\n",
      "Epoch [63/100], Step [40700/6235], Loss: 6.2446\n",
      "Epoch [63/100], Step [40800/6235], Loss: 0.6493\n",
      "Epoch [63/100], Step [40900/6235], Loss: 1.1886\n",
      "Epoch [63/100], Step [41000/6235], Loss: 41.4396\n",
      "Epoch [63/100], Step [41100/6235], Loss: 32.3791\n",
      "Epoch [63/100], Step [41200/6235], Loss: 13.2219\n",
      "Epoch [63/100], Step [41300/6235], Loss: 3.6701\n",
      "Epoch [63/100], Step [41400/6235], Loss: 0.4901\n",
      "Epoch [63/100], Step [41500/6235], Loss: 1.1324\n",
      "Epoch [63/100], Step [41600/6235], Loss: 0.0208\n",
      "Epoch [63/100], Step [41700/6235], Loss: 0.1442\n",
      "Epoch [63/100], Step [41800/6235], Loss: 1.6883\n",
      "Epoch [63/100], Step [41900/6235], Loss: 4.8293\n",
      "Epoch [63/100], Step [42000/6235], Loss: 4.0140\n",
      "Epoch [63/100], Step [42100/6235], Loss: 9.3148\n",
      "Epoch [63/100], Step [42200/6235], Loss: 19.8250\n",
      "Epoch [63/100], Step [42300/6235], Loss: 0.6917\n",
      "Epoch [63/100], Step [42400/6235], Loss: 3.3843\n",
      "Epoch [63/100], Step [42500/6235], Loss: 4.4480\n",
      "Epoch [63/100], Step [42600/6235], Loss: 0.5173\n",
      "Epoch [63/100], Step [42700/6235], Loss: 0.2311\n",
      "Epoch [63/100], Step [42800/6235], Loss: 2.6514\n",
      "Epoch [63/100], Step [42900/6235], Loss: 3.8591\n",
      "Epoch [63/100], Step [43000/6235], Loss: 0.2348\n",
      "Epoch [63/100], Step [43100/6235], Loss: 0.4978\n",
      "Epoch [63/100], Step [43200/6235], Loss: 1.0056\n",
      "Epoch [63/100], Step [43300/6235], Loss: 8.8469\n",
      "Epoch [63/100], Step [43400/6235], Loss: 11.1789\n",
      "Epoch [63/100], Step [43500/6235], Loss: 9.4614\n",
      "Epoch [63/100], Step [43600/6235], Loss: 14.2153\n",
      "Epoch [63/100], Step [43700/6235], Loss: 43.6993\n",
      "Epoch [63/100], Step [43800/6235], Loss: 0.9635\n",
      "Epoch [63/100], Step [43900/6235], Loss: 0.4814\n",
      "Epoch [63/100], Step [44000/6235], Loss: 56.3259\n",
      "Epoch [63/100], Step [44100/6235], Loss: 5.4590\n",
      "Epoch [63/100], Step [44200/6235], Loss: 9.7321\n",
      "Epoch [63/100], Step [44300/6235], Loss: 1.1027\n",
      "Epoch [63/100], Step [44400/6235], Loss: 0.5006\n",
      "Epoch [63/100], Step [44500/6235], Loss: 2.5309\n",
      "Epoch [63/100], Step [44600/6235], Loss: 8.8433\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [63/100], Step [44700/6235], Loss: 3.5030\n",
      "Epoch [63/100], Step [44800/6235], Loss: 5.0843\n",
      "Epoch [63/100], Step [44900/6235], Loss: 10.4567\n",
      "Epoch [63/100], Step [45000/6235], Loss: 5.9728\n",
      "Epoch [63/100], Step [45100/6235], Loss: 37.6149\n",
      "Epoch [63/100], Step [45200/6235], Loss: 0.7485\n",
      "Epoch [63/100], Step [45300/6235], Loss: 25.0038\n",
      "Epoch [63/100], Step [45400/6235], Loss: 14.1348\n",
      "Epoch [63/100], Step [45500/6235], Loss: 2.2972\n",
      "Epoch [63/100], Step [45600/6235], Loss: 0.9437\n",
      "Epoch [63/100], Step [45700/6235], Loss: 78.3920\n",
      "Epoch [63/100], Step [45800/6235], Loss: 469.0276\n",
      "Epoch [63/100], Step [45900/6235], Loss: 2.9840\n",
      "Epoch [63/100], Step [46000/6235], Loss: 59.1281\n",
      "Epoch [63/100], Step [46100/6235], Loss: 187.4937\n",
      "Epoch [63/100], Step [46200/6235], Loss: 195.1140\n",
      "Epoch [63/100], Step [46300/6235], Loss: 21.3426\n",
      "Epoch [63/100], Step [46400/6235], Loss: 2.9102\n",
      "Epoch [63/100], Step [46500/6235], Loss: 110.4984\n",
      "Epoch [63/100], Step [46600/6235], Loss: 24.3970\n",
      "Epoch [63/100], Step [46700/6235], Loss: 3.6559\n",
      "Epoch [63/100], Step [46800/6235], Loss: 34.9429\n",
      "Epoch [63/100], Step [46900/6235], Loss: 16.9127\n",
      "Epoch [63/100], Step [47000/6235], Loss: 0.7079\n",
      "Epoch [63/100], Step [47100/6235], Loss: 85.1594\n",
      "Epoch [63/100], Step [47200/6235], Loss: 80.7684\n",
      "Epoch [63/100], Step [47300/6235], Loss: 9.5138\n",
      "Epoch [63/100], Step [47400/6235], Loss: 552.0016\n",
      "Epoch [63/100], Step [47500/6235], Loss: 39.1328\n",
      "Epoch [63/100], Step [47600/6235], Loss: 3.0865\n",
      "Epoch [63/100], Step [47700/6235], Loss: 50.6767\n",
      "Epoch [63/100], Step [47800/6235], Loss: 4.2675\n",
      "Epoch [63/100], Step [47900/6235], Loss: 24.8600\n",
      "Epoch [63/100], Step [48000/6235], Loss: 117.7726\n",
      "Epoch [63/100], Step [48100/6235], Loss: 6.5686\n",
      "Epoch [63/100], Step [48200/6235], Loss: 89.0825\n",
      "Epoch [63/100], Step [48300/6235], Loss: 1051.7184\n",
      "Epoch [63/100], Step [48400/6235], Loss: 34.8784\n",
      "Epoch [63/100], Step [48500/6235], Loss: 10.1102\n",
      "Epoch [63/100], Step [48600/6235], Loss: 37.0094\n",
      "Epoch [63/100], Step [48700/6235], Loss: 2.8499\n",
      "Epoch [63/100], Step [48800/6235], Loss: 561.4545\n",
      "Epoch [63/100], Step [48900/6235], Loss: 14.4236\n",
      "Epoch [63/100], Step [49000/6235], Loss: 234.7258\n",
      "Epoch [63/100], Step [49100/6235], Loss: 552.2440\n",
      "Epoch [63/100], Step [49200/6235], Loss: 326.7163\n",
      "Epoch [63/100], Step [49300/6235], Loss: 539.2781\n",
      "Epoch [63/100], Step [49400/6235], Loss: 3.3946\n",
      "Epoch [63/100], Step [49500/6235], Loss: 27.8408\n",
      "Epoch [63/100], Step [49600/6235], Loss: 381.5562\n",
      "Epoch [63/100], Step [49700/6235], Loss: 1928.1962\n",
      "Epoch [63/100], Step [49800/6235], Loss: 909.9000\n",
      "Epoch [64/100], Step [100/6235], Loss: 28.9287\n",
      "Epoch [64/100], Step [200/6235], Loss: 0.2174\n",
      "Epoch [64/100], Step [300/6235], Loss: 0.0097\n",
      "Epoch [64/100], Step [400/6235], Loss: 0.0010\n",
      "Epoch [64/100], Step [500/6235], Loss: 1.7661\n",
      "Epoch [64/100], Step [600/6235], Loss: 0.0258\n",
      "Epoch [64/100], Step [700/6235], Loss: 0.6144\n",
      "Epoch [64/100], Step [800/6235], Loss: 0.0271\n",
      "Epoch [64/100], Step [900/6235], Loss: 0.0689\n",
      "Epoch [64/100], Step [1000/6235], Loss: 0.0229\n",
      "Epoch [64/100], Step [1100/6235], Loss: 0.0572\n",
      "Epoch [64/100], Step [1200/6235], Loss: 0.1584\n",
      "Epoch [64/100], Step [1300/6235], Loss: 0.0017\n",
      "Epoch [64/100], Step [1400/6235], Loss: 0.0756\n",
      "Epoch [64/100], Step [1500/6235], Loss: 0.0066\n",
      "Epoch [64/100], Step [1600/6235], Loss: 0.2343\n",
      "Epoch [64/100], Step [1700/6235], Loss: 0.2081\n",
      "Epoch [64/100], Step [1800/6235], Loss: 0.2714\n",
      "Epoch [64/100], Step [1900/6235], Loss: 0.2811\n",
      "Epoch [64/100], Step [2000/6235], Loss: 2.0953\n",
      "Epoch [64/100], Step [2100/6235], Loss: 2.5890\n",
      "Epoch [64/100], Step [2200/6235], Loss: 4.9446\n",
      "Epoch [64/100], Step [2300/6235], Loss: 0.8860\n",
      "Epoch [64/100], Step [2400/6235], Loss: 1.5175\n",
      "Epoch [64/100], Step [2500/6235], Loss: 13.5298\n",
      "Epoch [64/100], Step [2600/6235], Loss: 15.2392\n",
      "Epoch [64/100], Step [2700/6235], Loss: 8.1664\n",
      "Epoch [64/100], Step [2800/6235], Loss: 27.8421\n",
      "Epoch [64/100], Step [2900/6235], Loss: 11.8182\n",
      "Epoch [64/100], Step [3000/6235], Loss: 0.0296\n",
      "Epoch [64/100], Step [3100/6235], Loss: 78.3332\n",
      "Epoch [64/100], Step [3200/6235], Loss: 24.9948\n",
      "Epoch [64/100], Step [3300/6235], Loss: 4.1031\n",
      "Epoch [64/100], Step [3400/6235], Loss: 6.4714\n",
      "Epoch [64/100], Step [3500/6235], Loss: 57.2619\n",
      "Epoch [64/100], Step [3600/6235], Loss: 0.2009\n",
      "Epoch [64/100], Step [3700/6235], Loss: 0.1439\n",
      "Epoch [64/100], Step [3800/6235], Loss: 0.1495\n",
      "Epoch [64/100], Step [3900/6235], Loss: 0.1174\n",
      "Epoch [64/100], Step [4000/6235], Loss: 0.1810\n",
      "Epoch [64/100], Step [4100/6235], Loss: 9.5417\n",
      "Epoch [64/100], Step [4200/6235], Loss: 5.6194\n",
      "Epoch [64/100], Step [4300/6235], Loss: 5.0392\n",
      "Epoch [64/100], Step [4400/6235], Loss: 0.2391\n",
      "Epoch [64/100], Step [4500/6235], Loss: 43.3952\n",
      "Epoch [64/100], Step [4600/6235], Loss: 5.1367\n",
      "Epoch [64/100], Step [4700/6235], Loss: 0.1198\n",
      "Epoch [64/100], Step [4800/6235], Loss: 4.0144\n",
      "Epoch [64/100], Step [4900/6235], Loss: 4.3883\n",
      "Epoch [64/100], Step [5000/6235], Loss: 0.1570\n",
      "Epoch [64/100], Step [5100/6235], Loss: 0.8122\n",
      "Epoch [64/100], Step [5200/6235], Loss: 5.8334\n",
      "Epoch [64/100], Step [5300/6235], Loss: 12.6099\n",
      "Epoch [64/100], Step [5400/6235], Loss: 2.3976\n",
      "Epoch [64/100], Step [5500/6235], Loss: 0.0558\n",
      "Epoch [64/100], Step [5600/6235], Loss: 0.1561\n",
      "Epoch [64/100], Step [5700/6235], Loss: 0.0025\n",
      "Epoch [64/100], Step [5800/6235], Loss: 0.2396\n",
      "Epoch [64/100], Step [5900/6235], Loss: 0.0257\n",
      "Epoch [64/100], Step [6000/6235], Loss: 1.6408\n",
      "Epoch [64/100], Step [6100/6235], Loss: 0.1156\n",
      "Epoch [64/100], Step [6200/6235], Loss: 7.5425\n",
      "Epoch [64/100], Step [6300/6235], Loss: 0.9631\n",
      "Epoch [64/100], Step [6400/6235], Loss: 0.0095\n",
      "Epoch [64/100], Step [6500/6235], Loss: 0.3368\n",
      "Epoch [64/100], Step [6600/6235], Loss: 7.0692\n",
      "Epoch [64/100], Step [6700/6235], Loss: 1.4355\n",
      "Epoch [64/100], Step [6800/6235], Loss: 0.4267\n",
      "Epoch [64/100], Step [6900/6235], Loss: 0.5559\n",
      "Epoch [64/100], Step [7000/6235], Loss: 0.0074\n",
      "Epoch [64/100], Step [7100/6235], Loss: 0.4214\n",
      "Epoch [64/100], Step [7200/6235], Loss: 1.1285\n",
      "Epoch [64/100], Step [7300/6235], Loss: 0.6191\n",
      "Epoch [64/100], Step [7400/6235], Loss: 0.0627\n",
      "Epoch [64/100], Step [7500/6235], Loss: 0.9409\n",
      "Epoch [64/100], Step [7600/6235], Loss: 5.3308\n",
      "Epoch [64/100], Step [7700/6235], Loss: 8.0518\n",
      "Epoch [64/100], Step [7800/6235], Loss: 2.2348\n",
      "Epoch [64/100], Step [7900/6235], Loss: 5.0986\n",
      "Epoch [64/100], Step [8000/6235], Loss: 0.5962\n",
      "Epoch [64/100], Step [8100/6235], Loss: 0.4042\n",
      "Epoch [64/100], Step [8200/6235], Loss: 10.2547\n",
      "Epoch [64/100], Step [8300/6235], Loss: 18.2775\n",
      "Epoch [64/100], Step [8400/6235], Loss: 639.3552\n",
      "Epoch [64/100], Step [8500/6235], Loss: 18.6281\n",
      "Epoch [64/100], Step [8600/6235], Loss: 19.7027\n",
      "Epoch [64/100], Step [8700/6235], Loss: 35.9702\n",
      "Epoch [64/100], Step [8800/6235], Loss: 555.5417\n",
      "Epoch [64/100], Step [8900/6235], Loss: 401.9957\n",
      "Epoch [64/100], Step [9000/6235], Loss: 308.9865\n",
      "Epoch [64/100], Step [9100/6235], Loss: 2694.1233\n",
      "Epoch [64/100], Step [9200/6235], Loss: 3574.9514\n",
      "Epoch [64/100], Step [9300/6235], Loss: 244.6554\n",
      "Epoch [64/100], Step [9400/6235], Loss: 156.7424\n",
      "Epoch [64/100], Step [9500/6235], Loss: 1510.1375\n",
      "Epoch [64/100], Step [9600/6235], Loss: 977.4260\n",
      "Epoch [64/100], Step [9700/6235], Loss: 0.5440\n",
      "Epoch [64/100], Step [9800/6235], Loss: 207.6539\n",
      "Epoch [64/100], Step [9900/6235], Loss: 18.7240\n",
      "Epoch [64/100], Step [10000/6235], Loss: 11.2062\n",
      "Epoch [64/100], Step [10100/6235], Loss: 1.4775\n",
      "Epoch [64/100], Step [10200/6235], Loss: 1158.4950\n",
      "Epoch [64/100], Step [10300/6235], Loss: 17.6713\n",
      "Epoch [64/100], Step [10400/6235], Loss: 9.9149\n",
      "Epoch [64/100], Step [10500/6235], Loss: 195.5466\n",
      "Epoch [64/100], Step [10600/6235], Loss: 592.1122\n",
      "Epoch [64/100], Step [10700/6235], Loss: 28.7883\n",
      "Epoch [64/100], Step [10800/6235], Loss: 40.5743\n",
      "Epoch [64/100], Step [10900/6235], Loss: 127.7887\n",
      "Epoch [64/100], Step [11000/6235], Loss: 295.9200\n",
      "Epoch [64/100], Step [11100/6235], Loss: 11.2733\n",
      "Epoch [64/100], Step [11200/6235], Loss: 0.8738\n",
      "Epoch [64/100], Step [11300/6235], Loss: 96.5073\n",
      "Epoch [64/100], Step [11400/6235], Loss: 27.0782\n",
      "Epoch [64/100], Step [11500/6235], Loss: 11.9568\n",
      "Epoch [64/100], Step [11600/6235], Loss: 8.9882\n",
      "Epoch [64/100], Step [11700/6235], Loss: 49.7246\n",
      "Epoch [64/100], Step [11800/6235], Loss: 409.0866\n",
      "Epoch [64/100], Step [11900/6235], Loss: 64.5476\n",
      "Epoch [64/100], Step [12000/6235], Loss: 707.3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Step [12100/6235], Loss: 285.2706\n",
      "Epoch [64/100], Step [12200/6235], Loss: 41.4727\n",
      "Epoch [64/100], Step [12300/6235], Loss: 3.4347\n",
      "Epoch [64/100], Step [12400/6235], Loss: 373.8104\n",
      "Epoch [64/100], Step [12500/6235], Loss: 96.2641\n",
      "Epoch [64/100], Step [12600/6235], Loss: 3.4092\n",
      "Epoch [64/100], Step [12700/6235], Loss: 7.9146\n",
      "Epoch [64/100], Step [12800/6235], Loss: 10.4049\n",
      "Epoch [64/100], Step [12900/6235], Loss: 34.2768\n",
      "Epoch [64/100], Step [13000/6235], Loss: 0.1774\n",
      "Epoch [64/100], Step [13100/6235], Loss: 63.0376\n",
      "Epoch [64/100], Step [13200/6235], Loss: 7.8448\n",
      "Epoch [64/100], Step [13300/6235], Loss: 22.6770\n",
      "Epoch [64/100], Step [13400/6235], Loss: 225.9035\n",
      "Epoch [64/100], Step [13500/6235], Loss: 2.9306\n",
      "Epoch [64/100], Step [13600/6235], Loss: 1.0138\n",
      "Epoch [64/100], Step [13700/6235], Loss: 39.5499\n",
      "Epoch [64/100], Step [13800/6235], Loss: 140.0004\n",
      "Epoch [64/100], Step [13900/6235], Loss: 60.1604\n",
      "Epoch [64/100], Step [14000/6235], Loss: 15.1063\n",
      "Epoch [64/100], Step [14100/6235], Loss: 7.3113\n",
      "Epoch [64/100], Step [14200/6235], Loss: 20.6307\n",
      "Epoch [64/100], Step [14300/6235], Loss: 1.5419\n",
      "Epoch [64/100], Step [14400/6235], Loss: 33.3074\n",
      "Epoch [64/100], Step [14500/6235], Loss: 25.0884\n",
      "Epoch [64/100], Step [14600/6235], Loss: 0.4790\n",
      "Epoch [64/100], Step [14700/6235], Loss: 39.8318\n",
      "Epoch [64/100], Step [14800/6235], Loss: 33.8878\n",
      "Epoch [64/100], Step [14900/6235], Loss: 0.7022\n",
      "Epoch [64/100], Step [15000/6235], Loss: 1.6207\n",
      "Epoch [64/100], Step [15100/6235], Loss: 0.5572\n",
      "Epoch [64/100], Step [15200/6235], Loss: 11.1140\n",
      "Epoch [64/100], Step [15300/6235], Loss: 30.3969\n",
      "Epoch [64/100], Step [15400/6235], Loss: 101.9378\n",
      "Epoch [64/100], Step [15500/6235], Loss: 16.5652\n",
      "Epoch [64/100], Step [15600/6235], Loss: 168.5609\n",
      "Epoch [64/100], Step [15700/6235], Loss: 133.2635\n",
      "Epoch [64/100], Step [15800/6235], Loss: 8.1945\n",
      "Epoch [64/100], Step [15900/6235], Loss: 1.1593\n",
      "Epoch [64/100], Step [16000/6235], Loss: 94.4345\n",
      "Epoch [64/100], Step [16100/6235], Loss: 1.7555\n",
      "Epoch [64/100], Step [16200/6235], Loss: 0.3534\n",
      "Epoch [64/100], Step [16300/6235], Loss: 8.4215\n",
      "Epoch [64/100], Step [16400/6235], Loss: 24.1927\n",
      "Epoch [64/100], Step [16500/6235], Loss: 131.6958\n",
      "Epoch [64/100], Step [16600/6235], Loss: 15.3991\n",
      "Epoch [64/100], Step [16700/6235], Loss: 0.5442\n",
      "Epoch [64/100], Step [16800/6235], Loss: 11.2614\n",
      "Epoch [64/100], Step [16900/6235], Loss: 0.2029\n",
      "Epoch [64/100], Step [17000/6235], Loss: 0.2125\n",
      "Epoch [64/100], Step [17100/6235], Loss: 0.1432\n",
      "Epoch [64/100], Step [17200/6235], Loss: 266.7195\n",
      "Epoch [64/100], Step [17300/6235], Loss: 10.0410\n",
      "Epoch [64/100], Step [17400/6235], Loss: 56.4130\n",
      "Epoch [64/100], Step [17500/6235], Loss: 1.2886\n",
      "Epoch [64/100], Step [17600/6235], Loss: 2.5476\n",
      "Epoch [64/100], Step [17700/6235], Loss: 127.1987\n",
      "Epoch [64/100], Step [17800/6235], Loss: 24.5858\n",
      "Epoch [64/100], Step [17900/6235], Loss: 4.3130\n",
      "Epoch [64/100], Step [18000/6235], Loss: 0.9480\n",
      "Epoch [64/100], Step [18100/6235], Loss: 15.8362\n",
      "Epoch [64/100], Step [18200/6235], Loss: 0.8435\n",
      "Epoch [64/100], Step [18300/6235], Loss: 5.1680\n",
      "Epoch [64/100], Step [18400/6235], Loss: 3.0566\n",
      "Epoch [64/100], Step [18500/6235], Loss: 14.2294\n",
      "Epoch [64/100], Step [18600/6235], Loss: 1.7248\n",
      "Epoch [64/100], Step [18700/6235], Loss: 0.5101\n",
      "Epoch [64/100], Step [18800/6235], Loss: 96.5327\n",
      "Epoch [64/100], Step [18900/6235], Loss: 42.3665\n",
      "Epoch [64/100], Step [19000/6235], Loss: 1.0795\n",
      "Epoch [64/100], Step [19100/6235], Loss: 2.6752\n",
      "Epoch [64/100], Step [19200/6235], Loss: 2.6017\n",
      "Epoch [64/100], Step [19300/6235], Loss: 1.8103\n",
      "Epoch [64/100], Step [19400/6235], Loss: 136.6318\n",
      "Epoch [64/100], Step [19500/6235], Loss: 117.9740\n",
      "Epoch [64/100], Step [19600/6235], Loss: 90.2985\n",
      "Epoch [64/100], Step [19700/6235], Loss: 2.2034\n",
      "Epoch [64/100], Step [19800/6235], Loss: 1.4978\n",
      "Epoch [64/100], Step [19900/6235], Loss: 0.5492\n",
      "Epoch [64/100], Step [20000/6235], Loss: 87.0442\n",
      "Epoch [64/100], Step [20100/6235], Loss: 0.0684\n",
      "Epoch [64/100], Step [20200/6235], Loss: 8.6614\n",
      "Epoch [64/100], Step [20300/6235], Loss: 2.0356\n",
      "Epoch [64/100], Step [20400/6235], Loss: 16.4617\n",
      "Epoch [64/100], Step [20500/6235], Loss: 44.6063\n",
      "Epoch [64/100], Step [20600/6235], Loss: 27.2227\n",
      "Epoch [64/100], Step [20700/6235], Loss: 13.0247\n",
      "Epoch [64/100], Step [20800/6235], Loss: 0.9337\n",
      "Epoch [64/100], Step [20900/6235], Loss: 22.6683\n",
      "Epoch [64/100], Step [21000/6235], Loss: 14.9768\n",
      "Epoch [64/100], Step [21100/6235], Loss: 4.0760\n",
      "Epoch [64/100], Step [21200/6235], Loss: 0.1450\n",
      "Epoch [64/100], Step [21300/6235], Loss: 0.1818\n",
      "Epoch [64/100], Step [21400/6235], Loss: 5.9354\n",
      "Epoch [64/100], Step [21500/6235], Loss: 0.4241\n",
      "Epoch [64/100], Step [21600/6235], Loss: 28.2138\n",
      "Epoch [64/100], Step [21700/6235], Loss: 0.2567\n",
      "Epoch [64/100], Step [21800/6235], Loss: 0.1430\n",
      "Epoch [64/100], Step [21900/6235], Loss: 1.0123\n",
      "Epoch [64/100], Step [22000/6235], Loss: 6.2240\n",
      "Epoch [64/100], Step [22100/6235], Loss: 1.1192\n",
      "Epoch [64/100], Step [22200/6235], Loss: 7.3261\n",
      "Epoch [64/100], Step [22300/6235], Loss: 11.7437\n",
      "Epoch [64/100], Step [22400/6235], Loss: 2.8280\n",
      "Epoch [64/100], Step [22500/6235], Loss: 143.8934\n",
      "Epoch [64/100], Step [22600/6235], Loss: 14.7163\n",
      "Epoch [64/100], Step [22700/6235], Loss: 3.0323\n",
      "Epoch [64/100], Step [22800/6235], Loss: 3.8754\n",
      "Epoch [64/100], Step [22900/6235], Loss: 2.3067\n",
      "Epoch [64/100], Step [23000/6235], Loss: 9.6329\n",
      "Epoch [64/100], Step [23100/6235], Loss: 1.2500\n",
      "Epoch [64/100], Step [23200/6235], Loss: 6.5929\n",
      "Epoch [64/100], Step [23300/6235], Loss: 7.6479\n",
      "Epoch [64/100], Step [23400/6235], Loss: 2.1356\n",
      "Epoch [64/100], Step [23500/6235], Loss: 0.0566\n",
      "Epoch [64/100], Step [23600/6235], Loss: 120.5366\n",
      "Epoch [64/100], Step [23700/6235], Loss: 3.9116\n",
      "Epoch [64/100], Step [23800/6235], Loss: 0.9986\n",
      "Epoch [64/100], Step [23900/6235], Loss: 6.8443\n",
      "Epoch [64/100], Step [24000/6235], Loss: 0.2979\n",
      "Epoch [64/100], Step [24100/6235], Loss: 1.3149\n",
      "Epoch [64/100], Step [24200/6235], Loss: 43.2102\n",
      "Epoch [64/100], Step [24300/6235], Loss: 1.3790\n",
      "Epoch [64/100], Step [24400/6235], Loss: 4.8149\n",
      "Epoch [64/100], Step [24500/6235], Loss: 2.5169\n",
      "Epoch [64/100], Step [24600/6235], Loss: 0.1573\n",
      "Epoch [64/100], Step [24700/6235], Loss: 4.9172\n",
      "Epoch [64/100], Step [24800/6235], Loss: 0.0774\n",
      "Epoch [64/100], Step [24900/6235], Loss: 0.3648\n",
      "Epoch [64/100], Step [25000/6235], Loss: 16.8260\n",
      "Epoch [64/100], Step [25100/6235], Loss: 9.0092\n",
      "Epoch [64/100], Step [25200/6235], Loss: 1.4122\n",
      "Epoch [64/100], Step [25300/6235], Loss: 0.6426\n",
      "Epoch [64/100], Step [25400/6235], Loss: 9.5101\n",
      "Epoch [64/100], Step [25500/6235], Loss: 6.7524\n",
      "Epoch [64/100], Step [25600/6235], Loss: 3.4835\n",
      "Epoch [64/100], Step [25700/6235], Loss: 0.3322\n",
      "Epoch [64/100], Step [25800/6235], Loss: 0.1945\n",
      "Epoch [64/100], Step [25900/6235], Loss: 9.0025\n",
      "Epoch [64/100], Step [26000/6235], Loss: 0.4688\n",
      "Epoch [64/100], Step [26100/6235], Loss: 0.0832\n",
      "Epoch [64/100], Step [26200/6235], Loss: 0.2414\n",
      "Epoch [64/100], Step [26300/6235], Loss: 1.9531\n",
      "Epoch [64/100], Step [26400/6235], Loss: 0.1027\n",
      "Epoch [64/100], Step [26500/6235], Loss: 0.1903\n",
      "Epoch [64/100], Step [26600/6235], Loss: 2.9984\n",
      "Epoch [64/100], Step [26700/6235], Loss: 0.6171\n",
      "Epoch [64/100], Step [26800/6235], Loss: 0.6428\n",
      "Epoch [64/100], Step [26900/6235], Loss: 0.0319\n",
      "Epoch [64/100], Step [27000/6235], Loss: 13.2038\n",
      "Epoch [64/100], Step [27100/6235], Loss: 0.1095\n",
      "Epoch [64/100], Step [27200/6235], Loss: 0.0445\n",
      "Epoch [64/100], Step [27300/6235], Loss: 0.2284\n",
      "Epoch [64/100], Step [27400/6235], Loss: 0.8941\n",
      "Epoch [64/100], Step [27500/6235], Loss: 24.2474\n",
      "Epoch [64/100], Step [27600/6235], Loss: 0.0326\n",
      "Epoch [64/100], Step [27700/6235], Loss: 1.5709\n",
      "Epoch [64/100], Step [27800/6235], Loss: 5.8305\n",
      "Epoch [64/100], Step [27900/6235], Loss: 0.1659\n",
      "Epoch [64/100], Step [28000/6235], Loss: 195.3631\n",
      "Epoch [64/100], Step [28100/6235], Loss: 1.8555\n",
      "Epoch [64/100], Step [28200/6235], Loss: 34.9248\n",
      "Epoch [64/100], Step [28300/6235], Loss: 3.2778\n",
      "Epoch [64/100], Step [28400/6235], Loss: 23.9816\n",
      "Epoch [64/100], Step [28500/6235], Loss: 3.9495\n",
      "Epoch [64/100], Step [28600/6235], Loss: 0.6798\n",
      "Epoch [64/100], Step [28700/6235], Loss: 4.4809\n",
      "Epoch [64/100], Step [28800/6235], Loss: 0.3680\n",
      "Epoch [64/100], Step [28900/6235], Loss: 68.3853\n",
      "Epoch [64/100], Step [29000/6235], Loss: 10.1966\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Step [29100/6235], Loss: 0.0295\n",
      "Epoch [64/100], Step [29200/6235], Loss: 0.2105\n",
      "Epoch [64/100], Step [29300/6235], Loss: 8.1409\n",
      "Epoch [64/100], Step [29400/6235], Loss: 0.0769\n",
      "Epoch [64/100], Step [29500/6235], Loss: 2.6008\n",
      "Epoch [64/100], Step [29600/6235], Loss: 0.3115\n",
      "Epoch [64/100], Step [29700/6235], Loss: 0.3214\n",
      "Epoch [64/100], Step [29800/6235], Loss: 1.7050\n",
      "Epoch [64/100], Step [29900/6235], Loss: 0.1651\n",
      "Epoch [64/100], Step [30000/6235], Loss: 3.6668\n",
      "Epoch [64/100], Step [30100/6235], Loss: 0.0838\n",
      "Epoch [64/100], Step [30200/6235], Loss: 0.0615\n",
      "Epoch [64/100], Step [30300/6235], Loss: 1.0669\n",
      "Epoch [64/100], Step [30400/6235], Loss: 0.1850\n",
      "Epoch [64/100], Step [30500/6235], Loss: 1.6852\n",
      "Epoch [64/100], Step [30600/6235], Loss: 0.3973\n",
      "Epoch [64/100], Step [30700/6235], Loss: 0.2213\n",
      "Epoch [64/100], Step [30800/6235], Loss: 0.2236\n",
      "Epoch [64/100], Step [30900/6235], Loss: 2.4641\n",
      "Epoch [64/100], Step [31000/6235], Loss: 0.0602\n",
      "Epoch [64/100], Step [31100/6235], Loss: 0.1055\n",
      "Epoch [64/100], Step [31200/6235], Loss: 6.0052\n",
      "Epoch [64/100], Step [31300/6235], Loss: 1.3514\n",
      "Epoch [64/100], Step [31400/6235], Loss: 0.4777\n",
      "Epoch [64/100], Step [31500/6235], Loss: 0.4808\n",
      "Epoch [64/100], Step [31600/6235], Loss: 0.1707\n",
      "Epoch [64/100], Step [31700/6235], Loss: 15.9444\n",
      "Epoch [64/100], Step [31800/6235], Loss: 0.4755\n",
      "Epoch [64/100], Step [31900/6235], Loss: 307.0598\n",
      "Epoch [64/100], Step [32000/6235], Loss: 10.1822\n",
      "Epoch [64/100], Step [32100/6235], Loss: 1.7411\n",
      "Epoch [64/100], Step [32200/6235], Loss: 41.3215\n",
      "Epoch [64/100], Step [32300/6235], Loss: 1.1157\n",
      "Epoch [64/100], Step [32400/6235], Loss: 0.3722\n",
      "Epoch [64/100], Step [32500/6235], Loss: 21.9613\n",
      "Epoch [64/100], Step [32600/6235], Loss: 0.8828\n",
      "Epoch [64/100], Step [32700/6235], Loss: 51.1224\n",
      "Epoch [64/100], Step [32800/6235], Loss: 0.3009\n",
      "Epoch [64/100], Step [32900/6235], Loss: 11.6361\n",
      "Epoch [64/100], Step [33000/6235], Loss: 0.2536\n",
      "Epoch [64/100], Step [33100/6235], Loss: 1.5599\n",
      "Epoch [64/100], Step [33200/6235], Loss: 1.1158\n",
      "Epoch [64/100], Step [33300/6235], Loss: 4.4001\n",
      "Epoch [64/100], Step [33400/6235], Loss: 157.0096\n",
      "Epoch [64/100], Step [33500/6235], Loss: 2.0518\n",
      "Epoch [64/100], Step [33600/6235], Loss: 3.0588\n",
      "Epoch [64/100], Step [33700/6235], Loss: 1.2539\n",
      "Epoch [64/100], Step [33800/6235], Loss: 1.6455\n",
      "Epoch [64/100], Step [33900/6235], Loss: 23.0183\n",
      "Epoch [64/100], Step [34000/6235], Loss: 0.0895\n",
      "Epoch [64/100], Step [34100/6235], Loss: 0.0727\n",
      "Epoch [64/100], Step [34200/6235], Loss: 2.6808\n",
      "Epoch [64/100], Step [34300/6235], Loss: 7.6179\n",
      "Epoch [64/100], Step [34400/6235], Loss: 0.4891\n",
      "Epoch [64/100], Step [34500/6235], Loss: 86.8082\n",
      "Epoch [64/100], Step [34600/6235], Loss: 1.1306\n",
      "Epoch [64/100], Step [34700/6235], Loss: 1.6308\n",
      "Epoch [64/100], Step [34800/6235], Loss: 15.7471\n",
      "Epoch [64/100], Step [34900/6235], Loss: 65.3934\n",
      "Epoch [64/100], Step [35000/6235], Loss: 1.7375\n",
      "Epoch [64/100], Step [35100/6235], Loss: 1.0907\n",
      "Epoch [64/100], Step [35200/6235], Loss: 3.0017\n",
      "Epoch [64/100], Step [35300/6235], Loss: 0.0038\n",
      "Epoch [64/100], Step [35400/6235], Loss: 1.0709\n",
      "Epoch [64/100], Step [35500/6235], Loss: 1.9188\n",
      "Epoch [64/100], Step [35600/6235], Loss: 3.8217\n",
      "Epoch [64/100], Step [35700/6235], Loss: 5.5637\n",
      "Epoch [64/100], Step [35800/6235], Loss: 0.8345\n",
      "Epoch [64/100], Step [35900/6235], Loss: 0.2012\n",
      "Epoch [64/100], Step [36000/6235], Loss: 1.9372\n",
      "Epoch [64/100], Step [36100/6235], Loss: 0.2168\n",
      "Epoch [64/100], Step [36200/6235], Loss: 20.6476\n",
      "Epoch [64/100], Step [36300/6235], Loss: 0.2845\n",
      "Epoch [64/100], Step [36400/6235], Loss: 0.3151\n",
      "Epoch [64/100], Step [36500/6235], Loss: 10.0550\n",
      "Epoch [64/100], Step [36600/6235], Loss: 0.0363\n",
      "Epoch [64/100], Step [36700/6235], Loss: 0.2541\n",
      "Epoch [64/100], Step [36800/6235], Loss: 31.6278\n",
      "Epoch [64/100], Step [36900/6235], Loss: 3.2231\n",
      "Epoch [64/100], Step [37000/6235], Loss: 0.2033\n",
      "Epoch [64/100], Step [37100/6235], Loss: 0.0188\n",
      "Epoch [64/100], Step [37200/6235], Loss: 0.0349\n",
      "Epoch [64/100], Step [37300/6235], Loss: 0.4411\n",
      "Epoch [64/100], Step [37400/6235], Loss: 0.2118\n",
      "Epoch [64/100], Step [37500/6235], Loss: 2.6031\n",
      "Epoch [64/100], Step [37600/6235], Loss: 9.4191\n",
      "Epoch [64/100], Step [37700/6235], Loss: 0.0215\n",
      "Epoch [64/100], Step [37800/6235], Loss: 9.6747\n",
      "Epoch [64/100], Step [37900/6235], Loss: 7.2787\n",
      "Epoch [64/100], Step [38000/6235], Loss: 0.0762\n",
      "Epoch [64/100], Step [38100/6235], Loss: 2.8694\n",
      "Epoch [64/100], Step [38200/6235], Loss: 2.1424\n",
      "Epoch [64/100], Step [38300/6235], Loss: 0.5729\n",
      "Epoch [64/100], Step [38400/6235], Loss: 0.0841\n",
      "Epoch [64/100], Step [38500/6235], Loss: 4.9528\n",
      "Epoch [64/100], Step [38600/6235], Loss: 0.9704\n",
      "Epoch [64/100], Step [38700/6235], Loss: 0.2554\n",
      "Epoch [64/100], Step [38800/6235], Loss: 0.6103\n",
      "Epoch [64/100], Step [38900/6235], Loss: 10.6894\n",
      "Epoch [64/100], Step [39000/6235], Loss: 1.0748\n",
      "Epoch [64/100], Step [39100/6235], Loss: 10.9139\n",
      "Epoch [64/100], Step [39200/6235], Loss: 0.2873\n",
      "Epoch [64/100], Step [39300/6235], Loss: 61.1157\n",
      "Epoch [64/100], Step [39400/6235], Loss: 35.2138\n",
      "Epoch [64/100], Step [39500/6235], Loss: 359.0520\n",
      "Epoch [64/100], Step [39600/6235], Loss: 14.1259\n",
      "Epoch [64/100], Step [39700/6235], Loss: 159.9514\n",
      "Epoch [64/100], Step [39800/6235], Loss: 127.8641\n",
      "Epoch [64/100], Step [39900/6235], Loss: 11.3340\n",
      "Epoch [64/100], Step [40000/6235], Loss: 1.5523\n",
      "Epoch [64/100], Step [40100/6235], Loss: 5.1634\n",
      "Epoch [64/100], Step [40200/6235], Loss: 21.5309\n",
      "Epoch [64/100], Step [40300/6235], Loss: 1.1097\n",
      "Epoch [64/100], Step [40400/6235], Loss: 0.3843\n",
      "Epoch [64/100], Step [40500/6235], Loss: 3.4416\n",
      "Epoch [64/100], Step [40600/6235], Loss: 0.3981\n",
      "Epoch [64/100], Step [40700/6235], Loss: 4.8422\n",
      "Epoch [64/100], Step [40800/6235], Loss: 1.7721\n",
      "Epoch [64/100], Step [40900/6235], Loss: 1.3972\n",
      "Epoch [64/100], Step [41000/6235], Loss: 34.8119\n",
      "Epoch [64/100], Step [41100/6235], Loss: 24.2990\n",
      "Epoch [64/100], Step [41200/6235], Loss: 3.6330\n",
      "Epoch [64/100], Step [41300/6235], Loss: 2.6833\n",
      "Epoch [64/100], Step [41400/6235], Loss: 1.9193\n",
      "Epoch [64/100], Step [41500/6235], Loss: 4.7214\n",
      "Epoch [64/100], Step [41600/6235], Loss: 4.4509\n",
      "Epoch [64/100], Step [41700/6235], Loss: 0.1196\n",
      "Epoch [64/100], Step [41800/6235], Loss: 0.4617\n",
      "Epoch [64/100], Step [41900/6235], Loss: 3.8714\n",
      "Epoch [64/100], Step [42000/6235], Loss: 3.7041\n",
      "Epoch [64/100], Step [42100/6235], Loss: 12.1947\n",
      "Epoch [64/100], Step [42200/6235], Loss: 69.1356\n",
      "Epoch [64/100], Step [42300/6235], Loss: 0.0894\n",
      "Epoch [64/100], Step [42400/6235], Loss: 0.9421\n",
      "Epoch [64/100], Step [42500/6235], Loss: 1.5333\n",
      "Epoch [64/100], Step [42600/6235], Loss: 2.2437\n",
      "Epoch [64/100], Step [42700/6235], Loss: 0.4108\n",
      "Epoch [64/100], Step [42800/6235], Loss: 17.2105\n",
      "Epoch [64/100], Step [42900/6235], Loss: 0.1162\n",
      "Epoch [64/100], Step [43000/6235], Loss: 0.6168\n",
      "Epoch [64/100], Step [43100/6235], Loss: 0.0783\n",
      "Epoch [64/100], Step [43200/6235], Loss: 0.0169\n",
      "Epoch [64/100], Step [43300/6235], Loss: 3.7778\n",
      "Epoch [64/100], Step [43400/6235], Loss: 3.9645\n",
      "Epoch [64/100], Step [43500/6235], Loss: 12.5486\n",
      "Epoch [64/100], Step [43600/6235], Loss: 1.0363\n",
      "Epoch [64/100], Step [43700/6235], Loss: 46.2723\n",
      "Epoch [64/100], Step [43800/6235], Loss: 0.2760\n",
      "Epoch [64/100], Step [43900/6235], Loss: 2.1317\n",
      "Epoch [64/100], Step [44000/6235], Loss: 66.6519\n",
      "Epoch [64/100], Step [44100/6235], Loss: 1.5292\n",
      "Epoch [64/100], Step [44200/6235], Loss: 2.8487\n",
      "Epoch [64/100], Step [44300/6235], Loss: 74.9153\n",
      "Epoch [64/100], Step [44400/6235], Loss: 0.6387\n",
      "Epoch [64/100], Step [44500/6235], Loss: 0.5238\n",
      "Epoch [64/100], Step [44600/6235], Loss: 25.0147\n",
      "Epoch [64/100], Step [44700/6235], Loss: 2.1506\n",
      "Epoch [64/100], Step [44800/6235], Loss: 1.6435\n",
      "Epoch [64/100], Step [44900/6235], Loss: 11.6506\n",
      "Epoch [64/100], Step [45000/6235], Loss: 6.4450\n",
      "Epoch [64/100], Step [45100/6235], Loss: 54.5673\n",
      "Epoch [64/100], Step [45200/6235], Loss: 3.3060\n",
      "Epoch [64/100], Step [45300/6235], Loss: 25.0754\n",
      "Epoch [64/100], Step [45400/6235], Loss: 6.8318\n",
      "Epoch [64/100], Step [45500/6235], Loss: 2.2744\n",
      "Epoch [64/100], Step [45600/6235], Loss: 0.5535\n",
      "Epoch [64/100], Step [45700/6235], Loss: 63.0091\n",
      "Epoch [64/100], Step [45800/6235], Loss: 252.0006\n",
      "Epoch [64/100], Step [45900/6235], Loss: 0.7929\n",
      "Epoch [64/100], Step [46000/6235], Loss: 31.3278\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [64/100], Step [46100/6235], Loss: 143.7885\n",
      "Epoch [64/100], Step [46200/6235], Loss: 2.9003\n",
      "Epoch [64/100], Step [46300/6235], Loss: 180.0195\n",
      "Epoch [64/100], Step [46400/6235], Loss: 11.8975\n",
      "Epoch [64/100], Step [46500/6235], Loss: 21.7646\n",
      "Epoch [64/100], Step [46600/6235], Loss: 10.5306\n",
      "Epoch [64/100], Step [46700/6235], Loss: 32.9424\n",
      "Epoch [64/100], Step [46800/6235], Loss: 30.6045\n",
      "Epoch [64/100], Step [46900/6235], Loss: 9.7154\n",
      "Epoch [64/100], Step [47000/6235], Loss: 3.8474\n",
      "Epoch [64/100], Step [47100/6235], Loss: 26.6896\n",
      "Epoch [64/100], Step [47200/6235], Loss: 109.2144\n",
      "Epoch [64/100], Step [47300/6235], Loss: 2.1152\n",
      "Epoch [64/100], Step [47400/6235], Loss: 447.9012\n",
      "Epoch [64/100], Step [47500/6235], Loss: 5.7813\n",
      "Epoch [64/100], Step [47600/6235], Loss: 8.7871\n",
      "Epoch [64/100], Step [47700/6235], Loss: 13.5002\n",
      "Epoch [64/100], Step [47800/6235], Loss: 16.0321\n",
      "Epoch [64/100], Step [47900/6235], Loss: 16.7948\n",
      "Epoch [64/100], Step [48000/6235], Loss: 92.5423\n",
      "Epoch [64/100], Step [48100/6235], Loss: 10.3425\n",
      "Epoch [64/100], Step [48200/6235], Loss: 61.1682\n",
      "Epoch [64/100], Step [48300/6235], Loss: 390.1335\n",
      "Epoch [64/100], Step [48400/6235], Loss: 15.6826\n",
      "Epoch [64/100], Step [48500/6235], Loss: 39.2314\n",
      "Epoch [64/100], Step [48600/6235], Loss: 120.6370\n",
      "Epoch [64/100], Step [48700/6235], Loss: 0.3599\n",
      "Epoch [64/100], Step [48800/6235], Loss: 198.1108\n",
      "Epoch [64/100], Step [48900/6235], Loss: 49.7238\n",
      "Epoch [64/100], Step [49000/6235], Loss: 238.6852\n",
      "Epoch [64/100], Step [49100/6235], Loss: 1886.9042\n",
      "Epoch [64/100], Step [49200/6235], Loss: 889.0732\n",
      "Epoch [64/100], Step [49300/6235], Loss: 1262.4058\n",
      "Epoch [64/100], Step [49400/6235], Loss: 69.8103\n",
      "Epoch [64/100], Step [49500/6235], Loss: 3.8991\n",
      "Epoch [64/100], Step [49600/6235], Loss: 1532.6737\n",
      "Epoch [64/100], Step [49700/6235], Loss: 2757.6086\n",
      "Epoch [64/100], Step [49800/6235], Loss: 1023.1043\n",
      "Epoch [65/100], Step [100/6235], Loss: 33.0397\n",
      "Epoch [65/100], Step [200/6235], Loss: 0.2134\n",
      "Epoch [65/100], Step [300/6235], Loss: 0.0141\n",
      "Epoch [65/100], Step [400/6235], Loss: 0.0037\n",
      "Epoch [65/100], Step [500/6235], Loss: 10.4471\n",
      "Epoch [65/100], Step [600/6235], Loss: 0.0877\n",
      "Epoch [65/100], Step [700/6235], Loss: 0.7527\n",
      "Epoch [65/100], Step [800/6235], Loss: 0.0558\n",
      "Epoch [65/100], Step [900/6235], Loss: 0.0716\n",
      "Epoch [65/100], Step [1000/6235], Loss: 0.0379\n",
      "Epoch [65/100], Step [1100/6235], Loss: 0.1438\n",
      "Epoch [65/100], Step [1200/6235], Loss: 0.1663\n",
      "Epoch [65/100], Step [1300/6235], Loss: 0.0202\n",
      "Epoch [65/100], Step [1400/6235], Loss: 0.1362\n",
      "Epoch [65/100], Step [1500/6235], Loss: 0.0094\n",
      "Epoch [65/100], Step [1600/6235], Loss: 0.2392\n",
      "Epoch [65/100], Step [1700/6235], Loss: 0.1609\n",
      "Epoch [65/100], Step [1800/6235], Loss: 0.2497\n",
      "Epoch [65/100], Step [1900/6235], Loss: 0.2625\n",
      "Epoch [65/100], Step [2000/6235], Loss: 2.1891\n",
      "Epoch [65/100], Step [2100/6235], Loss: 2.5927\n",
      "Epoch [65/100], Step [2200/6235], Loss: 5.6079\n",
      "Epoch [65/100], Step [2300/6235], Loss: 0.1040\n",
      "Epoch [65/100], Step [2400/6235], Loss: 0.9032\n",
      "Epoch [65/100], Step [2500/6235], Loss: 21.5776\n",
      "Epoch [65/100], Step [2600/6235], Loss: 13.9624\n",
      "Epoch [65/100], Step [2700/6235], Loss: 13.4899\n",
      "Epoch [65/100], Step [2800/6235], Loss: 80.9466\n",
      "Epoch [65/100], Step [2900/6235], Loss: 17.6642\n",
      "Epoch [65/100], Step [3000/6235], Loss: 0.7792\n",
      "Epoch [65/100], Step [3100/6235], Loss: 64.2041\n",
      "Epoch [65/100], Step [3200/6235], Loss: 40.5927\n",
      "Epoch [65/100], Step [3300/6235], Loss: 10.4004\n",
      "Epoch [65/100], Step [3400/6235], Loss: 4.3211\n",
      "Epoch [65/100], Step [3500/6235], Loss: 55.1261\n",
      "Epoch [65/100], Step [3600/6235], Loss: 1.1602\n",
      "Epoch [65/100], Step [3700/6235], Loss: 0.1401\n",
      "Epoch [65/100], Step [3800/6235], Loss: 0.0724\n",
      "Epoch [65/100], Step [3900/6235], Loss: 0.1193\n",
      "Epoch [65/100], Step [4000/6235], Loss: 0.1366\n",
      "Epoch [65/100], Step [4100/6235], Loss: 10.0615\n",
      "Epoch [65/100], Step [4200/6235], Loss: 3.7292\n",
      "Epoch [65/100], Step [4300/6235], Loss: 5.9297\n",
      "Epoch [65/100], Step [4400/6235], Loss: 0.6004\n",
      "Epoch [65/100], Step [4500/6235], Loss: 38.0141\n",
      "Epoch [65/100], Step [4600/6235], Loss: 2.1321\n",
      "Epoch [65/100], Step [4700/6235], Loss: 0.1471\n",
      "Epoch [65/100], Step [4800/6235], Loss: 7.4114\n",
      "Epoch [65/100], Step [4900/6235], Loss: 1.4657\n",
      "Epoch [65/100], Step [5000/6235], Loss: 0.0587\n",
      "Epoch [65/100], Step [5100/6235], Loss: 0.4788\n",
      "Epoch [65/100], Step [5200/6235], Loss: 3.6551\n",
      "Epoch [65/100], Step [5300/6235], Loss: 25.6172\n",
      "Epoch [65/100], Step [5400/6235], Loss: 0.9181\n",
      "Epoch [65/100], Step [5500/6235], Loss: 0.1751\n",
      "Epoch [65/100], Step [5600/6235], Loss: 0.3059\n",
      "Epoch [65/100], Step [5700/6235], Loss: 0.1459\n",
      "Epoch [65/100], Step [5800/6235], Loss: 0.1719\n",
      "Epoch [65/100], Step [5900/6235], Loss: 0.2058\n",
      "Epoch [65/100], Step [6000/6235], Loss: 0.1165\n",
      "Epoch [65/100], Step [6100/6235], Loss: 0.5927\n",
      "Epoch [65/100], Step [6200/6235], Loss: 6.3943\n",
      "Epoch [65/100], Step [6300/6235], Loss: 0.1379\n",
      "Epoch [65/100], Step [6400/6235], Loss: 0.0089\n",
      "Epoch [65/100], Step [6500/6235], Loss: 2.4172\n",
      "Epoch [65/100], Step [6600/6235], Loss: 11.3625\n",
      "Epoch [65/100], Step [6700/6235], Loss: 0.9719\n",
      "Epoch [65/100], Step [6800/6235], Loss: 0.2301\n",
      "Epoch [65/100], Step [6900/6235], Loss: 0.2411\n",
      "Epoch [65/100], Step [7000/6235], Loss: 0.1684\n",
      "Epoch [65/100], Step [7100/6235], Loss: 0.3425\n",
      "Epoch [65/100], Step [7200/6235], Loss: 0.1035\n",
      "Epoch [65/100], Step [7300/6235], Loss: 0.2222\n",
      "Epoch [65/100], Step [7400/6235], Loss: 0.1484\n",
      "Epoch [65/100], Step [7500/6235], Loss: 0.7802\n",
      "Epoch [65/100], Step [7600/6235], Loss: 2.4809\n",
      "Epoch [65/100], Step [7700/6235], Loss: 14.6500\n",
      "Epoch [65/100], Step [7800/6235], Loss: 1.1959\n",
      "Epoch [65/100], Step [7900/6235], Loss: 3.5897\n",
      "Epoch [65/100], Step [8000/6235], Loss: 0.1124\n",
      "Epoch [65/100], Step [8100/6235], Loss: 3.2299\n",
      "Epoch [65/100], Step [8200/6235], Loss: 10.2807\n",
      "Epoch [65/100], Step [8300/6235], Loss: 14.6475\n",
      "Epoch [65/100], Step [8400/6235], Loss: 456.0632\n",
      "Epoch [65/100], Step [8500/6235], Loss: 2.7346\n",
      "Epoch [65/100], Step [8600/6235], Loss: 13.1456\n",
      "Epoch [65/100], Step [8700/6235], Loss: 24.6642\n",
      "Epoch [65/100], Step [8800/6235], Loss: 563.7006\n",
      "Epoch [65/100], Step [8900/6235], Loss: 169.5522\n",
      "Epoch [65/100], Step [9000/6235], Loss: 628.3531\n",
      "Epoch [65/100], Step [9100/6235], Loss: 2012.3115\n",
      "Epoch [65/100], Step [9200/6235], Loss: 3565.0698\n",
      "Epoch [65/100], Step [9300/6235], Loss: 83.7417\n",
      "Epoch [65/100], Step [9400/6235], Loss: 77.6460\n",
      "Epoch [65/100], Step [9500/6235], Loss: 961.2258\n",
      "Epoch [65/100], Step [9600/6235], Loss: 290.5238\n",
      "Epoch [65/100], Step [9700/6235], Loss: 0.4918\n",
      "Epoch [65/100], Step [9800/6235], Loss: 493.6305\n",
      "Epoch [65/100], Step [9900/6235], Loss: 30.5649\n",
      "Epoch [65/100], Step [10000/6235], Loss: 153.5762\n",
      "Epoch [65/100], Step [10100/6235], Loss: 1.9824\n",
      "Epoch [65/100], Step [10200/6235], Loss: 1251.1891\n",
      "Epoch [65/100], Step [10300/6235], Loss: 54.5201\n",
      "Epoch [65/100], Step [10400/6235], Loss: 10.6839\n",
      "Epoch [65/100], Step [10500/6235], Loss: 37.5121\n",
      "Epoch [65/100], Step [10600/6235], Loss: 33.7867\n",
      "Epoch [65/100], Step [10700/6235], Loss: 9.9791\n",
      "Epoch [65/100], Step [10800/6235], Loss: 123.3339\n",
      "Epoch [65/100], Step [10900/6235], Loss: 81.4835\n",
      "Epoch [65/100], Step [11000/6235], Loss: 293.9421\n",
      "Epoch [65/100], Step [11100/6235], Loss: 36.5002\n",
      "Epoch [65/100], Step [11200/6235], Loss: 4.2751\n",
      "Epoch [65/100], Step [11300/6235], Loss: 97.9222\n",
      "Epoch [65/100], Step [11400/6235], Loss: 57.9373\n",
      "Epoch [65/100], Step [11500/6235], Loss: 12.6084\n",
      "Epoch [65/100], Step [11600/6235], Loss: 9.2367\n",
      "Epoch [65/100], Step [11700/6235], Loss: 60.1526\n",
      "Epoch [65/100], Step [11800/6235], Loss: 227.3020\n",
      "Epoch [65/100], Step [11900/6235], Loss: 17.5622\n",
      "Epoch [65/100], Step [12000/6235], Loss: 694.0311\n",
      "Epoch [65/100], Step [12100/6235], Loss: 250.6712\n",
      "Epoch [65/100], Step [12200/6235], Loss: 3.6371\n",
      "Epoch [65/100], Step [12300/6235], Loss: 1.6806\n",
      "Epoch [65/100], Step [12400/6235], Loss: 214.5788\n",
      "Epoch [65/100], Step [12500/6235], Loss: 38.6301\n",
      "Epoch [65/100], Step [12600/6235], Loss: 19.0605\n",
      "Epoch [65/100], Step [12700/6235], Loss: 4.4575\n",
      "Epoch [65/100], Step [12800/6235], Loss: 7.7395\n",
      "Epoch [65/100], Step [12900/6235], Loss: 33.9221\n",
      "Epoch [65/100], Step [13000/6235], Loss: 0.3315\n",
      "Epoch [65/100], Step [13100/6235], Loss: 65.1250\n",
      "Epoch [65/100], Step [13200/6235], Loss: 8.3389\n",
      "Epoch [65/100], Step [13300/6235], Loss: 29.0591\n",
      "Epoch [65/100], Step [13400/6235], Loss: 239.2410\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Step [13500/6235], Loss: 1.0326\n",
      "Epoch [65/100], Step [13600/6235], Loss: 3.0070\n",
      "Epoch [65/100], Step [13700/6235], Loss: 139.4301\n",
      "Epoch [65/100], Step [13800/6235], Loss: 92.9877\n",
      "Epoch [65/100], Step [13900/6235], Loss: 23.6126\n",
      "Epoch [65/100], Step [14000/6235], Loss: 10.4879\n",
      "Epoch [65/100], Step [14100/6235], Loss: 35.9239\n",
      "Epoch [65/100], Step [14200/6235], Loss: 146.9132\n",
      "Epoch [65/100], Step [14300/6235], Loss: 40.0763\n",
      "Epoch [65/100], Step [14400/6235], Loss: 37.6122\n",
      "Epoch [65/100], Step [14500/6235], Loss: 27.0275\n",
      "Epoch [65/100], Step [14600/6235], Loss: 2.2166\n",
      "Epoch [65/100], Step [14700/6235], Loss: 26.6227\n",
      "Epoch [65/100], Step [14800/6235], Loss: 29.4989\n",
      "Epoch [65/100], Step [14900/6235], Loss: 0.7099\n",
      "Epoch [65/100], Step [15000/6235], Loss: 1.2169\n",
      "Epoch [65/100], Step [15100/6235], Loss: 0.4522\n",
      "Epoch [65/100], Step [15200/6235], Loss: 14.6922\n",
      "Epoch [65/100], Step [15300/6235], Loss: 42.5241\n",
      "Epoch [65/100], Step [15400/6235], Loss: 70.2304\n",
      "Epoch [65/100], Step [15500/6235], Loss: 9.7000\n",
      "Epoch [65/100], Step [15600/6235], Loss: 1.9811\n",
      "Epoch [65/100], Step [15700/6235], Loss: 59.5067\n",
      "Epoch [65/100], Step [15800/6235], Loss: 7.5634\n",
      "Epoch [65/100], Step [15900/6235], Loss: 0.4532\n",
      "Epoch [65/100], Step [16000/6235], Loss: 60.6092\n",
      "Epoch [65/100], Step [16100/6235], Loss: 5.0845\n",
      "Epoch [65/100], Step [16200/6235], Loss: 0.5304\n",
      "Epoch [65/100], Step [16300/6235], Loss: 9.4315\n",
      "Epoch [65/100], Step [16400/6235], Loss: 20.7000\n",
      "Epoch [65/100], Step [16500/6235], Loss: 622.9826\n",
      "Epoch [65/100], Step [16600/6235], Loss: 9.9561\n",
      "Epoch [65/100], Step [16700/6235], Loss: 0.6922\n",
      "Epoch [65/100], Step [16800/6235], Loss: 8.7990\n",
      "Epoch [65/100], Step [16900/6235], Loss: 0.1917\n",
      "Epoch [65/100], Step [17000/6235], Loss: 0.2113\n",
      "Epoch [65/100], Step [17100/6235], Loss: 0.1277\n",
      "Epoch [65/100], Step [17200/6235], Loss: 287.5956\n",
      "Epoch [65/100], Step [17300/6235], Loss: 63.9265\n",
      "Epoch [65/100], Step [17400/6235], Loss: 71.2791\n",
      "Epoch [65/100], Step [17500/6235], Loss: 0.7315\n",
      "Epoch [65/100], Step [17600/6235], Loss: 3.1420\n",
      "Epoch [65/100], Step [17700/6235], Loss: 3.1580\n",
      "Epoch [65/100], Step [17800/6235], Loss: 23.5552\n",
      "Epoch [65/100], Step [17900/6235], Loss: 9.7678\n",
      "Epoch [65/100], Step [18000/6235], Loss: 2.2356\n",
      "Epoch [65/100], Step [18100/6235], Loss: 12.1961\n",
      "Epoch [65/100], Step [18200/6235], Loss: 0.6039\n",
      "Epoch [65/100], Step [18300/6235], Loss: 4.2959\n",
      "Epoch [65/100], Step [18400/6235], Loss: 0.1230\n",
      "Epoch [65/100], Step [18500/6235], Loss: 18.1192\n",
      "Epoch [65/100], Step [18600/6235], Loss: 1.9224\n",
      "Epoch [65/100], Step [18700/6235], Loss: 0.5567\n",
      "Epoch [65/100], Step [18800/6235], Loss: 164.9950\n",
      "Epoch [65/100], Step [18900/6235], Loss: 18.5533\n",
      "Epoch [65/100], Step [19000/6235], Loss: 2.4641\n",
      "Epoch [65/100], Step [19100/6235], Loss: 43.9788\n",
      "Epoch [65/100], Step [19200/6235], Loss: 1.8564\n",
      "Epoch [65/100], Step [19300/6235], Loss: 8.3695\n",
      "Epoch [65/100], Step [19400/6235], Loss: 243.6333\n",
      "Epoch [65/100], Step [19500/6235], Loss: 194.6471\n",
      "Epoch [65/100], Step [19600/6235], Loss: 86.0218\n",
      "Epoch [65/100], Step [19700/6235], Loss: 6.0611\n",
      "Epoch [65/100], Step [19800/6235], Loss: 2.4208\n",
      "Epoch [65/100], Step [19900/6235], Loss: 0.1166\n",
      "Epoch [65/100], Step [20000/6235], Loss: 67.0672\n",
      "Epoch [65/100], Step [20100/6235], Loss: 0.0654\n",
      "Epoch [65/100], Step [20200/6235], Loss: 5.4436\n",
      "Epoch [65/100], Step [20300/6235], Loss: 2.5365\n",
      "Epoch [65/100], Step [20400/6235], Loss: 19.3028\n",
      "Epoch [65/100], Step [20500/6235], Loss: 42.7704\n",
      "Epoch [65/100], Step [20600/6235], Loss: 63.9064\n",
      "Epoch [65/100], Step [20700/6235], Loss: 10.9917\n",
      "Epoch [65/100], Step [20800/6235], Loss: 2.5453\n",
      "Epoch [65/100], Step [20900/6235], Loss: 32.8478\n",
      "Epoch [65/100], Step [21000/6235], Loss: 14.5681\n",
      "Epoch [65/100], Step [21100/6235], Loss: 4.3243\n",
      "Epoch [65/100], Step [21200/6235], Loss: 0.2185\n",
      "Epoch [65/100], Step [21300/6235], Loss: 0.2051\n",
      "Epoch [65/100], Step [21400/6235], Loss: 6.4501\n",
      "Epoch [65/100], Step [21500/6235], Loss: 0.3934\n",
      "Epoch [65/100], Step [21600/6235], Loss: 30.2691\n",
      "Epoch [65/100], Step [21700/6235], Loss: 0.2740\n",
      "Epoch [65/100], Step [21800/6235], Loss: 0.1678\n",
      "Epoch [65/100], Step [21900/6235], Loss: 0.3726\n",
      "Epoch [65/100], Step [22000/6235], Loss: 3.4293\n",
      "Epoch [65/100], Step [22100/6235], Loss: 3.7205\n",
      "Epoch [65/100], Step [22200/6235], Loss: 5.9997\n",
      "Epoch [65/100], Step [22300/6235], Loss: 0.6350\n",
      "Epoch [65/100], Step [22400/6235], Loss: 1.1978\n",
      "Epoch [65/100], Step [22500/6235], Loss: 126.5027\n",
      "Epoch [65/100], Step [22600/6235], Loss: 26.6456\n",
      "Epoch [65/100], Step [22700/6235], Loss: 2.2519\n",
      "Epoch [65/100], Step [22800/6235], Loss: 11.0580\n",
      "Epoch [65/100], Step [22900/6235], Loss: 3.2476\n",
      "Epoch [65/100], Step [23000/6235], Loss: 12.3347\n",
      "Epoch [65/100], Step [23100/6235], Loss: 5.8409\n",
      "Epoch [65/100], Step [23200/6235], Loss: 17.6022\n",
      "Epoch [65/100], Step [23300/6235], Loss: 15.9722\n",
      "Epoch [65/100], Step [23400/6235], Loss: 0.3584\n",
      "Epoch [65/100], Step [23500/6235], Loss: 0.3177\n",
      "Epoch [65/100], Step [23600/6235], Loss: 93.8955\n",
      "Epoch [65/100], Step [23700/6235], Loss: 7.9258\n",
      "Epoch [65/100], Step [23800/6235], Loss: 0.7014\n",
      "Epoch [65/100], Step [23900/6235], Loss: 7.7726\n",
      "Epoch [65/100], Step [24000/6235], Loss: 0.9210\n",
      "Epoch [65/100], Step [24100/6235], Loss: 2.4946\n",
      "Epoch [65/100], Step [24200/6235], Loss: 47.0792\n",
      "Epoch [65/100], Step [24300/6235], Loss: 2.0409\n",
      "Epoch [65/100], Step [24400/6235], Loss: 4.7167\n",
      "Epoch [65/100], Step [24500/6235], Loss: 2.8355\n",
      "Epoch [65/100], Step [24600/6235], Loss: 0.3545\n",
      "Epoch [65/100], Step [24700/6235], Loss: 17.3427\n",
      "Epoch [65/100], Step [24800/6235], Loss: 0.0711\n",
      "Epoch [65/100], Step [24900/6235], Loss: 16.7131\n",
      "Epoch [65/100], Step [25000/6235], Loss: 20.4860\n",
      "Epoch [65/100], Step [25100/6235], Loss: 8.2595\n",
      "Epoch [65/100], Step [25200/6235], Loss: 2.0416\n",
      "Epoch [65/100], Step [25300/6235], Loss: 1.0064\n",
      "Epoch [65/100], Step [25400/6235], Loss: 10.1839\n",
      "Epoch [65/100], Step [25500/6235], Loss: 3.5433\n",
      "Epoch [65/100], Step [25600/6235], Loss: 1.1761\n",
      "Epoch [65/100], Step [25700/6235], Loss: 0.1859\n",
      "Epoch [65/100], Step [25800/6235], Loss: 0.1494\n",
      "Epoch [65/100], Step [25900/6235], Loss: 10.2510\n",
      "Epoch [65/100], Step [26000/6235], Loss: 0.0530\n",
      "Epoch [65/100], Step [26100/6235], Loss: 0.0923\n",
      "Epoch [65/100], Step [26200/6235], Loss: 0.0677\n",
      "Epoch [65/100], Step [26300/6235], Loss: 4.2093\n",
      "Epoch [65/100], Step [26400/6235], Loss: 0.1858\n",
      "Epoch [65/100], Step [26500/6235], Loss: 0.4267\n",
      "Epoch [65/100], Step [26600/6235], Loss: 4.4738\n",
      "Epoch [65/100], Step [26700/6235], Loss: 0.8600\n",
      "Epoch [65/100], Step [26800/6235], Loss: 1.2627\n",
      "Epoch [65/100], Step [26900/6235], Loss: 0.1172\n",
      "Epoch [65/100], Step [27000/6235], Loss: 10.4433\n",
      "Epoch [65/100], Step [27100/6235], Loss: 0.4051\n",
      "Epoch [65/100], Step [27200/6235], Loss: 0.1566\n",
      "Epoch [65/100], Step [27300/6235], Loss: 0.1125\n",
      "Epoch [65/100], Step [27400/6235], Loss: 1.0832\n",
      "Epoch [65/100], Step [27500/6235], Loss: 17.4835\n",
      "Epoch [65/100], Step [27600/6235], Loss: 0.1532\n",
      "Epoch [65/100], Step [27700/6235], Loss: 0.9726\n",
      "Epoch [65/100], Step [27800/6235], Loss: 6.0268\n",
      "Epoch [65/100], Step [27900/6235], Loss: 1.0232\n",
      "Epoch [65/100], Step [28000/6235], Loss: 122.9710\n",
      "Epoch [65/100], Step [28100/6235], Loss: 5.7863\n",
      "Epoch [65/100], Step [28200/6235], Loss: 26.3064\n",
      "Epoch [65/100], Step [28300/6235], Loss: 3.3655\n",
      "Epoch [65/100], Step [28400/6235], Loss: 26.8523\n",
      "Epoch [65/100], Step [28500/6235], Loss: 3.7827\n",
      "Epoch [65/100], Step [28600/6235], Loss: 0.0891\n",
      "Epoch [65/100], Step [28700/6235], Loss: 5.3344\n",
      "Epoch [65/100], Step [28800/6235], Loss: 0.5239\n",
      "Epoch [65/100], Step [28900/6235], Loss: 74.7432\n",
      "Epoch [65/100], Step [29000/6235], Loss: 11.3004\n",
      "Epoch [65/100], Step [29100/6235], Loss: 0.0098\n",
      "Epoch [65/100], Step [29200/6235], Loss: 0.0967\n",
      "Epoch [65/100], Step [29300/6235], Loss: 9.5215\n",
      "Epoch [65/100], Step [29400/6235], Loss: 0.2458\n",
      "Epoch [65/100], Step [29500/6235], Loss: 2.7527\n",
      "Epoch [65/100], Step [29600/6235], Loss: 0.2320\n",
      "Epoch [65/100], Step [29700/6235], Loss: 0.1338\n",
      "Epoch [65/100], Step [29800/6235], Loss: 1.6178\n",
      "Epoch [65/100], Step [29900/6235], Loss: 0.2518\n",
      "Epoch [65/100], Step [30000/6235], Loss: 5.0239\n",
      "Epoch [65/100], Step [30100/6235], Loss: 8.6220\n",
      "Epoch [65/100], Step [30200/6235], Loss: 0.0423\n",
      "Epoch [65/100], Step [30300/6235], Loss: 0.7268\n",
      "Epoch [65/100], Step [30400/6235], Loss: 0.1235\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Step [30500/6235], Loss: 1.7443\n",
      "Epoch [65/100], Step [30600/6235], Loss: 0.4481\n",
      "Epoch [65/100], Step [30700/6235], Loss: 0.1981\n",
      "Epoch [65/100], Step [30800/6235], Loss: 0.2331\n",
      "Epoch [65/100], Step [30900/6235], Loss: 2.9463\n",
      "Epoch [65/100], Step [31000/6235], Loss: 0.0381\n",
      "Epoch [65/100], Step [31100/6235], Loss: 0.0751\n",
      "Epoch [65/100], Step [31200/6235], Loss: 5.2882\n",
      "Epoch [65/100], Step [31300/6235], Loss: 1.7958\n",
      "Epoch [65/100], Step [31400/6235], Loss: 6.0251\n",
      "Epoch [65/100], Step [31500/6235], Loss: 0.4943\n",
      "Epoch [65/100], Step [31600/6235], Loss: 9.0012\n",
      "Epoch [65/100], Step [31700/6235], Loss: 14.1173\n",
      "Epoch [65/100], Step [31800/6235], Loss: 1.9806\n",
      "Epoch [65/100], Step [31900/6235], Loss: 32.9993\n",
      "Epoch [65/100], Step [32000/6235], Loss: 5.3293\n",
      "Epoch [65/100], Step [32100/6235], Loss: 1.6228\n",
      "Epoch [65/100], Step [32200/6235], Loss: 1.4057\n",
      "Epoch [65/100], Step [32300/6235], Loss: 0.7420\n",
      "Epoch [65/100], Step [32400/6235], Loss: 0.2014\n",
      "Epoch [65/100], Step [32500/6235], Loss: 14.8999\n",
      "Epoch [65/100], Step [32600/6235], Loss: 1.5443\n",
      "Epoch [65/100], Step [32700/6235], Loss: 66.9949\n",
      "Epoch [65/100], Step [32800/6235], Loss: 2.1661\n",
      "Epoch [65/100], Step [32900/6235], Loss: 8.6277\n",
      "Epoch [65/100], Step [33000/6235], Loss: 0.2268\n",
      "Epoch [65/100], Step [33100/6235], Loss: 0.6326\n",
      "Epoch [65/100], Step [33200/6235], Loss: 1.0176\n",
      "Epoch [65/100], Step [33300/6235], Loss: 0.2923\n",
      "Epoch [65/100], Step [33400/6235], Loss: 153.6620\n",
      "Epoch [65/100], Step [33500/6235], Loss: 1.5761\n",
      "Epoch [65/100], Step [33600/6235], Loss: 5.8022\n",
      "Epoch [65/100], Step [33700/6235], Loss: 3.0503\n",
      "Epoch [65/100], Step [33800/6235], Loss: 1.8273\n",
      "Epoch [65/100], Step [33900/6235], Loss: 27.6822\n",
      "Epoch [65/100], Step [34000/6235], Loss: 0.0375\n",
      "Epoch [65/100], Step [34100/6235], Loss: 0.4466\n",
      "Epoch [65/100], Step [34200/6235], Loss: 3.5146\n",
      "Epoch [65/100], Step [34300/6235], Loss: 4.8467\n",
      "Epoch [65/100], Step [34400/6235], Loss: 0.2811\n",
      "Epoch [65/100], Step [34500/6235], Loss: 38.0022\n",
      "Epoch [65/100], Step [34600/6235], Loss: 0.9086\n",
      "Epoch [65/100], Step [34700/6235], Loss: 26.9055\n",
      "Epoch [65/100], Step [34800/6235], Loss: 10.6016\n",
      "Epoch [65/100], Step [34900/6235], Loss: 67.4542\n",
      "Epoch [65/100], Step [35000/6235], Loss: 1.0570\n",
      "Epoch [65/100], Step [35100/6235], Loss: 0.6762\n",
      "Epoch [65/100], Step [35200/6235], Loss: 0.3848\n",
      "Epoch [65/100], Step [35300/6235], Loss: 2.5688\n",
      "Epoch [65/100], Step [35400/6235], Loss: 0.4123\n",
      "Epoch [65/100], Step [35500/6235], Loss: 1.6328\n",
      "Epoch [65/100], Step [35600/6235], Loss: 11.3263\n",
      "Epoch [65/100], Step [35700/6235], Loss: 5.0173\n",
      "Epoch [65/100], Step [35800/6235], Loss: 0.3011\n",
      "Epoch [65/100], Step [35900/6235], Loss: 0.2579\n",
      "Epoch [65/100], Step [36000/6235], Loss: 0.2114\n",
      "Epoch [65/100], Step [36100/6235], Loss: 0.0760\n",
      "Epoch [65/100], Step [36200/6235], Loss: 17.5324\n",
      "Epoch [65/100], Step [36300/6235], Loss: 0.7604\n",
      "Epoch [65/100], Step [36400/6235], Loss: 2.8601\n",
      "Epoch [65/100], Step [36500/6235], Loss: 8.2320\n",
      "Epoch [65/100], Step [36600/6235], Loss: 0.1213\n",
      "Epoch [65/100], Step [36700/6235], Loss: 0.5301\n",
      "Epoch [65/100], Step [36800/6235], Loss: 8.7238\n",
      "Epoch [65/100], Step [36900/6235], Loss: 7.2194\n",
      "Epoch [65/100], Step [37000/6235], Loss: 0.5055\n",
      "Epoch [65/100], Step [37100/6235], Loss: 1.4082\n",
      "Epoch [65/100], Step [37200/6235], Loss: 0.0636\n",
      "Epoch [65/100], Step [37300/6235], Loss: 0.0322\n",
      "Epoch [65/100], Step [37400/6235], Loss: 0.1932\n",
      "Epoch [65/100], Step [37500/6235], Loss: 5.3335\n",
      "Epoch [65/100], Step [37600/6235], Loss: 12.0034\n",
      "Epoch [65/100], Step [37700/6235], Loss: 1.7430\n",
      "Epoch [65/100], Step [37800/6235], Loss: 7.9187\n",
      "Epoch [65/100], Step [37900/6235], Loss: 5.6703\n",
      "Epoch [65/100], Step [38000/6235], Loss: 0.7831\n",
      "Epoch [65/100], Step [38100/6235], Loss: 3.5686\n",
      "Epoch [65/100], Step [38200/6235], Loss: 2.5441\n",
      "Epoch [65/100], Step [38300/6235], Loss: 0.5284\n",
      "Epoch [65/100], Step [38400/6235], Loss: 0.0820\n",
      "Epoch [65/100], Step [38500/6235], Loss: 2.1310\n",
      "Epoch [65/100], Step [38600/6235], Loss: 0.1863\n",
      "Epoch [65/100], Step [38700/6235], Loss: 0.0856\n",
      "Epoch [65/100], Step [38800/6235], Loss: 0.1725\n",
      "Epoch [65/100], Step [38900/6235], Loss: 8.3375\n",
      "Epoch [65/100], Step [39000/6235], Loss: 1.1259\n",
      "Epoch [65/100], Step [39100/6235], Loss: 0.8655\n",
      "Epoch [65/100], Step [39200/6235], Loss: 2.2616\n",
      "Epoch [65/100], Step [39300/6235], Loss: 35.3650\n",
      "Epoch [65/100], Step [39400/6235], Loss: 69.3187\n",
      "Epoch [65/100], Step [39500/6235], Loss: 339.7330\n",
      "Epoch [65/100], Step [39600/6235], Loss: 35.7334\n",
      "Epoch [65/100], Step [39700/6235], Loss: 36.4911\n",
      "Epoch [65/100], Step [39800/6235], Loss: 82.8841\n",
      "Epoch [65/100], Step [39900/6235], Loss: 2.6275\n",
      "Epoch [65/100], Step [40000/6235], Loss: 15.9596\n",
      "Epoch [65/100], Step [40100/6235], Loss: 26.9537\n",
      "Epoch [65/100], Step [40200/6235], Loss: 1.9496\n",
      "Epoch [65/100], Step [40300/6235], Loss: 0.1593\n",
      "Epoch [65/100], Step [40400/6235], Loss: 1.7774\n",
      "Epoch [65/100], Step [40500/6235], Loss: 2.6263\n",
      "Epoch [65/100], Step [40600/6235], Loss: 0.2467\n",
      "Epoch [65/100], Step [40700/6235], Loss: 7.1941\n",
      "Epoch [65/100], Step [40800/6235], Loss: 0.7157\n",
      "Epoch [65/100], Step [40900/6235], Loss: 0.5679\n",
      "Epoch [65/100], Step [41000/6235], Loss: 47.3418\n",
      "Epoch [65/100], Step [41100/6235], Loss: 17.0461\n",
      "Epoch [65/100], Step [41200/6235], Loss: 19.5576\n",
      "Epoch [65/100], Step [41300/6235], Loss: 3.2367\n",
      "Epoch [65/100], Step [41400/6235], Loss: 0.0282\n",
      "Epoch [65/100], Step [41500/6235], Loss: 0.8570\n",
      "Epoch [65/100], Step [41600/6235], Loss: 0.1411\n",
      "Epoch [65/100], Step [41700/6235], Loss: 2.2041\n",
      "Epoch [65/100], Step [41800/6235], Loss: 0.4556\n",
      "Epoch [65/100], Step [41900/6235], Loss: 3.2332\n",
      "Epoch [65/100], Step [42000/6235], Loss: 2.6471\n",
      "Epoch [65/100], Step [42100/6235], Loss: 6.3327\n",
      "Epoch [65/100], Step [42200/6235], Loss: 2.3936\n",
      "Epoch [65/100], Step [42300/6235], Loss: 4.8079\n",
      "Epoch [65/100], Step [42400/6235], Loss: 0.2627\n",
      "Epoch [65/100], Step [42500/6235], Loss: 3.2933\n",
      "Epoch [65/100], Step [42600/6235], Loss: 0.6006\n",
      "Epoch [65/100], Step [42700/6235], Loss: 0.3001\n",
      "Epoch [65/100], Step [42800/6235], Loss: 0.7261\n",
      "Epoch [65/100], Step [42900/6235], Loss: 4.1462\n",
      "Epoch [65/100], Step [43000/6235], Loss: 0.2509\n",
      "Epoch [65/100], Step [43100/6235], Loss: 0.9220\n",
      "Epoch [65/100], Step [43200/6235], Loss: 0.7802\n",
      "Epoch [65/100], Step [43300/6235], Loss: 9.3357\n",
      "Epoch [65/100], Step [43400/6235], Loss: 10.5514\n",
      "Epoch [65/100], Step [43500/6235], Loss: 9.3306\n",
      "Epoch [65/100], Step [43600/6235], Loss: 20.4715\n",
      "Epoch [65/100], Step [43700/6235], Loss: 37.2776\n",
      "Epoch [65/100], Step [43800/6235], Loss: 5.0393\n",
      "Epoch [65/100], Step [43900/6235], Loss: 0.4735\n",
      "Epoch [65/100], Step [44000/6235], Loss: 60.5936\n",
      "Epoch [65/100], Step [44100/6235], Loss: 0.6043\n",
      "Epoch [65/100], Step [44200/6235], Loss: 1.5064\n",
      "Epoch [65/100], Step [44300/6235], Loss: 51.1982\n",
      "Epoch [65/100], Step [44400/6235], Loss: 4.6028\n",
      "Epoch [65/100], Step [44500/6235], Loss: 1.5384\n",
      "Epoch [65/100], Step [44600/6235], Loss: 9.8766\n",
      "Epoch [65/100], Step [44700/6235], Loss: 8.4201\n",
      "Epoch [65/100], Step [44800/6235], Loss: 4.0504\n",
      "Epoch [65/100], Step [44900/6235], Loss: 4.1493\n",
      "Epoch [65/100], Step [45000/6235], Loss: 5.0216\n",
      "Epoch [65/100], Step [45100/6235], Loss: 6.9787\n",
      "Epoch [65/100], Step [45200/6235], Loss: 0.7129\n",
      "Epoch [65/100], Step [45300/6235], Loss: 33.6664\n",
      "Epoch [65/100], Step [45400/6235], Loss: 5.5913\n",
      "Epoch [65/100], Step [45500/6235], Loss: 0.4098\n",
      "Epoch [65/100], Step [45600/6235], Loss: 0.3429\n",
      "Epoch [65/100], Step [45700/6235], Loss: 56.7623\n",
      "Epoch [65/100], Step [45800/6235], Loss: 237.8436\n",
      "Epoch [65/100], Step [45900/6235], Loss: 3.1149\n",
      "Epoch [65/100], Step [46000/6235], Loss: 223.5362\n",
      "Epoch [65/100], Step [46100/6235], Loss: 176.6441\n",
      "Epoch [65/100], Step [46200/6235], Loss: 21.2447\n",
      "Epoch [65/100], Step [46300/6235], Loss: 75.3689\n",
      "Epoch [65/100], Step [46400/6235], Loss: 10.0540\n",
      "Epoch [65/100], Step [46500/6235], Loss: 1.8738\n",
      "Epoch [65/100], Step [46600/6235], Loss: 19.9824\n",
      "Epoch [65/100], Step [46700/6235], Loss: 32.3889\n",
      "Epoch [65/100], Step [46800/6235], Loss: 4.0346\n",
      "Epoch [65/100], Step [46900/6235], Loss: 3.3625\n",
      "Epoch [65/100], Step [47000/6235], Loss: 6.7761\n",
      "Epoch [65/100], Step [47100/6235], Loss: 0.8147\n",
      "Epoch [65/100], Step [47200/6235], Loss: 25.9924\n",
      "Epoch [65/100], Step [47300/6235], Loss: 1.1983\n",
      "Epoch [65/100], Step [47400/6235], Loss: 72.6193\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [65/100], Step [47500/6235], Loss: 1.8607\n",
      "Epoch [65/100], Step [47600/6235], Loss: 1.4305\n",
      "Epoch [65/100], Step [47700/6235], Loss: 5.2736\n",
      "Epoch [65/100], Step [47800/6235], Loss: 1.4204\n",
      "Epoch [65/100], Step [47900/6235], Loss: 33.9283\n",
      "Epoch [65/100], Step [48000/6235], Loss: 24.2865\n",
      "Epoch [65/100], Step [48100/6235], Loss: 3.8408\n",
      "Epoch [65/100], Step [48200/6235], Loss: 13.8552\n",
      "Epoch [65/100], Step [48300/6235], Loss: 483.8987\n",
      "Epoch [65/100], Step [48400/6235], Loss: 20.2155\n",
      "Epoch [65/100], Step [48500/6235], Loss: 34.9415\n",
      "Epoch [65/100], Step [48600/6235], Loss: 162.8118\n",
      "Epoch [65/100], Step [48700/6235], Loss: 8.4003\n",
      "Epoch [65/100], Step [48800/6235], Loss: 423.8001\n",
      "Epoch [65/100], Step [48900/6235], Loss: 682.0922\n",
      "Epoch [65/100], Step [49000/6235], Loss: 106.0591\n",
      "Epoch [65/100], Step [49100/6235], Loss: 2048.6741\n",
      "Epoch [65/100], Step [49200/6235], Loss: 160.2025\n",
      "Epoch [65/100], Step [49300/6235], Loss: 712.7664\n",
      "Epoch [65/100], Step [49400/6235], Loss: 30.4655\n",
      "Epoch [65/100], Step [49500/6235], Loss: 16.2225\n",
      "Epoch [65/100], Step [49600/6235], Loss: 1173.0311\n",
      "Epoch [65/100], Step [49700/6235], Loss: 2678.1116\n",
      "Epoch [65/100], Step [49800/6235], Loss: 1626.8224\n",
      "Epoch [66/100], Step [100/6235], Loss: 0.0795\n",
      "Epoch [66/100], Step [200/6235], Loss: 0.0719\n",
      "Epoch [66/100], Step [300/6235], Loss: 0.0445\n",
      "Epoch [66/100], Step [400/6235], Loss: 0.0078\n",
      "Epoch [66/100], Step [500/6235], Loss: 16.5717\n",
      "Epoch [66/100], Step [600/6235], Loss: 0.0910\n",
      "Epoch [66/100], Step [700/6235], Loss: 0.4772\n",
      "Epoch [66/100], Step [800/6235], Loss: 0.0759\n",
      "Epoch [66/100], Step [900/6235], Loss: 0.0341\n",
      "Epoch [66/100], Step [1000/6235], Loss: 0.0254\n",
      "Epoch [66/100], Step [1100/6235], Loss: 0.0350\n",
      "Epoch [66/100], Step [1200/6235], Loss: 0.1344\n",
      "Epoch [66/100], Step [1300/6235], Loss: 0.0560\n",
      "Epoch [66/100], Step [1400/6235], Loss: 0.0353\n",
      "Epoch [66/100], Step [1500/6235], Loss: 0.0029\n",
      "Epoch [66/100], Step [1600/6235], Loss: 0.2037\n",
      "Epoch [66/100], Step [1700/6235], Loss: 0.0312\n",
      "Epoch [66/100], Step [1800/6235], Loss: 0.2123\n",
      "Epoch [66/100], Step [1900/6235], Loss: 0.8622\n",
      "Epoch [66/100], Step [2000/6235], Loss: 2.0023\n",
      "Epoch [66/100], Step [2100/6235], Loss: 0.8465\n",
      "Epoch [66/100], Step [2200/6235], Loss: 11.3929\n",
      "Epoch [66/100], Step [2300/6235], Loss: 26.0898\n",
      "Epoch [66/100], Step [2400/6235], Loss: 14.2485\n",
      "Epoch [66/100], Step [2500/6235], Loss: 32.4184\n",
      "Epoch [66/100], Step [2600/6235], Loss: 7.4131\n",
      "Epoch [66/100], Step [2700/6235], Loss: 40.3022\n",
      "Epoch [66/100], Step [2800/6235], Loss: 112.7047\n",
      "Epoch [66/100], Step [2900/6235], Loss: 6.4384\n",
      "Epoch [66/100], Step [3000/6235], Loss: 0.6152\n",
      "Epoch [66/100], Step [3100/6235], Loss: 52.1396\n",
      "Epoch [66/100], Step [3200/6235], Loss: 75.8536\n",
      "Epoch [66/100], Step [3300/6235], Loss: 0.4669\n",
      "Epoch [66/100], Step [3400/6235], Loss: 3.2218\n",
      "Epoch [66/100], Step [3500/6235], Loss: 31.3675\n",
      "Epoch [66/100], Step [3600/6235], Loss: 9.6137\n",
      "Epoch [66/100], Step [3700/6235], Loss: 1.5173\n",
      "Epoch [66/100], Step [3800/6235], Loss: 0.5394\n",
      "Epoch [66/100], Step [3900/6235], Loss: 1.1131\n",
      "Epoch [66/100], Step [4000/6235], Loss: 0.1363\n",
      "Epoch [66/100], Step [4100/6235], Loss: 3.9231\n",
      "Epoch [66/100], Step [4200/6235], Loss: 0.3653\n",
      "Epoch [66/100], Step [4300/6235], Loss: 10.1188\n",
      "Epoch [66/100], Step [4400/6235], Loss: 2.4373\n",
      "Epoch [66/100], Step [4500/6235], Loss: 65.0085\n",
      "Epoch [66/100], Step [4600/6235], Loss: 13.2585\n",
      "Epoch [66/100], Step [4700/6235], Loss: 2.1418\n",
      "Epoch [66/100], Step [4800/6235], Loss: 0.1313\n",
      "Epoch [66/100], Step [4900/6235], Loss: 0.0874\n",
      "Epoch [66/100], Step [5000/6235], Loss: 0.6991\n",
      "Epoch [66/100], Step [5100/6235], Loss: 1.2063\n",
      "Epoch [66/100], Step [5200/6235], Loss: 2.1749\n",
      "Epoch [66/100], Step [5300/6235], Loss: 32.3064\n",
      "Epoch [66/100], Step [5400/6235], Loss: 1.5334\n",
      "Epoch [66/100], Step [5500/6235], Loss: 0.0367\n",
      "Epoch [66/100], Step [5600/6235], Loss: 0.2446\n",
      "Epoch [66/100], Step [5700/6235], Loss: 1.3615\n",
      "Epoch [66/100], Step [5800/6235], Loss: 1.2238\n",
      "Epoch [66/100], Step [5900/6235], Loss: 0.2749\n",
      "Epoch [66/100], Step [6000/6235], Loss: 0.1842\n",
      "Epoch [66/100], Step [6100/6235], Loss: 0.0438\n",
      "Epoch [66/100], Step [6200/6235], Loss: 0.3697\n",
      "Epoch [66/100], Step [6300/6235], Loss: 0.5201\n",
      "Epoch [66/100], Step [6400/6235], Loss: 0.1549\n",
      "Epoch [66/100], Step [6500/6235], Loss: 1.2929\n",
      "Epoch [66/100], Step [6600/6235], Loss: 0.1137\n",
      "Epoch [66/100], Step [6700/6235], Loss: 0.4672\n",
      "Epoch [66/100], Step [6800/6235], Loss: 0.8176\n",
      "Epoch [66/100], Step [6900/6235], Loss: 2.8329\n",
      "Epoch [66/100], Step [7000/6235], Loss: 0.1763\n",
      "Epoch [66/100], Step [7100/6235], Loss: 0.1016\n",
      "Epoch [66/100], Step [7200/6235], Loss: 0.9266\n",
      "Epoch [66/100], Step [7300/6235], Loss: 1.7653\n",
      "Epoch [66/100], Step [7400/6235], Loss: 0.0903\n",
      "Epoch [66/100], Step [7500/6235], Loss: 2.5403\n",
      "Epoch [66/100], Step [7600/6235], Loss: 19.7899\n",
      "Epoch [66/100], Step [7700/6235], Loss: 9.1103\n",
      "Epoch [66/100], Step [7800/6235], Loss: 14.6827\n",
      "Epoch [66/100], Step [7900/6235], Loss: 8.2169\n",
      "Epoch [66/100], Step [8000/6235], Loss: 0.2825\n",
      "Epoch [66/100], Step [8100/6235], Loss: 4.1710\n",
      "Epoch [66/100], Step [8200/6235], Loss: 19.8213\n",
      "Epoch [66/100], Step [8300/6235], Loss: 64.9947\n",
      "Epoch [66/100], Step [8400/6235], Loss: 107.6621\n",
      "Epoch [66/100], Step [8500/6235], Loss: 8.8555\n",
      "Epoch [66/100], Step [8600/6235], Loss: 142.4276\n",
      "Epoch [66/100], Step [8700/6235], Loss: 91.4375\n",
      "Epoch [66/100], Step [8800/6235], Loss: 293.2706\n",
      "Epoch [66/100], Step [8900/6235], Loss: 269.1797\n",
      "Epoch [66/100], Step [9000/6235], Loss: 246.8250\n",
      "Epoch [66/100], Step [9100/6235], Loss: 2298.7976\n",
      "Epoch [66/100], Step [9200/6235], Loss: 4001.4109\n",
      "Epoch [66/100], Step [9300/6235], Loss: 109.2909\n",
      "Epoch [66/100], Step [9400/6235], Loss: 143.7500\n",
      "Epoch [66/100], Step [9500/6235], Loss: 2473.0540\n",
      "Epoch [66/100], Step [9600/6235], Loss: 663.4209\n",
      "Epoch [66/100], Step [9700/6235], Loss: 6.5372\n",
      "Epoch [66/100], Step [9800/6235], Loss: 3733.7092\n",
      "Epoch [66/100], Step [9900/6235], Loss: 335.8573\n",
      "Epoch [66/100], Step [10000/6235], Loss: 573.8488\n",
      "Epoch [66/100], Step [10100/6235], Loss: 3.9913\n",
      "Epoch [66/100], Step [10200/6235], Loss: 435.3982\n",
      "Epoch [66/100], Step [10300/6235], Loss: 5.5336\n",
      "Epoch [66/100], Step [10400/6235], Loss: 9.1110\n",
      "Epoch [66/100], Step [10500/6235], Loss: 2.7535\n",
      "Epoch [66/100], Step [10600/6235], Loss: 23.8059\n",
      "Epoch [66/100], Step [10700/6235], Loss: 27.0879\n",
      "Epoch [66/100], Step [10800/6235], Loss: 33.9393\n",
      "Epoch [66/100], Step [10900/6235], Loss: 1.3186\n",
      "Epoch [66/100], Step [11000/6235], Loss: 291.7318\n",
      "Epoch [66/100], Step [11100/6235], Loss: 34.7591\n",
      "Epoch [66/100], Step [11200/6235], Loss: 38.7153\n",
      "Epoch [66/100], Step [11300/6235], Loss: 149.9798\n",
      "Epoch [66/100], Step [11400/6235], Loss: 1.0152\n",
      "Epoch [66/100], Step [11500/6235], Loss: 4.8804\n",
      "Epoch [66/100], Step [11600/6235], Loss: 3.1568\n",
      "Epoch [66/100], Step [11700/6235], Loss: 39.2959\n",
      "Epoch [66/100], Step [11800/6235], Loss: 409.8955\n",
      "Epoch [66/100], Step [11900/6235], Loss: 403.3219\n",
      "Epoch [66/100], Step [12000/6235], Loss: 262.3248\n",
      "Epoch [66/100], Step [12100/6235], Loss: 191.5856\n",
      "Epoch [66/100], Step [12200/6235], Loss: 175.8682\n",
      "Epoch [66/100], Step [12300/6235], Loss: 52.1089\n",
      "Epoch [66/100], Step [12400/6235], Loss: 289.2755\n",
      "Epoch [66/100], Step [12500/6235], Loss: 32.3367\n",
      "Epoch [66/100], Step [12600/6235], Loss: 53.0043\n",
      "Epoch [66/100], Step [12700/6235], Loss: 2.3200\n",
      "Epoch [66/100], Step [12800/6235], Loss: 5.1490\n",
      "Epoch [66/100], Step [12900/6235], Loss: 38.7114\n",
      "Epoch [66/100], Step [13000/6235], Loss: 0.4556\n",
      "Epoch [66/100], Step [13100/6235], Loss: 66.1268\n",
      "Epoch [66/100], Step [13200/6235], Loss: 9.8425\n",
      "Epoch [66/100], Step [13300/6235], Loss: 41.4810\n",
      "Epoch [66/100], Step [13400/6235], Loss: 245.7834\n",
      "Epoch [66/100], Step [13500/6235], Loss: 2.9161\n",
      "Epoch [66/100], Step [13600/6235], Loss: 6.3666\n",
      "Epoch [66/100], Step [13700/6235], Loss: 22.2141\n",
      "Epoch [66/100], Step [13800/6235], Loss: 151.6646\n",
      "Epoch [66/100], Step [13900/6235], Loss: 58.9409\n",
      "Epoch [66/100], Step [14000/6235], Loss: 15.0244\n",
      "Epoch [66/100], Step [14100/6235], Loss: 45.9638\n",
      "Epoch [66/100], Step [14200/6235], Loss: 149.1569\n",
      "Epoch [66/100], Step [14300/6235], Loss: 53.1683\n",
      "Epoch [66/100], Step [14400/6235], Loss: 38.9997\n",
      "Epoch [66/100], Step [14500/6235], Loss: 46.5165\n",
      "Epoch [66/100], Step [14600/6235], Loss: 0.2109\n",
      "Epoch [66/100], Step [14700/6235], Loss: 41.9368\n",
      "Epoch [66/100], Step [14800/6235], Loss: 33.8490\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Step [14900/6235], Loss: 0.7476\n",
      "Epoch [66/100], Step [15000/6235], Loss: 1.6850\n",
      "Epoch [66/100], Step [15100/6235], Loss: 0.5398\n",
      "Epoch [66/100], Step [15200/6235], Loss: 7.7140\n",
      "Epoch [66/100], Step [15300/6235], Loss: 42.5248\n",
      "Epoch [66/100], Step [15400/6235], Loss: 27.1095\n",
      "Epoch [66/100], Step [15500/6235], Loss: 10.5022\n",
      "Epoch [66/100], Step [15600/6235], Loss: 166.8289\n",
      "Epoch [66/100], Step [15700/6235], Loss: 15.3326\n",
      "Epoch [66/100], Step [15800/6235], Loss: 4.4315\n",
      "Epoch [66/100], Step [15900/6235], Loss: 0.5554\n",
      "Epoch [66/100], Step [16000/6235], Loss: 21.9912\n",
      "Epoch [66/100], Step [16100/6235], Loss: 19.5274\n",
      "Epoch [66/100], Step [16200/6235], Loss: 0.2713\n",
      "Epoch [66/100], Step [16300/6235], Loss: 10.0883\n",
      "Epoch [66/100], Step [16400/6235], Loss: 29.0783\n",
      "Epoch [66/100], Step [16500/6235], Loss: 365.4687\n",
      "Epoch [66/100], Step [16600/6235], Loss: 18.4324\n",
      "Epoch [66/100], Step [16700/6235], Loss: 0.3571\n",
      "Epoch [66/100], Step [16800/6235], Loss: 14.8958\n",
      "Epoch [66/100], Step [16900/6235], Loss: 0.1009\n",
      "Epoch [66/100], Step [17000/6235], Loss: 0.2171\n",
      "Epoch [66/100], Step [17100/6235], Loss: 0.2849\n",
      "Epoch [66/100], Step [17200/6235], Loss: 294.5310\n",
      "Epoch [66/100], Step [17300/6235], Loss: 36.3081\n",
      "Epoch [66/100], Step [17400/6235], Loss: 37.7879\n",
      "Epoch [66/100], Step [17500/6235], Loss: 0.5843\n",
      "Epoch [66/100], Step [17600/6235], Loss: 3.0280\n",
      "Epoch [66/100], Step [17700/6235], Loss: 96.9543\n",
      "Epoch [66/100], Step [17800/6235], Loss: 23.6951\n",
      "Epoch [66/100], Step [17900/6235], Loss: 6.5777\n",
      "Epoch [66/100], Step [18000/6235], Loss: 4.9090\n",
      "Epoch [66/100], Step [18100/6235], Loss: 15.7279\n",
      "Epoch [66/100], Step [18200/6235], Loss: 0.9682\n",
      "Epoch [66/100], Step [18300/6235], Loss: 6.5101\n",
      "Epoch [66/100], Step [18400/6235], Loss: 3.7970\n",
      "Epoch [66/100], Step [18500/6235], Loss: 13.2961\n",
      "Epoch [66/100], Step [18600/6235], Loss: 1.9381\n",
      "Epoch [66/100], Step [18700/6235], Loss: 0.4184\n",
      "Epoch [66/100], Step [18800/6235], Loss: 48.0424\n",
      "Epoch [66/100], Step [18900/6235], Loss: 26.6512\n",
      "Epoch [66/100], Step [19000/6235], Loss: 14.3963\n",
      "Epoch [66/100], Step [19100/6235], Loss: 8.3349\n",
      "Epoch [66/100], Step [19200/6235], Loss: 2.4856\n",
      "Epoch [66/100], Step [19300/6235], Loss: 10.1332\n",
      "Epoch [66/100], Step [19400/6235], Loss: 98.1756\n",
      "Epoch [66/100], Step [19500/6235], Loss: 189.9037\n",
      "Epoch [66/100], Step [19600/6235], Loss: 131.2221\n",
      "Epoch [66/100], Step [19700/6235], Loss: 24.8820\n",
      "Epoch [66/100], Step [19800/6235], Loss: 0.8735\n",
      "Epoch [66/100], Step [19900/6235], Loss: 1.3802\n",
      "Epoch [66/100], Step [20000/6235], Loss: 109.3614\n",
      "Epoch [66/100], Step [20100/6235], Loss: 15.2431\n",
      "Epoch [66/100], Step [20200/6235], Loss: 1.0719\n",
      "Epoch [66/100], Step [20300/6235], Loss: 0.2448\n",
      "Epoch [66/100], Step [20400/6235], Loss: 32.2946\n",
      "Epoch [66/100], Step [20500/6235], Loss: 26.0803\n",
      "Epoch [66/100], Step [20600/6235], Loss: 11.6378\n",
      "Epoch [66/100], Step [20700/6235], Loss: 7.8685\n",
      "Epoch [66/100], Step [20800/6235], Loss: 0.2140\n",
      "Epoch [66/100], Step [20900/6235], Loss: 45.7726\n",
      "Epoch [66/100], Step [21000/6235], Loss: 16.1107\n",
      "Epoch [66/100], Step [21100/6235], Loss: 0.3050\n",
      "Epoch [66/100], Step [21200/6235], Loss: 0.1510\n",
      "Epoch [66/100], Step [21300/6235], Loss: 0.1395\n",
      "Epoch [66/100], Step [21400/6235], Loss: 5.3582\n",
      "Epoch [66/100], Step [21500/6235], Loss: 1.5361\n",
      "Epoch [66/100], Step [21600/6235], Loss: 32.4848\n",
      "Epoch [66/100], Step [21700/6235], Loss: 0.2124\n",
      "Epoch [66/100], Step [21800/6235], Loss: 6.5712\n",
      "Epoch [66/100], Step [21900/6235], Loss: 0.2559\n",
      "Epoch [66/100], Step [22000/6235], Loss: 3.1103\n",
      "Epoch [66/100], Step [22100/6235], Loss: 3.8764\n",
      "Epoch [66/100], Step [22200/6235], Loss: 0.6703\n",
      "Epoch [66/100], Step [22300/6235], Loss: 6.7070\n",
      "Epoch [66/100], Step [22400/6235], Loss: 1.3442\n",
      "Epoch [66/100], Step [22500/6235], Loss: 192.5036\n",
      "Epoch [66/100], Step [22600/6235], Loss: 26.9627\n",
      "Epoch [66/100], Step [22700/6235], Loss: 0.0330\n",
      "Epoch [66/100], Step [22800/6235], Loss: 7.1566\n",
      "Epoch [66/100], Step [22900/6235], Loss: 26.4931\n",
      "Epoch [66/100], Step [23000/6235], Loss: 4.3394\n",
      "Epoch [66/100], Step [23100/6235], Loss: 8.0167\n",
      "Epoch [66/100], Step [23200/6235], Loss: 13.3716\n",
      "Epoch [66/100], Step [23300/6235], Loss: 18.2535\n",
      "Epoch [66/100], Step [23400/6235], Loss: 1.3005\n",
      "Epoch [66/100], Step [23500/6235], Loss: 0.1717\n",
      "Epoch [66/100], Step [23600/6235], Loss: 109.2716\n",
      "Epoch [66/100], Step [23700/6235], Loss: 2.6383\n",
      "Epoch [66/100], Step [23800/6235], Loss: 1.0422\n",
      "Epoch [66/100], Step [23900/6235], Loss: 7.1616\n",
      "Epoch [66/100], Step [24000/6235], Loss: 0.2090\n",
      "Epoch [66/100], Step [24100/6235], Loss: 0.3187\n",
      "Epoch [66/100], Step [24200/6235], Loss: 28.9913\n",
      "Epoch [66/100], Step [24300/6235], Loss: 1.3208\n",
      "Epoch [66/100], Step [24400/6235], Loss: 5.1570\n",
      "Epoch [66/100], Step [24500/6235], Loss: 2.6990\n",
      "Epoch [66/100], Step [24600/6235], Loss: 0.1353\n",
      "Epoch [66/100], Step [24700/6235], Loss: 4.2111\n",
      "Epoch [66/100], Step [24800/6235], Loss: 0.0829\n",
      "Epoch [66/100], Step [24900/6235], Loss: 0.6771\n",
      "Epoch [66/100], Step [25000/6235], Loss: 16.2820\n",
      "Epoch [66/100], Step [25100/6235], Loss: 9.4089\n",
      "Epoch [66/100], Step [25200/6235], Loss: 1.6016\n",
      "Epoch [66/100], Step [25300/6235], Loss: 0.6462\n",
      "Epoch [66/100], Step [25400/6235], Loss: 9.6444\n",
      "Epoch [66/100], Step [25500/6235], Loss: 6.6349\n",
      "Epoch [66/100], Step [25600/6235], Loss: 2.7195\n",
      "Epoch [66/100], Step [25700/6235], Loss: 0.3730\n",
      "Epoch [66/100], Step [25800/6235], Loss: 0.1464\n",
      "Epoch [66/100], Step [25900/6235], Loss: 9.4041\n",
      "Epoch [66/100], Step [26000/6235], Loss: 4.1594\n",
      "Epoch [66/100], Step [26100/6235], Loss: 0.7137\n",
      "Epoch [66/100], Step [26200/6235], Loss: 0.1726\n",
      "Epoch [66/100], Step [26300/6235], Loss: 3.9781\n",
      "Epoch [66/100], Step [26400/6235], Loss: 0.1905\n",
      "Epoch [66/100], Step [26500/6235], Loss: 0.2338\n",
      "Epoch [66/100], Step [26600/6235], Loss: 3.1603\n",
      "Epoch [66/100], Step [26700/6235], Loss: 0.6457\n",
      "Epoch [66/100], Step [26800/6235], Loss: 1.0513\n",
      "Epoch [66/100], Step [26900/6235], Loss: 0.0440\n",
      "Epoch [66/100], Step [27000/6235], Loss: 12.7961\n",
      "Epoch [66/100], Step [27100/6235], Loss: 0.1389\n",
      "Epoch [66/100], Step [27200/6235], Loss: 0.0549\n",
      "Epoch [66/100], Step [27300/6235], Loss: 0.2108\n",
      "Epoch [66/100], Step [27400/6235], Loss: 0.9130\n",
      "Epoch [66/100], Step [27500/6235], Loss: 23.0267\n",
      "Epoch [66/100], Step [27600/6235], Loss: 0.1801\n",
      "Epoch [66/100], Step [27700/6235], Loss: 1.5944\n",
      "Epoch [66/100], Step [27800/6235], Loss: 6.1067\n",
      "Epoch [66/100], Step [27900/6235], Loss: 0.6967\n",
      "Epoch [66/100], Step [28000/6235], Loss: 179.7792\n",
      "Epoch [66/100], Step [28100/6235], Loss: 2.8537\n",
      "Epoch [66/100], Step [28200/6235], Loss: 25.3957\n",
      "Epoch [66/100], Step [28300/6235], Loss: 3.5518\n",
      "Epoch [66/100], Step [28400/6235], Loss: 23.6571\n",
      "Epoch [66/100], Step [28500/6235], Loss: 3.4069\n",
      "Epoch [66/100], Step [28600/6235], Loss: 0.6083\n",
      "Epoch [66/100], Step [28700/6235], Loss: 4.4843\n",
      "Epoch [66/100], Step [28800/6235], Loss: 0.3514\n",
      "Epoch [66/100], Step [28900/6235], Loss: 70.4928\n",
      "Epoch [66/100], Step [29000/6235], Loss: 3.6405\n",
      "Epoch [66/100], Step [29100/6235], Loss: 0.0482\n",
      "Epoch [66/100], Step [29200/6235], Loss: 0.1539\n",
      "Epoch [66/100], Step [29300/6235], Loss: 12.5753\n",
      "Epoch [66/100], Step [29400/6235], Loss: 0.1340\n",
      "Epoch [66/100], Step [29500/6235], Loss: 3.3867\n",
      "Epoch [66/100], Step [29600/6235], Loss: 0.3851\n",
      "Epoch [66/100], Step [29700/6235], Loss: 0.0858\n",
      "Epoch [66/100], Step [29800/6235], Loss: 1.5947\n",
      "Epoch [66/100], Step [29900/6235], Loss: 0.0437\n",
      "Epoch [66/100], Step [30000/6235], Loss: 4.0190\n",
      "Epoch [66/100], Step [30100/6235], Loss: 0.0336\n",
      "Epoch [66/100], Step [30200/6235], Loss: 0.0821\n",
      "Epoch [66/100], Step [30300/6235], Loss: 0.9783\n",
      "Epoch [66/100], Step [30400/6235], Loss: 0.1163\n",
      "Epoch [66/100], Step [30500/6235], Loss: 1.3314\n",
      "Epoch [66/100], Step [30600/6235], Loss: 0.2518\n",
      "Epoch [66/100], Step [30700/6235], Loss: 0.3203\n",
      "Epoch [66/100], Step [30800/6235], Loss: 0.1967\n",
      "Epoch [66/100], Step [30900/6235], Loss: 1.8872\n",
      "Epoch [66/100], Step [31000/6235], Loss: 0.0851\n",
      "Epoch [66/100], Step [31100/6235], Loss: 0.0800\n",
      "Epoch [66/100], Step [31200/6235], Loss: 6.3995\n",
      "Epoch [66/100], Step [31300/6235], Loss: 7.2179\n",
      "Epoch [66/100], Step [31400/6235], Loss: 7.0758\n",
      "Epoch [66/100], Step [31500/6235], Loss: 0.4055\n",
      "Epoch [66/100], Step [31600/6235], Loss: 5.9326\n",
      "Epoch [66/100], Step [31700/6235], Loss: 20.7847\n",
      "Epoch [66/100], Step [31800/6235], Loss: 2.1546\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Step [31900/6235], Loss: 1155.5918\n",
      "Epoch [66/100], Step [32000/6235], Loss: 103.3077\n",
      "Epoch [66/100], Step [32100/6235], Loss: 8.2388\n",
      "Epoch [66/100], Step [32200/6235], Loss: 97.9527\n",
      "Epoch [66/100], Step [32300/6235], Loss: 1.1425\n",
      "Epoch [66/100], Step [32400/6235], Loss: 0.0776\n",
      "Epoch [66/100], Step [32500/6235], Loss: 20.2522\n",
      "Epoch [66/100], Step [32600/6235], Loss: 1.1093\n",
      "Epoch [66/100], Step [32700/6235], Loss: 76.0753\n",
      "Epoch [66/100], Step [32800/6235], Loss: 16.7668\n",
      "Epoch [66/100], Step [32900/6235], Loss: 17.6102\n",
      "Epoch [66/100], Step [33000/6235], Loss: 0.3239\n",
      "Epoch [66/100], Step [33100/6235], Loss: 1.1637\n",
      "Epoch [66/100], Step [33200/6235], Loss: 1.4606\n",
      "Epoch [66/100], Step [33300/6235], Loss: 11.6251\n",
      "Epoch [66/100], Step [33400/6235], Loss: 59.0793\n",
      "Epoch [66/100], Step [33500/6235], Loss: 0.3112\n",
      "Epoch [66/100], Step [33600/6235], Loss: 3.1917\n",
      "Epoch [66/100], Step [33700/6235], Loss: 2.5937\n",
      "Epoch [66/100], Step [33800/6235], Loss: 3.2374\n",
      "Epoch [66/100], Step [33900/6235], Loss: 25.3467\n",
      "Epoch [66/100], Step [34000/6235], Loss: 0.0155\n",
      "Epoch [66/100], Step [34100/6235], Loss: 0.2602\n",
      "Epoch [66/100], Step [34200/6235], Loss: 2.8584\n",
      "Epoch [66/100], Step [34300/6235], Loss: 6.0048\n",
      "Epoch [66/100], Step [34400/6235], Loss: 0.1118\n",
      "Epoch [66/100], Step [34500/6235], Loss: 89.8501\n",
      "Epoch [66/100], Step [34600/6235], Loss: 2.1358\n",
      "Epoch [66/100], Step [34700/6235], Loss: 13.9161\n",
      "Epoch [66/100], Step [34800/6235], Loss: 7.7297\n",
      "Epoch [66/100], Step [34900/6235], Loss: 50.2817\n",
      "Epoch [66/100], Step [35000/6235], Loss: 1.5792\n",
      "Epoch [66/100], Step [35100/6235], Loss: 2.0514\n",
      "Epoch [66/100], Step [35200/6235], Loss: 0.8846\n",
      "Epoch [66/100], Step [35300/6235], Loss: 0.8952\n",
      "Epoch [66/100], Step [35400/6235], Loss: 0.6531\n",
      "Epoch [66/100], Step [35500/6235], Loss: 2.5209\n",
      "Epoch [66/100], Step [35600/6235], Loss: 0.9765\n",
      "Epoch [66/100], Step [35700/6235], Loss: 6.2619\n",
      "Epoch [66/100], Step [35800/6235], Loss: 4.6147\n",
      "Epoch [66/100], Step [35900/6235], Loss: 4.0818\n",
      "Epoch [66/100], Step [36000/6235], Loss: 0.0461\n",
      "Epoch [66/100], Step [36100/6235], Loss: 0.0308\n",
      "Epoch [66/100], Step [36200/6235], Loss: 22.7992\n",
      "Epoch [66/100], Step [36300/6235], Loss: 0.5593\n",
      "Epoch [66/100], Step [36400/6235], Loss: 2.5636\n",
      "Epoch [66/100], Step [36500/6235], Loss: 8.8951\n",
      "Epoch [66/100], Step [36600/6235], Loss: 0.1345\n",
      "Epoch [66/100], Step [36700/6235], Loss: 0.4101\n",
      "Epoch [66/100], Step [36800/6235], Loss: 11.7229\n",
      "Epoch [66/100], Step [36900/6235], Loss: 8.6127\n",
      "Epoch [66/100], Step [37000/6235], Loss: 0.5900\n",
      "Epoch [66/100], Step [37100/6235], Loss: 1.2666\n",
      "Epoch [66/100], Step [37200/6235], Loss: 0.0763\n",
      "Epoch [66/100], Step [37300/6235], Loss: 0.0354\n",
      "Epoch [66/100], Step [37400/6235], Loss: 0.2011\n",
      "Epoch [66/100], Step [37500/6235], Loss: 5.0995\n",
      "Epoch [66/100], Step [37600/6235], Loss: 11.8940\n",
      "Epoch [66/100], Step [37700/6235], Loss: 1.9611\n",
      "Epoch [66/100], Step [37800/6235], Loss: 3.5263\n",
      "Epoch [66/100], Step [37900/6235], Loss: 4.3789\n",
      "Epoch [66/100], Step [38000/6235], Loss: 0.9276\n",
      "Epoch [66/100], Step [38100/6235], Loss: 4.1765\n",
      "Epoch [66/100], Step [38200/6235], Loss: 2.0886\n",
      "Epoch [66/100], Step [38300/6235], Loss: 0.4540\n",
      "Epoch [66/100], Step [38400/6235], Loss: 0.0767\n",
      "Epoch [66/100], Step [38500/6235], Loss: 1.9296\n",
      "Epoch [66/100], Step [38600/6235], Loss: 0.1197\n",
      "Epoch [66/100], Step [38700/6235], Loss: 0.1634\n",
      "Epoch [66/100], Step [38800/6235], Loss: 0.2076\n",
      "Epoch [66/100], Step [38900/6235], Loss: 1.6073\n",
      "Epoch [66/100], Step [39000/6235], Loss: 1.4494\n",
      "Epoch [66/100], Step [39100/6235], Loss: 9.5176\n",
      "Epoch [66/100], Step [39200/6235], Loss: 0.6019\n",
      "Epoch [66/100], Step [39300/6235], Loss: 116.2514\n",
      "Epoch [66/100], Step [39400/6235], Loss: 177.3843\n",
      "Epoch [66/100], Step [39500/6235], Loss: 276.3694\n",
      "Epoch [66/100], Step [39600/6235], Loss: 15.0075\n",
      "Epoch [66/100], Step [39700/6235], Loss: 444.3631\n",
      "Epoch [66/100], Step [39800/6235], Loss: 192.8795\n",
      "Epoch [66/100], Step [39900/6235], Loss: 0.4704\n",
      "Epoch [66/100], Step [40000/6235], Loss: 17.5580\n",
      "Epoch [66/100], Step [40100/6235], Loss: 26.4002\n",
      "Epoch [66/100], Step [40200/6235], Loss: 2.2944\n",
      "Epoch [66/100], Step [40300/6235], Loss: 0.9778\n",
      "Epoch [66/100], Step [40400/6235], Loss: 2.8309\n",
      "Epoch [66/100], Step [40500/6235], Loss: 2.1908\n",
      "Epoch [66/100], Step [40600/6235], Loss: 0.3862\n",
      "Epoch [66/100], Step [40700/6235], Loss: 7.5922\n",
      "Epoch [66/100], Step [40800/6235], Loss: 1.7051\n",
      "Epoch [66/100], Step [40900/6235], Loss: 0.0671\n",
      "Epoch [66/100], Step [41000/6235], Loss: 46.8745\n",
      "Epoch [66/100], Step [41100/6235], Loss: 3.7095\n",
      "Epoch [66/100], Step [41200/6235], Loss: 16.3367\n",
      "Epoch [66/100], Step [41300/6235], Loss: 2.6610\n",
      "Epoch [66/100], Step [41400/6235], Loss: 0.9059\n",
      "Epoch [66/100], Step [41500/6235], Loss: 0.7132\n",
      "Epoch [66/100], Step [41600/6235], Loss: 0.7107\n",
      "Epoch [66/100], Step [41700/6235], Loss: 1.7722\n",
      "Epoch [66/100], Step [41800/6235], Loss: 0.0218\n",
      "Epoch [66/100], Step [41900/6235], Loss: 2.7926\n",
      "Epoch [66/100], Step [42000/6235], Loss: 2.5201\n",
      "Epoch [66/100], Step [42100/6235], Loss: 6.0437\n",
      "Epoch [66/100], Step [42200/6235], Loss: 0.6791\n",
      "Epoch [66/100], Step [42300/6235], Loss: 6.2708\n",
      "Epoch [66/100], Step [42400/6235], Loss: 0.2647\n",
      "Epoch [66/100], Step [42500/6235], Loss: 1.2188\n",
      "Epoch [66/100], Step [42600/6235], Loss: 0.5702\n",
      "Epoch [66/100], Step [42700/6235], Loss: 0.2612\n",
      "Epoch [66/100], Step [42800/6235], Loss: 0.4252\n",
      "Epoch [66/100], Step [42900/6235], Loss: 4.1891\n",
      "Epoch [66/100], Step [43000/6235], Loss: 0.2032\n",
      "Epoch [66/100], Step [43100/6235], Loss: 1.1309\n",
      "Epoch [66/100], Step [43200/6235], Loss: 0.6759\n",
      "Epoch [66/100], Step [43300/6235], Loss: 9.5643\n",
      "Epoch [66/100], Step [43400/6235], Loss: 10.1456\n",
      "Epoch [66/100], Step [43500/6235], Loss: 9.2360\n",
      "Epoch [66/100], Step [43600/6235], Loss: 23.1575\n",
      "Epoch [66/100], Step [43700/6235], Loss: 11.1405\n",
      "Epoch [66/100], Step [43800/6235], Loss: 8.7438\n",
      "Epoch [66/100], Step [43900/6235], Loss: 4.5522\n",
      "Epoch [66/100], Step [44000/6235], Loss: 55.9990\n",
      "Epoch [66/100], Step [44100/6235], Loss: 0.1508\n",
      "Epoch [66/100], Step [44200/6235], Loss: 6.0664\n",
      "Epoch [66/100], Step [44300/6235], Loss: 12.0234\n",
      "Epoch [66/100], Step [44400/6235], Loss: 4.2151\n",
      "Epoch [66/100], Step [44500/6235], Loss: 1.3637\n",
      "Epoch [66/100], Step [44600/6235], Loss: 16.4998\n",
      "Epoch [66/100], Step [44700/6235], Loss: 2.5600\n",
      "Epoch [66/100], Step [44800/6235], Loss: 3.0928\n",
      "Epoch [66/100], Step [44900/6235], Loss: 2.8663\n",
      "Epoch [66/100], Step [45000/6235], Loss: 5.0096\n",
      "Epoch [66/100], Step [45100/6235], Loss: 4.3452\n",
      "Epoch [66/100], Step [45200/6235], Loss: 2.1893\n",
      "Epoch [66/100], Step [45300/6235], Loss: 41.5113\n",
      "Epoch [66/100], Step [45400/6235], Loss: 13.3033\n",
      "Epoch [66/100], Step [45500/6235], Loss: 0.5262\n",
      "Epoch [66/100], Step [45600/6235], Loss: 0.3606\n",
      "Epoch [66/100], Step [45700/6235], Loss: 56.0192\n",
      "Epoch [66/100], Step [45800/6235], Loss: 492.1199\n",
      "Epoch [66/100], Step [45900/6235], Loss: 6.0095\n",
      "Epoch [66/100], Step [46000/6235], Loss: 14.1446\n",
      "Epoch [66/100], Step [46100/6235], Loss: 20.3640\n",
      "Epoch [66/100], Step [46200/6235], Loss: 48.5355\n",
      "Epoch [66/100], Step [46300/6235], Loss: 30.1634\n",
      "Epoch [66/100], Step [46400/6235], Loss: 9.6802\n",
      "Epoch [66/100], Step [46500/6235], Loss: 11.9912\n",
      "Epoch [66/100], Step [46600/6235], Loss: 15.0718\n",
      "Epoch [66/100], Step [46700/6235], Loss: 4.0746\n",
      "Epoch [66/100], Step [46800/6235], Loss: 22.3487\n",
      "Epoch [66/100], Step [46900/6235], Loss: 11.6712\n",
      "Epoch [66/100], Step [47000/6235], Loss: 2.8828\n",
      "Epoch [66/100], Step [47100/6235], Loss: 15.3798\n",
      "Epoch [66/100], Step [47200/6235], Loss: 54.3327\n",
      "Epoch [66/100], Step [47300/6235], Loss: 0.7208\n",
      "Epoch [66/100], Step [47400/6235], Loss: 486.1068\n",
      "Epoch [66/100], Step [47500/6235], Loss: 4.9371\n",
      "Epoch [66/100], Step [47600/6235], Loss: 14.3492\n",
      "Epoch [66/100], Step [47700/6235], Loss: 58.7011\n",
      "Epoch [66/100], Step [47800/6235], Loss: 11.3133\n",
      "Epoch [66/100], Step [47900/6235], Loss: 11.4121\n",
      "Epoch [66/100], Step [48000/6235], Loss: 103.2624\n",
      "Epoch [66/100], Step [48100/6235], Loss: 8.4930\n",
      "Epoch [66/100], Step [48200/6235], Loss: 103.9518\n",
      "Epoch [66/100], Step [48300/6235], Loss: 620.4860\n",
      "Epoch [66/100], Step [48400/6235], Loss: 4.1040\n",
      "Epoch [66/100], Step [48500/6235], Loss: 8.4919\n",
      "Epoch [66/100], Step [48600/6235], Loss: 7.3608\n",
      "Epoch [66/100], Step [48700/6235], Loss: 3.7041\n",
      "Epoch [66/100], Step [48800/6235], Loss: 536.3306\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [66/100], Step [48900/6235], Loss: 733.3642\n",
      "Epoch [66/100], Step [49000/6235], Loss: 163.7602\n",
      "Epoch [66/100], Step [49100/6235], Loss: 4484.7471\n",
      "Epoch [66/100], Step [49200/6235], Loss: 316.2787\n",
      "Epoch [66/100], Step [49300/6235], Loss: 343.5692\n",
      "Epoch [66/100], Step [49400/6235], Loss: 16.1964\n",
      "Epoch [66/100], Step [49500/6235], Loss: 20.3646\n",
      "Epoch [66/100], Step [49600/6235], Loss: 24.5867\n",
      "Epoch [66/100], Step [49700/6235], Loss: 248.2024\n",
      "Epoch [66/100], Step [49800/6235], Loss: 153.0702\n",
      "Epoch [67/100], Step [100/6235], Loss: 14.2382\n",
      "Epoch [67/100], Step [200/6235], Loss: 0.1905\n",
      "Epoch [67/100], Step [300/6235], Loss: 0.0119\n",
      "Epoch [67/100], Step [400/6235], Loss: 0.0030\n",
      "Epoch [67/100], Step [500/6235], Loss: 0.6607\n",
      "Epoch [67/100], Step [600/6235], Loss: 0.0449\n",
      "Epoch [67/100], Step [700/6235], Loss: 0.5890\n",
      "Epoch [67/100], Step [800/6235], Loss: 0.1145\n",
      "Epoch [67/100], Step [900/6235], Loss: 0.0342\n",
      "Epoch [67/100], Step [1000/6235], Loss: 0.0381\n",
      "Epoch [67/100], Step [1100/6235], Loss: 0.0190\n",
      "Epoch [67/100], Step [1200/6235], Loss: 0.1996\n",
      "Epoch [67/100], Step [1300/6235], Loss: 0.0314\n",
      "Epoch [67/100], Step [1400/6235], Loss: 0.0463\n",
      "Epoch [67/100], Step [1500/6235], Loss: 0.0069\n",
      "Epoch [67/100], Step [1600/6235], Loss: 0.2413\n",
      "Epoch [67/100], Step [1700/6235], Loss: 0.0137\n",
      "Epoch [67/100], Step [1800/6235], Loss: 0.2138\n",
      "Epoch [67/100], Step [1900/6235], Loss: 0.4691\n",
      "Epoch [67/100], Step [2000/6235], Loss: 2.3606\n",
      "Epoch [67/100], Step [2100/6235], Loss: 2.4820\n",
      "Epoch [67/100], Step [2200/6235], Loss: 8.4539\n",
      "Epoch [67/100], Step [2300/6235], Loss: 6.0637\n",
      "Epoch [67/100], Step [2400/6235], Loss: 1.2223\n",
      "Epoch [67/100], Step [2500/6235], Loss: 32.6114\n",
      "Epoch [67/100], Step [2600/6235], Loss: 13.3899\n",
      "Epoch [67/100], Step [2700/6235], Loss: 9.4359\n",
      "Epoch [67/100], Step [2800/6235], Loss: 89.2688\n",
      "Epoch [67/100], Step [2900/6235], Loss: 19.6034\n",
      "Epoch [67/100], Step [3000/6235], Loss: 1.4072\n",
      "Epoch [67/100], Step [3100/6235], Loss: 63.4307\n",
      "Epoch [67/100], Step [3200/6235], Loss: 47.8395\n",
      "Epoch [67/100], Step [3300/6235], Loss: 11.7454\n",
      "Epoch [67/100], Step [3400/6235], Loss: 3.2904\n",
      "Epoch [67/100], Step [3500/6235], Loss: 51.9244\n",
      "Epoch [67/100], Step [3600/6235], Loss: 2.4238\n",
      "Epoch [67/100], Step [3700/6235], Loss: 0.0458\n",
      "Epoch [67/100], Step [3800/6235], Loss: 0.0717\n",
      "Epoch [67/100], Step [3900/6235], Loss: 0.0710\n",
      "Epoch [67/100], Step [4000/6235], Loss: 0.1203\n",
      "Epoch [67/100], Step [4100/6235], Loss: 9.7646\n",
      "Epoch [67/100], Step [4200/6235], Loss: 2.8996\n",
      "Epoch [67/100], Step [4300/6235], Loss: 7.2616\n",
      "Epoch [67/100], Step [4400/6235], Loss: 0.7617\n",
      "Epoch [67/100], Step [4500/6235], Loss: 36.6934\n",
      "Epoch [67/100], Step [4600/6235], Loss: 3.0357\n",
      "Epoch [67/100], Step [4700/6235], Loss: 0.1802\n",
      "Epoch [67/100], Step [4800/6235], Loss: 9.0442\n",
      "Epoch [67/100], Step [4900/6235], Loss: 0.4366\n",
      "Epoch [67/100], Step [5000/6235], Loss: 0.0491\n",
      "Epoch [67/100], Step [5100/6235], Loss: 0.7806\n",
      "Epoch [67/100], Step [5200/6235], Loss: 3.6829\n",
      "Epoch [67/100], Step [5300/6235], Loss: 32.2972\n",
      "Epoch [67/100], Step [5400/6235], Loss: 0.5658\n",
      "Epoch [67/100], Step [5500/6235], Loss: 0.1574\n",
      "Epoch [67/100], Step [5600/6235], Loss: 0.3122\n",
      "Epoch [67/100], Step [5700/6235], Loss: 0.2138\n",
      "Epoch [67/100], Step [5800/6235], Loss: 0.2522\n",
      "Epoch [67/100], Step [5900/6235], Loss: 0.2163\n",
      "Epoch [67/100], Step [6000/6235], Loss: 0.8027\n",
      "Epoch [67/100], Step [6100/6235], Loss: 0.2093\n",
      "Epoch [67/100], Step [6200/6235], Loss: 5.5132\n",
      "Epoch [67/100], Step [6300/6235], Loss: 0.2636\n",
      "Epoch [67/100], Step [6400/6235], Loss: 0.0418\n",
      "Epoch [67/100], Step [6500/6235], Loss: 2.9332\n",
      "Epoch [67/100], Step [6600/6235], Loss: 14.6867\n",
      "Epoch [67/100], Step [6700/6235], Loss: 1.0086\n",
      "Epoch [67/100], Step [6800/6235], Loss: 0.2758\n",
      "Epoch [67/100], Step [6900/6235], Loss: 0.3180\n",
      "Epoch [67/100], Step [7000/6235], Loss: 0.1853\n",
      "Epoch [67/100], Step [7100/6235], Loss: 0.3581\n",
      "Epoch [67/100], Step [7200/6235], Loss: 0.0941\n",
      "Epoch [67/100], Step [7300/6235], Loss: 1.2161\n",
      "Epoch [67/100], Step [7400/6235], Loss: 0.0133\n",
      "Epoch [67/100], Step [7500/6235], Loss: 1.0120\n",
      "Epoch [67/100], Step [7600/6235], Loss: 4.9817\n",
      "Epoch [67/100], Step [7700/6235], Loss: 8.0884\n",
      "Epoch [67/100], Step [7800/6235], Loss: 3.0973\n",
      "Epoch [67/100], Step [7900/6235], Loss: 6.7390\n",
      "Epoch [67/100], Step [8000/6235], Loss: 0.5754\n",
      "Epoch [67/100], Step [8100/6235], Loss: 0.4474\n",
      "Epoch [67/100], Step [8200/6235], Loss: 10.4309\n",
      "Epoch [67/100], Step [8300/6235], Loss: 16.9810\n",
      "Epoch [67/100], Step [8400/6235], Loss: 619.5349\n",
      "Epoch [67/100], Step [8500/6235], Loss: 19.1559\n",
      "Epoch [67/100], Step [8600/6235], Loss: 20.8632\n",
      "Epoch [67/100], Step [8700/6235], Loss: 46.5799\n",
      "Epoch [67/100], Step [8800/6235], Loss: 381.7221\n",
      "Epoch [67/100], Step [8900/6235], Loss: 295.5170\n",
      "Epoch [67/100], Step [9000/6235], Loss: 247.4751\n",
      "Epoch [67/100], Step [9100/6235], Loss: 880.1379\n",
      "Epoch [67/100], Step [9200/6235], Loss: 648.0978\n",
      "Epoch [67/100], Step [9300/6235], Loss: 375.5535\n",
      "Epoch [67/100], Step [9400/6235], Loss: 434.4018\n",
      "Epoch [67/100], Step [9500/6235], Loss: 2316.5750\n",
      "Epoch [67/100], Step [9600/6235], Loss: 814.0774\n",
      "Epoch [67/100], Step [9700/6235], Loss: 2.5913\n",
      "Epoch [67/100], Step [9800/6235], Loss: 5265.5366\n",
      "Epoch [67/100], Step [9900/6235], Loss: 51.3788\n",
      "Epoch [67/100], Step [10000/6235], Loss: 210.3570\n",
      "Epoch [67/100], Step [10100/6235], Loss: 3.8416\n",
      "Epoch [67/100], Step [10200/6235], Loss: 472.6868\n",
      "Epoch [67/100], Step [10300/6235], Loss: 20.1034\n",
      "Epoch [67/100], Step [10400/6235], Loss: 8.7606\n",
      "Epoch [67/100], Step [10500/6235], Loss: 4.4762\n",
      "Epoch [67/100], Step [10600/6235], Loss: 39.2141\n",
      "Epoch [67/100], Step [10700/6235], Loss: 22.5597\n",
      "Epoch [67/100], Step [10800/6235], Loss: 32.3891\n",
      "Epoch [67/100], Step [10900/6235], Loss: 1.9125\n",
      "Epoch [67/100], Step [11000/6235], Loss: 296.6622\n",
      "Epoch [67/100], Step [11100/6235], Loss: 31.3910\n",
      "Epoch [67/100], Step [11200/6235], Loss: 42.2207\n",
      "Epoch [67/100], Step [11300/6235], Loss: 149.8071\n",
      "Epoch [67/100], Step [11400/6235], Loss: 5.4623\n",
      "Epoch [67/100], Step [11500/6235], Loss: 7.2130\n",
      "Epoch [67/100], Step [11600/6235], Loss: 4.4044\n",
      "Epoch [67/100], Step [11700/6235], Loss: 43.4287\n",
      "Epoch [67/100], Step [11800/6235], Loss: 393.2858\n",
      "Epoch [67/100], Step [11900/6235], Loss: 451.6243\n",
      "Epoch [67/100], Step [12000/6235], Loss: 431.5650\n",
      "Epoch [67/100], Step [12100/6235], Loss: 163.9119\n",
      "Epoch [67/100], Step [12200/6235], Loss: 181.2634\n",
      "Epoch [67/100], Step [12300/6235], Loss: 47.3019\n",
      "Epoch [67/100], Step [12400/6235], Loss: 592.7404\n",
      "Epoch [67/100], Step [12500/6235], Loss: 14.9421\n",
      "Epoch [67/100], Step [12600/6235], Loss: 75.8658\n",
      "Epoch [67/100], Step [12700/6235], Loss: 4.6699\n",
      "Epoch [67/100], Step [12800/6235], Loss: 10.6625\n",
      "Epoch [67/100], Step [12900/6235], Loss: 45.4885\n",
      "Epoch [67/100], Step [13000/6235], Loss: 1.3636\n",
      "Epoch [67/100], Step [13100/6235], Loss: 72.1086\n",
      "Epoch [67/100], Step [13200/6235], Loss: 12.0843\n",
      "Epoch [67/100], Step [13300/6235], Loss: 33.7138\n",
      "Epoch [67/100], Step [13400/6235], Loss: 253.1647\n",
      "Epoch [67/100], Step [13500/6235], Loss: 2.6394\n",
      "Epoch [67/100], Step [13600/6235], Loss: 0.2006\n",
      "Epoch [67/100], Step [13700/6235], Loss: 56.6713\n",
      "Epoch [67/100], Step [13800/6235], Loss: 164.5028\n",
      "Epoch [67/100], Step [13900/6235], Loss: 57.4532\n",
      "Epoch [67/100], Step [14000/6235], Loss: 13.8746\n",
      "Epoch [67/100], Step [14100/6235], Loss: 33.1218\n",
      "Epoch [67/100], Step [14200/6235], Loss: 73.0763\n",
      "Epoch [67/100], Step [14300/6235], Loss: 42.2332\n",
      "Epoch [67/100], Step [14400/6235], Loss: 39.0471\n",
      "Epoch [67/100], Step [14500/6235], Loss: 39.9828\n",
      "Epoch [67/100], Step [14600/6235], Loss: 0.1700\n",
      "Epoch [67/100], Step [14700/6235], Loss: 43.8123\n",
      "Epoch [67/100], Step [14800/6235], Loss: 33.1986\n",
      "Epoch [67/100], Step [14900/6235], Loss: 0.8521\n",
      "Epoch [67/100], Step [15000/6235], Loss: 1.9103\n",
      "Epoch [67/100], Step [15100/6235], Loss: 0.4771\n",
      "Epoch [67/100], Step [15200/6235], Loss: 6.2817\n",
      "Epoch [67/100], Step [15300/6235], Loss: 35.5869\n",
      "Epoch [67/100], Step [15400/6235], Loss: 64.1786\n",
      "Epoch [67/100], Step [15500/6235], Loss: 9.8106\n",
      "Epoch [67/100], Step [15600/6235], Loss: 3.8878\n",
      "Epoch [67/100], Step [15700/6235], Loss: 3.5468\n",
      "Epoch [67/100], Step [15800/6235], Loss: 3.3140\n",
      "Epoch [67/100], Step [15900/6235], Loss: 0.7958\n",
      "Epoch [67/100], Step [16000/6235], Loss: 132.9164\n",
      "Epoch [67/100], Step [16100/6235], Loss: 17.0316\n",
      "Epoch [67/100], Step [16200/6235], Loss: 0.3972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Step [16300/6235], Loss: 11.5181\n",
      "Epoch [67/100], Step [16400/6235], Loss: 40.3865\n",
      "Epoch [67/100], Step [16500/6235], Loss: 155.1809\n",
      "Epoch [67/100], Step [16600/6235], Loss: 6.8069\n",
      "Epoch [67/100], Step [16700/6235], Loss: 0.8379\n",
      "Epoch [67/100], Step [16800/6235], Loss: 8.9449\n",
      "Epoch [67/100], Step [16900/6235], Loss: 0.1607\n",
      "Epoch [67/100], Step [17000/6235], Loss: 0.2533\n",
      "Epoch [67/100], Step [17100/6235], Loss: 0.6730\n",
      "Epoch [67/100], Step [17200/6235], Loss: 311.2197\n",
      "Epoch [67/100], Step [17300/6235], Loss: 28.7109\n",
      "Epoch [67/100], Step [17400/6235], Loss: 31.8508\n",
      "Epoch [67/100], Step [17500/6235], Loss: 0.6924\n",
      "Epoch [67/100], Step [17600/6235], Loss: 4.1784\n",
      "Epoch [67/100], Step [17700/6235], Loss: 1.2323\n",
      "Epoch [67/100], Step [17800/6235], Loss: 25.9610\n",
      "Epoch [67/100], Step [17900/6235], Loss: 3.3694\n",
      "Epoch [67/100], Step [18000/6235], Loss: 0.6493\n",
      "Epoch [67/100], Step [18100/6235], Loss: 15.4065\n",
      "Epoch [67/100], Step [18200/6235], Loss: 0.3144\n",
      "Epoch [67/100], Step [18300/6235], Loss: 1.8241\n",
      "Epoch [67/100], Step [18400/6235], Loss: 0.4899\n",
      "Epoch [67/100], Step [18500/6235], Loss: 19.4107\n",
      "Epoch [67/100], Step [18600/6235], Loss: 3.3250\n",
      "Epoch [67/100], Step [18700/6235], Loss: 0.6923\n",
      "Epoch [67/100], Step [18800/6235], Loss: 113.9762\n",
      "Epoch [67/100], Step [18900/6235], Loss: 34.1957\n",
      "Epoch [67/100], Step [19000/6235], Loss: 4.8189\n",
      "Epoch [67/100], Step [19100/6235], Loss: 3.2157\n",
      "Epoch [67/100], Step [19200/6235], Loss: 3.9113\n",
      "Epoch [67/100], Step [19300/6235], Loss: 9.8201\n",
      "Epoch [67/100], Step [19400/6235], Loss: 126.5024\n",
      "Epoch [67/100], Step [19500/6235], Loss: 179.6836\n",
      "Epoch [67/100], Step [19600/6235], Loss: 115.9043\n",
      "Epoch [67/100], Step [19700/6235], Loss: 2.6322\n",
      "Epoch [67/100], Step [19800/6235], Loss: 1.1376\n",
      "Epoch [67/100], Step [19900/6235], Loss: 0.6657\n",
      "Epoch [67/100], Step [20000/6235], Loss: 89.4453\n",
      "Epoch [67/100], Step [20100/6235], Loss: 4.9676\n",
      "Epoch [67/100], Step [20200/6235], Loss: 2.7878\n",
      "Epoch [67/100], Step [20300/6235], Loss: 1.0479\n",
      "Epoch [67/100], Step [20400/6235], Loss: 25.3434\n",
      "Epoch [67/100], Step [20500/6235], Loss: 36.7544\n",
      "Epoch [67/100], Step [20600/6235], Loss: 89.1548\n",
      "Epoch [67/100], Step [20700/6235], Loss: 25.2390\n",
      "Epoch [67/100], Step [20800/6235], Loss: 0.2119\n",
      "Epoch [67/100], Step [20900/6235], Loss: 35.2471\n",
      "Epoch [67/100], Step [21000/6235], Loss: 13.6048\n",
      "Epoch [67/100], Step [21100/6235], Loss: 6.5092\n",
      "Epoch [67/100], Step [21200/6235], Loss: 0.2528\n",
      "Epoch [67/100], Step [21300/6235], Loss: 0.2127\n",
      "Epoch [67/100], Step [21400/6235], Loss: 6.2664\n",
      "Epoch [67/100], Step [21500/6235], Loss: 0.5929\n",
      "Epoch [67/100], Step [21600/6235], Loss: 29.4832\n",
      "Epoch [67/100], Step [21700/6235], Loss: 0.3944\n",
      "Epoch [67/100], Step [21800/6235], Loss: 2.7404\n",
      "Epoch [67/100], Step [21900/6235], Loss: 1.3254\n",
      "Epoch [67/100], Step [22000/6235], Loss: 6.8520\n",
      "Epoch [67/100], Step [22100/6235], Loss: 0.9237\n",
      "Epoch [67/100], Step [22200/6235], Loss: 3.9722\n",
      "Epoch [67/100], Step [22300/6235], Loss: 0.8987\n",
      "Epoch [67/100], Step [22400/6235], Loss: 15.8168\n",
      "Epoch [67/100], Step [22500/6235], Loss: 108.5758\n",
      "Epoch [67/100], Step [22600/6235], Loss: 12.1814\n",
      "Epoch [67/100], Step [22700/6235], Loss: 0.8409\n",
      "Epoch [67/100], Step [22800/6235], Loss: 4.4823\n",
      "Epoch [67/100], Step [22900/6235], Loss: 1.7378\n",
      "Epoch [67/100], Step [23000/6235], Loss: 11.5874\n",
      "Epoch [67/100], Step [23100/6235], Loss: 6.4758\n",
      "Epoch [67/100], Step [23200/6235], Loss: 11.7967\n",
      "Epoch [67/100], Step [23300/6235], Loss: 17.0932\n",
      "Epoch [67/100], Step [23400/6235], Loss: 2.1180\n",
      "Epoch [67/100], Step [23500/6235], Loss: 0.0506\n",
      "Epoch [67/100], Step [23600/6235], Loss: 122.9907\n",
      "Epoch [67/100], Step [23700/6235], Loss: 4.4052\n",
      "Epoch [67/100], Step [23800/6235], Loss: 1.0897\n",
      "Epoch [67/100], Step [23900/6235], Loss: 4.9697\n",
      "Epoch [67/100], Step [24000/6235], Loss: 0.1558\n",
      "Epoch [67/100], Step [24100/6235], Loss: 0.0897\n",
      "Epoch [67/100], Step [24200/6235], Loss: 20.5262\n",
      "Epoch [67/100], Step [24300/6235], Loss: 1.0918\n",
      "Epoch [67/100], Step [24400/6235], Loss: 3.5056\n",
      "Epoch [67/100], Step [24500/6235], Loss: 1.4394\n",
      "Epoch [67/100], Step [24600/6235], Loss: 0.1213\n",
      "Epoch [67/100], Step [24700/6235], Loss: 3.5622\n",
      "Epoch [67/100], Step [24800/6235], Loss: 0.1721\n",
      "Epoch [67/100], Step [24900/6235], Loss: 15.9716\n",
      "Epoch [67/100], Step [25000/6235], Loss: 17.6632\n",
      "Epoch [67/100], Step [25100/6235], Loss: 8.7978\n",
      "Epoch [67/100], Step [25200/6235], Loss: 1.0863\n",
      "Epoch [67/100], Step [25300/6235], Loss: 0.5480\n",
      "Epoch [67/100], Step [25400/6235], Loss: 8.9924\n",
      "Epoch [67/100], Step [25500/6235], Loss: 7.9568\n",
      "Epoch [67/100], Step [25600/6235], Loss: 4.9511\n",
      "Epoch [67/100], Step [25700/6235], Loss: 0.3152\n",
      "Epoch [67/100], Step [25800/6235], Loss: 0.0948\n",
      "Epoch [67/100], Step [25900/6235], Loss: 7.5935\n",
      "Epoch [67/100], Step [26000/6235], Loss: 0.7399\n",
      "Epoch [67/100], Step [26100/6235], Loss: 0.1005\n",
      "Epoch [67/100], Step [26200/6235], Loss: 0.8210\n",
      "Epoch [67/100], Step [26300/6235], Loss: 4.2160\n",
      "Epoch [67/100], Step [26400/6235], Loss: 0.0852\n",
      "Epoch [67/100], Step [26500/6235], Loss: 0.0254\n",
      "Epoch [67/100], Step [26600/6235], Loss: 1.6883\n",
      "Epoch [67/100], Step [26700/6235], Loss: 0.4083\n",
      "Epoch [67/100], Step [26800/6235], Loss: 0.2376\n",
      "Epoch [67/100], Step [26900/6235], Loss: 0.0009\n",
      "Epoch [67/100], Step [27000/6235], Loss: 14.8118\n",
      "Epoch [67/100], Step [27100/6235], Loss: 0.0482\n",
      "Epoch [67/100], Step [27200/6235], Loss: 0.0244\n",
      "Epoch [67/100], Step [27300/6235], Loss: 0.2291\n",
      "Epoch [67/100], Step [27400/6235], Loss: 0.7922\n",
      "Epoch [67/100], Step [27500/6235], Loss: 24.9384\n",
      "Epoch [67/100], Step [27600/6235], Loss: 1.1923\n",
      "Epoch [67/100], Step [27700/6235], Loss: 1.2837\n",
      "Epoch [67/100], Step [27800/6235], Loss: 7.3181\n",
      "Epoch [67/100], Step [27900/6235], Loss: 1.3986\n",
      "Epoch [67/100], Step [28000/6235], Loss: 154.7455\n",
      "Epoch [67/100], Step [28100/6235], Loss: 1.1567\n",
      "Epoch [67/100], Step [28200/6235], Loss: 30.0819\n",
      "Epoch [67/100], Step [28300/6235], Loss: 3.0648\n",
      "Epoch [67/100], Step [28400/6235], Loss: 25.2572\n",
      "Epoch [67/100], Step [28500/6235], Loss: 1.7283\n",
      "Epoch [67/100], Step [28600/6235], Loss: 0.1663\n",
      "Epoch [67/100], Step [28700/6235], Loss: 5.2043\n",
      "Epoch [67/100], Step [28800/6235], Loss: 0.5018\n",
      "Epoch [67/100], Step [28900/6235], Loss: 72.1078\n",
      "Epoch [67/100], Step [29000/6235], Loss: 9.6161\n",
      "Epoch [67/100], Step [29100/6235], Loss: 0.0803\n",
      "Epoch [67/100], Step [29200/6235], Loss: 0.4505\n",
      "Epoch [67/100], Step [29300/6235], Loss: 14.4953\n",
      "Epoch [67/100], Step [29400/6235], Loss: 0.1567\n",
      "Epoch [67/100], Step [29500/6235], Loss: 4.9717\n",
      "Epoch [67/100], Step [29600/6235], Loss: 0.6664\n",
      "Epoch [67/100], Step [29700/6235], Loss: 0.8024\n",
      "Epoch [67/100], Step [29800/6235], Loss: 1.7228\n",
      "Epoch [67/100], Step [29900/6235], Loss: 0.4588\n",
      "Epoch [67/100], Step [30000/6235], Loss: 4.8000\n",
      "Epoch [67/100], Step [30100/6235], Loss: 1.1349\n",
      "Epoch [67/100], Step [30200/6235], Loss: 0.3748\n",
      "Epoch [67/100], Step [30300/6235], Loss: 0.7805\n",
      "Epoch [67/100], Step [30400/6235], Loss: 0.5156\n",
      "Epoch [67/100], Step [30500/6235], Loss: 2.7861\n",
      "Epoch [67/100], Step [30600/6235], Loss: 1.1124\n",
      "Epoch [67/100], Step [30700/6235], Loss: 0.0155\n",
      "Epoch [67/100], Step [30800/6235], Loss: 0.3323\n",
      "Epoch [67/100], Step [30900/6235], Loss: 3.4962\n",
      "Epoch [67/100], Step [31000/6235], Loss: 0.0114\n",
      "Epoch [67/100], Step [31100/6235], Loss: 0.0770\n",
      "Epoch [67/100], Step [31200/6235], Loss: 5.8295\n",
      "Epoch [67/100], Step [31300/6235], Loss: 1.4987\n",
      "Epoch [67/100], Step [31400/6235], Loss: 8.2100\n",
      "Epoch [67/100], Step [31500/6235], Loss: 1.4136\n",
      "Epoch [67/100], Step [31600/6235], Loss: 6.0687\n",
      "Epoch [67/100], Step [31700/6235], Loss: 1.7119\n",
      "Epoch [67/100], Step [31800/6235], Loss: 2.7415\n",
      "Epoch [67/100], Step [31900/6235], Loss: 52.8243\n",
      "Epoch [67/100], Step [32000/6235], Loss: 65.0519\n",
      "Epoch [67/100], Step [32100/6235], Loss: 2.7085\n",
      "Epoch [67/100], Step [32200/6235], Loss: 50.3793\n",
      "Epoch [67/100], Step [32300/6235], Loss: 0.5281\n",
      "Epoch [67/100], Step [32400/6235], Loss: 0.4356\n",
      "Epoch [67/100], Step [32500/6235], Loss: 21.7775\n",
      "Epoch [67/100], Step [32600/6235], Loss: 0.8606\n",
      "Epoch [67/100], Step [32700/6235], Loss: 250.9139\n",
      "Epoch [67/100], Step [32800/6235], Loss: 1.7383\n",
      "Epoch [67/100], Step [32900/6235], Loss: 3.4984\n",
      "Epoch [67/100], Step [33000/6235], Loss: 0.3890\n",
      "Epoch [67/100], Step [33100/6235], Loss: 0.9320\n",
      "Epoch [67/100], Step [33200/6235], Loss: 1.2333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [67/100], Step [33300/6235], Loss: 1.6693\n",
      "Epoch [67/100], Step [33400/6235], Loss: 111.6405\n",
      "Epoch [67/100], Step [33500/6235], Loss: 1.6547\n",
      "Epoch [67/100], Step [33600/6235], Loss: 0.2959\n",
      "Epoch [67/100], Step [33700/6235], Loss: 1.5571\n",
      "Epoch [67/100], Step [33800/6235], Loss: 0.7014\n",
      "Epoch [67/100], Step [33900/6235], Loss: 29.0834\n",
      "Epoch [67/100], Step [34000/6235], Loss: 0.0467\n",
      "Epoch [67/100], Step [34100/6235], Loss: 0.4517\n",
      "Epoch [67/100], Step [34200/6235], Loss: 2.4705\n",
      "Epoch [67/100], Step [34300/6235], Loss: 4.5935\n",
      "Epoch [67/100], Step [34400/6235], Loss: 0.2178\n",
      "Epoch [67/100], Step [34500/6235], Loss: 35.0011\n",
      "Epoch [67/100], Step [34600/6235], Loss: 1.2067\n",
      "Epoch [67/100], Step [34700/6235], Loss: 16.2984\n",
      "Epoch [67/100], Step [34800/6235], Loss: 12.3552\n",
      "Epoch [67/100], Step [34900/6235], Loss: 67.9994\n",
      "Epoch [67/100], Step [35000/6235], Loss: 0.5423\n",
      "Epoch [67/100], Step [35100/6235], Loss: 0.5739\n",
      "Epoch [67/100], Step [35200/6235], Loss: 0.3086\n",
      "Epoch [67/100], Step [35300/6235], Loss: 2.9372\n",
      "Epoch [67/100], Step [35400/6235], Loss: 0.5259\n",
      "Epoch [67/100], Step [35500/6235], Loss: 1.4191\n",
      "Epoch [67/100], Step [35600/6235], Loss: 1.5413\n",
      "Epoch [67/100], Step [35700/6235], Loss: 5.0488\n",
      "Epoch [67/100], Step [35800/6235], Loss: 5.0716\n",
      "Epoch [67/100], Step [35900/6235], Loss: 4.3530\n",
      "Epoch [67/100], Step [36000/6235], Loss: 0.0699\n",
      "Epoch [67/100], Step [36100/6235], Loss: 0.0680\n",
      "Epoch [67/100], Step [36200/6235], Loss: 19.9497\n",
      "Epoch [67/100], Step [36300/6235], Loss: 1.6159\n",
      "Epoch [67/100], Step [36400/6235], Loss: 2.5216\n",
      "Epoch [67/100], Step [36500/6235], Loss: 8.1847\n",
      "Epoch [67/100], Step [36600/6235], Loss: 0.1421\n",
      "Epoch [67/100], Step [36700/6235], Loss: 0.5990\n",
      "Epoch [67/100], Step [36800/6235], Loss: 7.3934\n",
      "Epoch [67/100], Step [36900/6235], Loss: 8.2698\n",
      "Epoch [67/100], Step [37000/6235], Loss: 0.8062\n",
      "Epoch [67/100], Step [37100/6235], Loss: 1.4918\n",
      "Epoch [67/100], Step [37200/6235], Loss: 0.0593\n",
      "Epoch [67/100], Step [37300/6235], Loss: 0.0265\n",
      "Epoch [67/100], Step [37400/6235], Loss: 0.1900\n",
      "Epoch [67/100], Step [37500/6235], Loss: 6.1240\n",
      "Epoch [67/100], Step [37600/6235], Loss: 12.1902\n",
      "Epoch [67/100], Step [37700/6235], Loss: 2.2814\n",
      "Epoch [67/100], Step [37800/6235], Loss: 5.2930\n",
      "Epoch [67/100], Step [37900/6235], Loss: 5.8957\n",
      "Epoch [67/100], Step [38000/6235], Loss: 0.7297\n",
      "Epoch [67/100], Step [38100/6235], Loss: 4.6005\n",
      "Epoch [67/100], Step [38200/6235], Loss: 1.7333\n",
      "Epoch [67/100], Step [38300/6235], Loss: 0.1409\n",
      "Epoch [67/100], Step [38400/6235], Loss: 0.0501\n",
      "Epoch [67/100], Step [38500/6235], Loss: 1.6373\n",
      "Epoch [67/100], Step [38600/6235], Loss: 0.3043\n",
      "Epoch [67/100], Step [38700/6235], Loss: 0.0700\n",
      "Epoch [67/100], Step [38800/6235], Loss: 0.1342\n",
      "Epoch [67/100], Step [38900/6235], Loss: 12.6171\n",
      "Epoch [67/100], Step [39000/6235], Loss: 3.9665\n",
      "Epoch [67/100], Step [39100/6235], Loss: 14.3924\n",
      "Epoch [67/100], Step [39200/6235], Loss: 0.2838\n",
      "Epoch [67/100], Step [39300/6235], Loss: 36.2306\n",
      "Epoch [67/100], Step [39400/6235], Loss: 197.7513\n",
      "Epoch [67/100], Step [39500/6235], Loss: 291.1954\n",
      "Epoch [67/100], Step [39600/6235], Loss: 9.3910\n",
      "Epoch [67/100], Step [39700/6235], Loss: 27.8559\n",
      "Epoch [67/100], Step [39800/6235], Loss: 84.8099\n",
      "Epoch [67/100], Step [39900/6235], Loss: 3.5432\n",
      "Epoch [67/100], Step [40000/6235], Loss: 13.0037\n",
      "Epoch [67/100], Step [40100/6235], Loss: 21.0435\n",
      "Epoch [67/100], Step [40200/6235], Loss: 1.3862\n",
      "Epoch [67/100], Step [40300/6235], Loss: 1.4325\n",
      "Epoch [67/100], Step [40400/6235], Loss: 1.7216\n",
      "Epoch [67/100], Step [40500/6235], Loss: 2.4864\n",
      "Epoch [67/100], Step [40600/6235], Loss: 0.2158\n",
      "Epoch [67/100], Step [40700/6235], Loss: 7.3552\n",
      "Epoch [67/100], Step [40800/6235], Loss: 0.7805\n",
      "Epoch [67/100], Step [40900/6235], Loss: 0.3816\n",
      "Epoch [67/100], Step [41000/6235], Loss: 48.3145\n",
      "Epoch [67/100], Step [41100/6235], Loss: 15.3003\n",
      "Epoch [67/100], Step [41200/6235], Loss: 13.6924\n",
      "Epoch [67/100], Step [41300/6235], Loss: 2.9240\n",
      "Epoch [67/100], Step [41400/6235], Loss: 0.0301\n",
      "Epoch [67/100], Step [41500/6235], Loss: 0.7361\n",
      "Epoch [67/100], Step [41600/6235], Loss: 0.2618\n",
      "Epoch [67/100], Step [41700/6235], Loss: 1.0179\n",
      "Epoch [67/100], Step [41800/6235], Loss: 2.9893\n",
      "Epoch [67/100], Step [41900/6235], Loss: 4.1430\n",
      "Epoch [67/100], Step [42000/6235], Loss: 3.5374\n",
      "Epoch [67/100], Step [42100/6235], Loss: 7.7829\n",
      "Epoch [67/100], Step [42200/6235], Loss: 8.9448\n",
      "Epoch [67/100], Step [42300/6235], Loss: 0.8087\n",
      "Epoch [67/100], Step [42400/6235], Loss: 2.2121\n",
      "Epoch [67/100], Step [42500/6235], Loss: 4.5734\n",
      "Epoch [67/100], Step [42600/6235], Loss: 0.5336\n",
      "Epoch [67/100], Step [42700/6235], Loss: 0.2393\n",
      "Epoch [67/100], Step [42800/6235], Loss: 2.0512\n",
      "Epoch [67/100], Step [42900/6235], Loss: 4.1550\n",
      "Epoch [67/100], Step [43000/6235], Loss: 0.2471\n",
      "Epoch [67/100], Step [43100/6235], Loss: 0.8009\n",
      "Epoch [67/100], Step [43200/6235], Loss: 0.8503\n",
      "Epoch [67/100], Step [43300/6235], Loss: 9.3039\n",
      "Epoch [67/100], Step [43400/6235], Loss: 9.6461\n",
      "Epoch [67/100], Step [43500/6235], Loss: 9.0672\n",
      "Epoch [67/100], Step [43600/6235], Loss: 23.2819\n",
      "Epoch [67/100], Step [43700/6235], Loss: 38.4861\n",
      "Epoch [67/100], Step [43800/6235], Loss: 0.3363\n",
      "Epoch [67/100], Step [43900/6235], Loss: 0.4512\n",
      "Epoch [67/100], Step [44000/6235], Loss: 55.1150\n",
      "Epoch [67/100], Step [44100/6235], Loss: 3.7929\n",
      "Epoch [67/100], Step [44200/6235], Loss: 9.1299\n",
      "Epoch [67/100], Step [44300/6235], Loss: 9.8533\n",
      "Epoch [67/100], Step [44400/6235], Loss: 5.4938\n",
      "Epoch [67/100], Step [44500/6235], Loss: 1.7395\n",
      "Epoch [67/100], Step [44600/6235], Loss: 21.5605\n",
      "Epoch [67/100], Step [44700/6235], Loss: 2.4512\n",
      "Epoch [67/100], Step [44800/6235], Loss: 3.4111\n",
      "Epoch [67/100], Step [44900/6235], Loss: 2.1148\n",
      "Epoch [67/100], Step [45000/6235], Loss: 5.2032\n",
      "Epoch [67/100], Step [45100/6235], Loss: 16.9736\n",
      "Epoch [67/100], Step [45200/6235], Loss: 0.1241\n",
      "Epoch [67/100], Step [45300/6235], Loss: 38.5874\n",
      "Epoch [67/100], Step [45400/6235], Loss: 11.2275\n",
      "Epoch [67/100], Step [45500/6235], Loss: 0.1575\n",
      "Epoch [67/100], Step [45600/6235], Loss: 0.2005\n",
      "Epoch [67/100], Step [45700/6235], Loss: 30.7380\n",
      "Epoch [67/100], Step [45800/6235], Loss: 167.6059\n",
      "Epoch [67/100], Step [45900/6235], Loss: 25.1261\n",
      "Epoch [67/100], Step [46000/6235], Loss: 1.0525\n",
      "Epoch [67/100], Step [46100/6235], Loss: 11.4345\n",
      "Epoch [67/100], Step [46200/6235], Loss: 115.2935\n",
      "Epoch [67/100], Step [46300/6235], Loss: 74.6503\n",
      "Epoch [67/100], Step [46400/6235], Loss: 6.0974\n",
      "Epoch [67/100], Step [46500/6235], Loss: 4.8774\n",
      "Epoch [67/100], Step [46600/6235], Loss: 25.7994\n",
      "Epoch [67/100], Step [46700/6235], Loss: 1.8261\n",
      "Epoch [67/100], Step [46800/6235], Loss: 23.4371\n",
      "Epoch [67/100], Step [46900/6235], Loss: 20.6567\n",
      "Epoch [67/100], Step [47000/6235], Loss: 0.6942\n",
      "Epoch [67/100], Step [47100/6235], Loss: 47.6744\n",
      "Epoch [67/100], Step [47200/6235], Loss: 78.0217\n",
      "Epoch [67/100], Step [47300/6235], Loss: 0.7996\n",
      "Epoch [67/100], Step [47400/6235], Loss: 237.9227\n",
      "Epoch [67/100], Step [47500/6235], Loss: 18.4610\n",
      "Epoch [67/100], Step [47600/6235], Loss: 14.0041\n",
      "Epoch [67/100], Step [47700/6235], Loss: 12.8480\n",
      "Epoch [67/100], Step [47800/6235], Loss: 16.5313\n",
      "Epoch [67/100], Step [47900/6235], Loss: 15.8340\n",
      "Epoch [67/100], Step [48000/6235], Loss: 69.5777\n",
      "Epoch [67/100], Step [48100/6235], Loss: 5.4509\n",
      "Epoch [67/100], Step [48200/6235], Loss: 8.4392\n",
      "Epoch [67/100], Step [48300/6235], Loss: 537.5653\n",
      "Epoch [67/100], Step [48400/6235], Loss: 9.5839\n",
      "Epoch [67/100], Step [48500/6235], Loss: 47.1709\n",
      "Epoch [67/100], Step [48600/6235], Loss: 96.0166\n",
      "Epoch [67/100], Step [48700/6235], Loss: 1.0808\n",
      "Epoch [67/100], Step [48800/6235], Loss: 175.0045\n",
      "Epoch [67/100], Step [48900/6235], Loss: 802.7521\n",
      "Epoch [67/100], Step [49000/6235], Loss: 234.1008\n",
      "Epoch [67/100], Step [49100/6235], Loss: 2216.3989\n",
      "Epoch [67/100], Step [49200/6235], Loss: 664.8592\n",
      "Epoch [67/100], Step [49300/6235], Loss: 1253.9703\n",
      "Epoch [67/100], Step [49400/6235], Loss: 100.4405\n",
      "Epoch [67/100], Step [49500/6235], Loss: 5.6013\n",
      "Epoch [67/100], Step [49600/6235], Loss: 100.7816\n",
      "Epoch [67/100], Step [49700/6235], Loss: 2503.8745\n",
      "Epoch [67/100], Step [49800/6235], Loss: 622.2217\n",
      "Epoch [68/100], Step [100/6235], Loss: 7.9556\n",
      "Epoch [68/100], Step [200/6235], Loss: 0.1911\n",
      "Epoch [68/100], Step [300/6235], Loss: 0.0097\n",
      "Epoch [68/100], Step [400/6235], Loss: 0.0194\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Step [500/6235], Loss: 0.2775\n",
      "Epoch [68/100], Step [600/6235], Loss: 0.1495\n",
      "Epoch [68/100], Step [700/6235], Loss: 0.7299\n",
      "Epoch [68/100], Step [800/6235], Loss: 0.0957\n",
      "Epoch [68/100], Step [900/6235], Loss: 0.0542\n",
      "Epoch [68/100], Step [1000/6235], Loss: 0.0374\n",
      "Epoch [68/100], Step [1100/6235], Loss: 0.0371\n",
      "Epoch [68/100], Step [1200/6235], Loss: 0.1960\n",
      "Epoch [68/100], Step [1300/6235], Loss: 0.0374\n",
      "Epoch [68/100], Step [1400/6235], Loss: 0.0639\n",
      "Epoch [68/100], Step [1500/6235], Loss: 0.0235\n",
      "Epoch [68/100], Step [1600/6235], Loss: 0.2363\n",
      "Epoch [68/100], Step [1700/6235], Loss: 0.0573\n",
      "Epoch [68/100], Step [1800/6235], Loss: 0.5610\n",
      "Epoch [68/100], Step [1900/6235], Loss: 0.3618\n",
      "Epoch [68/100], Step [2000/6235], Loss: 2.4727\n",
      "Epoch [68/100], Step [2100/6235], Loss: 6.5296\n",
      "Epoch [68/100], Step [2200/6235], Loss: 7.6791\n",
      "Epoch [68/100], Step [2300/6235], Loss: 2.8884\n",
      "Epoch [68/100], Step [2400/6235], Loss: 2.3784\n",
      "Epoch [68/100], Step [2500/6235], Loss: 32.9597\n",
      "Epoch [68/100], Step [2600/6235], Loss: 13.8166\n",
      "Epoch [68/100], Step [2700/6235], Loss: 7.6076\n",
      "Epoch [68/100], Step [2800/6235], Loss: 132.2307\n",
      "Epoch [68/100], Step [2900/6235], Loss: 15.0346\n",
      "Epoch [68/100], Step [3000/6235], Loss: 1.3303\n",
      "Epoch [68/100], Step [3100/6235], Loss: 65.2877\n",
      "Epoch [68/100], Step [3200/6235], Loss: 72.9260\n",
      "Epoch [68/100], Step [3300/6235], Loss: 8.6914\n",
      "Epoch [68/100], Step [3400/6235], Loss: 1.9406\n",
      "Epoch [68/100], Step [3500/6235], Loss: 39.9029\n",
      "Epoch [68/100], Step [3600/6235], Loss: 7.5717\n",
      "Epoch [68/100], Step [3700/6235], Loss: 0.0961\n",
      "Epoch [68/100], Step [3800/6235], Loss: 0.2065\n",
      "Epoch [68/100], Step [3900/6235], Loss: 0.5429\n",
      "Epoch [68/100], Step [4000/6235], Loss: 0.0673\n",
      "Epoch [68/100], Step [4100/6235], Loss: 7.7816\n",
      "Epoch [68/100], Step [4200/6235], Loss: 0.8397\n",
      "Epoch [68/100], Step [4300/6235], Loss: 8.2896\n",
      "Epoch [68/100], Step [4400/6235], Loss: 2.4949\n",
      "Epoch [68/100], Step [4500/6235], Loss: 39.1765\n",
      "Epoch [68/100], Step [4600/6235], Loss: 5.9102\n",
      "Epoch [68/100], Step [4700/6235], Loss: 0.0613\n",
      "Epoch [68/100], Step [4800/6235], Loss: 10.4789\n",
      "Epoch [68/100], Step [4900/6235], Loss: 0.3916\n",
      "Epoch [68/100], Step [5000/6235], Loss: 0.0646\n",
      "Epoch [68/100], Step [5100/6235], Loss: 6.1002\n",
      "Epoch [68/100], Step [5200/6235], Loss: 3.9952\n",
      "Epoch [68/100], Step [5300/6235], Loss: 41.6120\n",
      "Epoch [68/100], Step [5400/6235], Loss: 1.8715\n",
      "Epoch [68/100], Step [5500/6235], Loss: 0.4772\n",
      "Epoch [68/100], Step [5600/6235], Loss: 0.4821\n",
      "Epoch [68/100], Step [5700/6235], Loss: 0.0465\n",
      "Epoch [68/100], Step [5800/6235], Loss: 0.1745\n",
      "Epoch [68/100], Step [5900/6235], Loss: 0.0785\n",
      "Epoch [68/100], Step [6000/6235], Loss: 3.1751\n",
      "Epoch [68/100], Step [6100/6235], Loss: 0.0315\n",
      "Epoch [68/100], Step [6200/6235], Loss: 2.4819\n",
      "Epoch [68/100], Step [6300/6235], Loss: 2.3944\n",
      "Epoch [68/100], Step [6400/6235], Loss: 0.0651\n",
      "Epoch [68/100], Step [6500/6235], Loss: 2.3625\n",
      "Epoch [68/100], Step [6600/6235], Loss: 6.5569\n",
      "Epoch [68/100], Step [6700/6235], Loss: 3.9818\n",
      "Epoch [68/100], Step [6800/6235], Loss: 0.3508\n",
      "Epoch [68/100], Step [6900/6235], Loss: 1.1250\n",
      "Epoch [68/100], Step [7000/6235], Loss: 0.7600\n",
      "Epoch [68/100], Step [7100/6235], Loss: 0.1969\n",
      "Epoch [68/100], Step [7200/6235], Loss: 0.6259\n",
      "Epoch [68/100], Step [7300/6235], Loss: 0.1609\n",
      "Epoch [68/100], Step [7400/6235], Loss: 0.2723\n",
      "Epoch [68/100], Step [7500/6235], Loss: 0.9260\n",
      "Epoch [68/100], Step [7600/6235], Loss: 2.2164\n",
      "Epoch [68/100], Step [7700/6235], Loss: 18.7010\n",
      "Epoch [68/100], Step [7800/6235], Loss: 7.1069\n",
      "Epoch [68/100], Step [7900/6235], Loss: 3.6707\n",
      "Epoch [68/100], Step [8000/6235], Loss: 0.0886\n",
      "Epoch [68/100], Step [8100/6235], Loss: 4.6124\n",
      "Epoch [68/100], Step [8200/6235], Loss: 16.6433\n",
      "Epoch [68/100], Step [8300/6235], Loss: 63.1135\n",
      "Epoch [68/100], Step [8400/6235], Loss: 182.9327\n",
      "Epoch [68/100], Step [8500/6235], Loss: 4.8165\n",
      "Epoch [68/100], Step [8600/6235], Loss: 148.1021\n",
      "Epoch [68/100], Step [8700/6235], Loss: 91.1077\n",
      "Epoch [68/100], Step [8800/6235], Loss: 458.9810\n",
      "Epoch [68/100], Step [8900/6235], Loss: 397.2603\n",
      "Epoch [68/100], Step [9000/6235], Loss: 181.3034\n",
      "Epoch [68/100], Step [9100/6235], Loss: 1492.9580\n",
      "Epoch [68/100], Step [9200/6235], Loss: 2919.6072\n",
      "Epoch [68/100], Step [9300/6235], Loss: 14.2220\n",
      "Epoch [68/100], Step [9400/6235], Loss: 167.4471\n",
      "Epoch [68/100], Step [9500/6235], Loss: 2434.4233\n",
      "Epoch [68/100], Step [9600/6235], Loss: 453.3875\n",
      "Epoch [68/100], Step [9700/6235], Loss: 11.6375\n",
      "Epoch [68/100], Step [9800/6235], Loss: 5932.2441\n",
      "Epoch [68/100], Step [9900/6235], Loss: 401.2860\n",
      "Epoch [68/100], Step [10000/6235], Loss: 684.4992\n",
      "Epoch [68/100], Step [10100/6235], Loss: 4.2410\n",
      "Epoch [68/100], Step [10200/6235], Loss: 947.1029\n",
      "Epoch [68/100], Step [10300/6235], Loss: 1.6163\n",
      "Epoch [68/100], Step [10400/6235], Loss: 15.6764\n",
      "Epoch [68/100], Step [10500/6235], Loss: 1.2842\n",
      "Epoch [68/100], Step [10600/6235], Loss: 23.8785\n",
      "Epoch [68/100], Step [10700/6235], Loss: 346.8028\n",
      "Epoch [68/100], Step [10800/6235], Loss: 114.1582\n",
      "Epoch [68/100], Step [10900/6235], Loss: 7.2873\n",
      "Epoch [68/100], Step [11000/6235], Loss: 115.7265\n",
      "Epoch [68/100], Step [11100/6235], Loss: 2.4825\n",
      "Epoch [68/100], Step [11200/6235], Loss: 119.0096\n",
      "Epoch [68/100], Step [11300/6235], Loss: 253.8733\n",
      "Epoch [68/100], Step [11400/6235], Loss: 4.7976\n",
      "Epoch [68/100], Step [11500/6235], Loss: 0.9312\n",
      "Epoch [68/100], Step [11600/6235], Loss: 3.6949\n",
      "Epoch [68/100], Step [11700/6235], Loss: 51.8568\n",
      "Epoch [68/100], Step [11800/6235], Loss: 395.7834\n",
      "Epoch [68/100], Step [11900/6235], Loss: 642.5163\n",
      "Epoch [68/100], Step [12000/6235], Loss: 124.5793\n",
      "Epoch [68/100], Step [12100/6235], Loss: 178.2872\n",
      "Epoch [68/100], Step [12200/6235], Loss: 287.2660\n",
      "Epoch [68/100], Step [12300/6235], Loss: 90.5394\n",
      "Epoch [68/100], Step [12400/6235], Loss: 82.8395\n",
      "Epoch [68/100], Step [12500/6235], Loss: 0.6456\n",
      "Epoch [68/100], Step [12600/6235], Loss: 170.1722\n",
      "Epoch [68/100], Step [12700/6235], Loss: 0.7195\n",
      "Epoch [68/100], Step [12800/6235], Loss: 3.9153\n",
      "Epoch [68/100], Step [12900/6235], Loss: 40.5102\n",
      "Epoch [68/100], Step [13000/6235], Loss: 0.5269\n",
      "Epoch [68/100], Step [13100/6235], Loss: 70.0693\n",
      "Epoch [68/100], Step [13200/6235], Loss: 19.9496\n",
      "Epoch [68/100], Step [13300/6235], Loss: 65.8147\n",
      "Epoch [68/100], Step [13400/6235], Loss: 247.5988\n",
      "Epoch [68/100], Step [13500/6235], Loss: 8.7322\n",
      "Epoch [68/100], Step [13600/6235], Loss: 15.9446\n",
      "Epoch [68/100], Step [13700/6235], Loss: 47.0377\n",
      "Epoch [68/100], Step [13800/6235], Loss: 168.0119\n",
      "Epoch [68/100], Step [13900/6235], Loss: 37.9509\n",
      "Epoch [68/100], Step [14000/6235], Loss: 12.1029\n",
      "Epoch [68/100], Step [14100/6235], Loss: 4.4681\n",
      "Epoch [68/100], Step [14200/6235], Loss: 74.2015\n",
      "Epoch [68/100], Step [14300/6235], Loss: 85.2744\n",
      "Epoch [68/100], Step [14400/6235], Loss: 37.4158\n",
      "Epoch [68/100], Step [14500/6235], Loss: 69.1374\n",
      "Epoch [68/100], Step [14600/6235], Loss: 1.1488\n",
      "Epoch [68/100], Step [14700/6235], Loss: 44.8260\n",
      "Epoch [68/100], Step [14800/6235], Loss: 30.6113\n",
      "Epoch [68/100], Step [14900/6235], Loss: 2.0916\n",
      "Epoch [68/100], Step [15000/6235], Loss: 3.6263\n",
      "Epoch [68/100], Step [15100/6235], Loss: 0.1575\n",
      "Epoch [68/100], Step [15200/6235], Loss: 1.3132\n",
      "Epoch [68/100], Step [15300/6235], Loss: 23.9041\n",
      "Epoch [68/100], Step [15400/6235], Loss: 27.8369\n",
      "Epoch [68/100], Step [15500/6235], Loss: 9.3158\n",
      "Epoch [68/100], Step [15600/6235], Loss: 175.2715\n",
      "Epoch [68/100], Step [15700/6235], Loss: 35.8371\n",
      "Epoch [68/100], Step [15800/6235], Loss: 1.0404\n",
      "Epoch [68/100], Step [15900/6235], Loss: 1.3490\n",
      "Epoch [68/100], Step [16000/6235], Loss: 136.1422\n",
      "Epoch [68/100], Step [16100/6235], Loss: 19.3765\n",
      "Epoch [68/100], Step [16200/6235], Loss: 0.3445\n",
      "Epoch [68/100], Step [16300/6235], Loss: 11.8986\n",
      "Epoch [68/100], Step [16400/6235], Loss: 40.8569\n",
      "Epoch [68/100], Step [16500/6235], Loss: 653.5443\n",
      "Epoch [68/100], Step [16600/6235], Loss: 11.2213\n",
      "Epoch [68/100], Step [16700/6235], Loss: 0.6456\n",
      "Epoch [68/100], Step [16800/6235], Loss: 10.2875\n",
      "Epoch [68/100], Step [16900/6235], Loss: 0.0546\n",
      "Epoch [68/100], Step [17000/6235], Loss: 0.2905\n",
      "Epoch [68/100], Step [17100/6235], Loss: 0.7051\n",
      "Epoch [68/100], Step [17200/6235], Loss: 314.5289\n",
      "Epoch [68/100], Step [17300/6235], Loss: 31.4441\n",
      "Epoch [68/100], Step [17400/6235], Loss: 31.6470\n",
      "Epoch [68/100], Step [17500/6235], Loss: 0.7634\n",
      "Epoch [68/100], Step [17600/6235], Loss: 4.1340\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Step [17700/6235], Loss: 27.8504\n",
      "Epoch [68/100], Step [17800/6235], Loss: 16.1419\n",
      "Epoch [68/100], Step [17900/6235], Loss: 6.5180\n",
      "Epoch [68/100], Step [18000/6235], Loss: 1.4329\n",
      "Epoch [68/100], Step [18100/6235], Loss: 15.3733\n",
      "Epoch [68/100], Step [18200/6235], Loss: 0.4060\n",
      "Epoch [68/100], Step [18300/6235], Loss: 1.8767\n",
      "Epoch [68/100], Step [18400/6235], Loss: 0.2234\n",
      "Epoch [68/100], Step [18500/6235], Loss: 31.9698\n",
      "Epoch [68/100], Step [18600/6235], Loss: 3.9089\n",
      "Epoch [68/100], Step [18700/6235], Loss: 1.0640\n",
      "Epoch [68/100], Step [18800/6235], Loss: 126.7078\n",
      "Epoch [68/100], Step [18900/6235], Loss: 61.9807\n",
      "Epoch [68/100], Step [19000/6235], Loss: 6.1692\n",
      "Epoch [68/100], Step [19100/6235], Loss: 4.4804\n",
      "Epoch [68/100], Step [19200/6235], Loss: 3.9541\n",
      "Epoch [68/100], Step [19300/6235], Loss: 2.0543\n",
      "Epoch [68/100], Step [19400/6235], Loss: 160.9369\n",
      "Epoch [68/100], Step [19500/6235], Loss: 104.9848\n",
      "Epoch [68/100], Step [19600/6235], Loss: 86.9709\n",
      "Epoch [68/100], Step [19700/6235], Loss: 11.5327\n",
      "Epoch [68/100], Step [19800/6235], Loss: 4.1315\n",
      "Epoch [68/100], Step [19900/6235], Loss: 0.1069\n",
      "Epoch [68/100], Step [20000/6235], Loss: 69.5413\n",
      "Epoch [68/100], Step [20100/6235], Loss: 0.8827\n",
      "Epoch [68/100], Step [20200/6235], Loss: 5.3423\n",
      "Epoch [68/100], Step [20300/6235], Loss: 2.5091\n",
      "Epoch [68/100], Step [20400/6235], Loss: 11.8855\n",
      "Epoch [68/100], Step [20500/6235], Loss: 54.0481\n",
      "Epoch [68/100], Step [20600/6235], Loss: 164.9697\n",
      "Epoch [68/100], Step [20700/6235], Loss: 18.0232\n",
      "Epoch [68/100], Step [20800/6235], Loss: 7.8723\n",
      "Epoch [68/100], Step [20900/6235], Loss: 4.9226\n",
      "Epoch [68/100], Step [21000/6235], Loss: 17.4214\n",
      "Epoch [68/100], Step [21100/6235], Loss: 6.7717\n",
      "Epoch [68/100], Step [21200/6235], Loss: 0.2683\n",
      "Epoch [68/100], Step [21300/6235], Loss: 0.1346\n",
      "Epoch [68/100], Step [21400/6235], Loss: 4.3050\n",
      "Epoch [68/100], Step [21500/6235], Loss: 0.6079\n",
      "Epoch [68/100], Step [21600/6235], Loss: 29.9178\n",
      "Epoch [68/100], Step [21700/6235], Loss: 0.2644\n",
      "Epoch [68/100], Step [21800/6235], Loss: 4.7707\n",
      "Epoch [68/100], Step [21900/6235], Loss: 1.7250\n",
      "Epoch [68/100], Step [22000/6235], Loss: 9.4983\n",
      "Epoch [68/100], Step [22100/6235], Loss: 0.0702\n",
      "Epoch [68/100], Step [22200/6235], Loss: 3.8483\n",
      "Epoch [68/100], Step [22300/6235], Loss: 4.8500\n",
      "Epoch [68/100], Step [22400/6235], Loss: 0.5864\n",
      "Epoch [68/100], Step [22500/6235], Loss: 148.6850\n",
      "Epoch [68/100], Step [22600/6235], Loss: 19.2635\n",
      "Epoch [68/100], Step [22700/6235], Loss: 0.0507\n",
      "Epoch [68/100], Step [22800/6235], Loss: 7.7711\n",
      "Epoch [68/100], Step [22900/6235], Loss: 1.6074\n",
      "Epoch [68/100], Step [23000/6235], Loss: 7.6210\n",
      "Epoch [68/100], Step [23100/6235], Loss: 6.7098\n",
      "Epoch [68/100], Step [23200/6235], Loss: 4.9192\n",
      "Epoch [68/100], Step [23300/6235], Loss: 19.9148\n",
      "Epoch [68/100], Step [23400/6235], Loss: 2.6238\n",
      "Epoch [68/100], Step [23500/6235], Loss: 0.1044\n",
      "Epoch [68/100], Step [23600/6235], Loss: 133.9583\n",
      "Epoch [68/100], Step [23700/6235], Loss: 2.3778\n",
      "Epoch [68/100], Step [23800/6235], Loss: 0.7986\n",
      "Epoch [68/100], Step [23900/6235], Loss: 3.0411\n",
      "Epoch [68/100], Step [24000/6235], Loss: 0.3776\n",
      "Epoch [68/100], Step [24100/6235], Loss: 0.4447\n",
      "Epoch [68/100], Step [24200/6235], Loss: 5.3398\n",
      "Epoch [68/100], Step [24300/6235], Loss: 1.1204\n",
      "Epoch [68/100], Step [24400/6235], Loss: 2.2827\n",
      "Epoch [68/100], Step [24500/6235], Loss: 0.6233\n",
      "Epoch [68/100], Step [24600/6235], Loss: 0.1949\n",
      "Epoch [68/100], Step [24700/6235], Loss: 4.2989\n",
      "Epoch [68/100], Step [24800/6235], Loss: 0.2554\n",
      "Epoch [68/100], Step [24900/6235], Loss: 15.3227\n",
      "Epoch [68/100], Step [25000/6235], Loss: 13.2614\n",
      "Epoch [68/100], Step [25100/6235], Loss: 6.3894\n",
      "Epoch [68/100], Step [25200/6235], Loss: 0.4212\n",
      "Epoch [68/100], Step [25300/6235], Loss: 0.7194\n",
      "Epoch [68/100], Step [25400/6235], Loss: 9.8718\n",
      "Epoch [68/100], Step [25500/6235], Loss: 9.1448\n",
      "Epoch [68/100], Step [25600/6235], Loss: 6.3678\n",
      "Epoch [68/100], Step [25700/6235], Loss: 0.1408\n",
      "Epoch [68/100], Step [25800/6235], Loss: 0.0593\n",
      "Epoch [68/100], Step [25900/6235], Loss: 5.1776\n",
      "Epoch [68/100], Step [26000/6235], Loss: 1.6932\n",
      "Epoch [68/100], Step [26100/6235], Loss: 0.1184\n",
      "Epoch [68/100], Step [26200/6235], Loss: 1.0579\n",
      "Epoch [68/100], Step [26300/6235], Loss: 3.1442\n",
      "Epoch [68/100], Step [26400/6235], Loss: 0.1578\n",
      "Epoch [68/100], Step [26500/6235], Loss: 0.0135\n",
      "Epoch [68/100], Step [26600/6235], Loss: 0.8695\n",
      "Epoch [68/100], Step [26700/6235], Loss: 0.2713\n",
      "Epoch [68/100], Step [26800/6235], Loss: 0.0987\n",
      "Epoch [68/100], Step [26900/6235], Loss: 0.0110\n",
      "Epoch [68/100], Step [27000/6235], Loss: 15.8951\n",
      "Epoch [68/100], Step [27100/6235], Loss: 0.0521\n",
      "Epoch [68/100], Step [27200/6235], Loss: 0.0153\n",
      "Epoch [68/100], Step [27300/6235], Loss: 0.1347\n",
      "Epoch [68/100], Step [27400/6235], Loss: 0.7207\n",
      "Epoch [68/100], Step [27500/6235], Loss: 19.1943\n",
      "Epoch [68/100], Step [27600/6235], Loss: 1.5070\n",
      "Epoch [68/100], Step [27700/6235], Loss: 1.7400\n",
      "Epoch [68/100], Step [27800/6235], Loss: 6.5355\n",
      "Epoch [68/100], Step [27900/6235], Loss: 0.2268\n",
      "Epoch [68/100], Step [28000/6235], Loss: 158.9206\n",
      "Epoch [68/100], Step [28100/6235], Loss: 0.4047\n",
      "Epoch [68/100], Step [28200/6235], Loss: 37.1566\n",
      "Epoch [68/100], Step [28300/6235], Loss: 2.5560\n",
      "Epoch [68/100], Step [28400/6235], Loss: 27.3865\n",
      "Epoch [68/100], Step [28500/6235], Loss: 4.4296\n",
      "Epoch [68/100], Step [28600/6235], Loss: 0.0920\n",
      "Epoch [68/100], Step [28700/6235], Loss: 5.4323\n",
      "Epoch [68/100], Step [28800/6235], Loss: 0.6270\n",
      "Epoch [68/100], Step [28900/6235], Loss: 68.7855\n",
      "Epoch [68/100], Step [29000/6235], Loss: 13.1767\n",
      "Epoch [68/100], Step [29100/6235], Loss: 0.1667\n",
      "Epoch [68/100], Step [29200/6235], Loss: 1.9730\n",
      "Epoch [68/100], Step [29300/6235], Loss: 13.5588\n",
      "Epoch [68/100], Step [29400/6235], Loss: 0.0961\n",
      "Epoch [68/100], Step [29500/6235], Loss: 0.8819\n",
      "Epoch [68/100], Step [29600/6235], Loss: 0.6313\n",
      "Epoch [68/100], Step [29700/6235], Loss: 1.5893\n",
      "Epoch [68/100], Step [29800/6235], Loss: 1.4959\n",
      "Epoch [68/100], Step [29900/6235], Loss: 0.4794\n",
      "Epoch [68/100], Step [30000/6235], Loss: 7.1608\n",
      "Epoch [68/100], Step [30100/6235], Loss: 11.0743\n",
      "Epoch [68/100], Step [30200/6235], Loss: 1.2512\n",
      "Epoch [68/100], Step [30300/6235], Loss: 0.0205\n",
      "Epoch [68/100], Step [30400/6235], Loss: 1.1383\n",
      "Epoch [68/100], Step [30500/6235], Loss: 3.1167\n",
      "Epoch [68/100], Step [30600/6235], Loss: 1.7812\n",
      "Epoch [68/100], Step [30700/6235], Loss: 0.6007\n",
      "Epoch [68/100], Step [30800/6235], Loss: 0.5134\n",
      "Epoch [68/100], Step [30900/6235], Loss: 3.7557\n",
      "Epoch [68/100], Step [31000/6235], Loss: 0.1634\n",
      "Epoch [68/100], Step [31100/6235], Loss: 0.0647\n",
      "Epoch [68/100], Step [31200/6235], Loss: 6.1076\n",
      "Epoch [68/100], Step [31300/6235], Loss: 1.9008\n",
      "Epoch [68/100], Step [31400/6235], Loss: 0.2095\n",
      "Epoch [68/100], Step [31500/6235], Loss: 0.7076\n",
      "Epoch [68/100], Step [31600/6235], Loss: 5.7688\n",
      "Epoch [68/100], Step [31700/6235], Loss: 35.8643\n",
      "Epoch [68/100], Step [31800/6235], Loss: 0.3547\n",
      "Epoch [68/100], Step [31900/6235], Loss: 1356.6042\n",
      "Epoch [68/100], Step [32000/6235], Loss: 11.0932\n",
      "Epoch [68/100], Step [32100/6235], Loss: 1.6076\n",
      "Epoch [68/100], Step [32200/6235], Loss: 134.9149\n",
      "Epoch [68/100], Step [32300/6235], Loss: 2.3807\n",
      "Epoch [68/100], Step [32400/6235], Loss: 1.2724\n",
      "Epoch [68/100], Step [32500/6235], Loss: 18.5798\n",
      "Epoch [68/100], Step [32600/6235], Loss: 0.6168\n",
      "Epoch [68/100], Step [32700/6235], Loss: 77.2944\n",
      "Epoch [68/100], Step [32800/6235], Loss: 0.9774\n",
      "Epoch [68/100], Step [32900/6235], Loss: 4.1810\n",
      "Epoch [68/100], Step [33000/6235], Loss: 0.4865\n",
      "Epoch [68/100], Step [33100/6235], Loss: 0.6789\n",
      "Epoch [68/100], Step [33200/6235], Loss: 0.9421\n",
      "Epoch [68/100], Step [33300/6235], Loss: 0.5232\n",
      "Epoch [68/100], Step [33400/6235], Loss: 129.3158\n",
      "Epoch [68/100], Step [33500/6235], Loss: 1.8922\n",
      "Epoch [68/100], Step [33600/6235], Loss: 4.3970\n",
      "Epoch [68/100], Step [33700/6235], Loss: 0.7006\n",
      "Epoch [68/100], Step [33800/6235], Loss: 0.8409\n",
      "Epoch [68/100], Step [33900/6235], Loss: 32.1455\n",
      "Epoch [68/100], Step [34000/6235], Loss: 0.0793\n",
      "Epoch [68/100], Step [34100/6235], Loss: 0.5440\n",
      "Epoch [68/100], Step [34200/6235], Loss: 2.4371\n",
      "Epoch [68/100], Step [34300/6235], Loss: 3.9885\n",
      "Epoch [68/100], Step [34400/6235], Loss: 0.2222\n",
      "Epoch [68/100], Step [34500/6235], Loss: 24.0164\n",
      "Epoch [68/100], Step [34600/6235], Loss: 1.2923\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [68/100], Step [34700/6235], Loss: 11.7254\n",
      "Epoch [68/100], Step [34800/6235], Loss: 9.6422\n",
      "Epoch [68/100], Step [34900/6235], Loss: 55.3540\n",
      "Epoch [68/100], Step [35000/6235], Loss: 0.4174\n",
      "Epoch [68/100], Step [35100/6235], Loss: 0.4875\n",
      "Epoch [68/100], Step [35200/6235], Loss: 0.3258\n",
      "Epoch [68/100], Step [35300/6235], Loss: 2.9090\n",
      "Epoch [68/100], Step [35400/6235], Loss: 0.4610\n",
      "Epoch [68/100], Step [35500/6235], Loss: 1.2522\n",
      "Epoch [68/100], Step [35600/6235], Loss: 0.1985\n",
      "Epoch [68/100], Step [35700/6235], Loss: 5.5746\n",
      "Epoch [68/100], Step [35800/6235], Loss: 0.2156\n",
      "Epoch [68/100], Step [35900/6235], Loss: 1.3953\n",
      "Epoch [68/100], Step [36000/6235], Loss: 0.0682\n",
      "Epoch [68/100], Step [36100/6235], Loss: 0.0416\n",
      "Epoch [68/100], Step [36200/6235], Loss: 28.9616\n",
      "Epoch [68/100], Step [36300/6235], Loss: 1.5504\n",
      "Epoch [68/100], Step [36400/6235], Loss: 3.2008\n",
      "Epoch [68/100], Step [36500/6235], Loss: 7.8940\n",
      "Epoch [68/100], Step [36600/6235], Loss: 0.1013\n",
      "Epoch [68/100], Step [36700/6235], Loss: 0.5862\n",
      "Epoch [68/100], Step [36800/6235], Loss: 6.7960\n",
      "Epoch [68/100], Step [36900/6235], Loss: 10.2047\n",
      "Epoch [68/100], Step [37000/6235], Loss: 0.8678\n",
      "Epoch [68/100], Step [37100/6235], Loss: 1.7217\n",
      "Epoch [68/100], Step [37200/6235], Loss: 0.0526\n",
      "Epoch [68/100], Step [37300/6235], Loss: 0.0308\n",
      "Epoch [68/100], Step [37400/6235], Loss: 0.1842\n",
      "Epoch [68/100], Step [37500/6235], Loss: 6.3273\n",
      "Epoch [68/100], Step [37600/6235], Loss: 12.1949\n",
      "Epoch [68/100], Step [37700/6235], Loss: 2.2002\n",
      "Epoch [68/100], Step [37800/6235], Loss: 2.8871\n",
      "Epoch [68/100], Step [37900/6235], Loss: 7.7289\n",
      "Epoch [68/100], Step [38000/6235], Loss: 0.9671\n",
      "Epoch [68/100], Step [38100/6235], Loss: 4.8008\n",
      "Epoch [68/100], Step [38200/6235], Loss: 2.8507\n",
      "Epoch [68/100], Step [38300/6235], Loss: 0.3613\n",
      "Epoch [68/100], Step [38400/6235], Loss: 0.0500\n",
      "Epoch [68/100], Step [38500/6235], Loss: 1.6372\n",
      "Epoch [68/100], Step [38600/6235], Loss: 0.3341\n",
      "Epoch [68/100], Step [38700/6235], Loss: 0.1687\n",
      "Epoch [68/100], Step [38800/6235], Loss: 0.1390\n",
      "Epoch [68/100], Step [38900/6235], Loss: 11.6146\n",
      "Epoch [68/100], Step [39000/6235], Loss: 3.6879\n",
      "Epoch [68/100], Step [39100/6235], Loss: 14.6830\n",
      "Epoch [68/100], Step [39200/6235], Loss: 0.3646\n",
      "Epoch [68/100], Step [39300/6235], Loss: 3.1031\n",
      "Epoch [68/100], Step [39400/6235], Loss: 393.9919\n",
      "Epoch [68/100], Step [39500/6235], Loss: 2.4243\n",
      "Epoch [68/100], Step [39600/6235], Loss: 42.9074\n",
      "Epoch [68/100], Step [39700/6235], Loss: 341.8997\n",
      "Epoch [68/100], Step [39800/6235], Loss: 223.5273\n",
      "Epoch [68/100], Step [39900/6235], Loss: 6.1013\n",
      "Epoch [68/100], Step [40000/6235], Loss: 14.9031\n",
      "Epoch [68/100], Step [40100/6235], Loss: 20.3853\n",
      "Epoch [68/100], Step [40200/6235], Loss: 1.4561\n",
      "Epoch [68/100], Step [40300/6235], Loss: 1.2566\n",
      "Epoch [68/100], Step [40400/6235], Loss: 1.6697\n",
      "Epoch [68/100], Step [40500/6235], Loss: 2.5243\n",
      "Epoch [68/100], Step [40600/6235], Loss: 0.2458\n",
      "Epoch [68/100], Step [40700/6235], Loss: 7.4364\n",
      "Epoch [68/100], Step [40800/6235], Loss: 0.8739\n",
      "Epoch [68/100], Step [40900/6235], Loss: 0.3256\n",
      "Epoch [68/100], Step [41000/6235], Loss: 48.2621\n",
      "Epoch [68/100], Step [41100/6235], Loss: 13.8518\n",
      "Epoch [68/100], Step [41200/6235], Loss: 2.7086\n",
      "Epoch [68/100], Step [41300/6235], Loss: 3.6888\n",
      "Epoch [68/100], Step [41400/6235], Loss: 0.4315\n",
      "Epoch [68/100], Step [41500/6235], Loss: 0.9881\n",
      "Epoch [68/100], Step [41600/6235], Loss: 0.2469\n",
      "Epoch [68/100], Step [41700/6235], Loss: 4.4244\n",
      "Epoch [68/100], Step [41800/6235], Loss: 1.9805\n",
      "Epoch [68/100], Step [41900/6235], Loss: 2.9191\n",
      "Epoch [68/100], Step [42000/6235], Loss: 2.8903\n",
      "Epoch [68/100], Step [42100/6235], Loss: 6.1425\n",
      "Epoch [68/100], Step [42200/6235], Loss: 2.8541\n",
      "Epoch [68/100], Step [42300/6235], Loss: 2.2712\n",
      "Epoch [68/100], Step [42400/6235], Loss: 5.7655\n",
      "Epoch [68/100], Step [42500/6235], Loss: 0.8566\n",
      "Epoch [68/100], Step [42600/6235], Loss: 0.9156\n",
      "Epoch [68/100], Step [42700/6235], Loss: 0.4604\n",
      "Epoch [68/100], Step [42800/6235], Loss: 1.3005\n",
      "Epoch [68/100], Step [42900/6235], Loss: 3.1768\n",
      "Epoch [68/100], Step [43000/6235], Loss: 0.2800\n",
      "Epoch [68/100], Step [43100/6235], Loss: 0.6105\n",
      "Epoch [68/100], Step [43200/6235], Loss: 0.9651\n",
      "Epoch [68/100], Step [43300/6235], Loss: 9.0158\n",
      "Epoch [68/100], Step [43400/6235], Loss: 10.1172\n",
      "Epoch [68/100], Step [43500/6235], Loss: 9.3115\n",
      "Epoch [68/100], Step [43600/6235], Loss: 19.9262\n",
      "Epoch [68/100], Step [43700/6235], Loss: 25.0849\n",
      "Epoch [68/100], Step [43800/6235], Loss: 0.3694\n",
      "Epoch [68/100], Step [43900/6235], Loss: 1.0472\n",
      "Epoch [68/100], Step [44000/6235], Loss: 122.4493\n",
      "Epoch [68/100], Step [44100/6235], Loss: 5.2219\n",
      "Epoch [68/100], Step [44200/6235], Loss: 3.1476\n",
      "Epoch [68/100], Step [44300/6235], Loss: 4.9028\n",
      "Epoch [68/100], Step [44400/6235], Loss: 1.7301\n",
      "Epoch [68/100], Step [44500/6235], Loss: 0.3054\n",
      "Epoch [68/100], Step [44600/6235], Loss: 28.7293\n",
      "Epoch [68/100], Step [44700/6235], Loss: 4.1150\n",
      "Epoch [68/100], Step [44800/6235], Loss: 5.5728\n",
      "Epoch [68/100], Step [44900/6235], Loss: 7.4244\n",
      "Epoch [68/100], Step [45000/6235], Loss: 5.3759\n",
      "Epoch [68/100], Step [45100/6235], Loss: 62.4141\n",
      "Epoch [68/100], Step [45200/6235], Loss: 0.5990\n",
      "Epoch [68/100], Step [45300/6235], Loss: 27.0699\n",
      "Epoch [68/100], Step [45400/6235], Loss: 9.9830\n",
      "Epoch [68/100], Step [45500/6235], Loss: 0.7960\n",
      "Epoch [68/100], Step [45600/6235], Loss: 0.2437\n",
      "Epoch [68/100], Step [45700/6235], Loss: 86.8490\n",
      "Epoch [68/100], Step [45800/6235], Loss: 519.8134\n",
      "Epoch [68/100], Step [45900/6235], Loss: 25.2675\n",
      "Epoch [68/100], Step [46000/6235], Loss: 14.9811\n",
      "Epoch [68/100], Step [46100/6235], Loss: 15.1215\n",
      "Epoch [68/100], Step [46200/6235], Loss: 8.0807\n",
      "Epoch [68/100], Step [46300/6235], Loss: 21.3298\n",
      "Epoch [68/100], Step [46400/6235], Loss: 8.2655\n",
      "Epoch [68/100], Step [46500/6235], Loss: 27.8170\n",
      "Epoch [68/100], Step [46600/6235], Loss: 13.8237\n",
      "Epoch [68/100], Step [46700/6235], Loss: 54.8078\n",
      "Epoch [68/100], Step [46800/6235], Loss: 0.9356\n",
      "Epoch [68/100], Step [46900/6235], Loss: 60.8752\n",
      "Epoch [68/100], Step [47000/6235], Loss: 2.8684\n",
      "Epoch [68/100], Step [47100/6235], Loss: 124.9225\n",
      "Epoch [68/100], Step [47200/6235], Loss: 9.6655\n",
      "Epoch [68/100], Step [47300/6235], Loss: 16.3112\n",
      "Epoch [68/100], Step [47400/6235], Loss: 412.8733\n",
      "Epoch [68/100], Step [47500/6235], Loss: 6.5712\n",
      "Epoch [68/100], Step [47600/6235], Loss: 0.5016\n",
      "Epoch [68/100], Step [47700/6235], Loss: 0.1139\n",
      "Epoch [68/100], Step [47800/6235], Loss: 70.0674\n",
      "Epoch [68/100], Step [47900/6235], Loss: 1.5902\n",
      "Epoch [68/100], Step [48000/6235], Loss: 77.5366\n",
      "Epoch [68/100], Step [48100/6235], Loss: 34.0504\n",
      "Epoch [68/100], Step [48200/6235], Loss: 222.4818\n",
      "Epoch [68/100], Step [48300/6235], Loss: 827.4178\n",
      "Epoch [68/100], Step [48400/6235], Loss: 2.6906\n",
      "Epoch [68/100], Step [48500/6235], Loss: 13.3857\n",
      "Epoch [68/100], Step [48600/6235], Loss: 14.6308\n",
      "Epoch [68/100], Step [48700/6235], Loss: 43.6813\n",
      "Epoch [68/100], Step [48800/6235], Loss: 388.7230\n",
      "Epoch [68/100], Step [48900/6235], Loss: 806.5416\n",
      "Epoch [68/100], Step [49000/6235], Loss: 124.1278\n",
      "Epoch [68/100], Step [49100/6235], Loss: 2305.2078\n",
      "Epoch [68/100], Step [49200/6235], Loss: 2989.7322\n",
      "Epoch [68/100], Step [49300/6235], Loss: 986.0939\n",
      "Epoch [68/100], Step [49400/6235], Loss: 130.3153\n",
      "Epoch [68/100], Step [49500/6235], Loss: 24.3738\n",
      "Epoch [68/100], Step [49600/6235], Loss: 60.4313\n",
      "Epoch [68/100], Step [49700/6235], Loss: 6127.2568\n",
      "Epoch [68/100], Step [49800/6235], Loss: 867.9515\n",
      "Epoch [69/100], Step [100/6235], Loss: 14.8824\n",
      "Epoch [69/100], Step [200/6235], Loss: 0.2751\n",
      "Epoch [69/100], Step [300/6235], Loss: 0.1160\n",
      "Epoch [69/100], Step [400/6235], Loss: 0.0598\n",
      "Epoch [69/100], Step [500/6235], Loss: 0.4094\n",
      "Epoch [69/100], Step [600/6235], Loss: 0.2569\n",
      "Epoch [69/100], Step [700/6235], Loss: 0.6135\n",
      "Epoch [69/100], Step [800/6235], Loss: 0.1023\n",
      "Epoch [69/100], Step [900/6235], Loss: 0.0740\n",
      "Epoch [69/100], Step [1000/6235], Loss: 0.0397\n",
      "Epoch [69/100], Step [1100/6235], Loss: 0.0943\n",
      "Epoch [69/100], Step [1200/6235], Loss: 0.1755\n",
      "Epoch [69/100], Step [1300/6235], Loss: 0.0242\n",
      "Epoch [69/100], Step [1400/6235], Loss: 0.2907\n",
      "Epoch [69/100], Step [1500/6235], Loss: 0.0103\n",
      "Epoch [69/100], Step [1600/6235], Loss: 0.2464\n",
      "Epoch [69/100], Step [1700/6235], Loss: 0.0699\n",
      "Epoch [69/100], Step [1800/6235], Loss: 0.2459\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Step [1900/6235], Loss: 0.3615\n",
      "Epoch [69/100], Step [2000/6235], Loss: 2.3523\n",
      "Epoch [69/100], Step [2100/6235], Loss: 1.9762\n",
      "Epoch [69/100], Step [2200/6235], Loss: 7.5394\n",
      "Epoch [69/100], Step [2300/6235], Loss: 2.9268\n",
      "Epoch [69/100], Step [2400/6235], Loss: 1.9074\n",
      "Epoch [69/100], Step [2500/6235], Loss: 28.8048\n",
      "Epoch [69/100], Step [2600/6235], Loss: 13.3315\n",
      "Epoch [69/100], Step [2700/6235], Loss: 4.8094\n",
      "Epoch [69/100], Step [2800/6235], Loss: 84.1834\n",
      "Epoch [69/100], Step [2900/6235], Loss: 19.0419\n",
      "Epoch [69/100], Step [3000/6235], Loss: 1.5826\n",
      "Epoch [69/100], Step [3100/6235], Loss: 66.3738\n",
      "Epoch [69/100], Step [3200/6235], Loss: 45.8438\n",
      "Epoch [69/100], Step [3300/6235], Loss: 10.9725\n",
      "Epoch [69/100], Step [3400/6235], Loss: 3.3150\n",
      "Epoch [69/100], Step [3500/6235], Loss: 53.5339\n",
      "Epoch [69/100], Step [3600/6235], Loss: 2.0097\n",
      "Epoch [69/100], Step [3700/6235], Loss: 0.0564\n",
      "Epoch [69/100], Step [3800/6235], Loss: 0.0250\n",
      "Epoch [69/100], Step [3900/6235], Loss: 0.0422\n",
      "Epoch [69/100], Step [4000/6235], Loss: 0.1092\n",
      "Epoch [69/100], Step [4100/6235], Loss: 9.5846\n",
      "Epoch [69/100], Step [4200/6235], Loss: 3.1309\n",
      "Epoch [69/100], Step [4300/6235], Loss: 4.3126\n",
      "Epoch [69/100], Step [4400/6235], Loss: 0.6297\n",
      "Epoch [69/100], Step [4500/6235], Loss: 36.1837\n",
      "Epoch [69/100], Step [4600/6235], Loss: 0.6003\n",
      "Epoch [69/100], Step [4700/6235], Loss: 0.2275\n",
      "Epoch [69/100], Step [4800/6235], Loss: 8.4803\n",
      "Epoch [69/100], Step [4900/6235], Loss: 0.6674\n",
      "Epoch [69/100], Step [5000/6235], Loss: 0.0325\n",
      "Epoch [69/100], Step [5100/6235], Loss: 0.6037\n",
      "Epoch [69/100], Step [5200/6235], Loss: 2.5604\n",
      "Epoch [69/100], Step [5300/6235], Loss: 29.9538\n",
      "Epoch [69/100], Step [5400/6235], Loss: 0.2681\n",
      "Epoch [69/100], Step [5500/6235], Loss: 0.0242\n",
      "Epoch [69/100], Step [5600/6235], Loss: 0.3762\n",
      "Epoch [69/100], Step [5700/6235], Loss: 0.1909\n",
      "Epoch [69/100], Step [5800/6235], Loss: 0.2787\n",
      "Epoch [69/100], Step [5900/6235], Loss: 0.2655\n",
      "Epoch [69/100], Step [6000/6235], Loss: 0.3465\n",
      "Epoch [69/100], Step [6100/6235], Loss: 0.1419\n",
      "Epoch [69/100], Step [6200/6235], Loss: 5.6689\n",
      "Epoch [69/100], Step [6300/6235], Loss: 0.1290\n",
      "Epoch [69/100], Step [6400/6235], Loss: 0.0239\n",
      "Epoch [69/100], Step [6500/6235], Loss: 2.3855\n",
      "Epoch [69/100], Step [6600/6235], Loss: 6.5225\n",
      "Epoch [69/100], Step [6700/6235], Loss: 1.2316\n",
      "Epoch [69/100], Step [6800/6235], Loss: 0.1927\n",
      "Epoch [69/100], Step [6900/6235], Loss: 0.4165\n",
      "Epoch [69/100], Step [7000/6235], Loss: 0.1236\n",
      "Epoch [69/100], Step [7100/6235], Loss: 0.8514\n",
      "Epoch [69/100], Step [7200/6235], Loss: 0.1060\n",
      "Epoch [69/100], Step [7300/6235], Loss: 1.2732\n",
      "Epoch [69/100], Step [7400/6235], Loss: 0.0199\n",
      "Epoch [69/100], Step [7500/6235], Loss: 0.3046\n",
      "Epoch [69/100], Step [7600/6235], Loss: 5.0814\n",
      "Epoch [69/100], Step [7700/6235], Loss: 5.8013\n",
      "Epoch [69/100], Step [7800/6235], Loss: 3.0533\n",
      "Epoch [69/100], Step [7900/6235], Loss: 4.8028\n",
      "Epoch [69/100], Step [8000/6235], Loss: 0.5054\n",
      "Epoch [69/100], Step [8100/6235], Loss: 0.5295\n",
      "Epoch [69/100], Step [8200/6235], Loss: 10.4345\n",
      "Epoch [69/100], Step [8300/6235], Loss: 19.0014\n",
      "Epoch [69/100], Step [8400/6235], Loss: 650.4858\n",
      "Epoch [69/100], Step [8500/6235], Loss: 21.4534\n",
      "Epoch [69/100], Step [8600/6235], Loss: 23.2316\n",
      "Epoch [69/100], Step [8700/6235], Loss: 23.2624\n",
      "Epoch [69/100], Step [8800/6235], Loss: 553.5236\n",
      "Epoch [69/100], Step [8900/6235], Loss: 327.6732\n",
      "Epoch [69/100], Step [9000/6235], Loss: 295.1490\n",
      "Epoch [69/100], Step [9100/6235], Loss: 714.4977\n",
      "Epoch [69/100], Step [9200/6235], Loss: 2673.9023\n",
      "Epoch [69/100], Step [9300/6235], Loss: 88.0649\n",
      "Epoch [69/100], Step [9400/6235], Loss: 82.4362\n",
      "Epoch [69/100], Step [9500/6235], Loss: 2024.9786\n",
      "Epoch [69/100], Step [9600/6235], Loss: 792.4443\n",
      "Epoch [69/100], Step [9700/6235], Loss: 9.2839\n",
      "Epoch [69/100], Step [9800/6235], Loss: 2706.5615\n",
      "Epoch [69/100], Step [9900/6235], Loss: 412.3611\n",
      "Epoch [69/100], Step [10000/6235], Loss: 592.7844\n",
      "Epoch [69/100], Step [10100/6235], Loss: 4.3777\n",
      "Epoch [69/100], Step [10200/6235], Loss: 473.0125\n",
      "Epoch [69/100], Step [10300/6235], Loss: 1.1361\n",
      "Epoch [69/100], Step [10400/6235], Loss: 5.4455\n",
      "Epoch [69/100], Step [10500/6235], Loss: 0.9636\n",
      "Epoch [69/100], Step [10600/6235], Loss: 15.4845\n",
      "Epoch [69/100], Step [10700/6235], Loss: 43.4013\n",
      "Epoch [69/100], Step [10800/6235], Loss: 20.2163\n",
      "Epoch [69/100], Step [10900/6235], Loss: 3.6104\n",
      "Epoch [69/100], Step [11000/6235], Loss: 284.5443\n",
      "Epoch [69/100], Step [11100/6235], Loss: 24.0738\n",
      "Epoch [69/100], Step [11200/6235], Loss: 55.8155\n",
      "Epoch [69/100], Step [11300/6235], Loss: 174.2443\n",
      "Epoch [69/100], Step [11400/6235], Loss: 4.8355\n",
      "Epoch [69/100], Step [11500/6235], Loss: 3.2667\n",
      "Epoch [69/100], Step [11600/6235], Loss: 1.6235\n",
      "Epoch [69/100], Step [11700/6235], Loss: 38.4937\n",
      "Epoch [69/100], Step [11800/6235], Loss: 402.6635\n",
      "Epoch [69/100], Step [11900/6235], Loss: 323.4000\n",
      "Epoch [69/100], Step [12000/6235], Loss: 364.4440\n",
      "Epoch [69/100], Step [12100/6235], Loss: 205.4370\n",
      "Epoch [69/100], Step [12200/6235], Loss: 204.6654\n",
      "Epoch [69/100], Step [12300/6235], Loss: 63.7202\n",
      "Epoch [69/100], Step [12400/6235], Loss: 369.7984\n",
      "Epoch [69/100], Step [12500/6235], Loss: 5.1781\n",
      "Epoch [69/100], Step [12600/6235], Loss: 100.2818\n",
      "Epoch [69/100], Step [12700/6235], Loss: 3.4730\n",
      "Epoch [69/100], Step [12800/6235], Loss: 4.1944\n",
      "Epoch [69/100], Step [12900/6235], Loss: 38.2145\n",
      "Epoch [69/100], Step [13000/6235], Loss: 0.4288\n",
      "Epoch [69/100], Step [13100/6235], Loss: 67.2226\n",
      "Epoch [69/100], Step [13200/6235], Loss: 14.0719\n",
      "Epoch [69/100], Step [13300/6235], Loss: 60.1799\n",
      "Epoch [69/100], Step [13400/6235], Loss: 249.5234\n",
      "Epoch [69/100], Step [13500/6235], Loss: 3.9433\n",
      "Epoch [69/100], Step [13600/6235], Loss: 6.8588\n",
      "Epoch [69/100], Step [13700/6235], Loss: 41.3071\n",
      "Epoch [69/100], Step [13800/6235], Loss: 166.6154\n",
      "Epoch [69/100], Step [13900/6235], Loss: 51.2284\n",
      "Epoch [69/100], Step [14000/6235], Loss: 13.8863\n",
      "Epoch [69/100], Step [14100/6235], Loss: 40.5492\n",
      "Epoch [69/100], Step [14200/6235], Loss: 125.3019\n",
      "Epoch [69/100], Step [14300/6235], Loss: 50.6802\n",
      "Epoch [69/100], Step [14400/6235], Loss: 38.7735\n",
      "Epoch [69/100], Step [14500/6235], Loss: 50.5621\n",
      "Epoch [69/100], Step [14600/6235], Loss: 0.1731\n",
      "Epoch [69/100], Step [14700/6235], Loss: 45.4993\n",
      "Epoch [69/100], Step [14800/6235], Loss: 31.7482\n",
      "Epoch [69/100], Step [14900/6235], Loss: 1.5374\n",
      "Epoch [69/100], Step [15000/6235], Loss: 2.6677\n",
      "Epoch [69/100], Step [15100/6235], Loss: 0.2742\n",
      "Epoch [69/100], Step [15200/6235], Loss: 0.7901\n",
      "Epoch [69/100], Step [15300/6235], Loss: 41.6751\n",
      "Epoch [69/100], Step [15400/6235], Loss: 92.5450\n",
      "Epoch [69/100], Step [15500/6235], Loss: 10.6589\n",
      "Epoch [69/100], Step [15600/6235], Loss: 77.1107\n",
      "Epoch [69/100], Step [15700/6235], Loss: 37.6815\n",
      "Epoch [69/100], Step [15800/6235], Loss: 10.1487\n",
      "Epoch [69/100], Step [15900/6235], Loss: 0.3254\n",
      "Epoch [69/100], Step [16000/6235], Loss: 35.4175\n",
      "Epoch [69/100], Step [16100/6235], Loss: 5.3574\n",
      "Epoch [69/100], Step [16200/6235], Loss: 0.6629\n",
      "Epoch [69/100], Step [16300/6235], Loss: 10.5360\n",
      "Epoch [69/100], Step [16400/6235], Loss: 29.9435\n",
      "Epoch [69/100], Step [16500/6235], Loss: 683.8765\n",
      "Epoch [69/100], Step [16600/6235], Loss: 6.9338\n",
      "Epoch [69/100], Step [16700/6235], Loss: 0.5599\n",
      "Epoch [69/100], Step [16800/6235], Loss: 10.8169\n",
      "Epoch [69/100], Step [16900/6235], Loss: 0.0699\n",
      "Epoch [69/100], Step [17000/6235], Loss: 0.2555\n",
      "Epoch [69/100], Step [17100/6235], Loss: 0.3552\n",
      "Epoch [69/100], Step [17200/6235], Loss: 300.8581\n",
      "Epoch [69/100], Step [17300/6235], Loss: 45.7260\n",
      "Epoch [69/100], Step [17400/6235], Loss: 44.0152\n",
      "Epoch [69/100], Step [17500/6235], Loss: 0.5404\n",
      "Epoch [69/100], Step [17600/6235], Loss: 3.6227\n",
      "Epoch [69/100], Step [17700/6235], Loss: 72.2002\n",
      "Epoch [69/100], Step [17800/6235], Loss: 19.7676\n",
      "Epoch [69/100], Step [17900/6235], Loss: 6.7611\n",
      "Epoch [69/100], Step [18000/6235], Loss: 4.3914\n",
      "Epoch [69/100], Step [18100/6235], Loss: 20.1625\n",
      "Epoch [69/100], Step [18200/6235], Loss: 0.4724\n",
      "Epoch [69/100], Step [18300/6235], Loss: 5.7101\n",
      "Epoch [69/100], Step [18400/6235], Loss: 1.1782\n",
      "Epoch [69/100], Step [18500/6235], Loss: 29.8931\n",
      "Epoch [69/100], Step [18600/6235], Loss: 4.0379\n",
      "Epoch [69/100], Step [18700/6235], Loss: 0.7686\n",
      "Epoch [69/100], Step [18800/6235], Loss: 158.0924\n",
      "Epoch [69/100], Step [18900/6235], Loss: 62.8247\n",
      "Epoch [69/100], Step [19000/6235], Loss: 8.9704\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Step [19100/6235], Loss: 8.2203\n",
      "Epoch [69/100], Step [19200/6235], Loss: 2.1466\n",
      "Epoch [69/100], Step [19300/6235], Loss: 6.6690\n",
      "Epoch [69/100], Step [19400/6235], Loss: 97.1263\n",
      "Epoch [69/100], Step [19500/6235], Loss: 192.8879\n",
      "Epoch [69/100], Step [19600/6235], Loss: 128.7471\n",
      "Epoch [69/100], Step [19700/6235], Loss: 3.1109\n",
      "Epoch [69/100], Step [19800/6235], Loss: 0.9086\n",
      "Epoch [69/100], Step [19900/6235], Loss: 1.2530\n",
      "Epoch [69/100], Step [20000/6235], Loss: 103.0698\n",
      "Epoch [69/100], Step [20100/6235], Loss: 10.1681\n",
      "Epoch [69/100], Step [20200/6235], Loss: 2.7318\n",
      "Epoch [69/100], Step [20300/6235], Loss: 0.3599\n",
      "Epoch [69/100], Step [20400/6235], Loss: 28.9344\n",
      "Epoch [69/100], Step [20500/6235], Loss: 31.3460\n",
      "Epoch [69/100], Step [20600/6235], Loss: 28.8909\n",
      "Epoch [69/100], Step [20700/6235], Loss: 20.2876\n",
      "Epoch [69/100], Step [20800/6235], Loss: 0.5109\n",
      "Epoch [69/100], Step [20900/6235], Loss: 2.0665\n",
      "Epoch [69/100], Step [21000/6235], Loss: 15.1360\n",
      "Epoch [69/100], Step [21100/6235], Loss: 6.4538\n",
      "Epoch [69/100], Step [21200/6235], Loss: 0.2772\n",
      "Epoch [69/100], Step [21300/6235], Loss: 0.1705\n",
      "Epoch [69/100], Step [21400/6235], Loss: 5.8989\n",
      "Epoch [69/100], Step [21500/6235], Loss: 2.5915\n",
      "Epoch [69/100], Step [21600/6235], Loss: 27.0612\n",
      "Epoch [69/100], Step [21700/6235], Loss: 0.2272\n",
      "Epoch [69/100], Step [21800/6235], Loss: 3.6551\n",
      "Epoch [69/100], Step [21900/6235], Loss: 1.5532\n",
      "Epoch [69/100], Step [22000/6235], Loss: 7.8711\n",
      "Epoch [69/100], Step [22100/6235], Loss: 0.5158\n",
      "Epoch [69/100], Step [22200/6235], Loss: 4.8309\n",
      "Epoch [69/100], Step [22300/6235], Loss: 0.3561\n",
      "Epoch [69/100], Step [22400/6235], Loss: 15.0902\n",
      "Epoch [69/100], Step [22500/6235], Loss: 112.3698\n",
      "Epoch [69/100], Step [22600/6235], Loss: 14.8897\n",
      "Epoch [69/100], Step [22700/6235], Loss: 1.5639\n",
      "Epoch [69/100], Step [22800/6235], Loss: 5.1164\n",
      "Epoch [69/100], Step [22900/6235], Loss: 6.8263\n",
      "Epoch [69/100], Step [23000/6235], Loss: 18.4663\n",
      "Epoch [69/100], Step [23100/6235], Loss: 0.5757\n",
      "Epoch [69/100], Step [23200/6235], Loss: 7.6049\n",
      "Epoch [69/100], Step [23300/6235], Loss: 17.4960\n",
      "Epoch [69/100], Step [23400/6235], Loss: 1.9262\n",
      "Epoch [69/100], Step [23500/6235], Loss: 0.0892\n",
      "Epoch [69/100], Step [23600/6235], Loss: 122.7828\n",
      "Epoch [69/100], Step [23700/6235], Loss: 3.6206\n",
      "Epoch [69/100], Step [23800/6235], Loss: 1.0479\n",
      "Epoch [69/100], Step [23900/6235], Loss: 5.4047\n",
      "Epoch [69/100], Step [24000/6235], Loss: 0.0859\n",
      "Epoch [69/100], Step [24100/6235], Loss: 0.6810\n",
      "Epoch [69/100], Step [24200/6235], Loss: 12.3913\n",
      "Epoch [69/100], Step [24300/6235], Loss: 1.0477\n",
      "Epoch [69/100], Step [24400/6235], Loss: 2.5474\n",
      "Epoch [69/100], Step [24500/6235], Loss: 1.0208\n",
      "Epoch [69/100], Step [24600/6235], Loss: 0.1099\n",
      "Epoch [69/100], Step [24700/6235], Loss: 1.2305\n",
      "Epoch [69/100], Step [24800/6235], Loss: 0.2555\n",
      "Epoch [69/100], Step [24900/6235], Loss: 16.7874\n",
      "Epoch [69/100], Step [25000/6235], Loss: 18.1093\n",
      "Epoch [69/100], Step [25100/6235], Loss: 6.6309\n",
      "Epoch [69/100], Step [25200/6235], Loss: 0.7087\n",
      "Epoch [69/100], Step [25300/6235], Loss: 0.5761\n",
      "Epoch [69/100], Step [25400/6235], Loss: 8.6632\n",
      "Epoch [69/100], Step [25500/6235], Loss: 7.6042\n",
      "Epoch [69/100], Step [25600/6235], Loss: 4.6781\n",
      "Epoch [69/100], Step [25700/6235], Loss: 0.3758\n",
      "Epoch [69/100], Step [25800/6235], Loss: 0.0964\n",
      "Epoch [69/100], Step [25900/6235], Loss: 8.3154\n",
      "Epoch [69/100], Step [26000/6235], Loss: 1.1422\n",
      "Epoch [69/100], Step [26100/6235], Loss: 0.6263\n",
      "Epoch [69/100], Step [26200/6235], Loss: 0.3764\n",
      "Epoch [69/100], Step [26300/6235], Loss: 4.8355\n",
      "Epoch [69/100], Step [26400/6235], Loss: 0.0714\n",
      "Epoch [69/100], Step [26500/6235], Loss: 0.0285\n",
      "Epoch [69/100], Step [26600/6235], Loss: 1.8353\n",
      "Epoch [69/100], Step [26700/6235], Loss: 0.4212\n",
      "Epoch [69/100], Step [26800/6235], Loss: 0.2302\n",
      "Epoch [69/100], Step [26900/6235], Loss: 0.0010\n",
      "Epoch [69/100], Step [27000/6235], Loss: 14.5965\n",
      "Epoch [69/100], Step [27100/6235], Loss: 0.0522\n",
      "Epoch [69/100], Step [27200/6235], Loss: 0.0296\n",
      "Epoch [69/100], Step [27300/6235], Loss: 0.2333\n",
      "Epoch [69/100], Step [27400/6235], Loss: 0.7924\n",
      "Epoch [69/100], Step [27500/6235], Loss: 17.8973\n",
      "Epoch [69/100], Step [27600/6235], Loss: 0.5243\n",
      "Epoch [69/100], Step [27700/6235], Loss: 0.2450\n",
      "Epoch [69/100], Step [27800/6235], Loss: 6.3129\n",
      "Epoch [69/100], Step [27900/6235], Loss: 0.2790\n",
      "Epoch [69/100], Step [28000/6235], Loss: 127.7241\n",
      "Epoch [69/100], Step [28100/6235], Loss: 5.7838\n",
      "Epoch [69/100], Step [28200/6235], Loss: 30.6156\n",
      "Epoch [69/100], Step [28300/6235], Loss: 2.8948\n",
      "Epoch [69/100], Step [28400/6235], Loss: 25.8135\n",
      "Epoch [69/100], Step [28500/6235], Loss: 4.1812\n",
      "Epoch [69/100], Step [28600/6235], Loss: 0.0276\n",
      "Epoch [69/100], Step [28700/6235], Loss: 5.5966\n",
      "Epoch [69/100], Step [28800/6235], Loss: 0.5934\n",
      "Epoch [69/100], Step [28900/6235], Loss: 73.1374\n",
      "Epoch [69/100], Step [29000/6235], Loss: 11.9139\n",
      "Epoch [69/100], Step [29100/6235], Loss: 0.0651\n",
      "Epoch [69/100], Step [29200/6235], Loss: 0.7740\n",
      "Epoch [69/100], Step [29300/6235], Loss: 18.6748\n",
      "Epoch [69/100], Step [29400/6235], Loss: 0.6275\n",
      "Epoch [69/100], Step [29500/6235], Loss: 0.1179\n",
      "Epoch [69/100], Step [29600/6235], Loss: 0.5802\n",
      "Epoch [69/100], Step [29700/6235], Loss: 1.3263\n",
      "Epoch [69/100], Step [29800/6235], Loss: 1.6219\n",
      "Epoch [69/100], Step [29900/6235], Loss: 0.9423\n",
      "Epoch [69/100], Step [30000/6235], Loss: 5.1378\n",
      "Epoch [69/100], Step [30100/6235], Loss: 10.8500\n",
      "Epoch [69/100], Step [30200/6235], Loss: 0.8457\n",
      "Epoch [69/100], Step [30300/6235], Loss: 0.0067\n",
      "Epoch [69/100], Step [30400/6235], Loss: 0.8479\n",
      "Epoch [69/100], Step [30500/6235], Loss: 3.2458\n",
      "Epoch [69/100], Step [30600/6235], Loss: 1.6086\n",
      "Epoch [69/100], Step [30700/6235], Loss: 0.2544\n",
      "Epoch [69/100], Step [30800/6235], Loss: 0.4440\n",
      "Epoch [69/100], Step [30900/6235], Loss: 3.9745\n",
      "Epoch [69/100], Step [31000/6235], Loss: 0.0969\n",
      "Epoch [69/100], Step [31100/6235], Loss: 0.0314\n",
      "Epoch [69/100], Step [31200/6235], Loss: 6.2340\n",
      "Epoch [69/100], Step [31300/6235], Loss: 0.8644\n",
      "Epoch [69/100], Step [31400/6235], Loss: 1.3170\n",
      "Epoch [69/100], Step [31500/6235], Loss: 0.6726\n",
      "Epoch [69/100], Step [31600/6235], Loss: 5.1368\n",
      "Epoch [69/100], Step [31700/6235], Loss: 1.5543\n",
      "Epoch [69/100], Step [31800/6235], Loss: 0.7694\n",
      "Epoch [69/100], Step [31900/6235], Loss: 1177.4301\n",
      "Epoch [69/100], Step [32000/6235], Loss: 0.5665\n",
      "Epoch [69/100], Step [32100/6235], Loss: 0.4022\n",
      "Epoch [69/100], Step [32200/6235], Loss: 112.1381\n",
      "Epoch [69/100], Step [32300/6235], Loss: 1.7343\n",
      "Epoch [69/100], Step [32400/6235], Loss: 1.5548\n",
      "Epoch [69/100], Step [32500/6235], Loss: 13.3748\n",
      "Epoch [69/100], Step [32600/6235], Loss: 0.4572\n",
      "Epoch [69/100], Step [32700/6235], Loss: 130.7491\n",
      "Epoch [69/100], Step [32800/6235], Loss: 6.2114\n",
      "Epoch [69/100], Step [32900/6235], Loss: 0.4199\n",
      "Epoch [69/100], Step [33000/6235], Loss: 0.1478\n",
      "Epoch [69/100], Step [33100/6235], Loss: 0.4979\n",
      "Epoch [69/100], Step [33200/6235], Loss: 1.2146\n",
      "Epoch [69/100], Step [33300/6235], Loss: 0.7638\n",
      "Epoch [69/100], Step [33400/6235], Loss: 83.6174\n",
      "Epoch [69/100], Step [33500/6235], Loss: 2.1586\n",
      "Epoch [69/100], Step [33600/6235], Loss: 7.9257\n",
      "Epoch [69/100], Step [33700/6235], Loss: 8.1147\n",
      "Epoch [69/100], Step [33800/6235], Loss: 1.7334\n",
      "Epoch [69/100], Step [33900/6235], Loss: 27.0722\n",
      "Epoch [69/100], Step [34000/6235], Loss: 0.0835\n",
      "Epoch [69/100], Step [34100/6235], Loss: 0.5006\n",
      "Epoch [69/100], Step [34200/6235], Loss: 2.0738\n",
      "Epoch [69/100], Step [34300/6235], Loss: 3.9269\n",
      "Epoch [69/100], Step [34400/6235], Loss: 0.1431\n",
      "Epoch [69/100], Step [34500/6235], Loss: 16.4795\n",
      "Epoch [69/100], Step [34600/6235], Loss: 1.6039\n",
      "Epoch [69/100], Step [34700/6235], Loss: 23.9483\n",
      "Epoch [69/100], Step [34800/6235], Loss: 10.2988\n",
      "Epoch [69/100], Step [34900/6235], Loss: 66.6391\n",
      "Epoch [69/100], Step [35000/6235], Loss: 0.2197\n",
      "Epoch [69/100], Step [35100/6235], Loss: 0.8824\n",
      "Epoch [69/100], Step [35200/6235], Loss: 0.5734\n",
      "Epoch [69/100], Step [35300/6235], Loss: 3.0912\n",
      "Epoch [69/100], Step [35400/6235], Loss: 0.5611\n",
      "Epoch [69/100], Step [35500/6235], Loss: 0.7287\n",
      "Epoch [69/100], Step [35600/6235], Loss: 0.4569\n",
      "Epoch [69/100], Step [35700/6235], Loss: 3.6455\n",
      "Epoch [69/100], Step [35800/6235], Loss: 2.1406\n",
      "Epoch [69/100], Step [35900/6235], Loss: 1.6854\n",
      "Epoch [69/100], Step [36000/6235], Loss: 0.0174\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [69/100], Step [36100/6235], Loss: 0.0368\n",
      "Epoch [69/100], Step [36200/6235], Loss: 28.6689\n",
      "Epoch [69/100], Step [36300/6235], Loss: 1.0632\n",
      "Epoch [69/100], Step [36400/6235], Loss: 3.0264\n",
      "Epoch [69/100], Step [36500/6235], Loss: 7.5989\n",
      "Epoch [69/100], Step [36600/6235], Loss: 0.1212\n",
      "Epoch [69/100], Step [36700/6235], Loss: 0.5968\n",
      "Epoch [69/100], Step [36800/6235], Loss: 5.2926\n",
      "Epoch [69/100], Step [36900/6235], Loss: 10.8545\n",
      "Epoch [69/100], Step [37000/6235], Loss: 0.9337\n",
      "Epoch [69/100], Step [37100/6235], Loss: 1.9568\n",
      "Epoch [69/100], Step [37200/6235], Loss: 0.0497\n",
      "Epoch [69/100], Step [37300/6235], Loss: 0.0363\n",
      "Epoch [69/100], Step [37400/6235], Loss: 0.1742\n",
      "Epoch [69/100], Step [37500/6235], Loss: 6.2602\n",
      "Epoch [69/100], Step [37600/6235], Loss: 12.0452\n",
      "Epoch [69/100], Step [37700/6235], Loss: 0.6988\n",
      "Epoch [69/100], Step [37800/6235], Loss: 6.6349\n",
      "Epoch [69/100], Step [37900/6235], Loss: 6.2289\n",
      "Epoch [69/100], Step [38000/6235], Loss: 0.9727\n",
      "Epoch [69/100], Step [38100/6235], Loss: 4.6790\n",
      "Epoch [69/100], Step [38200/6235], Loss: 2.8909\n",
      "Epoch [69/100], Step [38300/6235], Loss: 0.3196\n",
      "Epoch [69/100], Step [38400/6235], Loss: 0.0704\n",
      "Epoch [69/100], Step [38500/6235], Loss: 1.6360\n",
      "Epoch [69/100], Step [38600/6235], Loss: 0.4014\n",
      "Epoch [69/100], Step [38700/6235], Loss: 0.1714\n",
      "Epoch [69/100], Step [38800/6235], Loss: 0.1450\n",
      "Epoch [69/100], Step [38900/6235], Loss: 19.2684\n",
      "Epoch [69/100], Step [39000/6235], Loss: 7.5829\n",
      "Epoch [69/100], Step [39100/6235], Loss: 8.8648\n",
      "Epoch [69/100], Step [39200/6235], Loss: 0.3469\n",
      "Epoch [69/100], Step [39300/6235], Loss: 18.1242\n",
      "Epoch [69/100], Step [39400/6235], Loss: 342.9585\n",
      "Epoch [69/100], Step [39500/6235], Loss: 182.8083\n",
      "Epoch [69/100], Step [39600/6235], Loss: 19.3783\n",
      "Epoch [69/100], Step [39700/6235], Loss: 197.6835\n",
      "Epoch [69/100], Step [39800/6235], Loss: 11.1418\n",
      "Epoch [69/100], Step [39900/6235], Loss: 0.2550\n",
      "Epoch [69/100], Step [40000/6235], Loss: 46.9016\n",
      "Epoch [69/100], Step [40100/6235], Loss: 27.2154\n",
      "Epoch [69/100], Step [40200/6235], Loss: 4.3289\n",
      "Epoch [69/100], Step [40300/6235], Loss: 0.9608\n",
      "Epoch [69/100], Step [40400/6235], Loss: 2.2604\n",
      "Epoch [69/100], Step [40500/6235], Loss: 2.2157\n",
      "Epoch [69/100], Step [40600/6235], Loss: 0.2822\n",
      "Epoch [69/100], Step [40700/6235], Loss: 7.5233\n",
      "Epoch [69/100], Step [40800/6235], Loss: 1.2485\n",
      "Epoch [69/100], Step [40900/6235], Loss: 0.1720\n",
      "Epoch [69/100], Step [41000/6235], Loss: 48.2875\n",
      "Epoch [69/100], Step [41100/6235], Loss: 47.8225\n",
      "Epoch [69/100], Step [41200/6235], Loss: 16.5668\n",
      "Epoch [69/100], Step [41300/6235], Loss: 6.5201\n",
      "Epoch [69/100], Step [41400/6235], Loss: 3.1653\n",
      "Epoch [69/100], Step [41500/6235], Loss: 1.4161\n",
      "Epoch [69/100], Step [41600/6235], Loss: 0.0349\n",
      "Epoch [69/100], Step [41700/6235], Loss: 4.0493\n",
      "Epoch [69/100], Step [41800/6235], Loss: 1.2081\n",
      "Epoch [69/100], Step [41900/6235], Loss: 3.2693\n",
      "Epoch [69/100], Step [42000/6235], Loss: 2.9382\n",
      "Epoch [69/100], Step [42100/6235], Loss: 7.0008\n",
      "Epoch [69/100], Step [42200/6235], Loss: 1.6305\n",
      "Epoch [69/100], Step [42300/6235], Loss: 2.6978\n",
      "Epoch [69/100], Step [42400/6235], Loss: 0.2510\n",
      "Epoch [69/100], Step [42500/6235], Loss: 0.8639\n",
      "Epoch [69/100], Step [42600/6235], Loss: 0.5041\n",
      "Epoch [69/100], Step [42700/6235], Loss: 0.2365\n",
      "Epoch [69/100], Step [42800/6235], Loss: 1.0353\n",
      "Epoch [69/100], Step [42900/6235], Loss: 4.2220\n",
      "Epoch [69/100], Step [43000/6235], Loss: 0.2733\n",
      "Epoch [69/100], Step [43100/6235], Loss: 0.7222\n",
      "Epoch [69/100], Step [43200/6235], Loss: 0.9028\n",
      "Epoch [69/100], Step [43300/6235], Loss: 9.0973\n",
      "Epoch [69/100], Step [43400/6235], Loss: 4.6981\n",
      "Epoch [69/100], Step [43500/6235], Loss: 9.4966\n",
      "Epoch [69/100], Step [43600/6235], Loss: 17.1266\n",
      "Epoch [69/100], Step [43700/6235], Loss: 35.7950\n",
      "Epoch [69/100], Step [43800/6235], Loss: 3.2976\n",
      "Epoch [69/100], Step [43900/6235], Loss: 0.2233\n",
      "Epoch [69/100], Step [44000/6235], Loss: 62.0932\n",
      "Epoch [69/100], Step [44100/6235], Loss: 2.8968\n",
      "Epoch [69/100], Step [44200/6235], Loss: 5.6030\n",
      "Epoch [69/100], Step [44300/6235], Loss: 10.6909\n",
      "Epoch [69/100], Step [44400/6235], Loss: 0.6171\n",
      "Epoch [69/100], Step [44500/6235], Loss: 0.1735\n",
      "Epoch [69/100], Step [44600/6235], Loss: 16.2915\n",
      "Epoch [69/100], Step [44700/6235], Loss: 0.7845\n",
      "Epoch [69/100], Step [44800/6235], Loss: 2.8558\n",
      "Epoch [69/100], Step [44900/6235], Loss: 8.1755\n",
      "Epoch [69/100], Step [45000/6235], Loss: 5.2764\n",
      "Epoch [69/100], Step [45100/6235], Loss: 21.7331\n",
      "Epoch [69/100], Step [45200/6235], Loss: 3.0891\n",
      "Epoch [69/100], Step [45300/6235], Loss: 27.7007\n",
      "Epoch [69/100], Step [45400/6235], Loss: 14.1599\n",
      "Epoch [69/100], Step [45500/6235], Loss: 1.8238\n",
      "Epoch [69/100], Step [45600/6235], Loss: 0.8815\n",
      "Epoch [69/100], Step [45700/6235], Loss: 130.6787\n",
      "Epoch [69/100], Step [45800/6235], Loss: 230.7207\n",
      "Epoch [69/100], Step [45900/6235], Loss: 6.4348\n",
      "Epoch [69/100], Step [46000/6235], Loss: 153.0889\n",
      "Epoch [69/100], Step [46100/6235], Loss: 188.5537\n",
      "Epoch [69/100], Step [46200/6235], Loss: 4.7430\n",
      "Epoch [69/100], Step [46300/6235], Loss: 46.7181\n",
      "Epoch [69/100], Step [46400/6235], Loss: 0.8890\n",
      "Epoch [69/100], Step [46500/6235], Loss: 11.3684\n",
      "Epoch [69/100], Step [46600/6235], Loss: 7.8562\n",
      "Epoch [69/100], Step [46700/6235], Loss: 54.2709\n",
      "Epoch [69/100], Step [46800/6235], Loss: 4.7727\n",
      "Epoch [69/100], Step [46900/6235], Loss: 76.8330\n",
      "Epoch [69/100], Step [47000/6235], Loss: 3.0896\n",
      "Epoch [69/100], Step [47100/6235], Loss: 122.5040\n",
      "Epoch [69/100], Step [47200/6235], Loss: 8.8249\n",
      "Epoch [69/100], Step [47300/6235], Loss: 13.2476\n",
      "Epoch [69/100], Step [47400/6235], Loss: 292.5894\n",
      "Epoch [69/100], Step [47500/6235], Loss: 0.5574\n",
      "Epoch [69/100], Step [47600/6235], Loss: 5.6961\n",
      "Epoch [69/100], Step [47700/6235], Loss: 10.5537\n",
      "Epoch [69/100], Step [47800/6235], Loss: 9.9662\n",
      "Epoch [69/100], Step [47900/6235], Loss: 14.0288\n",
      "Epoch [69/100], Step [48000/6235], Loss: 117.9737\n",
      "Epoch [69/100], Step [48100/6235], Loss: 21.6695\n",
      "Epoch [69/100], Step [48200/6235], Loss: 114.2687\n",
      "Epoch [69/100], Step [48300/6235], Loss: 419.8817\n",
      "Epoch [69/100], Step [48400/6235], Loss: 5.1231\n",
      "Epoch [69/100], Step [48500/6235], Loss: 5.1168\n",
      "Epoch [69/100], Step [48600/6235], Loss: 3.0705\n",
      "Epoch [69/100], Step [48700/6235], Loss: 8.1416\n",
      "Epoch [69/100], Step [48800/6235], Loss: 433.0864\n",
      "Epoch [69/100], Step [48900/6235], Loss: 81.3785\n",
      "Epoch [69/100], Step [49000/6235], Loss: 220.0600\n",
      "Epoch [69/100], Step [49100/6235], Loss: 2188.3499\n",
      "Epoch [69/100], Step [49200/6235], Loss: 523.2985\n",
      "Epoch [69/100], Step [49300/6235], Loss: 608.1935\n",
      "Epoch [69/100], Step [49400/6235], Loss: 2.0958\n",
      "Epoch [69/100], Step [49500/6235], Loss: 23.3965\n",
      "Epoch [69/100], Step [49600/6235], Loss: 242.5906\n",
      "Epoch [69/100], Step [49700/6235], Loss: 5397.7915\n",
      "Epoch [69/100], Step [49800/6235], Loss: 230.4263\n",
      "Epoch [70/100], Step [100/6235], Loss: 22.7343\n",
      "Epoch [70/100], Step [200/6235], Loss: 0.2797\n",
      "Epoch [70/100], Step [300/6235], Loss: 0.0032\n",
      "Epoch [70/100], Step [400/6235], Loss: 0.0023\n",
      "Epoch [70/100], Step [500/6235], Loss: 4.5625\n",
      "Epoch [70/100], Step [600/6235], Loss: 0.0270\n",
      "Epoch [70/100], Step [700/6235], Loss: 0.6135\n",
      "Epoch [70/100], Step [800/6235], Loss: 0.0815\n",
      "Epoch [70/100], Step [900/6235], Loss: 0.0758\n",
      "Epoch [70/100], Step [1000/6235], Loss: 0.0302\n",
      "Epoch [70/100], Step [1100/6235], Loss: 0.2104\n",
      "Epoch [70/100], Step [1200/6235], Loss: 0.1736\n",
      "Epoch [70/100], Step [1300/6235], Loss: 0.0153\n",
      "Epoch [70/100], Step [1400/6235], Loss: 0.2073\n",
      "Epoch [70/100], Step [1500/6235], Loss: 0.0072\n",
      "Epoch [70/100], Step [1600/6235], Loss: 0.2327\n",
      "Epoch [70/100], Step [1700/6235], Loss: 0.1246\n",
      "Epoch [70/100], Step [1800/6235], Loss: 0.2368\n",
      "Epoch [70/100], Step [1900/6235], Loss: 0.2624\n",
      "Epoch [70/100], Step [2000/6235], Loss: 2.2165\n",
      "Epoch [70/100], Step [2100/6235], Loss: 1.9870\n",
      "Epoch [70/100], Step [2200/6235], Loss: 5.9586\n",
      "Epoch [70/100], Step [2300/6235], Loss: 0.6666\n",
      "Epoch [70/100], Step [2400/6235], Loss: 1.2795\n",
      "Epoch [70/100], Step [2500/6235], Loss: 24.3443\n",
      "Epoch [70/100], Step [2600/6235], Loss: 14.3089\n",
      "Epoch [70/100], Step [2700/6235], Loss: 6.9630\n",
      "Epoch [70/100], Step [2800/6235], Loss: 147.9562\n",
      "Epoch [70/100], Step [2900/6235], Loss: 16.4244\n",
      "Epoch [70/100], Step [3000/6235], Loss: 0.5600\n",
      "Epoch [70/100], Step [3100/6235], Loss: 70.4107\n",
      "Epoch [70/100], Step [3200/6235], Loss: 34.5731\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Step [3300/6235], Loss: 8.3340\n",
      "Epoch [70/100], Step [3400/6235], Loss: 4.7155\n",
      "Epoch [70/100], Step [3500/6235], Loss: 54.4936\n",
      "Epoch [70/100], Step [3600/6235], Loss: 0.6345\n",
      "Epoch [70/100], Step [3700/6235], Loss: 0.0699\n",
      "Epoch [70/100], Step [3800/6235], Loss: 0.0764\n",
      "Epoch [70/100], Step [3900/6235], Loss: 0.1292\n",
      "Epoch [70/100], Step [4000/6235], Loss: 0.1467\n",
      "Epoch [70/100], Step [4100/6235], Loss: 9.8519\n",
      "Epoch [70/100], Step [4200/6235], Loss: 4.6404\n",
      "Epoch [70/100], Step [4300/6235], Loss: 5.2661\n",
      "Epoch [70/100], Step [4400/6235], Loss: 0.5179\n",
      "Epoch [70/100], Step [4500/6235], Loss: 39.4610\n",
      "Epoch [70/100], Step [4600/6235], Loss: 2.7090\n",
      "Epoch [70/100], Step [4700/6235], Loss: 0.2530\n",
      "Epoch [70/100], Step [4800/6235], Loss: 6.3703\n",
      "Epoch [70/100], Step [4900/6235], Loss: 2.3277\n",
      "Epoch [70/100], Step [5000/6235], Loss: 0.0358\n",
      "Epoch [70/100], Step [5100/6235], Loss: 0.1384\n",
      "Epoch [70/100], Step [5200/6235], Loss: 4.3142\n",
      "Epoch [70/100], Step [5300/6235], Loss: 22.0732\n",
      "Epoch [70/100], Step [5400/6235], Loss: 1.4826\n",
      "Epoch [70/100], Step [5500/6235], Loss: 0.1294\n",
      "Epoch [70/100], Step [5600/6235], Loss: 0.3375\n",
      "Epoch [70/100], Step [5700/6235], Loss: 0.0907\n",
      "Epoch [70/100], Step [5800/6235], Loss: 0.1375\n",
      "Epoch [70/100], Step [5900/6235], Loss: 0.1357\n",
      "Epoch [70/100], Step [6000/6235], Loss: 0.1669\n",
      "Epoch [70/100], Step [6100/6235], Loss: 0.1182\n",
      "Epoch [70/100], Step [6200/6235], Loss: 7.2013\n",
      "Epoch [70/100], Step [6300/6235], Loss: 0.3981\n",
      "Epoch [70/100], Step [6400/6235], Loss: 0.0215\n",
      "Epoch [70/100], Step [6500/6235], Loss: 0.8543\n",
      "Epoch [70/100], Step [6600/6235], Loss: 6.3993\n",
      "Epoch [70/100], Step [6700/6235], Loss: 1.0860\n",
      "Epoch [70/100], Step [6800/6235], Loss: 0.4459\n",
      "Epoch [70/100], Step [6900/6235], Loss: 0.5076\n",
      "Epoch [70/100], Step [7000/6235], Loss: 0.4330\n",
      "Epoch [70/100], Step [7100/6235], Loss: 0.3971\n",
      "Epoch [70/100], Step [7200/6235], Loss: 0.0976\n",
      "Epoch [70/100], Step [7300/6235], Loss: 0.7223\n",
      "Epoch [70/100], Step [7400/6235], Loss: 0.0720\n",
      "Epoch [70/100], Step [7500/6235], Loss: 0.7997\n",
      "Epoch [70/100], Step [7600/6235], Loss: 4.8030\n",
      "Epoch [70/100], Step [7700/6235], Loss: 9.3603\n",
      "Epoch [70/100], Step [7800/6235], Loss: 2.0736\n",
      "Epoch [70/100], Step [7900/6235], Loss: 3.3911\n",
      "Epoch [70/100], Step [8000/6235], Loss: 0.3791\n",
      "Epoch [70/100], Step [8100/6235], Loss: 0.7873\n",
      "Epoch [70/100], Step [8200/6235], Loss: 9.9386\n",
      "Epoch [70/100], Step [8300/6235], Loss: 19.3984\n",
      "Epoch [70/100], Step [8400/6235], Loss: 651.2702\n",
      "Epoch [70/100], Step [8500/6235], Loss: 18.4748\n",
      "Epoch [70/100], Step [8600/6235], Loss: 20.5458\n",
      "Epoch [70/100], Step [8700/6235], Loss: 37.4474\n",
      "Epoch [70/100], Step [8800/6235], Loss: 524.4917\n",
      "Epoch [70/100], Step [8900/6235], Loss: 366.4734\n",
      "Epoch [70/100], Step [9000/6235], Loss: 358.9227\n",
      "Epoch [70/100], Step [9100/6235], Loss: 1036.0876\n",
      "Epoch [70/100], Step [9200/6235], Loss: 2768.2996\n",
      "Epoch [70/100], Step [9300/6235], Loss: 142.5075\n",
      "Epoch [70/100], Step [9400/6235], Loss: 174.6219\n",
      "Epoch [70/100], Step [9500/6235], Loss: 1817.1229\n",
      "Epoch [70/100], Step [9600/6235], Loss: 1229.1678\n",
      "Epoch [70/100], Step [9700/6235], Loss: 0.5264\n",
      "Epoch [70/100], Step [9800/6235], Loss: 2514.0762\n",
      "Epoch [70/100], Step [9900/6235], Loss: 36.6195\n",
      "Epoch [70/100], Step [10000/6235], Loss: 403.6193\n",
      "Epoch [70/100], Step [10100/6235], Loss: 4.6843\n",
      "Epoch [70/100], Step [10200/6235], Loss: 533.5370\n",
      "Epoch [70/100], Step [10300/6235], Loss: 48.6663\n",
      "Epoch [70/100], Step [10400/6235], Loss: 7.7609\n",
      "Epoch [70/100], Step [10500/6235], Loss: 16.4299\n",
      "Epoch [70/100], Step [10600/6235], Loss: 13.4939\n",
      "Epoch [70/100], Step [10700/6235], Loss: 13.6215\n",
      "Epoch [70/100], Step [10800/6235], Loss: 73.1847\n",
      "Epoch [70/100], Step [10900/6235], Loss: 11.9591\n",
      "Epoch [70/100], Step [11000/6235], Loss: 300.9115\n",
      "Epoch [70/100], Step [11100/6235], Loss: 47.2755\n",
      "Epoch [70/100], Step [11200/6235], Loss: 21.5830\n",
      "Epoch [70/100], Step [11300/6235], Loss: 118.3486\n",
      "Epoch [70/100], Step [11400/6235], Loss: 23.2447\n",
      "Epoch [70/100], Step [11500/6235], Loss: 10.8074\n",
      "Epoch [70/100], Step [11600/6235], Loss: 7.4353\n",
      "Epoch [70/100], Step [11700/6235], Loss: 51.0267\n",
      "Epoch [70/100], Step [11800/6235], Loss: 385.8015\n",
      "Epoch [70/100], Step [11900/6235], Loss: 15.4689\n",
      "Epoch [70/100], Step [12000/6235], Loss: 746.1622\n",
      "Epoch [70/100], Step [12100/6235], Loss: 221.5042\n",
      "Epoch [70/100], Step [12200/6235], Loss: 42.9682\n",
      "Epoch [70/100], Step [12300/6235], Loss: 20.8636\n",
      "Epoch [70/100], Step [12400/6235], Loss: 209.7414\n",
      "Epoch [70/100], Step [12500/6235], Loss: 10.2432\n",
      "Epoch [70/100], Step [12600/6235], Loss: 59.5702\n",
      "Epoch [70/100], Step [12700/6235], Loss: 2.4114\n",
      "Epoch [70/100], Step [12800/6235], Loss: 5.7374\n",
      "Epoch [70/100], Step [12900/6235], Loss: 31.3173\n",
      "Epoch [70/100], Step [13000/6235], Loss: 0.0507\n",
      "Epoch [70/100], Step [13100/6235], Loss: 63.2228\n",
      "Epoch [70/100], Step [13200/6235], Loss: 9.1474\n",
      "Epoch [70/100], Step [13300/6235], Loss: 37.3301\n",
      "Epoch [70/100], Step [13400/6235], Loss: 237.0587\n",
      "Epoch [70/100], Step [13500/6235], Loss: 1.9894\n",
      "Epoch [70/100], Step [13600/6235], Loss: 6.9868\n",
      "Epoch [70/100], Step [13700/6235], Loss: 0.4141\n",
      "Epoch [70/100], Step [13800/6235], Loss: 170.4187\n",
      "Epoch [70/100], Step [13900/6235], Loss: 54.4843\n",
      "Epoch [70/100], Step [14000/6235], Loss: 10.8796\n",
      "Epoch [70/100], Step [14100/6235], Loss: 26.7907\n",
      "Epoch [70/100], Step [14200/6235], Loss: 21.7060\n",
      "Epoch [70/100], Step [14300/6235], Loss: 27.1080\n",
      "Epoch [70/100], Step [14400/6235], Loss: 38.6769\n",
      "Epoch [70/100], Step [14500/6235], Loss: 31.7502\n",
      "Epoch [70/100], Step [14600/6235], Loss: 0.3848\n",
      "Epoch [70/100], Step [14700/6235], Loss: 43.4184\n",
      "Epoch [70/100], Step [14800/6235], Loss: 33.3728\n",
      "Epoch [70/100], Step [14900/6235], Loss: 0.7558\n",
      "Epoch [70/100], Step [15000/6235], Loss: 1.8305\n",
      "Epoch [70/100], Step [15100/6235], Loss: 0.5088\n",
      "Epoch [70/100], Step [15200/6235], Loss: 9.2303\n",
      "Epoch [70/100], Step [15300/6235], Loss: 36.4056\n",
      "Epoch [70/100], Step [15400/6235], Loss: 0.6763\n",
      "Epoch [70/100], Step [15500/6235], Loss: 11.3719\n",
      "Epoch [70/100], Step [15600/6235], Loss: 169.9272\n",
      "Epoch [70/100], Step [15700/6235], Loss: 78.0348\n",
      "Epoch [70/100], Step [15800/6235], Loss: 4.7038\n",
      "Epoch [70/100], Step [15900/6235], Loss: 0.7833\n",
      "Epoch [70/100], Step [16000/6235], Loss: 123.1338\n",
      "Epoch [70/100], Step [16100/6235], Loss: 0.7169\n",
      "Epoch [70/100], Step [16200/6235], Loss: 0.7983\n",
      "Epoch [70/100], Step [16300/6235], Loss: 9.4125\n",
      "Epoch [70/100], Step [16400/6235], Loss: 24.1278\n",
      "Epoch [70/100], Step [16500/6235], Loss: 340.2664\n",
      "Epoch [70/100], Step [16600/6235], Loss: 26.4176\n",
      "Epoch [70/100], Step [16700/6235], Loss: 0.3049\n",
      "Epoch [70/100], Step [16800/6235], Loss: 15.3580\n",
      "Epoch [70/100], Step [16900/6235], Loss: 0.1621\n",
      "Epoch [70/100], Step [17000/6235], Loss: 0.1839\n",
      "Epoch [70/100], Step [17100/6235], Loss: 0.1737\n",
      "Epoch [70/100], Step [17200/6235], Loss: 281.7831\n",
      "Epoch [70/100], Step [17300/6235], Loss: 32.6152\n",
      "Epoch [70/100], Step [17400/6235], Loss: 34.6541\n",
      "Epoch [70/100], Step [17500/6235], Loss: 0.9655\n",
      "Epoch [70/100], Step [17600/6235], Loss: 2.7471\n",
      "Epoch [70/100], Step [17700/6235], Loss: 66.4075\n",
      "Epoch [70/100], Step [17800/6235], Loss: 34.9629\n",
      "Epoch [70/100], Step [17900/6235], Loss: 9.6634\n",
      "Epoch [70/100], Step [18000/6235], Loss: 8.5682\n",
      "Epoch [70/100], Step [18100/6235], Loss: 15.5238\n",
      "Epoch [70/100], Step [18200/6235], Loss: 0.9186\n",
      "Epoch [70/100], Step [18300/6235], Loss: 5.0069\n",
      "Epoch [70/100], Step [18400/6235], Loss: 3.2481\n",
      "Epoch [70/100], Step [18500/6235], Loss: 10.6356\n",
      "Epoch [70/100], Step [18600/6235], Loss: 2.1414\n",
      "Epoch [70/100], Step [18700/6235], Loss: 0.5360\n",
      "Epoch [70/100], Step [18800/6235], Loss: 51.7755\n",
      "Epoch [70/100], Step [18900/6235], Loss: 15.1957\n",
      "Epoch [70/100], Step [19000/6235], Loss: 11.2009\n",
      "Epoch [70/100], Step [19100/6235], Loss: 42.2901\n",
      "Epoch [70/100], Step [19200/6235], Loss: 7.0878\n",
      "Epoch [70/100], Step [19300/6235], Loss: 3.3970\n",
      "Epoch [70/100], Step [19400/6235], Loss: 48.5150\n",
      "Epoch [70/100], Step [19500/6235], Loss: 86.0298\n",
      "Epoch [70/100], Step [19600/6235], Loss: 141.1110\n",
      "Epoch [70/100], Step [19700/6235], Loss: 11.6181\n",
      "Epoch [70/100], Step [19800/6235], Loss: 3.3297\n",
      "Epoch [70/100], Step [19900/6235], Loss: 0.1396\n",
      "Epoch [70/100], Step [20000/6235], Loss: 66.6837\n",
      "Epoch [70/100], Step [20100/6235], Loss: 0.9580\n",
      "Epoch [70/100], Step [20200/6235], Loss: 2.0073\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Step [20300/6235], Loss: 1.7735\n",
      "Epoch [70/100], Step [20400/6235], Loss: 15.4314\n",
      "Epoch [70/100], Step [20500/6235], Loss: 45.2206\n",
      "Epoch [70/100], Step [20600/6235], Loss: 41.8253\n",
      "Epoch [70/100], Step [20700/6235], Loss: 9.2141\n",
      "Epoch [70/100], Step [20800/6235], Loss: 46.2618\n",
      "Epoch [70/100], Step [20900/6235], Loss: 26.7292\n",
      "Epoch [70/100], Step [21000/6235], Loss: 17.3882\n",
      "Epoch [70/100], Step [21100/6235], Loss: 0.4342\n",
      "Epoch [70/100], Step [21200/6235], Loss: 0.0956\n",
      "Epoch [70/100], Step [21300/6235], Loss: 0.2133\n",
      "Epoch [70/100], Step [21400/6235], Loss: 4.7802\n",
      "Epoch [70/100], Step [21500/6235], Loss: 5.3387\n",
      "Epoch [70/100], Step [21600/6235], Loss: 3.3913\n",
      "Epoch [70/100], Step [21700/6235], Loss: 0.2869\n",
      "Epoch [70/100], Step [21800/6235], Loss: 30.8417\n",
      "Epoch [70/100], Step [21900/6235], Loss: 0.4931\n",
      "Epoch [70/100], Step [22000/6235], Loss: 4.9884\n",
      "Epoch [70/100], Step [22100/6235], Loss: 1.9281\n",
      "Epoch [70/100], Step [22200/6235], Loss: 2.0226\n",
      "Epoch [70/100], Step [22300/6235], Loss: 0.3242\n",
      "Epoch [70/100], Step [22400/6235], Loss: 1.8743\n",
      "Epoch [70/100], Step [22500/6235], Loss: 66.1262\n",
      "Epoch [70/100], Step [22600/6235], Loss: 11.8049\n",
      "Epoch [70/100], Step [22700/6235], Loss: 0.2661\n",
      "Epoch [70/100], Step [22800/6235], Loss: 11.1778\n",
      "Epoch [70/100], Step [22900/6235], Loss: 10.5464\n",
      "Epoch [70/100], Step [23000/6235], Loss: 5.2275\n",
      "Epoch [70/100], Step [23100/6235], Loss: 8.1002\n",
      "Epoch [70/100], Step [23200/6235], Loss: 8.4783\n",
      "Epoch [70/100], Step [23300/6235], Loss: 17.3196\n",
      "Epoch [70/100], Step [23400/6235], Loss: 1.7740\n",
      "Epoch [70/100], Step [23500/6235], Loss: 0.1137\n",
      "Epoch [70/100], Step [23600/6235], Loss: 111.4642\n",
      "Epoch [70/100], Step [23700/6235], Loss: 7.1657\n",
      "Epoch [70/100], Step [23800/6235], Loss: 1.0174\n",
      "Epoch [70/100], Step [23900/6235], Loss: 6.6607\n",
      "Epoch [70/100], Step [24000/6235], Loss: 0.4495\n",
      "Epoch [70/100], Step [24100/6235], Loss: 1.4293\n",
      "Epoch [70/100], Step [24200/6235], Loss: 42.0994\n",
      "Epoch [70/100], Step [24300/6235], Loss: 1.4710\n",
      "Epoch [70/100], Step [24400/6235], Loss: 4.7202\n",
      "Epoch [70/100], Step [24500/6235], Loss: 2.7084\n",
      "Epoch [70/100], Step [24600/6235], Loss: 0.2564\n",
      "Epoch [70/100], Step [24700/6235], Loss: 1.5153\n",
      "Epoch [70/100], Step [24800/6235], Loss: 0.1225\n",
      "Epoch [70/100], Step [24900/6235], Loss: 11.4571\n",
      "Epoch [70/100], Step [25000/6235], Loss: 18.5124\n",
      "Epoch [70/100], Step [25100/6235], Loss: 8.0889\n",
      "Epoch [70/100], Step [25200/6235], Loss: 1.5519\n",
      "Epoch [70/100], Step [25300/6235], Loss: 0.6471\n",
      "Epoch [70/100], Step [25400/6235], Loss: 8.8281\n",
      "Epoch [70/100], Step [25500/6235], Loss: 6.9294\n",
      "Epoch [70/100], Step [25600/6235], Loss: 3.1798\n",
      "Epoch [70/100], Step [25700/6235], Loss: 0.3412\n",
      "Epoch [70/100], Step [25800/6235], Loss: 0.1688\n",
      "Epoch [70/100], Step [25900/6235], Loss: 9.3736\n",
      "Epoch [70/100], Step [26000/6235], Loss: 0.4736\n",
      "Epoch [70/100], Step [26100/6235], Loss: 0.1844\n",
      "Epoch [70/100], Step [26200/6235], Loss: 0.3655\n",
      "Epoch [70/100], Step [26300/6235], Loss: 4.8702\n",
      "Epoch [70/100], Step [26400/6235], Loss: 0.1599\n",
      "Epoch [70/100], Step [26500/6235], Loss: 0.2010\n",
      "Epoch [70/100], Step [26600/6235], Loss: 2.8963\n",
      "Epoch [70/100], Step [26700/6235], Loss: 0.6011\n",
      "Epoch [70/100], Step [26800/6235], Loss: 0.7145\n",
      "Epoch [70/100], Step [26900/6235], Loss: 0.0325\n",
      "Epoch [70/100], Step [27000/6235], Loss: 13.1798\n",
      "Epoch [70/100], Step [27100/6235], Loss: 0.1146\n",
      "Epoch [70/100], Step [27200/6235], Loss: 0.0471\n",
      "Epoch [70/100], Step [27300/6235], Loss: 0.2255\n",
      "Epoch [70/100], Step [27400/6235], Loss: 0.8934\n",
      "Epoch [70/100], Step [27500/6235], Loss: 15.4669\n",
      "Epoch [70/100], Step [27600/6235], Loss: 0.8734\n",
      "Epoch [70/100], Step [27700/6235], Loss: 0.1909\n",
      "Epoch [70/100], Step [27800/6235], Loss: 0.8172\n",
      "Epoch [70/100], Step [27900/6235], Loss: 0.1844\n",
      "Epoch [70/100], Step [28000/6235], Loss: 101.0559\n",
      "Epoch [70/100], Step [28100/6235], Loss: 1.2680\n",
      "Epoch [70/100], Step [28200/6235], Loss: 35.1338\n",
      "Epoch [70/100], Step [28300/6235], Loss: 3.4274\n",
      "Epoch [70/100], Step [28400/6235], Loss: 21.5805\n",
      "Epoch [70/100], Step [28500/6235], Loss: 3.9127\n",
      "Epoch [70/100], Step [28600/6235], Loss: 0.4718\n",
      "Epoch [70/100], Step [28700/6235], Loss: 4.6463\n",
      "Epoch [70/100], Step [28800/6235], Loss: 0.4031\n",
      "Epoch [70/100], Step [28900/6235], Loss: 71.0066\n",
      "Epoch [70/100], Step [29000/6235], Loss: 7.9527\n",
      "Epoch [70/100], Step [29100/6235], Loss: 0.0343\n",
      "Epoch [70/100], Step [29200/6235], Loss: 0.2057\n",
      "Epoch [70/100], Step [29300/6235], Loss: 19.4543\n",
      "Epoch [70/100], Step [29400/6235], Loss: 0.1827\n",
      "Epoch [70/100], Step [29500/6235], Loss: 4.7634\n",
      "Epoch [70/100], Step [29600/6235], Loss: 0.1989\n",
      "Epoch [70/100], Step [29700/6235], Loss: 0.7416\n",
      "Epoch [70/100], Step [29800/6235], Loss: 1.7262\n",
      "Epoch [70/100], Step [29900/6235], Loss: 0.4691\n",
      "Epoch [70/100], Step [30000/6235], Loss: 7.0585\n",
      "Epoch [70/100], Step [30100/6235], Loss: 10.8217\n",
      "Epoch [70/100], Step [30200/6235], Loss: 0.3876\n",
      "Epoch [70/100], Step [30300/6235], Loss: 0.2162\n",
      "Epoch [70/100], Step [30400/6235], Loss: 0.4382\n",
      "Epoch [70/100], Step [30500/6235], Loss: 2.4720\n",
      "Epoch [70/100], Step [30600/6235], Loss: 0.9064\n",
      "Epoch [70/100], Step [30700/6235], Loss: 0.0226\n",
      "Epoch [70/100], Step [30800/6235], Loss: 0.3021\n",
      "Epoch [70/100], Step [30900/6235], Loss: 3.2578\n",
      "Epoch [70/100], Step [31000/6235], Loss: 0.0159\n",
      "Epoch [70/100], Step [31100/6235], Loss: 0.0950\n",
      "Epoch [70/100], Step [31200/6235], Loss: 6.3578\n",
      "Epoch [70/100], Step [31300/6235], Loss: 0.6220\n",
      "Epoch [70/100], Step [31400/6235], Loss: 5.7225\n",
      "Epoch [70/100], Step [31500/6235], Loss: 1.6887\n",
      "Epoch [70/100], Step [31600/6235], Loss: 5.9428\n",
      "Epoch [70/100], Step [31700/6235], Loss: 2.2469\n",
      "Epoch [70/100], Step [31800/6235], Loss: 1.8288\n",
      "Epoch [70/100], Step [31900/6235], Loss: 50.8733\n",
      "Epoch [70/100], Step [32000/6235], Loss: 86.7009\n",
      "Epoch [70/100], Step [32100/6235], Loss: 2.7111\n",
      "Epoch [70/100], Step [32200/6235], Loss: 53.0539\n",
      "Epoch [70/100], Step [32300/6235], Loss: 0.4120\n",
      "Epoch [70/100], Step [32400/6235], Loss: 0.8868\n",
      "Epoch [70/100], Step [32500/6235], Loss: 18.5094\n",
      "Epoch [70/100], Step [32600/6235], Loss: 1.2637\n",
      "Epoch [70/100], Step [32700/6235], Loss: 65.3068\n",
      "Epoch [70/100], Step [32800/6235], Loss: 4.8068\n",
      "Epoch [70/100], Step [32900/6235], Loss: 15.9943\n",
      "Epoch [70/100], Step [33000/6235], Loss: 0.2129\n",
      "Epoch [70/100], Step [33100/6235], Loss: 0.5471\n",
      "Epoch [70/100], Step [33200/6235], Loss: 1.5131\n",
      "Epoch [70/100], Step [33300/6235], Loss: 4.3323\n",
      "Epoch [70/100], Step [33400/6235], Loss: 132.2052\n",
      "Epoch [70/100], Step [33500/6235], Loss: 1.7687\n",
      "Epoch [70/100], Step [33600/6235], Loss: 4.0351\n",
      "Epoch [70/100], Step [33700/6235], Loss: 1.9739\n",
      "Epoch [70/100], Step [33800/6235], Loss: 3.3273\n",
      "Epoch [70/100], Step [33900/6235], Loss: 24.2670\n",
      "Epoch [70/100], Step [34000/6235], Loss: 0.0580\n",
      "Epoch [70/100], Step [34100/6235], Loss: 0.1686\n",
      "Epoch [70/100], Step [34200/6235], Loss: 3.0164\n",
      "Epoch [70/100], Step [34300/6235], Loss: 6.7340\n",
      "Epoch [70/100], Step [34400/6235], Loss: 0.0915\n",
      "Epoch [70/100], Step [34500/6235], Loss: 135.8110\n",
      "Epoch [70/100], Step [34600/6235], Loss: 0.2487\n",
      "Epoch [70/100], Step [34700/6235], Loss: 17.8126\n",
      "Epoch [70/100], Step [34800/6235], Loss: 14.1240\n",
      "Epoch [70/100], Step [34900/6235], Loss: 66.8506\n",
      "Epoch [70/100], Step [35000/6235], Loss: 1.8611\n",
      "Epoch [70/100], Step [35100/6235], Loss: 0.4962\n",
      "Epoch [70/100], Step [35200/6235], Loss: 0.9143\n",
      "Epoch [70/100], Step [35300/6235], Loss: 0.8897\n",
      "Epoch [70/100], Step [35400/6235], Loss: 0.7929\n",
      "Epoch [70/100], Step [35500/6235], Loss: 2.6220\n",
      "Epoch [70/100], Step [35600/6235], Loss: 1.9328\n",
      "Epoch [70/100], Step [35700/6235], Loss: 6.2268\n",
      "Epoch [70/100], Step [35800/6235], Loss: 1.7808\n",
      "Epoch [70/100], Step [35900/6235], Loss: 0.2306\n",
      "Epoch [70/100], Step [36000/6235], Loss: 0.5954\n",
      "Epoch [70/100], Step [36100/6235], Loss: 0.0322\n",
      "Epoch [70/100], Step [36200/6235], Loss: 17.9779\n",
      "Epoch [70/100], Step [36300/6235], Loss: 0.2008\n",
      "Epoch [70/100], Step [36400/6235], Loss: 1.2109\n",
      "Epoch [70/100], Step [36500/6235], Loss: 9.7457\n",
      "Epoch [70/100], Step [36600/6235], Loss: 0.1038\n",
      "Epoch [70/100], Step [36700/6235], Loss: 0.0947\n",
      "Epoch [70/100], Step [36800/6235], Loss: 21.9768\n",
      "Epoch [70/100], Step [36900/6235], Loss: 4.0617\n",
      "Epoch [70/100], Step [37000/6235], Loss: 0.0222\n",
      "Epoch [70/100], Step [37100/6235], Loss: 0.3701\n",
      "Epoch [70/100], Step [37200/6235], Loss: 0.0540\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [70/100], Step [37300/6235], Loss: 0.1629\n",
      "Epoch [70/100], Step [37400/6235], Loss: 0.1972\n",
      "Epoch [70/100], Step [37500/6235], Loss: 3.0760\n",
      "Epoch [70/100], Step [37600/6235], Loss: 10.7474\n",
      "Epoch [70/100], Step [37700/6235], Loss: 0.6084\n",
      "Epoch [70/100], Step [37800/6235], Loss: 7.5400\n",
      "Epoch [70/100], Step [37900/6235], Loss: 8.7057\n",
      "Epoch [70/100], Step [38000/6235], Loss: 0.2758\n",
      "Epoch [70/100], Step [38100/6235], Loss: 3.2459\n",
      "Epoch [70/100], Step [38200/6235], Loss: 2.2210\n",
      "Epoch [70/100], Step [38300/6235], Loss: 0.2116\n",
      "Epoch [70/100], Step [38400/6235], Loss: 0.1632\n",
      "Epoch [70/100], Step [38500/6235], Loss: 3.0021\n",
      "Epoch [70/100], Step [38600/6235], Loss: 0.1855\n",
      "Epoch [70/100], Step [38700/6235], Loss: 0.1863\n",
      "Epoch [70/100], Step [38800/6235], Loss: 0.3712\n",
      "Epoch [70/100], Step [38900/6235], Loss: 6.8200\n",
      "Epoch [70/100], Step [39000/6235], Loss: 7.3866\n",
      "Epoch [70/100], Step [39100/6235], Loss: 16.6209\n",
      "Epoch [70/100], Step [39200/6235], Loss: 0.2088\n",
      "Epoch [70/100], Step [39300/6235], Loss: 23.2779\n",
      "Epoch [70/100], Step [39400/6235], Loss: 221.7433\n",
      "Epoch [70/100], Step [39500/6235], Loss: 78.9018\n",
      "Epoch [70/100], Step [39600/6235], Loss: 8.1418\n",
      "Epoch [70/100], Step [39700/6235], Loss: 52.7656\n",
      "Epoch [70/100], Step [39800/6235], Loss: 216.1516\n",
      "Epoch [70/100], Step [39900/6235], Loss: 0.6739\n",
      "Epoch [70/100], Step [40000/6235], Loss: 10.1668\n",
      "Epoch [70/100], Step [40100/6235], Loss: 7.3765\n",
      "Epoch [70/100], Step [40200/6235], Loss: 15.4882\n",
      "Epoch [70/100], Step [40300/6235], Loss: 3.7338\n",
      "Epoch [70/100], Step [40400/6235], Loss: 0.1211\n",
      "Epoch [70/100], Step [40500/6235], Loss: 3.6030\n",
      "Epoch [70/100], Step [40600/6235], Loss: 0.4448\n",
      "Epoch [70/100], Step [40700/6235], Loss: 4.6999\n",
      "Epoch [70/100], Step [40800/6235], Loss: 1.7616\n",
      "Epoch [70/100], Step [40900/6235], Loss: 1.3963\n",
      "Epoch [70/100], Step [41000/6235], Loss: 33.9427\n",
      "Epoch [70/100], Step [41100/6235], Loss: 3.9593\n",
      "Epoch [70/100], Step [41200/6235], Loss: 25.2523\n",
      "Epoch [70/100], Step [41300/6235], Loss: 3.1870\n",
      "Epoch [70/100], Step [41400/6235], Loss: 0.1271\n",
      "Epoch [70/100], Step [41500/6235], Loss: 5.9617\n",
      "Epoch [70/100], Step [41600/6235], Loss: 2.5082\n",
      "Epoch [70/100], Step [41700/6235], Loss: 0.1337\n",
      "Epoch [70/100], Step [41800/6235], Loss: 0.5451\n",
      "Epoch [70/100], Step [41900/6235], Loss: 4.5280\n",
      "Epoch [70/100], Step [42000/6235], Loss: 4.4499\n",
      "Epoch [70/100], Step [42100/6235], Loss: 12.0582\n",
      "Epoch [70/100], Step [42200/6235], Loss: 53.4621\n",
      "Epoch [70/100], Step [42300/6235], Loss: 0.3048\n",
      "Epoch [70/100], Step [42400/6235], Loss: 5.9924\n",
      "Epoch [70/100], Step [42500/6235], Loss: 1.6013\n",
      "Epoch [70/100], Step [42600/6235], Loss: 0.5081\n",
      "Epoch [70/100], Step [42700/6235], Loss: 0.1976\n",
      "Epoch [70/100], Step [42800/6235], Loss: 15.5609\n",
      "Epoch [70/100], Step [42900/6235], Loss: 0.3490\n",
      "Epoch [70/100], Step [43000/6235], Loss: 0.4097\n",
      "Epoch [70/100], Step [43100/6235], Loss: 0.0426\n",
      "Epoch [70/100], Step [43200/6235], Loss: 0.2559\n",
      "Epoch [70/100], Step [43300/6235], Loss: 5.1898\n",
      "Epoch [70/100], Step [43400/6235], Loss: 6.8745\n",
      "Epoch [70/100], Step [43500/6235], Loss: 10.8817\n",
      "Epoch [70/100], Step [43600/6235], Loss: 3.3118\n",
      "Epoch [70/100], Step [43700/6235], Loss: 13.8279\n",
      "Epoch [70/100], Step [43800/6235], Loss: 0.9602\n",
      "Epoch [70/100], Step [43900/6235], Loss: 2.7397\n",
      "Epoch [70/100], Step [44000/6235], Loss: 90.3092\n",
      "Epoch [70/100], Step [44100/6235], Loss: 1.1231\n",
      "Epoch [70/100], Step [44200/6235], Loss: 1.4691\n",
      "Epoch [70/100], Step [44300/6235], Loss: 68.6701\n",
      "Epoch [70/100], Step [44400/6235], Loss: 0.7182\n",
      "Epoch [70/100], Step [44500/6235], Loss: 0.2653\n",
      "Epoch [70/100], Step [44600/6235], Loss: 24.4968\n",
      "Epoch [70/100], Step [44700/6235], Loss: 0.5353\n",
      "Epoch [70/100], Step [44800/6235], Loss: 5.4807\n",
      "Epoch [70/100], Step [44900/6235], Loss: 12.1558\n",
      "Epoch [70/100], Step [45000/6235], Loss: 6.2980\n",
      "Epoch [70/100], Step [45100/6235], Loss: 51.0744\n",
      "Epoch [70/100], Step [45200/6235], Loss: 6.3359\n",
      "Epoch [70/100], Step [45300/6235], Loss: 23.9001\n",
      "Epoch [70/100], Step [45400/6235], Loss: 7.0487\n",
      "Epoch [70/100], Step [45500/6235], Loss: 3.2885\n",
      "Epoch [70/100], Step [45600/6235], Loss: 1.3847\n",
      "Epoch [70/100], Step [45700/6235], Loss: 143.5546\n",
      "Epoch [70/100], Step [45800/6235], Loss: 203.4437\n",
      "Epoch [70/100], Step [45900/6235], Loss: 17.4992\n",
      "Epoch [70/100], Step [46000/6235], Loss: 9.2956\n",
      "Epoch [70/100], Step [46100/6235], Loss: 9.1467\n",
      "Epoch [70/100], Step [46200/6235], Loss: 48.2614\n",
      "Epoch [70/100], Step [46300/6235], Loss: 20.5309\n",
      "Epoch [70/100], Step [46400/6235], Loss: 12.7594\n",
      "Epoch [70/100], Step [46500/6235], Loss: 162.9278\n",
      "Epoch [70/100], Step [46600/6235], Loss: 7.3549\n",
      "Epoch [70/100], Step [46700/6235], Loss: 50.7173\n",
      "Epoch [70/100], Step [46800/6235], Loss: 10.4922\n",
      "Epoch [70/100], Step [46900/6235], Loss: 0.3774\n",
      "Epoch [70/100], Step [47000/6235], Loss: 8.2632\n",
      "Epoch [70/100], Step [47100/6235], Loss: 11.7383\n",
      "Epoch [70/100], Step [47200/6235], Loss: 8.0417\n",
      "Epoch [70/100], Step [47300/6235], Loss: 0.8670\n",
      "Epoch [70/100], Step [47400/6235], Loss: 9.2460\n",
      "Epoch [70/100], Step [47500/6235], Loss: 2.2700\n",
      "Epoch [70/100], Step [47600/6235], Loss: 0.5907\n",
      "Epoch [70/100], Step [47700/6235], Loss: 5.8996\n",
      "Epoch [70/100], Step [47800/6235], Loss: 0.7023\n",
      "Epoch [70/100], Step [47900/6235], Loss: 27.8499\n",
      "Epoch [70/100], Step [48000/6235], Loss: 51.4068\n",
      "Epoch [70/100], Step [48100/6235], Loss: 4.0802\n",
      "Epoch [70/100], Step [48200/6235], Loss: 11.9960\n",
      "Epoch [70/100], Step [48300/6235], Loss: 651.6345\n",
      "Epoch [70/100], Step [48400/6235], Loss: 22.5432\n",
      "Epoch [70/100], Step [48500/6235], Loss: 21.3645\n",
      "Epoch [70/100], Step [48600/6235], Loss: 165.1462\n",
      "Epoch [70/100], Step [48700/6235], Loss: 21.6134\n",
      "Epoch [70/100], Step [48800/6235], Loss: 975.7213\n",
      "Epoch [70/100], Step [48900/6235], Loss: 689.3963\n",
      "Epoch [70/100], Step [49000/6235], Loss: 126.4986\n",
      "Epoch [70/100], Step [49100/6235], Loss: 2347.9841\n",
      "Epoch [70/100], Step [49200/6235], Loss: 1209.9480\n",
      "Epoch [70/100], Step [49300/6235], Loss: 1149.6261\n",
      "Epoch [70/100], Step [49400/6235], Loss: 35.7358\n",
      "Epoch [70/100], Step [49500/6235], Loss: 40.9552\n",
      "Epoch [70/100], Step [49600/6235], Loss: 53.3646\n",
      "Epoch [70/100], Step [49700/6235], Loss: 3920.7678\n",
      "Epoch [70/100], Step [49800/6235], Loss: 1872.4375\n",
      "Epoch [71/100], Step [100/6235], Loss: 23.2111\n",
      "Epoch [71/100], Step [200/6235], Loss: 0.1075\n",
      "Epoch [71/100], Step [300/6235], Loss: 0.1435\n",
      "Epoch [71/100], Step [400/6235], Loss: 0.0354\n",
      "Epoch [71/100], Step [500/6235], Loss: 60.6446\n",
      "Epoch [71/100], Step [600/6235], Loss: 0.5487\n",
      "Epoch [71/100], Step [700/6235], Loss: 0.8460\n",
      "Epoch [71/100], Step [800/6235], Loss: 0.0928\n",
      "Epoch [71/100], Step [900/6235], Loss: 0.3676\n",
      "Epoch [71/100], Step [1000/6235], Loss: 0.0537\n",
      "Epoch [71/100], Step [1100/6235], Loss: 0.0440\n",
      "Epoch [71/100], Step [1200/6235], Loss: 0.1393\n",
      "Epoch [71/100], Step [1300/6235], Loss: 0.0729\n",
      "Epoch [71/100], Step [1400/6235], Loss: 0.0510\n",
      "Epoch [71/100], Step [1500/6235], Loss: 0.0020\n",
      "Epoch [71/100], Step [1600/6235], Loss: 0.2056\n",
      "Epoch [71/100], Step [1700/6235], Loss: 0.0389\n",
      "Epoch [71/100], Step [1800/6235], Loss: 0.2280\n",
      "Epoch [71/100], Step [1900/6235], Loss: 0.8323\n",
      "Epoch [71/100], Step [2000/6235], Loss: 1.9703\n",
      "Epoch [71/100], Step [2100/6235], Loss: 1.6126\n",
      "Epoch [71/100], Step [2200/6235], Loss: 11.6792\n",
      "Epoch [71/100], Step [2300/6235], Loss: 25.4662\n",
      "Epoch [71/100], Step [2400/6235], Loss: 16.9473\n",
      "Epoch [71/100], Step [2500/6235], Loss: 30.0271\n",
      "Epoch [71/100], Step [2600/6235], Loss: 7.1834\n",
      "Epoch [71/100], Step [2700/6235], Loss: 35.1353\n",
      "Epoch [71/100], Step [2800/6235], Loss: 343.6089\n",
      "Epoch [71/100], Step [2900/6235], Loss: 6.2686\n",
      "Epoch [71/100], Step [3000/6235], Loss: 0.7073\n",
      "Epoch [71/100], Step [3100/6235], Loss: 44.6232\n",
      "Epoch [71/100], Step [3200/6235], Loss: 64.6627\n",
      "Epoch [71/100], Step [3300/6235], Loss: 0.1856\n",
      "Epoch [71/100], Step [3400/6235], Loss: 2.7520\n",
      "Epoch [71/100], Step [3500/6235], Loss: 37.2029\n",
      "Epoch [71/100], Step [3600/6235], Loss: 10.6495\n",
      "Epoch [71/100], Step [3700/6235], Loss: 1.5739\n",
      "Epoch [71/100], Step [3800/6235], Loss: 0.4527\n",
      "Epoch [71/100], Step [3900/6235], Loss: 1.2790\n",
      "Epoch [71/100], Step [4000/6235], Loss: 0.1513\n",
      "Epoch [71/100], Step [4100/6235], Loss: 2.9455\n",
      "Epoch [71/100], Step [4200/6235], Loss: 0.2882\n",
      "Epoch [71/100], Step [4300/6235], Loss: 9.5548\n",
      "Epoch [71/100], Step [4400/6235], Loss: 0.3934\n",
      "Epoch [71/100], Step [4500/6235], Loss: 72.3865\n",
      "Epoch [71/100], Step [4600/6235], Loss: 16.1952\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Step [4700/6235], Loss: 2.4981\n",
      "Epoch [71/100], Step [4800/6235], Loss: 2.4863\n",
      "Epoch [71/100], Step [4900/6235], Loss: 0.0761\n",
      "Epoch [71/100], Step [5000/6235], Loss: 0.9891\n",
      "Epoch [71/100], Step [5100/6235], Loss: 2.2347\n",
      "Epoch [71/100], Step [5200/6235], Loss: 5.3078\n",
      "Epoch [71/100], Step [5300/6235], Loss: 36.3835\n",
      "Epoch [71/100], Step [5400/6235], Loss: 9.2443\n",
      "Epoch [71/100], Step [5500/6235], Loss: 0.4761\n",
      "Epoch [71/100], Step [5600/6235], Loss: 0.0867\n",
      "Epoch [71/100], Step [5700/6235], Loss: 0.1029\n",
      "Epoch [71/100], Step [5800/6235], Loss: 1.3031\n",
      "Epoch [71/100], Step [5900/6235], Loss: 1.0901\n",
      "Epoch [71/100], Step [6000/6235], Loss: 0.5284\n",
      "Epoch [71/100], Step [6100/6235], Loss: 0.0474\n",
      "Epoch [71/100], Step [6200/6235], Loss: 0.3038\n",
      "Epoch [71/100], Step [6300/6235], Loss: 0.4097\n",
      "Epoch [71/100], Step [6400/6235], Loss: 0.0865\n",
      "Epoch [71/100], Step [6500/6235], Loss: 0.2927\n",
      "Epoch [71/100], Step [6600/6235], Loss: 9.7782\n",
      "Epoch [71/100], Step [6700/6235], Loss: 0.7931\n",
      "Epoch [71/100], Step [6800/6235], Loss: 0.6330\n",
      "Epoch [71/100], Step [6900/6235], Loss: 0.8857\n",
      "Epoch [71/100], Step [7000/6235], Loss: 0.0292\n",
      "Epoch [71/100], Step [7100/6235], Loss: 0.6356\n",
      "Epoch [71/100], Step [7200/6235], Loss: 0.6264\n",
      "Epoch [71/100], Step [7300/6235], Loss: 0.9987\n",
      "Epoch [71/100], Step [7400/6235], Loss: 0.0103\n",
      "Epoch [71/100], Step [7500/6235], Loss: 12.4719\n",
      "Epoch [71/100], Step [7600/6235], Loss: 1.1408\n",
      "Epoch [71/100], Step [7700/6235], Loss: 2.6202\n",
      "Epoch [71/100], Step [7800/6235], Loss: 4.0346\n",
      "Epoch [71/100], Step [7900/6235], Loss: 24.1258\n",
      "Epoch [71/100], Step [8000/6235], Loss: 0.3747\n",
      "Epoch [71/100], Step [8100/6235], Loss: 4.6196\n",
      "Epoch [71/100], Step [8200/6235], Loss: 17.2775\n",
      "Epoch [71/100], Step [8300/6235], Loss: 65.4986\n",
      "Epoch [71/100], Step [8400/6235], Loss: 47.8918\n",
      "Epoch [71/100], Step [8500/6235], Loss: 75.6353\n",
      "Epoch [71/100], Step [8600/6235], Loss: 1.5954\n",
      "Epoch [71/100], Step [8700/6235], Loss: 57.2558\n",
      "Epoch [71/100], Step [8800/6235], Loss: 707.1570\n",
      "Epoch [71/100], Step [8900/6235], Loss: 4.1757\n",
      "Epoch [71/100], Step [9000/6235], Loss: 672.5970\n",
      "Epoch [71/100], Step [9100/6235], Loss: 3461.6899\n",
      "Epoch [71/100], Step [9200/6235], Loss: 4700.6309\n",
      "Epoch [71/100], Step [9300/6235], Loss: 126.5993\n",
      "Epoch [71/100], Step [9400/6235], Loss: 31.0047\n",
      "Epoch [71/100], Step [9500/6235], Loss: 2258.3223\n",
      "Epoch [71/100], Step [9600/6235], Loss: 897.4664\n",
      "Epoch [71/100], Step [9700/6235], Loss: 9.1109\n",
      "Epoch [71/100], Step [9800/6235], Loss: 3097.7610\n",
      "Epoch [71/100], Step [9900/6235], Loss: 133.4068\n",
      "Epoch [71/100], Step [10000/6235], Loss: 163.7589\n",
      "Epoch [71/100], Step [10100/6235], Loss: 2.9584\n",
      "Epoch [71/100], Step [10200/6235], Loss: 839.7095\n",
      "Epoch [71/100], Step [10300/6235], Loss: 28.9903\n",
      "Epoch [71/100], Step [10400/6235], Loss: 8.2031\n",
      "Epoch [71/100], Step [10500/6235], Loss: 4.5235\n",
      "Epoch [71/100], Step [10600/6235], Loss: 448.7530\n",
      "Epoch [71/100], Step [10700/6235], Loss: 13.4501\n",
      "Epoch [71/100], Step [10800/6235], Loss: 133.3860\n",
      "Epoch [71/100], Step [10900/6235], Loss: 79.4194\n",
      "Epoch [71/100], Step [11000/6235], Loss: 297.6644\n",
      "Epoch [71/100], Step [11100/6235], Loss: 39.4514\n",
      "Epoch [71/100], Step [11200/6235], Loss: 8.8687\n",
      "Epoch [71/100], Step [11300/6235], Loss: 114.1054\n",
      "Epoch [71/100], Step [11400/6235], Loss: 2.6796\n",
      "Epoch [71/100], Step [11500/6235], Loss: 7.8354\n",
      "Epoch [71/100], Step [11600/6235], Loss: 5.6864\n",
      "Epoch [71/100], Step [11700/6235], Loss: 41.3607\n",
      "Epoch [71/100], Step [11800/6235], Loss: 416.5048\n",
      "Epoch [71/100], Step [11900/6235], Loss: 85.8261\n",
      "Epoch [71/100], Step [12000/6235], Loss: 624.2423\n",
      "Epoch [71/100], Step [12100/6235], Loss: 235.9630\n",
      "Epoch [71/100], Step [12200/6235], Loss: 48.3607\n",
      "Epoch [71/100], Step [12300/6235], Loss: 8.0260\n",
      "Epoch [71/100], Step [12400/6235], Loss: 116.8827\n",
      "Epoch [71/100], Step [12500/6235], Loss: 38.1696\n",
      "Epoch [71/100], Step [12600/6235], Loss: 24.7749\n",
      "Epoch [71/100], Step [12700/6235], Loss: 7.0516\n",
      "Epoch [71/100], Step [12800/6235], Loss: 7.0449\n",
      "Epoch [71/100], Step [12900/6235], Loss: 36.5637\n",
      "Epoch [71/100], Step [13000/6235], Loss: 0.2723\n",
      "Epoch [71/100], Step [13100/6235], Loss: 65.1553\n",
      "Epoch [71/100], Step [13200/6235], Loss: 9.0934\n",
      "Epoch [71/100], Step [13300/6235], Loss: 36.0686\n",
      "Epoch [71/100], Step [13400/6235], Loss: 242.6883\n",
      "Epoch [71/100], Step [13500/6235], Loss: 1.6363\n",
      "Epoch [71/100], Step [13600/6235], Loss: 0.6622\n",
      "Epoch [71/100], Step [13700/6235], Loss: 76.0065\n",
      "Epoch [71/100], Step [13800/6235], Loss: 116.1258\n",
      "Epoch [71/100], Step [13900/6235], Loss: 44.8685\n",
      "Epoch [71/100], Step [14000/6235], Loss: 14.3708\n",
      "Epoch [71/100], Step [14100/6235], Loss: 29.3424\n",
      "Epoch [71/100], Step [14200/6235], Loss: 116.1704\n",
      "Epoch [71/100], Step [14300/6235], Loss: 29.0632\n",
      "Epoch [71/100], Step [14400/6235], Loss: 37.8175\n",
      "Epoch [71/100], Step [14500/6235], Loss: 35.7270\n",
      "Epoch [71/100], Step [14600/6235], Loss: 1.2457\n",
      "Epoch [71/100], Step [14700/6235], Loss: 32.8879\n",
      "Epoch [71/100], Step [14800/6235], Loss: 32.2939\n",
      "Epoch [71/100], Step [14900/6235], Loss: 0.6870\n",
      "Epoch [71/100], Step [15000/6235], Loss: 1.4206\n",
      "Epoch [71/100], Step [15100/6235], Loss: 0.5382\n",
      "Epoch [71/100], Step [15200/6235], Loss: 8.8209\n",
      "Epoch [71/100], Step [15300/6235], Loss: 43.3908\n",
      "Epoch [71/100], Step [15400/6235], Loss: 56.1267\n",
      "Epoch [71/100], Step [15500/6235], Loss: 11.9781\n",
      "Epoch [71/100], Step [15600/6235], Loss: 165.9465\n",
      "Epoch [71/100], Step [15700/6235], Loss: 52.0840\n",
      "Epoch [71/100], Step [15800/6235], Loss: 6.9963\n",
      "Epoch [71/100], Step [15900/6235], Loss: 0.6243\n",
      "Epoch [71/100], Step [16000/6235], Loss: 151.9403\n",
      "Epoch [71/100], Step [16100/6235], Loss: 11.8509\n",
      "Epoch [71/100], Step [16200/6235], Loss: 4.8016\n",
      "Epoch [71/100], Step [16300/6235], Loss: 8.9424\n",
      "Epoch [71/100], Step [16400/6235], Loss: 26.8094\n",
      "Epoch [71/100], Step [16500/6235], Loss: 312.5753\n",
      "Epoch [71/100], Step [16600/6235], Loss: 29.5909\n",
      "Epoch [71/100], Step [16700/6235], Loss: 0.4373\n",
      "Epoch [71/100], Step [16800/6235], Loss: 10.7935\n",
      "Epoch [71/100], Step [16900/6235], Loss: 0.1506\n",
      "Epoch [71/100], Step [17000/6235], Loss: 0.2226\n",
      "Epoch [71/100], Step [17100/6235], Loss: 0.1671\n",
      "Epoch [71/100], Step [17200/6235], Loss: 279.7977\n",
      "Epoch [71/100], Step [17300/6235], Loss: 2.3718\n",
      "Epoch [71/100], Step [17400/6235], Loss: 29.9303\n",
      "Epoch [71/100], Step [17500/6235], Loss: 0.4689\n",
      "Epoch [71/100], Step [17600/6235], Loss: 2.8507\n",
      "Epoch [71/100], Step [17700/6235], Loss: 75.4959\n",
      "Epoch [71/100], Step [17800/6235], Loss: 26.0840\n",
      "Epoch [71/100], Step [17900/6235], Loss: 9.3237\n",
      "Epoch [71/100], Step [18000/6235], Loss: 10.4409\n",
      "Epoch [71/100], Step [18100/6235], Loss: 5.7005\n",
      "Epoch [71/100], Step [18200/6235], Loss: 0.4710\n",
      "Epoch [71/100], Step [18300/6235], Loss: 6.7723\n",
      "Epoch [71/100], Step [18400/6235], Loss: 4.9008\n",
      "Epoch [71/100], Step [18500/6235], Loss: 15.8529\n",
      "Epoch [71/100], Step [18600/6235], Loss: 1.3116\n",
      "Epoch [71/100], Step [18700/6235], Loss: 0.3945\n",
      "Epoch [71/100], Step [18800/6235], Loss: 118.1664\n",
      "Epoch [71/100], Step [18900/6235], Loss: 33.4178\n",
      "Epoch [71/100], Step [19000/6235], Loss: 31.4056\n",
      "Epoch [71/100], Step [19100/6235], Loss: 5.8713\n",
      "Epoch [71/100], Step [19200/6235], Loss: 3.5747\n",
      "Epoch [71/100], Step [19300/6235], Loss: 9.5074\n",
      "Epoch [71/100], Step [19400/6235], Loss: 234.0465\n",
      "Epoch [71/100], Step [19500/6235], Loss: 154.0674\n",
      "Epoch [71/100], Step [19600/6235], Loss: 127.1293\n",
      "Epoch [71/100], Step [19700/6235], Loss: 4.4208\n",
      "Epoch [71/100], Step [19800/6235], Loss: 0.7287\n",
      "Epoch [71/100], Step [19900/6235], Loss: 1.3926\n",
      "Epoch [71/100], Step [20000/6235], Loss: 108.5115\n",
      "Epoch [71/100], Step [20100/6235], Loss: 14.9440\n",
      "Epoch [71/100], Step [20200/6235], Loss: 1.3639\n",
      "Epoch [71/100], Step [20300/6235], Loss: 0.2650\n",
      "Epoch [71/100], Step [20400/6235], Loss: 33.2768\n",
      "Epoch [71/100], Step [20500/6235], Loss: 24.7090\n",
      "Epoch [71/100], Step [20600/6235], Loss: 5.9407\n",
      "Epoch [71/100], Step [20700/6235], Loss: 0.5534\n",
      "Epoch [71/100], Step [20800/6235], Loss: 26.8843\n",
      "Epoch [71/100], Step [20900/6235], Loss: 26.3637\n",
      "Epoch [71/100], Step [21000/6235], Loss: 16.6623\n",
      "Epoch [71/100], Step [21100/6235], Loss: 1.5467\n",
      "Epoch [71/100], Step [21200/6235], Loss: 0.2455\n",
      "Epoch [71/100], Step [21300/6235], Loss: 0.0521\n",
      "Epoch [71/100], Step [21400/6235], Loss: 2.8545\n",
      "Epoch [71/100], Step [21500/6235], Loss: 3.3717\n",
      "Epoch [71/100], Step [21600/6235], Loss: 32.6495\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Step [21700/6235], Loss: 0.2430\n",
      "Epoch [71/100], Step [21800/6235], Loss: 17.3398\n",
      "Epoch [71/100], Step [21900/6235], Loss: 0.0505\n",
      "Epoch [71/100], Step [22000/6235], Loss: 0.0579\n",
      "Epoch [71/100], Step [22100/6235], Loss: 6.3447\n",
      "Epoch [71/100], Step [22200/6235], Loss: 10.3976\n",
      "Epoch [71/100], Step [22300/6235], Loss: 0.2399\n",
      "Epoch [71/100], Step [22400/6235], Loss: 0.0811\n",
      "Epoch [71/100], Step [22500/6235], Loss: 113.7230\n",
      "Epoch [71/100], Step [22600/6235], Loss: 4.5278\n",
      "Epoch [71/100], Step [22700/6235], Loss: 0.3002\n",
      "Epoch [71/100], Step [22800/6235], Loss: 2.1198\n",
      "Epoch [71/100], Step [22900/6235], Loss: 2.4477\n",
      "Epoch [71/100], Step [23000/6235], Loss: 12.5772\n",
      "Epoch [71/100], Step [23100/6235], Loss: 1.3189\n",
      "Epoch [71/100], Step [23200/6235], Loss: 38.3484\n",
      "Epoch [71/100], Step [23300/6235], Loss: 9.4403\n",
      "Epoch [71/100], Step [23400/6235], Loss: 0.0615\n",
      "Epoch [71/100], Step [23500/6235], Loss: 0.4692\n",
      "Epoch [71/100], Step [23600/6235], Loss: 64.7546\n",
      "Epoch [71/100], Step [23700/6235], Loss: 2.1656\n",
      "Epoch [71/100], Step [23800/6235], Loss: 0.0508\n",
      "Epoch [71/100], Step [23900/6235], Loss: 4.8452\n",
      "Epoch [71/100], Step [24000/6235], Loss: 4.2774\n",
      "Epoch [71/100], Step [24100/6235], Loss: 3.6914\n",
      "Epoch [71/100], Step [24200/6235], Loss: 10.6693\n",
      "Epoch [71/100], Step [24300/6235], Loss: 4.1610\n",
      "Epoch [71/100], Step [24400/6235], Loss: 7.6255\n",
      "Epoch [71/100], Step [24500/6235], Loss: 3.5218\n",
      "Epoch [71/100], Step [24600/6235], Loss: 0.1977\n",
      "Epoch [71/100], Step [24700/6235], Loss: 5.1994\n",
      "Epoch [71/100], Step [24800/6235], Loss: 0.2652\n",
      "Epoch [71/100], Step [24900/6235], Loss: 0.1727\n",
      "Epoch [71/100], Step [25000/6235], Loss: 18.7550\n",
      "Epoch [71/100], Step [25100/6235], Loss: 8.2708\n",
      "Epoch [71/100], Step [25200/6235], Loss: 2.1005\n",
      "Epoch [71/100], Step [25300/6235], Loss: 1.6680\n",
      "Epoch [71/100], Step [25400/6235], Loss: 10.3316\n",
      "Epoch [71/100], Step [25500/6235], Loss: 1.3406\n",
      "Epoch [71/100], Step [25600/6235], Loss: 0.2531\n",
      "Epoch [71/100], Step [25700/6235], Loss: 0.0640\n",
      "Epoch [71/100], Step [25800/6235], Loss: 0.1408\n",
      "Epoch [71/100], Step [25900/6235], Loss: 8.7251\n",
      "Epoch [71/100], Step [26000/6235], Loss: 3.2464\n",
      "Epoch [71/100], Step [26100/6235], Loss: 0.1789\n",
      "Epoch [71/100], Step [26200/6235], Loss: 0.0233\n",
      "Epoch [71/100], Step [26300/6235], Loss: 4.2520\n",
      "Epoch [71/100], Step [26400/6235], Loss: 0.1454\n",
      "Epoch [71/100], Step [26500/6235], Loss: 0.5824\n",
      "Epoch [71/100], Step [26600/6235], Loss: 5.0658\n",
      "Epoch [71/100], Step [26700/6235], Loss: 0.9751\n",
      "Epoch [71/100], Step [26800/6235], Loss: 1.5370\n",
      "Epoch [71/100], Step [26900/6235], Loss: 0.1759\n",
      "Epoch [71/100], Step [27000/6235], Loss: 9.3140\n",
      "Epoch [71/100], Step [27100/6235], Loss: 0.5178\n",
      "Epoch [71/100], Step [27200/6235], Loss: 0.2113\n",
      "Epoch [71/100], Step [27300/6235], Loss: 0.0785\n",
      "Epoch [71/100], Step [27400/6235], Loss: 1.1937\n",
      "Epoch [71/100], Step [27500/6235], Loss: 19.7494\n",
      "Epoch [71/100], Step [27600/6235], Loss: 0.1632\n",
      "Epoch [71/100], Step [27700/6235], Loss: 1.3385\n",
      "Epoch [71/100], Step [27800/6235], Loss: 6.2515\n",
      "Epoch [71/100], Step [27900/6235], Loss: 1.0549\n",
      "Epoch [71/100], Step [28000/6235], Loss: 168.6564\n",
      "Epoch [71/100], Step [28100/6235], Loss: 8.7173\n",
      "Epoch [71/100], Step [28200/6235], Loss: 27.1308\n",
      "Epoch [71/100], Step [28300/6235], Loss: 3.9345\n",
      "Epoch [71/100], Step [28400/6235], Loss: 24.2458\n",
      "Epoch [71/100], Step [28500/6235], Loss: 1.4484\n",
      "Epoch [71/100], Step [28600/6235], Loss: 0.6282\n",
      "Epoch [71/100], Step [28700/6235], Loss: 4.2817\n",
      "Epoch [71/100], Step [28800/6235], Loss: 0.3571\n",
      "Epoch [71/100], Step [28900/6235], Loss: 67.7535\n",
      "Epoch [71/100], Step [29000/6235], Loss: 2.6990\n",
      "Epoch [71/100], Step [29100/6235], Loss: 0.4340\n",
      "Epoch [71/100], Step [29200/6235], Loss: 0.0702\n",
      "Epoch [71/100], Step [29300/6235], Loss: 15.5476\n",
      "Epoch [71/100], Step [29400/6235], Loss: 0.4185\n",
      "Epoch [71/100], Step [29500/6235], Loss: 3.9340\n",
      "Epoch [71/100], Step [29600/6235], Loss: 0.8521\n",
      "Epoch [71/100], Step [29700/6235], Loss: 0.0950\n",
      "Epoch [71/100], Step [29800/6235], Loss: 1.5174\n",
      "Epoch [71/100], Step [29900/6235], Loss: 0.0534\n",
      "Epoch [71/100], Step [30000/6235], Loss: 5.9230\n",
      "Epoch [71/100], Step [30100/6235], Loss: 0.0206\n",
      "Epoch [71/100], Step [30200/6235], Loss: 0.1184\n",
      "Epoch [71/100], Step [30300/6235], Loss: 0.9605\n",
      "Epoch [71/100], Step [30400/6235], Loss: 0.0729\n",
      "Epoch [71/100], Step [30500/6235], Loss: 1.1475\n",
      "Epoch [71/100], Step [30600/6235], Loss: 0.2041\n",
      "Epoch [71/100], Step [30700/6235], Loss: 0.3565\n",
      "Epoch [71/100], Step [30800/6235], Loss: 0.1846\n",
      "Epoch [71/100], Step [30900/6235], Loss: 2.2324\n",
      "Epoch [71/100], Step [31000/6235], Loss: 0.0798\n",
      "Epoch [71/100], Step [31100/6235], Loss: 0.0496\n",
      "Epoch [71/100], Step [31200/6235], Loss: 10.5888\n",
      "Epoch [71/100], Step [31300/6235], Loss: 1.9415\n",
      "Epoch [71/100], Step [31400/6235], Loss: 3.8978\n",
      "Epoch [71/100], Step [31500/6235], Loss: 0.0668\n",
      "Epoch [71/100], Step [31600/6235], Loss: 6.3202\n",
      "Epoch [71/100], Step [31700/6235], Loss: 5.3191\n",
      "Epoch [71/100], Step [31800/6235], Loss: 1.0643\n",
      "Epoch [71/100], Step [31900/6235], Loss: 25.6336\n",
      "Epoch [71/100], Step [32000/6235], Loss: 135.5013\n",
      "Epoch [71/100], Step [32100/6235], Loss: 8.7969\n",
      "Epoch [71/100], Step [32200/6235], Loss: 1.2731\n",
      "Epoch [71/100], Step [32300/6235], Loss: 9.8252\n",
      "Epoch [71/100], Step [32400/6235], Loss: 1.8566\n",
      "Epoch [71/100], Step [32500/6235], Loss: 0.5503\n",
      "Epoch [71/100], Step [32600/6235], Loss: 0.0882\n",
      "Epoch [71/100], Step [32700/6235], Loss: 91.5335\n",
      "Epoch [71/100], Step [32800/6235], Loss: 0.9108\n",
      "Epoch [71/100], Step [32900/6235], Loss: 3.5216\n",
      "Epoch [71/100], Step [33000/6235], Loss: 0.2547\n",
      "Epoch [71/100], Step [33100/6235], Loss: 1.0323\n",
      "Epoch [71/100], Step [33200/6235], Loss: 1.0120\n",
      "Epoch [71/100], Step [33300/6235], Loss: 0.3877\n",
      "Epoch [71/100], Step [33400/6235], Loss: 45.1862\n",
      "Epoch [71/100], Step [33500/6235], Loss: 1.5358\n",
      "Epoch [71/100], Step [33600/6235], Loss: 7.0734\n",
      "Epoch [71/100], Step [33700/6235], Loss: 6.1908\n",
      "Epoch [71/100], Step [33800/6235], Loss: 1.0065\n",
      "Epoch [71/100], Step [33900/6235], Loss: 26.4652\n",
      "Epoch [71/100], Step [34000/6235], Loss: 0.0363\n",
      "Epoch [71/100], Step [34100/6235], Loss: 0.4917\n",
      "Epoch [71/100], Step [34200/6235], Loss: 2.4647\n",
      "Epoch [71/100], Step [34300/6235], Loss: 4.4445\n",
      "Epoch [71/100], Step [34400/6235], Loss: 0.1851\n",
      "Epoch [71/100], Step [34500/6235], Loss: 34.7053\n",
      "Epoch [71/100], Step [34600/6235], Loss: 2.4948\n",
      "Epoch [71/100], Step [34700/6235], Loss: 20.8021\n",
      "Epoch [71/100], Step [34800/6235], Loss: 8.1694\n",
      "Epoch [71/100], Step [34900/6235], Loss: 47.0437\n",
      "Epoch [71/100], Step [35000/6235], Loss: 0.0429\n",
      "Epoch [71/100], Step [35100/6235], Loss: 3.5678\n",
      "Epoch [71/100], Step [35200/6235], Loss: 1.6453\n",
      "Epoch [71/100], Step [35300/6235], Loss: 0.4678\n",
      "Epoch [71/100], Step [35400/6235], Loss: 0.5624\n",
      "Epoch [71/100], Step [35500/6235], Loss: 2.3662\n",
      "Epoch [71/100], Step [35600/6235], Loss: 3.6319\n",
      "Epoch [71/100], Step [35700/6235], Loss: 5.7249\n",
      "Epoch [71/100], Step [35800/6235], Loss: 0.4019\n",
      "Epoch [71/100], Step [35900/6235], Loss: 0.6044\n",
      "Epoch [71/100], Step [36000/6235], Loss: 0.1592\n",
      "Epoch [71/100], Step [36100/6235], Loss: 0.0559\n",
      "Epoch [71/100], Step [36200/6235], Loss: 20.2681\n",
      "Epoch [71/100], Step [36300/6235], Loss: 1.2287\n",
      "Epoch [71/100], Step [36400/6235], Loss: 2.5670\n",
      "Epoch [71/100], Step [36500/6235], Loss: 8.7724\n",
      "Epoch [71/100], Step [36600/6235], Loss: 0.1280\n",
      "Epoch [71/100], Step [36700/6235], Loss: 0.4210\n",
      "Epoch [71/100], Step [36800/6235], Loss: 11.3791\n",
      "Epoch [71/100], Step [36900/6235], Loss: 7.8997\n",
      "Epoch [71/100], Step [37000/6235], Loss: 0.5867\n",
      "Epoch [71/100], Step [37100/6235], Loss: 1.2588\n",
      "Epoch [71/100], Step [37200/6235], Loss: 0.0776\n",
      "Epoch [71/100], Step [37300/6235], Loss: 0.0404\n",
      "Epoch [71/100], Step [37400/6235], Loss: 0.1994\n",
      "Epoch [71/100], Step [37500/6235], Loss: 4.8797\n",
      "Epoch [71/100], Step [37600/6235], Loss: 11.8628\n",
      "Epoch [71/100], Step [37700/6235], Loss: 1.7955\n",
      "Epoch [71/100], Step [37800/6235], Loss: 3.9389\n",
      "Epoch [71/100], Step [37900/6235], Loss: 4.1487\n",
      "Epoch [71/100], Step [38000/6235], Loss: 0.8661\n",
      "Epoch [71/100], Step [38100/6235], Loss: 4.6488\n",
      "Epoch [71/100], Step [38200/6235], Loss: 2.0610\n",
      "Epoch [71/100], Step [38300/6235], Loss: 0.6266\n",
      "Epoch [71/100], Step [38400/6235], Loss: 0.0904\n",
      "Epoch [71/100], Step [38500/6235], Loss: 2.2453\n",
      "Epoch [71/100], Step [38600/6235], Loss: 0.2416\n",
      "Epoch [71/100], Step [38700/6235], Loss: 0.0401\n",
      "Epoch [71/100], Step [38800/6235], Loss: 0.1668\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [71/100], Step [38900/6235], Loss: 2.9919\n",
      "Epoch [71/100], Step [39000/6235], Loss: 7.6169\n",
      "Epoch [71/100], Step [39100/6235], Loss: 21.0886\n",
      "Epoch [71/100], Step [39200/6235], Loss: 0.6645\n",
      "Epoch [71/100], Step [39300/6235], Loss: 15.0248\n",
      "Epoch [71/100], Step [39400/6235], Loss: 241.3640\n",
      "Epoch [71/100], Step [39500/6235], Loss: 14.7854\n",
      "Epoch [71/100], Step [39600/6235], Loss: 11.1756\n",
      "Epoch [71/100], Step [39700/6235], Loss: 79.3068\n",
      "Epoch [71/100], Step [39800/6235], Loss: 86.4788\n",
      "Epoch [71/100], Step [39900/6235], Loss: 3.0346\n",
      "Epoch [71/100], Step [40000/6235], Loss: 15.7608\n",
      "Epoch [71/100], Step [40100/6235], Loss: 26.7277\n",
      "Epoch [71/100], Step [40200/6235], Loss: 2.4755\n",
      "Epoch [71/100], Step [40300/6235], Loss: 1.6699\n",
      "Epoch [71/100], Step [40400/6235], Loss: 0.4453\n",
      "Epoch [71/100], Step [40500/6235], Loss: 2.8250\n",
      "Epoch [71/100], Step [40600/6235], Loss: 0.2380\n",
      "Epoch [71/100], Step [40700/6235], Loss: 6.6844\n",
      "Epoch [71/100], Step [40800/6235], Loss: 0.5343\n",
      "Epoch [71/100], Step [40900/6235], Loss: 0.9804\n",
      "Epoch [71/100], Step [41000/6235], Loss: 45.6409\n",
      "Epoch [71/100], Step [41100/6235], Loss: 6.4139\n",
      "Epoch [71/100], Step [41200/6235], Loss: 32.8973\n",
      "Epoch [71/100], Step [41300/6235], Loss: 1.9377\n",
      "Epoch [71/100], Step [41400/6235], Loss: 0.2138\n",
      "Epoch [71/100], Step [41500/6235], Loss: 3.1941\n",
      "Epoch [71/100], Step [41600/6235], Loss: 0.2825\n",
      "Epoch [71/100], Step [41700/6235], Loss: 0.0687\n",
      "Epoch [71/100], Step [41800/6235], Loss: 0.9910\n",
      "Epoch [71/100], Step [41900/6235], Loss: 4.8950\n",
      "Epoch [71/100], Step [42000/6235], Loss: 4.6321\n",
      "Epoch [71/100], Step [42100/6235], Loss: 10.9197\n",
      "Epoch [71/100], Step [42200/6235], Loss: 43.0656\n",
      "Epoch [71/100], Step [42300/6235], Loss: 1.8604\n",
      "Epoch [71/100], Step [42400/6235], Loss: 6.0046\n",
      "Epoch [71/100], Step [42500/6235], Loss: 0.5213\n",
      "Epoch [71/100], Step [42600/6235], Loss: 1.2828\n",
      "Epoch [71/100], Step [42700/6235], Loss: 0.6288\n",
      "Epoch [71/100], Step [42800/6235], Loss: 5.6700\n",
      "Epoch [71/100], Step [42900/6235], Loss: 2.1464\n",
      "Epoch [71/100], Step [43000/6235], Loss: 0.1715\n",
      "Epoch [71/100], Step [43100/6235], Loss: 0.0367\n",
      "Epoch [71/100], Step [43200/6235], Loss: 0.9016\n",
      "Epoch [71/100], Step [43300/6235], Loss: 7.5730\n",
      "Epoch [71/100], Step [43400/6235], Loss: 11.4390\n",
      "Epoch [71/100], Step [43500/6235], Loss: 9.5744\n",
      "Epoch [71/100], Step [43600/6235], Loss: 8.2951\n",
      "Epoch [71/100], Step [43700/6235], Loss: 46.4927\n",
      "Epoch [71/100], Step [43800/6235], Loss: 0.5593\n",
      "Epoch [71/100], Step [43900/6235], Loss: 0.3309\n",
      "Epoch [71/100], Step [44000/6235], Loss: 56.0158\n",
      "Epoch [71/100], Step [44100/6235], Loss: 4.0065\n",
      "Epoch [71/100], Step [44200/6235], Loss: 3.2134\n",
      "Epoch [71/100], Step [44300/6235], Loss: 19.9742\n",
      "Epoch [71/100], Step [44400/6235], Loss: 2.8159\n",
      "Epoch [71/100], Step [44500/6235], Loss: 0.7242\n",
      "Epoch [71/100], Step [44600/6235], Loss: 26.1690\n",
      "Epoch [71/100], Step [44700/6235], Loss: 4.4832\n",
      "Epoch [71/100], Step [44800/6235], Loss: 4.1770\n",
      "Epoch [71/100], Step [44900/6235], Loss: 5.0257\n",
      "Epoch [71/100], Step [45000/6235], Loss: 4.9031\n",
      "Epoch [71/100], Step [45100/6235], Loss: 59.9794\n",
      "Epoch [71/100], Step [45200/6235], Loss: 0.6199\n",
      "Epoch [71/100], Step [45300/6235], Loss: 31.0492\n",
      "Epoch [71/100], Step [45400/6235], Loss: 12.3025\n",
      "Epoch [71/100], Step [45500/6235], Loss: 0.2914\n",
      "Epoch [71/100], Step [45600/6235], Loss: 0.2342\n",
      "Epoch [71/100], Step [45700/6235], Loss: 54.9848\n",
      "Epoch [71/100], Step [45800/6235], Loss: 240.0945\n",
      "Epoch [71/100], Step [45900/6235], Loss: 7.1660\n",
      "Epoch [71/100], Step [46000/6235], Loss: 22.1072\n",
      "Epoch [71/100], Step [46100/6235], Loss: 16.3069\n",
      "Epoch [71/100], Step [46200/6235], Loss: 4.2145\n",
      "Epoch [71/100], Step [46300/6235], Loss: 14.2327\n",
      "Epoch [71/100], Step [46400/6235], Loss: 3.3232\n",
      "Epoch [71/100], Step [46500/6235], Loss: 17.1338\n",
      "Epoch [71/100], Step [46600/6235], Loss: 12.5821\n",
      "Epoch [71/100], Step [46700/6235], Loss: 10.1399\n",
      "Epoch [71/100], Step [46800/6235], Loss: 8.3393\n",
      "Epoch [71/100], Step [46900/6235], Loss: 10.4131\n",
      "Epoch [71/100], Step [47000/6235], Loss: 2.8117\n",
      "Epoch [71/100], Step [47100/6235], Loss: 13.6573\n",
      "Epoch [71/100], Step [47200/6235], Loss: 34.9630\n",
      "Epoch [71/100], Step [47300/6235], Loss: 1.0211\n",
      "Epoch [71/100], Step [47400/6235], Loss: 53.4794\n",
      "Epoch [71/100], Step [47500/6235], Loss: 3.7494\n",
      "Epoch [71/100], Step [47600/6235], Loss: 16.0541\n",
      "Epoch [71/100], Step [47700/6235], Loss: 15.1825\n",
      "Epoch [71/100], Step [47800/6235], Loss: 11.1649\n",
      "Epoch [71/100], Step [47900/6235], Loss: 16.9841\n",
      "Epoch [71/100], Step [48000/6235], Loss: 64.9516\n",
      "Epoch [71/100], Step [48100/6235], Loss: 4.3932\n",
      "Epoch [71/100], Step [48200/6235], Loss: 23.4463\n",
      "Epoch [71/100], Step [48300/6235], Loss: 400.0378\n",
      "Epoch [71/100], Step [48400/6235], Loss: 19.5582\n",
      "Epoch [71/100], Step [48500/6235], Loss: 26.4486\n",
      "Epoch [71/100], Step [48600/6235], Loss: 157.5678\n",
      "Epoch [71/100], Step [48700/6235], Loss: 7.0996\n",
      "Epoch [71/100], Step [48800/6235], Loss: 271.1640\n",
      "Epoch [71/100], Step [48900/6235], Loss: 375.7161\n",
      "Epoch [71/100], Step [49000/6235], Loss: 202.6773\n",
      "Epoch [71/100], Step [49100/6235], Loss: 3694.9590\n",
      "Epoch [71/100], Step [49200/6235], Loss: 611.4962\n",
      "Epoch [71/100], Step [49300/6235], Loss: 1198.9098\n",
      "Epoch [71/100], Step [49400/6235], Loss: 148.1193\n",
      "Epoch [71/100], Step [49500/6235], Loss: 23.0170\n",
      "Epoch [71/100], Step [49600/6235], Loss: 111.1820\n",
      "Epoch [71/100], Step [49700/6235], Loss: 1503.3682\n",
      "Epoch [71/100], Step [49800/6235], Loss: 404.8382\n",
      "Epoch [72/100], Step [100/6235], Loss: 37.8407\n",
      "Epoch [72/100], Step [200/6235], Loss: 0.6903\n",
      "Epoch [72/100], Step [300/6235], Loss: 0.0498\n",
      "Epoch [72/100], Step [400/6235], Loss: 0.0056\n",
      "Epoch [72/100], Step [500/6235], Loss: 9.3474\n",
      "Epoch [72/100], Step [600/6235], Loss: 0.0633\n",
      "Epoch [72/100], Step [700/6235], Loss: 0.6365\n",
      "Epoch [72/100], Step [800/6235], Loss: 0.1160\n",
      "Epoch [72/100], Step [900/6235], Loss: 0.2159\n",
      "Epoch [72/100], Step [1000/6235], Loss: 0.0474\n",
      "Epoch [72/100], Step [1100/6235], Loss: 0.8784\n",
      "Epoch [72/100], Step [1200/6235], Loss: 0.1774\n",
      "Epoch [72/100], Step [1300/6235], Loss: 0.0824\n",
      "Epoch [72/100], Step [1400/6235], Loss: 1.4223\n",
      "Epoch [72/100], Step [1500/6235], Loss: 0.0182\n",
      "Epoch [72/100], Step [1600/6235], Loss: 0.2470\n",
      "Epoch [72/100], Step [1700/6235], Loss: 0.2265\n",
      "Epoch [72/100], Step [1800/6235], Loss: 0.3090\n",
      "Epoch [72/100], Step [1900/6235], Loss: 0.3313\n",
      "Epoch [72/100], Step [2000/6235], Loss: 2.5549\n",
      "Epoch [72/100], Step [2100/6235], Loss: 2.5307\n",
      "Epoch [72/100], Step [2200/6235], Loss: 6.1832\n",
      "Epoch [72/100], Step [2300/6235], Loss: 0.4520\n",
      "Epoch [72/100], Step [2400/6235], Loss: 1.3365\n",
      "Epoch [72/100], Step [2500/6235], Loss: 30.0252\n",
      "Epoch [72/100], Step [2600/6235], Loss: 13.4394\n",
      "Epoch [72/100], Step [2700/6235], Loss: 5.8142\n",
      "Epoch [72/100], Step [2800/6235], Loss: 53.6998\n",
      "Epoch [72/100], Step [2900/6235], Loss: 17.9061\n",
      "Epoch [72/100], Step [3000/6235], Loss: 0.8053\n",
      "Epoch [72/100], Step [3100/6235], Loss: 67.9185\n",
      "Epoch [72/100], Step [3200/6235], Loss: 43.0911\n",
      "Epoch [72/100], Step [3300/6235], Loss: 9.7417\n",
      "Epoch [72/100], Step [3400/6235], Loss: 3.4867\n",
      "Epoch [72/100], Step [3500/6235], Loss: 53.6574\n",
      "Epoch [72/100], Step [3600/6235], Loss: 1.3311\n",
      "Epoch [72/100], Step [3700/6235], Loss: 0.0399\n",
      "Epoch [72/100], Step [3800/6235], Loss: 0.0282\n",
      "Epoch [72/100], Step [3900/6235], Loss: 0.0997\n",
      "Epoch [72/100], Step [4000/6235], Loss: 0.0967\n",
      "Epoch [72/100], Step [4100/6235], Loss: 9.7463\n",
      "Epoch [72/100], Step [4200/6235], Loss: 3.6409\n",
      "Epoch [72/100], Step [4300/6235], Loss: 4.4265\n",
      "Epoch [72/100], Step [4400/6235], Loss: 0.5663\n",
      "Epoch [72/100], Step [4500/6235], Loss: 38.3830\n",
      "Epoch [72/100], Step [4600/6235], Loss: 1.2238\n",
      "Epoch [72/100], Step [4700/6235], Loss: 0.3563\n",
      "Epoch [72/100], Step [4800/6235], Loss: 7.6203\n",
      "Epoch [72/100], Step [4900/6235], Loss: 1.2808\n",
      "Epoch [72/100], Step [5000/6235], Loss: 0.1735\n",
      "Epoch [72/100], Step [5100/6235], Loss: 0.1444\n",
      "Epoch [72/100], Step [5200/6235], Loss: 3.9431\n",
      "Epoch [72/100], Step [5300/6235], Loss: 26.4661\n",
      "Epoch [72/100], Step [5400/6235], Loss: 1.3154\n",
      "Epoch [72/100], Step [5500/6235], Loss: 0.0273\n",
      "Epoch [72/100], Step [5600/6235], Loss: 0.2613\n",
      "Epoch [72/100], Step [5700/6235], Loss: 0.1133\n",
      "Epoch [72/100], Step [5800/6235], Loss: 0.1490\n",
      "Epoch [72/100], Step [5900/6235], Loss: 0.2284\n",
      "Epoch [72/100], Step [6000/6235], Loss: 0.0446\n",
      "Epoch [72/100], Step [6100/6235], Loss: 0.0558\n",
      "Epoch [72/100], Step [6200/6235], Loss: 6.2660\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Step [6300/6235], Loss: 0.1680\n",
      "Epoch [72/100], Step [6400/6235], Loss: 0.0097\n",
      "Epoch [72/100], Step [6500/6235], Loss: 2.4373\n",
      "Epoch [72/100], Step [6600/6235], Loss: 5.1541\n",
      "Epoch [72/100], Step [6700/6235], Loss: 0.9499\n",
      "Epoch [72/100], Step [6800/6235], Loss: 0.2356\n",
      "Epoch [72/100], Step [6900/6235], Loss: 0.9864\n",
      "Epoch [72/100], Step [7000/6235], Loss: 0.1162\n",
      "Epoch [72/100], Step [7100/6235], Loss: 0.5335\n",
      "Epoch [72/100], Step [7200/6235], Loss: 0.1085\n",
      "Epoch [72/100], Step [7300/6235], Loss: 0.7912\n",
      "Epoch [72/100], Step [7400/6235], Loss: 0.2686\n",
      "Epoch [72/100], Step [7500/6235], Loss: 0.3572\n",
      "Epoch [72/100], Step [7600/6235], Loss: 0.6834\n",
      "Epoch [72/100], Step [7700/6235], Loss: 19.9928\n",
      "Epoch [72/100], Step [7800/6235], Loss: 1.8634\n",
      "Epoch [72/100], Step [7900/6235], Loss: 0.1837\n",
      "Epoch [72/100], Step [8000/6235], Loss: 0.1630\n",
      "Epoch [72/100], Step [8100/6235], Loss: 2.4239\n",
      "Epoch [72/100], Step [8200/6235], Loss: 10.3990\n",
      "Epoch [72/100], Step [8300/6235], Loss: 13.1253\n",
      "Epoch [72/100], Step [8400/6235], Loss: 535.6124\n",
      "Epoch [72/100], Step [8500/6235], Loss: 11.0129\n",
      "Epoch [72/100], Step [8600/6235], Loss: 31.0573\n",
      "Epoch [72/100], Step [8700/6235], Loss: 21.0178\n",
      "Epoch [72/100], Step [8800/6235], Loss: 651.0302\n",
      "Epoch [72/100], Step [8900/6235], Loss: 261.9792\n",
      "Epoch [72/100], Step [9000/6235], Loss: 553.6052\n",
      "Epoch [72/100], Step [9100/6235], Loss: 742.1541\n",
      "Epoch [72/100], Step [9200/6235], Loss: 320.6648\n",
      "Epoch [72/100], Step [9300/6235], Loss: 326.3263\n",
      "Epoch [72/100], Step [9400/6235], Loss: 29.9271\n",
      "Epoch [72/100], Step [9500/6235], Loss: 2353.9753\n",
      "Epoch [72/100], Step [9600/6235], Loss: 341.4440\n",
      "Epoch [72/100], Step [9700/6235], Loss: 12.5745\n",
      "Epoch [72/100], Step [9800/6235], Loss: 4435.6079\n",
      "Epoch [72/100], Step [9900/6235], Loss: 16.6054\n",
      "Epoch [72/100], Step [10000/6235], Loss: 7.3224\n",
      "Epoch [72/100], Step [10100/6235], Loss: 3.4203\n",
      "Epoch [72/100], Step [10200/6235], Loss: 561.1627\n",
      "Epoch [72/100], Step [10300/6235], Loss: 51.1974\n",
      "Epoch [72/100], Step [10400/6235], Loss: 9.1129\n",
      "Epoch [72/100], Step [10500/6235], Loss: 27.3107\n",
      "Epoch [72/100], Step [10600/6235], Loss: 358.9640\n",
      "Epoch [72/100], Step [10700/6235], Loss: 18.6050\n",
      "Epoch [72/100], Step [10800/6235], Loss: 89.7551\n",
      "Epoch [72/100], Step [10900/6235], Loss: 11.8881\n",
      "Epoch [72/100], Step [11000/6235], Loss: 299.5719\n",
      "Epoch [72/100], Step [11100/6235], Loss: 46.6228\n",
      "Epoch [72/100], Step [11200/6235], Loss: 22.8725\n",
      "Epoch [72/100], Step [11300/6235], Loss: 116.1493\n",
      "Epoch [72/100], Step [11400/6235], Loss: 23.5630\n",
      "Epoch [72/100], Step [11500/6235], Loss: 11.5750\n",
      "Epoch [72/100], Step [11600/6235], Loss: 7.1819\n",
      "Epoch [72/100], Step [11700/6235], Loss: 50.4066\n",
      "Epoch [72/100], Step [11800/6235], Loss: 138.5089\n",
      "Epoch [72/100], Step [11900/6235], Loss: 22.5772\n",
      "Epoch [72/100], Step [12000/6235], Loss: 617.8035\n",
      "Epoch [72/100], Step [12100/6235], Loss: 211.5130\n",
      "Epoch [72/100], Step [12200/6235], Loss: 39.0433\n",
      "Epoch [72/100], Step [12300/6235], Loss: 13.2746\n",
      "Epoch [72/100], Step [12400/6235], Loss: 584.8029\n",
      "Epoch [72/100], Step [12500/6235], Loss: 85.2607\n",
      "Epoch [72/100], Step [12600/6235], Loss: 11.5879\n",
      "Epoch [72/100], Step [12700/6235], Loss: 7.9367\n",
      "Epoch [72/100], Step [12800/6235], Loss: 16.4079\n",
      "Epoch [72/100], Step [12900/6235], Loss: 31.0930\n",
      "Epoch [72/100], Step [13000/6235], Loss: 0.2059\n",
      "Epoch [72/100], Step [13100/6235], Loss: 64.2395\n",
      "Epoch [72/100], Step [13200/6235], Loss: 11.8754\n",
      "Epoch [72/100], Step [13300/6235], Loss: 14.2101\n",
      "Epoch [72/100], Step [13400/6235], Loss: 227.9698\n",
      "Epoch [72/100], Step [13500/6235], Loss: 3.6971\n",
      "Epoch [72/100], Step [13600/6235], Loss: 1.4422\n",
      "Epoch [72/100], Step [13700/6235], Loss: 90.2409\n",
      "Epoch [72/100], Step [13800/6235], Loss: 130.9512\n",
      "Epoch [72/100], Step [13900/6235], Loss: 56.7799\n",
      "Epoch [72/100], Step [14000/6235], Loss: 2.2575\n",
      "Epoch [72/100], Step [14100/6235], Loss: 120.9989\n",
      "Epoch [72/100], Step [14200/6235], Loss: 122.6191\n",
      "Epoch [72/100], Step [14300/6235], Loss: 17.3830\n",
      "Epoch [72/100], Step [14400/6235], Loss: 35.5662\n",
      "Epoch [72/100], Step [14500/6235], Loss: 42.2047\n",
      "Epoch [72/100], Step [14600/6235], Loss: 1.6450\n",
      "Epoch [72/100], Step [14700/6235], Loss: 35.3233\n",
      "Epoch [72/100], Step [14800/6235], Loss: 33.7259\n",
      "Epoch [72/100], Step [14900/6235], Loss: 0.6850\n",
      "Epoch [72/100], Step [15000/6235], Loss: 1.5095\n",
      "Epoch [72/100], Step [15100/6235], Loss: 0.5480\n",
      "Epoch [72/100], Step [15200/6235], Loss: 35.5343\n",
      "Epoch [72/100], Step [15300/6235], Loss: 3.8423\n",
      "Epoch [72/100], Step [15400/6235], Loss: 11.9696\n",
      "Epoch [72/100], Step [15500/6235], Loss: 12.7329\n",
      "Epoch [72/100], Step [15600/6235], Loss: 228.2074\n",
      "Epoch [72/100], Step [15700/6235], Loss: 135.2907\n",
      "Epoch [72/100], Step [15800/6235], Loss: 0.3362\n",
      "Epoch [72/100], Step [15900/6235], Loss: 2.8308\n",
      "Epoch [72/100], Step [16000/6235], Loss: 123.8023\n",
      "Epoch [72/100], Step [16100/6235], Loss: 1.0765\n",
      "Epoch [72/100], Step [16200/6235], Loss: 1.0322\n",
      "Epoch [72/100], Step [16300/6235], Loss: 9.2439\n",
      "Epoch [72/100], Step [16400/6235], Loss: 20.8251\n",
      "Epoch [72/100], Step [16500/6235], Loss: 61.5884\n",
      "Epoch [72/100], Step [16600/6235], Loss: 15.4445\n",
      "Epoch [72/100], Step [16700/6235], Loss: 0.7247\n",
      "Epoch [72/100], Step [16800/6235], Loss: 10.1538\n",
      "Epoch [72/100], Step [16900/6235], Loss: 0.5082\n",
      "Epoch [72/100], Step [17000/6235], Loss: 0.1914\n",
      "Epoch [72/100], Step [17100/6235], Loss: 0.1422\n",
      "Epoch [72/100], Step [17200/6235], Loss: 113.8852\n",
      "Epoch [72/100], Step [17300/6235], Loss: 83.5348\n",
      "Epoch [72/100], Step [17400/6235], Loss: 33.1180\n",
      "Epoch [72/100], Step [17500/6235], Loss: 7.5412\n",
      "Epoch [72/100], Step [17600/6235], Loss: 2.4896\n",
      "Epoch [72/100], Step [17700/6235], Loss: 2.7042\n",
      "Epoch [72/100], Step [17800/6235], Loss: 18.2756\n",
      "Epoch [72/100], Step [17900/6235], Loss: 5.1467\n",
      "Epoch [72/100], Step [18000/6235], Loss: 6.5084\n",
      "Epoch [72/100], Step [18100/6235], Loss: 10.8138\n",
      "Epoch [72/100], Step [18200/6235], Loss: 0.9438\n",
      "Epoch [72/100], Step [18300/6235], Loss: 7.0635\n",
      "Epoch [72/100], Step [18400/6235], Loss: 1.4617\n",
      "Epoch [72/100], Step [18500/6235], Loss: 5.5793\n",
      "Epoch [72/100], Step [18600/6235], Loss: 0.7747\n",
      "Epoch [72/100], Step [18700/6235], Loss: 0.3486\n",
      "Epoch [72/100], Step [18800/6235], Loss: 96.8449\n",
      "Epoch [72/100], Step [18900/6235], Loss: 36.3887\n",
      "Epoch [72/100], Step [19000/6235], Loss: 2.5300\n",
      "Epoch [72/100], Step [19100/6235], Loss: 36.1813\n",
      "Epoch [72/100], Step [19200/6235], Loss: 2.8626\n",
      "Epoch [72/100], Step [19300/6235], Loss: 9.3604\n",
      "Epoch [72/100], Step [19400/6235], Loss: 2.9496\n",
      "Epoch [72/100], Step [19500/6235], Loss: 79.8847\n",
      "Epoch [72/100], Step [19600/6235], Loss: 137.5834\n",
      "Epoch [72/100], Step [19700/6235], Loss: 5.5233\n",
      "Epoch [72/100], Step [19800/6235], Loss: 3.1425\n",
      "Epoch [72/100], Step [19900/6235], Loss: 0.0884\n",
      "Epoch [72/100], Step [20000/6235], Loss: 64.7744\n",
      "Epoch [72/100], Step [20100/6235], Loss: 0.6796\n",
      "Epoch [72/100], Step [20200/6235], Loss: 4.2910\n",
      "Epoch [72/100], Step [20300/6235], Loss: 1.9120\n",
      "Epoch [72/100], Step [20400/6235], Loss: 17.6516\n",
      "Epoch [72/100], Step [20500/6235], Loss: 42.5618\n",
      "Epoch [72/100], Step [20600/6235], Loss: 57.4059\n",
      "Epoch [72/100], Step [20700/6235], Loss: 28.6623\n",
      "Epoch [72/100], Step [20800/6235], Loss: 5.4707\n",
      "Epoch [72/100], Step [20900/6235], Loss: 37.0124\n",
      "Epoch [72/100], Step [21000/6235], Loss: 17.6015\n",
      "Epoch [72/100], Step [21100/6235], Loss: 4.4456\n",
      "Epoch [72/100], Step [21200/6235], Loss: 0.1561\n",
      "Epoch [72/100], Step [21300/6235], Loss: 0.2169\n",
      "Epoch [72/100], Step [21400/6235], Loss: 5.9350\n",
      "Epoch [72/100], Step [21500/6235], Loss: 1.0631\n",
      "Epoch [72/100], Step [21600/6235], Loss: 29.7989\n",
      "Epoch [72/100], Step [21700/6235], Loss: 0.1740\n",
      "Epoch [72/100], Step [21800/6235], Loss: 0.7162\n",
      "Epoch [72/100], Step [21900/6235], Loss: 0.7480\n",
      "Epoch [72/100], Step [22000/6235], Loss: 5.5103\n",
      "Epoch [72/100], Step [22100/6235], Loss: 1.6225\n",
      "Epoch [72/100], Step [22200/6235], Loss: 9.0939\n",
      "Epoch [72/100], Step [22300/6235], Loss: 1.2856\n",
      "Epoch [72/100], Step [22400/6235], Loss: 5.7860\n",
      "Epoch [72/100], Step [22500/6235], Loss: 168.4758\n",
      "Epoch [72/100], Step [22600/6235], Loss: 22.2381\n",
      "Epoch [72/100], Step [22700/6235], Loss: 0.9172\n",
      "Epoch [72/100], Step [22800/6235], Loss: 8.4500\n",
      "Epoch [72/100], Step [22900/6235], Loss: 12.7405\n",
      "Epoch [72/100], Step [23000/6235], Loss: 5.4162\n",
      "Epoch [72/100], Step [23100/6235], Loss: 6.9118\n",
      "Epoch [72/100], Step [23200/6235], Loss: 17.6054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Step [23300/6235], Loss: 18.5080\n",
      "Epoch [72/100], Step [23400/6235], Loss: 1.4297\n",
      "Epoch [72/100], Step [23500/6235], Loss: 0.1280\n",
      "Epoch [72/100], Step [23600/6235], Loss: 110.5622\n",
      "Epoch [72/100], Step [23700/6235], Loss: 3.4878\n",
      "Epoch [72/100], Step [23800/6235], Loss: 0.9862\n",
      "Epoch [72/100], Step [23900/6235], Loss: 8.5789\n",
      "Epoch [72/100], Step [24000/6235], Loss: 0.3094\n",
      "Epoch [72/100], Step [24100/6235], Loss: 1.0912\n",
      "Epoch [72/100], Step [24200/6235], Loss: 52.3398\n",
      "Epoch [72/100], Step [24300/6235], Loss: 3.2489\n",
      "Epoch [72/100], Step [24400/6235], Loss: 5.6502\n",
      "Epoch [72/100], Step [24500/6235], Loss: 3.0866\n",
      "Epoch [72/100], Step [24600/6235], Loss: 0.2183\n",
      "Epoch [72/100], Step [24700/6235], Loss: 1.3960\n",
      "Epoch [72/100], Step [24800/6235], Loss: 0.0854\n",
      "Epoch [72/100], Step [24900/6235], Loss: 11.0151\n",
      "Epoch [72/100], Step [25000/6235], Loss: 18.9583\n",
      "Epoch [72/100], Step [25100/6235], Loss: 7.1575\n",
      "Epoch [72/100], Step [25200/6235], Loss: 1.8715\n",
      "Epoch [72/100], Step [25300/6235], Loss: 1.2394\n",
      "Epoch [72/100], Step [25400/6235], Loss: 9.6308\n",
      "Epoch [72/100], Step [25500/6235], Loss: 6.1269\n",
      "Epoch [72/100], Step [25600/6235], Loss: 2.8135\n",
      "Epoch [72/100], Step [25700/6235], Loss: 0.3480\n",
      "Epoch [72/100], Step [25800/6235], Loss: 0.1673\n",
      "Epoch [72/100], Step [25900/6235], Loss: 9.7152\n",
      "Epoch [72/100], Step [26000/6235], Loss: 0.4244\n",
      "Epoch [72/100], Step [26100/6235], Loss: 0.1348\n",
      "Epoch [72/100], Step [26200/6235], Loss: 0.1738\n",
      "Epoch [72/100], Step [26300/6235], Loss: 4.7217\n",
      "Epoch [72/100], Step [26400/6235], Loss: 0.1811\n",
      "Epoch [72/100], Step [26500/6235], Loss: 0.2332\n",
      "Epoch [72/100], Step [26600/6235], Loss: 3.2437\n",
      "Epoch [72/100], Step [26700/6235], Loss: 0.6673\n",
      "Epoch [72/100], Step [26800/6235], Loss: 0.7063\n",
      "Epoch [72/100], Step [26900/6235], Loss: 0.0489\n",
      "Epoch [72/100], Step [27000/6235], Loss: 12.6121\n",
      "Epoch [72/100], Step [27100/6235], Loss: 0.1473\n",
      "Epoch [72/100], Step [27200/6235], Loss: 0.0589\n",
      "Epoch [72/100], Step [27300/6235], Loss: 0.2035\n",
      "Epoch [72/100], Step [27400/6235], Loss: 0.9294\n",
      "Epoch [72/100], Step [27500/6235], Loss: 16.4686\n",
      "Epoch [72/100], Step [27600/6235], Loss: 0.2864\n",
      "Epoch [72/100], Step [27700/6235], Loss: 1.4529\n",
      "Epoch [72/100], Step [27800/6235], Loss: 0.2839\n",
      "Epoch [72/100], Step [27900/6235], Loss: 0.7203\n",
      "Epoch [72/100], Step [28000/6235], Loss: 119.8364\n",
      "Epoch [72/100], Step [28100/6235], Loss: 5.2189\n",
      "Epoch [72/100], Step [28200/6235], Loss: 20.1370\n",
      "Epoch [72/100], Step [28300/6235], Loss: 3.7954\n",
      "Epoch [72/100], Step [28400/6235], Loss: 24.5603\n",
      "Epoch [72/100], Step [28500/6235], Loss: 3.7268\n",
      "Epoch [72/100], Step [28600/6235], Loss: 0.3935\n",
      "Epoch [72/100], Step [28700/6235], Loss: 4.7694\n",
      "Epoch [72/100], Step [28800/6235], Loss: 0.4110\n",
      "Epoch [72/100], Step [28900/6235], Loss: 72.0918\n",
      "Epoch [72/100], Step [29000/6235], Loss: 8.4928\n",
      "Epoch [72/100], Step [29100/6235], Loss: 0.0176\n",
      "Epoch [72/100], Step [29200/6235], Loss: 0.1915\n",
      "Epoch [72/100], Step [29300/6235], Loss: 15.3730\n",
      "Epoch [72/100], Step [29400/6235], Loss: 0.1168\n",
      "Epoch [72/100], Step [29500/6235], Loss: 7.2728\n",
      "Epoch [72/100], Step [29600/6235], Loss: 0.6718\n",
      "Epoch [72/100], Step [29700/6235], Loss: 0.4768\n",
      "Epoch [72/100], Step [29800/6235], Loss: 1.7255\n",
      "Epoch [72/100], Step [29900/6235], Loss: 0.2496\n",
      "Epoch [72/100], Step [30000/6235], Loss: 6.7871\n",
      "Epoch [72/100], Step [30100/6235], Loss: 8.8276\n",
      "Epoch [72/100], Step [30200/6235], Loss: 0.1408\n",
      "Epoch [72/100], Step [30300/6235], Loss: 0.5451\n",
      "Epoch [72/100], Step [30400/6235], Loss: 0.2536\n",
      "Epoch [72/100], Step [30500/6235], Loss: 1.9279\n",
      "Epoch [72/100], Step [30600/6235], Loss: 0.5605\n",
      "Epoch [72/100], Step [30700/6235], Loss: 0.1508\n",
      "Epoch [72/100], Step [30800/6235], Loss: 0.2446\n",
      "Epoch [72/100], Step [30900/6235], Loss: 2.7193\n",
      "Epoch [72/100], Step [31000/6235], Loss: 0.0488\n",
      "Epoch [72/100], Step [31100/6235], Loss: 0.0803\n",
      "Epoch [72/100], Step [31200/6235], Loss: 11.1122\n",
      "Epoch [72/100], Step [31300/6235], Loss: 6.4188\n",
      "Epoch [72/100], Step [31400/6235], Loss: 0.3769\n",
      "Epoch [72/100], Step [31500/6235], Loss: 0.5560\n",
      "Epoch [72/100], Step [31600/6235], Loss: 1.9147\n",
      "Epoch [72/100], Step [31700/6235], Loss: 2.8448\n",
      "Epoch [72/100], Step [31800/6235], Loss: 0.2190\n",
      "Epoch [72/100], Step [31900/6235], Loss: 1139.8806\n",
      "Epoch [72/100], Step [32000/6235], Loss: 44.0808\n",
      "Epoch [72/100], Step [32100/6235], Loss: 5.9196\n",
      "Epoch [72/100], Step [32200/6235], Loss: 12.1297\n",
      "Epoch [72/100], Step [32300/6235], Loss: 0.2239\n",
      "Epoch [72/100], Step [32400/6235], Loss: 0.1504\n",
      "Epoch [72/100], Step [32500/6235], Loss: 18.7103\n",
      "Epoch [72/100], Step [32600/6235], Loss: 1.3523\n",
      "Epoch [72/100], Step [32700/6235], Loss: 315.2655\n",
      "Epoch [72/100], Step [32800/6235], Loss: 8.1068\n",
      "Epoch [72/100], Step [32900/6235], Loss: 10.3394\n",
      "Epoch [72/100], Step [33000/6235], Loss: 0.3718\n",
      "Epoch [72/100], Step [33100/6235], Loss: 1.5029\n",
      "Epoch [72/100], Step [33200/6235], Loss: 2.4603\n",
      "Epoch [72/100], Step [33300/6235], Loss: 0.8329\n",
      "Epoch [72/100], Step [33400/6235], Loss: 153.6531\n",
      "Epoch [72/100], Step [33500/6235], Loss: 2.3054\n",
      "Epoch [72/100], Step [33600/6235], Loss: 6.2798\n",
      "Epoch [72/100], Step [33700/6235], Loss: 12.5922\n",
      "Epoch [72/100], Step [33800/6235], Loss: 0.7925\n",
      "Epoch [72/100], Step [33900/6235], Loss: 23.2440\n",
      "Epoch [72/100], Step [34000/6235], Loss: 0.0801\n",
      "Epoch [72/100], Step [34100/6235], Loss: 0.0863\n",
      "Epoch [72/100], Step [34200/6235], Loss: 2.7683\n",
      "Epoch [72/100], Step [34300/6235], Loss: 7.5079\n",
      "Epoch [72/100], Step [34400/6235], Loss: 0.3470\n",
      "Epoch [72/100], Step [34500/6235], Loss: 102.3320\n",
      "Epoch [72/100], Step [34600/6235], Loss: 1.3653\n",
      "Epoch [72/100], Step [34700/6235], Loss: 6.4198\n",
      "Epoch [72/100], Step [34800/6235], Loss: 12.3385\n",
      "Epoch [72/100], Step [34900/6235], Loss: 49.1635\n",
      "Epoch [72/100], Step [35000/6235], Loss: 1.0064\n",
      "Epoch [72/100], Step [35100/6235], Loss: 1.1078\n",
      "Epoch [72/100], Step [35200/6235], Loss: 2.5950\n",
      "Epoch [72/100], Step [35300/6235], Loss: 0.0147\n",
      "Epoch [72/100], Step [35400/6235], Loss: 0.9673\n",
      "Epoch [72/100], Step [35500/6235], Loss: 2.0890\n",
      "Epoch [72/100], Step [35600/6235], Loss: 3.2623\n",
      "Epoch [72/100], Step [35700/6235], Loss: 5.8275\n",
      "Epoch [72/100], Step [35800/6235], Loss: 0.2920\n",
      "Epoch [72/100], Step [35900/6235], Loss: 0.3175\n",
      "Epoch [72/100], Step [36000/6235], Loss: 2.0150\n",
      "Epoch [72/100], Step [36100/6235], Loss: 0.0582\n",
      "Epoch [72/100], Step [36200/6235], Loss: 18.9819\n",
      "Epoch [72/100], Step [36300/6235], Loss: 0.1879\n",
      "Epoch [72/100], Step [36400/6235], Loss: 0.5964\n",
      "Epoch [72/100], Step [36500/6235], Loss: 9.9354\n",
      "Epoch [72/100], Step [36600/6235], Loss: 0.0371\n",
      "Epoch [72/100], Step [36700/6235], Loss: 0.1395\n",
      "Epoch [72/100], Step [36800/6235], Loss: 27.5257\n",
      "Epoch [72/100], Step [36900/6235], Loss: 4.2813\n",
      "Epoch [72/100], Step [37000/6235], Loss: 0.0343\n",
      "Epoch [72/100], Step [37100/6235], Loss: 0.1371\n",
      "Epoch [72/100], Step [37200/6235], Loss: 0.0317\n",
      "Epoch [72/100], Step [37300/6235], Loss: 0.2909\n",
      "Epoch [72/100], Step [37400/6235], Loss: 0.1974\n",
      "Epoch [72/100], Step [37500/6235], Loss: 2.7063\n",
      "Epoch [72/100], Step [37600/6235], Loss: 10.1854\n",
      "Epoch [72/100], Step [37700/6235], Loss: 0.2374\n",
      "Epoch [72/100], Step [37800/6235], Loss: 8.4557\n",
      "Epoch [72/100], Step [37900/6235], Loss: 7.3347\n",
      "Epoch [72/100], Step [38000/6235], Loss: 0.3014\n",
      "Epoch [72/100], Step [38100/6235], Loss: 2.4140\n",
      "Epoch [72/100], Step [38200/6235], Loss: 2.1636\n",
      "Epoch [72/100], Step [38300/6235], Loss: 0.0737\n",
      "Epoch [72/100], Step [38400/6235], Loss: 0.1482\n",
      "Epoch [72/100], Step [38500/6235], Loss: 3.6881\n",
      "Epoch [72/100], Step [38600/6235], Loss: 0.2972\n",
      "Epoch [72/100], Step [38700/6235], Loss: 0.2526\n",
      "Epoch [72/100], Step [38800/6235], Loss: 0.4286\n",
      "Epoch [72/100], Step [38900/6235], Loss: 20.4947\n",
      "Epoch [72/100], Step [39000/6235], Loss: 22.3430\n",
      "Epoch [72/100], Step [39100/6235], Loss: 18.7667\n",
      "Epoch [72/100], Step [39200/6235], Loss: 0.2439\n",
      "Epoch [72/100], Step [39300/6235], Loss: 24.8578\n",
      "Epoch [72/100], Step [39400/6235], Loss: 189.3254\n",
      "Epoch [72/100], Step [39500/6235], Loss: 140.1190\n",
      "Epoch [72/100], Step [39600/6235], Loss: 11.7057\n",
      "Epoch [72/100], Step [39700/6235], Loss: 152.0192\n",
      "Epoch [72/100], Step [39800/6235], Loss: 165.2356\n",
      "Epoch [72/100], Step [39900/6235], Loss: 4.6839\n",
      "Epoch [72/100], Step [40000/6235], Loss: 1.6209\n",
      "Epoch [72/100], Step [40100/6235], Loss: 6.5999\n",
      "Epoch [72/100], Step [40200/6235], Loss: 19.1037\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [72/100], Step [40300/6235], Loss: 0.3254\n",
      "Epoch [72/100], Step [40400/6235], Loss: 0.6020\n",
      "Epoch [72/100], Step [40500/6235], Loss: 3.5005\n",
      "Epoch [72/100], Step [40600/6235], Loss: 0.3967\n",
      "Epoch [72/100], Step [40700/6235], Loss: 4.6306\n",
      "Epoch [72/100], Step [40800/6235], Loss: 1.7430\n",
      "Epoch [72/100], Step [40900/6235], Loss: 1.4051\n",
      "Epoch [72/100], Step [41000/6235], Loss: 37.9665\n",
      "Epoch [72/100], Step [41100/6235], Loss: 19.5011\n",
      "Epoch [72/100], Step [41200/6235], Loss: 27.0686\n",
      "Epoch [72/100], Step [41300/6235], Loss: 2.1562\n",
      "Epoch [72/100], Step [41400/6235], Loss: 0.4234\n",
      "Epoch [72/100], Step [41500/6235], Loss: 11.3218\n",
      "Epoch [72/100], Step [41600/6235], Loss: 2.4203\n",
      "Epoch [72/100], Step [41700/6235], Loss: 0.1300\n",
      "Epoch [72/100], Step [41800/6235], Loss: 0.5299\n",
      "Epoch [72/100], Step [41900/6235], Loss: 3.8996\n",
      "Epoch [72/100], Step [42000/6235], Loss: 4.0387\n",
      "Epoch [72/100], Step [42100/6235], Loss: 12.1994\n",
      "Epoch [72/100], Step [42200/6235], Loss: 79.0018\n",
      "Epoch [72/100], Step [42300/6235], Loss: 0.3904\n",
      "Epoch [72/100], Step [42400/6235], Loss: 1.2174\n",
      "Epoch [72/100], Step [42500/6235], Loss: 1.7157\n",
      "Epoch [72/100], Step [42600/6235], Loss: 2.0837\n",
      "Epoch [72/100], Step [42700/6235], Loss: 0.3589\n",
      "Epoch [72/100], Step [42800/6235], Loss: 12.9802\n",
      "Epoch [72/100], Step [42900/6235], Loss: 0.1951\n",
      "Epoch [72/100], Step [43000/6235], Loss: 0.4669\n",
      "Epoch [72/100], Step [43100/6235], Loss: 0.0625\n",
      "Epoch [72/100], Step [43200/6235], Loss: 0.1039\n",
      "Epoch [72/100], Step [43300/6235], Loss: 4.2670\n",
      "Epoch [72/100], Step [43400/6235], Loss: 4.4301\n",
      "Epoch [72/100], Step [43500/6235], Loss: 12.0708\n",
      "Epoch [72/100], Step [43600/6235], Loss: 1.4319\n",
      "Epoch [72/100], Step [43700/6235], Loss: 47.8309\n",
      "Epoch [72/100], Step [43800/6235], Loss: 0.5462\n",
      "Epoch [72/100], Step [43900/6235], Loss: 3.7902\n",
      "Epoch [72/100], Step [44000/6235], Loss: 57.4730\n",
      "Epoch [72/100], Step [44100/6235], Loss: 5.1845\n",
      "Epoch [72/100], Step [44200/6235], Loss: 0.6503\n",
      "Epoch [72/100], Step [44300/6235], Loss: 3.6100\n",
      "Epoch [72/100], Step [44400/6235], Loss: 0.7857\n",
      "Epoch [72/100], Step [44500/6235], Loss: 6.3103\n",
      "Epoch [72/100], Step [44600/6235], Loss: 11.3017\n",
      "Epoch [72/100], Step [44700/6235], Loss: 5.2013\n",
      "Epoch [72/100], Step [44800/6235], Loss: 1.1377\n",
      "Epoch [72/100], Step [44900/6235], Loss: 12.3427\n",
      "Epoch [72/100], Step [45000/6235], Loss: 6.3582\n",
      "Epoch [72/100], Step [45100/6235], Loss: 56.6212\n",
      "Epoch [72/100], Step [45200/6235], Loss: 2.2676\n",
      "Epoch [72/100], Step [45300/6235], Loss: 24.7255\n",
      "Epoch [72/100], Step [45400/6235], Loss: 7.6779\n",
      "Epoch [72/100], Step [45500/6235], Loss: 2.9065\n",
      "Epoch [72/100], Step [45600/6235], Loss: 0.9779\n",
      "Epoch [72/100], Step [45700/6235], Loss: 121.8437\n",
      "Epoch [72/100], Step [45800/6235], Loss: 382.7053\n",
      "Epoch [72/100], Step [45900/6235], Loss: 27.0752\n",
      "Epoch [72/100], Step [46000/6235], Loss: 1.4666\n",
      "Epoch [72/100], Step [46100/6235], Loss: 9.2518\n",
      "Epoch [72/100], Step [46200/6235], Loss: 56.9166\n",
      "Epoch [72/100], Step [46300/6235], Loss: 7.1117\n",
      "Epoch [72/100], Step [46400/6235], Loss: 7.0019\n",
      "Epoch [72/100], Step [46500/6235], Loss: 29.5385\n",
      "Epoch [72/100], Step [46600/6235], Loss: 20.4968\n",
      "Epoch [72/100], Step [46700/6235], Loss: 24.0554\n",
      "Epoch [72/100], Step [46800/6235], Loss: 11.2168\n",
      "Epoch [72/100], Step [46900/6235], Loss: 1.3047\n",
      "Epoch [72/100], Step [47000/6235], Loss: 8.2748\n",
      "Epoch [72/100], Step [47100/6235], Loss: 4.5122\n",
      "Epoch [72/100], Step [47200/6235], Loss: 15.4811\n",
      "Epoch [72/100], Step [47300/6235], Loss: 1.2432\n",
      "Epoch [72/100], Step [47400/6235], Loss: 221.4104\n",
      "Epoch [72/100], Step [47500/6235], Loss: 6.6358\n",
      "Epoch [72/100], Step [47600/6235], Loss: 1.3006\n",
      "Epoch [72/100], Step [47700/6235], Loss: 46.0039\n",
      "Epoch [72/100], Step [47800/6235], Loss: 68.9402\n",
      "Epoch [72/100], Step [47900/6235], Loss: 23.1892\n",
      "Epoch [72/100], Step [48000/6235], Loss: 54.1982\n",
      "Epoch [72/100], Step [48100/6235], Loss: 36.2846\n",
      "Epoch [72/100], Step [48200/6235], Loss: 210.1702\n",
      "Epoch [72/100], Step [48300/6235], Loss: 765.5291\n",
      "Epoch [72/100], Step [48400/6235], Loss: 1.9713\n",
      "Epoch [72/100], Step [48500/6235], Loss: 23.3526\n",
      "Epoch [72/100], Step [48600/6235], Loss: 13.6672\n",
      "Epoch [72/100], Step [48700/6235], Loss: 33.4544\n",
      "Epoch [72/100], Step [48800/6235], Loss: 251.4027\n",
      "Epoch [72/100], Step [48900/6235], Loss: 889.0367\n",
      "Epoch [72/100], Step [49000/6235], Loss: 209.1019\n",
      "Epoch [72/100], Step [49100/6235], Loss: 3035.0544\n",
      "Epoch [72/100], Step [49200/6235], Loss: 150.0702\n",
      "Epoch [72/100], Step [49300/6235], Loss: 983.7440\n",
      "Epoch [72/100], Step [49400/6235], Loss: 157.9446\n",
      "Epoch [72/100], Step [49500/6235], Loss: 5.5306\n",
      "Epoch [72/100], Step [49600/6235], Loss: 170.4801\n",
      "Epoch [72/100], Step [49700/6235], Loss: 161.7724\n",
      "Epoch [72/100], Step [49800/6235], Loss: 517.5224\n",
      "Epoch [73/100], Step [100/6235], Loss: 24.5802\n",
      "Epoch [73/100], Step [200/6235], Loss: 0.1128\n",
      "Epoch [73/100], Step [300/6235], Loss: 0.0117\n",
      "Epoch [73/100], Step [400/6235], Loss: 0.0030\n",
      "Epoch [73/100], Step [500/6235], Loss: 7.2037\n",
      "Epoch [73/100], Step [600/6235], Loss: 0.0388\n",
      "Epoch [73/100], Step [700/6235], Loss: 0.4072\n",
      "Epoch [73/100], Step [800/6235], Loss: 0.1320\n",
      "Epoch [73/100], Step [900/6235], Loss: 0.0287\n",
      "Epoch [73/100], Step [1000/6235], Loss: 0.0292\n",
      "Epoch [73/100], Step [1100/6235], Loss: 0.0748\n",
      "Epoch [73/100], Step [1200/6235], Loss: 0.1649\n",
      "Epoch [73/100], Step [1300/6235], Loss: 0.0401\n",
      "Epoch [73/100], Step [1400/6235], Loss: 0.0434\n",
      "Epoch [73/100], Step [1500/6235], Loss: 0.0041\n",
      "Epoch [73/100], Step [1600/6235], Loss: 0.2197\n",
      "Epoch [73/100], Step [1700/6235], Loss: 0.0047\n",
      "Epoch [73/100], Step [1800/6235], Loss: 0.1894\n",
      "Epoch [73/100], Step [1900/6235], Loss: 0.6058\n",
      "Epoch [73/100], Step [2000/6235], Loss: 2.1838\n",
      "Epoch [73/100], Step [2100/6235], Loss: 1.6115\n",
      "Epoch [73/100], Step [2200/6235], Loss: 9.7385\n",
      "Epoch [73/100], Step [2300/6235], Loss: 14.0082\n",
      "Epoch [73/100], Step [2400/6235], Loss: 5.6111\n",
      "Epoch [73/100], Step [2500/6235], Loss: 35.4850\n",
      "Epoch [73/100], Step [2600/6235], Loss: 10.2988\n",
      "Epoch [73/100], Step [2700/6235], Loss: 16.1114\n",
      "Epoch [73/100], Step [2800/6235], Loss: 324.8694\n",
      "Epoch [73/100], Step [2900/6235], Loss: 9.3636\n",
      "Epoch [73/100], Step [3000/6235], Loss: 0.5330\n",
      "Epoch [73/100], Step [3100/6235], Loss: 71.1855\n",
      "Epoch [73/100], Step [3200/6235], Loss: 86.5325\n",
      "Epoch [73/100], Step [3300/6235], Loss: 5.3442\n",
      "Epoch [73/100], Step [3400/6235], Loss: 2.1218\n",
      "Epoch [73/100], Step [3500/6235], Loss: 28.1118\n",
      "Epoch [73/100], Step [3600/6235], Loss: 10.4411\n",
      "Epoch [73/100], Step [3700/6235], Loss: 0.2906\n",
      "Epoch [73/100], Step [3800/6235], Loss: 0.4753\n",
      "Epoch [73/100], Step [3900/6235], Loss: 1.7637\n",
      "Epoch [73/100], Step [4000/6235], Loss: 0.0249\n",
      "Epoch [73/100], Step [4100/6235], Loss: 5.8417\n",
      "Epoch [73/100], Step [4200/6235], Loss: 0.5408\n",
      "Epoch [73/100], Step [4300/6235], Loss: 9.3806\n",
      "Epoch [73/100], Step [4400/6235], Loss: 4.2447\n",
      "Epoch [73/100], Step [4500/6235], Loss: 44.2661\n",
      "Epoch [73/100], Step [4600/6235], Loss: 3.9743\n",
      "Epoch [73/100], Step [4700/6235], Loss: 0.8569\n",
      "Epoch [73/100], Step [4800/6235], Loss: 7.8714\n",
      "Epoch [73/100], Step [4900/6235], Loss: 0.1077\n",
      "Epoch [73/100], Step [5000/6235], Loss: 0.8876\n",
      "Epoch [73/100], Step [5100/6235], Loss: 4.0552\n",
      "Epoch [73/100], Step [5200/6235], Loss: 1.1939\n",
      "Epoch [73/100], Step [5300/6235], Loss: 38.0488\n",
      "Epoch [73/100], Step [5400/6235], Loss: 1.9452\n",
      "Epoch [73/100], Step [5500/6235], Loss: 1.8997\n",
      "Epoch [73/100], Step [5600/6235], Loss: 0.2934\n",
      "Epoch [73/100], Step [5700/6235], Loss: 0.5953\n",
      "Epoch [73/100], Step [5800/6235], Loss: 3.0114\n",
      "Epoch [73/100], Step [5900/6235], Loss: 0.4259\n",
      "Epoch [73/100], Step [6000/6235], Loss: 2.5020\n",
      "Epoch [73/100], Step [6100/6235], Loss: 0.5497\n",
      "Epoch [73/100], Step [6200/6235], Loss: 1.7857\n",
      "Epoch [73/100], Step [6300/6235], Loss: 4.1108\n",
      "Epoch [73/100], Step [6400/6235], Loss: 0.0389\n",
      "Epoch [73/100], Step [6500/6235], Loss: 1.2389\n",
      "Epoch [73/100], Step [6600/6235], Loss: 5.5130\n",
      "Epoch [73/100], Step [6700/6235], Loss: 2.6976\n",
      "Epoch [73/100], Step [6800/6235], Loss: 1.7995\n",
      "Epoch [73/100], Step [6900/6235], Loss: 1.2743\n",
      "Epoch [73/100], Step [7000/6235], Loss: 0.6968\n",
      "Epoch [73/100], Step [7100/6235], Loss: 0.1006\n",
      "Epoch [73/100], Step [7200/6235], Loss: 0.3849\n",
      "Epoch [73/100], Step [7300/6235], Loss: 0.5865\n",
      "Epoch [73/100], Step [7400/6235], Loss: 0.1059\n",
      "Epoch [73/100], Step [7500/6235], Loss: 0.7597\n",
      "Epoch [73/100], Step [7600/6235], Loss: 2.0883\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Step [7700/6235], Loss: 15.8555\n",
      "Epoch [73/100], Step [7800/6235], Loss: 3.5648\n",
      "Epoch [73/100], Step [7900/6235], Loss: 2.4779\n",
      "Epoch [73/100], Step [8000/6235], Loss: 0.0985\n",
      "Epoch [73/100], Step [8100/6235], Loss: 4.5892\n",
      "Epoch [73/100], Step [8200/6235], Loss: 15.4285\n",
      "Epoch [73/100], Step [8300/6235], Loss: 67.2280\n",
      "Epoch [73/100], Step [8400/6235], Loss: 208.0724\n",
      "Epoch [73/100], Step [8500/6235], Loss: 9.0711\n",
      "Epoch [73/100], Step [8600/6235], Loss: 155.6291\n",
      "Epoch [73/100], Step [8700/6235], Loss: 87.9079\n",
      "Epoch [73/100], Step [8800/6235], Loss: 483.7238\n",
      "Epoch [73/100], Step [8900/6235], Loss: 141.4921\n",
      "Epoch [73/100], Step [9000/6235], Loss: 626.8911\n",
      "Epoch [73/100], Step [9100/6235], Loss: 2257.1370\n",
      "Epoch [73/100], Step [9200/6235], Loss: 3987.8679\n",
      "Epoch [73/100], Step [9300/6235], Loss: 43.3495\n",
      "Epoch [73/100], Step [9400/6235], Loss: 129.0046\n",
      "Epoch [73/100], Step [9500/6235], Loss: 2840.6248\n",
      "Epoch [73/100], Step [9600/6235], Loss: 1205.8781\n",
      "Epoch [73/100], Step [9700/6235], Loss: 0.9285\n",
      "Epoch [73/100], Step [9800/6235], Loss: 189.2981\n",
      "Epoch [73/100], Step [9900/6235], Loss: 70.1483\n",
      "Epoch [73/100], Step [10000/6235], Loss: 193.4982\n",
      "Epoch [73/100], Step [10100/6235], Loss: 0.8643\n",
      "Epoch [73/100], Step [10200/6235], Loss: 1295.9725\n",
      "Epoch [73/100], Step [10300/6235], Loss: 62.9927\n",
      "Epoch [73/100], Step [10400/6235], Loss: 12.7364\n",
      "Epoch [73/100], Step [10500/6235], Loss: 13.5050\n",
      "Epoch [73/100], Step [10600/6235], Loss: 110.1324\n",
      "Epoch [73/100], Step [10700/6235], Loss: 21.2296\n",
      "Epoch [73/100], Step [10800/6235], Loss: 111.7901\n",
      "Epoch [73/100], Step [10900/6235], Loss: 112.0721\n",
      "Epoch [73/100], Step [11000/6235], Loss: 288.0068\n",
      "Epoch [73/100], Step [11100/6235], Loss: 20.8331\n",
      "Epoch [73/100], Step [11200/6235], Loss: 1.9801\n",
      "Epoch [73/100], Step [11300/6235], Loss: 96.0414\n",
      "Epoch [73/100], Step [11400/6235], Loss: 64.9624\n",
      "Epoch [73/100], Step [11500/6235], Loss: 12.7836\n",
      "Epoch [73/100], Step [11600/6235], Loss: 9.8675\n",
      "Epoch [73/100], Step [11700/6235], Loss: 60.2574\n",
      "Epoch [73/100], Step [11800/6235], Loss: 391.3008\n",
      "Epoch [73/100], Step [11900/6235], Loss: 241.7717\n",
      "Epoch [73/100], Step [12000/6235], Loss: 496.9527\n",
      "Epoch [73/100], Step [12100/6235], Loss: 189.3047\n",
      "Epoch [73/100], Step [12200/6235], Loss: 88.1342\n",
      "Epoch [73/100], Step [12300/6235], Loss: 13.1353\n",
      "Epoch [73/100], Step [12400/6235], Loss: 154.7958\n",
      "Epoch [73/100], Step [12500/6235], Loss: 23.1430\n",
      "Epoch [73/100], Step [12600/6235], Loss: 49.2623\n",
      "Epoch [73/100], Step [12700/6235], Loss: 5.5997\n",
      "Epoch [73/100], Step [12800/6235], Loss: 4.5416\n",
      "Epoch [73/100], Step [12900/6235], Loss: 44.9703\n",
      "Epoch [73/100], Step [13000/6235], Loss: 0.8371\n",
      "Epoch [73/100], Step [13100/6235], Loss: 69.0224\n",
      "Epoch [73/100], Step [13200/6235], Loss: 11.2673\n",
      "Epoch [73/100], Step [13300/6235], Loss: 44.0099\n",
      "Epoch [73/100], Step [13400/6235], Loss: 250.5395\n",
      "Epoch [73/100], Step [13500/6235], Loss: 13.7183\n",
      "Epoch [73/100], Step [13600/6235], Loss: 29.8928\n",
      "Epoch [73/100], Step [13700/6235], Loss: 23.4812\n",
      "Epoch [73/100], Step [13800/6235], Loss: 146.5109\n",
      "Epoch [73/100], Step [13900/6235], Loss: 57.2212\n",
      "Epoch [73/100], Step [14000/6235], Loss: 9.5623\n",
      "Epoch [73/100], Step [14100/6235], Loss: 21.0979\n",
      "Epoch [73/100], Step [14200/6235], Loss: 123.1431\n",
      "Epoch [73/100], Step [14300/6235], Loss: 62.9824\n",
      "Epoch [73/100], Step [14400/6235], Loss: 38.9646\n",
      "Epoch [73/100], Step [14500/6235], Loss: 44.3710\n",
      "Epoch [73/100], Step [14600/6235], Loss: 0.1442\n",
      "Epoch [73/100], Step [14700/6235], Loss: 42.5307\n",
      "Epoch [73/100], Step [14800/6235], Loss: 33.7250\n",
      "Epoch [73/100], Step [14900/6235], Loss: 0.8920\n",
      "Epoch [73/100], Step [15000/6235], Loss: 1.8080\n",
      "Epoch [73/100], Step [15100/6235], Loss: 0.4936\n",
      "Epoch [73/100], Step [15200/6235], Loss: 1.6780\n",
      "Epoch [73/100], Step [15300/6235], Loss: 38.8719\n",
      "Epoch [73/100], Step [15400/6235], Loss: 74.8028\n",
      "Epoch [73/100], Step [15500/6235], Loss: 13.0585\n",
      "Epoch [73/100], Step [15600/6235], Loss: 168.8072\n",
      "Epoch [73/100], Step [15700/6235], Loss: 9.2988\n",
      "Epoch [73/100], Step [15800/6235], Loss: 5.9537\n",
      "Epoch [73/100], Step [15900/6235], Loss: 0.5295\n",
      "Epoch [73/100], Step [16000/6235], Loss: 137.8894\n",
      "Epoch [73/100], Step [16100/6235], Loss: 11.3267\n",
      "Epoch [73/100], Step [16200/6235], Loss: 0.9280\n",
      "Epoch [73/100], Step [16300/6235], Loss: 9.3914\n",
      "Epoch [73/100], Step [16400/6235], Loss: 26.8689\n",
      "Epoch [73/100], Step [16500/6235], Loss: 644.7532\n",
      "Epoch [73/100], Step [16600/6235], Loss: 23.7848\n",
      "Epoch [73/100], Step [16700/6235], Loss: 0.7401\n",
      "Epoch [73/100], Step [16800/6235], Loss: 10.0587\n",
      "Epoch [73/100], Step [16900/6235], Loss: 0.2251\n",
      "Epoch [73/100], Step [17000/6235], Loss: 0.2537\n",
      "Epoch [73/100], Step [17100/6235], Loss: 0.2736\n",
      "Epoch [73/100], Step [17200/6235], Loss: 282.9578\n",
      "Epoch [73/100], Step [17300/6235], Loss: 3.1582\n",
      "Epoch [73/100], Step [17400/6235], Loss: 31.3174\n",
      "Epoch [73/100], Step [17500/6235], Loss: 0.8824\n",
      "Epoch [73/100], Step [17600/6235], Loss: 3.1866\n",
      "Epoch [73/100], Step [17700/6235], Loss: 35.2987\n",
      "Epoch [73/100], Step [17800/6235], Loss: 35.2537\n",
      "Epoch [73/100], Step [17900/6235], Loss: 10.6089\n",
      "Epoch [73/100], Step [18000/6235], Loss: 13.5978\n",
      "Epoch [73/100], Step [18100/6235], Loss: 16.7158\n",
      "Epoch [73/100], Step [18200/6235], Loss: 0.6443\n",
      "Epoch [73/100], Step [18300/6235], Loss: 3.5684\n",
      "Epoch [73/100], Step [18400/6235], Loss: 3.4127\n",
      "Epoch [73/100], Step [18500/6235], Loss: 28.1452\n",
      "Epoch [73/100], Step [18600/6235], Loss: 2.1137\n",
      "Epoch [73/100], Step [18700/6235], Loss: 0.4587\n",
      "Epoch [73/100], Step [18800/6235], Loss: 42.4042\n",
      "Epoch [73/100], Step [18900/6235], Loss: 53.2787\n",
      "Epoch [73/100], Step [19000/6235], Loss: 8.5127\n",
      "Epoch [73/100], Step [19100/6235], Loss: 1.4717\n",
      "Epoch [73/100], Step [19200/6235], Loss: 1.4267\n",
      "Epoch [73/100], Step [19300/6235], Loss: 7.2996\n",
      "Epoch [73/100], Step [19400/6235], Loss: 90.3819\n",
      "Epoch [73/100], Step [19500/6235], Loss: 103.0520\n",
      "Epoch [73/100], Step [19600/6235], Loss: 96.1078\n",
      "Epoch [73/100], Step [19700/6235], Loss: 4.6059\n",
      "Epoch [73/100], Step [19800/6235], Loss: 2.1749\n",
      "Epoch [73/100], Step [19900/6235], Loss: 0.3425\n",
      "Epoch [73/100], Step [20000/6235], Loss: 73.0411\n",
      "Epoch [73/100], Step [20100/6235], Loss: 0.0545\n",
      "Epoch [73/100], Step [20200/6235], Loss: 5.8023\n",
      "Epoch [73/100], Step [20300/6235], Loss: 2.4821\n",
      "Epoch [73/100], Step [20400/6235], Loss: 20.4729\n",
      "Epoch [73/100], Step [20500/6235], Loss: 40.3249\n",
      "Epoch [73/100], Step [20600/6235], Loss: 31.5783\n",
      "Epoch [73/100], Step [20700/6235], Loss: 7.6451\n",
      "Epoch [73/100], Step [20800/6235], Loss: 10.7650\n",
      "Epoch [73/100], Step [20900/6235], Loss: 26.5671\n",
      "Epoch [73/100], Step [21000/6235], Loss: 15.3975\n",
      "Epoch [73/100], Step [21100/6235], Loss: 4.8928\n",
      "Epoch [73/100], Step [21200/6235], Loss: 0.1595\n",
      "Epoch [73/100], Step [21300/6235], Loss: 0.1655\n",
      "Epoch [73/100], Step [21400/6235], Loss: 6.3959\n",
      "Epoch [73/100], Step [21500/6235], Loss: 0.9864\n",
      "Epoch [73/100], Step [21600/6235], Loss: 30.0582\n",
      "Epoch [73/100], Step [21700/6235], Loss: 0.1886\n",
      "Epoch [73/100], Step [21800/6235], Loss: 19.5331\n",
      "Epoch [73/100], Step [21900/6235], Loss: 0.5155\n",
      "Epoch [73/100], Step [22000/6235], Loss: 4.2409\n",
      "Epoch [73/100], Step [22100/6235], Loss: 2.8123\n",
      "Epoch [73/100], Step [22200/6235], Loss: 4.9535\n",
      "Epoch [73/100], Step [22300/6235], Loss: 15.8654\n",
      "Epoch [73/100], Step [22400/6235], Loss: 5.5063\n",
      "Epoch [73/100], Step [22500/6235], Loss: 95.9860\n",
      "Epoch [73/100], Step [22600/6235], Loss: 11.1638\n",
      "Epoch [73/100], Step [22700/6235], Loss: 0.3244\n",
      "Epoch [73/100], Step [22800/6235], Loss: 4.1540\n",
      "Epoch [73/100], Step [22900/6235], Loss: 4.8925\n",
      "Epoch [73/100], Step [23000/6235], Loss: 9.6418\n",
      "Epoch [73/100], Step [23100/6235], Loss: 7.9661\n",
      "Epoch [73/100], Step [23200/6235], Loss: 9.8796\n",
      "Epoch [73/100], Step [23300/6235], Loss: 19.3840\n",
      "Epoch [73/100], Step [23400/6235], Loss: 1.4390\n",
      "Epoch [73/100], Step [23500/6235], Loss: 0.1478\n",
      "Epoch [73/100], Step [23600/6235], Loss: 114.2075\n",
      "Epoch [73/100], Step [23700/6235], Loss: 8.6651\n",
      "Epoch [73/100], Step [23800/6235], Loss: 1.0971\n",
      "Epoch [73/100], Step [23900/6235], Loss: 6.5513\n",
      "Epoch [73/100], Step [24000/6235], Loss: 0.4022\n",
      "Epoch [73/100], Step [24100/6235], Loss: 1.5718\n",
      "Epoch [73/100], Step [24200/6235], Loss: 50.3959\n",
      "Epoch [73/100], Step [24300/6235], Loss: 1.1522\n",
      "Epoch [73/100], Step [24400/6235], Loss: 4.4120\n",
      "Epoch [73/100], Step [24500/6235], Loss: 2.3000\n",
      "Epoch [73/100], Step [24600/6235], Loss: 0.1024\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Step [24700/6235], Loss: 3.5292\n",
      "Epoch [73/100], Step [24800/6235], Loss: 0.1085\n",
      "Epoch [73/100], Step [24900/6235], Loss: 15.9610\n",
      "Epoch [73/100], Step [25000/6235], Loss: 19.6448\n",
      "Epoch [73/100], Step [25100/6235], Loss: 8.3416\n",
      "Epoch [73/100], Step [25200/6235], Loss: 1.5747\n",
      "Epoch [73/100], Step [25300/6235], Loss: 0.6154\n",
      "Epoch [73/100], Step [25400/6235], Loss: 8.5859\n",
      "Epoch [73/100], Step [25500/6235], Loss: 6.4973\n",
      "Epoch [73/100], Step [25600/6235], Loss: 2.8442\n",
      "Epoch [73/100], Step [25700/6235], Loss: 0.3749\n",
      "Epoch [73/100], Step [25800/6235], Loss: 0.1464\n",
      "Epoch [73/100], Step [25900/6235], Loss: 9.3440\n",
      "Epoch [73/100], Step [26000/6235], Loss: 0.2222\n",
      "Epoch [73/100], Step [26100/6235], Loss: 0.0654\n",
      "Epoch [73/100], Step [26200/6235], Loss: 0.3515\n",
      "Epoch [73/100], Step [26300/6235], Loss: 4.8820\n",
      "Epoch [73/100], Step [26400/6235], Loss: 0.1607\n",
      "Epoch [73/100], Step [26500/6235], Loss: 0.1651\n",
      "Epoch [73/100], Step [26600/6235], Loss: 2.8507\n",
      "Epoch [73/100], Step [26700/6235], Loss: 0.5910\n",
      "Epoch [73/100], Step [26800/6235], Loss: 0.6130\n",
      "Epoch [73/100], Step [26900/6235], Loss: 0.0259\n",
      "Epoch [73/100], Step [27000/6235], Loss: 13.3038\n",
      "Epoch [73/100], Step [27100/6235], Loss: 0.0958\n",
      "Epoch [73/100], Step [27200/6235], Loss: 0.0459\n",
      "Epoch [73/100], Step [27300/6235], Loss: 0.2248\n",
      "Epoch [73/100], Step [27400/6235], Loss: 0.8724\n",
      "Epoch [73/100], Step [27500/6235], Loss: 18.4982\n",
      "Epoch [73/100], Step [27600/6235], Loss: 0.7698\n",
      "Epoch [73/100], Step [27700/6235], Loss: 1.4538\n",
      "Epoch [73/100], Step [27800/6235], Loss: 3.7576\n",
      "Epoch [73/100], Step [27900/6235], Loss: 1.2645\n",
      "Epoch [73/100], Step [28000/6235], Loss: 138.3621\n",
      "Epoch [73/100], Step [28100/6235], Loss: 7.6624\n",
      "Epoch [73/100], Step [28200/6235], Loss: 24.4388\n",
      "Epoch [73/100], Step [28300/6235], Loss: 3.5161\n",
      "Epoch [73/100], Step [28400/6235], Loss: 24.6222\n",
      "Epoch [73/100], Step [28500/6235], Loss: 4.3459\n",
      "Epoch [73/100], Step [28600/6235], Loss: 0.3556\n",
      "Epoch [73/100], Step [28700/6235], Loss: 4.8981\n",
      "Epoch [73/100], Step [28800/6235], Loss: 0.4420\n",
      "Epoch [73/100], Step [28900/6235], Loss: 70.1343\n",
      "Epoch [73/100], Step [29000/6235], Loss: 9.1166\n",
      "Epoch [73/100], Step [29100/6235], Loss: 0.0381\n",
      "Epoch [73/100], Step [29200/6235], Loss: 0.3115\n",
      "Epoch [73/100], Step [29300/6235], Loss: 14.8496\n",
      "Epoch [73/100], Step [29400/6235], Loss: 0.1742\n",
      "Epoch [73/100], Step [29500/6235], Loss: 1.5321\n",
      "Epoch [73/100], Step [29600/6235], Loss: 0.5749\n",
      "Epoch [73/100], Step [29700/6235], Loss: 0.9039\n",
      "Epoch [73/100], Step [29800/6235], Loss: 1.7120\n",
      "Epoch [73/100], Step [29900/6235], Loss: 0.4151\n",
      "Epoch [73/100], Step [30000/6235], Loss: 8.0811\n",
      "Epoch [73/100], Step [30100/6235], Loss: 11.5360\n",
      "Epoch [73/100], Step [30200/6235], Loss: 0.4625\n",
      "Epoch [73/100], Step [30300/6235], Loss: 0.3562\n",
      "Epoch [73/100], Step [30400/6235], Loss: 0.5046\n",
      "Epoch [73/100], Step [30500/6235], Loss: 2.3185\n",
      "Epoch [73/100], Step [30600/6235], Loss: 0.9364\n",
      "Epoch [73/100], Step [30700/6235], Loss: 0.0154\n",
      "Epoch [73/100], Step [30800/6235], Loss: 0.3103\n",
      "Epoch [73/100], Step [30900/6235], Loss: 3.2351\n",
      "Epoch [73/100], Step [31000/6235], Loss: 0.0133\n",
      "Epoch [73/100], Step [31100/6235], Loss: 0.0904\n",
      "Epoch [73/100], Step [31200/6235], Loss: 5.4612\n",
      "Epoch [73/100], Step [31300/6235], Loss: 2.3778\n",
      "Epoch [73/100], Step [31400/6235], Loss: 0.0576\n",
      "Epoch [73/100], Step [31500/6235], Loss: 0.6459\n",
      "Epoch [73/100], Step [31600/6235], Loss: 2.8527\n",
      "Epoch [73/100], Step [31700/6235], Loss: 8.5853\n",
      "Epoch [73/100], Step [31800/6235], Loss: 3.2557\n",
      "Epoch [73/100], Step [31900/6235], Loss: 442.6669\n",
      "Epoch [73/100], Step [32000/6235], Loss: 4.8620\n",
      "Epoch [73/100], Step [32100/6235], Loss: 0.1032\n",
      "Epoch [73/100], Step [32200/6235], Loss: 41.1062\n",
      "Epoch [73/100], Step [32300/6235], Loss: 1.9779\n",
      "Epoch [73/100], Step [32400/6235], Loss: 1.3571\n",
      "Epoch [73/100], Step [32500/6235], Loss: 17.7434\n",
      "Epoch [73/100], Step [32600/6235], Loss: 0.5944\n",
      "Epoch [73/100], Step [32700/6235], Loss: 77.7910\n",
      "Epoch [73/100], Step [32800/6235], Loss: 1.6191\n",
      "Epoch [73/100], Step [32900/6235], Loss: 4.1331\n",
      "Epoch [73/100], Step [33000/6235], Loss: 0.6029\n",
      "Epoch [73/100], Step [33100/6235], Loss: 0.8387\n",
      "Epoch [73/100], Step [33200/6235], Loss: 1.1851\n",
      "Epoch [73/100], Step [33300/6235], Loss: 0.0409\n",
      "Epoch [73/100], Step [33400/6235], Loss: 167.7671\n",
      "Epoch [73/100], Step [33500/6235], Loss: 0.7146\n",
      "Epoch [73/100], Step [33600/6235], Loss: 4.8215\n",
      "Epoch [73/100], Step [33700/6235], Loss: 0.4640\n",
      "Epoch [73/100], Step [33800/6235], Loss: 2.5637\n",
      "Epoch [73/100], Step [33900/6235], Loss: 23.7152\n",
      "Epoch [73/100], Step [34000/6235], Loss: 0.0155\n",
      "Epoch [73/100], Step [34100/6235], Loss: 0.2322\n",
      "Epoch [73/100], Step [34200/6235], Loss: 2.1667\n",
      "Epoch [73/100], Step [34300/6235], Loss: 6.0161\n",
      "Epoch [73/100], Step [34400/6235], Loss: 0.1829\n",
      "Epoch [73/100], Step [34500/6235], Loss: 46.8317\n",
      "Epoch [73/100], Step [34600/6235], Loss: 0.7267\n",
      "Epoch [73/100], Step [34700/6235], Loss: 14.1930\n",
      "Epoch [73/100], Step [34800/6235], Loss: 12.8372\n",
      "Epoch [73/100], Step [34900/6235], Loss: 43.7978\n",
      "Epoch [73/100], Step [35000/6235], Loss: 1.7664\n",
      "Epoch [73/100], Step [35100/6235], Loss: 1.9103\n",
      "Epoch [73/100], Step [35200/6235], Loss: 0.6279\n",
      "Epoch [73/100], Step [35300/6235], Loss: 1.6591\n",
      "Epoch [73/100], Step [35400/6235], Loss: 0.5360\n",
      "Epoch [73/100], Step [35500/6235], Loss: 2.5666\n",
      "Epoch [73/100], Step [35600/6235], Loss: 1.5819\n",
      "Epoch [73/100], Step [35700/6235], Loss: 5.9528\n",
      "Epoch [73/100], Step [35800/6235], Loss: 0.1398\n",
      "Epoch [73/100], Step [35900/6235], Loss: 1.3887\n",
      "Epoch [73/100], Step [36000/6235], Loss: 0.3271\n",
      "Epoch [73/100], Step [36100/6235], Loss: 0.0236\n",
      "Epoch [73/100], Step [36200/6235], Loss: 17.0436\n",
      "Epoch [73/100], Step [36300/6235], Loss: 0.0651\n",
      "Epoch [73/100], Step [36400/6235], Loss: 2.0782\n",
      "Epoch [73/100], Step [36500/6235], Loss: 9.3133\n",
      "Epoch [73/100], Step [36600/6235], Loss: 0.1262\n",
      "Epoch [73/100], Step [36700/6235], Loss: 0.2518\n",
      "Epoch [73/100], Step [36800/6235], Loss: 15.8604\n",
      "Epoch [73/100], Step [36900/6235], Loss: 8.3740\n",
      "Epoch [73/100], Step [37000/6235], Loss: 0.2643\n",
      "Epoch [73/100], Step [37100/6235], Loss: 0.8906\n",
      "Epoch [73/100], Step [37200/6235], Loss: 0.0788\n",
      "Epoch [73/100], Step [37300/6235], Loss: 0.0745\n",
      "Epoch [73/100], Step [37400/6235], Loss: 0.2056\n",
      "Epoch [73/100], Step [37500/6235], Loss: 3.9654\n",
      "Epoch [73/100], Step [37600/6235], Loss: 11.4499\n",
      "Epoch [73/100], Step [37700/6235], Loss: 1.2734\n",
      "Epoch [73/100], Step [37800/6235], Loss: 5.8319\n",
      "Epoch [73/100], Step [37900/6235], Loss: 7.7270\n",
      "Epoch [73/100], Step [38000/6235], Loss: 0.4728\n",
      "Epoch [73/100], Step [38100/6235], Loss: 4.4232\n",
      "Epoch [73/100], Step [38200/6235], Loss: 1.2163\n",
      "Epoch [73/100], Step [38300/6235], Loss: 0.8362\n",
      "Epoch [73/100], Step [38400/6235], Loss: 0.1313\n",
      "Epoch [73/100], Step [38500/6235], Loss: 2.7410\n",
      "Epoch [73/100], Step [38600/6235], Loss: 0.0842\n",
      "Epoch [73/100], Step [38700/6235], Loss: 0.0895\n",
      "Epoch [73/100], Step [38800/6235], Loss: 0.2604\n",
      "Epoch [73/100], Step [38900/6235], Loss: 3.4191\n",
      "Epoch [73/100], Step [39000/6235], Loss: 2.0703\n",
      "Epoch [73/100], Step [39100/6235], Loss: 10.6370\n",
      "Epoch [73/100], Step [39200/6235], Loss: 0.1744\n",
      "Epoch [73/100], Step [39300/6235], Loss: 7.7694\n",
      "Epoch [73/100], Step [39400/6235], Loss: 68.4797\n",
      "Epoch [73/100], Step [39500/6235], Loss: 58.8412\n",
      "Epoch [73/100], Step [39600/6235], Loss: 6.1400\n",
      "Epoch [73/100], Step [39700/6235], Loss: 32.8932\n",
      "Epoch [73/100], Step [39800/6235], Loss: 200.6528\n",
      "Epoch [73/100], Step [39900/6235], Loss: 13.0337\n",
      "Epoch [73/100], Step [40000/6235], Loss: 1.3345\n",
      "Epoch [73/100], Step [40100/6235], Loss: 8.4767\n",
      "Epoch [73/100], Step [40200/6235], Loss: 13.2757\n",
      "Epoch [73/100], Step [40300/6235], Loss: 0.9213\n",
      "Epoch [73/100], Step [40400/6235], Loss: 0.4000\n",
      "Epoch [73/100], Step [40500/6235], Loss: 3.0991\n",
      "Epoch [73/100], Step [40600/6235], Loss: 0.3760\n",
      "Epoch [73/100], Step [40700/6235], Loss: 5.6779\n",
      "Epoch [73/100], Step [40800/6235], Loss: 1.0615\n",
      "Epoch [73/100], Step [40900/6235], Loss: 1.3202\n",
      "Epoch [73/100], Step [41000/6235], Loss: 39.8592\n",
      "Epoch [73/100], Step [41100/6235], Loss: 51.2729\n",
      "Epoch [73/100], Step [41200/6235], Loss: 19.1457\n",
      "Epoch [73/100], Step [41300/6235], Loss: 1.7087\n",
      "Epoch [73/100], Step [41400/6235], Loss: 0.4320\n",
      "Epoch [73/100], Step [41500/6235], Loss: 32.9323\n",
      "Epoch [73/100], Step [41600/6235], Loss: 4.5111\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [73/100], Step [41700/6235], Loss: 0.0860\n",
      "Epoch [73/100], Step [41800/6235], Loss: 0.3709\n",
      "Epoch [73/100], Step [41900/6235], Loss: 3.4113\n",
      "Epoch [73/100], Step [42000/6235], Loss: 3.3878\n",
      "Epoch [73/100], Step [42100/6235], Loss: 12.1591\n",
      "Epoch [73/100], Step [42200/6235], Loss: 65.4389\n",
      "Epoch [73/100], Step [42300/6235], Loss: 0.0920\n",
      "Epoch [73/100], Step [42400/6235], Loss: 2.1289\n",
      "Epoch [73/100], Step [42500/6235], Loss: 1.1612\n",
      "Epoch [73/100], Step [42600/6235], Loss: 0.9063\n",
      "Epoch [73/100], Step [42700/6235], Loss: 0.5419\n",
      "Epoch [73/100], Step [42800/6235], Loss: 15.0721\n",
      "Epoch [73/100], Step [42900/6235], Loss: 0.1117\n",
      "Epoch [73/100], Step [43000/6235], Loss: 0.6022\n",
      "Epoch [73/100], Step [43100/6235], Loss: 0.0770\n",
      "Epoch [73/100], Step [43200/6235], Loss: 0.0278\n",
      "Epoch [73/100], Step [43300/6235], Loss: 3.8237\n",
      "Epoch [73/100], Step [43400/6235], Loss: 4.3991\n",
      "Epoch [73/100], Step [43500/6235], Loss: 12.3682\n",
      "Epoch [73/100], Step [43600/6235], Loss: 1.0159\n",
      "Epoch [73/100], Step [43700/6235], Loss: 45.4546\n",
      "Epoch [73/100], Step [43800/6235], Loss: 0.2348\n",
      "Epoch [73/100], Step [43900/6235], Loss: 2.0371\n",
      "Epoch [73/100], Step [44000/6235], Loss: 64.9942\n",
      "Epoch [73/100], Step [44100/6235], Loss: 1.2771\n",
      "Epoch [73/100], Step [44200/6235], Loss: 1.7268\n",
      "Epoch [73/100], Step [44300/6235], Loss: 3.0204\n",
      "Epoch [73/100], Step [44400/6235], Loss: 0.8392\n",
      "Epoch [73/100], Step [44500/6235], Loss: 1.7033\n",
      "Epoch [73/100], Step [44600/6235], Loss: 14.8711\n",
      "Epoch [73/100], Step [44700/6235], Loss: 19.0402\n",
      "Epoch [73/100], Step [44800/6235], Loss: 3.1534\n",
      "Epoch [73/100], Step [44900/6235], Loss: 12.2840\n",
      "Epoch [73/100], Step [45000/6235], Loss: 6.5001\n",
      "Epoch [73/100], Step [45100/6235], Loss: 70.3055\n",
      "Epoch [73/100], Step [45200/6235], Loss: 4.0358\n",
      "Epoch [73/100], Step [45300/6235], Loss: 24.6236\n",
      "Epoch [73/100], Step [45400/6235], Loss: 7.3915\n",
      "Epoch [73/100], Step [45500/6235], Loss: 2.2791\n",
      "Epoch [73/100], Step [45600/6235], Loss: 0.6697\n",
      "Epoch [73/100], Step [45700/6235], Loss: 91.1024\n",
      "Epoch [73/100], Step [45800/6235], Loss: 305.0237\n",
      "Epoch [73/100], Step [45900/6235], Loss: 28.6919\n",
      "Epoch [73/100], Step [46000/6235], Loss: 1.4861\n",
      "Epoch [73/100], Step [46100/6235], Loss: 11.7227\n",
      "Epoch [73/100], Step [46200/6235], Loss: 31.1826\n",
      "Epoch [73/100], Step [46300/6235], Loss: 16.4524\n",
      "Epoch [73/100], Step [46400/6235], Loss: 12.9649\n",
      "Epoch [73/100], Step [46500/6235], Loss: 24.8343\n",
      "Epoch [73/100], Step [46600/6235], Loss: 15.5319\n",
      "Epoch [73/100], Step [46700/6235], Loss: 16.9554\n",
      "Epoch [73/100], Step [46800/6235], Loss: 12.8419\n",
      "Epoch [73/100], Step [46900/6235], Loss: 6.5736\n",
      "Epoch [73/100], Step [47000/6235], Loss: 4.7864\n",
      "Epoch [73/100], Step [47100/6235], Loss: 7.6759\n",
      "Epoch [73/100], Step [47200/6235], Loss: 57.0127\n",
      "Epoch [73/100], Step [47300/6235], Loss: 0.9833\n",
      "Epoch [73/100], Step [47400/6235], Loss: 106.5343\n",
      "Epoch [73/100], Step [47500/6235], Loss: 24.5965\n",
      "Epoch [73/100], Step [47600/6235], Loss: 3.6437\n",
      "Epoch [73/100], Step [47700/6235], Loss: 6.8540\n",
      "Epoch [73/100], Step [47800/6235], Loss: 6.4510\n",
      "Epoch [73/100], Step [47900/6235], Loss: 17.1311\n",
      "Epoch [73/100], Step [48000/6235], Loss: 3.8981\n",
      "Epoch [73/100], Step [48100/6235], Loss: 3.9505\n",
      "Epoch [73/100], Step [48200/6235], Loss: 9.7617\n",
      "Epoch [73/100], Step [48300/6235], Loss: 339.2607\n",
      "Epoch [73/100], Step [48400/6235], Loss: 23.9009\n",
      "Epoch [73/100], Step [48500/6235], Loss: 16.9023\n",
      "Epoch [73/100], Step [48600/6235], Loss: 165.4941\n",
      "Epoch [73/100], Step [48700/6235], Loss: 20.0872\n",
      "Epoch [73/100], Step [48800/6235], Loss: 172.2851\n",
      "Epoch [73/100], Step [48900/6235], Loss: 73.3585\n",
      "Epoch [73/100], Step [49000/6235], Loss: 287.3498\n",
      "Epoch [73/100], Step [49100/6235], Loss: 2590.7825\n",
      "Epoch [73/100], Step [49200/6235], Loss: 606.4042\n",
      "Epoch [73/100], Step [49300/6235], Loss: 1140.3518\n",
      "Epoch [73/100], Step [49400/6235], Loss: 89.5219\n",
      "Epoch [73/100], Step [49500/6235], Loss: 9.3499\n",
      "Epoch [73/100], Step [49600/6235], Loss: 111.2038\n",
      "Epoch [73/100], Step [49700/6235], Loss: 897.8173\n",
      "Epoch [73/100], Step [49800/6235], Loss: 2593.6731\n",
      "Epoch [74/100], Step [100/6235], Loss: 7.0576\n",
      "Epoch [74/100], Step [200/6235], Loss: 0.1159\n",
      "Epoch [74/100], Step [300/6235], Loss: 0.0022\n",
      "Epoch [74/100], Step [400/6235], Loss: 0.0016\n",
      "Epoch [74/100], Step [500/6235], Loss: 0.2014\n",
      "Epoch [74/100], Step [600/6235], Loss: 0.0276\n",
      "Epoch [74/100], Step [700/6235], Loss: 0.4598\n",
      "Epoch [74/100], Step [800/6235], Loss: 0.1417\n",
      "Epoch [74/100], Step [900/6235], Loss: 0.0258\n",
      "Epoch [74/100], Step [1000/6235], Loss: 0.0313\n",
      "Epoch [74/100], Step [1100/6235], Loss: 0.0153\n",
      "Epoch [74/100], Step [1200/6235], Loss: 0.1716\n",
      "Epoch [74/100], Step [1300/6235], Loss: 0.0378\n",
      "Epoch [74/100], Step [1400/6235], Loss: 0.0658\n",
      "Epoch [74/100], Step [1500/6235], Loss: 0.0049\n",
      "Epoch [74/100], Step [1600/6235], Loss: 0.2239\n",
      "Epoch [74/100], Step [1700/6235], Loss: 0.0270\n",
      "Epoch [74/100], Step [1800/6235], Loss: 0.2055\n",
      "Epoch [74/100], Step [1900/6235], Loss: 0.5193\n",
      "Epoch [74/100], Step [2000/6235], Loss: 2.2681\n",
      "Epoch [74/100], Step [2100/6235], Loss: 2.8684\n",
      "Epoch [74/100], Step [2200/6235], Loss: 9.0680\n",
      "Epoch [74/100], Step [2300/6235], Loss: 10.0468\n",
      "Epoch [74/100], Step [2400/6235], Loss: 4.2356\n",
      "Epoch [74/100], Step [2500/6235], Loss: 39.1510\n",
      "Epoch [74/100], Step [2600/6235], Loss: 11.2279\n",
      "Epoch [74/100], Step [2700/6235], Loss: 15.1595\n",
      "Epoch [74/100], Step [2800/6235], Loss: 101.7540\n",
      "Epoch [74/100], Step [2900/6235], Loss: 6.7897\n",
      "Epoch [74/100], Step [3000/6235], Loss: 0.4669\n",
      "Epoch [74/100], Step [3100/6235], Loss: 68.9964\n",
      "Epoch [74/100], Step [3200/6235], Loss: 87.1740\n",
      "Epoch [74/100], Step [3300/6235], Loss: 2.1146\n",
      "Epoch [74/100], Step [3400/6235], Loss: 2.5255\n",
      "Epoch [74/100], Step [3500/6235], Loss: 29.3472\n",
      "Epoch [74/100], Step [3600/6235], Loss: 10.2078\n",
      "Epoch [74/100], Step [3700/6235], Loss: 0.7287\n",
      "Epoch [74/100], Step [3800/6235], Loss: 0.6120\n",
      "Epoch [74/100], Step [3900/6235], Loss: 1.7712\n",
      "Epoch [74/100], Step [4000/6235], Loss: 0.0473\n",
      "Epoch [74/100], Step [4100/6235], Loss: 4.9273\n",
      "Epoch [74/100], Step [4200/6235], Loss: 0.2576\n",
      "Epoch [74/100], Step [4300/6235], Loss: 10.1742\n",
      "Epoch [74/100], Step [4400/6235], Loss: 4.7874\n",
      "Epoch [74/100], Step [4500/6235], Loss: 63.2577\n",
      "Epoch [74/100], Step [4600/6235], Loss: 8.9793\n",
      "Epoch [74/100], Step [4700/6235], Loss: 1.4495\n",
      "Epoch [74/100], Step [4800/6235], Loss: 3.0370\n",
      "Epoch [74/100], Step [4900/6235], Loss: 0.0888\n",
      "Epoch [74/100], Step [5000/6235], Loss: 0.1876\n",
      "Epoch [74/100], Step [5100/6235], Loss: 2.8419\n",
      "Epoch [74/100], Step [5200/6235], Loss: 1.1677\n",
      "Epoch [74/100], Step [5300/6235], Loss: 32.5408\n",
      "Epoch [74/100], Step [5400/6235], Loss: 0.0870\n",
      "Epoch [74/100], Step [5500/6235], Loss: 0.8918\n",
      "Epoch [74/100], Step [5600/6235], Loss: 0.6356\n",
      "Epoch [74/100], Step [5700/6235], Loss: 1.9165\n",
      "Epoch [74/100], Step [5800/6235], Loss: 1.3090\n",
      "Epoch [74/100], Step [5900/6235], Loss: 0.1402\n",
      "Epoch [74/100], Step [6000/6235], Loss: 0.8086\n",
      "Epoch [74/100], Step [6100/6235], Loss: 0.2359\n",
      "Epoch [74/100], Step [6200/6235], Loss: 0.9219\n",
      "Epoch [74/100], Step [6300/6235], Loss: 1.7011\n",
      "Epoch [74/100], Step [6400/6235], Loss: 0.0784\n",
      "Epoch [74/100], Step [6500/6235], Loss: 0.2518\n",
      "Epoch [74/100], Step [6600/6235], Loss: 4.0232\n",
      "Epoch [74/100], Step [6700/6235], Loss: 1.7613\n",
      "Epoch [74/100], Step [6800/6235], Loss: 1.1941\n",
      "Epoch [74/100], Step [6900/6235], Loss: 3.3947\n",
      "Epoch [74/100], Step [7000/6235], Loss: 0.8238\n",
      "Epoch [74/100], Step [7100/6235], Loss: 0.1339\n",
      "Epoch [74/100], Step [7200/6235], Loss: 0.3628\n",
      "Epoch [74/100], Step [7300/6235], Loss: 1.2330\n",
      "Epoch [74/100], Step [7400/6235], Loss: 0.1982\n",
      "Epoch [74/100], Step [7500/6235], Loss: 1.1617\n",
      "Epoch [74/100], Step [7600/6235], Loss: 17.5342\n",
      "Epoch [74/100], Step [7700/6235], Loss: 12.4178\n",
      "Epoch [74/100], Step [7800/6235], Loss: 15.5079\n",
      "Epoch [74/100], Step [7900/6235], Loss: 11.3001\n",
      "Epoch [74/100], Step [8000/6235], Loss: 0.6888\n",
      "Epoch [74/100], Step [8100/6235], Loss: 3.8673\n",
      "Epoch [74/100], Step [8200/6235], Loss: 22.3461\n",
      "Epoch [74/100], Step [8300/6235], Loss: 60.3274\n",
      "Epoch [74/100], Step [8400/6235], Loss: 44.3189\n",
      "Epoch [74/100], Step [8500/6235], Loss: 78.2018\n",
      "Epoch [74/100], Step [8600/6235], Loss: 11.7568\n",
      "Epoch [74/100], Step [8700/6235], Loss: 78.7105\n",
      "Epoch [74/100], Step [8800/6235], Loss: 369.3615\n",
      "Epoch [74/100], Step [8900/6235], Loss: 1.6628\n",
      "Epoch [74/100], Step [9000/6235], Loss: 547.3710\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Step [9100/6235], Loss: 2626.0251\n",
      "Epoch [74/100], Step [9200/6235], Loss: 5036.8145\n",
      "Epoch [74/100], Step [9300/6235], Loss: 72.0603\n",
      "Epoch [74/100], Step [9400/6235], Loss: 179.9582\n",
      "Epoch [74/100], Step [9500/6235], Loss: 1795.3302\n",
      "Epoch [74/100], Step [9600/6235], Loss: 433.3537\n",
      "Epoch [74/100], Step [9700/6235], Loss: 10.9203\n",
      "Epoch [74/100], Step [9800/6235], Loss: 2861.5383\n",
      "Epoch [74/100], Step [9900/6235], Loss: 19.0058\n",
      "Epoch [74/100], Step [10000/6235], Loss: 90.8879\n",
      "Epoch [74/100], Step [10100/6235], Loss: 1.2865\n",
      "Epoch [74/100], Step [10200/6235], Loss: 514.2739\n",
      "Epoch [74/100], Step [10300/6235], Loss: 25.4960\n",
      "Epoch [74/100], Step [10400/6235], Loss: 8.2186\n",
      "Epoch [74/100], Step [10500/6235], Loss: 32.2460\n",
      "Epoch [74/100], Step [10600/6235], Loss: 74.0525\n",
      "Epoch [74/100], Step [10700/6235], Loss: 13.9646\n",
      "Epoch [74/100], Step [10800/6235], Loss: 113.1936\n",
      "Epoch [74/100], Step [10900/6235], Loss: 29.0540\n",
      "Epoch [74/100], Step [11000/6235], Loss: 296.3100\n",
      "Epoch [74/100], Step [11100/6235], Loss: 47.2642\n",
      "Epoch [74/100], Step [11200/6235], Loss: 20.5098\n",
      "Epoch [74/100], Step [11300/6235], Loss: 133.0072\n",
      "Epoch [74/100], Step [11400/6235], Loss: 6.5471\n",
      "Epoch [74/100], Step [11500/6235], Loss: 6.4952\n",
      "Epoch [74/100], Step [11600/6235], Loss: 4.1836\n",
      "Epoch [74/100], Step [11700/6235], Loss: 41.8123\n",
      "Epoch [74/100], Step [11800/6235], Loss: 391.6523\n",
      "Epoch [74/100], Step [11900/6235], Loss: 49.4226\n",
      "Epoch [74/100], Step [12000/6235], Loss: 606.4473\n",
      "Epoch [74/100], Step [12100/6235], Loss: 187.9089\n",
      "Epoch [74/100], Step [12200/6235], Loss: 6.9476\n",
      "Epoch [74/100], Step [12300/6235], Loss: 0.5163\n",
      "Epoch [74/100], Step [12400/6235], Loss: 256.3003\n",
      "Epoch [74/100], Step [12500/6235], Loss: 62.6763\n",
      "Epoch [74/100], Step [12600/6235], Loss: 6.4418\n",
      "Epoch [74/100], Step [12700/6235], Loss: 4.6968\n",
      "Epoch [74/100], Step [12800/6235], Loss: 9.4986\n",
      "Epoch [74/100], Step [12900/6235], Loss: 38.4637\n",
      "Epoch [74/100], Step [13000/6235], Loss: 0.8079\n",
      "Epoch [74/100], Step [13100/6235], Loss: 66.8112\n",
      "Epoch [74/100], Step [13200/6235], Loss: 8.3494\n",
      "Epoch [74/100], Step [13300/6235], Loss: 25.9868\n",
      "Epoch [74/100], Step [13400/6235], Loss: 244.2833\n",
      "Epoch [74/100], Step [13500/6235], Loss: 2.9136\n",
      "Epoch [74/100], Step [13600/6235], Loss: 0.6373\n",
      "Epoch [74/100], Step [13700/6235], Loss: 116.6756\n",
      "Epoch [74/100], Step [13800/6235], Loss: 102.9358\n",
      "Epoch [74/100], Step [13900/6235], Loss: 25.3243\n",
      "Epoch [74/100], Step [14000/6235], Loss: 11.9240\n",
      "Epoch [74/100], Step [14100/6235], Loss: 29.0079\n",
      "Epoch [74/100], Step [14200/6235], Loss: 127.2604\n",
      "Epoch [74/100], Step [14300/6235], Loss: 55.6991\n",
      "Epoch [74/100], Step [14400/6235], Loss: 38.9524\n",
      "Epoch [74/100], Step [14500/6235], Loss: 34.4546\n",
      "Epoch [74/100], Step [14600/6235], Loss: 0.8200\n",
      "Epoch [74/100], Step [14700/6235], Loss: 35.1753\n",
      "Epoch [74/100], Step [14800/6235], Loss: 32.9047\n",
      "Epoch [74/100], Step [14900/6235], Loss: 0.7183\n",
      "Epoch [74/100], Step [15000/6235], Loss: 1.4903\n",
      "Epoch [74/100], Step [15100/6235], Loss: 0.5552\n",
      "Epoch [74/100], Step [15200/6235], Loss: 3.9963\n",
      "Epoch [74/100], Step [15300/6235], Loss: 30.3708\n",
      "Epoch [74/100], Step [15400/6235], Loss: 81.1215\n",
      "Epoch [74/100], Step [15500/6235], Loss: 15.8117\n",
      "Epoch [74/100], Step [15600/6235], Loss: 186.5467\n",
      "Epoch [74/100], Step [15700/6235], Loss: 95.9995\n",
      "Epoch [74/100], Step [15800/6235], Loss: 9.2552\n",
      "Epoch [74/100], Step [15900/6235], Loss: 0.7593\n",
      "Epoch [74/100], Step [16000/6235], Loss: 112.7121\n",
      "Epoch [74/100], Step [16100/6235], Loss: 2.0396\n",
      "Epoch [74/100], Step [16200/6235], Loss: 0.2056\n",
      "Epoch [74/100], Step [16300/6235], Loss: 10.1712\n",
      "Epoch [74/100], Step [16400/6235], Loss: 13.8330\n",
      "Epoch [74/100], Step [16500/6235], Loss: 42.3042\n",
      "Epoch [74/100], Step [16600/6235], Loss: 1.9335\n",
      "Epoch [74/100], Step [16700/6235], Loss: 0.7860\n",
      "Epoch [74/100], Step [16800/6235], Loss: 9.1537\n",
      "Epoch [74/100], Step [16900/6235], Loss: 0.3289\n",
      "Epoch [74/100], Step [17000/6235], Loss: 0.2163\n",
      "Epoch [74/100], Step [17100/6235], Loss: 0.1474\n",
      "Epoch [74/100], Step [17200/6235], Loss: 277.3663\n",
      "Epoch [74/100], Step [17300/6235], Loss: 1.6325\n",
      "Epoch [74/100], Step [17400/6235], Loss: 31.6219\n",
      "Epoch [74/100], Step [17500/6235], Loss: 1.5032\n",
      "Epoch [74/100], Step [17600/6235], Loss: 3.0522\n",
      "Epoch [74/100], Step [17700/6235], Loss: 0.5793\n",
      "Epoch [74/100], Step [17800/6235], Loss: 25.8708\n",
      "Epoch [74/100], Step [17900/6235], Loss: 6.0090\n",
      "Epoch [74/100], Step [18000/6235], Loss: 0.6733\n",
      "Epoch [74/100], Step [18100/6235], Loss: 15.1420\n",
      "Epoch [74/100], Step [18200/6235], Loss: 0.5657\n",
      "Epoch [74/100], Step [18300/6235], Loss: 1.6472\n",
      "Epoch [74/100], Step [18400/6235], Loss: 0.1097\n",
      "Epoch [74/100], Step [18500/6235], Loss: 11.7581\n",
      "Epoch [74/100], Step [18600/6235], Loss: 3.1883\n",
      "Epoch [74/100], Step [18700/6235], Loss: 0.7191\n",
      "Epoch [74/100], Step [18800/6235], Loss: 147.6770\n",
      "Epoch [74/100], Step [18900/6235], Loss: 77.8810\n",
      "Epoch [74/100], Step [19000/6235], Loss: 7.7673\n",
      "Epoch [74/100], Step [19100/6235], Loss: 31.0166\n",
      "Epoch [74/100], Step [19200/6235], Loss: 2.3361\n",
      "Epoch [74/100], Step [19300/6235], Loss: 7.0653\n",
      "Epoch [74/100], Step [19400/6235], Loss: 254.1754\n",
      "Epoch [74/100], Step [19500/6235], Loss: 144.0635\n",
      "Epoch [74/100], Step [19600/6235], Loss: 37.8052\n",
      "Epoch [74/100], Step [19700/6235], Loss: 7.6640\n",
      "Epoch [74/100], Step [19800/6235], Loss: 4.0320\n",
      "Epoch [74/100], Step [19900/6235], Loss: 0.1320\n",
      "Epoch [74/100], Step [20000/6235], Loss: 67.0771\n",
      "Epoch [74/100], Step [20100/6235], Loss: 2.3329\n",
      "Epoch [74/100], Step [20200/6235], Loss: 1.8831\n",
      "Epoch [74/100], Step [20300/6235], Loss: 1.8853\n",
      "Epoch [74/100], Step [20400/6235], Loss: 12.1691\n",
      "Epoch [74/100], Step [20500/6235], Loss: 52.3820\n",
      "Epoch [74/100], Step [20600/6235], Loss: 131.6835\n",
      "Epoch [74/100], Step [20700/6235], Loss: 18.4633\n",
      "Epoch [74/100], Step [20800/6235], Loss: 2.0455\n",
      "Epoch [74/100], Step [20900/6235], Loss: 4.1299\n",
      "Epoch [74/100], Step [21000/6235], Loss: 14.7278\n",
      "Epoch [74/100], Step [21100/6235], Loss: 6.3905\n",
      "Epoch [74/100], Step [21200/6235], Loss: 0.2844\n",
      "Epoch [74/100], Step [21300/6235], Loss: 0.1578\n",
      "Epoch [74/100], Step [21400/6235], Loss: 6.0080\n",
      "Epoch [74/100], Step [21500/6235], Loss: 1.8146\n",
      "Epoch [74/100], Step [21600/6235], Loss: 30.9936\n",
      "Epoch [74/100], Step [21700/6235], Loss: 0.3008\n",
      "Epoch [74/100], Step [21800/6235], Loss: 4.8924\n",
      "Epoch [74/100], Step [21900/6235], Loss: 1.4508\n",
      "Epoch [74/100], Step [22000/6235], Loss: 7.4888\n",
      "Epoch [74/100], Step [22100/6235], Loss: 0.7029\n",
      "Epoch [74/100], Step [22200/6235], Loss: 6.0189\n",
      "Epoch [74/100], Step [22300/6235], Loss: 0.4821\n",
      "Epoch [74/100], Step [22400/6235], Loss: 10.4427\n",
      "Epoch [74/100], Step [22500/6235], Loss: 145.8933\n",
      "Epoch [74/100], Step [22600/6235], Loss: 12.1129\n",
      "Epoch [74/100], Step [22700/6235], Loss: 0.4637\n",
      "Epoch [74/100], Step [22800/6235], Loss: 5.3609\n",
      "Epoch [74/100], Step [22900/6235], Loss: 7.7468\n",
      "Epoch [74/100], Step [23000/6235], Loss: 6.9677\n",
      "Epoch [74/100], Step [23100/6235], Loss: 6.0036\n",
      "Epoch [74/100], Step [23200/6235], Loss: 8.7383\n",
      "Epoch [74/100], Step [23300/6235], Loss: 18.0601\n",
      "Epoch [74/100], Step [23400/6235], Loss: 1.6642\n",
      "Epoch [74/100], Step [23500/6235], Loss: 0.1209\n",
      "Epoch [74/100], Step [23600/6235], Loss: 123.2220\n",
      "Epoch [74/100], Step [23700/6235], Loss: 4.0713\n",
      "Epoch [74/100], Step [23800/6235], Loss: 1.0779\n",
      "Epoch [74/100], Step [23900/6235], Loss: 5.7184\n",
      "Epoch [74/100], Step [24000/6235], Loss: 0.3537\n",
      "Epoch [74/100], Step [24100/6235], Loss: 0.7647\n",
      "Epoch [74/100], Step [24200/6235], Loss: 49.3003\n",
      "Epoch [74/100], Step [24300/6235], Loss: 0.9620\n",
      "Epoch [74/100], Step [24400/6235], Loss: 2.3540\n",
      "Epoch [74/100], Step [24500/6235], Loss: 0.8315\n",
      "Epoch [74/100], Step [24600/6235], Loss: 0.2369\n",
      "Epoch [74/100], Step [24700/6235], Loss: 0.1449\n",
      "Epoch [74/100], Step [24800/6235], Loss: 0.1815\n",
      "Epoch [74/100], Step [24900/6235], Loss: 11.2177\n",
      "Epoch [74/100], Step [25000/6235], Loss: 15.0294\n",
      "Epoch [74/100], Step [25100/6235], Loss: 7.3215\n",
      "Epoch [74/100], Step [25200/6235], Loss: 0.7007\n",
      "Epoch [74/100], Step [25300/6235], Loss: 0.5819\n",
      "Epoch [74/100], Step [25400/6235], Loss: 7.9367\n",
      "Epoch [74/100], Step [25500/6235], Loss: 7.3992\n",
      "Epoch [74/100], Step [25600/6235], Loss: 4.4853\n",
      "Epoch [74/100], Step [25700/6235], Loss: 0.3741\n",
      "Epoch [74/100], Step [25800/6235], Loss: 0.1128\n",
      "Epoch [74/100], Step [25900/6235], Loss: 8.6594\n",
      "Epoch [74/100], Step [26000/6235], Loss: 1.4568\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Step [26100/6235], Loss: 0.1692\n",
      "Epoch [74/100], Step [26200/6235], Loss: 0.8615\n",
      "Epoch [74/100], Step [26300/6235], Loss: 3.9548\n",
      "Epoch [74/100], Step [26400/6235], Loss: 0.0871\n",
      "Epoch [74/100], Step [26500/6235], Loss: 0.0174\n",
      "Epoch [74/100], Step [26600/6235], Loss: 1.6272\n",
      "Epoch [74/100], Step [26700/6235], Loss: 0.3808\n",
      "Epoch [74/100], Step [26800/6235], Loss: 0.1965\n",
      "Epoch [74/100], Step [26900/6235], Loss: 0.0007\n",
      "Epoch [74/100], Step [27000/6235], Loss: 14.9154\n",
      "Epoch [74/100], Step [27100/6235], Loss: 0.0512\n",
      "Epoch [74/100], Step [27200/6235], Loss: 0.0254\n",
      "Epoch [74/100], Step [27300/6235], Loss: 0.2266\n",
      "Epoch [74/100], Step [27400/6235], Loss: 0.7705\n",
      "Epoch [74/100], Step [27500/6235], Loss: 9.3085\n",
      "Epoch [74/100], Step [27600/6235], Loss: 0.7100\n",
      "Epoch [74/100], Step [27700/6235], Loss: 1.4669\n",
      "Epoch [74/100], Step [27800/6235], Loss: 5.3789\n",
      "Epoch [74/100], Step [27900/6235], Loss: 0.8914\n",
      "Epoch [74/100], Step [28000/6235], Loss: 60.7806\n",
      "Epoch [74/100], Step [28100/6235], Loss: 1.1043\n",
      "Epoch [74/100], Step [28200/6235], Loss: 36.5252\n",
      "Epoch [74/100], Step [28300/6235], Loss: 2.7616\n",
      "Epoch [74/100], Step [28400/6235], Loss: 25.1777\n",
      "Epoch [74/100], Step [28500/6235], Loss: 4.6348\n",
      "Epoch [74/100], Step [28600/6235], Loss: 0.1550\n",
      "Epoch [74/100], Step [28700/6235], Loss: 5.4820\n",
      "Epoch [74/100], Step [28800/6235], Loss: 0.6440\n",
      "Epoch [74/100], Step [28900/6235], Loss: 69.9794\n",
      "Epoch [74/100], Step [29000/6235], Loss: 9.6932\n",
      "Epoch [74/100], Step [29100/6235], Loss: 0.2661\n",
      "Epoch [74/100], Step [29200/6235], Loss: 1.6901\n",
      "Epoch [74/100], Step [29300/6235], Loss: 2.4904\n",
      "Epoch [74/100], Step [29400/6235], Loss: 0.0778\n",
      "Epoch [74/100], Step [29500/6235], Loss: 3.3546\n",
      "Epoch [74/100], Step [29600/6235], Loss: 0.3577\n",
      "Epoch [74/100], Step [29700/6235], Loss: 1.2353\n",
      "Epoch [74/100], Step [29800/6235], Loss: 1.6064\n",
      "Epoch [74/100], Step [29900/6235], Loss: 1.1688\n",
      "Epoch [74/100], Step [30000/6235], Loss: 7.8542\n",
      "Epoch [74/100], Step [30100/6235], Loss: 11.1224\n",
      "Epoch [74/100], Step [30200/6235], Loss: 1.0931\n",
      "Epoch [74/100], Step [30300/6235], Loss: 0.0124\n",
      "Epoch [74/100], Step [30400/6235], Loss: 1.0888\n",
      "Epoch [74/100], Step [30500/6235], Loss: 3.1778\n",
      "Epoch [74/100], Step [30600/6235], Loss: 1.8078\n",
      "Epoch [74/100], Step [30700/6235], Loss: 0.6134\n",
      "Epoch [74/100], Step [30800/6235], Loss: 0.5150\n",
      "Epoch [74/100], Step [30900/6235], Loss: 3.6296\n",
      "Epoch [74/100], Step [31000/6235], Loss: 0.1979\n",
      "Epoch [74/100], Step [31100/6235], Loss: 0.0439\n",
      "Epoch [74/100], Step [31200/6235], Loss: 6.2359\n",
      "Epoch [74/100], Step [31300/6235], Loss: 1.8597\n",
      "Epoch [74/100], Step [31400/6235], Loss: 0.5620\n",
      "Epoch [74/100], Step [31500/6235], Loss: 0.5762\n",
      "Epoch [74/100], Step [31600/6235], Loss: 7.9908\n",
      "Epoch [74/100], Step [31700/6235], Loss: 12.5455\n",
      "Epoch [74/100], Step [31800/6235], Loss: 0.5408\n",
      "Epoch [74/100], Step [31900/6235], Loss: 117.7001\n",
      "Epoch [74/100], Step [32000/6235], Loss: 66.5934\n",
      "Epoch [74/100], Step [32100/6235], Loss: 1.3507\n",
      "Epoch [74/100], Step [32200/6235], Loss: 135.5203\n",
      "Epoch [74/100], Step [32300/6235], Loss: 1.0593\n",
      "Epoch [74/100], Step [32400/6235], Loss: 1.5358\n",
      "Epoch [74/100], Step [32500/6235], Loss: 15.3411\n",
      "Epoch [74/100], Step [32600/6235], Loss: 0.5125\n",
      "Epoch [74/100], Step [32700/6235], Loss: 92.1638\n",
      "Epoch [74/100], Step [32800/6235], Loss: 0.2754\n",
      "Epoch [74/100], Step [32900/6235], Loss: 0.7000\n",
      "Epoch [74/100], Step [33000/6235], Loss: 0.4395\n",
      "Epoch [74/100], Step [33100/6235], Loss: 0.5240\n",
      "Epoch [74/100], Step [33200/6235], Loss: 1.2634\n",
      "Epoch [74/100], Step [33300/6235], Loss: 0.1889\n",
      "Epoch [74/100], Step [33400/6235], Loss: 59.9730\n",
      "Epoch [74/100], Step [33500/6235], Loss: 0.8164\n",
      "Epoch [74/100], Step [33600/6235], Loss: 9.3678\n",
      "Epoch [74/100], Step [33700/6235], Loss: 10.5424\n",
      "Epoch [74/100], Step [33800/6235], Loss: 0.5273\n",
      "Epoch [74/100], Step [33900/6235], Loss: 30.0803\n",
      "Epoch [74/100], Step [34000/6235], Loss: 0.0953\n",
      "Epoch [74/100], Step [34100/6235], Loss: 0.6023\n",
      "Epoch [74/100], Step [34200/6235], Loss: 2.2781\n",
      "Epoch [74/100], Step [34300/6235], Loss: 3.5017\n",
      "Epoch [74/100], Step [34400/6235], Loss: 0.1721\n",
      "Epoch [74/100], Step [34500/6235], Loss: 30.0315\n",
      "Epoch [74/100], Step [34600/6235], Loss: 1.0445\n",
      "Epoch [74/100], Step [34700/6235], Loss: 10.8565\n",
      "Epoch [74/100], Step [34800/6235], Loss: 12.5553\n",
      "Epoch [74/100], Step [34900/6235], Loss: 68.8474\n",
      "Epoch [74/100], Step [35000/6235], Loss: 0.7053\n",
      "Epoch [74/100], Step [35100/6235], Loss: 0.3915\n",
      "Epoch [74/100], Step [35200/6235], Loss: 0.3568\n",
      "Epoch [74/100], Step [35300/6235], Loss: 2.9824\n",
      "Epoch [74/100], Step [35400/6235], Loss: 0.3921\n",
      "Epoch [74/100], Step [35500/6235], Loss: 1.1436\n",
      "Epoch [74/100], Step [35600/6235], Loss: 0.1526\n",
      "Epoch [74/100], Step [35700/6235], Loss: 6.2907\n",
      "Epoch [74/100], Step [35800/6235], Loss: 0.4256\n",
      "Epoch [74/100], Step [35900/6235], Loss: 0.6730\n",
      "Epoch [74/100], Step [36000/6235], Loss: 0.2450\n",
      "Epoch [74/100], Step [36100/6235], Loss: 0.0549\n",
      "Epoch [74/100], Step [36200/6235], Loss: 24.3026\n",
      "Epoch [74/100], Step [36300/6235], Loss: 0.5995\n",
      "Epoch [74/100], Step [36400/6235], Loss: 2.9149\n",
      "Epoch [74/100], Step [36500/6235], Loss: 8.2184\n",
      "Epoch [74/100], Step [36600/6235], Loss: 0.1124\n",
      "Epoch [74/100], Step [36700/6235], Loss: 0.5262\n",
      "Epoch [74/100], Step [36800/6235], Loss: 8.7145\n",
      "Epoch [74/100], Step [36900/6235], Loss: 11.1060\n",
      "Epoch [74/100], Step [37000/6235], Loss: 0.7369\n",
      "Epoch [74/100], Step [37100/6235], Loss: 1.5427\n",
      "Epoch [74/100], Step [37200/6235], Loss: 0.0643\n",
      "Epoch [74/100], Step [37300/6235], Loss: 0.0355\n",
      "Epoch [74/100], Step [37400/6235], Loss: 0.1956\n",
      "Epoch [74/100], Step [37500/6235], Loss: 5.3835\n",
      "Epoch [74/100], Step [37600/6235], Loss: 12.0099\n",
      "Epoch [74/100], Step [37700/6235], Loss: 1.7120\n",
      "Epoch [74/100], Step [37800/6235], Loss: 7.0608\n",
      "Epoch [74/100], Step [37900/6235], Loss: 5.2267\n",
      "Epoch [74/100], Step [38000/6235], Loss: 0.8126\n",
      "Epoch [74/100], Step [38100/6235], Loss: 4.3528\n",
      "Epoch [74/100], Step [38200/6235], Loss: 2.7217\n",
      "Epoch [74/100], Step [38300/6235], Loss: 0.5403\n",
      "Epoch [74/100], Step [38400/6235], Loss: 0.0976\n",
      "Epoch [74/100], Step [38500/6235], Loss: 2.1993\n",
      "Epoch [74/100], Step [38600/6235], Loss: 0.2665\n",
      "Epoch [74/100], Step [38700/6235], Loss: 0.1879\n",
      "Epoch [74/100], Step [38800/6235], Loss: 0.1754\n",
      "Epoch [74/100], Step [38900/6235], Loss: 9.0525\n",
      "Epoch [74/100], Step [39000/6235], Loss: 10.4785\n",
      "Epoch [74/100], Step [39100/6235], Loss: 20.9615\n",
      "Epoch [74/100], Step [39200/6235], Loss: 0.2507\n",
      "Epoch [74/100], Step [39300/6235], Loss: 54.0911\n",
      "Epoch [74/100], Step [39400/6235], Loss: 115.4800\n",
      "Epoch [74/100], Step [39500/6235], Loss: 390.5717\n",
      "Epoch [74/100], Step [39600/6235], Loss: 14.2540\n",
      "Epoch [74/100], Step [39700/6235], Loss: 72.7421\n",
      "Epoch [74/100], Step [39800/6235], Loss: 190.3362\n",
      "Epoch [74/100], Step [39900/6235], Loss: 16.4751\n",
      "Epoch [74/100], Step [40000/6235], Loss: 6.2695\n",
      "Epoch [74/100], Step [40100/6235], Loss: 15.3089\n",
      "Epoch [74/100], Step [40200/6235], Loss: 4.5605\n",
      "Epoch [74/100], Step [40300/6235], Loss: 0.5761\n",
      "Epoch [74/100], Step [40400/6235], Loss: 0.6465\n",
      "Epoch [74/100], Step [40500/6235], Loss: 2.8722\n",
      "Epoch [74/100], Step [40600/6235], Loss: 0.2378\n",
      "Epoch [74/100], Step [40700/6235], Loss: 6.7189\n",
      "Epoch [74/100], Step [40800/6235], Loss: 0.5287\n",
      "Epoch [74/100], Step [40900/6235], Loss: 0.9475\n",
      "Epoch [74/100], Step [41000/6235], Loss: 45.4255\n",
      "Epoch [74/100], Step [41100/6235], Loss: 20.1874\n",
      "Epoch [74/100], Step [41200/6235], Loss: 6.2539\n",
      "Epoch [74/100], Step [41300/6235], Loss: 2.7599\n",
      "Epoch [74/100], Step [41400/6235], Loss: 2.0447\n",
      "Epoch [74/100], Step [41500/6235], Loss: 0.4112\n",
      "Epoch [74/100], Step [41600/6235], Loss: 0.1061\n",
      "Epoch [74/100], Step [41700/6235], Loss: 0.7029\n",
      "Epoch [74/100], Step [41800/6235], Loss: 2.8702\n",
      "Epoch [74/100], Step [41900/6235], Loss: 4.4461\n",
      "Epoch [74/100], Step [42000/6235], Loss: 4.2866\n",
      "Epoch [74/100], Step [42100/6235], Loss: 9.4886\n",
      "Epoch [74/100], Step [42200/6235], Loss: 35.5898\n",
      "Epoch [74/100], Step [42300/6235], Loss: 1.9948\n",
      "Epoch [74/100], Step [42400/6235], Loss: 5.1178\n",
      "Epoch [74/100], Step [42500/6235], Loss: 0.6829\n",
      "Epoch [74/100], Step [42600/6235], Loss: 2.3745\n",
      "Epoch [74/100], Step [42700/6235], Loss: 0.6735\n",
      "Epoch [74/100], Step [42800/6235], Loss: 13.3524\n",
      "Epoch [74/100], Step [42900/6235], Loss: 1.2471\n",
      "Epoch [74/100], Step [43000/6235], Loss: 0.1832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [74/100], Step [43100/6235], Loss: 0.0242\n",
      "Epoch [74/100], Step [43200/6235], Loss: 0.7539\n",
      "Epoch [74/100], Step [43300/6235], Loss: 7.0714\n",
      "Epoch [74/100], Step [43400/6235], Loss: 10.1797\n",
      "Epoch [74/100], Step [43500/6235], Loss: 9.7137\n",
      "Epoch [74/100], Step [43600/6235], Loss: 7.5447\n",
      "Epoch [74/100], Step [43700/6235], Loss: 49.8971\n",
      "Epoch [74/100], Step [43800/6235], Loss: 0.7113\n",
      "Epoch [74/100], Step [43900/6235], Loss: 0.1655\n",
      "Epoch [74/100], Step [44000/6235], Loss: 52.0120\n",
      "Epoch [74/100], Step [44100/6235], Loss: 4.0647\n",
      "Epoch [74/100], Step [44200/6235], Loss: 4.7427\n",
      "Epoch [74/100], Step [44300/6235], Loss: 86.0537\n",
      "Epoch [74/100], Step [44400/6235], Loss: 3.0827\n",
      "Epoch [74/100], Step [44500/6235], Loss: 1.0440\n",
      "Epoch [74/100], Step [44600/6235], Loss: 32.5032\n",
      "Epoch [74/100], Step [44700/6235], Loss: 1.0352\n",
      "Epoch [74/100], Step [44800/6235], Loss: 4.1440\n",
      "Epoch [74/100], Step [44900/6235], Loss: 2.6888\n",
      "Epoch [74/100], Step [45000/6235], Loss: 5.1414\n",
      "Epoch [74/100], Step [45100/6235], Loss: 27.4442\n",
      "Epoch [74/100], Step [45200/6235], Loss: 0.4804\n",
      "Epoch [74/100], Step [45300/6235], Loss: 40.6961\n",
      "Epoch [74/100], Step [45400/6235], Loss: 12.2726\n",
      "Epoch [74/100], Step [45500/6235], Loss: 0.1495\n",
      "Epoch [74/100], Step [45600/6235], Loss: 0.1277\n",
      "Epoch [74/100], Step [45700/6235], Loss: 28.8019\n",
      "Epoch [74/100], Step [45800/6235], Loss: 222.6634\n",
      "Epoch [74/100], Step [45900/6235], Loss: 27.3077\n",
      "Epoch [74/100], Step [46000/6235], Loss: 0.4931\n",
      "Epoch [74/100], Step [46100/6235], Loss: 17.1994\n",
      "Epoch [74/100], Step [46200/6235], Loss: 43.0071\n",
      "Epoch [74/100], Step [46300/6235], Loss: 10.6361\n",
      "Epoch [74/100], Step [46400/6235], Loss: 11.9779\n",
      "Epoch [74/100], Step [46500/6235], Loss: 0.5374\n",
      "Epoch [74/100], Step [46600/6235], Loss: 18.4428\n",
      "Epoch [74/100], Step [46700/6235], Loss: 1.6771\n",
      "Epoch [74/100], Step [46800/6235], Loss: 9.3849\n",
      "Epoch [74/100], Step [46900/6235], Loss: 15.9447\n",
      "Epoch [74/100], Step [47000/6235], Loss: 1.3343\n",
      "Epoch [74/100], Step [47100/6235], Loss: 23.5474\n",
      "Epoch [74/100], Step [47200/6235], Loss: 25.8998\n",
      "Epoch [74/100], Step [47300/6235], Loss: 0.9505\n",
      "Epoch [74/100], Step [47400/6235], Loss: 28.2613\n",
      "Epoch [74/100], Step [47500/6235], Loss: 2.1688\n",
      "Epoch [74/100], Step [47600/6235], Loss: 10.3441\n",
      "Epoch [74/100], Step [47700/6235], Loss: 8.2838\n",
      "Epoch [74/100], Step [47800/6235], Loss: 9.2473\n",
      "Epoch [74/100], Step [47900/6235], Loss: 20.6678\n",
      "Epoch [74/100], Step [48000/6235], Loss: 54.9461\n",
      "Epoch [74/100], Step [48100/6235], Loss: 4.8558\n",
      "Epoch [74/100], Step [48200/6235], Loss: 7.5270\n",
      "Epoch [74/100], Step [48300/6235], Loss: 387.8753\n",
      "Epoch [74/100], Step [48400/6235], Loss: 16.5077\n",
      "Epoch [74/100], Step [48500/6235], Loss: 31.2762\n",
      "Epoch [74/100], Step [48600/6235], Loss: 156.9854\n",
      "Epoch [74/100], Step [48700/6235], Loss: 6.2230\n",
      "Epoch [74/100], Step [48800/6235], Loss: 341.7166\n",
      "Epoch [74/100], Step [48900/6235], Loss: 262.4828\n",
      "Epoch [74/100], Step [49000/6235], Loss: 194.0812\n",
      "Epoch [74/100], Step [49100/6235], Loss: 3512.2368\n",
      "Epoch [74/100], Step [49200/6235], Loss: 613.8521\n",
      "Epoch [74/100], Step [49300/6235], Loss: 1212.9850\n",
      "Epoch [74/100], Step [49400/6235], Loss: 213.0866\n",
      "Epoch [74/100], Step [49500/6235], Loss: 5.0377\n",
      "Epoch [74/100], Step [49600/6235], Loss: 167.1097\n",
      "Epoch [74/100], Step [49700/6235], Loss: 3006.5024\n",
      "Epoch [74/100], Step [49800/6235], Loss: 1207.8762\n",
      "Epoch [75/100], Step [100/6235], Loss: 35.6781\n",
      "Epoch [75/100], Step [200/6235], Loss: 0.2021\n",
      "Epoch [75/100], Step [300/6235], Loss: 0.0617\n",
      "Epoch [75/100], Step [400/6235], Loss: 0.0055\n",
      "Epoch [75/100], Step [500/6235], Loss: 26.4449\n",
      "Epoch [75/100], Step [600/6235], Loss: 0.1180\n",
      "Epoch [75/100], Step [700/6235], Loss: 1.4452\n",
      "Epoch [75/100], Step [800/6235], Loss: 0.0795\n",
      "Epoch [75/100], Step [900/6235], Loss: 0.0787\n",
      "Epoch [75/100], Step [1000/6235], Loss: 0.0428\n",
      "Epoch [75/100], Step [1100/6235], Loss: 0.1717\n",
      "Epoch [75/100], Step [1200/6235], Loss: 0.1935\n",
      "Epoch [75/100], Step [1300/6235], Loss: 0.0300\n",
      "Epoch [75/100], Step [1400/6235], Loss: 0.0906\n",
      "Epoch [75/100], Step [1500/6235], Loss: 0.0075\n",
      "Epoch [75/100], Step [1600/6235], Loss: 0.2432\n",
      "Epoch [75/100], Step [1700/6235], Loss: 0.0606\n",
      "Epoch [75/100], Step [1800/6235], Loss: 0.2179\n",
      "Epoch [75/100], Step [1900/6235], Loss: 0.3382\n",
      "Epoch [75/100], Step [2000/6235], Loss: 2.2609\n",
      "Epoch [75/100], Step [2100/6235], Loss: 1.8921\n",
      "Epoch [75/100], Step [2200/6235], Loss: 6.8515\n",
      "Epoch [75/100], Step [2300/6235], Loss: 1.8686\n",
      "Epoch [75/100], Step [2400/6235], Loss: 0.6223\n",
      "Epoch [75/100], Step [2500/6235], Loss: 25.2822\n",
      "Epoch [75/100], Step [2600/6235], Loss: 13.6537\n",
      "Epoch [75/100], Step [2700/6235], Loss: 5.8346\n",
      "Epoch [75/100], Step [2800/6235], Loss: 59.5468\n",
      "Epoch [75/100], Step [2900/6235], Loss: 18.0053\n",
      "Epoch [75/100], Step [3000/6235], Loss: 0.9920\n",
      "Epoch [75/100], Step [3100/6235], Loss: 65.7055\n",
      "Epoch [75/100], Step [3200/6235], Loss: 38.6199\n",
      "Epoch [75/100], Step [3300/6235], Loss: 10.0274\n",
      "Epoch [75/100], Step [3400/6235], Loss: 4.4873\n",
      "Epoch [75/100], Step [3500/6235], Loss: 53.6701\n",
      "Epoch [75/100], Step [3600/6235], Loss: 1.0560\n",
      "Epoch [75/100], Step [3700/6235], Loss: 0.0555\n",
      "Epoch [75/100], Step [3800/6235], Loss: 0.0741\n",
      "Epoch [75/100], Step [3900/6235], Loss: 0.1425\n",
      "Epoch [75/100], Step [4000/6235], Loss: 0.1288\n",
      "Epoch [75/100], Step [4100/6235], Loss: 9.9505\n",
      "Epoch [75/100], Step [4200/6235], Loss: 4.2657\n",
      "Epoch [75/100], Step [4300/6235], Loss: 4.8527\n",
      "Epoch [75/100], Step [4400/6235], Loss: 0.5120\n",
      "Epoch [75/100], Step [4500/6235], Loss: 40.0917\n",
      "Epoch [75/100], Step [4600/6235], Loss: 1.5359\n",
      "Epoch [75/100], Step [4700/6235], Loss: 0.1267\n",
      "Epoch [75/100], Step [4800/6235], Loss: 7.1417\n",
      "Epoch [75/100], Step [4900/6235], Loss: 1.7998\n",
      "Epoch [75/100], Step [5000/6235], Loss: 0.0397\n",
      "Epoch [75/100], Step [5100/6235], Loss: 0.6734\n",
      "Epoch [75/100], Step [5200/6235], Loss: 4.5649\n",
      "Epoch [75/100], Step [5300/6235], Loss: 24.5737\n",
      "Epoch [75/100], Step [5400/6235], Loss: 1.0610\n",
      "Epoch [75/100], Step [5500/6235], Loss: 0.1102\n",
      "Epoch [75/100], Step [5600/6235], Loss: 0.3337\n",
      "Epoch [75/100], Step [5700/6235], Loss: 0.1769\n",
      "Epoch [75/100], Step [5800/6235], Loss: 0.7226\n",
      "Epoch [75/100], Step [5900/6235], Loss: 0.1827\n",
      "Epoch [75/100], Step [6000/6235], Loss: 0.1883\n",
      "Epoch [75/100], Step [6100/6235], Loss: 0.0307\n",
      "Epoch [75/100], Step [6200/6235], Loss: 7.0310\n",
      "Epoch [75/100], Step [6300/6235], Loss: 0.5548\n",
      "Epoch [75/100], Step [6400/6235], Loss: 0.0533\n",
      "Epoch [75/100], Step [6500/6235], Loss: 0.9327\n",
      "Epoch [75/100], Step [6600/6235], Loss: 7.5740\n",
      "Epoch [75/100], Step [6700/6235], Loss: 2.0743\n",
      "Epoch [75/100], Step [6800/6235], Loss: 0.5008\n",
      "Epoch [75/100], Step [6900/6235], Loss: 0.5278\n",
      "Epoch [75/100], Step [7000/6235], Loss: 0.3129\n",
      "Epoch [75/100], Step [7100/6235], Loss: 0.2926\n",
      "Epoch [75/100], Step [7200/6235], Loss: 0.1587\n",
      "Epoch [75/100], Step [7300/6235], Loss: 0.8546\n",
      "Epoch [75/100], Step [7400/6235], Loss: 0.0097\n",
      "Epoch [75/100], Step [7500/6235], Loss: 0.6851\n",
      "Epoch [75/100], Step [7600/6235], Loss: 4.5981\n",
      "Epoch [75/100], Step [7700/6235], Loss: 7.1275\n",
      "Epoch [75/100], Step [7800/6235], Loss: 3.9783\n",
      "Epoch [75/100], Step [7900/6235], Loss: 8.8966\n",
      "Epoch [75/100], Step [8000/6235], Loss: 0.6173\n",
      "Epoch [75/100], Step [8100/6235], Loss: 0.1125\n",
      "Epoch [75/100], Step [8200/6235], Loss: 11.0376\n",
      "Epoch [75/100], Step [8300/6235], Loss: 4.2374\n",
      "Epoch [75/100], Step [8400/6235], Loss: 533.2607\n",
      "Epoch [75/100], Step [8500/6235], Loss: 18.0692\n",
      "Epoch [75/100], Step [8600/6235], Loss: 39.0427\n",
      "Epoch [75/100], Step [8700/6235], Loss: 52.8676\n",
      "Epoch [75/100], Step [8800/6235], Loss: 399.4702\n",
      "Epoch [75/100], Step [8900/6235], Loss: 3.9808\n",
      "Epoch [75/100], Step [9000/6235], Loss: 375.8838\n",
      "Epoch [75/100], Step [9100/6235], Loss: 34.6921\n",
      "Epoch [75/100], Step [9200/6235], Loss: 92.1346\n",
      "Epoch [75/100], Step [9300/6235], Loss: 528.6118\n",
      "Epoch [75/100], Step [9400/6235], Loss: 1117.5244\n",
      "Epoch [75/100], Step [9500/6235], Loss: 1765.9684\n",
      "Epoch [75/100], Step [9600/6235], Loss: 510.2869\n",
      "Epoch [75/100], Step [9700/6235], Loss: 8.0671\n",
      "Epoch [75/100], Step [9800/6235], Loss: 106.7832\n",
      "Epoch [75/100], Step [9900/6235], Loss: 33.0677\n",
      "Epoch [75/100], Step [10000/6235], Loss: 960.2013\n",
      "Epoch [75/100], Step [10100/6235], Loss: 62.1161\n",
      "Epoch [75/100], Step [10200/6235], Loss: 866.0905\n",
      "Epoch [75/100], Step [10300/6235], Loss: 0.6030\n",
      "Epoch [75/100], Step [10400/6235], Loss: 11.2171\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Step [10500/6235], Loss: 269.5454\n",
      "Epoch [75/100], Step [10600/6235], Loss: 414.4949\n",
      "Epoch [75/100], Step [10700/6235], Loss: 8.7257\n",
      "Epoch [75/100], Step [10800/6235], Loss: 62.7575\n",
      "Epoch [75/100], Step [10900/6235], Loss: 144.6761\n",
      "Epoch [75/100], Step [11000/6235], Loss: 291.4429\n",
      "Epoch [75/100], Step [11100/6235], Loss: 6.3893\n",
      "Epoch [75/100], Step [11200/6235], Loss: 0.5619\n",
      "Epoch [75/100], Step [11300/6235], Loss: 107.7303\n",
      "Epoch [75/100], Step [11400/6235], Loss: 58.6560\n",
      "Epoch [75/100], Step [11500/6235], Loss: 11.4488\n",
      "Epoch [75/100], Step [11600/6235], Loss: 9.1991\n",
      "Epoch [75/100], Step [11700/6235], Loss: 57.5433\n",
      "Epoch [75/100], Step [11800/6235], Loss: 3.6943\n",
      "Epoch [75/100], Step [11900/6235], Loss: 58.9120\n",
      "Epoch [75/100], Step [12000/6235], Loss: 725.1411\n",
      "Epoch [75/100], Step [12100/6235], Loss: 215.0432\n",
      "Epoch [75/100], Step [12200/6235], Loss: 0.4768\n",
      "Epoch [75/100], Step [12300/6235], Loss: 1.8002\n",
      "Epoch [75/100], Step [12400/6235], Loss: 484.7480\n",
      "Epoch [75/100], Step [12500/6235], Loss: 38.2930\n",
      "Epoch [75/100], Step [12600/6235], Loss: 17.3202\n",
      "Epoch [75/100], Step [12700/6235], Loss: 3.3369\n",
      "Epoch [75/100], Step [12800/6235], Loss: 7.3764\n",
      "Epoch [75/100], Step [12900/6235], Loss: 36.3599\n",
      "Epoch [75/100], Step [13000/6235], Loss: 0.3880\n",
      "Epoch [75/100], Step [13100/6235], Loss: 65.5451\n",
      "Epoch [75/100], Step [13200/6235], Loss: 8.8896\n",
      "Epoch [75/100], Step [13300/6235], Loss: 33.7247\n",
      "Epoch [75/100], Step [13400/6235], Loss: 243.1663\n",
      "Epoch [75/100], Step [13500/6235], Loss: 3.0945\n",
      "Epoch [75/100], Step [13600/6235], Loss: 4.2752\n",
      "Epoch [75/100], Step [13700/6235], Loss: 171.4164\n",
      "Epoch [75/100], Step [13800/6235], Loss: 73.9693\n",
      "Epoch [75/100], Step [13900/6235], Loss: 2.9670\n",
      "Epoch [75/100], Step [14000/6235], Loss: 5.0667\n",
      "Epoch [75/100], Step [14100/6235], Loss: 43.7488\n",
      "Epoch [75/100], Step [14200/6235], Loss: 40.4318\n",
      "Epoch [75/100], Step [14300/6235], Loss: 21.4857\n",
      "Epoch [75/100], Step [14400/6235], Loss: 34.4125\n",
      "Epoch [75/100], Step [14500/6235], Loss: 28.7604\n",
      "Epoch [75/100], Step [14600/6235], Loss: 2.5983\n",
      "Epoch [75/100], Step [14700/6235], Loss: 24.2055\n",
      "Epoch [75/100], Step [14800/6235], Loss: 28.0352\n",
      "Epoch [75/100], Step [14900/6235], Loss: 0.7404\n",
      "Epoch [75/100], Step [15000/6235], Loss: 1.1474\n",
      "Epoch [75/100], Step [15100/6235], Loss: 0.4189\n",
      "Epoch [75/100], Step [15200/6235], Loss: 15.3326\n",
      "Epoch [75/100], Step [15300/6235], Loss: 17.9659\n",
      "Epoch [75/100], Step [15400/6235], Loss: 13.5101\n",
      "Epoch [75/100], Step [15500/6235], Loss: 11.3744\n",
      "Epoch [75/100], Step [15600/6235], Loss: 99.1077\n",
      "Epoch [75/100], Step [15700/6235], Loss: 244.5317\n",
      "Epoch [75/100], Step [15800/6235], Loss: 8.8831\n",
      "Epoch [75/100], Step [15900/6235], Loss: 0.3984\n",
      "Epoch [75/100], Step [16000/6235], Loss: 141.0108\n",
      "Epoch [75/100], Step [16100/6235], Loss: 0.4131\n",
      "Epoch [75/100], Step [16200/6235], Loss: 0.3903\n",
      "Epoch [75/100], Step [16300/6235], Loss: 10.1980\n",
      "Epoch [75/100], Step [16400/6235], Loss: 27.3211\n",
      "Epoch [75/100], Step [16500/6235], Loss: 744.1855\n",
      "Epoch [75/100], Step [16600/6235], Loss: 30.6485\n",
      "Epoch [75/100], Step [16700/6235], Loss: 0.7578\n",
      "Epoch [75/100], Step [16800/6235], Loss: 8.6928\n",
      "Epoch [75/100], Step [16900/6235], Loss: 0.1450\n",
      "Epoch [75/100], Step [17000/6235], Loss: 0.3021\n",
      "Epoch [75/100], Step [17100/6235], Loss: 0.3399\n",
      "Epoch [75/100], Step [17200/6235], Loss: 299.2487\n",
      "Epoch [75/100], Step [17300/6235], Loss: 43.5414\n",
      "Epoch [75/100], Step [17400/6235], Loss: 47.1051\n",
      "Epoch [75/100], Step [17500/6235], Loss: 0.4963\n",
      "Epoch [75/100], Step [17600/6235], Loss: 3.6136\n",
      "Epoch [75/100], Step [17700/6235], Loss: 1.0090\n",
      "Epoch [75/100], Step [17800/6235], Loss: 29.4680\n",
      "Epoch [75/100], Step [17900/6235], Loss: 24.7932\n",
      "Epoch [75/100], Step [18000/6235], Loss: 2.1887\n",
      "Epoch [75/100], Step [18100/6235], Loss: 15.8580\n",
      "Epoch [75/100], Step [18200/6235], Loss: 0.4704\n",
      "Epoch [75/100], Step [18300/6235], Loss: 1.7631\n",
      "Epoch [75/100], Step [18400/6235], Loss: 1.0997\n",
      "Epoch [75/100], Step [18500/6235], Loss: 24.8662\n",
      "Epoch [75/100], Step [18600/6235], Loss: 3.4926\n",
      "Epoch [75/100], Step [18700/6235], Loss: 0.7303\n",
      "Epoch [75/100], Step [18800/6235], Loss: 95.4016\n",
      "Epoch [75/100], Step [18900/6235], Loss: 41.0514\n",
      "Epoch [75/100], Step [19000/6235], Loss: 3.8142\n",
      "Epoch [75/100], Step [19100/6235], Loss: 39.7794\n",
      "Epoch [75/100], Step [19200/6235], Loss: 1.4146\n",
      "Epoch [75/100], Step [19300/6235], Loss: 0.2060\n",
      "Epoch [75/100], Step [19400/6235], Loss: 116.6700\n",
      "Epoch [75/100], Step [19500/6235], Loss: 82.7913\n",
      "Epoch [75/100], Step [19600/6235], Loss: 83.6714\n",
      "Epoch [75/100], Step [19700/6235], Loss: 7.2466\n",
      "Epoch [75/100], Step [19800/6235], Loss: 8.7880\n",
      "Epoch [75/100], Step [19900/6235], Loss: 0.1495\n",
      "Epoch [75/100], Step [20000/6235], Loss: 68.5980\n",
      "Epoch [75/100], Step [20100/6235], Loss: 2.5159\n",
      "Epoch [75/100], Step [20200/6235], Loss: 2.3731\n",
      "Epoch [75/100], Step [20300/6235], Loss: 2.0418\n",
      "Epoch [75/100], Step [20400/6235], Loss: 11.8427\n",
      "Epoch [75/100], Step [20500/6235], Loss: 54.0085\n",
      "Epoch [75/100], Step [20600/6235], Loss: 164.7092\n",
      "Epoch [75/100], Step [20700/6235], Loss: 16.7840\n",
      "Epoch [75/100], Step [20800/6235], Loss: 10.7234\n",
      "Epoch [75/100], Step [20900/6235], Loss: 44.0788\n",
      "Epoch [75/100], Step [21000/6235], Loss: 15.4302\n",
      "Epoch [75/100], Step [21100/6235], Loss: 6.6286\n",
      "Epoch [75/100], Step [21200/6235], Loss: 0.2242\n",
      "Epoch [75/100], Step [21300/6235], Loss: 0.1885\n",
      "Epoch [75/100], Step [21400/6235], Loss: 6.5041\n",
      "Epoch [75/100], Step [21500/6235], Loss: 1.3572\n",
      "Epoch [75/100], Step [21600/6235], Loss: 32.9830\n",
      "Epoch [75/100], Step [21700/6235], Loss: 0.1300\n",
      "Epoch [75/100], Step [21800/6235], Loss: 35.1005\n",
      "Epoch [75/100], Step [21900/6235], Loss: 0.5883\n",
      "Epoch [75/100], Step [22000/6235], Loss: 5.6879\n",
      "Epoch [75/100], Step [22100/6235], Loss: 1.7913\n",
      "Epoch [75/100], Step [22200/6235], Loss: 5.7718\n",
      "Epoch [75/100], Step [22300/6235], Loss: 3.8941\n",
      "Epoch [75/100], Step [22400/6235], Loss: 4.8134\n",
      "Epoch [75/100], Step [22500/6235], Loss: 140.1853\n",
      "Epoch [75/100], Step [22600/6235], Loss: 11.3460\n",
      "Epoch [75/100], Step [22700/6235], Loss: 1.2495\n",
      "Epoch [75/100], Step [22800/6235], Loss: 4.2545\n",
      "Epoch [75/100], Step [22900/6235], Loss: 2.5235\n",
      "Epoch [75/100], Step [23000/6235], Loss: 10.4343\n",
      "Epoch [75/100], Step [23100/6235], Loss: 0.7318\n",
      "Epoch [75/100], Step [23200/6235], Loss: 7.4506\n",
      "Epoch [75/100], Step [23300/6235], Loss: 19.3836\n",
      "Epoch [75/100], Step [23400/6235], Loss: 1.3196\n",
      "Epoch [75/100], Step [23500/6235], Loss: 0.1941\n",
      "Epoch [75/100], Step [23600/6235], Loss: 120.2956\n",
      "Epoch [75/100], Step [23700/6235], Loss: 3.3006\n",
      "Epoch [75/100], Step [23800/6235], Loss: 1.1280\n",
      "Epoch [75/100], Step [23900/6235], Loss: 6.4502\n",
      "Epoch [75/100], Step [24000/6235], Loss: 0.1601\n",
      "Epoch [75/100], Step [24100/6235], Loss: 0.2320\n",
      "Epoch [75/100], Step [24200/6235], Loss: 21.6955\n",
      "Epoch [75/100], Step [24300/6235], Loss: 1.0072\n",
      "Epoch [75/100], Step [24400/6235], Loss: 1.7288\n",
      "Epoch [75/100], Step [24500/6235], Loss: 0.5736\n",
      "Epoch [75/100], Step [24600/6235], Loss: 0.1501\n",
      "Epoch [75/100], Step [24700/6235], Loss: 0.8149\n",
      "Epoch [75/100], Step [24800/6235], Loss: 0.2888\n",
      "Epoch [75/100], Step [24900/6235], Loss: 12.7621\n",
      "Epoch [75/100], Step [25000/6235], Loss: 17.8920\n",
      "Epoch [75/100], Step [25100/6235], Loss: 6.7106\n",
      "Epoch [75/100], Step [25200/6235], Loss: 0.6535\n",
      "Epoch [75/100], Step [25300/6235], Loss: 0.6067\n",
      "Epoch [75/100], Step [25400/6235], Loss: 6.2709\n",
      "Epoch [75/100], Step [25500/6235], Loss: 7.2199\n",
      "Epoch [75/100], Step [25600/6235], Loss: 4.5388\n",
      "Epoch [75/100], Step [25700/6235], Loss: 0.3829\n",
      "Epoch [75/100], Step [25800/6235], Loss: 0.0912\n",
      "Epoch [75/100], Step [25900/6235], Loss: 8.8526\n",
      "Epoch [75/100], Step [26000/6235], Loss: 0.8177\n",
      "Epoch [75/100], Step [26100/6235], Loss: 0.0939\n",
      "Epoch [75/100], Step [26200/6235], Loss: 0.9254\n",
      "Epoch [75/100], Step [26300/6235], Loss: 3.7940\n",
      "Epoch [75/100], Step [26400/6235], Loss: 0.0758\n",
      "Epoch [75/100], Step [26500/6235], Loss: 0.0120\n",
      "Epoch [75/100], Step [26600/6235], Loss: 1.5805\n",
      "Epoch [75/100], Step [26700/6235], Loss: 0.3701\n",
      "Epoch [75/100], Step [26800/6235], Loss: 0.1979\n",
      "Epoch [75/100], Step [26900/6235], Loss: 0.0012\n",
      "Epoch [75/100], Step [27000/6235], Loss: 14.9478\n",
      "Epoch [75/100], Step [27100/6235], Loss: 0.0496\n",
      "Epoch [75/100], Step [27200/6235], Loss: 0.0265\n",
      "Epoch [75/100], Step [27300/6235], Loss: 0.2240\n",
      "Epoch [75/100], Step [27400/6235], Loss: 0.7646\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Step [27500/6235], Loss: 1.7096\n",
      "Epoch [75/100], Step [27600/6235], Loss: 0.4352\n",
      "Epoch [75/100], Step [27700/6235], Loss: 1.3439\n",
      "Epoch [75/100], Step [27800/6235], Loss: 5.7123\n",
      "Epoch [75/100], Step [27900/6235], Loss: 0.4726\n",
      "Epoch [75/100], Step [28000/6235], Loss: 157.9302\n",
      "Epoch [75/100], Step [28100/6235], Loss: 9.1339\n",
      "Epoch [75/100], Step [28200/6235], Loss: 34.0623\n",
      "Epoch [75/100], Step [28300/6235], Loss: 3.4255\n",
      "Epoch [75/100], Step [28400/6235], Loss: 26.0327\n",
      "Epoch [75/100], Step [28500/6235], Loss: 3.6065\n",
      "Epoch [75/100], Step [28600/6235], Loss: 0.2039\n",
      "Epoch [75/100], Step [28700/6235], Loss: 5.4278\n",
      "Epoch [75/100], Step [28800/6235], Loss: 0.6645\n",
      "Epoch [75/100], Step [28900/6235], Loss: 69.5733\n",
      "Epoch [75/100], Step [29000/6235], Loss: 13.5867\n",
      "Epoch [75/100], Step [29100/6235], Loss: 0.1771\n",
      "Epoch [75/100], Step [29200/6235], Loss: 1.8885\n",
      "Epoch [75/100], Step [29300/6235], Loss: 16.9336\n",
      "Epoch [75/100], Step [29400/6235], Loss: 1.2282\n",
      "Epoch [75/100], Step [29500/6235], Loss: 10.9599\n",
      "Epoch [75/100], Step [29600/6235], Loss: 0.0247\n",
      "Epoch [75/100], Step [29700/6235], Loss: 2.0552\n",
      "Epoch [75/100], Step [29800/6235], Loss: 1.3020\n",
      "Epoch [75/100], Step [29900/6235], Loss: 1.6532\n",
      "Epoch [75/100], Step [30000/6235], Loss: 4.3505\n",
      "Epoch [75/100], Step [30100/6235], Loss: 8.5338\n",
      "Epoch [75/100], Step [30200/6235], Loss: 1.4554\n",
      "Epoch [75/100], Step [30300/6235], Loss: 0.0489\n",
      "Epoch [75/100], Step [30400/6235], Loss: 1.4521\n",
      "Epoch [75/100], Step [30500/6235], Loss: 2.4896\n",
      "Epoch [75/100], Step [30600/6235], Loss: 1.8649\n",
      "Epoch [75/100], Step [30700/6235], Loss: 1.0953\n",
      "Epoch [75/100], Step [30800/6235], Loss: 0.5534\n",
      "Epoch [75/100], Step [30900/6235], Loss: 3.1836\n",
      "Epoch [75/100], Step [31000/6235], Loss: 0.2780\n",
      "Epoch [75/100], Step [31100/6235], Loss: 0.0322\n",
      "Epoch [75/100], Step [31200/6235], Loss: 6.1577\n",
      "Epoch [75/100], Step [31300/6235], Loss: 1.5828\n",
      "Epoch [75/100], Step [31400/6235], Loss: 12.0978\n",
      "Epoch [75/100], Step [31500/6235], Loss: 1.2944\n",
      "Epoch [75/100], Step [31600/6235], Loss: 4.9738\n",
      "Epoch [75/100], Step [31700/6235], Loss: 3.3638\n",
      "Epoch [75/100], Step [31800/6235], Loss: 0.3481\n",
      "Epoch [75/100], Step [31900/6235], Loss: 138.8997\n",
      "Epoch [75/100], Step [32000/6235], Loss: 4.8832\n",
      "Epoch [75/100], Step [32100/6235], Loss: 0.4575\n",
      "Epoch [75/100], Step [32200/6235], Loss: 122.0183\n",
      "Epoch [75/100], Step [32300/6235], Loss: 2.0927\n",
      "Epoch [75/100], Step [32400/6235], Loss: 1.4171\n",
      "Epoch [75/100], Step [32500/6235], Loss: 18.5611\n",
      "Epoch [75/100], Step [32600/6235], Loss: 0.6225\n",
      "Epoch [75/100], Step [32700/6235], Loss: 83.3112\n",
      "Epoch [75/100], Step [32800/6235], Loss: 6.3966\n",
      "Epoch [75/100], Step [32900/6235], Loss: 0.0392\n",
      "Epoch [75/100], Step [33000/6235], Loss: 0.1626\n",
      "Epoch [75/100], Step [33100/6235], Loss: 0.6156\n",
      "Epoch [75/100], Step [33200/6235], Loss: 0.9779\n",
      "Epoch [75/100], Step [33300/6235], Loss: 2.2067\n",
      "Epoch [75/100], Step [33400/6235], Loss: 99.6231\n",
      "Epoch [75/100], Step [33500/6235], Loss: 0.9759\n",
      "Epoch [75/100], Step [33600/6235], Loss: 0.8434\n",
      "Epoch [75/100], Step [33700/6235], Loss: 1.1768\n",
      "Epoch [75/100], Step [33800/6235], Loss: 0.5138\n",
      "Epoch [75/100], Step [33900/6235], Loss: 26.8754\n",
      "Epoch [75/100], Step [34000/6235], Loss: 0.0409\n",
      "Epoch [75/100], Step [34100/6235], Loss: 0.4573\n",
      "Epoch [75/100], Step [34200/6235], Loss: 2.2595\n",
      "Epoch [75/100], Step [34300/6235], Loss: 4.7938\n",
      "Epoch [75/100], Step [34400/6235], Loss: 0.2062\n",
      "Epoch [75/100], Step [34500/6235], Loss: 95.2214\n",
      "Epoch [75/100], Step [34600/6235], Loss: 0.4155\n",
      "Epoch [75/100], Step [34700/6235], Loss: 10.9123\n",
      "Epoch [75/100], Step [34800/6235], Loss: 8.4570\n",
      "Epoch [75/100], Step [34900/6235], Loss: 50.9350\n",
      "Epoch [75/100], Step [35000/6235], Loss: 2.2262\n",
      "Epoch [75/100], Step [35100/6235], Loss: 2.1861\n",
      "Epoch [75/100], Step [35200/6235], Loss: 0.2596\n",
      "Epoch [75/100], Step [35300/6235], Loss: 1.9679\n",
      "Epoch [75/100], Step [35400/6235], Loss: 0.4339\n",
      "Epoch [75/100], Step [35500/6235], Loss: 1.5110\n",
      "Epoch [75/100], Step [35600/6235], Loss: 0.5455\n",
      "Epoch [75/100], Step [35700/6235], Loss: 5.2840\n",
      "Epoch [75/100], Step [35800/6235], Loss: 0.9064\n",
      "Epoch [75/100], Step [35900/6235], Loss: 4.3315\n",
      "Epoch [75/100], Step [36000/6235], Loss: 0.0333\n",
      "Epoch [75/100], Step [36100/6235], Loss: 0.0371\n",
      "Epoch [75/100], Step [36200/6235], Loss: 27.9495\n",
      "Epoch [75/100], Step [36300/6235], Loss: 0.4790\n",
      "Epoch [75/100], Step [36400/6235], Loss: 3.0167\n",
      "Epoch [75/100], Step [36500/6235], Loss: 8.0304\n",
      "Epoch [75/100], Step [36600/6235], Loss: 0.1569\n",
      "Epoch [75/100], Step [36700/6235], Loss: 0.5467\n",
      "Epoch [75/100], Step [36800/6235], Loss: 8.0917\n",
      "Epoch [75/100], Step [36900/6235], Loss: 13.6788\n",
      "Epoch [75/100], Step [37000/6235], Loss: 0.7971\n",
      "Epoch [75/100], Step [37100/6235], Loss: 1.6351\n",
      "Epoch [75/100], Step [37200/6235], Loss: 0.0731\n",
      "Epoch [75/100], Step [37300/6235], Loss: 0.0282\n",
      "Epoch [75/100], Step [37400/6235], Loss: 0.2013\n",
      "Epoch [75/100], Step [37500/6235], Loss: 5.7404\n",
      "Epoch [75/100], Step [37600/6235], Loss: 12.1078\n",
      "Epoch [75/100], Step [37700/6235], Loss: 2.0140\n",
      "Epoch [75/100], Step [37800/6235], Loss: 2.9430\n",
      "Epoch [75/100], Step [37900/6235], Loss: 4.6366\n",
      "Epoch [75/100], Step [38000/6235], Loss: 0.8827\n",
      "Epoch [75/100], Step [38100/6235], Loss: 4.5959\n",
      "Epoch [75/100], Step [38200/6235], Loss: 2.5899\n",
      "Epoch [75/100], Step [38300/6235], Loss: 0.5378\n",
      "Epoch [75/100], Step [38400/6235], Loss: 0.0861\n",
      "Epoch [75/100], Step [38500/6235], Loss: 2.1018\n",
      "Epoch [75/100], Step [38600/6235], Loss: 0.2193\n",
      "Epoch [75/100], Step [38700/6235], Loss: 0.2493\n",
      "Epoch [75/100], Step [38800/6235], Loss: 0.1864\n",
      "Epoch [75/100], Step [38900/6235], Loss: 0.6057\n",
      "Epoch [75/100], Step [39000/6235], Loss: 2.5861\n",
      "Epoch [75/100], Step [39100/6235], Loss: 14.6201\n",
      "Epoch [75/100], Step [39200/6235], Loss: 0.2444\n",
      "Epoch [75/100], Step [39300/6235], Loss: 138.1482\n",
      "Epoch [75/100], Step [39400/6235], Loss: 108.8913\n",
      "Epoch [75/100], Step [39500/6235], Loss: 253.6905\n",
      "Epoch [75/100], Step [39600/6235], Loss: 19.3556\n",
      "Epoch [75/100], Step [39700/6235], Loss: 923.3745\n",
      "Epoch [75/100], Step [39800/6235], Loss: 149.5962\n",
      "Epoch [75/100], Step [39900/6235], Loss: 0.8614\n",
      "Epoch [75/100], Step [40000/6235], Loss: 1.9884\n",
      "Epoch [75/100], Step [40100/6235], Loss: 24.7894\n",
      "Epoch [75/100], Step [40200/6235], Loss: 0.5610\n",
      "Epoch [75/100], Step [40300/6235], Loss: 1.4451\n",
      "Epoch [75/100], Step [40400/6235], Loss: 1.6742\n",
      "Epoch [75/100], Step [40500/6235], Loss: 2.6475\n",
      "Epoch [75/100], Step [40600/6235], Loss: 0.2372\n",
      "Epoch [75/100], Step [40700/6235], Loss: 7.1753\n",
      "Epoch [75/100], Step [40800/6235], Loss: 0.5380\n",
      "Epoch [75/100], Step [40900/6235], Loss: 0.7199\n",
      "Epoch [75/100], Step [41000/6235], Loss: 46.7814\n",
      "Epoch [75/100], Step [41100/6235], Loss: 12.0183\n",
      "Epoch [75/100], Step [41200/6235], Loss: 20.6046\n",
      "Epoch [75/100], Step [41300/6235], Loss: 3.0488\n",
      "Epoch [75/100], Step [41400/6235], Loss: 0.2601\n",
      "Epoch [75/100], Step [41500/6235], Loss: 16.2026\n",
      "Epoch [75/100], Step [41600/6235], Loss: 3.4543\n",
      "Epoch [75/100], Step [41700/6235], Loss: 0.1210\n",
      "Epoch [75/100], Step [41800/6235], Loss: 0.4729\n",
      "Epoch [75/100], Step [41900/6235], Loss: 3.8865\n",
      "Epoch [75/100], Step [42000/6235], Loss: 4.0288\n",
      "Epoch [75/100], Step [42100/6235], Loss: 12.2216\n",
      "Epoch [75/100], Step [42200/6235], Loss: 79.6142\n",
      "Epoch [75/100], Step [42300/6235], Loss: 0.2642\n",
      "Epoch [75/100], Step [42400/6235], Loss: 1.8921\n",
      "Epoch [75/100], Step [42500/6235], Loss: 1.3009\n",
      "Epoch [75/100], Step [42600/6235], Loss: 0.9428\n",
      "Epoch [75/100], Step [42700/6235], Loss: 0.5382\n",
      "Epoch [75/100], Step [42800/6235], Loss: 12.3365\n",
      "Epoch [75/100], Step [42900/6235], Loss: 0.2834\n",
      "Epoch [75/100], Step [43000/6235], Loss: 0.4349\n",
      "Epoch [75/100], Step [43100/6235], Loss: 0.0543\n",
      "Epoch [75/100], Step [43200/6235], Loss: 0.1831\n",
      "Epoch [75/100], Step [43300/6235], Loss: 4.6052\n",
      "Epoch [75/100], Step [43400/6235], Loss: 4.5855\n",
      "Epoch [75/100], Step [43500/6235], Loss: 11.9657\n",
      "Epoch [75/100], Step [43600/6235], Loss: 1.5983\n",
      "Epoch [75/100], Step [43700/6235], Loss: 48.4708\n",
      "Epoch [75/100], Step [43800/6235], Loss: 0.4529\n",
      "Epoch [75/100], Step [43900/6235], Loss: 4.0002\n",
      "Epoch [75/100], Step [44000/6235], Loss: 57.5229\n",
      "Epoch [75/100], Step [44100/6235], Loss: 3.5907\n",
      "Epoch [75/100], Step [44200/6235], Loss: 3.8427\n",
      "Epoch [75/100], Step [44300/6235], Loss: 4.1199\n",
      "Epoch [75/100], Step [44400/6235], Loss: 0.6424\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [75/100], Step [44500/6235], Loss: 1.3508\n",
      "Epoch [75/100], Step [44600/6235], Loss: 20.7830\n",
      "Epoch [75/100], Step [44700/6235], Loss: 26.4830\n",
      "Epoch [75/100], Step [44800/6235], Loss: 4.4726\n",
      "Epoch [75/100], Step [44900/6235], Loss: 11.5955\n",
      "Epoch [75/100], Step [45000/6235], Loss: 6.4965\n",
      "Epoch [75/100], Step [45100/6235], Loss: 73.4409\n",
      "Epoch [75/100], Step [45200/6235], Loss: 5.7624\n",
      "Epoch [75/100], Step [45300/6235], Loss: 24.9914\n",
      "Epoch [75/100], Step [45400/6235], Loss: 9.0672\n",
      "Epoch [75/100], Step [45500/6235], Loss: 2.8665\n",
      "Epoch [75/100], Step [45600/6235], Loss: 0.8508\n",
      "Epoch [75/100], Step [45700/6235], Loss: 97.6580\n",
      "Epoch [75/100], Step [45800/6235], Loss: 478.5555\n",
      "Epoch [75/100], Step [45900/6235], Loss: 29.7922\n",
      "Epoch [75/100], Step [46000/6235], Loss: 11.2827\n",
      "Epoch [75/100], Step [46100/6235], Loss: 14.5961\n",
      "Epoch [75/100], Step [46200/6235], Loss: 37.3998\n",
      "Epoch [75/100], Step [46300/6235], Loss: 18.9616\n",
      "Epoch [75/100], Step [46400/6235], Loss: 13.9119\n",
      "Epoch [75/100], Step [46500/6235], Loss: 16.6600\n",
      "Epoch [75/100], Step [46600/6235], Loss: 0.3817\n",
      "Epoch [75/100], Step [46700/6235], Loss: 1.6115\n",
      "Epoch [75/100], Step [46800/6235], Loss: 62.1525\n",
      "Epoch [75/100], Step [46900/6235], Loss: 34.4873\n",
      "Epoch [75/100], Step [47000/6235], Loss: 3.0333\n",
      "Epoch [75/100], Step [47100/6235], Loss: 144.6094\n",
      "Epoch [75/100], Step [47200/6235], Loss: 13.9794\n",
      "Epoch [75/100], Step [47300/6235], Loss: 5.1735\n",
      "Epoch [75/100], Step [47400/6235], Loss: 336.0320\n",
      "Epoch [75/100], Step [47500/6235], Loss: 12.6509\n",
      "Epoch [75/100], Step [47600/6235], Loss: 16.9178\n",
      "Epoch [75/100], Step [47700/6235], Loss: 26.6378\n",
      "Epoch [75/100], Step [47800/6235], Loss: 36.9087\n",
      "Epoch [75/100], Step [47900/6235], Loss: 15.6484\n",
      "Epoch [75/100], Step [48000/6235], Loss: 4.6702\n",
      "Epoch [75/100], Step [48100/6235], Loss: 7.9114\n",
      "Epoch [75/100], Step [48200/6235], Loss: 30.7301\n",
      "Epoch [75/100], Step [48300/6235], Loss: 662.9341\n",
      "Epoch [75/100], Step [48400/6235], Loss: 2.6906\n",
      "Epoch [75/100], Step [48500/6235], Loss: 45.7475\n",
      "Epoch [75/100], Step [48600/6235], Loss: 55.4914\n",
      "Epoch [75/100], Step [48700/6235], Loss: 7.1496\n",
      "Epoch [75/100], Step [48800/6235], Loss: 321.6771\n",
      "Epoch [75/100], Step [48900/6235], Loss: 87.2861\n",
      "Epoch [75/100], Step [49000/6235], Loss: 270.1000\n",
      "Epoch [75/100], Step [49100/6235], Loss: 313.9488\n",
      "Epoch [75/100], Step [49200/6235], Loss: 969.5353\n",
      "Epoch [75/100], Step [49300/6235], Loss: 1004.8130\n",
      "Epoch [75/100], Step [49400/6235], Loss: 89.6070\n",
      "Epoch [75/100], Step [49500/6235], Loss: 8.6664\n",
      "Epoch [75/100], Step [49600/6235], Loss: 513.9342\n",
      "Epoch [75/100], Step [49700/6235], Loss: 1283.8575\n",
      "Epoch [75/100], Step [49800/6235], Loss: 136.2281\n",
      "Epoch [76/100], Step [100/6235], Loss: 29.6292\n",
      "Epoch [76/100], Step [200/6235], Loss: 0.1851\n",
      "Epoch [76/100], Step [300/6235], Loss: 0.0048\n",
      "Epoch [76/100], Step [400/6235], Loss: 0.0016\n",
      "Epoch [76/100], Step [500/6235], Loss: 1.8074\n",
      "Epoch [76/100], Step [600/6235], Loss: 0.0273\n",
      "Epoch [76/100], Step [700/6235], Loss: 0.6482\n",
      "Epoch [76/100], Step [800/6235], Loss: 0.0536\n",
      "Epoch [76/100], Step [900/6235], Loss: 0.0841\n",
      "Epoch [76/100], Step [1000/6235], Loss: 0.0314\n",
      "Epoch [76/100], Step [1100/6235], Loss: 0.1072\n",
      "Epoch [76/100], Step [1200/6235], Loss: 0.1659\n",
      "Epoch [76/100], Step [1300/6235], Loss: 0.0290\n",
      "Epoch [76/100], Step [1400/6235], Loss: 0.2839\n",
      "Epoch [76/100], Step [1500/6235], Loss: 0.0083\n",
      "Epoch [76/100], Step [1600/6235], Loss: 0.2430\n",
      "Epoch [76/100], Step [1700/6235], Loss: 0.1775\n",
      "Epoch [76/100], Step [1800/6235], Loss: 0.2715\n",
      "Epoch [76/100], Step [1900/6235], Loss: 0.3015\n",
      "Epoch [76/100], Step [2000/6235], Loss: 2.2611\n",
      "Epoch [76/100], Step [2100/6235], Loss: 3.8279\n",
      "Epoch [76/100], Step [2200/6235], Loss: 5.4913\n",
      "Epoch [76/100], Step [2300/6235], Loss: 0.7143\n",
      "Epoch [76/100], Step [2400/6235], Loss: 0.6783\n",
      "Epoch [76/100], Step [2500/6235], Loss: 17.7843\n",
      "Epoch [76/100], Step [2600/6235], Loss: 14.3682\n",
      "Epoch [76/100], Step [2700/6235], Loss: 7.2041\n",
      "Epoch [76/100], Step [2800/6235], Loss: 109.6676\n",
      "Epoch [76/100], Step [2900/6235], Loss: 13.7719\n",
      "Epoch [76/100], Step [3000/6235], Loss: 0.0786\n",
      "Epoch [76/100], Step [3100/6235], Loss: 76.9663\n",
      "Epoch [76/100], Step [3200/6235], Loss: 28.6449\n",
      "Epoch [76/100], Step [3300/6235], Loss: 5.8591\n",
      "Epoch [76/100], Step [3400/6235], Loss: 5.8201\n",
      "Epoch [76/100], Step [3500/6235], Loss: 56.7296\n",
      "Epoch [76/100], Step [3600/6235], Loss: 0.2677\n",
      "Epoch [76/100], Step [3700/6235], Loss: 0.1053\n",
      "Epoch [76/100], Step [3800/6235], Loss: 0.1004\n",
      "Epoch [76/100], Step [3900/6235], Loss: 0.1224\n",
      "Epoch [76/100], Step [4000/6235], Loss: 0.1623\n",
      "Epoch [76/100], Step [4100/6235], Loss: 9.7520\n",
      "Epoch [76/100], Step [4200/6235], Loss: 5.4729\n",
      "Epoch [76/100], Step [4300/6235], Loss: 4.5997\n",
      "Epoch [76/100], Step [4400/6235], Loss: 0.3450\n",
      "Epoch [76/100], Step [4500/6235], Loss: 41.7191\n",
      "Epoch [76/100], Step [4600/6235], Loss: 5.5748\n",
      "Epoch [76/100], Step [4700/6235], Loss: 0.1185\n",
      "Epoch [76/100], Step [4800/6235], Loss: 4.8097\n",
      "Epoch [76/100], Step [4900/6235], Loss: 3.8888\n",
      "Epoch [76/100], Step [5000/6235], Loss: 0.2443\n",
      "Epoch [76/100], Step [5100/6235], Loss: 0.3434\n",
      "Epoch [76/100], Step [5200/6235], Loss: 5.1889\n",
      "Epoch [76/100], Step [5300/6235], Loss: 15.1687\n",
      "Epoch [76/100], Step [5400/6235], Loss: 2.4208\n",
      "Epoch [76/100], Step [5500/6235], Loss: 0.0613\n",
      "Epoch [76/100], Step [5600/6235], Loss: 0.2384\n",
      "Epoch [76/100], Step [5700/6235], Loss: 0.0415\n",
      "Epoch [76/100], Step [5800/6235], Loss: 0.3468\n",
      "Epoch [76/100], Step [5900/6235], Loss: 0.0577\n",
      "Epoch [76/100], Step [6000/6235], Loss: 1.0378\n",
      "Epoch [76/100], Step [6100/6235], Loss: 0.0945\n",
      "Epoch [76/100], Step [6200/6235], Loss: 7.6173\n",
      "Epoch [76/100], Step [6300/6235], Loss: 0.8889\n",
      "Epoch [76/100], Step [6400/6235], Loss: 0.0230\n",
      "Epoch [76/100], Step [6500/6235], Loss: 0.4052\n",
      "Epoch [76/100], Step [6600/6235], Loss: 7.6875\n",
      "Epoch [76/100], Step [6700/6235], Loss: 1.5059\n",
      "Epoch [76/100], Step [6800/6235], Loss: 0.5638\n",
      "Epoch [76/100], Step [6900/6235], Loss: 0.1461\n",
      "Epoch [76/100], Step [7000/6235], Loss: 0.0226\n",
      "Epoch [76/100], Step [7100/6235], Loss: 0.3712\n",
      "Epoch [76/100], Step [7200/6235], Loss: 0.3610\n",
      "Epoch [76/100], Step [7300/6235], Loss: 0.6315\n",
      "Epoch [76/100], Step [7400/6235], Loss: 0.0659\n",
      "Epoch [76/100], Step [7500/6235], Loss: 0.7691\n",
      "Epoch [76/100], Step [7600/6235], Loss: 5.5387\n",
      "Epoch [76/100], Step [7700/6235], Loss: 7.0678\n",
      "Epoch [76/100], Step [7800/6235], Loss: 3.3827\n",
      "Epoch [76/100], Step [7900/6235], Loss: 5.8367\n",
      "Epoch [76/100], Step [8000/6235], Loss: 0.5729\n",
      "Epoch [76/100], Step [8100/6235], Loss: 0.3388\n",
      "Epoch [76/100], Step [8200/6235], Loss: 10.2728\n",
      "Epoch [76/100], Step [8300/6235], Loss: 15.7526\n",
      "Epoch [76/100], Step [8400/6235], Loss: 635.8019\n",
      "Epoch [76/100], Step [8500/6235], Loss: 17.3420\n",
      "Epoch [76/100], Step [8600/6235], Loss: 20.5554\n",
      "Epoch [76/100], Step [8700/6235], Loss: 28.1703\n",
      "Epoch [76/100], Step [8800/6235], Loss: 524.9086\n",
      "Epoch [76/100], Step [8900/6235], Loss: 335.0806\n",
      "Epoch [76/100], Step [9000/6235], Loss: 468.3930\n",
      "Epoch [76/100], Step [9100/6235], Loss: 1972.7125\n",
      "Epoch [76/100], Step [9200/6235], Loss: 3540.8311\n",
      "Epoch [76/100], Step [9300/6235], Loss: 117.1194\n",
      "Epoch [76/100], Step [9400/6235], Loss: 9.7490\n",
      "Epoch [76/100], Step [9500/6235], Loss: 945.6226\n",
      "Epoch [76/100], Step [9600/6235], Loss: 836.8400\n",
      "Epoch [76/100], Step [9700/6235], Loss: 3.9692\n",
      "Epoch [76/100], Step [9800/6235], Loss: 52.3025\n",
      "Epoch [76/100], Step [9900/6235], Loss: 1.8629\n",
      "Epoch [76/100], Step [10000/6235], Loss: 458.7505\n",
      "Epoch [76/100], Step [10100/6235], Loss: 68.4528\n",
      "Epoch [76/100], Step [10200/6235], Loss: 888.5161\n",
      "Epoch [76/100], Step [10300/6235], Loss: 0.7371\n",
      "Epoch [76/100], Step [10400/6235], Loss: 10.8585\n",
      "Epoch [76/100], Step [10500/6235], Loss: 256.0757\n",
      "Epoch [76/100], Step [10600/6235], Loss: 1093.8058\n",
      "Epoch [76/100], Step [10700/6235], Loss: 46.2588\n",
      "Epoch [76/100], Step [10800/6235], Loss: 8.1189\n",
      "Epoch [76/100], Step [10900/6235], Loss: 131.2202\n",
      "Epoch [76/100], Step [11000/6235], Loss: 285.6770\n",
      "Epoch [76/100], Step [11100/6235], Loss: 8.7223\n",
      "Epoch [76/100], Step [11200/6235], Loss: 0.3791\n",
      "Epoch [76/100], Step [11300/6235], Loss: 120.9538\n",
      "Epoch [76/100], Step [11400/6235], Loss: 17.0930\n",
      "Epoch [76/100], Step [11500/6235], Loss: 2.3341\n",
      "Epoch [76/100], Step [11600/6235], Loss: 3.3624\n",
      "Epoch [76/100], Step [11700/6235], Loss: 47.8139\n",
      "Epoch [76/100], Step [11800/6235], Loss: 3.1058\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Step [11900/6235], Loss: 5.6766\n",
      "Epoch [76/100], Step [12000/6235], Loss: 603.7376\n",
      "Epoch [76/100], Step [12100/6235], Loss: 243.8857\n",
      "Epoch [76/100], Step [12200/6235], Loss: 13.0270\n",
      "Epoch [76/100], Step [12300/6235], Loss: 0.9605\n",
      "Epoch [76/100], Step [12400/6235], Loss: 104.2010\n",
      "Epoch [76/100], Step [12500/6235], Loss: 93.1572\n",
      "Epoch [76/100], Step [12600/6235], Loss: 1.8387\n",
      "Epoch [76/100], Step [12700/6235], Loss: 6.2728\n",
      "Epoch [76/100], Step [12800/6235], Loss: 13.7967\n",
      "Epoch [76/100], Step [12900/6235], Loss: 29.8591\n",
      "Epoch [76/100], Step [13000/6235], Loss: 0.2121\n",
      "Epoch [76/100], Step [13100/6235], Loss: 62.0391\n",
      "Epoch [76/100], Step [13200/6235], Loss: 8.0778\n",
      "Epoch [76/100], Step [13300/6235], Loss: 18.1476\n",
      "Epoch [76/100], Step [13400/6235], Loss: 202.9006\n",
      "Epoch [76/100], Step [13500/6235], Loss: 4.6187\n",
      "Epoch [76/100], Step [13600/6235], Loss: 3.4976\n",
      "Epoch [76/100], Step [13700/6235], Loss: 154.7883\n",
      "Epoch [76/100], Step [13800/6235], Loss: 84.3763\n",
      "Epoch [76/100], Step [13900/6235], Loss: 15.2555\n",
      "Epoch [76/100], Step [14000/6235], Loss: 9.1861\n",
      "Epoch [76/100], Step [14100/6235], Loss: 49.9204\n",
      "Epoch [76/100], Step [14200/6235], Loss: 0.9680\n",
      "Epoch [76/100], Step [14300/6235], Loss: 16.3503\n",
      "Epoch [76/100], Step [14400/6235], Loss: 35.2314\n",
      "Epoch [76/100], Step [14500/6235], Loss: 26.4432\n",
      "Epoch [76/100], Step [14600/6235], Loss: 2.3593\n",
      "Epoch [76/100], Step [14700/6235], Loss: 27.0129\n",
      "Epoch [76/100], Step [14800/6235], Loss: 29.8378\n",
      "Epoch [76/100], Step [14900/6235], Loss: 0.7010\n",
      "Epoch [76/100], Step [15000/6235], Loss: 1.2398\n",
      "Epoch [76/100], Step [15100/6235], Loss: 0.4579\n",
      "Epoch [76/100], Step [15200/6235], Loss: 15.1044\n",
      "Epoch [76/100], Step [15300/6235], Loss: 29.5337\n",
      "Epoch [76/100], Step [15400/6235], Loss: 78.7951\n",
      "Epoch [76/100], Step [15500/6235], Loss: 13.3166\n",
      "Epoch [76/100], Step [15600/6235], Loss: 11.9476\n",
      "Epoch [76/100], Step [15700/6235], Loss: 18.7023\n",
      "Epoch [76/100], Step [15800/6235], Loss: 10.3116\n",
      "Epoch [76/100], Step [15900/6235], Loss: 0.3849\n",
      "Epoch [76/100], Step [16000/6235], Loss: 68.2958\n",
      "Epoch [76/100], Step [16100/6235], Loss: 0.6325\n",
      "Epoch [76/100], Step [16200/6235], Loss: 4.1414\n",
      "Epoch [76/100], Step [16300/6235], Loss: 8.3940\n",
      "Epoch [76/100], Step [16400/6235], Loss: 23.6620\n",
      "Epoch [76/100], Step [16500/6235], Loss: 235.7590\n",
      "Epoch [76/100], Step [16600/6235], Loss: 37.7298\n",
      "Epoch [76/100], Step [16700/6235], Loss: 0.3332\n",
      "Epoch [76/100], Step [16800/6235], Loss: 12.4512\n",
      "Epoch [76/100], Step [16900/6235], Loss: 0.3827\n",
      "Epoch [76/100], Step [17000/6235], Loss: 0.1793\n",
      "Epoch [76/100], Step [17100/6235], Loss: 0.2068\n",
      "Epoch [76/100], Step [17200/6235], Loss: 249.6385\n",
      "Epoch [76/100], Step [17300/6235], Loss: 5.0375\n",
      "Epoch [76/100], Step [17400/6235], Loss: 30.4200\n",
      "Epoch [76/100], Step [17500/6235], Loss: 1.7598\n",
      "Epoch [76/100], Step [17600/6235], Loss: 2.6395\n",
      "Epoch [76/100], Step [17700/6235], Loss: 23.1056\n",
      "Epoch [76/100], Step [17800/6235], Loss: 17.6341\n",
      "Epoch [76/100], Step [17900/6235], Loss: 10.9508\n",
      "Epoch [76/100], Step [18000/6235], Loss: 18.4234\n",
      "Epoch [76/100], Step [18100/6235], Loss: 15.4893\n",
      "Epoch [76/100], Step [18200/6235], Loss: 0.7824\n",
      "Epoch [76/100], Step [18300/6235], Loss: 3.8245\n",
      "Epoch [76/100], Step [18400/6235], Loss: 1.7796\n",
      "Epoch [76/100], Step [18500/6235], Loss: 15.9964\n",
      "Epoch [76/100], Step [18600/6235], Loss: 2.3804\n",
      "Epoch [76/100], Step [18700/6235], Loss: 0.5467\n",
      "Epoch [76/100], Step [18800/6235], Loss: 149.0852\n",
      "Epoch [76/100], Step [18900/6235], Loss: 36.6310\n",
      "Epoch [76/100], Step [19000/6235], Loss: 0.8908\n",
      "Epoch [76/100], Step [19100/6235], Loss: 5.4254\n",
      "Epoch [76/100], Step [19200/6235], Loss: 1.5656\n",
      "Epoch [76/100], Step [19300/6235], Loss: 1.6801\n",
      "Epoch [76/100], Step [19400/6235], Loss: 173.3683\n",
      "Epoch [76/100], Step [19500/6235], Loss: 163.7411\n",
      "Epoch [76/100], Step [19600/6235], Loss: 124.4447\n",
      "Epoch [76/100], Step [19700/6235], Loss: 25.9668\n",
      "Epoch [76/100], Step [19800/6235], Loss: 0.6898\n",
      "Epoch [76/100], Step [19900/6235], Loss: 1.5453\n",
      "Epoch [76/100], Step [20000/6235], Loss: 105.9760\n",
      "Epoch [76/100], Step [20100/6235], Loss: 11.9594\n",
      "Epoch [76/100], Step [20200/6235], Loss: 2.3118\n",
      "Epoch [76/100], Step [20300/6235], Loss: 0.2955\n",
      "Epoch [76/100], Step [20400/6235], Loss: 30.6561\n",
      "Epoch [76/100], Step [20500/6235], Loss: 27.7579\n",
      "Epoch [76/100], Step [20600/6235], Loss: 14.6821\n",
      "Epoch [76/100], Step [20700/6235], Loss: 15.8939\n",
      "Epoch [76/100], Step [20800/6235], Loss: 0.9886\n",
      "Epoch [76/100], Step [20900/6235], Loss: 23.3608\n",
      "Epoch [76/100], Step [21000/6235], Loss: 19.0651\n",
      "Epoch [76/100], Step [21100/6235], Loss: 5.5242\n",
      "Epoch [76/100], Step [21200/6235], Loss: 0.2236\n",
      "Epoch [76/100], Step [21300/6235], Loss: 0.2054\n",
      "Epoch [76/100], Step [21400/6235], Loss: 6.2965\n",
      "Epoch [76/100], Step [21500/6235], Loss: 1.3694\n",
      "Epoch [76/100], Step [21600/6235], Loss: 31.6639\n",
      "Epoch [76/100], Step [21700/6235], Loss: 0.1996\n",
      "Epoch [76/100], Step [21800/6235], Loss: 0.9322\n",
      "Epoch [76/100], Step [21900/6235], Loss: 0.7284\n",
      "Epoch [76/100], Step [22000/6235], Loss: 4.4440\n",
      "Epoch [76/100], Step [22100/6235], Loss: 2.8287\n",
      "Epoch [76/100], Step [22200/6235], Loss: 7.6630\n",
      "Epoch [76/100], Step [22300/6235], Loss: 1.3085\n",
      "Epoch [76/100], Step [22400/6235], Loss: 2.1771\n",
      "Epoch [76/100], Step [22500/6235], Loss: 162.1259\n",
      "Epoch [76/100], Step [22600/6235], Loss: 15.2028\n",
      "Epoch [76/100], Step [22700/6235], Loss: 0.1266\n",
      "Epoch [76/100], Step [22800/6235], Loss: 12.7602\n",
      "Epoch [76/100], Step [22900/6235], Loss: 6.4381\n",
      "Epoch [76/100], Step [23000/6235], Loss: 34.5151\n",
      "Epoch [76/100], Step [23100/6235], Loss: 9.5818\n",
      "Epoch [76/100], Step [23200/6235], Loss: 9.6865\n",
      "Epoch [76/100], Step [23300/6235], Loss: 18.3327\n",
      "Epoch [76/100], Step [23400/6235], Loss: 1.1187\n",
      "Epoch [76/100], Step [23500/6235], Loss: 0.2093\n",
      "Epoch [76/100], Step [23600/6235], Loss: 117.8709\n",
      "Epoch [76/100], Step [23700/6235], Loss: 2.5415\n",
      "Epoch [76/100], Step [23800/6235], Loss: 1.0869\n",
      "Epoch [76/100], Step [23900/6235], Loss: 6.9788\n",
      "Epoch [76/100], Step [24000/6235], Loss: 0.1224\n",
      "Epoch [76/100], Step [24100/6235], Loss: 0.1391\n",
      "Epoch [76/100], Step [24200/6235], Loss: 23.3900\n",
      "Epoch [76/100], Step [24300/6235], Loss: 1.2352\n",
      "Epoch [76/100], Step [24400/6235], Loss: 2.4116\n",
      "Epoch [76/100], Step [24500/6235], Loss: 1.0245\n",
      "Epoch [76/100], Step [24600/6235], Loss: 0.0944\n",
      "Epoch [76/100], Step [24700/6235], Loss: 2.3903\n",
      "Epoch [76/100], Step [24800/6235], Loss: 0.2397\n",
      "Epoch [76/100], Step [24900/6235], Loss: 16.8998\n",
      "Epoch [76/100], Step [25000/6235], Loss: 20.2172\n",
      "Epoch [76/100], Step [25100/6235], Loss: 6.6615\n",
      "Epoch [76/100], Step [25200/6235], Loss: 0.8458\n",
      "Epoch [76/100], Step [25300/6235], Loss: 0.5630\n",
      "Epoch [76/100], Step [25400/6235], Loss: 9.6418\n",
      "Epoch [76/100], Step [25500/6235], Loss: 6.4406\n",
      "Epoch [76/100], Step [25600/6235], Loss: 3.5632\n",
      "Epoch [76/100], Step [25700/6235], Loss: 0.3840\n",
      "Epoch [76/100], Step [25800/6235], Loss: 0.1330\n",
      "Epoch [76/100], Step [25900/6235], Loss: 9.6269\n",
      "Epoch [76/100], Step [26000/6235], Loss: 0.9946\n",
      "Epoch [76/100], Step [26100/6235], Loss: 0.2792\n",
      "Epoch [76/100], Step [26200/6235], Loss: 0.6107\n",
      "Epoch [76/100], Step [26300/6235], Loss: 4.4047\n",
      "Epoch [76/100], Step [26400/6235], Loss: 0.1020\n",
      "Epoch [76/100], Step [26500/6235], Loss: 0.0691\n",
      "Epoch [76/100], Step [26600/6235], Loss: 2.3392\n",
      "Epoch [76/100], Step [26700/6235], Loss: 0.4934\n",
      "Epoch [76/100], Step [26800/6235], Loss: 0.3279\n",
      "Epoch [76/100], Step [26900/6235], Loss: 0.0059\n",
      "Epoch [76/100], Step [27000/6235], Loss: 13.8298\n",
      "Epoch [76/100], Step [27100/6235], Loss: 0.0882\n",
      "Epoch [76/100], Step [27200/6235], Loss: 0.0419\n",
      "Epoch [76/100], Step [27300/6235], Loss: 0.2379\n",
      "Epoch [76/100], Step [27400/6235], Loss: 0.8300\n",
      "Epoch [76/100], Step [27500/6235], Loss: 29.3296\n",
      "Epoch [76/100], Step [27600/6235], Loss: 0.9090\n",
      "Epoch [76/100], Step [27700/6235], Loss: 1.4391\n",
      "Epoch [76/100], Step [27800/6235], Loss: 3.6898\n",
      "Epoch [76/100], Step [27900/6235], Loss: 0.8269\n",
      "Epoch [76/100], Step [28000/6235], Loss: 177.6672\n",
      "Epoch [76/100], Step [28100/6235], Loss: 0.5519\n",
      "Epoch [76/100], Step [28200/6235], Loss: 26.0751\n",
      "Epoch [76/100], Step [28300/6235], Loss: 2.6436\n",
      "Epoch [76/100], Step [28400/6235], Loss: 28.4230\n",
      "Epoch [76/100], Step [28500/6235], Loss: 4.1501\n",
      "Epoch [76/100], Step [28600/6235], Loss: 0.0567\n",
      "Epoch [76/100], Step [28700/6235], Loss: 5.6152\n",
      "Epoch [76/100], Step [28800/6235], Loss: 0.6213\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Step [28900/6235], Loss: 72.3294\n",
      "Epoch [76/100], Step [29000/6235], Loss: 10.4421\n",
      "Epoch [76/100], Step [29100/6235], Loss: 0.1769\n",
      "Epoch [76/100], Step [29200/6235], Loss: 1.0978\n",
      "Epoch [76/100], Step [29300/6235], Loss: 0.3446\n",
      "Epoch [76/100], Step [29400/6235], Loss: 0.8742\n",
      "Epoch [76/100], Step [29500/6235], Loss: 2.1933\n",
      "Epoch [76/100], Step [29600/6235], Loss: 0.2328\n",
      "Epoch [76/100], Step [29700/6235], Loss: 1.0439\n",
      "Epoch [76/100], Step [29800/6235], Loss: 1.6783\n",
      "Epoch [76/100], Step [29900/6235], Loss: 0.9578\n",
      "Epoch [76/100], Step [30000/6235], Loss: 5.0166\n",
      "Epoch [76/100], Step [30100/6235], Loss: 10.5938\n",
      "Epoch [76/100], Step [30200/6235], Loss: 0.8447\n",
      "Epoch [76/100], Step [30300/6235], Loss: 0.0054\n",
      "Epoch [76/100], Step [30400/6235], Loss: 0.8601\n",
      "Epoch [76/100], Step [30500/6235], Loss: 3.2188\n",
      "Epoch [76/100], Step [30600/6235], Loss: 1.6789\n",
      "Epoch [76/100], Step [30700/6235], Loss: 0.3500\n",
      "Epoch [76/100], Step [30800/6235], Loss: 0.4730\n",
      "Epoch [76/100], Step [30900/6235], Loss: 3.8409\n",
      "Epoch [76/100], Step [31000/6235], Loss: 0.1366\n",
      "Epoch [76/100], Step [31100/6235], Loss: 0.0625\n",
      "Epoch [76/100], Step [31200/6235], Loss: 5.7661\n",
      "Epoch [76/100], Step [31300/6235], Loss: 1.0250\n",
      "Epoch [76/100], Step [31400/6235], Loss: 1.3825\n",
      "Epoch [76/100], Step [31500/6235], Loss: 0.6504\n",
      "Epoch [76/100], Step [31600/6235], Loss: 6.9686\n",
      "Epoch [76/100], Step [31700/6235], Loss: 47.0400\n",
      "Epoch [76/100], Step [31800/6235], Loss: 0.2606\n",
      "Epoch [76/100], Step [31900/6235], Loss: 174.0034\n",
      "Epoch [76/100], Step [32000/6235], Loss: 21.3788\n",
      "Epoch [76/100], Step [32100/6235], Loss: 0.6587\n",
      "Epoch [76/100], Step [32200/6235], Loss: 67.2930\n",
      "Epoch [76/100], Step [32300/6235], Loss: 0.4232\n",
      "Epoch [76/100], Step [32400/6235], Loss: 0.4212\n",
      "Epoch [76/100], Step [32500/6235], Loss: 22.2661\n",
      "Epoch [76/100], Step [32600/6235], Loss: 0.9894\n",
      "Epoch [76/100], Step [32700/6235], Loss: 100.9507\n",
      "Epoch [76/100], Step [32800/6235], Loss: 0.2309\n",
      "Epoch [76/100], Step [32900/6235], Loss: 1.6345\n",
      "Epoch [76/100], Step [33000/6235], Loss: 0.2055\n",
      "Epoch [76/100], Step [33100/6235], Loss: 0.6769\n",
      "Epoch [76/100], Step [33200/6235], Loss: 1.0222\n",
      "Epoch [76/100], Step [33300/6235], Loss: 0.4512\n",
      "Epoch [76/100], Step [33400/6235], Loss: 18.2016\n",
      "Epoch [76/100], Step [33500/6235], Loss: 0.6392\n",
      "Epoch [76/100], Step [33600/6235], Loss: 8.2462\n",
      "Epoch [76/100], Step [33700/6235], Loss: 11.1424\n",
      "Epoch [76/100], Step [33800/6235], Loss: 2.6937\n",
      "Epoch [76/100], Step [33900/6235], Loss: 26.2458\n",
      "Epoch [76/100], Step [34000/6235], Loss: 0.0844\n",
      "Epoch [76/100], Step [34100/6235], Loss: 0.5745\n",
      "Epoch [76/100], Step [34200/6235], Loss: 2.3275\n",
      "Epoch [76/100], Step [34300/6235], Loss: 3.9588\n",
      "Epoch [76/100], Step [34400/6235], Loss: 0.2039\n",
      "Epoch [76/100], Step [34500/6235], Loss: 100.1725\n",
      "Epoch [76/100], Step [34600/6235], Loss: 0.1796\n",
      "Epoch [76/100], Step [34700/6235], Loss: 6.8062\n",
      "Epoch [76/100], Step [34800/6235], Loss: 15.4937\n",
      "Epoch [76/100], Step [34900/6235], Loss: 69.2673\n",
      "Epoch [76/100], Step [35000/6235], Loss: 1.6444\n",
      "Epoch [76/100], Step [35100/6235], Loss: 0.4578\n",
      "Epoch [76/100], Step [35200/6235], Loss: 0.6333\n",
      "Epoch [76/100], Step [35300/6235], Loss: 2.6663\n",
      "Epoch [76/100], Step [35400/6235], Loss: 0.5621\n",
      "Epoch [76/100], Step [35500/6235], Loss: 1.6634\n",
      "Epoch [76/100], Step [35600/6235], Loss: 5.3976\n",
      "Epoch [76/100], Step [35700/6235], Loss: 5.0222\n",
      "Epoch [76/100], Step [35800/6235], Loss: 2.1146\n",
      "Epoch [76/100], Step [35900/6235], Loss: 0.3323\n",
      "Epoch [76/100], Step [36000/6235], Loss: 0.1039\n",
      "Epoch [76/100], Step [36100/6235], Loss: 0.0254\n",
      "Epoch [76/100], Step [36200/6235], Loss: 23.7201\n",
      "Epoch [76/100], Step [36300/6235], Loss: 0.0495\n",
      "Epoch [76/100], Step [36400/6235], Loss: 2.9711\n",
      "Epoch [76/100], Step [36500/6235], Loss: 8.2041\n",
      "Epoch [76/100], Step [36600/6235], Loss: 0.1155\n",
      "Epoch [76/100], Step [36700/6235], Loss: 0.5337\n",
      "Epoch [76/100], Step [36800/6235], Loss: 8.7444\n",
      "Epoch [76/100], Step [36900/6235], Loss: 9.0812\n",
      "Epoch [76/100], Step [37000/6235], Loss: 0.6600\n",
      "Epoch [76/100], Step [37100/6235], Loss: 1.5089\n",
      "Epoch [76/100], Step [37200/6235], Loss: 0.0630\n",
      "Epoch [76/100], Step [37300/6235], Loss: 0.0311\n",
      "Epoch [76/100], Step [37400/6235], Loss: 0.1912\n",
      "Epoch [76/100], Step [37500/6235], Loss: 5.3676\n",
      "Epoch [76/100], Step [37600/6235], Loss: 11.9642\n",
      "Epoch [76/100], Step [37700/6235], Loss: 1.6190\n",
      "Epoch [76/100], Step [37800/6235], Loss: 6.6433\n",
      "Epoch [76/100], Step [37900/6235], Loss: 6.4618\n",
      "Epoch [76/100], Step [38000/6235], Loss: 0.6938\n",
      "Epoch [76/100], Step [38100/6235], Loss: 3.4273\n",
      "Epoch [76/100], Step [38200/6235], Loss: 2.0590\n",
      "Epoch [76/100], Step [38300/6235], Loss: 0.6393\n",
      "Epoch [76/100], Step [38400/6235], Loss: 0.1020\n",
      "Epoch [76/100], Step [38500/6235], Loss: 2.2596\n",
      "Epoch [76/100], Step [38600/6235], Loss: 0.1954\n",
      "Epoch [76/100], Step [38700/6235], Loss: 0.1125\n",
      "Epoch [76/100], Step [38800/6235], Loss: 0.1867\n",
      "Epoch [76/100], Step [38900/6235], Loss: 2.1507\n",
      "Epoch [76/100], Step [39000/6235], Loss: 9.7881\n",
      "Epoch [76/100], Step [39100/6235], Loss: 18.4121\n",
      "Epoch [76/100], Step [39200/6235], Loss: 0.1860\n",
      "Epoch [76/100], Step [39300/6235], Loss: 5.5734\n",
      "Epoch [76/100], Step [39400/6235], Loss: 179.6702\n",
      "Epoch [76/100], Step [39500/6235], Loss: 187.2414\n",
      "Epoch [76/100], Step [39600/6235], Loss: 9.1804\n",
      "Epoch [76/100], Step [39700/6235], Loss: 103.0887\n",
      "Epoch [76/100], Step [39800/6235], Loss: 255.4983\n",
      "Epoch [76/100], Step [39900/6235], Loss: 7.3847\n",
      "Epoch [76/100], Step [40000/6235], Loss: 2.8191\n",
      "Epoch [76/100], Step [40100/6235], Loss: 7.0371\n",
      "Epoch [76/100], Step [40200/6235], Loss: 14.2473\n",
      "Epoch [76/100], Step [40300/6235], Loss: 1.1831\n",
      "Epoch [76/100], Step [40400/6235], Loss: 0.5164\n",
      "Epoch [76/100], Step [40500/6235], Loss: 3.2124\n",
      "Epoch [76/100], Step [40600/6235], Loss: 0.2508\n",
      "Epoch [76/100], Step [40700/6235], Loss: 5.6365\n",
      "Epoch [76/100], Step [40800/6235], Loss: 1.0646\n",
      "Epoch [76/100], Step [40900/6235], Loss: 1.3429\n",
      "Epoch [76/100], Step [41000/6235], Loss: 38.6859\n",
      "Epoch [76/100], Step [41100/6235], Loss: 23.4066\n",
      "Epoch [76/100], Step [41200/6235], Loss: 3.5160\n",
      "Epoch [76/100], Step [41300/6235], Loss: 2.5970\n",
      "Epoch [76/100], Step [41400/6235], Loss: 2.5037\n",
      "Epoch [76/100], Step [41500/6235], Loss: 7.6854\n",
      "Epoch [76/100], Step [41600/6235], Loss: 2.1822\n",
      "Epoch [76/100], Step [41700/6235], Loss: 0.1519\n",
      "Epoch [76/100], Step [41800/6235], Loss: 0.5768\n",
      "Epoch [76/100], Step [41900/6235], Loss: 4.5150\n",
      "Epoch [76/100], Step [42000/6235], Loss: 4.3343\n",
      "Epoch [76/100], Step [42100/6235], Loss: 12.0932\n",
      "Epoch [76/100], Step [42200/6235], Loss: 63.9669\n",
      "Epoch [76/100], Step [42300/6235], Loss: 0.1579\n",
      "Epoch [76/100], Step [42400/6235], Loss: 4.5539\n",
      "Epoch [76/100], Step [42500/6235], Loss: 2.1671\n",
      "Epoch [76/100], Step [42600/6235], Loss: 0.4603\n",
      "Epoch [76/100], Step [42700/6235], Loss: 0.1812\n",
      "Epoch [76/100], Step [42800/6235], Loss: 11.7538\n",
      "Epoch [76/100], Step [42900/6235], Loss: 0.4004\n",
      "Epoch [76/100], Step [43000/6235], Loss: 0.4070\n",
      "Epoch [76/100], Step [43100/6235], Loss: 0.0476\n",
      "Epoch [76/100], Step [43200/6235], Loss: 0.1987\n",
      "Epoch [76/100], Step [43300/6235], Loss: 4.9279\n",
      "Epoch [76/100], Step [43400/6235], Loss: 5.7972\n",
      "Epoch [76/100], Step [43500/6235], Loss: 11.1404\n",
      "Epoch [76/100], Step [43600/6235], Loss: 1.8893\n",
      "Epoch [76/100], Step [43700/6235], Loss: 50.7952\n",
      "Epoch [76/100], Step [43800/6235], Loss: 0.5093\n",
      "Epoch [76/100], Step [43900/6235], Loss: 2.4390\n",
      "Epoch [76/100], Step [44000/6235], Loss: 50.5383\n",
      "Epoch [76/100], Step [44100/6235], Loss: 2.0577\n",
      "Epoch [76/100], Step [44200/6235], Loss: 3.3658\n",
      "Epoch [76/100], Step [44300/6235], Loss: 32.4512\n",
      "Epoch [76/100], Step [44400/6235], Loss: 3.8870\n",
      "Epoch [76/100], Step [44500/6235], Loss: 0.3411\n",
      "Epoch [76/100], Step [44600/6235], Loss: 15.5007\n",
      "Epoch [76/100], Step [44700/6235], Loss: 6.5011\n",
      "Epoch [76/100], Step [44800/6235], Loss: 0.6731\n",
      "Epoch [76/100], Step [44900/6235], Loss: 11.8697\n",
      "Epoch [76/100], Step [45000/6235], Loss: 6.3834\n",
      "Epoch [76/100], Step [45100/6235], Loss: 15.8195\n",
      "Epoch [76/100], Step [45200/6235], Loss: 0.9753\n",
      "Epoch [76/100], Step [45300/6235], Loss: 25.2429\n",
      "Epoch [76/100], Step [45400/6235], Loss: 13.6181\n",
      "Epoch [76/100], Step [45500/6235], Loss: 3.2206\n",
      "Epoch [76/100], Step [45600/6235], Loss: 1.0377\n",
      "Epoch [76/100], Step [45700/6235], Loss: 87.9737\n",
      "Epoch [76/100], Step [45800/6235], Loss: 217.8695\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [76/100], Step [45900/6235], Loss: 19.9691\n",
      "Epoch [76/100], Step [46000/6235], Loss: 19.7869\n",
      "Epoch [76/100], Step [46100/6235], Loss: 63.7860\n",
      "Epoch [76/100], Step [46200/6235], Loss: 68.4633\n",
      "Epoch [76/100], Step [46300/6235], Loss: 78.7776\n",
      "Epoch [76/100], Step [46400/6235], Loss: 14.9426\n",
      "Epoch [76/100], Step [46500/6235], Loss: 2.6830\n",
      "Epoch [76/100], Step [46600/6235], Loss: 14.0902\n",
      "Epoch [76/100], Step [46700/6235], Loss: 81.8934\n",
      "Epoch [76/100], Step [46800/6235], Loss: 1.0210\n",
      "Epoch [76/100], Step [46900/6235], Loss: 0.7394\n",
      "Epoch [76/100], Step [47000/6235], Loss: 0.0821\n",
      "Epoch [76/100], Step [47100/6235], Loss: 100.1545\n",
      "Epoch [76/100], Step [47200/6235], Loss: 4.0708\n",
      "Epoch [76/100], Step [47300/6235], Loss: 26.2703\n",
      "Epoch [76/100], Step [47400/6235], Loss: 83.6894\n",
      "Epoch [76/100], Step [47500/6235], Loss: 1.5190\n",
      "Epoch [76/100], Step [47600/6235], Loss: 8.7233\n",
      "Epoch [76/100], Step [47700/6235], Loss: 104.7383\n",
      "Epoch [76/100], Step [47800/6235], Loss: 22.1453\n",
      "Epoch [76/100], Step [47900/6235], Loss: 0.4625\n",
      "Epoch [76/100], Step [48000/6235], Loss: 102.6820\n",
      "Epoch [76/100], Step [48100/6235], Loss: 5.9225\n",
      "Epoch [76/100], Step [48200/6235], Loss: 53.5060\n",
      "Epoch [76/100], Step [48300/6235], Loss: 963.4382\n",
      "Epoch [76/100], Step [48400/6235], Loss: 6.4845\n",
      "Epoch [76/100], Step [48500/6235], Loss: 8.8027\n",
      "Epoch [76/100], Step [48600/6235], Loss: 16.0487\n",
      "Epoch [76/100], Step [48700/6235], Loss: 2.2571\n",
      "Epoch [76/100], Step [48800/6235], Loss: 1177.1671\n",
      "Epoch [76/100], Step [48900/6235], Loss: 22.1215\n",
      "Epoch [76/100], Step [49000/6235], Loss: 170.0811\n",
      "Epoch [76/100], Step [49100/6235], Loss: 3084.8154\n",
      "Epoch [76/100], Step [49200/6235], Loss: 231.5433\n",
      "Epoch [76/100], Step [49300/6235], Loss: 375.9517\n",
      "Epoch [76/100], Step [49400/6235], Loss: 11.0943\n",
      "Epoch [76/100], Step [49500/6235], Loss: 21.5332\n",
      "Epoch [76/100], Step [49600/6235], Loss: 310.2278\n",
      "Epoch [76/100], Step [49700/6235], Loss: 238.6962\n",
      "Epoch [76/100], Step [49800/6235], Loss: 1519.0808\n",
      "Epoch [77/100], Step [100/6235], Loss: 23.7189\n",
      "Epoch [77/100], Step [200/6235], Loss: 0.1971\n",
      "Epoch [77/100], Step [300/6235], Loss: 0.0083\n",
      "Epoch [77/100], Step [400/6235], Loss: 0.0026\n",
      "Epoch [77/100], Step [500/6235], Loss: 3.4016\n",
      "Epoch [77/100], Step [600/6235], Loss: 0.0345\n",
      "Epoch [77/100], Step [700/6235], Loss: 0.6144\n",
      "Epoch [77/100], Step [800/6235], Loss: 0.0819\n",
      "Epoch [77/100], Step [900/6235], Loss: 0.0590\n",
      "Epoch [77/100], Step [1000/6235], Loss: 0.0285\n",
      "Epoch [77/100], Step [1100/6235], Loss: 0.1333\n",
      "Epoch [77/100], Step [1200/6235], Loss: 0.1700\n",
      "Epoch [77/100], Step [1300/6235], Loss: 0.0330\n",
      "Epoch [77/100], Step [1400/6235], Loss: 0.1966\n",
      "Epoch [77/100], Step [1500/6235], Loss: 0.0087\n",
      "Epoch [77/100], Step [1600/6235], Loss: 0.2364\n",
      "Epoch [77/100], Step [1700/6235], Loss: 0.1105\n",
      "Epoch [77/100], Step [1800/6235], Loss: 0.2334\n",
      "Epoch [77/100], Step [1900/6235], Loss: 0.3176\n",
      "Epoch [77/100], Step [2000/6235], Loss: 2.3291\n",
      "Epoch [77/100], Step [2100/6235], Loss: 1.8968\n",
      "Epoch [77/100], Step [2200/6235], Loss: 6.0999\n",
      "Epoch [77/100], Step [2300/6235], Loss: 0.7627\n",
      "Epoch [77/100], Step [2400/6235], Loss: 0.6662\n",
      "Epoch [77/100], Step [2500/6235], Loss: 22.8867\n",
      "Epoch [77/100], Step [2600/6235], Loss: 14.5857\n",
      "Epoch [77/100], Step [2700/6235], Loss: 11.2827\n",
      "Epoch [77/100], Step [2800/6235], Loss: 244.0318\n",
      "Epoch [77/100], Step [2900/6235], Loss: 19.3597\n",
      "Epoch [77/100], Step [3000/6235], Loss: 1.1204\n",
      "Epoch [77/100], Step [3100/6235], Loss: 64.6543\n",
      "Epoch [77/100], Step [3200/6235], Loss: 40.0347\n",
      "Epoch [77/100], Step [3300/6235], Loss: 9.9724\n",
      "Epoch [77/100], Step [3400/6235], Loss: 4.0646\n",
      "Epoch [77/100], Step [3500/6235], Loss: 58.8198\n",
      "Epoch [77/100], Step [3600/6235], Loss: 1.3234\n",
      "Epoch [77/100], Step [3700/6235], Loss: 0.0400\n",
      "Epoch [77/100], Step [3800/6235], Loss: 0.0358\n",
      "Epoch [77/100], Step [3900/6235], Loss: 0.2879\n",
      "Epoch [77/100], Step [4000/6235], Loss: 0.1191\n",
      "Epoch [77/100], Step [4100/6235], Loss: 10.0487\n",
      "Epoch [77/100], Step [4200/6235], Loss: 3.8203\n",
      "Epoch [77/100], Step [4300/6235], Loss: 6.0606\n",
      "Epoch [77/100], Step [4400/6235], Loss: 0.5609\n",
      "Epoch [77/100], Step [4500/6235], Loss: 36.5909\n",
      "Epoch [77/100], Step [4600/6235], Loss: 4.8034\n",
      "Epoch [77/100], Step [4700/6235], Loss: 0.2311\n",
      "Epoch [77/100], Step [4800/6235], Loss: 7.8180\n",
      "Epoch [77/100], Step [4900/6235], Loss: 1.0102\n",
      "Epoch [77/100], Step [5000/6235], Loss: 0.0281\n",
      "Epoch [77/100], Step [5100/6235], Loss: 4.1787\n",
      "Epoch [77/100], Step [5200/6235], Loss: 7.8595\n",
      "Epoch [77/100], Step [5300/6235], Loss: 27.9063\n",
      "Epoch [77/100], Step [5400/6235], Loss: 1.1797\n",
      "Epoch [77/100], Step [5500/6235], Loss: 0.1492\n",
      "Epoch [77/100], Step [5600/6235], Loss: 0.2745\n",
      "Epoch [77/100], Step [5700/6235], Loss: 0.3335\n",
      "Epoch [77/100], Step [5800/6235], Loss: 0.5640\n",
      "Epoch [77/100], Step [5900/6235], Loss: 0.3245\n",
      "Epoch [77/100], Step [6000/6235], Loss: 0.0674\n",
      "Epoch [77/100], Step [6100/6235], Loss: 0.0824\n",
      "Epoch [77/100], Step [6200/6235], Loss: 5.9926\n",
      "Epoch [77/100], Step [6300/6235], Loss: 0.2695\n",
      "Epoch [77/100], Step [6400/6235], Loss: 0.1472\n",
      "Epoch [77/100], Step [6500/6235], Loss: 1.6023\n",
      "Epoch [77/100], Step [6600/6235], Loss: 5.8242\n",
      "Epoch [77/100], Step [6700/6235], Loss: 0.9550\n",
      "Epoch [77/100], Step [6800/6235], Loss: 0.1852\n",
      "Epoch [77/100], Step [6900/6235], Loss: 0.7366\n",
      "Epoch [77/100], Step [7000/6235], Loss: 0.7593\n",
      "Epoch [77/100], Step [7100/6235], Loss: 0.3805\n",
      "Epoch [77/100], Step [7200/6235], Loss: 0.0794\n",
      "Epoch [77/100], Step [7300/6235], Loss: 0.6060\n",
      "Epoch [77/100], Step [7400/6235], Loss: 0.0784\n",
      "Epoch [77/100], Step [7500/6235], Loss: 0.9182\n",
      "Epoch [77/100], Step [7600/6235], Loss: 5.3245\n",
      "Epoch [77/100], Step [7700/6235], Loss: 7.1463\n",
      "Epoch [77/100], Step [7800/6235], Loss: 2.6928\n",
      "Epoch [77/100], Step [7900/6235], Loss: 5.0316\n",
      "Epoch [77/100], Step [8000/6235], Loss: 0.4687\n",
      "Epoch [77/100], Step [8100/6235], Loss: 0.5162\n",
      "Epoch [77/100], Step [8200/6235], Loss: 10.1790\n",
      "Epoch [77/100], Step [8300/6235], Loss: 21.8744\n",
      "Epoch [77/100], Step [8400/6235], Loss: 613.1822\n",
      "Epoch [77/100], Step [8500/6235], Loss: 18.5576\n",
      "Epoch [77/100], Step [8600/6235], Loss: 20.6119\n",
      "Epoch [77/100], Step [8700/6235], Loss: 45.5591\n",
      "Epoch [77/100], Step [8800/6235], Loss: 690.8313\n",
      "Epoch [77/100], Step [8900/6235], Loss: 382.1795\n",
      "Epoch [77/100], Step [9000/6235], Loss: 187.7774\n",
      "Epoch [77/100], Step [9100/6235], Loss: 1142.6742\n",
      "Epoch [77/100], Step [9200/6235], Loss: 2449.4211\n",
      "Epoch [77/100], Step [9300/6235], Loss: 1.4509\n",
      "Epoch [77/100], Step [9400/6235], Loss: 100.7595\n",
      "Epoch [77/100], Step [9500/6235], Loss: 1397.2029\n",
      "Epoch [77/100], Step [9600/6235], Loss: 1052.1062\n",
      "Epoch [77/100], Step [9700/6235], Loss: 7.8889\n",
      "Epoch [77/100], Step [9800/6235], Loss: 7670.8091\n",
      "Epoch [77/100], Step [9900/6235], Loss: 57.3937\n",
      "Epoch [77/100], Step [10000/6235], Loss: 222.9662\n",
      "Epoch [77/100], Step [10100/6235], Loss: 1.3869\n",
      "Epoch [77/100], Step [10200/6235], Loss: 1357.9656\n",
      "Epoch [77/100], Step [10300/6235], Loss: 67.1822\n",
      "Epoch [77/100], Step [10400/6235], Loss: 12.4628\n",
      "Epoch [77/100], Step [10500/6235], Loss: 23.8545\n",
      "Epoch [77/100], Step [10600/6235], Loss: 28.4398\n",
      "Epoch [77/100], Step [10700/6235], Loss: 7.0497\n",
      "Epoch [77/100], Step [10800/6235], Loss: 123.8423\n",
      "Epoch [77/100], Step [10900/6235], Loss: 93.5598\n",
      "Epoch [77/100], Step [11000/6235], Loss: 285.9796\n",
      "Epoch [77/100], Step [11100/6235], Loss: 28.7587\n",
      "Epoch [77/100], Step [11200/6235], Loss: 2.1521\n",
      "Epoch [77/100], Step [11300/6235], Loss: 96.8535\n",
      "Epoch [77/100], Step [11400/6235], Loss: 93.8825\n",
      "Epoch [77/100], Step [11500/6235], Loss: 11.6407\n",
      "Epoch [77/100], Step [11600/6235], Loss: 9.4570\n",
      "Epoch [77/100], Step [11700/6235], Loss: 68.7491\n",
      "Epoch [77/100], Step [11800/6235], Loss: 344.9933\n",
      "Epoch [77/100], Step [11900/6235], Loss: 20.6511\n",
      "Epoch [77/100], Step [12000/6235], Loss: 718.2051\n",
      "Epoch [77/100], Step [12100/6235], Loss: 211.1840\n",
      "Epoch [77/100], Step [12200/6235], Loss: 3.4323\n",
      "Epoch [77/100], Step [12300/6235], Loss: 2.1697\n",
      "Epoch [77/100], Step [12400/6235], Loss: 198.0560\n",
      "Epoch [77/100], Step [12500/6235], Loss: 35.8645\n",
      "Epoch [77/100], Step [12600/6235], Loss: 21.1960\n",
      "Epoch [77/100], Step [12700/6235], Loss: 7.5296\n",
      "Epoch [77/100], Step [12800/6235], Loss: 12.9690\n",
      "Epoch [77/100], Step [12900/6235], Loss: 44.4386\n",
      "Epoch [77/100], Step [13000/6235], Loss: 1.0980\n",
      "Epoch [77/100], Step [13100/6235], Loss: 68.1873\n",
      "Epoch [77/100], Step [13200/6235], Loss: 7.4691\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Step [13300/6235], Loss: 21.3795\n",
      "Epoch [77/100], Step [13400/6235], Loss: 244.7493\n",
      "Epoch [77/100], Step [13500/6235], Loss: 3.8465\n",
      "Epoch [77/100], Step [13600/6235], Loss: 2.7178\n",
      "Epoch [77/100], Step [13700/6235], Loss: 16.1745\n",
      "Epoch [77/100], Step [13800/6235], Loss: 140.7131\n",
      "Epoch [77/100], Step [13900/6235], Loss: 59.2095\n",
      "Epoch [77/100], Step [14000/6235], Loss: 5.3893\n",
      "Epoch [77/100], Step [14100/6235], Loss: 21.8274\n",
      "Epoch [77/100], Step [14200/6235], Loss: 4.5369\n",
      "Epoch [77/100], Step [14300/6235], Loss: 48.7892\n",
      "Epoch [77/100], Step [14400/6235], Loss: 38.8048\n",
      "Epoch [77/100], Step [14500/6235], Loss: 50.0930\n",
      "Epoch [77/100], Step [14600/6235], Loss: 0.1508\n",
      "Epoch [77/100], Step [14700/6235], Loss: 43.9154\n",
      "Epoch [77/100], Step [14800/6235], Loss: 33.2012\n",
      "Epoch [77/100], Step [14900/6235], Loss: 0.7963\n",
      "Epoch [77/100], Step [15000/6235], Loss: 1.8721\n",
      "Epoch [77/100], Step [15100/6235], Loss: 0.4928\n",
      "Epoch [77/100], Step [15200/6235], Loss: 7.4114\n",
      "Epoch [77/100], Step [15300/6235], Loss: 32.9583\n",
      "Epoch [77/100], Step [15400/6235], Loss: 56.3059\n",
      "Epoch [77/100], Step [15500/6235], Loss: 11.7372\n",
      "Epoch [77/100], Step [15600/6235], Loss: 173.2529\n",
      "Epoch [77/100], Step [15700/6235], Loss: 34.4963\n",
      "Epoch [77/100], Step [15800/6235], Loss: 2.1583\n",
      "Epoch [77/100], Step [15900/6235], Loss: 2.5182\n",
      "Epoch [77/100], Step [16000/6235], Loss: 92.3996\n",
      "Epoch [77/100], Step [16100/6235], Loss: 3.5698\n",
      "Epoch [77/100], Step [16200/6235], Loss: 0.4914\n",
      "Epoch [77/100], Step [16300/6235], Loss: 9.9905\n",
      "Epoch [77/100], Step [16400/6235], Loss: 30.7682\n",
      "Epoch [77/100], Step [16500/6235], Loss: 446.4545\n",
      "Epoch [77/100], Step [16600/6235], Loss: 13.2674\n",
      "Epoch [77/100], Step [16700/6235], Loss: 0.5567\n",
      "Epoch [77/100], Step [16800/6235], Loss: 12.9750\n",
      "Epoch [77/100], Step [16900/6235], Loss: 0.1123\n",
      "Epoch [77/100], Step [17000/6235], Loss: 0.2440\n",
      "Epoch [77/100], Step [17100/6235], Loss: 0.1700\n",
      "Epoch [77/100], Step [17200/6235], Loss: 283.3580\n",
      "Epoch [77/100], Step [17300/6235], Loss: 25.1117\n",
      "Epoch [77/100], Step [17400/6235], Loss: 33.8359\n",
      "Epoch [77/100], Step [17500/6235], Loss: 0.8597\n",
      "Epoch [77/100], Step [17600/6235], Loss: 3.0568\n",
      "Epoch [77/100], Step [17700/6235], Loss: 9.5660\n",
      "Epoch [77/100], Step [17800/6235], Loss: 36.1751\n",
      "Epoch [77/100], Step [17900/6235], Loss: 2.0668\n",
      "Epoch [77/100], Step [18000/6235], Loss: 13.3395\n",
      "Epoch [77/100], Step [18100/6235], Loss: 16.1976\n",
      "Epoch [77/100], Step [18200/6235], Loss: 0.4974\n",
      "Epoch [77/100], Step [18300/6235], Loss: 1.9920\n",
      "Epoch [77/100], Step [18400/6235], Loss: 0.3441\n",
      "Epoch [77/100], Step [18500/6235], Loss: 26.8216\n",
      "Epoch [77/100], Step [18600/6235], Loss: 3.4872\n",
      "Epoch [77/100], Step [18700/6235], Loss: 0.9623\n",
      "Epoch [77/100], Step [18800/6235], Loss: 118.6869\n",
      "Epoch [77/100], Step [18900/6235], Loss: 64.4873\n",
      "Epoch [77/100], Step [19000/6235], Loss: 6.0256\n",
      "Epoch [77/100], Step [19100/6235], Loss: 1.0062\n",
      "Epoch [77/100], Step [19200/6235], Loss: 2.4572\n",
      "Epoch [77/100], Step [19300/6235], Loss: 1.5029\n",
      "Epoch [77/100], Step [19400/6235], Loss: 286.3097\n",
      "Epoch [77/100], Step [19500/6235], Loss: 18.5520\n",
      "Epoch [77/100], Step [19600/6235], Loss: 88.9514\n",
      "Epoch [77/100], Step [19700/6235], Loss: 7.0805\n",
      "Epoch [77/100], Step [19800/6235], Loss: 5.9985\n",
      "Epoch [77/100], Step [19900/6235], Loss: 0.1292\n",
      "Epoch [77/100], Step [20000/6235], Loss: 67.8985\n",
      "Epoch [77/100], Step [20100/6235], Loss: 1.6394\n",
      "Epoch [77/100], Step [20200/6235], Loss: 2.8901\n",
      "Epoch [77/100], Step [20300/6235], Loss: 2.3844\n",
      "Epoch [77/100], Step [20400/6235], Loss: 12.4944\n",
      "Epoch [77/100], Step [20500/6235], Loss: 53.1159\n",
      "Epoch [77/100], Step [20600/6235], Loss: 160.7825\n",
      "Epoch [77/100], Step [20700/6235], Loss: 3.4846\n",
      "Epoch [77/100], Step [20800/6235], Loss: 0.8862\n",
      "Epoch [77/100], Step [20900/6235], Loss: 11.7784\n",
      "Epoch [77/100], Step [21000/6235], Loss: 22.7181\n",
      "Epoch [77/100], Step [21100/6235], Loss: 6.6079\n",
      "Epoch [77/100], Step [21200/6235], Loss: 0.3097\n",
      "Epoch [77/100], Step [21300/6235], Loss: 0.1715\n",
      "Epoch [77/100], Step [21400/6235], Loss: 4.8398\n",
      "Epoch [77/100], Step [21500/6235], Loss: 0.2550\n",
      "Epoch [77/100], Step [21600/6235], Loss: 24.1733\n",
      "Epoch [77/100], Step [21700/6235], Loss: 0.3080\n",
      "Epoch [77/100], Step [21800/6235], Loss: 3.6308\n",
      "Epoch [77/100], Step [21900/6235], Loss: 1.7682\n",
      "Epoch [77/100], Step [22000/6235], Loss: 9.6450\n",
      "Epoch [77/100], Step [22100/6235], Loss: 0.0548\n",
      "Epoch [77/100], Step [22200/6235], Loss: 1.4797\n",
      "Epoch [77/100], Step [22300/6235], Loss: 2.5907\n",
      "Epoch [77/100], Step [22400/6235], Loss: 17.3380\n",
      "Epoch [77/100], Step [22500/6235], Loss: 52.6851\n",
      "Epoch [77/100], Step [22600/6235], Loss: 26.7366\n",
      "Epoch [77/100], Step [22700/6235], Loss: 0.6095\n",
      "Epoch [77/100], Step [22800/6235], Loss: 5.8650\n",
      "Epoch [77/100], Step [22900/6235], Loss: 0.6146\n",
      "Epoch [77/100], Step [23000/6235], Loss: 11.4026\n",
      "Epoch [77/100], Step [23100/6235], Loss: 5.3130\n",
      "Epoch [77/100], Step [23200/6235], Loss: 0.9223\n",
      "Epoch [77/100], Step [23300/6235], Loss: 4.8532\n",
      "Epoch [77/100], Step [23400/6235], Loss: 2.8906\n",
      "Epoch [77/100], Step [23500/6235], Loss: 0.2532\n",
      "Epoch [77/100], Step [23600/6235], Loss: 135.6480\n",
      "Epoch [77/100], Step [23700/6235], Loss: 6.1264\n",
      "Epoch [77/100], Step [23800/6235], Loss: 1.1325\n",
      "Epoch [77/100], Step [23900/6235], Loss: 0.4633\n",
      "Epoch [77/100], Step [24000/6235], Loss: 2.5961\n",
      "Epoch [77/100], Step [24100/6235], Loss: 2.3024\n",
      "Epoch [77/100], Step [24200/6235], Loss: 33.5496\n",
      "Epoch [77/100], Step [24300/6235], Loss: 0.7480\n",
      "Epoch [77/100], Step [24400/6235], Loss: 1.6108\n",
      "Epoch [77/100], Step [24500/6235], Loss: 0.3889\n",
      "Epoch [77/100], Step [24600/6235], Loss: 0.2746\n",
      "Epoch [77/100], Step [24700/6235], Loss: 0.1691\n",
      "Epoch [77/100], Step [24800/6235], Loss: 0.3719\n",
      "Epoch [77/100], Step [24900/6235], Loss: 8.3926\n",
      "Epoch [77/100], Step [25000/6235], Loss: 8.1304\n",
      "Epoch [77/100], Step [25100/6235], Loss: 6.9174\n",
      "Epoch [77/100], Step [25200/6235], Loss: 0.0115\n",
      "Epoch [77/100], Step [25300/6235], Loss: 1.1397\n",
      "Epoch [77/100], Step [25400/6235], Loss: 3.8968\n",
      "Epoch [77/100], Step [25500/6235], Loss: 9.3731\n",
      "Epoch [77/100], Step [25600/6235], Loss: 8.5359\n",
      "Epoch [77/100], Step [25700/6235], Loss: 0.0503\n",
      "Epoch [77/100], Step [25800/6235], Loss: 0.3947\n",
      "Epoch [77/100], Step [25900/6235], Loss: 3.0306\n",
      "Epoch [77/100], Step [26000/6235], Loss: 0.2243\n",
      "Epoch [77/100], Step [26100/6235], Loss: 0.0627\n",
      "Epoch [77/100], Step [26200/6235], Loss: 1.4418\n",
      "Epoch [77/100], Step [26300/6235], Loss: 1.8664\n",
      "Epoch [77/100], Step [26400/6235], Loss: 0.3936\n",
      "Epoch [77/100], Step [26500/6235], Loss: 0.0451\n",
      "Epoch [77/100], Step [26600/6235], Loss: 0.3229\n",
      "Epoch [77/100], Step [26700/6235], Loss: 0.1600\n",
      "Epoch [77/100], Step [26800/6235], Loss: 0.0911\n",
      "Epoch [77/100], Step [26900/6235], Loss: 0.0427\n",
      "Epoch [77/100], Step [27000/6235], Loss: 16.2560\n",
      "Epoch [77/100], Step [27100/6235], Loss: 0.0655\n",
      "Epoch [77/100], Step [27200/6235], Loss: 0.0095\n",
      "Epoch [77/100], Step [27300/6235], Loss: 0.0421\n",
      "Epoch [77/100], Step [27400/6235], Loss: 0.6302\n",
      "Epoch [77/100], Step [27500/6235], Loss: 2.2722\n",
      "Epoch [77/100], Step [27600/6235], Loss: 0.6610\n",
      "Epoch [77/100], Step [27700/6235], Loss: 0.9360\n",
      "Epoch [77/100], Step [27800/6235], Loss: 5.6410\n",
      "Epoch [77/100], Step [27900/6235], Loss: 0.1996\n",
      "Epoch [77/100], Step [28000/6235], Loss: 194.7897\n",
      "Epoch [77/100], Step [28100/6235], Loss: 11.8246\n",
      "Epoch [77/100], Step [28200/6235], Loss: 24.3305\n",
      "Epoch [77/100], Step [28300/6235], Loss: 1.9775\n",
      "Epoch [77/100], Step [28400/6235], Loss: 25.1657\n",
      "Epoch [77/100], Step [28500/6235], Loss: 4.4322\n",
      "Epoch [77/100], Step [28600/6235], Loss: 0.2177\n",
      "Epoch [77/100], Step [28700/6235], Loss: 5.0299\n",
      "Epoch [77/100], Step [28800/6235], Loss: 0.6704\n",
      "Epoch [77/100], Step [28900/6235], Loss: 63.9789\n",
      "Epoch [77/100], Step [29000/6235], Loss: 11.8612\n",
      "Epoch [77/100], Step [29100/6235], Loss: 0.5004\n",
      "Epoch [77/100], Step [29200/6235], Loss: 3.0453\n",
      "Epoch [77/100], Step [29300/6235], Loss: 0.7115\n",
      "Epoch [77/100], Step [29400/6235], Loss: 0.1178\n",
      "Epoch [77/100], Step [29500/6235], Loss: 1.7666\n",
      "Epoch [77/100], Step [29600/6235], Loss: 0.4212\n",
      "Epoch [77/100], Step [29700/6235], Loss: 2.1968\n",
      "Epoch [77/100], Step [29800/6235], Loss: 1.2528\n",
      "Epoch [77/100], Step [29900/6235], Loss: 0.6993\n",
      "Epoch [77/100], Step [30000/6235], Loss: 5.2833\n",
      "Epoch [77/100], Step [30100/6235], Loss: 11.0517\n",
      "Epoch [77/100], Step [30200/6235], Loss: 1.5717\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Step [30300/6235], Loss: 0.0600\n",
      "Epoch [77/100], Step [30400/6235], Loss: 1.4926\n",
      "Epoch [77/100], Step [30500/6235], Loss: 2.4795\n",
      "Epoch [77/100], Step [30600/6235], Loss: 1.8683\n",
      "Epoch [77/100], Step [30700/6235], Loss: 1.0743\n",
      "Epoch [77/100], Step [30800/6235], Loss: 0.5574\n",
      "Epoch [77/100], Step [30900/6235], Loss: 3.4359\n",
      "Epoch [77/100], Step [31000/6235], Loss: 0.2396\n",
      "Epoch [77/100], Step [31100/6235], Loss: 0.0674\n",
      "Epoch [77/100], Step [31200/6235], Loss: 6.5829\n",
      "Epoch [77/100], Step [31300/6235], Loss: 1.5514\n",
      "Epoch [77/100], Step [31400/6235], Loss: 3.9638\n",
      "Epoch [77/100], Step [31500/6235], Loss: 0.7034\n",
      "Epoch [77/100], Step [31600/6235], Loss: 4.9497\n",
      "Epoch [77/100], Step [31700/6235], Loss: 34.3349\n",
      "Epoch [77/100], Step [31800/6235], Loss: 3.4487\n",
      "Epoch [77/100], Step [31900/6235], Loss: 186.7420\n",
      "Epoch [77/100], Step [32000/6235], Loss: 29.7308\n",
      "Epoch [77/100], Step [32100/6235], Loss: 0.4543\n",
      "Epoch [77/100], Step [32200/6235], Loss: 121.1093\n",
      "Epoch [77/100], Step [32300/6235], Loss: 1.3326\n",
      "Epoch [77/100], Step [32400/6235], Loss: 1.4632\n",
      "Epoch [77/100], Step [32500/6235], Loss: 10.8523\n",
      "Epoch [77/100], Step [32600/6235], Loss: 0.3675\n",
      "Epoch [77/100], Step [32700/6235], Loss: 132.1190\n",
      "Epoch [77/100], Step [32800/6235], Loss: 2.1070\n",
      "Epoch [77/100], Step [32900/6235], Loss: 0.1407\n",
      "Epoch [77/100], Step [33000/6235], Loss: 0.3391\n",
      "Epoch [77/100], Step [33100/6235], Loss: 0.6029\n",
      "Epoch [77/100], Step [33200/6235], Loss: 0.8323\n",
      "Epoch [77/100], Step [33300/6235], Loss: 0.6756\n",
      "Epoch [77/100], Step [33400/6235], Loss: 120.2794\n",
      "Epoch [77/100], Step [33500/6235], Loss: 2.2103\n",
      "Epoch [77/100], Step [33600/6235], Loss: 7.9399\n",
      "Epoch [77/100], Step [33700/6235], Loss: 9.7329\n",
      "Epoch [77/100], Step [33800/6235], Loss: 0.8257\n",
      "Epoch [77/100], Step [33900/6235], Loss: 30.7869\n",
      "Epoch [77/100], Step [34000/6235], Loss: 0.0584\n",
      "Epoch [77/100], Step [34100/6235], Loss: 0.4881\n",
      "Epoch [77/100], Step [34200/6235], Loss: 2.3911\n",
      "Epoch [77/100], Step [34300/6235], Loss: 4.3806\n",
      "Epoch [77/100], Step [34400/6235], Loss: 0.2749\n",
      "Epoch [77/100], Step [34500/6235], Loss: 31.2671\n",
      "Epoch [77/100], Step [34600/6235], Loss: 1.0610\n",
      "Epoch [77/100], Step [34700/6235], Loss: 1.5352\n",
      "Epoch [77/100], Step [34800/6235], Loss: 15.0991\n",
      "Epoch [77/100], Step [34900/6235], Loss: 68.7514\n",
      "Epoch [77/100], Step [35000/6235], Loss: 0.2866\n",
      "Epoch [77/100], Step [35100/6235], Loss: 0.4671\n",
      "Epoch [77/100], Step [35200/6235], Loss: 0.2132\n",
      "Epoch [77/100], Step [35300/6235], Loss: 2.4530\n",
      "Epoch [77/100], Step [35400/6235], Loss: 0.4938\n",
      "Epoch [77/100], Step [35500/6235], Loss: 2.2718\n",
      "Epoch [77/100], Step [35600/6235], Loss: 3.5474\n",
      "Epoch [77/100], Step [35700/6235], Loss: 5.4973\n",
      "Epoch [77/100], Step [35800/6235], Loss: 0.5724\n",
      "Epoch [77/100], Step [35900/6235], Loss: 0.3526\n",
      "Epoch [77/100], Step [36000/6235], Loss: 0.2045\n",
      "Epoch [77/100], Step [36100/6235], Loss: 0.0484\n",
      "Epoch [77/100], Step [36200/6235], Loss: 11.1311\n",
      "Epoch [77/100], Step [36300/6235], Loss: 0.4578\n",
      "Epoch [77/100], Step [36400/6235], Loss: 2.1776\n",
      "Epoch [77/100], Step [36500/6235], Loss: 9.1963\n",
      "Epoch [77/100], Step [36600/6235], Loss: 0.1338\n",
      "Epoch [77/100], Step [36700/6235], Loss: 0.3355\n",
      "Epoch [77/100], Step [36800/6235], Loss: 14.6505\n",
      "Epoch [77/100], Step [36900/6235], Loss: 5.4750\n",
      "Epoch [77/100], Step [37000/6235], Loss: 0.3119\n",
      "Epoch [77/100], Step [37100/6235], Loss: 0.8963\n",
      "Epoch [77/100], Step [37200/6235], Loss: 0.0808\n",
      "Epoch [77/100], Step [37300/6235], Loss: 0.0651\n",
      "Epoch [77/100], Step [37400/6235], Loss: 0.2053\n",
      "Epoch [77/100], Step [37500/6235], Loss: 4.1938\n",
      "Epoch [77/100], Step [37600/6235], Loss: 11.5196\n",
      "Epoch [77/100], Step [37700/6235], Loss: 1.4290\n",
      "Epoch [77/100], Step [37800/6235], Loss: 5.8168\n",
      "Epoch [77/100], Step [37900/6235], Loss: 7.0982\n",
      "Epoch [77/100], Step [38000/6235], Loss: 0.5821\n",
      "Epoch [77/100], Step [38100/6235], Loss: 3.2513\n",
      "Epoch [77/100], Step [38200/6235], Loss: 2.0505\n",
      "Epoch [77/100], Step [38300/6235], Loss: 0.4111\n",
      "Epoch [77/100], Step [38400/6235], Loss: 0.1268\n",
      "Epoch [77/100], Step [38500/6235], Loss: 2.5746\n",
      "Epoch [77/100], Step [38600/6235], Loss: 0.0618\n",
      "Epoch [77/100], Step [38700/6235], Loss: 0.2092\n",
      "Epoch [77/100], Step [38800/6235], Loss: 0.2350\n",
      "Epoch [77/100], Step [38900/6235], Loss: 5.4401\n",
      "Epoch [77/100], Step [39000/6235], Loss: 12.5173\n",
      "Epoch [77/100], Step [39100/6235], Loss: 19.1739\n",
      "Epoch [77/100], Step [39200/6235], Loss: 0.6639\n",
      "Epoch [77/100], Step [39300/6235], Loss: 6.6456\n",
      "Epoch [77/100], Step [39400/6235], Loss: 110.6598\n",
      "Epoch [77/100], Step [39500/6235], Loss: 281.8348\n",
      "Epoch [77/100], Step [39600/6235], Loss: 43.7269\n",
      "Epoch [77/100], Step [39700/6235], Loss: 56.5834\n",
      "Epoch [77/100], Step [39800/6235], Loss: 93.8990\n",
      "Epoch [77/100], Step [39900/6235], Loss: 5.3149\n",
      "Epoch [77/100], Step [40000/6235], Loss: 4.4218\n",
      "Epoch [77/100], Step [40100/6235], Loss: 12.6803\n",
      "Epoch [77/100], Step [40200/6235], Loss: 7.6147\n",
      "Epoch [77/100], Step [40300/6235], Loss: 1.9943\n",
      "Epoch [77/100], Step [40400/6235], Loss: 0.2808\n",
      "Epoch [77/100], Step [40500/6235], Loss: 3.0551\n",
      "Epoch [77/100], Step [40600/6235], Loss: 0.3104\n",
      "Epoch [77/100], Step [40700/6235], Loss: 6.1242\n",
      "Epoch [77/100], Step [40800/6235], Loss: 0.6825\n",
      "Epoch [77/100], Step [40900/6235], Loss: 1.1676\n",
      "Epoch [77/100], Step [41000/6235], Loss: 43.9120\n",
      "Epoch [77/100], Step [41100/6235], Loss: 36.7128\n",
      "Epoch [77/100], Step [41200/6235], Loss: 5.9484\n",
      "Epoch [77/100], Step [41300/6235], Loss: 3.7780\n",
      "Epoch [77/100], Step [41400/6235], Loss: 0.0043\n",
      "Epoch [77/100], Step [41500/6235], Loss: 0.9011\n",
      "Epoch [77/100], Step [41600/6235], Loss: 0.1669\n",
      "Epoch [77/100], Step [41700/6235], Loss: 0.1238\n",
      "Epoch [77/100], Step [41800/6235], Loss: 1.6008\n",
      "Epoch [77/100], Step [41900/6235], Loss: 4.7557\n",
      "Epoch [77/100], Step [42000/6235], Loss: 4.7344\n",
      "Epoch [77/100], Step [42100/6235], Loss: 11.1344\n",
      "Epoch [77/100], Step [42200/6235], Loss: 43.8709\n",
      "Epoch [77/100], Step [42300/6235], Loss: 0.6066\n",
      "Epoch [77/100], Step [42400/6235], Loss: 2.8165\n",
      "Epoch [77/100], Step [42500/6235], Loss: 1.2136\n",
      "Epoch [77/100], Step [42600/6235], Loss: 2.1452\n",
      "Epoch [77/100], Step [42700/6235], Loss: 0.4647\n",
      "Epoch [77/100], Step [42800/6235], Loss: 14.9018\n",
      "Epoch [77/100], Step [42900/6235], Loss: 0.5797\n",
      "Epoch [77/100], Step [43000/6235], Loss: 0.2884\n",
      "Epoch [77/100], Step [43100/6235], Loss: 0.0271\n",
      "Epoch [77/100], Step [43200/6235], Loss: 0.4435\n",
      "Epoch [77/100], Step [43300/6235], Loss: 5.7818\n",
      "Epoch [77/100], Step [43400/6235], Loss: 6.6532\n",
      "Epoch [77/100], Step [43500/6235], Loss: 10.6252\n",
      "Epoch [77/100], Step [43600/6235], Loss: 3.3692\n",
      "Epoch [77/100], Step [43700/6235], Loss: 52.2724\n",
      "Epoch [77/100], Step [43800/6235], Loss: 0.2973\n",
      "Epoch [77/100], Step [43900/6235], Loss: 2.0366\n",
      "Epoch [77/100], Step [44000/6235], Loss: 51.3997\n",
      "Epoch [77/100], Step [44100/6235], Loss: 2.6664\n",
      "Epoch [77/100], Step [44200/6235], Loss: 4.3320\n",
      "Epoch [77/100], Step [44300/6235], Loss: 8.9924\n",
      "Epoch [77/100], Step [44400/6235], Loss: 2.2125\n",
      "Epoch [77/100], Step [44500/6235], Loss: 1.1260\n",
      "Epoch [77/100], Step [44600/6235], Loss: 26.9611\n",
      "Epoch [77/100], Step [44700/6235], Loss: 0.6403\n",
      "Epoch [77/100], Step [44800/6235], Loss: 3.4243\n",
      "Epoch [77/100], Step [44900/6235], Loss: 8.6501\n",
      "Epoch [77/100], Step [45000/6235], Loss: 5.7374\n",
      "Epoch [77/100], Step [45100/6235], Loss: 54.3523\n",
      "Epoch [77/100], Step [45200/6235], Loss: 0.4986\n",
      "Epoch [77/100], Step [45300/6235], Loss: 27.3938\n",
      "Epoch [77/100], Step [45400/6235], Loss: 10.4045\n",
      "Epoch [77/100], Step [45500/6235], Loss: 1.3994\n",
      "Epoch [77/100], Step [45600/6235], Loss: 0.3087\n",
      "Epoch [77/100], Step [45700/6235], Loss: 97.8133\n",
      "Epoch [77/100], Step [45800/6235], Loss: 355.1954\n",
      "Epoch [77/100], Step [45900/6235], Loss: 18.0729\n",
      "Epoch [77/100], Step [46000/6235], Loss: 12.0974\n",
      "Epoch [77/100], Step [46100/6235], Loss: 12.9162\n",
      "Epoch [77/100], Step [46200/6235], Loss: 28.4374\n",
      "Epoch [77/100], Step [46300/6235], Loss: 34.4830\n",
      "Epoch [77/100], Step [46400/6235], Loss: 15.5721\n",
      "Epoch [77/100], Step [46500/6235], Loss: 6.4743\n",
      "Epoch [77/100], Step [46600/6235], Loss: 10.0243\n",
      "Epoch [77/100], Step [46700/6235], Loss: 19.4000\n",
      "Epoch [77/100], Step [46800/6235], Loss: 0.9268\n",
      "Epoch [77/100], Step [46900/6235], Loss: 3.6669\n",
      "Epoch [77/100], Step [47000/6235], Loss: 5.8482\n",
      "Epoch [77/100], Step [47100/6235], Loss: 1.4759\n",
      "Epoch [77/100], Step [47200/6235], Loss: 20.1442\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [77/100], Step [47300/6235], Loss: 1.1530\n",
      "Epoch [77/100], Step [47400/6235], Loss: 19.2029\n",
      "Epoch [77/100], Step [47500/6235], Loss: 6.8500\n",
      "Epoch [77/100], Step [47600/6235], Loss: 5.3630\n",
      "Epoch [77/100], Step [47700/6235], Loss: 9.9763\n",
      "Epoch [77/100], Step [47800/6235], Loss: 8.0946\n",
      "Epoch [77/100], Step [47900/6235], Loss: 17.1060\n",
      "Epoch [77/100], Step [48000/6235], Loss: 40.2435\n",
      "Epoch [77/100], Step [48100/6235], Loss: 3.4521\n",
      "Epoch [77/100], Step [48200/6235], Loss: 16.6927\n",
      "Epoch [77/100], Step [48300/6235], Loss: 239.4691\n",
      "Epoch [77/100], Step [48400/6235], Loss: 20.7631\n",
      "Epoch [77/100], Step [48500/6235], Loss: 20.8009\n",
      "Epoch [77/100], Step [48600/6235], Loss: 166.2832\n",
      "Epoch [77/100], Step [48700/6235], Loss: 20.5273\n",
      "Epoch [77/100], Step [48800/6235], Loss: 204.3363\n",
      "Epoch [77/100], Step [48900/6235], Loss: 12.0706\n",
      "Epoch [77/100], Step [49000/6235], Loss: 170.7086\n",
      "Epoch [77/100], Step [49100/6235], Loss: 3403.6746\n",
      "Epoch [77/100], Step [49200/6235], Loss: 548.5589\n",
      "Epoch [77/100], Step [49300/6235], Loss: 1206.1664\n",
      "Epoch [77/100], Step [49400/6235], Loss: 165.0530\n",
      "Epoch [77/100], Step [49500/6235], Loss: 8.3881\n",
      "Epoch [77/100], Step [49600/6235], Loss: 67.7788\n",
      "Epoch [77/100], Step [49700/6235], Loss: 353.1470\n",
      "Epoch [77/100], Step [49800/6235], Loss: 1764.3308\n",
      "Epoch [78/100], Step [100/6235], Loss: 4.8199\n",
      "Epoch [78/100], Step [200/6235], Loss: 0.2485\n",
      "Epoch [78/100], Step [300/6235], Loss: 0.0302\n",
      "Epoch [78/100], Step [400/6235], Loss: 0.0114\n",
      "Epoch [78/100], Step [500/6235], Loss: 4.6728\n",
      "Epoch [78/100], Step [600/6235], Loss: 0.0595\n",
      "Epoch [78/100], Step [700/6235], Loss: 0.5425\n",
      "Epoch [78/100], Step [800/6235], Loss: 0.1261\n",
      "Epoch [78/100], Step [900/6235], Loss: 0.0532\n",
      "Epoch [78/100], Step [1000/6235], Loss: 0.0338\n",
      "Epoch [78/100], Step [1100/6235], Loss: 0.0843\n",
      "Epoch [78/100], Step [1200/6235], Loss: 0.2250\n",
      "Epoch [78/100], Step [1300/6235], Loss: 0.0428\n",
      "Epoch [78/100], Step [1400/6235], Loss: 0.0495\n",
      "Epoch [78/100], Step [1500/6235], Loss: 0.0092\n",
      "Epoch [78/100], Step [1600/6235], Loss: 0.2242\n",
      "Epoch [78/100], Step [1700/6235], Loss: 0.0102\n",
      "Epoch [78/100], Step [1800/6235], Loss: 0.2134\n",
      "Epoch [78/100], Step [1900/6235], Loss: 0.6155\n",
      "Epoch [78/100], Step [2000/6235], Loss: 2.1883\n",
      "Epoch [78/100], Step [2100/6235], Loss: 0.9530\n",
      "Epoch [78/100], Step [2200/6235], Loss: 9.6533\n",
      "Epoch [78/100], Step [2300/6235], Loss: 13.6384\n",
      "Epoch [78/100], Step [2400/6235], Loss: 4.3618\n",
      "Epoch [78/100], Step [2500/6235], Loss: 36.2576\n",
      "Epoch [78/100], Step [2600/6235], Loss: 10.9745\n",
      "Epoch [78/100], Step [2700/6235], Loss: 12.3458\n",
      "Epoch [78/100], Step [2800/6235], Loss: 616.4613\n",
      "Epoch [78/100], Step [2900/6235], Loss: 7.3697\n",
      "Epoch [78/100], Step [3000/6235], Loss: 1.6764\n",
      "Epoch [78/100], Step [3100/6235], Loss: 66.6427\n",
      "Epoch [78/100], Step [3200/6235], Loss: 85.9844\n",
      "Epoch [78/100], Step [3300/6235], Loss: 2.8293\n",
      "Epoch [78/100], Step [3400/6235], Loss: 3.0428\n",
      "Epoch [78/100], Step [3500/6235], Loss: 27.6195\n",
      "Epoch [78/100], Step [3600/6235], Loss: 10.2938\n",
      "Epoch [78/100], Step [3700/6235], Loss: 0.8853\n",
      "Epoch [78/100], Step [3800/6235], Loss: 0.5879\n",
      "Epoch [78/100], Step [3900/6235], Loss: 1.8191\n",
      "Epoch [78/100], Step [4000/6235], Loss: 0.0614\n",
      "Epoch [78/100], Step [4100/6235], Loss: 4.9615\n",
      "Epoch [78/100], Step [4200/6235], Loss: 0.2552\n",
      "Epoch [78/100], Step [4300/6235], Loss: 9.6446\n",
      "Epoch [78/100], Step [4400/6235], Loss: 4.2388\n",
      "Epoch [78/100], Step [4500/6235], Loss: 51.5198\n",
      "Epoch [78/100], Step [4600/6235], Loss: 9.0507\n",
      "Epoch [78/100], Step [4700/6235], Loss: 1.2469\n",
      "Epoch [78/100], Step [4800/6235], Loss: 2.1878\n",
      "Epoch [78/100], Step [4900/6235], Loss: 0.5482\n",
      "Epoch [78/100], Step [5000/6235], Loss: 0.3528\n",
      "Epoch [78/100], Step [5100/6235], Loss: 5.9317\n",
      "Epoch [78/100], Step [5200/6235], Loss: 16.2602\n",
      "Epoch [78/100], Step [5300/6235], Loss: 32.0534\n",
      "Epoch [78/100], Step [5400/6235], Loss: 0.0995\n",
      "Epoch [78/100], Step [5500/6235], Loss: 0.2670\n",
      "Epoch [78/100], Step [5600/6235], Loss: 0.3642\n",
      "Epoch [78/100], Step [5700/6235], Loss: 1.8712\n",
      "Epoch [78/100], Step [5800/6235], Loss: 1.1039\n",
      "Epoch [78/100], Step [5900/6235], Loss: 0.0568\n",
      "Epoch [78/100], Step [6000/6235], Loss: 0.3753\n",
      "Epoch [78/100], Step [6100/6235], Loss: 0.1076\n",
      "Epoch [78/100], Step [6200/6235], Loss: 0.7434\n",
      "Epoch [78/100], Step [6300/6235], Loss: 1.8983\n",
      "Epoch [78/100], Step [6400/6235], Loss: 0.0097\n",
      "Epoch [78/100], Step [6500/6235], Loss: 0.2247\n",
      "Epoch [78/100], Step [6600/6235], Loss: 3.2143\n",
      "Epoch [78/100], Step [6700/6235], Loss: 1.4879\n",
      "Epoch [78/100], Step [6800/6235], Loss: 0.7234\n",
      "Epoch [78/100], Step [6900/6235], Loss: 3.1285\n",
      "Epoch [78/100], Step [7000/6235], Loss: 1.7211\n",
      "Epoch [78/100], Step [7100/6235], Loss: 0.1408\n",
      "Epoch [78/100], Step [7200/6235], Loss: 0.6426\n",
      "Epoch [78/100], Step [7300/6235], Loss: 1.9547\n",
      "Epoch [78/100], Step [7400/6235], Loss: 0.1496\n",
      "Epoch [78/100], Step [7500/6235], Loss: 1.7700\n",
      "Epoch [78/100], Step [7600/6235], Loss: 17.9194\n",
      "Epoch [78/100], Step [7700/6235], Loss: 14.8223\n",
      "Epoch [78/100], Step [7800/6235], Loss: 13.6446\n",
      "Epoch [78/100], Step [7900/6235], Loss: 9.0120\n",
      "Epoch [78/100], Step [8000/6235], Loss: 0.1976\n",
      "Epoch [78/100], Step [8100/6235], Loss: 4.3068\n",
      "Epoch [78/100], Step [8200/6235], Loss: 18.7863\n",
      "Epoch [78/100], Step [8300/6235], Loss: 64.5972\n",
      "Epoch [78/100], Step [8400/6235], Loss: 136.4729\n",
      "Epoch [78/100], Step [8500/6235], Loss: 18.4239\n",
      "Epoch [78/100], Step [8600/6235], Loss: 125.3746\n",
      "Epoch [78/100], Step [8700/6235], Loss: 101.6081\n",
      "Epoch [78/100], Step [8800/6235], Loss: 436.0922\n",
      "Epoch [78/100], Step [8900/6235], Loss: 246.8257\n",
      "Epoch [78/100], Step [9000/6235], Loss: 249.6806\n",
      "Epoch [78/100], Step [9100/6235], Loss: 3129.1519\n",
      "Epoch [78/100], Step [9200/6235], Loss: 5977.3906\n",
      "Epoch [78/100], Step [9300/6235], Loss: 165.0474\n",
      "Epoch [78/100], Step [9400/6235], Loss: 186.5966\n",
      "Epoch [78/100], Step [9500/6235], Loss: 2770.1733\n",
      "Epoch [78/100], Step [9600/6235], Loss: 579.4427\n",
      "Epoch [78/100], Step [9700/6235], Loss: 6.6668\n",
      "Epoch [78/100], Step [9800/6235], Loss: 5106.5244\n",
      "Epoch [78/100], Step [9900/6235], Loss: 91.5269\n",
      "Epoch [78/100], Step [10000/6235], Loss: 90.2229\n",
      "Epoch [78/100], Step [10100/6235], Loss: 5.8086\n",
      "Epoch [78/100], Step [10200/6235], Loss: 569.2853\n",
      "Epoch [78/100], Step [10300/6235], Loss: 8.5654\n",
      "Epoch [78/100], Step [10400/6235], Loss: 9.6043\n",
      "Epoch [78/100], Step [10500/6235], Loss: 28.8788\n",
      "Epoch [78/100], Step [10600/6235], Loss: 287.0141\n",
      "Epoch [78/100], Step [10700/6235], Loss: 20.0042\n",
      "Epoch [78/100], Step [10800/6235], Loss: 70.5820\n",
      "Epoch [78/100], Step [10900/6235], Loss: 3.7126\n",
      "Epoch [78/100], Step [11000/6235], Loss: 289.5370\n",
      "Epoch [78/100], Step [11100/6235], Loss: 39.1676\n",
      "Epoch [78/100], Step [11200/6235], Loss: 35.0688\n",
      "Epoch [78/100], Step [11300/6235], Loss: 157.3929\n",
      "Epoch [78/100], Step [11400/6235], Loss: 4.2162\n",
      "Epoch [78/100], Step [11500/6235], Loss: 3.4366\n",
      "Epoch [78/100], Step [11600/6235], Loss: 2.2264\n",
      "Epoch [78/100], Step [11700/6235], Loss: 38.0140\n",
      "Epoch [78/100], Step [11800/6235], Loss: 401.4708\n",
      "Epoch [78/100], Step [11900/6235], Loss: 72.9123\n",
      "Epoch [78/100], Step [12000/6235], Loss: 648.7404\n",
      "Epoch [78/100], Step [12100/6235], Loss: 272.1568\n",
      "Epoch [78/100], Step [12200/6235], Loss: 30.1722\n",
      "Epoch [78/100], Step [12300/6235], Loss: 1.0343\n",
      "Epoch [78/100], Step [12400/6235], Loss: 107.5309\n",
      "Epoch [78/100], Step [12500/6235], Loss: 120.6047\n",
      "Epoch [78/100], Step [12600/6235], Loss: 0.1696\n",
      "Epoch [78/100], Step [12700/6235], Loss: 5.9467\n",
      "Epoch [78/100], Step [12800/6235], Loss: 11.0359\n",
      "Epoch [78/100], Step [12900/6235], Loss: 29.1673\n",
      "Epoch [78/100], Step [13000/6235], Loss: 0.0566\n",
      "Epoch [78/100], Step [13100/6235], Loss: 62.0941\n",
      "Epoch [78/100], Step [13200/6235], Loss: 7.8228\n",
      "Epoch [78/100], Step [13300/6235], Loss: 17.9425\n",
      "Epoch [78/100], Step [13400/6235], Loss: 204.3225\n",
      "Epoch [78/100], Step [13500/6235], Loss: 3.9476\n",
      "Epoch [78/100], Step [13600/6235], Loss: 7.7162\n",
      "Epoch [78/100], Step [13700/6235], Loss: 187.7995\n",
      "Epoch [78/100], Step [13800/6235], Loss: 73.4336\n",
      "Epoch [78/100], Step [13900/6235], Loss: 2.0443\n",
      "Epoch [78/100], Step [14000/6235], Loss: 5.0346\n",
      "Epoch [78/100], Step [14100/6235], Loss: 52.5187\n",
      "Epoch [78/100], Step [14200/6235], Loss: 14.4801\n",
      "Epoch [78/100], Step [14300/6235], Loss: 18.4696\n",
      "Epoch [78/100], Step [14400/6235], Loss: 34.1612\n",
      "Epoch [78/100], Step [14500/6235], Loss: 21.6497\n",
      "Epoch [78/100], Step [14600/6235], Loss: 3.3344\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Step [14700/6235], Loss: 18.8629\n",
      "Epoch [78/100], Step [14800/6235], Loss: 24.9714\n",
      "Epoch [78/100], Step [14900/6235], Loss: 0.8246\n",
      "Epoch [78/100], Step [15000/6235], Loss: 0.8546\n",
      "Epoch [78/100], Step [15100/6235], Loss: 0.2495\n",
      "Epoch [78/100], Step [15200/6235], Loss: 25.7848\n",
      "Epoch [78/100], Step [15300/6235], Loss: 40.7173\n",
      "Epoch [78/100], Step [15400/6235], Loss: 72.6164\n",
      "Epoch [78/100], Step [15500/6235], Loss: 16.8767\n",
      "Epoch [78/100], Step [15600/6235], Loss: 179.3231\n",
      "Epoch [78/100], Step [15700/6235], Loss: 90.2738\n",
      "Epoch [78/100], Step [15800/6235], Loss: 8.9405\n",
      "Epoch [78/100], Step [15900/6235], Loss: 0.6803\n",
      "Epoch [78/100], Step [16000/6235], Loss: 170.7025\n",
      "Epoch [78/100], Step [16100/6235], Loss: 0.6309\n",
      "Epoch [78/100], Step [16200/6235], Loss: 0.3012\n",
      "Epoch [78/100], Step [16300/6235], Loss: 9.0259\n",
      "Epoch [78/100], Step [16400/6235], Loss: 29.6493\n",
      "Epoch [78/100], Step [16500/6235], Loss: 196.5092\n",
      "Epoch [78/100], Step [16600/6235], Loss: 10.6858\n",
      "Epoch [78/100], Step [16700/6235], Loss: 0.4930\n",
      "Epoch [78/100], Step [16800/6235], Loss: 11.9057\n",
      "Epoch [78/100], Step [16900/6235], Loss: 0.2738\n",
      "Epoch [78/100], Step [17000/6235], Loss: 0.2339\n",
      "Epoch [78/100], Step [17100/6235], Loss: 0.1440\n",
      "Epoch [78/100], Step [17200/6235], Loss: 274.9057\n",
      "Epoch [78/100], Step [17300/6235], Loss: 3.2570\n",
      "Epoch [78/100], Step [17400/6235], Loss: 31.5717\n",
      "Epoch [78/100], Step [17500/6235], Loss: 0.6113\n",
      "Epoch [78/100], Step [17600/6235], Loss: 2.9057\n",
      "Epoch [78/100], Step [17700/6235], Loss: 8.6315\n",
      "Epoch [78/100], Step [17800/6235], Loss: 21.8654\n",
      "Epoch [78/100], Step [17900/6235], Loss: 7.8246\n",
      "Epoch [78/100], Step [18000/6235], Loss: 13.1868\n",
      "Epoch [78/100], Step [18100/6235], Loss: 19.0347\n",
      "Epoch [78/100], Step [18200/6235], Loss: 0.6726\n",
      "Epoch [78/100], Step [18300/6235], Loss: 5.7864\n",
      "Epoch [78/100], Step [18400/6235], Loss: 4.0242\n",
      "Epoch [78/100], Step [18500/6235], Loss: 15.0190\n",
      "Epoch [78/100], Step [18600/6235], Loss: 2.3485\n",
      "Epoch [78/100], Step [18700/6235], Loss: 0.4890\n",
      "Epoch [78/100], Step [18800/6235], Loss: 139.6962\n",
      "Epoch [78/100], Step [18900/6235], Loss: 1.1918\n",
      "Epoch [78/100], Step [19000/6235], Loss: 3.9792\n",
      "Epoch [78/100], Step [19100/6235], Loss: 5.4766\n",
      "Epoch [78/100], Step [19200/6235], Loss: 1.6656\n",
      "Epoch [78/100], Step [19300/6235], Loss: 5.6747\n",
      "Epoch [78/100], Step [19400/6235], Loss: 122.2388\n",
      "Epoch [78/100], Step [19500/6235], Loss: 199.3977\n",
      "Epoch [78/100], Step [19600/6235], Loss: 138.9827\n",
      "Epoch [78/100], Step [19700/6235], Loss: 30.1484\n",
      "Epoch [78/100], Step [19800/6235], Loss: 1.9631\n",
      "Epoch [78/100], Step [19900/6235], Loss: 0.9661\n",
      "Epoch [78/100], Step [20000/6235], Loss: 106.2748\n",
      "Epoch [78/100], Step [20100/6235], Loss: 17.5210\n",
      "Epoch [78/100], Step [20200/6235], Loss: 0.6926\n",
      "Epoch [78/100], Step [20300/6235], Loss: 0.1241\n",
      "Epoch [78/100], Step [20400/6235], Loss: 34.4599\n",
      "Epoch [78/100], Step [20500/6235], Loss: 25.2441\n",
      "Epoch [78/100], Step [20600/6235], Loss: 5.0903\n",
      "Epoch [78/100], Step [20700/6235], Loss: 24.5434\n",
      "Epoch [78/100], Step [20800/6235], Loss: 0.4429\n",
      "Epoch [78/100], Step [20900/6235], Loss: 28.4887\n",
      "Epoch [78/100], Step [21000/6235], Loss: 14.9685\n",
      "Epoch [78/100], Step [21100/6235], Loss: 4.1803\n",
      "Epoch [78/100], Step [21200/6235], Loss: 0.1769\n",
      "Epoch [78/100], Step [21300/6235], Loss: 0.1783\n",
      "Epoch [78/100], Step [21400/6235], Loss: 5.5284\n",
      "Epoch [78/100], Step [21500/6235], Loss: 2.9992\n",
      "Epoch [78/100], Step [21600/6235], Loss: 31.5056\n",
      "Epoch [78/100], Step [21700/6235], Loss: 0.4547\n",
      "Epoch [78/100], Step [21800/6235], Loss: 2.2508\n",
      "Epoch [78/100], Step [21900/6235], Loss: 0.1867\n",
      "Epoch [78/100], Step [22000/6235], Loss: 2.5504\n",
      "Epoch [78/100], Step [22100/6235], Loss: 4.5485\n",
      "Epoch [78/100], Step [22200/6235], Loss: 8.6365\n",
      "Epoch [78/100], Step [22300/6235], Loss: 0.3452\n",
      "Epoch [78/100], Step [22400/6235], Loss: 2.6492\n",
      "Epoch [78/100], Step [22500/6235], Loss: 85.3535\n",
      "Epoch [78/100], Step [22600/6235], Loss: 25.8529\n",
      "Epoch [78/100], Step [22700/6235], Loss: 2.0856\n",
      "Epoch [78/100], Step [22800/6235], Loss: 2.8181\n",
      "Epoch [78/100], Step [22900/6235], Loss: 4.9088\n",
      "Epoch [78/100], Step [23000/6235], Loss: 17.4154\n",
      "Epoch [78/100], Step [23100/6235], Loss: 1.2802\n",
      "Epoch [78/100], Step [23200/6235], Loss: 11.1479\n",
      "Epoch [78/100], Step [23300/6235], Loss: 4.8491\n",
      "Epoch [78/100], Step [23400/6235], Loss: 0.8295\n",
      "Epoch [78/100], Step [23500/6235], Loss: 0.2740\n",
      "Epoch [78/100], Step [23600/6235], Loss: 109.6071\n",
      "Epoch [78/100], Step [23700/6235], Loss: 4.8236\n",
      "Epoch [78/100], Step [23800/6235], Loss: 1.0280\n",
      "Epoch [78/100], Step [23900/6235], Loss: 7.6660\n",
      "Epoch [78/100], Step [24000/6235], Loss: 0.4259\n",
      "Epoch [78/100], Step [24100/6235], Loss: 0.3973\n",
      "Epoch [78/100], Step [24200/6235], Loss: 29.8247\n",
      "Epoch [78/100], Step [24300/6235], Loss: 1.5823\n",
      "Epoch [78/100], Step [24400/6235], Loss: 3.1641\n",
      "Epoch [78/100], Step [24500/6235], Loss: 1.6881\n",
      "Epoch [78/100], Step [24600/6235], Loss: 0.1365\n",
      "Epoch [78/100], Step [24700/6235], Loss: 2.3336\n",
      "Epoch [78/100], Step [24800/6235], Loss: 0.1219\n",
      "Epoch [78/100], Step [24900/6235], Loss: 17.3068\n",
      "Epoch [78/100], Step [25000/6235], Loss: 20.2357\n",
      "Epoch [78/100], Step [25100/6235], Loss: 7.2930\n",
      "Epoch [78/100], Step [25200/6235], Loss: 1.6620\n",
      "Epoch [78/100], Step [25300/6235], Loss: 0.6681\n",
      "Epoch [78/100], Step [25400/6235], Loss: 9.3016\n",
      "Epoch [78/100], Step [25500/6235], Loss: 4.8062\n",
      "Epoch [78/100], Step [25600/6235], Loss: 2.0334\n",
      "Epoch [78/100], Step [25700/6235], Loss: 0.2639\n",
      "Epoch [78/100], Step [25800/6235], Loss: 0.1963\n",
      "Epoch [78/100], Step [25900/6235], Loss: 10.4185\n",
      "Epoch [78/100], Step [26000/6235], Loss: 7.0065\n",
      "Epoch [78/100], Step [26100/6235], Loss: 0.4335\n",
      "Epoch [78/100], Step [26200/6235], Loss: 0.0424\n",
      "Epoch [78/100], Step [26300/6235], Loss: 4.4204\n",
      "Epoch [78/100], Step [26400/6235], Loss: 0.1770\n",
      "Epoch [78/100], Step [26500/6235], Loss: 0.2522\n",
      "Epoch [78/100], Step [26600/6235], Loss: 3.6080\n",
      "Epoch [78/100], Step [26700/6235], Loss: 0.7079\n",
      "Epoch [78/100], Step [26800/6235], Loss: 0.7484\n",
      "Epoch [78/100], Step [26900/6235], Loss: 0.0557\n",
      "Epoch [78/100], Step [27000/6235], Loss: 11.8396\n",
      "Epoch [78/100], Step [27100/6235], Loss: 0.2528\n",
      "Epoch [78/100], Step [27200/6235], Loss: 0.0985\n",
      "Epoch [78/100], Step [27300/6235], Loss: 0.1643\n",
      "Epoch [78/100], Step [27400/6235], Loss: 0.9658\n",
      "Epoch [78/100], Step [27500/6235], Loss: 13.6745\n",
      "Epoch [78/100], Step [27600/6235], Loss: 1.1089\n",
      "Epoch [78/100], Step [27700/6235], Loss: 1.3349\n",
      "Epoch [78/100], Step [27800/6235], Loss: 0.1439\n",
      "Epoch [78/100], Step [27900/6235], Loss: 0.9500\n",
      "Epoch [78/100], Step [28000/6235], Loss: 145.9264\n",
      "Epoch [78/100], Step [28100/6235], Loss: 6.2657\n",
      "Epoch [78/100], Step [28200/6235], Loss: 20.4667\n",
      "Epoch [78/100], Step [28300/6235], Loss: 3.5022\n",
      "Epoch [78/100], Step [28400/6235], Loss: 26.1201\n",
      "Epoch [78/100], Step [28500/6235], Loss: 3.4974\n",
      "Epoch [78/100], Step [28600/6235], Loss: 0.1499\n",
      "Epoch [78/100], Step [28700/6235], Loss: 5.1317\n",
      "Epoch [78/100], Step [28800/6235], Loss: 0.4892\n",
      "Epoch [78/100], Step [28900/6235], Loss: 74.4528\n",
      "Epoch [78/100], Step [29000/6235], Loss: 10.8732\n",
      "Epoch [78/100], Step [29100/6235], Loss: 0.0130\n",
      "Epoch [78/100], Step [29200/6235], Loss: 0.0685\n",
      "Epoch [78/100], Step [29300/6235], Loss: 18.4275\n",
      "Epoch [78/100], Step [29400/6235], Loss: 0.1103\n",
      "Epoch [78/100], Step [29500/6235], Loss: 1.4525\n",
      "Epoch [78/100], Step [29600/6235], Loss: 0.0213\n",
      "Epoch [78/100], Step [29700/6235], Loss: 0.7352\n",
      "Epoch [78/100], Step [29800/6235], Loss: 1.7336\n",
      "Epoch [78/100], Step [29900/6235], Loss: 0.6979\n",
      "Epoch [78/100], Step [30000/6235], Loss: 5.7055\n",
      "Epoch [78/100], Step [30100/6235], Loss: 11.7909\n",
      "Epoch [78/100], Step [30200/6235], Loss: 0.3332\n",
      "Epoch [78/100], Step [30300/6235], Loss: 0.1712\n",
      "Epoch [78/100], Step [30400/6235], Loss: 0.4164\n",
      "Epoch [78/100], Step [30500/6235], Loss: 2.8652\n",
      "Epoch [78/100], Step [30600/6235], Loss: 1.1155\n",
      "Epoch [78/100], Step [30700/6235], Loss: 0.0144\n",
      "Epoch [78/100], Step [30800/6235], Loss: 0.3350\n",
      "Epoch [78/100], Step [30900/6235], Loss: 3.8198\n",
      "Epoch [78/100], Step [31000/6235], Loss: 0.0238\n",
      "Epoch [78/100], Step [31100/6235], Loss: 0.0526\n",
      "Epoch [78/100], Step [31200/6235], Loss: 5.8181\n",
      "Epoch [78/100], Step [31300/6235], Loss: 2.4362\n",
      "Epoch [78/100], Step [31400/6235], Loss: 7.3926\n",
      "Epoch [78/100], Step [31500/6235], Loss: 0.6916\n",
      "Epoch [78/100], Step [31600/6235], Loss: 6.4333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Step [31700/6235], Loss: 12.0633\n",
      "Epoch [78/100], Step [31800/6235], Loss: 1.5400\n",
      "Epoch [78/100], Step [31900/6235], Loss: 859.7490\n",
      "Epoch [78/100], Step [32000/6235], Loss: 40.3372\n",
      "Epoch [78/100], Step [32100/6235], Loss: 0.9208\n",
      "Epoch [78/100], Step [32200/6235], Loss: 140.5942\n",
      "Epoch [78/100], Step [32300/6235], Loss: 1.5847\n",
      "Epoch [78/100], Step [32400/6235], Loss: 1.4858\n",
      "Epoch [78/100], Step [32500/6235], Loss: 17.2070\n",
      "Epoch [78/100], Step [32600/6235], Loss: 0.5887\n",
      "Epoch [78/100], Step [32700/6235], Loss: 69.9022\n",
      "Epoch [78/100], Step [32800/6235], Loss: 3.7934\n",
      "Epoch [78/100], Step [32900/6235], Loss: 5.6075\n",
      "Epoch [78/100], Step [33000/6235], Loss: 0.3610\n",
      "Epoch [78/100], Step [33100/6235], Loss: 1.1493\n",
      "Epoch [78/100], Step [33200/6235], Loss: 0.6543\n",
      "Epoch [78/100], Step [33300/6235], Loss: 0.7499\n",
      "Epoch [78/100], Step [33400/6235], Loss: 54.0224\n",
      "Epoch [78/100], Step [33500/6235], Loss: 0.7736\n",
      "Epoch [78/100], Step [33600/6235], Loss: 9.5166\n",
      "Epoch [78/100], Step [33700/6235], Loss: 14.0696\n",
      "Epoch [78/100], Step [33800/6235], Loss: 0.1932\n",
      "Epoch [78/100], Step [33900/6235], Loss: 33.0596\n",
      "Epoch [78/100], Step [34000/6235], Loss: 0.0982\n",
      "Epoch [78/100], Step [34100/6235], Loss: 0.6276\n",
      "Epoch [78/100], Step [34200/6235], Loss: 2.3895\n",
      "Epoch [78/100], Step [34300/6235], Loss: 3.4105\n",
      "Epoch [78/100], Step [34400/6235], Loss: 0.1885\n",
      "Epoch [78/100], Step [34500/6235], Loss: 22.2165\n",
      "Epoch [78/100], Step [34600/6235], Loss: 0.1448\n",
      "Epoch [78/100], Step [34700/6235], Loss: 22.6555\n",
      "Epoch [78/100], Step [34800/6235], Loss: 8.6663\n",
      "Epoch [78/100], Step [34900/6235], Loss: 65.1904\n",
      "Epoch [78/100], Step [35000/6235], Loss: 2.4755\n",
      "Epoch [78/100], Step [35100/6235], Loss: 0.4416\n",
      "Epoch [78/100], Step [35200/6235], Loss: 0.2152\n",
      "Epoch [78/100], Step [35300/6235], Loss: 2.8422\n",
      "Epoch [78/100], Step [35400/6235], Loss: 0.3912\n",
      "Epoch [78/100], Step [35500/6235], Loss: 1.2761\n",
      "Epoch [78/100], Step [35600/6235], Loss: 3.3898\n",
      "Epoch [78/100], Step [35700/6235], Loss: 5.2156\n",
      "Epoch [78/100], Step [35800/6235], Loss: 0.4975\n",
      "Epoch [78/100], Step [35900/6235], Loss: 0.3242\n",
      "Epoch [78/100], Step [36000/6235], Loss: 0.0415\n",
      "Epoch [78/100], Step [36100/6235], Loss: 0.0243\n",
      "Epoch [78/100], Step [36200/6235], Loss: 14.0086\n",
      "Epoch [78/100], Step [36300/6235], Loss: 1.0251\n",
      "Epoch [78/100], Step [36400/6235], Loss: 2.9731\n",
      "Epoch [78/100], Step [36500/6235], Loss: 8.1354\n",
      "Epoch [78/100], Step [36600/6235], Loss: 0.1115\n",
      "Epoch [78/100], Step [36700/6235], Loss: 0.5477\n",
      "Epoch [78/100], Step [36800/6235], Loss: 8.1539\n",
      "Epoch [78/100], Step [36900/6235], Loss: 11.1461\n",
      "Epoch [78/100], Step [37000/6235], Loss: 0.7968\n",
      "Epoch [78/100], Step [37100/6235], Loss: 1.6098\n",
      "Epoch [78/100], Step [37200/6235], Loss: 0.0595\n",
      "Epoch [78/100], Step [37300/6235], Loss: 0.0306\n",
      "Epoch [78/100], Step [37400/6235], Loss: 0.1914\n",
      "Epoch [78/100], Step [37500/6235], Loss: 5.6304\n",
      "Epoch [78/100], Step [37600/6235], Loss: 12.0674\n",
      "Epoch [78/100], Step [37700/6235], Loss: 1.9832\n",
      "Epoch [78/100], Step [37800/6235], Loss: 5.0506\n",
      "Epoch [78/100], Step [37900/6235], Loss: 5.4955\n",
      "Epoch [78/100], Step [38000/6235], Loss: 0.7507\n",
      "Epoch [78/100], Step [38100/6235], Loss: 3.2819\n",
      "Epoch [78/100], Step [38200/6235], Loss: 1.5875\n",
      "Epoch [78/100], Step [38300/6235], Loss: 0.4623\n",
      "Epoch [78/100], Step [38400/6235], Loss: 0.0637\n",
      "Epoch [78/100], Step [38500/6235], Loss: 1.9494\n",
      "Epoch [78/100], Step [38600/6235], Loss: 0.1972\n",
      "Epoch [78/100], Step [38700/6235], Loss: 0.1600\n",
      "Epoch [78/100], Step [38800/6235], Loss: 0.1537\n",
      "Epoch [78/100], Step [38900/6235], Loss: 26.9102\n",
      "Epoch [78/100], Step [39000/6235], Loss: 3.8312\n",
      "Epoch [78/100], Step [39100/6235], Loss: 0.6651\n",
      "Epoch [78/100], Step [39200/6235], Loss: 0.6300\n",
      "Epoch [78/100], Step [39300/6235], Loss: 8.4410\n",
      "Epoch [78/100], Step [39400/6235], Loss: 431.1930\n",
      "Epoch [78/100], Step [39500/6235], Loss: 4.6266\n",
      "Epoch [78/100], Step [39600/6235], Loss: 28.2400\n",
      "Epoch [78/100], Step [39700/6235], Loss: 259.3616\n",
      "Epoch [78/100], Step [39800/6235], Loss: 111.0580\n",
      "Epoch [78/100], Step [39900/6235], Loss: 0.4284\n",
      "Epoch [78/100], Step [40000/6235], Loss: 2.6285\n",
      "Epoch [78/100], Step [40100/6235], Loss: 30.8730\n",
      "Epoch [78/100], Step [40200/6235], Loss: 10.3953\n",
      "Epoch [78/100], Step [40300/6235], Loss: 1.4405\n",
      "Epoch [78/100], Step [40400/6235], Loss: 2.9424\n",
      "Epoch [78/100], Step [40500/6235], Loss: 2.0577\n",
      "Epoch [78/100], Step [40600/6235], Loss: 0.4729\n",
      "Epoch [78/100], Step [40700/6235], Loss: 7.6090\n",
      "Epoch [78/100], Step [40800/6235], Loss: 2.0284\n",
      "Epoch [78/100], Step [40900/6235], Loss: 0.0583\n",
      "Epoch [78/100], Step [41000/6235], Loss: 42.9926\n",
      "Epoch [78/100], Step [41100/6235], Loss: 5.6501\n",
      "Epoch [78/100], Step [41200/6235], Loss: 27.0193\n",
      "Epoch [78/100], Step [41300/6235], Loss: 3.2768\n",
      "Epoch [78/100], Step [41400/6235], Loss: 0.0847\n",
      "Epoch [78/100], Step [41500/6235], Loss: 1.3966\n",
      "Epoch [78/100], Step [41600/6235], Loss: 0.2187\n",
      "Epoch [78/100], Step [41700/6235], Loss: 3.5461\n",
      "Epoch [78/100], Step [41800/6235], Loss: 0.4319\n",
      "Epoch [78/100], Step [41900/6235], Loss: 3.3336\n",
      "Epoch [78/100], Step [42000/6235], Loss: 3.1150\n",
      "Epoch [78/100], Step [42100/6235], Loss: 7.4541\n",
      "Epoch [78/100], Step [42200/6235], Loss: 5.9581\n",
      "Epoch [78/100], Step [42300/6235], Loss: 1.8733\n",
      "Epoch [78/100], Step [42400/6235], Loss: 0.4850\n",
      "Epoch [78/100], Step [42500/6235], Loss: 0.8599\n",
      "Epoch [78/100], Step [42600/6235], Loss: 0.4747\n",
      "Epoch [78/100], Step [42700/6235], Loss: 0.1593\n",
      "Epoch [78/100], Step [42800/6235], Loss: 1.7115\n",
      "Epoch [78/100], Step [42900/6235], Loss: 4.0933\n",
      "Epoch [78/100], Step [43000/6235], Loss: 0.2528\n",
      "Epoch [78/100], Step [43100/6235], Loss: 0.7524\n",
      "Epoch [78/100], Step [43200/6235], Loss: 0.8916\n",
      "Epoch [78/100], Step [43300/6235], Loss: 9.2968\n",
      "Epoch [78/100], Step [43400/6235], Loss: 8.9970\n",
      "Epoch [78/100], Step [43500/6235], Loss: 9.3676\n",
      "Epoch [78/100], Step [43600/6235], Loss: 19.6952\n",
      "Epoch [78/100], Step [43700/6235], Loss: 38.0511\n",
      "Epoch [78/100], Step [43800/6235], Loss: 0.8141\n",
      "Epoch [78/100], Step [43900/6235], Loss: 1.4902\n",
      "Epoch [78/100], Step [44000/6235], Loss: 60.4854\n",
      "Epoch [78/100], Step [44100/6235], Loss: 2.4479\n",
      "Epoch [78/100], Step [44200/6235], Loss: 10.8728\n",
      "Epoch [78/100], Step [44300/6235], Loss: 46.3150\n",
      "Epoch [78/100], Step [44400/6235], Loss: 1.8362\n",
      "Epoch [78/100], Step [44500/6235], Loss: 2.4774\n",
      "Epoch [78/100], Step [44600/6235], Loss: 26.0522\n",
      "Epoch [78/100], Step [44700/6235], Loss: 7.1058\n",
      "Epoch [78/100], Step [44800/6235], Loss: 5.7839\n",
      "Epoch [78/100], Step [44900/6235], Loss: 9.1129\n",
      "Epoch [78/100], Step [45000/6235], Loss: 5.7808\n",
      "Epoch [78/100], Step [45100/6235], Loss: 30.2346\n",
      "Epoch [78/100], Step [45200/6235], Loss: 1.3615\n",
      "Epoch [78/100], Step [45300/6235], Loss: 26.8201\n",
      "Epoch [78/100], Step [45400/6235], Loss: 12.6890\n",
      "Epoch [78/100], Step [45500/6235], Loss: 1.9308\n",
      "Epoch [78/100], Step [45600/6235], Loss: 0.6451\n",
      "Epoch [78/100], Step [45700/6235], Loss: 112.9980\n",
      "Epoch [78/100], Step [45800/6235], Loss: 499.2017\n",
      "Epoch [78/100], Step [45900/6235], Loss: 17.3216\n",
      "Epoch [78/100], Step [46000/6235], Loss: 4.7147\n",
      "Epoch [78/100], Step [46100/6235], Loss: 14.3996\n",
      "Epoch [78/100], Step [46200/6235], Loss: 24.4997\n",
      "Epoch [78/100], Step [46300/6235], Loss: 38.6321\n",
      "Epoch [78/100], Step [46400/6235], Loss: 4.0998\n",
      "Epoch [78/100], Step [46500/6235], Loss: 47.9478\n",
      "Epoch [78/100], Step [46600/6235], Loss: 24.4509\n",
      "Epoch [78/100], Step [46700/6235], Loss: 4.9698\n",
      "Epoch [78/100], Step [46800/6235], Loss: 24.3665\n",
      "Epoch [78/100], Step [46900/6235], Loss: 5.3851\n",
      "Epoch [78/100], Step [47000/6235], Loss: 5.3803\n",
      "Epoch [78/100], Step [47100/6235], Loss: 3.9667\n",
      "Epoch [78/100], Step [47200/6235], Loss: 50.8052\n",
      "Epoch [78/100], Step [47300/6235], Loss: 0.8166\n",
      "Epoch [78/100], Step [47400/6235], Loss: 207.7957\n",
      "Epoch [78/100], Step [47500/6235], Loss: 0.5256\n",
      "Epoch [78/100], Step [47600/6235], Loss: 8.4620\n",
      "Epoch [78/100], Step [47700/6235], Loss: 44.3397\n",
      "Epoch [78/100], Step [47800/6235], Loss: 9.6867\n",
      "Epoch [78/100], Step [47900/6235], Loss: 16.4774\n",
      "Epoch [78/100], Step [48000/6235], Loss: 24.1374\n",
      "Epoch [78/100], Step [48100/6235], Loss: 4.9329\n",
      "Epoch [78/100], Step [48200/6235], Loss: 11.6945\n",
      "Epoch [78/100], Step [48300/6235], Loss: 455.8708\n",
      "Epoch [78/100], Step [48400/6235], Loss: 16.0522\n",
      "Epoch [78/100], Step [48500/6235], Loss: 39.1433\n",
      "Epoch [78/100], Step [48600/6235], Loss: 120.0685\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [78/100], Step [48700/6235], Loss: 0.6891\n",
      "Epoch [78/100], Step [48800/6235], Loss: 760.5222\n",
      "Epoch [78/100], Step [48900/6235], Loss: 284.3366\n",
      "Epoch [78/100], Step [49000/6235], Loss: 191.8299\n",
      "Epoch [78/100], Step [49100/6235], Loss: 3175.2700\n",
      "Epoch [78/100], Step [49200/6235], Loss: 857.8463\n",
      "Epoch [78/100], Step [49300/6235], Loss: 1045.7538\n",
      "Epoch [78/100], Step [49400/6235], Loss: 64.3718\n",
      "Epoch [78/100], Step [49500/6235], Loss: 25.4855\n",
      "Epoch [78/100], Step [49600/6235], Loss: 138.3923\n",
      "Epoch [78/100], Step [49700/6235], Loss: 6120.0244\n",
      "Epoch [78/100], Step [49800/6235], Loss: 386.0220\n",
      "Epoch [79/100], Step [100/6235], Loss: 25.3774\n",
      "Epoch [79/100], Step [200/6235], Loss: 0.1267\n",
      "Epoch [79/100], Step [300/6235], Loss: 0.0072\n",
      "Epoch [79/100], Step [400/6235], Loss: 0.0051\n",
      "Epoch [79/100], Step [500/6235], Loss: 5.6398\n",
      "Epoch [79/100], Step [600/6235], Loss: 0.0367\n",
      "Epoch [79/100], Step [700/6235], Loss: 0.5216\n",
      "Epoch [79/100], Step [800/6235], Loss: 0.1384\n",
      "Epoch [79/100], Step [900/6235], Loss: 0.0414\n",
      "Epoch [79/100], Step [1000/6235], Loss: 0.0345\n",
      "Epoch [79/100], Step [1100/6235], Loss: 0.0508\n",
      "Epoch [79/100], Step [1200/6235], Loss: 0.1729\n",
      "Epoch [79/100], Step [1300/6235], Loss: 0.0316\n",
      "Epoch [79/100], Step [1400/6235], Loss: 0.0552\n",
      "Epoch [79/100], Step [1500/6235], Loss: 0.0053\n",
      "Epoch [79/100], Step [1600/6235], Loss: 0.2255\n",
      "Epoch [79/100], Step [1700/6235], Loss: 0.0322\n",
      "Epoch [79/100], Step [1800/6235], Loss: 0.1971\n",
      "Epoch [79/100], Step [1900/6235], Loss: 0.4603\n",
      "Epoch [79/100], Step [2000/6235], Loss: 2.2408\n",
      "Epoch [79/100], Step [2100/6235], Loss: 3.0462\n",
      "Epoch [79/100], Step [2200/6235], Loss: 8.7807\n",
      "Epoch [79/100], Step [2300/6235], Loss: 8.9517\n",
      "Epoch [79/100], Step [2400/6235], Loss: 3.1598\n",
      "Epoch [79/100], Step [2500/6235], Loss: 37.3570\n",
      "Epoch [79/100], Step [2600/6235], Loss: 11.8666\n",
      "Epoch [79/100], Step [2700/6235], Loss: 14.3714\n",
      "Epoch [79/100], Step [2800/6235], Loss: 537.0535\n",
      "Epoch [79/100], Step [2900/6235], Loss: 7.0693\n",
      "Epoch [79/100], Step [3000/6235], Loss: 0.2760\n",
      "Epoch [79/100], Step [3100/6235], Loss: 65.8301\n",
      "Epoch [79/100], Step [3200/6235], Loss: 85.7672\n",
      "Epoch [79/100], Step [3300/6235], Loss: 1.9772\n",
      "Epoch [79/100], Step [3400/6235], Loss: 2.6668\n",
      "Epoch [79/100], Step [3500/6235], Loss: 29.6503\n",
      "Epoch [79/100], Step [3600/6235], Loss: 10.4405\n",
      "Epoch [79/100], Step [3700/6235], Loss: 1.0957\n",
      "Epoch [79/100], Step [3800/6235], Loss: 0.5728\n",
      "Epoch [79/100], Step [3900/6235], Loss: 1.9629\n",
      "Epoch [79/100], Step [4000/6235], Loss: 0.0662\n",
      "Epoch [79/100], Step [4100/6235], Loss: 4.7298\n",
      "Epoch [79/100], Step [4200/6235], Loss: 0.4689\n",
      "Epoch [79/100], Step [4300/6235], Loss: 10.6207\n",
      "Epoch [79/100], Step [4400/6235], Loss: 4.3993\n",
      "Epoch [79/100], Step [4500/6235], Loss: 52.6236\n",
      "Epoch [79/100], Step [4600/6235], Loss: 14.1832\n",
      "Epoch [79/100], Step [4700/6235], Loss: 1.2615\n",
      "Epoch [79/100], Step [4800/6235], Loss: 1.6359\n",
      "Epoch [79/100], Step [4900/6235], Loss: 0.0940\n",
      "Epoch [79/100], Step [5000/6235], Loss: 0.2573\n",
      "Epoch [79/100], Step [5100/6235], Loss: 5.5331\n",
      "Epoch [79/100], Step [5200/6235], Loss: 13.2151\n",
      "Epoch [79/100], Step [5300/6235], Loss: 31.3235\n",
      "Epoch [79/100], Step [5400/6235], Loss: 0.2231\n",
      "Epoch [79/100], Step [5500/6235], Loss: 0.2403\n",
      "Epoch [79/100], Step [5600/6235], Loss: 0.4133\n",
      "Epoch [79/100], Step [5700/6235], Loss: 2.0256\n",
      "Epoch [79/100], Step [5800/6235], Loss: 0.9858\n",
      "Epoch [79/100], Step [5900/6235], Loss: 0.0111\n",
      "Epoch [79/100], Step [6000/6235], Loss: 0.7502\n",
      "Epoch [79/100], Step [6100/6235], Loss: 0.2520\n",
      "Epoch [79/100], Step [6200/6235], Loss: 0.6288\n",
      "Epoch [79/100], Step [6300/6235], Loss: 2.1173\n",
      "Epoch [79/100], Step [6400/6235], Loss: 0.0954\n",
      "Epoch [79/100], Step [6500/6235], Loss: 1.1239\n",
      "Epoch [79/100], Step [6600/6235], Loss: 3.9493\n",
      "Epoch [79/100], Step [6700/6235], Loss: 0.6486\n",
      "Epoch [79/100], Step [6800/6235], Loss: 0.6569\n",
      "Epoch [79/100], Step [6900/6235], Loss: 2.9389\n",
      "Epoch [79/100], Step [7000/6235], Loss: 0.5352\n",
      "Epoch [79/100], Step [7100/6235], Loss: 0.1956\n",
      "Epoch [79/100], Step [7200/6235], Loss: 0.2298\n",
      "Epoch [79/100], Step [7300/6235], Loss: 0.8432\n",
      "Epoch [79/100], Step [7400/6235], Loss: 0.0179\n",
      "Epoch [79/100], Step [7500/6235], Loss: 8.1282\n",
      "Epoch [79/100], Step [7600/6235], Loss: 1.6075\n",
      "Epoch [79/100], Step [7700/6235], Loss: 4.2260\n",
      "Epoch [79/100], Step [7800/6235], Loss: 6.7454\n",
      "Epoch [79/100], Step [7900/6235], Loss: 18.8114\n",
      "Epoch [79/100], Step [8000/6235], Loss: 0.4873\n",
      "Epoch [79/100], Step [8100/6235], Loss: 3.5560\n",
      "Epoch [79/100], Step [8200/6235], Loss: 22.8308\n",
      "Epoch [79/100], Step [8300/6235], Loss: 64.2319\n",
      "Epoch [79/100], Step [8400/6235], Loss: 36.4781\n",
      "Epoch [79/100], Step [8500/6235], Loss: 67.5372\n",
      "Epoch [79/100], Step [8600/6235], Loss: 0.3658\n",
      "Epoch [79/100], Step [8700/6235], Loss: 61.9341\n",
      "Epoch [79/100], Step [8800/6235], Loss: 783.1132\n",
      "Epoch [79/100], Step [8900/6235], Loss: 211.9447\n",
      "Epoch [79/100], Step [9000/6235], Loss: 533.9639\n",
      "Epoch [79/100], Step [9100/6235], Loss: 2696.6431\n",
      "Epoch [79/100], Step [9200/6235], Loss: 6008.1895\n",
      "Epoch [79/100], Step [9300/6235], Loss: 127.5507\n",
      "Epoch [79/100], Step [9400/6235], Loss: 7.5566\n",
      "Epoch [79/100], Step [9500/6235], Loss: 1967.5767\n",
      "Epoch [79/100], Step [9600/6235], Loss: 960.1252\n",
      "Epoch [79/100], Step [9700/6235], Loss: 6.5910\n",
      "Epoch [79/100], Step [9800/6235], Loss: 2662.4390\n",
      "Epoch [79/100], Step [9900/6235], Loss: 164.7975\n",
      "Epoch [79/100], Step [10000/6235], Loss: 358.9524\n",
      "Epoch [79/100], Step [10100/6235], Loss: 4.8986\n",
      "Epoch [79/100], Step [10200/6235], Loss: 565.3809\n",
      "Epoch [79/100], Step [10300/6235], Loss: 22.3463\n",
      "Epoch [79/100], Step [10400/6235], Loss: 8.3003\n",
      "Epoch [79/100], Step [10500/6235], Loss: 26.3214\n",
      "Epoch [79/100], Step [10600/6235], Loss: 151.4631\n",
      "Epoch [79/100], Step [10700/6235], Loss: 13.0108\n",
      "Epoch [79/100], Step [10800/6235], Loss: 104.4779\n",
      "Epoch [79/100], Step [10900/6235], Loss: 27.7705\n",
      "Epoch [79/100], Step [11000/6235], Loss: 296.4254\n",
      "Epoch [79/100], Step [11100/6235], Loss: 47.6365\n",
      "Epoch [79/100], Step [11200/6235], Loss: 19.1692\n",
      "Epoch [79/100], Step [11300/6235], Loss: 130.5493\n",
      "Epoch [79/100], Step [11400/6235], Loss: 0.7194\n",
      "Epoch [79/100], Step [11500/6235], Loss: 5.4217\n",
      "Epoch [79/100], Step [11600/6235], Loss: 3.5699\n",
      "Epoch [79/100], Step [11700/6235], Loss: 39.0808\n",
      "Epoch [79/100], Step [11800/6235], Loss: 422.5028\n",
      "Epoch [79/100], Step [11900/6235], Loss: 422.3578\n",
      "Epoch [79/100], Step [12000/6235], Loss: 179.8964\n",
      "Epoch [79/100], Step [12100/6235], Loss: 189.5139\n",
      "Epoch [79/100], Step [12200/6235], Loss: 149.0091\n",
      "Epoch [79/100], Step [12300/6235], Loss: 40.6010\n",
      "Epoch [79/100], Step [12400/6235], Loss: 132.8754\n",
      "Epoch [79/100], Step [12500/6235], Loss: 3.0962\n",
      "Epoch [79/100], Step [12600/6235], Loss: 119.7098\n",
      "Epoch [79/100], Step [12700/6235], Loss: 4.3216\n",
      "Epoch [79/100], Step [12800/6235], Loss: 4.4854\n",
      "Epoch [79/100], Step [12900/6235], Loss: 38.4630\n",
      "Epoch [79/100], Step [13000/6235], Loss: 0.5291\n",
      "Epoch [79/100], Step [13100/6235], Loss: 67.9277\n",
      "Epoch [79/100], Step [13200/6235], Loss: 14.7953\n",
      "Epoch [79/100], Step [13300/6235], Loss: 63.7647\n",
      "Epoch [79/100], Step [13400/6235], Loss: 248.9220\n",
      "Epoch [79/100], Step [13500/6235], Loss: 10.1779\n",
      "Epoch [79/100], Step [13600/6235], Loss: 23.4336\n",
      "Epoch [79/100], Step [13700/6235], Loss: 6.3865\n",
      "Epoch [79/100], Step [13800/6235], Loss: 167.3323\n",
      "Epoch [79/100], Step [13900/6235], Loss: 59.9261\n",
      "Epoch [79/100], Step [14000/6235], Loss: 14.1943\n",
      "Epoch [79/100], Step [14100/6235], Loss: 7.3488\n",
      "Epoch [79/100], Step [14200/6235], Loss: 82.1832\n",
      "Epoch [79/100], Step [14300/6235], Loss: 80.6204\n",
      "Epoch [79/100], Step [14400/6235], Loss: 38.0094\n",
      "Epoch [79/100], Step [14500/6235], Loss: 67.3613\n",
      "Epoch [79/100], Step [14600/6235], Loss: 0.3511\n",
      "Epoch [79/100], Step [14700/6235], Loss: 45.2945\n",
      "Epoch [79/100], Step [14800/6235], Loss: 31.8852\n",
      "Epoch [79/100], Step [14900/6235], Loss: 1.6835\n",
      "Epoch [79/100], Step [15000/6235], Loss: 2.7020\n",
      "Epoch [79/100], Step [15100/6235], Loss: 0.2547\n",
      "Epoch [79/100], Step [15200/6235], Loss: 4.9395\n",
      "Epoch [79/100], Step [15300/6235], Loss: 47.1271\n",
      "Epoch [79/100], Step [15400/6235], Loss: 101.5195\n",
      "Epoch [79/100], Step [15500/6235], Loss: 9.6860\n",
      "Epoch [79/100], Step [15600/6235], Loss: 94.3960\n",
      "Epoch [79/100], Step [15700/6235], Loss: 11.3219\n",
      "Epoch [79/100], Step [15800/6235], Loss: 3.6005\n",
      "Epoch [79/100], Step [15900/6235], Loss: 0.8465\n",
      "Epoch [79/100], Step [16000/6235], Loss: 39.4593\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Step [16100/6235], Loss: 14.6352\n",
      "Epoch [79/100], Step [16200/6235], Loss: 0.5627\n",
      "Epoch [79/100], Step [16300/6235], Loss: 10.9658\n",
      "Epoch [79/100], Step [16400/6235], Loss: 32.6077\n",
      "Epoch [79/100], Step [16500/6235], Loss: 678.4647\n",
      "Epoch [79/100], Step [16600/6235], Loss: 11.7911\n",
      "Epoch [79/100], Step [16700/6235], Loss: 0.6124\n",
      "Epoch [79/100], Step [16800/6235], Loss: 9.8064\n",
      "Epoch [79/100], Step [16900/6235], Loss: 0.0870\n",
      "Epoch [79/100], Step [17000/6235], Loss: 0.2420\n",
      "Epoch [79/100], Step [17100/6235], Loss: 0.3025\n",
      "Epoch [79/100], Step [17200/6235], Loss: 298.8851\n",
      "Epoch [79/100], Step [17300/6235], Loss: 43.5706\n",
      "Epoch [79/100], Step [17400/6235], Loss: 35.0645\n",
      "Epoch [79/100], Step [17500/6235], Loss: 0.3655\n",
      "Epoch [79/100], Step [17600/6235], Loss: 3.5821\n",
      "Epoch [79/100], Step [17700/6235], Loss: 53.1038\n",
      "Epoch [79/100], Step [17800/6235], Loss: 19.3400\n",
      "Epoch [79/100], Step [17900/6235], Loss: 14.2938\n",
      "Epoch [79/100], Step [18000/6235], Loss: 4.1512\n",
      "Epoch [79/100], Step [18100/6235], Loss: 15.2348\n",
      "Epoch [79/100], Step [18200/6235], Loss: 0.3208\n",
      "Epoch [79/100], Step [18300/6235], Loss: 1.9635\n",
      "Epoch [79/100], Step [18400/6235], Loss: 0.7817\n",
      "Epoch [79/100], Step [18500/6235], Loss: 22.8952\n",
      "Epoch [79/100], Step [18600/6235], Loss: 3.4540\n",
      "Epoch [79/100], Step [18700/6235], Loss: 0.7752\n",
      "Epoch [79/100], Step [18800/6235], Loss: 146.3808\n",
      "Epoch [79/100], Step [18900/6235], Loss: 65.3043\n",
      "Epoch [79/100], Step [19000/6235], Loss: 2.5845\n",
      "Epoch [79/100], Step [19100/6235], Loss: 47.2027\n",
      "Epoch [79/100], Step [19200/6235], Loss: 0.6491\n",
      "Epoch [79/100], Step [19300/6235], Loss: 0.2526\n",
      "Epoch [79/100], Step [19400/6235], Loss: 15.7858\n",
      "Epoch [79/100], Step [19500/6235], Loss: 55.1441\n",
      "Epoch [79/100], Step [19600/6235], Loss: 58.6622\n",
      "Epoch [79/100], Step [19700/6235], Loss: 2.5055\n",
      "Epoch [79/100], Step [19800/6235], Loss: 4.4349\n",
      "Epoch [79/100], Step [19900/6235], Loss: 0.1076\n",
      "Epoch [79/100], Step [20000/6235], Loss: 67.9756\n",
      "Epoch [79/100], Step [20100/6235], Loss: 4.0515\n",
      "Epoch [79/100], Step [20200/6235], Loss: 0.5385\n",
      "Epoch [79/100], Step [20300/6235], Loss: 1.2060\n",
      "Epoch [79/100], Step [20400/6235], Loss: 7.9353\n",
      "Epoch [79/100], Step [20500/6235], Loss: 57.0300\n",
      "Epoch [79/100], Step [20600/6235], Loss: 219.7997\n",
      "Epoch [79/100], Step [20700/6235], Loss: 22.0829\n",
      "Epoch [79/100], Step [20800/6235], Loss: 4.1306\n",
      "Epoch [79/100], Step [20900/6235], Loss: 1.9105\n",
      "Epoch [79/100], Step [21000/6235], Loss: 22.6235\n",
      "Epoch [79/100], Step [21100/6235], Loss: 6.6346\n",
      "Epoch [79/100], Step [21200/6235], Loss: 0.2966\n",
      "Epoch [79/100], Step [21300/6235], Loss: 0.0754\n",
      "Epoch [79/100], Step [21400/6235], Loss: 3.7555\n",
      "Epoch [79/100], Step [21500/6235], Loss: 1.8144\n",
      "Epoch [79/100], Step [21600/6235], Loss: 22.2635\n",
      "Epoch [79/100], Step [21700/6235], Loss: 0.1653\n",
      "Epoch [79/100], Step [21800/6235], Loss: 3.3142\n",
      "Epoch [79/100], Step [21900/6235], Loss: 1.6086\n",
      "Epoch [79/100], Step [22000/6235], Loss: 9.3243\n",
      "Epoch [79/100], Step [22100/6235], Loss: 0.1372\n",
      "Epoch [79/100], Step [22200/6235], Loss: 4.6338\n",
      "Epoch [79/100], Step [22300/6235], Loss: 0.3975\n",
      "Epoch [79/100], Step [22400/6235], Loss: 9.0658\n",
      "Epoch [79/100], Step [22500/6235], Loss: 101.8613\n",
      "Epoch [79/100], Step [22600/6235], Loss: 39.1302\n",
      "Epoch [79/100], Step [22700/6235], Loss: 1.9549\n",
      "Epoch [79/100], Step [22800/6235], Loss: 10.3741\n",
      "Epoch [79/100], Step [22900/6235], Loss: 3.6818\n",
      "Epoch [79/100], Step [23000/6235], Loss: 6.9060\n",
      "Epoch [79/100], Step [23100/6235], Loss: 7.2137\n",
      "Epoch [79/100], Step [23200/6235], Loss: 8.9302\n",
      "Epoch [79/100], Step [23300/6235], Loss: 18.7862\n",
      "Epoch [79/100], Step [23400/6235], Loss: 2.1356\n",
      "Epoch [79/100], Step [23500/6235], Loss: 0.0656\n",
      "Epoch [79/100], Step [23600/6235], Loss: 132.0716\n",
      "Epoch [79/100], Step [23700/6235], Loss: 3.2353\n",
      "Epoch [79/100], Step [23800/6235], Loss: 0.8546\n",
      "Epoch [79/100], Step [23900/6235], Loss: 3.1800\n",
      "Epoch [79/100], Step [24000/6235], Loss: 1.2717\n",
      "Epoch [79/100], Step [24100/6235], Loss: 2.1220\n",
      "Epoch [79/100], Step [24200/6235], Loss: 44.6542\n",
      "Epoch [79/100], Step [24300/6235], Loss: 0.8094\n",
      "Epoch [79/100], Step [24400/6235], Loss: 1.0695\n",
      "Epoch [79/100], Step [24500/6235], Loss: 0.3614\n",
      "Epoch [79/100], Step [24600/6235], Loss: 0.1239\n",
      "Epoch [79/100], Step [24700/6235], Loss: 0.1330\n",
      "Epoch [79/100], Step [24800/6235], Loss: 0.2799\n",
      "Epoch [79/100], Step [24900/6235], Loss: 11.1363\n",
      "Epoch [79/100], Step [25000/6235], Loss: 12.2039\n",
      "Epoch [79/100], Step [25100/6235], Loss: 6.3742\n",
      "Epoch [79/100], Step [25200/6235], Loss: 0.1927\n",
      "Epoch [79/100], Step [25300/6235], Loss: 0.9072\n",
      "Epoch [79/100], Step [25400/6235], Loss: 8.5373\n",
      "Epoch [79/100], Step [25500/6235], Loss: 8.9680\n",
      "Epoch [79/100], Step [25600/6235], Loss: 7.3133\n",
      "Epoch [79/100], Step [25700/6235], Loss: 0.1418\n",
      "Epoch [79/100], Step [25800/6235], Loss: 0.1367\n",
      "Epoch [79/100], Step [25900/6235], Loss: 5.4814\n",
      "Epoch [79/100], Step [26000/6235], Loss: 1.5159\n",
      "Epoch [79/100], Step [26100/6235], Loss: 0.1923\n",
      "Epoch [79/100], Step [26200/6235], Loss: 1.2242\n",
      "Epoch [79/100], Step [26300/6235], Loss: 2.1757\n",
      "Epoch [79/100], Step [26400/6235], Loss: 0.3171\n",
      "Epoch [79/100], Step [26500/6235], Loss: 0.0342\n",
      "Epoch [79/100], Step [26600/6235], Loss: 0.5389\n",
      "Epoch [79/100], Step [26700/6235], Loss: 0.1985\n",
      "Epoch [79/100], Step [26800/6235], Loss: 0.1101\n",
      "Epoch [79/100], Step [26900/6235], Loss: 0.0327\n",
      "Epoch [79/100], Step [27000/6235], Loss: 16.1891\n",
      "Epoch [79/100], Step [27100/6235], Loss: 0.0595\n",
      "Epoch [79/100], Step [27200/6235], Loss: 0.0109\n",
      "Epoch [79/100], Step [27300/6235], Loss: 0.0840\n",
      "Epoch [79/100], Step [27400/6235], Loss: 0.6582\n",
      "Epoch [79/100], Step [27500/6235], Loss: 2.3209\n",
      "Epoch [79/100], Step [27600/6235], Loss: 0.7236\n",
      "Epoch [79/100], Step [27700/6235], Loss: 0.8498\n",
      "Epoch [79/100], Step [27800/6235], Loss: 5.0650\n",
      "Epoch [79/100], Step [27900/6235], Loss: 0.3767\n",
      "Epoch [79/100], Step [28000/6235], Loss: 148.2652\n",
      "Epoch [79/100], Step [28100/6235], Loss: 0.4397\n",
      "Epoch [79/100], Step [28200/6235], Loss: 23.7956\n",
      "Epoch [79/100], Step [28300/6235], Loss: 2.9088\n",
      "Epoch [79/100], Step [28400/6235], Loss: 27.3619\n",
      "Epoch [79/100], Step [28500/6235], Loss: 4.0372\n",
      "Epoch [79/100], Step [28600/6235], Loss: 0.7005\n",
      "Epoch [79/100], Step [28700/6235], Loss: 4.2329\n",
      "Epoch [79/100], Step [28800/6235], Loss: 0.6567\n",
      "Epoch [79/100], Step [28900/6235], Loss: 57.9313\n",
      "Epoch [79/100], Step [29000/6235], Loss: 1.7790\n",
      "Epoch [79/100], Step [29100/6235], Loss: 0.2022\n",
      "Epoch [79/100], Step [29200/6235], Loss: 3.7090\n",
      "Epoch [79/100], Step [29300/6235], Loss: 0.0694\n",
      "Epoch [79/100], Step [29400/6235], Loss: 1.0382\n",
      "Epoch [79/100], Step [29500/6235], Loss: 3.9302\n",
      "Epoch [79/100], Step [29600/6235], Loss: 0.4376\n",
      "Epoch [79/100], Step [29700/6235], Loss: 1.8514\n",
      "Epoch [79/100], Step [29800/6235], Loss: 1.2186\n",
      "Epoch [79/100], Step [29900/6235], Loss: 0.2175\n",
      "Epoch [79/100], Step [30000/6235], Loss: 5.7204\n",
      "Epoch [79/100], Step [30100/6235], Loss: 8.3786\n",
      "Epoch [79/100], Step [30200/6235], Loss: 1.7249\n",
      "Epoch [79/100], Step [30300/6235], Loss: 0.0924\n",
      "Epoch [79/100], Step [30400/6235], Loss: 1.8133\n",
      "Epoch [79/100], Step [30500/6235], Loss: 1.3856\n",
      "Epoch [79/100], Step [30600/6235], Loss: 0.5554\n",
      "Epoch [79/100], Step [30700/6235], Loss: 1.6436\n",
      "Epoch [79/100], Step [30800/6235], Loss: 0.5551\n",
      "Epoch [79/100], Step [30900/6235], Loss: 2.5338\n",
      "Epoch [79/100], Step [31000/6235], Loss: 0.3294\n",
      "Epoch [79/100], Step [31100/6235], Loss: 0.0923\n",
      "Epoch [79/100], Step [31200/6235], Loss: 6.5771\n",
      "Epoch [79/100], Step [31300/6235], Loss: 0.9753\n",
      "Epoch [79/100], Step [31400/6235], Loss: 10.8817\n",
      "Epoch [79/100], Step [31500/6235], Loss: 0.8887\n",
      "Epoch [79/100], Step [31600/6235], Loss: 6.1472\n",
      "Epoch [79/100], Step [31700/6235], Loss: 59.8481\n",
      "Epoch [79/100], Step [31800/6235], Loss: 0.5280\n",
      "Epoch [79/100], Step [31900/6235], Loss: 381.1637\n",
      "Epoch [79/100], Step [32000/6235], Loss: 25.9312\n",
      "Epoch [79/100], Step [32100/6235], Loss: 0.4305\n",
      "Epoch [79/100], Step [32200/6235], Loss: 143.8228\n",
      "Epoch [79/100], Step [32300/6235], Loss: 1.7581\n",
      "Epoch [79/100], Step [32400/6235], Loss: 1.4256\n",
      "Epoch [79/100], Step [32500/6235], Loss: 9.4379\n",
      "Epoch [79/100], Step [32600/6235], Loss: 0.3176\n",
      "Epoch [79/100], Step [32700/6235], Loss: 105.1142\n",
      "Epoch [79/100], Step [32800/6235], Loss: 7.5811\n",
      "Epoch [79/100], Step [32900/6235], Loss: 0.2999\n",
      "Epoch [79/100], Step [33000/6235], Loss: 0.3271\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [79/100], Step [33100/6235], Loss: 0.6293\n",
      "Epoch [79/100], Step [33200/6235], Loss: 1.1416\n",
      "Epoch [79/100], Step [33300/6235], Loss: 4.1497\n",
      "Epoch [79/100], Step [33400/6235], Loss: 27.9587\n",
      "Epoch [79/100], Step [33500/6235], Loss: 1.1997\n",
      "Epoch [79/100], Step [33600/6235], Loss: 9.8785\n",
      "Epoch [79/100], Step [33700/6235], Loss: 14.6062\n",
      "Epoch [79/100], Step [33800/6235], Loss: 0.5017\n",
      "Epoch [79/100], Step [33900/6235], Loss: 30.8533\n",
      "Epoch [79/100], Step [34000/6235], Loss: 0.1025\n",
      "Epoch [79/100], Step [34100/6235], Loss: 0.6474\n",
      "Epoch [79/100], Step [34200/6235], Loss: 2.9013\n",
      "Epoch [79/100], Step [34300/6235], Loss: 3.0104\n",
      "Epoch [79/100], Step [34400/6235], Loss: 0.2281\n",
      "Epoch [79/100], Step [34500/6235], Loss: 42.8177\n",
      "Epoch [79/100], Step [34600/6235], Loss: 2.1540\n",
      "Epoch [79/100], Step [34700/6235], Loss: 20.9668\n",
      "Epoch [79/100], Step [34800/6235], Loss: 13.2492\n",
      "Epoch [79/100], Step [34900/6235], Loss: 68.2112\n",
      "Epoch [79/100], Step [35000/6235], Loss: 0.2377\n",
      "Epoch [79/100], Step [35100/6235], Loss: 0.7066\n",
      "Epoch [79/100], Step [35200/6235], Loss: 0.5730\n",
      "Epoch [79/100], Step [35300/6235], Loss: 3.1230\n",
      "Epoch [79/100], Step [35400/6235], Loss: 0.5289\n",
      "Epoch [79/100], Step [35500/6235], Loss: 0.7012\n",
      "Epoch [79/100], Step [35600/6235], Loss: 0.4403\n",
      "Epoch [79/100], Step [35700/6235], Loss: 4.8817\n",
      "Epoch [79/100], Step [35800/6235], Loss: 0.3493\n",
      "Epoch [79/100], Step [35900/6235], Loss: 0.9662\n",
      "Epoch [79/100], Step [36000/6235], Loss: 0.0398\n",
      "Epoch [79/100], Step [36100/6235], Loss: 0.0330\n",
      "Epoch [79/100], Step [36200/6235], Loss: 29.5190\n",
      "Epoch [79/100], Step [36300/6235], Loss: 2.2696\n",
      "Epoch [79/100], Step [36400/6235], Loss: 2.8527\n",
      "Epoch [79/100], Step [36500/6235], Loss: 7.8223\n",
      "Epoch [79/100], Step [36600/6235], Loss: 0.0976\n",
      "Epoch [79/100], Step [36700/6235], Loss: 0.5745\n",
      "Epoch [79/100], Step [36800/6235], Loss: 6.7958\n",
      "Epoch [79/100], Step [36900/6235], Loss: 13.2684\n",
      "Epoch [79/100], Step [37000/6235], Loss: 0.8687\n",
      "Epoch [79/100], Step [37100/6235], Loss: 1.7661\n",
      "Epoch [79/100], Step [37200/6235], Loss: 0.0530\n",
      "Epoch [79/100], Step [37300/6235], Loss: 0.0309\n",
      "Epoch [79/100], Step [37400/6235], Loss: 0.1858\n",
      "Epoch [79/100], Step [37500/6235], Loss: 6.0334\n",
      "Epoch [79/100], Step [37600/6235], Loss: 12.1100\n",
      "Epoch [79/100], Step [37700/6235], Loss: 2.0293\n",
      "Epoch [79/100], Step [37800/6235], Loss: 4.1210\n",
      "Epoch [79/100], Step [37900/6235], Loss: 6.9697\n",
      "Epoch [79/100], Step [38000/6235], Loss: 0.9086\n",
      "Epoch [79/100], Step [38100/6235], Loss: 4.4112\n",
      "Epoch [79/100], Step [38200/6235], Loss: 1.9861\n",
      "Epoch [79/100], Step [38300/6235], Loss: 0.4556\n",
      "Epoch [79/100], Step [38400/6235], Loss: 0.0530\n",
      "Epoch [79/100], Step [38500/6235], Loss: 1.9578\n",
      "Epoch [79/100], Step [38600/6235], Loss: 0.3384\n",
      "Epoch [79/100], Step [38700/6235], Loss: 0.0516\n",
      "Epoch [79/100], Step [38800/6235], Loss: 0.1536\n",
      "Epoch [79/100], Step [38900/6235], Loss: 2.9851\n",
      "Epoch [79/100], Step [39000/6235], Loss: 4.2835\n",
      "Epoch [79/100], Step [39100/6235], Loss: 14.4438\n",
      "Epoch [79/100], Step [39200/6235], Loss: 0.2514\n",
      "Epoch [79/100], Step [39300/6235], Loss: 70.3861\n",
      "Epoch [79/100], Step [39400/6235], Loss: 98.6844\n",
      "Epoch [79/100], Step [39500/6235], Loss: 401.6930\n",
      "Epoch [79/100], Step [39600/6235], Loss: 9.5524\n",
      "Epoch [79/100], Step [39700/6235], Loss: 143.5562\n",
      "Epoch [79/100], Step [39800/6235], Loss: 132.4097\n",
      "Epoch [79/100], Step [39900/6235], Loss: 1.0997\n",
      "Epoch [79/100], Step [40000/6235], Loss: 2.1648\n",
      "Epoch [79/100], Step [40100/6235], Loss: 8.5000\n",
      "Epoch [79/100], Step [40200/6235], Loss: 15.6126\n",
      "Epoch [79/100], Step [40300/6235], Loss: 0.2889\n",
      "Epoch [79/100], Step [40400/6235], Loss: 0.8716\n",
      "Epoch [79/100], Step [40500/6235], Loss: 3.2587\n",
      "Epoch [79/100], Step [40600/6235], Loss: 0.3085\n",
      "Epoch [79/100], Step [40700/6235], Loss: 5.3173\n",
      "Epoch [79/100], Step [40800/6235], Loss: 1.0654\n",
      "Epoch [79/100], Step [40900/6235], Loss: 1.3435\n",
      "Epoch [79/100], Step [41000/6235], Loss: 42.1810\n",
      "Epoch [79/100], Step [41100/6235], Loss: 22.4794\n",
      "Epoch [79/100], Step [41200/6235], Loss: 3.5278\n",
      "Epoch [79/100], Step [41300/6235], Loss: 2.9134\n",
      "Epoch [79/100], Step [41400/6235], Loss: 1.7226\n",
      "Epoch [79/100], Step [41500/6235], Loss: 2.3856\n",
      "Epoch [79/100], Step [41600/6235], Loss: 0.1838\n",
      "Epoch [79/100], Step [41700/6235], Loss: 0.3867\n",
      "Epoch [79/100], Step [41800/6235], Loss: 2.8995\n",
      "Epoch [79/100], Step [41900/6235], Loss: 4.8522\n",
      "Epoch [79/100], Step [42000/6235], Loss: 4.5620\n",
      "Epoch [79/100], Step [42100/6235], Loss: 10.8779\n",
      "Epoch [79/100], Step [42200/6235], Loss: 21.8538\n",
      "Epoch [79/100], Step [42300/6235], Loss: 0.4568\n",
      "Epoch [79/100], Step [42400/6235], Loss: 2.5299\n",
      "Epoch [79/100], Step [42500/6235], Loss: 3.6368\n",
      "Epoch [79/100], Step [42600/6235], Loss: 0.4606\n",
      "Epoch [79/100], Step [42700/6235], Loss: 0.1695\n",
      "Epoch [79/100], Step [42800/6235], Loss: 9.1623\n",
      "Epoch [79/100], Step [42900/6235], Loss: 2.1255\n",
      "Epoch [79/100], Step [43000/6235], Loss: 0.1593\n",
      "Epoch [79/100], Step [43100/6235], Loss: 0.0484\n",
      "Epoch [79/100], Step [43200/6235], Loss: 0.9418\n",
      "Epoch [79/100], Step [43300/6235], Loss: 7.7681\n",
      "Epoch [79/100], Step [43400/6235], Loss: 11.3742\n",
      "Epoch [79/100], Step [43500/6235], Loss: 9.6334\n",
      "Epoch [79/100], Step [43600/6235], Loss: 8.1736\n",
      "Epoch [79/100], Step [43700/6235], Loss: 45.3485\n",
      "Epoch [79/100], Step [43800/6235], Loss: 0.6869\n",
      "Epoch [79/100], Step [43900/6235], Loss: 0.3561\n",
      "Epoch [79/100], Step [44000/6235], Loss: 55.1178\n",
      "Epoch [79/100], Step [44100/6235], Loss: 3.5224\n",
      "Epoch [79/100], Step [44200/6235], Loss: 4.9416\n",
      "Epoch [79/100], Step [44300/6235], Loss: 30.8816\n",
      "Epoch [79/100], Step [44400/6235], Loss: 0.7134\n",
      "Epoch [79/100], Step [44500/6235], Loss: 6.1052\n",
      "Epoch [79/100], Step [44600/6235], Loss: 27.7851\n",
      "Epoch [79/100], Step [44700/6235], Loss: 0.9640\n",
      "Epoch [79/100], Step [44800/6235], Loss: 3.5614\n",
      "Epoch [79/100], Step [44900/6235], Loss: 9.0240\n",
      "Epoch [79/100], Step [45000/6235], Loss: 5.8626\n",
      "Epoch [79/100], Step [45100/6235], Loss: 20.3741\n",
      "Epoch [79/100], Step [45200/6235], Loss: 1.3770\n",
      "Epoch [79/100], Step [45300/6235], Loss: 26.2639\n",
      "Epoch [79/100], Step [45400/6235], Loss: 10.5766\n",
      "Epoch [79/100], Step [45500/6235], Loss: 1.5318\n",
      "Epoch [79/100], Step [45600/6235], Loss: 0.3414\n",
      "Epoch [79/100], Step [45700/6235], Loss: 86.1651\n",
      "Epoch [79/100], Step [45800/6235], Loss: 319.8232\n",
      "Epoch [79/100], Step [45900/6235], Loss: 8.4547\n",
      "Epoch [79/100], Step [46000/6235], Loss: 93.7194\n",
      "Epoch [79/100], Step [46100/6235], Loss: 32.2190\n",
      "Epoch [79/100], Step [46200/6235], Loss: 51.2272\n",
      "Epoch [79/100], Step [46300/6235], Loss: 5.3569\n",
      "Epoch [79/100], Step [46400/6235], Loss: 11.0963\n",
      "Epoch [79/100], Step [46500/6235], Loss: 4.6104\n",
      "Epoch [79/100], Step [46600/6235], Loss: 22.0333\n",
      "Epoch [79/100], Step [46700/6235], Loss: 14.6060\n",
      "Epoch [79/100], Step [46800/6235], Loss: 18.5091\n",
      "Epoch [79/100], Step [46900/6235], Loss: 8.0285\n",
      "Epoch [79/100], Step [47000/6235], Loss: 4.7531\n",
      "Epoch [79/100], Step [47100/6235], Loss: 6.7503\n",
      "Epoch [79/100], Step [47200/6235], Loss: 46.9449\n",
      "Epoch [79/100], Step [47300/6235], Loss: 0.8835\n",
      "Epoch [79/100], Step [47400/6235], Loss: 86.7457\n",
      "Epoch [79/100], Step [47500/6235], Loss: 19.4187\n",
      "Epoch [79/100], Step [47600/6235], Loss: 3.0264\n",
      "Epoch [79/100], Step [47700/6235], Loss: 4.7204\n",
      "Epoch [79/100], Step [47800/6235], Loss: 4.1835\n",
      "Epoch [79/100], Step [47900/6235], Loss: 20.5238\n",
      "Epoch [79/100], Step [48000/6235], Loss: 52.8137\n",
      "Epoch [79/100], Step [48100/6235], Loss: 4.2821\n",
      "Epoch [79/100], Step [48200/6235], Loss: 15.8225\n",
      "Epoch [79/100], Step [48300/6235], Loss: 426.6951\n",
      "Epoch [79/100], Step [48400/6235], Loss: 20.4134\n",
      "Epoch [79/100], Step [48500/6235], Loss: 26.8490\n",
      "Epoch [79/100], Step [48600/6235], Loss: 163.7187\n",
      "Epoch [79/100], Step [48700/6235], Loss: 13.5166\n",
      "Epoch [79/100], Step [48800/6235], Loss: 212.2068\n",
      "Epoch [79/100], Step [48900/6235], Loss: 732.6614\n",
      "Epoch [79/100], Step [49000/6235], Loss: 284.6528\n",
      "Epoch [79/100], Step [49100/6235], Loss: 1855.0214\n",
      "Epoch [79/100], Step [49200/6235], Loss: 798.9600\n",
      "Epoch [79/100], Step [49300/6235], Loss: 1209.5754\n",
      "Epoch [79/100], Step [49400/6235], Loss: 4.7574\n",
      "Epoch [79/100], Step [49500/6235], Loss: 5.9970\n",
      "Epoch [79/100], Step [49600/6235], Loss: 225.1233\n",
      "Epoch [79/100], Step [49700/6235], Loss: 445.6926\n",
      "Epoch [79/100], Step [49800/6235], Loss: 120.9752\n",
      "Epoch [80/100], Step [100/6235], Loss: 14.2490\n",
      "Epoch [80/100], Step [200/6235], Loss: 1.3822\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Step [300/6235], Loss: 0.2313\n",
      "Epoch [80/100], Step [400/6235], Loss: 0.1776\n",
      "Epoch [80/100], Step [500/6235], Loss: 9.0297\n",
      "Epoch [80/100], Step [600/6235], Loss: 0.9580\n",
      "Epoch [80/100], Step [700/6235], Loss: 0.8577\n",
      "Epoch [80/100], Step [800/6235], Loss: 0.0714\n",
      "Epoch [80/100], Step [900/6235], Loss: 0.1733\n",
      "Epoch [80/100], Step [1000/6235], Loss: 0.0292\n",
      "Epoch [80/100], Step [1100/6235], Loss: 0.1728\n",
      "Epoch [80/100], Step [1200/6235], Loss: 0.1595\n",
      "Epoch [80/100], Step [1300/6235], Loss: 0.0111\n",
      "Epoch [80/100], Step [1400/6235], Loss: 0.7224\n",
      "Epoch [80/100], Step [1500/6235], Loss: 0.0051\n",
      "Epoch [80/100], Step [1600/6235], Loss: 0.2962\n",
      "Epoch [80/100], Step [1700/6235], Loss: 0.3139\n",
      "Epoch [80/100], Step [1800/6235], Loss: 0.4065\n",
      "Epoch [80/100], Step [1900/6235], Loss: 0.3411\n",
      "Epoch [80/100], Step [2000/6235], Loss: 2.2595\n",
      "Epoch [80/100], Step [2100/6235], Loss: 3.7865\n",
      "Epoch [80/100], Step [2200/6235], Loss: 3.9695\n",
      "Epoch [80/100], Step [2300/6235], Loss: 1.7734\n",
      "Epoch [80/100], Step [2400/6235], Loss: 2.2745\n",
      "Epoch [80/100], Step [2500/6235], Loss: 8.5174\n",
      "Epoch [80/100], Step [2600/6235], Loss: 16.2756\n",
      "Epoch [80/100], Step [2700/6235], Loss: 10.3678\n",
      "Epoch [80/100], Step [2800/6235], Loss: 28.9018\n",
      "Epoch [80/100], Step [2900/6235], Loss: 12.0757\n",
      "Epoch [80/100], Step [3000/6235], Loss: 0.1172\n",
      "Epoch [80/100], Step [3100/6235], Loss: 74.8833\n",
      "Epoch [80/100], Step [3200/6235], Loss: 31.6518\n",
      "Epoch [80/100], Step [3300/6235], Loss: 7.2369\n",
      "Epoch [80/100], Step [3400/6235], Loss: 5.6801\n",
      "Epoch [80/100], Step [3500/6235], Loss: 61.4245\n",
      "Epoch [80/100], Step [3600/6235], Loss: 0.3779\n",
      "Epoch [80/100], Step [3700/6235], Loss: 0.1160\n",
      "Epoch [80/100], Step [3800/6235], Loss: 0.0944\n",
      "Epoch [80/100], Step [3900/6235], Loss: 0.1822\n",
      "Epoch [80/100], Step [4000/6235], Loss: 0.1334\n",
      "Epoch [80/100], Step [4100/6235], Loss: 9.9170\n",
      "Epoch [80/100], Step [4200/6235], Loss: 5.1217\n",
      "Epoch [80/100], Step [4300/6235], Loss: 3.3500\n",
      "Epoch [80/100], Step [4400/6235], Loss: 0.3594\n",
      "Epoch [80/100], Step [4500/6235], Loss: 40.7383\n",
      "Epoch [80/100], Step [4600/6235], Loss: 3.1717\n",
      "Epoch [80/100], Step [4700/6235], Loss: 0.0619\n",
      "Epoch [80/100], Step [4800/6235], Loss: 5.1147\n",
      "Epoch [80/100], Step [4900/6235], Loss: 3.9258\n",
      "Epoch [80/100], Step [5000/6235], Loss: 0.1486\n",
      "Epoch [80/100], Step [5100/6235], Loss: 0.3363\n",
      "Epoch [80/100], Step [5200/6235], Loss: 5.5058\n",
      "Epoch [80/100], Step [5300/6235], Loss: 15.7710\n",
      "Epoch [80/100], Step [5400/6235], Loss: 2.2111\n",
      "Epoch [80/100], Step [5500/6235], Loss: 0.1169\n",
      "Epoch [80/100], Step [5600/6235], Loss: 0.2521\n",
      "Epoch [80/100], Step [5700/6235], Loss: 0.0255\n",
      "Epoch [80/100], Step [5800/6235], Loss: 0.1172\n",
      "Epoch [80/100], Step [5900/6235], Loss: 0.0720\n",
      "Epoch [80/100], Step [6000/6235], Loss: 0.6371\n",
      "Epoch [80/100], Step [6100/6235], Loss: 0.0373\n",
      "Epoch [80/100], Step [6200/6235], Loss: 7.4304\n",
      "Epoch [80/100], Step [6300/6235], Loss: 0.6374\n",
      "Epoch [80/100], Step [6400/6235], Loss: 0.0311\n",
      "Epoch [80/100], Step [6500/6235], Loss: 0.8629\n",
      "Epoch [80/100], Step [6600/6235], Loss: 6.5129\n",
      "Epoch [80/100], Step [6700/6235], Loss: 1.0680\n",
      "Epoch [80/100], Step [6800/6235], Loss: 0.2954\n",
      "Epoch [80/100], Step [6900/6235], Loss: 0.2064\n",
      "Epoch [80/100], Step [7000/6235], Loss: 0.4264\n",
      "Epoch [80/100], Step [7100/6235], Loss: 0.2591\n",
      "Epoch [80/100], Step [7200/6235], Loss: 0.0634\n",
      "Epoch [80/100], Step [7300/6235], Loss: 0.3093\n",
      "Epoch [80/100], Step [7400/6235], Loss: 0.2565\n",
      "Epoch [80/100], Step [7500/6235], Loss: 0.2266\n",
      "Epoch [80/100], Step [7600/6235], Loss: 1.9204\n",
      "Epoch [80/100], Step [7700/6235], Loss: 19.2202\n",
      "Epoch [80/100], Step [7800/6235], Loss: 6.3441\n",
      "Epoch [80/100], Step [7900/6235], Loss: 0.3743\n",
      "Epoch [80/100], Step [8000/6235], Loss: 0.1348\n",
      "Epoch [80/100], Step [8100/6235], Loss: 4.6766\n",
      "Epoch [80/100], Step [8200/6235], Loss: 13.6992\n",
      "Epoch [80/100], Step [8300/6235], Loss: 45.9579\n",
      "Epoch [80/100], Step [8400/6235], Loss: 168.7444\n",
      "Epoch [80/100], Step [8500/6235], Loss: 1.9033\n",
      "Epoch [80/100], Step [8600/6235], Loss: 143.7816\n",
      "Epoch [80/100], Step [8700/6235], Loss: 99.8233\n",
      "Epoch [80/100], Step [8800/6235], Loss: 585.4406\n",
      "Epoch [80/100], Step [8900/6235], Loss: 4.4396\n",
      "Epoch [80/100], Step [9000/6235], Loss: 363.8999\n",
      "Epoch [80/100], Step [9100/6235], Loss: 1930.6990\n",
      "Epoch [80/100], Step [9200/6235], Loss: 3975.9231\n",
      "Epoch [80/100], Step [9300/6235], Loss: 176.1641\n",
      "Epoch [80/100], Step [9400/6235], Loss: 28.4330\n",
      "Epoch [80/100], Step [9500/6235], Loss: 1825.2671\n",
      "Epoch [80/100], Step [9600/6235], Loss: 526.8454\n",
      "Epoch [80/100], Step [9700/6235], Loss: 6.0526\n",
      "Epoch [80/100], Step [9800/6235], Loss: 2369.1260\n",
      "Epoch [80/100], Step [9900/6235], Loss: 279.0027\n",
      "Epoch [80/100], Step [10000/6235], Loss: 109.9357\n",
      "Epoch [80/100], Step [10100/6235], Loss: 3.2181\n",
      "Epoch [80/100], Step [10200/6235], Loss: 573.8168\n",
      "Epoch [80/100], Step [10300/6235], Loss: 2.3071\n",
      "Epoch [80/100], Step [10400/6235], Loss: 5.5837\n",
      "Epoch [80/100], Step [10500/6235], Loss: 1.6067\n",
      "Epoch [80/100], Step [10600/6235], Loss: 19.0569\n",
      "Epoch [80/100], Step [10700/6235], Loss: 24.1457\n",
      "Epoch [80/100], Step [10800/6235], Loss: 45.6295\n",
      "Epoch [80/100], Step [10900/6235], Loss: 1.3799\n",
      "Epoch [80/100], Step [11000/6235], Loss: 281.3878\n",
      "Epoch [80/100], Step [11100/6235], Loss: 33.4840\n",
      "Epoch [80/100], Step [11200/6235], Loss: 43.1265\n",
      "Epoch [80/100], Step [11300/6235], Loss: 169.7024\n",
      "Epoch [80/100], Step [11400/6235], Loss: 7.2226\n",
      "Epoch [80/100], Step [11500/6235], Loss: 2.1156\n",
      "Epoch [80/100], Step [11600/6235], Loss: 1.1618\n",
      "Epoch [80/100], Step [11700/6235], Loss: 38.3351\n",
      "Epoch [80/100], Step [11800/6235], Loss: 433.0467\n",
      "Epoch [80/100], Step [11900/6235], Loss: 334.8922\n",
      "Epoch [80/100], Step [12000/6235], Loss: 600.4963\n",
      "Epoch [80/100], Step [12100/6235], Loss: 326.9445\n",
      "Epoch [80/100], Step [12200/6235], Loss: 12.7378\n",
      "Epoch [80/100], Step [12300/6235], Loss: 1.3978\n",
      "Epoch [80/100], Step [12400/6235], Loss: 160.2525\n",
      "Epoch [80/100], Step [12500/6235], Loss: 198.4761\n",
      "Epoch [80/100], Step [12600/6235], Loss: 2.4516\n",
      "Epoch [80/100], Step [12700/6235], Loss: 4.8964\n",
      "Epoch [80/100], Step [12800/6235], Loss: 15.4200\n",
      "Epoch [80/100], Step [12900/6235], Loss: 30.2365\n",
      "Epoch [80/100], Step [13000/6235], Loss: 0.2093\n",
      "Epoch [80/100], Step [13100/6235], Loss: 61.8249\n",
      "Epoch [80/100], Step [13200/6235], Loss: 8.4712\n",
      "Epoch [80/100], Step [13300/6235], Loss: 18.2142\n",
      "Epoch [80/100], Step [13400/6235], Loss: 199.3194\n",
      "Epoch [80/100], Step [13500/6235], Loss: 2.7939\n",
      "Epoch [80/100], Step [13600/6235], Loss: 13.2456\n",
      "Epoch [80/100], Step [13700/6235], Loss: 172.5657\n",
      "Epoch [80/100], Step [13800/6235], Loss: 78.7205\n",
      "Epoch [80/100], Step [13900/6235], Loss: 10.2800\n",
      "Epoch [80/100], Step [14000/6235], Loss: 9.6991\n",
      "Epoch [80/100], Step [14100/6235], Loss: 7.9851\n",
      "Epoch [80/100], Step [14200/6235], Loss: 57.8661\n",
      "Epoch [80/100], Step [14300/6235], Loss: 7.2867\n",
      "Epoch [80/100], Step [14400/6235], Loss: 33.8641\n",
      "Epoch [80/100], Step [14500/6235], Loss: 26.2091\n",
      "Epoch [80/100], Step [14600/6235], Loss: 2.6319\n",
      "Epoch [80/100], Step [14700/6235], Loss: 26.1510\n",
      "Epoch [80/100], Step [14800/6235], Loss: 29.9607\n",
      "Epoch [80/100], Step [14900/6235], Loss: 0.7120\n",
      "Epoch [80/100], Step [15000/6235], Loss: 1.1940\n",
      "Epoch [80/100], Step [15100/6235], Loss: 0.4127\n",
      "Epoch [80/100], Step [15200/6235], Loss: 26.4484\n",
      "Epoch [80/100], Step [15300/6235], Loss: 13.0864\n",
      "Epoch [80/100], Step [15400/6235], Loss: 54.0727\n",
      "Epoch [80/100], Step [15500/6235], Loss: 17.0432\n",
      "Epoch [80/100], Step [15600/6235], Loss: 196.5487\n",
      "Epoch [80/100], Step [15700/6235], Loss: 85.2596\n",
      "Epoch [80/100], Step [15800/6235], Loss: 8.5563\n",
      "Epoch [80/100], Step [15900/6235], Loss: 0.6895\n",
      "Epoch [80/100], Step [16000/6235], Loss: 156.8210\n",
      "Epoch [80/100], Step [16100/6235], Loss: 0.7160\n",
      "Epoch [80/100], Step [16200/6235], Loss: 0.4595\n",
      "Epoch [80/100], Step [16300/6235], Loss: 8.4705\n",
      "Epoch [80/100], Step [16400/6235], Loss: 23.2755\n",
      "Epoch [80/100], Step [16500/6235], Loss: 158.1035\n",
      "Epoch [80/100], Step [16600/6235], Loss: 26.2650\n",
      "Epoch [80/100], Step [16700/6235], Loss: 0.5072\n",
      "Epoch [80/100], Step [16800/6235], Loss: 11.1884\n",
      "Epoch [80/100], Step [16900/6235], Loss: 0.4235\n",
      "Epoch [80/100], Step [17000/6235], Loss: 0.1757\n",
      "Epoch [80/100], Step [17100/6235], Loss: 0.1406\n",
      "Epoch [80/100], Step [17200/6235], Loss: 257.7053\n",
      "Epoch [80/100], Step [17300/6235], Loss: 21.0949\n",
      "Epoch [80/100], Step [17400/6235], Loss: 35.0074\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Step [17500/6235], Loss: 2.8254\n",
      "Epoch [80/100], Step [17600/6235], Loss: 2.5372\n",
      "Epoch [80/100], Step [17700/6235], Loss: 14.0457\n",
      "Epoch [80/100], Step [17800/6235], Loss: 42.9868\n",
      "Epoch [80/100], Step [17900/6235], Loss: 7.6845\n",
      "Epoch [80/100], Step [18000/6235], Loss: 1.6194\n",
      "Epoch [80/100], Step [18100/6235], Loss: 17.4087\n",
      "Epoch [80/100], Step [18200/6235], Loss: 0.6582\n",
      "Epoch [80/100], Step [18300/6235], Loss: 5.0072\n",
      "Epoch [80/100], Step [18400/6235], Loss: 4.6832\n",
      "Epoch [80/100], Step [18500/6235], Loss: 16.6975\n",
      "Epoch [80/100], Step [18600/6235], Loss: 1.0470\n",
      "Epoch [80/100], Step [18700/6235], Loss: 0.4286\n",
      "Epoch [80/100], Step [18800/6235], Loss: 45.1272\n",
      "Epoch [80/100], Step [18900/6235], Loss: 35.7096\n",
      "Epoch [80/100], Step [19000/6235], Loss: 14.6117\n",
      "Epoch [80/100], Step [19100/6235], Loss: 6.2456\n",
      "Epoch [80/100], Step [19200/6235], Loss: 3.3105\n",
      "Epoch [80/100], Step [19300/6235], Loss: 8.7708\n",
      "Epoch [80/100], Step [19400/6235], Loss: 223.8997\n",
      "Epoch [80/100], Step [19500/6235], Loss: 157.4401\n",
      "Epoch [80/100], Step [19600/6235], Loss: 127.3708\n",
      "Epoch [80/100], Step [19700/6235], Loss: 9.9636\n",
      "Epoch [80/100], Step [19800/6235], Loss: 0.7247\n",
      "Epoch [80/100], Step [19900/6235], Loss: 1.5639\n",
      "Epoch [80/100], Step [20000/6235], Loss: 103.8527\n",
      "Epoch [80/100], Step [20100/6235], Loss: 11.3138\n",
      "Epoch [80/100], Step [20200/6235], Loss: 2.8796\n",
      "Epoch [80/100], Step [20300/6235], Loss: 0.5217\n",
      "Epoch [80/100], Step [20400/6235], Loss: 30.3398\n",
      "Epoch [80/100], Step [20500/6235], Loss: 27.2739\n",
      "Epoch [80/100], Step [20600/6235], Loss: 26.9308\n",
      "Epoch [80/100], Step [20700/6235], Loss: 7.6553\n",
      "Epoch [80/100], Step [20800/6235], Loss: 5.3082\n",
      "Epoch [80/100], Step [20900/6235], Loss: 32.2451\n",
      "Epoch [80/100], Step [21000/6235], Loss: 16.9699\n",
      "Epoch [80/100], Step [21100/6235], Loss: 1.0987\n",
      "Epoch [80/100], Step [21200/6235], Loss: 0.1216\n",
      "Epoch [80/100], Step [21300/6235], Loss: 0.1255\n",
      "Epoch [80/100], Step [21400/6235], Loss: 5.0656\n",
      "Epoch [80/100], Step [21500/6235], Loss: 2.3806\n",
      "Epoch [80/100], Step [21600/6235], Loss: 32.9167\n",
      "Epoch [80/100], Step [21700/6235], Loss: 0.7263\n",
      "Epoch [80/100], Step [21800/6235], Loss: 6.0838\n",
      "Epoch [80/100], Step [21900/6235], Loss: 0.1015\n",
      "Epoch [80/100], Step [22000/6235], Loss: 2.3283\n",
      "Epoch [80/100], Step [22100/6235], Loss: 4.6893\n",
      "Epoch [80/100], Step [22200/6235], Loss: 8.3860\n",
      "Epoch [80/100], Step [22300/6235], Loss: 1.3896\n",
      "Epoch [80/100], Step [22400/6235], Loss: 4.0058\n",
      "Epoch [80/100], Step [22500/6235], Loss: 95.6192\n",
      "Epoch [80/100], Step [22600/6235], Loss: 12.8261\n",
      "Epoch [80/100], Step [22700/6235], Loss: 1.4034\n",
      "Epoch [80/100], Step [22800/6235], Loss: 11.3437\n",
      "Epoch [80/100], Step [22900/6235], Loss: 9.7245\n",
      "Epoch [80/100], Step [23000/6235], Loss: 12.1994\n",
      "Epoch [80/100], Step [23100/6235], Loss: 0.7902\n",
      "Epoch [80/100], Step [23200/6235], Loss: 15.5196\n",
      "Epoch [80/100], Step [23300/6235], Loss: 18.5647\n",
      "Epoch [80/100], Step [23400/6235], Loss: 0.5691\n",
      "Epoch [80/100], Step [23500/6235], Loss: 0.2862\n",
      "Epoch [80/100], Step [23600/6235], Loss: 96.1462\n",
      "Epoch [80/100], Step [23700/6235], Loss: 8.7516\n",
      "Epoch [80/100], Step [23800/6235], Loss: 0.8651\n",
      "Epoch [80/100], Step [23900/6235], Loss: 7.8134\n",
      "Epoch [80/100], Step [24000/6235], Loss: 0.7390\n",
      "Epoch [80/100], Step [24100/6235], Loss: 1.2243\n",
      "Epoch [80/100], Step [24200/6235], Loss: 32.8711\n",
      "Epoch [80/100], Step [24300/6235], Loss: 1.3290\n",
      "Epoch [80/100], Step [24400/6235], Loss: 4.7777\n",
      "Epoch [80/100], Step [24500/6235], Loss: 2.6220\n",
      "Epoch [80/100], Step [24600/6235], Loss: 0.1259\n",
      "Epoch [80/100], Step [24700/6235], Loss: 2.2406\n",
      "Epoch [80/100], Step [24800/6235], Loss: 0.0850\n",
      "Epoch [80/100], Step [24900/6235], Loss: 0.8057\n",
      "Epoch [80/100], Step [25000/6235], Loss: 17.8514\n",
      "Epoch [80/100], Step [25100/6235], Loss: 8.1718\n",
      "Epoch [80/100], Step [25200/6235], Loss: 1.8727\n",
      "Epoch [80/100], Step [25300/6235], Loss: 0.8202\n",
      "Epoch [80/100], Step [25400/6235], Loss: 9.9613\n",
      "Epoch [80/100], Step [25500/6235], Loss: 4.5088\n",
      "Epoch [80/100], Step [25600/6235], Loss: 1.6884\n",
      "Epoch [80/100], Step [25700/6235], Loss: 0.2620\n",
      "Epoch [80/100], Step [25800/6235], Loss: 0.1471\n",
      "Epoch [80/100], Step [25900/6235], Loss: 10.4063\n",
      "Epoch [80/100], Step [26000/6235], Loss: 3.5704\n",
      "Epoch [80/100], Step [26100/6235], Loss: 0.5042\n",
      "Epoch [80/100], Step [26200/6235], Loss: 0.0305\n",
      "Epoch [80/100], Step [26300/6235], Loss: 4.5442\n",
      "Epoch [80/100], Step [26400/6235], Loss: 0.1811\n",
      "Epoch [80/100], Step [26500/6235], Loss: 0.3050\n",
      "Epoch [80/100], Step [26600/6235], Loss: 3.8011\n",
      "Epoch [80/100], Step [26700/6235], Loss: 0.7507\n",
      "Epoch [80/100], Step [26800/6235], Loss: 0.8454\n",
      "Epoch [80/100], Step [26900/6235], Loss: 0.0723\n",
      "Epoch [80/100], Step [27000/6235], Loss: 11.6060\n",
      "Epoch [80/100], Step [27100/6235], Loss: 0.2638\n",
      "Epoch [80/100], Step [27200/6235], Loss: 0.1001\n",
      "Epoch [80/100], Step [27300/6235], Loss: 0.1541\n",
      "Epoch [80/100], Step [27400/6235], Loss: 0.9847\n",
      "Epoch [80/100], Step [27500/6235], Loss: 23.3492\n",
      "Epoch [80/100], Step [27600/6235], Loss: 0.6195\n",
      "Epoch [80/100], Step [27700/6235], Loss: 1.5668\n",
      "Epoch [80/100], Step [27800/6235], Loss: 6.8755\n",
      "Epoch [80/100], Step [27900/6235], Loss: 1.0001\n",
      "Epoch [80/100], Step [28000/6235], Loss: 148.4519\n",
      "Epoch [80/100], Step [28100/6235], Loss: 1.5533\n",
      "Epoch [80/100], Step [28200/6235], Loss: 30.2445\n",
      "Epoch [80/100], Step [28300/6235], Loss: 4.6820\n",
      "Epoch [80/100], Step [28400/6235], Loss: 24.5991\n",
      "Epoch [80/100], Step [28500/6235], Loss: 3.6371\n",
      "Epoch [80/100], Step [28600/6235], Loss: 0.3425\n",
      "Epoch [80/100], Step [28700/6235], Loss: 4.7455\n",
      "Epoch [80/100], Step [28800/6235], Loss: 0.4262\n",
      "Epoch [80/100], Step [28900/6235], Loss: 72.4392\n",
      "Epoch [80/100], Step [29000/6235], Loss: 11.3597\n",
      "Epoch [80/100], Step [29100/6235], Loss: 0.0113\n",
      "Epoch [80/100], Step [29200/6235], Loss: 0.0884\n",
      "Epoch [80/100], Step [29300/6235], Loss: 7.2193\n",
      "Epoch [80/100], Step [29400/6235], Loss: 0.1441\n",
      "Epoch [80/100], Step [29500/6235], Loss: 0.7108\n",
      "Epoch [80/100], Step [29600/6235], Loss: 0.5991\n",
      "Epoch [80/100], Step [29700/6235], Loss: 0.3280\n",
      "Epoch [80/100], Step [29800/6235], Loss: 1.6906\n",
      "Epoch [80/100], Step [29900/6235], Loss: 0.2993\n",
      "Epoch [80/100], Step [30000/6235], Loss: 4.5682\n",
      "Epoch [80/100], Step [30100/6235], Loss: 9.9223\n",
      "Epoch [80/100], Step [30200/6235], Loss: 0.1165\n",
      "Epoch [80/100], Step [30300/6235], Loss: 0.5003\n",
      "Epoch [80/100], Step [30400/6235], Loss: 0.2636\n",
      "Epoch [80/100], Step [30500/6235], Loss: 1.6968\n",
      "Epoch [80/100], Step [30600/6235], Loss: 0.6852\n",
      "Epoch [80/100], Step [30700/6235], Loss: 0.0845\n",
      "Epoch [80/100], Step [30800/6235], Loss: 0.2643\n",
      "Epoch [80/100], Step [30900/6235], Loss: 3.0917\n",
      "Epoch [80/100], Step [31000/6235], Loss: 0.0259\n",
      "Epoch [80/100], Step [31100/6235], Loss: 0.0442\n",
      "Epoch [80/100], Step [31200/6235], Loss: 11.0077\n",
      "Epoch [80/100], Step [31300/6235], Loss: 1.4593\n",
      "Epoch [80/100], Step [31400/6235], Loss: 3.1662\n",
      "Epoch [80/100], Step [31500/6235], Loss: 0.6291\n",
      "Epoch [80/100], Step [31600/6235], Loss: 1.2198\n",
      "Epoch [80/100], Step [31700/6235], Loss: 24.0536\n",
      "Epoch [80/100], Step [31800/6235], Loss: 1.7270\n",
      "Epoch [80/100], Step [31900/6235], Loss: 510.9063\n",
      "Epoch [80/100], Step [32000/6235], Loss: 4.5787\n",
      "Epoch [80/100], Step [32100/6235], Loss: 3.5920\n",
      "Epoch [80/100], Step [32200/6235], Loss: 24.5131\n",
      "Epoch [80/100], Step [32300/6235], Loss: 0.9236\n",
      "Epoch [80/100], Step [32400/6235], Loss: 0.4069\n",
      "Epoch [80/100], Step [32500/6235], Loss: 21.8248\n",
      "Epoch [80/100], Step [32600/6235], Loss: 0.8792\n",
      "Epoch [80/100], Step [32700/6235], Loss: 84.3015\n",
      "Epoch [80/100], Step [32800/6235], Loss: 12.9778\n",
      "Epoch [80/100], Step [32900/6235], Loss: 10.5071\n",
      "Epoch [80/100], Step [33000/6235], Loss: 0.3271\n",
      "Epoch [80/100], Step [33100/6235], Loss: 0.7568\n",
      "Epoch [80/100], Step [33200/6235], Loss: 1.0024\n",
      "Epoch [80/100], Step [33300/6235], Loss: 0.3951\n",
      "Epoch [80/100], Step [33400/6235], Loss: 102.3953\n",
      "Epoch [80/100], Step [33500/6235], Loss: 1.0891\n",
      "Epoch [80/100], Step [33600/6235], Loss: 8.9679\n",
      "Epoch [80/100], Step [33700/6235], Loss: 14.8187\n",
      "Epoch [80/100], Step [33800/6235], Loss: 0.7512\n",
      "Epoch [80/100], Step [33900/6235], Loss: 29.5457\n",
      "Epoch [80/100], Step [34000/6235], Loss: 0.0156\n",
      "Epoch [80/100], Step [34100/6235], Loss: 0.3293\n",
      "Epoch [80/100], Step [34200/6235], Loss: 3.1509\n",
      "Epoch [80/100], Step [34300/6235], Loss: 5.6530\n",
      "Epoch [80/100], Step [34400/6235], Loss: 0.2100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [80/100], Step [34500/6235], Loss: 64.1360\n",
      "Epoch [80/100], Step [34600/6235], Loss: 0.4471\n",
      "Epoch [80/100], Step [34700/6235], Loss: 11.4241\n",
      "Epoch [80/100], Step [34800/6235], Loss: 14.2150\n",
      "Epoch [80/100], Step [34900/6235], Loss: 67.6303\n",
      "Epoch [80/100], Step [35000/6235], Loss: 0.9060\n",
      "Epoch [80/100], Step [35100/6235], Loss: 0.4435\n",
      "Epoch [80/100], Step [35200/6235], Loss: 0.2198\n",
      "Epoch [80/100], Step [35300/6235], Loss: 2.0860\n",
      "Epoch [80/100], Step [35400/6235], Loss: 0.5600\n",
      "Epoch [80/100], Step [35500/6235], Loss: 2.5068\n",
      "Epoch [80/100], Step [35600/6235], Loss: 1.5167\n",
      "Epoch [80/100], Step [35700/6235], Loss: 5.8457\n",
      "Epoch [80/100], Step [35800/6235], Loss: 0.0918\n",
      "Epoch [80/100], Step [35900/6235], Loss: 0.4114\n",
      "Epoch [80/100], Step [36000/6235], Loss: 0.4646\n",
      "Epoch [80/100], Step [36100/6235], Loss: 0.0247\n",
      "Epoch [80/100], Step [36200/6235], Loss: 16.5637\n",
      "Epoch [80/100], Step [36300/6235], Loss: 0.7945\n",
      "Epoch [80/100], Step [36400/6235], Loss: 1.9606\n",
      "Epoch [80/100], Step [36500/6235], Loss: 9.3642\n",
      "Epoch [80/100], Step [36600/6235], Loss: 0.1280\n",
      "Epoch [80/100], Step [36700/6235], Loss: 0.2396\n",
      "Epoch [80/100], Step [36800/6235], Loss: 16.5288\n",
      "Epoch [80/100], Step [36900/6235], Loss: 6.5524\n",
      "Epoch [80/100], Step [37000/6235], Loss: 0.2463\n",
      "Epoch [80/100], Step [37100/6235], Loss: 0.7895\n",
      "Epoch [80/100], Step [37200/6235], Loss: 0.0784\n",
      "Epoch [80/100], Step [37300/6235], Loss: 0.0842\n",
      "Epoch [80/100], Step [37400/6235], Loss: 0.2067\n",
      "Epoch [80/100], Step [37500/6235], Loss: 3.7239\n",
      "Epoch [80/100], Step [37600/6235], Loss: 11.3348\n",
      "Epoch [80/100], Step [37700/6235], Loss: 1.0648\n",
      "Epoch [80/100], Step [37800/6235], Loss: 6.3355\n",
      "Epoch [80/100], Step [37900/6235], Loss: 7.5856\n",
      "Epoch [80/100], Step [38000/6235], Loss: 0.3333\n",
      "Epoch [80/100], Step [38100/6235], Loss: 3.2462\n",
      "Epoch [80/100], Step [38200/6235], Loss: 2.2265\n",
      "Epoch [80/100], Step [38300/6235], Loss: 0.7137\n",
      "Epoch [80/100], Step [38400/6235], Loss: 0.1448\n",
      "Epoch [80/100], Step [38500/6235], Loss: 3.0987\n",
      "Epoch [80/100], Step [38600/6235], Loss: 0.0856\n",
      "Epoch [80/100], Step [38700/6235], Loss: 0.1065\n",
      "Epoch [80/100], Step [38800/6235], Loss: 0.3051\n",
      "Epoch [80/100], Step [38900/6235], Loss: 10.4293\n",
      "Epoch [80/100], Step [39000/6235], Loss: 4.4663\n",
      "Epoch [80/100], Step [39100/6235], Loss: 18.2774\n",
      "Epoch [80/100], Step [39200/6235], Loss: 0.3533\n",
      "Epoch [80/100], Step [39300/6235], Loss: 58.2457\n",
      "Epoch [80/100], Step [39400/6235], Loss: 101.3797\n",
      "Epoch [80/100], Step [39500/6235], Loss: 467.2645\n",
      "Epoch [80/100], Step [39600/6235], Loss: 7.6667\n",
      "Epoch [80/100], Step [39700/6235], Loss: 31.5774\n",
      "Epoch [80/100], Step [39800/6235], Loss: 204.9034\n",
      "Epoch [80/100], Step [39900/6235], Loss: 18.6172\n",
      "Epoch [80/100], Step [40000/6235], Loss: 1.0298\n",
      "Epoch [80/100], Step [40100/6235], Loss: 2.8312\n",
      "Epoch [80/100], Step [40200/6235], Loss: 26.0351\n",
      "Epoch [80/100], Step [40300/6235], Loss: 0.4029\n",
      "Epoch [80/100], Step [40400/6235], Loss: 0.2545\n",
      "Epoch [80/100], Step [40500/6235], Loss: 3.8248\n",
      "Epoch [80/100], Step [40600/6235], Loss: 0.3454\n",
      "Epoch [80/100], Step [40700/6235], Loss: 4.0410\n",
      "Epoch [80/100], Step [40800/6235], Loss: 2.3092\n",
      "Epoch [80/100], Step [40900/6235], Loss: 1.3333\n",
      "Epoch [80/100], Step [41000/6235], Loss: 32.7894\n",
      "Epoch [80/100], Step [41100/6235], Loss: 57.1176\n",
      "Epoch [80/100], Step [41200/6235], Loss: 9.2313\n",
      "Epoch [80/100], Step [41300/6235], Loss: 0.1282\n",
      "Epoch [80/100], Step [41400/6235], Loss: 0.9854\n",
      "Epoch [80/100], Step [41500/6235], Loss: 23.7011\n",
      "Epoch [80/100], Step [41600/6235], Loss: 6.2486\n",
      "Epoch [80/100], Step [41700/6235], Loss: 0.1074\n",
      "Epoch [80/100], Step [41800/6235], Loss: 0.3426\n",
      "Epoch [80/100], Step [41900/6235], Loss: 3.3732\n",
      "Epoch [80/100], Step [42000/6235], Loss: 3.4855\n",
      "Epoch [80/100], Step [42100/6235], Loss: 12.2036\n",
      "Epoch [80/100], Step [42200/6235], Loss: 63.7838\n",
      "Epoch [80/100], Step [42300/6235], Loss: 0.2524\n",
      "Epoch [80/100], Step [42400/6235], Loss: 2.0536\n",
      "Epoch [80/100], Step [42500/6235], Loss: 0.9410\n",
      "Epoch [80/100], Step [42600/6235], Loss: 0.4782\n",
      "Epoch [80/100], Step [42700/6235], Loss: 0.6292\n",
      "Epoch [80/100], Step [42800/6235], Loss: 15.7350\n",
      "Epoch [80/100], Step [42900/6235], Loss: 0.1820\n",
      "Epoch [80/100], Step [43000/6235], Loss: 0.7456\n",
      "Epoch [80/100], Step [43100/6235], Loss: 0.1033\n",
      "Epoch [80/100], Step [43200/6235], Loss: 0.0366\n",
      "Epoch [80/100], Step [43300/6235], Loss: 3.8560\n",
      "Epoch [80/100], Step [43400/6235], Loss: 3.8079\n",
      "Epoch [80/100], Step [43500/6235], Loss: 12.6383\n",
      "Epoch [80/100], Step [43600/6235], Loss: 1.0582\n",
      "Epoch [80/100], Step [43700/6235], Loss: 38.7715\n",
      "Epoch [80/100], Step [43800/6235], Loss: 0.3353\n",
      "Epoch [80/100], Step [43900/6235], Loss: 3.6692\n",
      "Epoch [80/100], Step [44000/6235], Loss: 55.9629\n",
      "Epoch [80/100], Step [44100/6235], Loss: 0.3110\n",
      "Epoch [80/100], Step [44200/6235], Loss: 1.4012\n",
      "Epoch [80/100], Step [44300/6235], Loss: 11.3974\n",
      "Epoch [80/100], Step [44400/6235], Loss: 0.6939\n",
      "Epoch [80/100], Step [44500/6235], Loss: 1.9040\n",
      "Epoch [80/100], Step [44600/6235], Loss: 25.1191\n",
      "Epoch [80/100], Step [44700/6235], Loss: 5.8798\n",
      "Epoch [80/100], Step [44800/6235], Loss: 5.5271\n",
      "Epoch [80/100], Step [44900/6235], Loss: 11.7816\n",
      "Epoch [80/100], Step [45000/6235], Loss: 6.0146\n",
      "Epoch [80/100], Step [45100/6235], Loss: 46.7591\n",
      "Epoch [80/100], Step [45200/6235], Loss: 5.7554\n",
      "Epoch [80/100], Step [45300/6235], Loss: 23.2084\n",
      "Epoch [80/100], Step [45400/6235], Loss: 3.9541\n",
      "Epoch [80/100], Step [45500/6235], Loss: 3.2350\n",
      "Epoch [80/100], Step [45600/6235], Loss: 1.4729\n",
      "Epoch [80/100], Step [45700/6235], Loss: 109.6250\n",
      "Epoch [80/100], Step [45800/6235], Loss: 312.3434\n",
      "Epoch [80/100], Step [45900/6235], Loss: 14.6671\n",
      "Epoch [80/100], Step [46000/6235], Loss: 1.6469\n",
      "Epoch [80/100], Step [46100/6235], Loss: 15.6275\n",
      "Epoch [80/100], Step [46200/6235], Loss: 15.9850\n",
      "Epoch [80/100], Step [46300/6235], Loss: 45.9072\n",
      "Epoch [80/100], Step [46400/6235], Loss: 7.1984\n",
      "Epoch [80/100], Step [46500/6235], Loss: 168.6016\n",
      "Epoch [80/100], Step [46600/6235], Loss: 11.2820\n",
      "Epoch [80/100], Step [46700/6235], Loss: 16.6533\n",
      "Epoch [80/100], Step [46800/6235], Loss: 26.0414\n",
      "Epoch [80/100], Step [46900/6235], Loss: 4.8030\n",
      "Epoch [80/100], Step [47000/6235], Loss: 6.3088\n",
      "Epoch [80/100], Step [47100/6235], Loss: 7.4709\n",
      "Epoch [80/100], Step [47200/6235], Loss: 103.0415\n",
      "Epoch [80/100], Step [47300/6235], Loss: 0.9817\n",
      "Epoch [80/100], Step [47400/6235], Loss: 312.5750\n",
      "Epoch [80/100], Step [47500/6235], Loss: 10.6609\n",
      "Epoch [80/100], Step [47600/6235], Loss: 2.7846\n",
      "Epoch [80/100], Step [47700/6235], Loss: 7.3250\n",
      "Epoch [80/100], Step [47800/6235], Loss: 5.9158\n",
      "Epoch [80/100], Step [47900/6235], Loss: 17.1867\n",
      "Epoch [80/100], Step [48000/6235], Loss: 24.2800\n",
      "Epoch [80/100], Step [48100/6235], Loss: 4.5410\n",
      "Epoch [80/100], Step [48200/6235], Loss: 11.2545\n",
      "Epoch [80/100], Step [48300/6235], Loss: 456.3542\n",
      "Epoch [80/100], Step [48400/6235], Loss: 19.1355\n",
      "Epoch [80/100], Step [48500/6235], Loss: 21.8163\n",
      "Epoch [80/100], Step [48600/6235], Loss: 159.3111\n",
      "Epoch [80/100], Step [48700/6235], Loss: 8.9558\n",
      "Epoch [80/100], Step [48800/6235], Loss: 200.9554\n",
      "Epoch [80/100], Step [48900/6235], Loss: 422.7467\n",
      "Epoch [80/100], Step [49000/6235], Loss: 256.1177\n",
      "Epoch [80/100], Step [49100/6235], Loss: 2500.4211\n",
      "Epoch [80/100], Step [49200/6235], Loss: 659.1429\n",
      "Epoch [80/100], Step [49300/6235], Loss: 1279.9802\n",
      "Epoch [80/100], Step [49400/6235], Loss: 8.6772\n",
      "Epoch [80/100], Step [49500/6235], Loss: 15.6446\n",
      "Epoch [80/100], Step [49600/6235], Loss: 1079.7899\n",
      "Epoch [80/100], Step [49700/6235], Loss: 1211.6326\n",
      "Epoch [80/100], Step [49800/6235], Loss: 446.4891\n",
      "Epoch [81/100], Step [100/6235], Loss: 5.7091\n",
      "Epoch [81/100], Step [200/6235], Loss: 0.1840\n",
      "Epoch [81/100], Step [300/6235], Loss: 0.0261\n",
      "Epoch [81/100], Step [400/6235], Loss: 0.0027\n",
      "Epoch [81/100], Step [500/6235], Loss: 4.8999\n",
      "Epoch [81/100], Step [600/6235], Loss: 0.0293\n",
      "Epoch [81/100], Step [700/6235], Loss: 0.5406\n",
      "Epoch [81/100], Step [800/6235], Loss: 0.1924\n",
      "Epoch [81/100], Step [900/6235], Loss: 0.0921\n",
      "Epoch [81/100], Step [1000/6235], Loss: 0.0542\n",
      "Epoch [81/100], Step [1100/6235], Loss: 0.0563\n",
      "Epoch [81/100], Step [1200/6235], Loss: 0.1742\n",
      "Epoch [81/100], Step [1300/6235], Loss: 0.0353\n",
      "Epoch [81/100], Step [1400/6235], Loss: 0.0594\n",
      "Epoch [81/100], Step [1500/6235], Loss: 0.0098\n",
      "Epoch [81/100], Step [1600/6235], Loss: 0.2309\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Step [1700/6235], Loss: 0.0597\n",
      "Epoch [81/100], Step [1800/6235], Loss: 0.2196\n",
      "Epoch [81/100], Step [1900/6235], Loss: 0.6768\n",
      "Epoch [81/100], Step [2000/6235], Loss: 2.2358\n",
      "Epoch [81/100], Step [2100/6235], Loss: 2.2857\n",
      "Epoch [81/100], Step [2200/6235], Loss: 8.7375\n",
      "Epoch [81/100], Step [2300/6235], Loss: 8.6524\n",
      "Epoch [81/100], Step [2400/6235], Loss: 13.3878\n",
      "Epoch [81/100], Step [2500/6235], Loss: 148.0030\n",
      "Epoch [81/100], Step [2600/6235], Loss: 13.1891\n",
      "Epoch [81/100], Step [2700/6235], Loss: 10.6695\n",
      "Epoch [81/100], Step [2800/6235], Loss: 103.8695\n",
      "Epoch [81/100], Step [2900/6235], Loss: 12.9973\n",
      "Epoch [81/100], Step [3000/6235], Loss: 1.4323\n",
      "Epoch [81/100], Step [3100/6235], Loss: 67.5203\n",
      "Epoch [81/100], Step [3200/6235], Loss: 78.2359\n",
      "Epoch [81/100], Step [3300/6235], Loss: 7.3594\n",
      "Epoch [81/100], Step [3400/6235], Loss: 1.8400\n",
      "Epoch [81/100], Step [3500/6235], Loss: 37.1311\n",
      "Epoch [81/100], Step [3600/6235], Loss: 8.2535\n",
      "Epoch [81/100], Step [3700/6235], Loss: 0.0839\n",
      "Epoch [81/100], Step [3800/6235], Loss: 0.2369\n",
      "Epoch [81/100], Step [3900/6235], Loss: 0.6474\n",
      "Epoch [81/100], Step [4000/6235], Loss: 0.0357\n",
      "Epoch [81/100], Step [4100/6235], Loss: 7.1897\n",
      "Epoch [81/100], Step [4200/6235], Loss: 0.6367\n",
      "Epoch [81/100], Step [4300/6235], Loss: 8.4363\n",
      "Epoch [81/100], Step [4400/6235], Loss: 2.9329\n",
      "Epoch [81/100], Step [4500/6235], Loss: 59.0325\n",
      "Epoch [81/100], Step [4600/6235], Loss: 1.4275\n",
      "Epoch [81/100], Step [4700/6235], Loss: 0.0918\n",
      "Epoch [81/100], Step [4800/6235], Loss: 10.5636\n",
      "Epoch [81/100], Step [4900/6235], Loss: 0.4146\n",
      "Epoch [81/100], Step [5000/6235], Loss: 0.0734\n",
      "Epoch [81/100], Step [5100/6235], Loss: 3.5240\n",
      "Epoch [81/100], Step [5200/6235], Loss: 0.6908\n",
      "Epoch [81/100], Step [5300/6235], Loss: 42.0737\n",
      "Epoch [81/100], Step [5400/6235], Loss: 4.6056\n",
      "Epoch [81/100], Step [5500/6235], Loss: 0.8736\n",
      "Epoch [81/100], Step [5600/6235], Loss: 0.4736\n",
      "Epoch [81/100], Step [5700/6235], Loss: 0.0524\n",
      "Epoch [81/100], Step [5800/6235], Loss: 1.3796\n",
      "Epoch [81/100], Step [5900/6235], Loss: 0.4547\n",
      "Epoch [81/100], Step [6000/6235], Loss: 3.1797\n",
      "Epoch [81/100], Step [6100/6235], Loss: 0.0732\n",
      "Epoch [81/100], Step [6200/6235], Loss: 2.5789\n",
      "Epoch [81/100], Step [6300/6235], Loss: 1.7928\n",
      "Epoch [81/100], Step [6400/6235], Loss: 0.0404\n",
      "Epoch [81/100], Step [6500/6235], Loss: 2.2541\n",
      "Epoch [81/100], Step [6600/6235], Loss: 25.9572\n",
      "Epoch [81/100], Step [6700/6235], Loss: 4.2327\n",
      "Epoch [81/100], Step [6800/6235], Loss: 0.3968\n",
      "Epoch [81/100], Step [6900/6235], Loss: 0.8098\n",
      "Epoch [81/100], Step [7000/6235], Loss: 0.2297\n",
      "Epoch [81/100], Step [7100/6235], Loss: 0.3084\n",
      "Epoch [81/100], Step [7200/6235], Loss: 0.0769\n",
      "Epoch [81/100], Step [7300/6235], Loss: 0.1934\n",
      "Epoch [81/100], Step [7400/6235], Loss: 0.2689\n",
      "Epoch [81/100], Step [7500/6235], Loss: 0.5362\n",
      "Epoch [81/100], Step [7600/6235], Loss: 5.2704\n",
      "Epoch [81/100], Step [7700/6235], Loss: 20.7077\n",
      "Epoch [81/100], Step [7800/6235], Loss: 9.0002\n",
      "Epoch [81/100], Step [7900/6235], Loss: 1.8042\n",
      "Epoch [81/100], Step [8000/6235], Loss: 0.2296\n",
      "Epoch [81/100], Step [8100/6235], Loss: 4.6171\n",
      "Epoch [81/100], Step [8200/6235], Loss: 14.4902\n",
      "Epoch [81/100], Step [8300/6235], Loss: 35.1859\n",
      "Epoch [81/100], Step [8400/6235], Loss: 177.0417\n",
      "Epoch [81/100], Step [8500/6235], Loss: 1.9203\n",
      "Epoch [81/100], Step [8600/6235], Loss: 152.9508\n",
      "Epoch [81/100], Step [8700/6235], Loss: 86.1832\n",
      "Epoch [81/100], Step [8800/6235], Loss: 274.6895\n",
      "Epoch [81/100], Step [8900/6235], Loss: 159.1651\n",
      "Epoch [81/100], Step [9000/6235], Loss: 673.1752\n",
      "Epoch [81/100], Step [9100/6235], Loss: 3387.4832\n",
      "Epoch [81/100], Step [9200/6235], Loss: 6334.0293\n",
      "Epoch [81/100], Step [9300/6235], Loss: 92.4192\n",
      "Epoch [81/100], Step [9400/6235], Loss: 90.3877\n",
      "Epoch [81/100], Step [9500/6235], Loss: 2432.1323\n",
      "Epoch [81/100], Step [9600/6235], Loss: 710.0425\n",
      "Epoch [81/100], Step [9700/6235], Loss: 4.2068\n",
      "Epoch [81/100], Step [9800/6235], Loss: 2000.1012\n",
      "Epoch [81/100], Step [9900/6235], Loss: 122.9633\n",
      "Epoch [81/100], Step [10000/6235], Loss: 108.9161\n",
      "Epoch [81/100], Step [10100/6235], Loss: 1.9652\n",
      "Epoch [81/100], Step [10200/6235], Loss: 950.4025\n",
      "Epoch [81/100], Step [10300/6235], Loss: 24.7293\n",
      "Epoch [81/100], Step [10400/6235], Loss: 9.4569\n",
      "Epoch [81/100], Step [10500/6235], Loss: 40.6794\n",
      "Epoch [81/100], Step [10600/6235], Loss: 484.1608\n",
      "Epoch [81/100], Step [10700/6235], Loss: 30.0681\n",
      "Epoch [81/100], Step [10800/6235], Loss: 83.2890\n",
      "Epoch [81/100], Step [10900/6235], Loss: 113.3377\n",
      "Epoch [81/100], Step [11000/6235], Loss: 295.6381\n",
      "Epoch [81/100], Step [11100/6235], Loss: 20.2209\n",
      "Epoch [81/100], Step [11200/6235], Loss: 2.3486\n",
      "Epoch [81/100], Step [11300/6235], Loss: 98.7474\n",
      "Epoch [81/100], Step [11400/6235], Loss: 17.8136\n",
      "Epoch [81/100], Step [11500/6235], Loss: 11.3756\n",
      "Epoch [81/100], Step [11600/6235], Loss: 8.9195\n",
      "Epoch [81/100], Step [11700/6235], Loss: 47.1048\n",
      "Epoch [81/100], Step [11800/6235], Loss: 344.9455\n",
      "Epoch [81/100], Step [11900/6235], Loss: 365.5129\n",
      "Epoch [81/100], Step [12000/6235], Loss: 697.5869\n",
      "Epoch [81/100], Step [12100/6235], Loss: 257.3998\n",
      "Epoch [81/100], Step [12200/6235], Loss: 15.1726\n",
      "Epoch [81/100], Step [12300/6235], Loss: 1.7339\n",
      "Epoch [81/100], Step [12400/6235], Loss: 49.2583\n",
      "Epoch [81/100], Step [12500/6235], Loss: 47.7093\n",
      "Epoch [81/100], Step [12600/6235], Loss: 11.9974\n",
      "Epoch [81/100], Step [12700/6235], Loss: 6.2438\n",
      "Epoch [81/100], Step [12800/6235], Loss: 9.7796\n",
      "Epoch [81/100], Step [12900/6235], Loss: 30.8224\n",
      "Epoch [81/100], Step [13000/6235], Loss: 0.1746\n",
      "Epoch [81/100], Step [13100/6235], Loss: 62.8294\n",
      "Epoch [81/100], Step [13200/6235], Loss: 8.2044\n",
      "Epoch [81/100], Step [13300/6235], Loss: 25.8631\n",
      "Epoch [81/100], Step [13400/6235], Loss: 219.9319\n",
      "Epoch [81/100], Step [13500/6235], Loss: 3.5934\n",
      "Epoch [81/100], Step [13600/6235], Loss: 3.5679\n",
      "Epoch [81/100], Step [13700/6235], Loss: 115.6124\n",
      "Epoch [81/100], Step [13800/6235], Loss: 90.9619\n",
      "Epoch [81/100], Step [13900/6235], Loss: 28.6243\n",
      "Epoch [81/100], Step [14000/6235], Loss: 9.3483\n",
      "Epoch [81/100], Step [14100/6235], Loss: 42.6913\n",
      "Epoch [81/100], Step [14200/6235], Loss: 137.2158\n",
      "Epoch [81/100], Step [14300/6235], Loss: 16.9378\n",
      "Epoch [81/100], Step [14400/6235], Loss: 34.0472\n",
      "Epoch [81/100], Step [14500/6235], Loss: 27.0596\n",
      "Epoch [81/100], Step [14600/6235], Loss: 3.0939\n",
      "Epoch [81/100], Step [14700/6235], Loss: 21.3624\n",
      "Epoch [81/100], Step [14800/6235], Loss: 26.6662\n",
      "Epoch [81/100], Step [14900/6235], Loss: 0.7970\n",
      "Epoch [81/100], Step [15000/6235], Loss: 0.9704\n",
      "Epoch [81/100], Step [15100/6235], Loss: 0.3209\n",
      "Epoch [81/100], Step [15200/6235], Loss: 24.7641\n",
      "Epoch [81/100], Step [15300/6235], Loss: 33.8330\n",
      "Epoch [81/100], Step [15400/6235], Loss: 83.4300\n",
      "Epoch [81/100], Step [15500/6235], Loss: 9.4699\n",
      "Epoch [81/100], Step [15600/6235], Loss: 188.0723\n",
      "Epoch [81/100], Step [15700/6235], Loss: 185.9168\n",
      "Epoch [81/100], Step [15800/6235], Loss: 0.6558\n",
      "Epoch [81/100], Step [15900/6235], Loss: 2.9473\n",
      "Epoch [81/100], Step [16000/6235], Loss: 169.4331\n",
      "Epoch [81/100], Step [16100/6235], Loss: 0.6439\n",
      "Epoch [81/100], Step [16200/6235], Loss: 0.2670\n",
      "Epoch [81/100], Step [16300/6235], Loss: 8.7851\n",
      "Epoch [81/100], Step [16400/6235], Loss: 26.1729\n",
      "Epoch [81/100], Step [16500/6235], Loss: 366.6713\n",
      "Epoch [81/100], Step [16600/6235], Loss: 13.7944\n",
      "Epoch [81/100], Step [16700/6235], Loss: 0.2907\n",
      "Epoch [81/100], Step [16800/6235], Loss: 15.5242\n",
      "Epoch [81/100], Step [16900/6235], Loss: 0.2317\n",
      "Epoch [81/100], Step [17000/6235], Loss: 0.2194\n",
      "Epoch [81/100], Step [17100/6235], Loss: 0.0255\n",
      "Epoch [81/100], Step [17200/6235], Loss: 269.6001\n",
      "Epoch [81/100], Step [17300/6235], Loss: 19.0869\n",
      "Epoch [81/100], Step [17400/6235], Loss: 44.5545\n",
      "Epoch [81/100], Step [17500/6235], Loss: 2.5342\n",
      "Epoch [81/100], Step [17600/6235], Loss: 2.6891\n",
      "Epoch [81/100], Step [17700/6235], Loss: 4.9398\n",
      "Epoch [81/100], Step [17800/6235], Loss: 25.9457\n",
      "Epoch [81/100], Step [17900/6235], Loss: 14.0463\n",
      "Epoch [81/100], Step [18000/6235], Loss: 10.4946\n",
      "Epoch [81/100], Step [18100/6235], Loss: 17.9677\n",
      "Epoch [81/100], Step [18200/6235], Loss: 0.7255\n",
      "Epoch [81/100], Step [18300/6235], Loss: 5.1536\n",
      "Epoch [81/100], Step [18400/6235], Loss: 3.8676\n",
      "Epoch [81/100], Step [18500/6235], Loss: 10.3674\n",
      "Epoch [81/100], Step [18600/6235], Loss: 1.1951\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Step [18700/6235], Loss: 0.3597\n",
      "Epoch [81/100], Step [18800/6235], Loss: 111.7664\n",
      "Epoch [81/100], Step [18900/6235], Loss: 47.9733\n",
      "Epoch [81/100], Step [19000/6235], Loss: 18.2981\n",
      "Epoch [81/100], Step [19100/6235], Loss: 7.7948\n",
      "Epoch [81/100], Step [19200/6235], Loss: 4.5973\n",
      "Epoch [81/100], Step [19300/6235], Loss: 5.2185\n",
      "Epoch [81/100], Step [19400/6235], Loss: 282.4945\n",
      "Epoch [81/100], Step [19500/6235], Loss: 110.1220\n",
      "Epoch [81/100], Step [19600/6235], Loss: 101.0753\n",
      "Epoch [81/100], Step [19700/6235], Loss: 7.1499\n",
      "Epoch [81/100], Step [19800/6235], Loss: 0.6844\n",
      "Epoch [81/100], Step [19900/6235], Loss: 0.9583\n",
      "Epoch [81/100], Step [20000/6235], Loss: 85.6941\n",
      "Epoch [81/100], Step [20100/6235], Loss: 3.2863\n",
      "Epoch [81/100], Step [20200/6235], Loss: 4.8097\n",
      "Epoch [81/100], Step [20300/6235], Loss: 1.4087\n",
      "Epoch [81/100], Step [20400/6235], Loss: 25.9122\n",
      "Epoch [81/100], Step [20500/6235], Loss: 32.9494\n",
      "Epoch [81/100], Step [20600/6235], Loss: 5.4021\n",
      "Epoch [81/100], Step [20700/6235], Loss: 15.2269\n",
      "Epoch [81/100], Step [20800/6235], Loss: 0.8587\n",
      "Epoch [81/100], Step [20900/6235], Loss: 20.9369\n",
      "Epoch [81/100], Step [21000/6235], Loss: 16.3253\n",
      "Epoch [81/100], Step [21100/6235], Loss: 1.1606\n",
      "Epoch [81/100], Step [21200/6235], Loss: 0.1278\n",
      "Epoch [81/100], Step [21300/6235], Loss: 0.1350\n",
      "Epoch [81/100], Step [21400/6235], Loss: 5.0786\n",
      "Epoch [81/100], Step [21500/6235], Loss: 1.8296\n",
      "Epoch [81/100], Step [21600/6235], Loss: 32.7690\n",
      "Epoch [81/100], Step [21700/6235], Loss: 0.1796\n",
      "Epoch [81/100], Step [21800/6235], Loss: 3.5283\n",
      "Epoch [81/100], Step [21900/6235], Loss: 0.0773\n",
      "Epoch [81/100], Step [22000/6235], Loss: 1.9532\n",
      "Epoch [81/100], Step [22100/6235], Loss: 5.1207\n",
      "Epoch [81/100], Step [22200/6235], Loss: 9.9509\n",
      "Epoch [81/100], Step [22300/6235], Loss: 1.1387\n",
      "Epoch [81/100], Step [22400/6235], Loss: 3.5225\n",
      "Epoch [81/100], Step [22500/6235], Loss: 127.6240\n",
      "Epoch [81/100], Step [22600/6235], Loss: 15.9868\n",
      "Epoch [81/100], Step [22700/6235], Loss: 0.9182\n",
      "Epoch [81/100], Step [22800/6235], Loss: 2.6540\n",
      "Epoch [81/100], Step [22900/6235], Loss: 9.5985\n",
      "Epoch [81/100], Step [23000/6235], Loss: 10.9133\n",
      "Epoch [81/100], Step [23100/6235], Loss: 7.3357\n",
      "Epoch [81/100], Step [23200/6235], Loss: 15.9507\n",
      "Epoch [81/100], Step [23300/6235], Loss: 18.0499\n",
      "Epoch [81/100], Step [23400/6235], Loss: 0.4300\n",
      "Epoch [81/100], Step [23500/6235], Loss: 0.3074\n",
      "Epoch [81/100], Step [23600/6235], Loss: 96.6652\n",
      "Epoch [81/100], Step [23700/6235], Loss: 7.6822\n",
      "Epoch [81/100], Step [23800/6235], Loss: 0.7990\n",
      "Epoch [81/100], Step [23900/6235], Loss: 7.9073\n",
      "Epoch [81/100], Step [24000/6235], Loss: 0.7837\n",
      "Epoch [81/100], Step [24100/6235], Loss: 0.9734\n",
      "Epoch [81/100], Step [24200/6235], Loss: 28.2631\n",
      "Epoch [81/100], Step [24300/6235], Loss: 1.2889\n",
      "Epoch [81/100], Step [24400/6235], Loss: 4.5081\n",
      "Epoch [81/100], Step [24500/6235], Loss: 2.4724\n",
      "Epoch [81/100], Step [24600/6235], Loss: 0.1348\n",
      "Epoch [81/100], Step [24700/6235], Loss: 1.1135\n",
      "Epoch [81/100], Step [24800/6235], Loss: 0.0643\n",
      "Epoch [81/100], Step [24900/6235], Loss: 0.5497\n",
      "Epoch [81/100], Step [25000/6235], Loss: 17.2782\n",
      "Epoch [81/100], Step [25100/6235], Loss: 8.5162\n",
      "Epoch [81/100], Step [25200/6235], Loss: 1.9556\n",
      "Epoch [81/100], Step [25300/6235], Loss: 0.8396\n",
      "Epoch [81/100], Step [25400/6235], Loss: 10.0482\n",
      "Epoch [81/100], Step [25500/6235], Loss: 4.1524\n",
      "Epoch [81/100], Step [25600/6235], Loss: 1.5396\n",
      "Epoch [81/100], Step [25700/6235], Loss: 0.2245\n",
      "Epoch [81/100], Step [25800/6235], Loss: 0.1602\n",
      "Epoch [81/100], Step [25900/6235], Loss: 10.4062\n",
      "Epoch [81/100], Step [26000/6235], Loss: 1.1320\n",
      "Epoch [81/100], Step [26100/6235], Loss: 0.4001\n",
      "Epoch [81/100], Step [26200/6235], Loss: 0.0675\n",
      "Epoch [81/100], Step [26300/6235], Loss: 4.5955\n",
      "Epoch [81/100], Step [26400/6235], Loss: 0.1938\n",
      "Epoch [81/100], Step [26500/6235], Loss: 0.3024\n",
      "Epoch [81/100], Step [26600/6235], Loss: 3.8542\n",
      "Epoch [81/100], Step [26700/6235], Loss: 0.7522\n",
      "Epoch [81/100], Step [26800/6235], Loss: 0.8743\n",
      "Epoch [81/100], Step [26900/6235], Loss: 0.0733\n",
      "Epoch [81/100], Step [27000/6235], Loss: 11.4625\n",
      "Epoch [81/100], Step [27100/6235], Loss: 0.2896\n",
      "Epoch [81/100], Step [27200/6235], Loss: 0.1105\n",
      "Epoch [81/100], Step [27300/6235], Loss: 0.1498\n",
      "Epoch [81/100], Step [27400/6235], Loss: 0.9981\n",
      "Epoch [81/100], Step [27500/6235], Loss: 18.0081\n",
      "Epoch [81/100], Step [27600/6235], Loss: 0.8474\n",
      "Epoch [81/100], Step [27700/6235], Loss: 1.4127\n",
      "Epoch [81/100], Step [27800/6235], Loss: 2.3504\n",
      "Epoch [81/100], Step [27900/6235], Loss: 0.1932\n",
      "Epoch [81/100], Step [28000/6235], Loss: 157.0612\n",
      "Epoch [81/100], Step [28100/6235], Loss: 1.2248\n",
      "Epoch [81/100], Step [28200/6235], Loss: 26.7928\n",
      "Epoch [81/100], Step [28300/6235], Loss: 3.1495\n",
      "Epoch [81/100], Step [28400/6235], Loss: 25.3951\n",
      "Epoch [81/100], Step [28500/6235], Loss: 2.6718\n",
      "Epoch [81/100], Step [28600/6235], Loss: 0.2302\n",
      "Epoch [81/100], Step [28700/6235], Loss: 5.0180\n",
      "Epoch [81/100], Step [28800/6235], Loss: 0.4626\n",
      "Epoch [81/100], Step [28900/6235], Loss: 74.0244\n",
      "Epoch [81/100], Step [29000/6235], Loss: 10.6976\n",
      "Epoch [81/100], Step [29100/6235], Loss: 0.0124\n",
      "Epoch [81/100], Step [29200/6235], Loss: 0.0919\n",
      "Epoch [81/100], Step [29300/6235], Loss: 0.6618\n",
      "Epoch [81/100], Step [29400/6235], Loss: 1.0160\n",
      "Epoch [81/100], Step [29500/6235], Loss: 4.0627\n",
      "Epoch [81/100], Step [29600/6235], Loss: 0.7322\n",
      "Epoch [81/100], Step [29700/6235], Loss: 0.2795\n",
      "Epoch [81/100], Step [29800/6235], Loss: 1.6682\n",
      "Epoch [81/100], Step [29900/6235], Loss: 0.3692\n",
      "Epoch [81/100], Step [30000/6235], Loss: 5.4376\n",
      "Epoch [81/100], Step [30100/6235], Loss: 9.5381\n",
      "Epoch [81/100], Step [30200/6235], Loss: 0.0458\n",
      "Epoch [81/100], Step [30300/6235], Loss: 0.6022\n",
      "Epoch [81/100], Step [30400/6235], Loss: 0.1665\n",
      "Epoch [81/100], Step [30500/6235], Loss: 1.9159\n",
      "Epoch [81/100], Step [30600/6235], Loss: 0.5285\n",
      "Epoch [81/100], Step [30700/6235], Loss: 0.1542\n",
      "Epoch [81/100], Step [30800/6235], Loss: 0.2420\n",
      "Epoch [81/100], Step [30900/6235], Loss: 3.0644\n",
      "Epoch [81/100], Step [31000/6235], Loss: 0.0332\n",
      "Epoch [81/100], Step [31100/6235], Loss: 0.0527\n",
      "Epoch [81/100], Step [31200/6235], Loss: 6.0754\n",
      "Epoch [81/100], Step [31300/6235], Loss: 1.5433\n",
      "Epoch [81/100], Step [31400/6235], Loss: 11.9038\n",
      "Epoch [81/100], Step [31500/6235], Loss: 0.5785\n",
      "Epoch [81/100], Step [31600/6235], Loss: 6.6438\n",
      "Epoch [81/100], Step [31700/6235], Loss: 13.7198\n",
      "Epoch [81/100], Step [31800/6235], Loss: 1.4162\n",
      "Epoch [81/100], Step [31900/6235], Loss: 530.8787\n",
      "Epoch [81/100], Step [32000/6235], Loss: 11.2574\n",
      "Epoch [81/100], Step [32100/6235], Loss: 1.6606\n",
      "Epoch [81/100], Step [32200/6235], Loss: 100.0619\n",
      "Epoch [81/100], Step [32300/6235], Loss: 1.7092\n",
      "Epoch [81/100], Step [32400/6235], Loss: 1.1473\n",
      "Epoch [81/100], Step [32500/6235], Loss: 19.6783\n",
      "Epoch [81/100], Step [32600/6235], Loss: 0.6655\n",
      "Epoch [81/100], Step [32700/6235], Loss: 93.9817\n",
      "Epoch [81/100], Step [32800/6235], Loss: 2.7636\n",
      "Epoch [81/100], Step [32900/6235], Loss: 7.7041\n",
      "Epoch [81/100], Step [33000/6235], Loss: 0.3781\n",
      "Epoch [81/100], Step [33100/6235], Loss: 0.8696\n",
      "Epoch [81/100], Step [33200/6235], Loss: 1.0687\n",
      "Epoch [81/100], Step [33300/6235], Loss: 1.3611\n",
      "Epoch [81/100], Step [33400/6235], Loss: 137.8020\n",
      "Epoch [81/100], Step [33500/6235], Loss: 2.9487\n",
      "Epoch [81/100], Step [33600/6235], Loss: 1.4135\n",
      "Epoch [81/100], Step [33700/6235], Loss: 3.1529\n",
      "Epoch [81/100], Step [33800/6235], Loss: 0.6393\n",
      "Epoch [81/100], Step [33900/6235], Loss: 27.0592\n",
      "Epoch [81/100], Step [34000/6235], Loss: 0.0070\n",
      "Epoch [81/100], Step [34100/6235], Loss: 0.2855\n",
      "Epoch [81/100], Step [34200/6235], Loss: 2.5151\n",
      "Epoch [81/100], Step [34300/6235], Loss: 6.3015\n",
      "Epoch [81/100], Step [34400/6235], Loss: 0.1279\n",
      "Epoch [81/100], Step [34500/6235], Loss: 77.9157\n",
      "Epoch [81/100], Step [34600/6235], Loss: 0.1452\n",
      "Epoch [81/100], Step [34700/6235], Loss: 2.5530\n",
      "Epoch [81/100], Step [34800/6235], Loss: 15.5756\n",
      "Epoch [81/100], Step [34900/6235], Loss: 68.3821\n",
      "Epoch [81/100], Step [35000/6235], Loss: 1.3052\n",
      "Epoch [81/100], Step [35100/6235], Loss: 0.4479\n",
      "Epoch [81/100], Step [35200/6235], Loss: 0.3931\n",
      "Epoch [81/100], Step [35300/6235], Loss: 2.3803\n",
      "Epoch [81/100], Step [35400/6235], Loss: 0.4216\n",
      "Epoch [81/100], Step [35500/6235], Loss: 2.2728\n",
      "Epoch [81/100], Step [35600/6235], Loss: 1.3082\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [81/100], Step [35700/6235], Loss: 6.5955\n",
      "Epoch [81/100], Step [35800/6235], Loss: 0.3650\n",
      "Epoch [81/100], Step [35900/6235], Loss: 0.2498\n",
      "Epoch [81/100], Step [36000/6235], Loss: 0.4392\n",
      "Epoch [81/100], Step [36100/6235], Loss: 0.0110\n",
      "Epoch [81/100], Step [36200/6235], Loss: 15.9725\n",
      "Epoch [81/100], Step [36300/6235], Loss: 0.6436\n",
      "Epoch [81/100], Step [36400/6235], Loss: 2.0625\n",
      "Epoch [81/100], Step [36500/6235], Loss: 9.2504\n",
      "Epoch [81/100], Step [36600/6235], Loss: 0.1600\n",
      "Epoch [81/100], Step [36700/6235], Loss: 0.2828\n",
      "Epoch [81/100], Step [36800/6235], Loss: 15.2259\n",
      "Epoch [81/100], Step [36900/6235], Loss: 7.6072\n",
      "Epoch [81/100], Step [37000/6235], Loss: 0.3155\n",
      "Epoch [81/100], Step [37100/6235], Loss: 0.9034\n",
      "Epoch [81/100], Step [37200/6235], Loss: 0.0793\n",
      "Epoch [81/100], Step [37300/6235], Loss: 0.0662\n",
      "Epoch [81/100], Step [37400/6235], Loss: 0.2013\n",
      "Epoch [81/100], Step [37500/6235], Loss: 3.8634\n",
      "Epoch [81/100], Step [37600/6235], Loss: 11.3992\n",
      "Epoch [81/100], Step [37700/6235], Loss: 0.9860\n",
      "Epoch [81/100], Step [37800/6235], Loss: 6.7936\n",
      "Epoch [81/100], Step [37900/6235], Loss: 7.1638\n",
      "Epoch [81/100], Step [38000/6235], Loss: 0.4743\n",
      "Epoch [81/100], Step [38100/6235], Loss: 3.0382\n",
      "Epoch [81/100], Step [38200/6235], Loss: 2.1538\n",
      "Epoch [81/100], Step [38300/6235], Loss: 1.0093\n",
      "Epoch [81/100], Step [38400/6235], Loss: 0.1496\n",
      "Epoch [81/100], Step [38500/6235], Loss: 3.1866\n",
      "Epoch [81/100], Step [38600/6235], Loss: 0.1078\n",
      "Epoch [81/100], Step [38700/6235], Loss: 0.1576\n",
      "Epoch [81/100], Step [38800/6235], Loss: 0.3032\n",
      "Epoch [81/100], Step [38900/6235], Loss: 3.3135\n",
      "Epoch [81/100], Step [39000/6235], Loss: 8.9499\n",
      "Epoch [81/100], Step [39100/6235], Loss: 17.9538\n",
      "Epoch [81/100], Step [39200/6235], Loss: 0.5329\n",
      "Epoch [81/100], Step [39300/6235], Loss: 0.4847\n",
      "Epoch [81/100], Step [39400/6235], Loss: 367.9368\n",
      "Epoch [81/100], Step [39500/6235], Loss: 49.7619\n",
      "Epoch [81/100], Step [39600/6235], Loss: 5.4076\n",
      "Epoch [81/100], Step [39700/6235], Loss: 229.2293\n",
      "Epoch [81/100], Step [39800/6235], Loss: 208.5100\n",
      "Epoch [81/100], Step [39900/6235], Loss: 39.3356\n",
      "Epoch [81/100], Step [40000/6235], Loss: 4.2613\n",
      "Epoch [81/100], Step [40100/6235], Loss: 6.7208\n",
      "Epoch [81/100], Step [40200/6235], Loss: 25.5263\n",
      "Epoch [81/100], Step [40300/6235], Loss: 0.8609\n",
      "Epoch [81/100], Step [40400/6235], Loss: 0.1975\n",
      "Epoch [81/100], Step [40500/6235], Loss: 3.6153\n",
      "Epoch [81/100], Step [40600/6235], Loss: 0.3572\n",
      "Epoch [81/100], Step [40700/6235], Loss: 4.1559\n",
      "Epoch [81/100], Step [40800/6235], Loss: 2.4848\n",
      "Epoch [81/100], Step [40900/6235], Loss: 1.3135\n",
      "Epoch [81/100], Step [41000/6235], Loss: 32.6182\n",
      "Epoch [81/100], Step [41100/6235], Loss: 23.5334\n",
      "Epoch [81/100], Step [41200/6235], Loss: 11.5376\n",
      "Epoch [81/100], Step [41300/6235], Loss: 2.9146\n",
      "Epoch [81/100], Step [41400/6235], Loss: 0.4766\n",
      "Epoch [81/100], Step [41500/6235], Loss: 16.5272\n",
      "Epoch [81/100], Step [41600/6235], Loss: 5.4531\n",
      "Epoch [81/100], Step [41700/6235], Loss: 0.0812\n",
      "Epoch [81/100], Step [41800/6235], Loss: 0.2810\n",
      "Epoch [81/100], Step [41900/6235], Loss: 3.7084\n",
      "Epoch [81/100], Step [42000/6235], Loss: 3.5754\n",
      "Epoch [81/100], Step [42100/6235], Loss: 12.2047\n",
      "Epoch [81/100], Step [42200/6235], Loss: 71.5585\n",
      "Epoch [81/100], Step [42300/6235], Loss: 0.1325\n",
      "Epoch [81/100], Step [42400/6235], Loss: 1.3374\n",
      "Epoch [81/100], Step [42500/6235], Loss: 1.4846\n",
      "Epoch [81/100], Step [42600/6235], Loss: 1.5852\n",
      "Epoch [81/100], Step [42700/6235], Loss: 0.7068\n",
      "Epoch [81/100], Step [42800/6235], Loss: 17.2604\n",
      "Epoch [81/100], Step [42900/6235], Loss: 0.0737\n",
      "Epoch [81/100], Step [43000/6235], Loss: 0.6345\n",
      "Epoch [81/100], Step [43100/6235], Loss: 0.0811\n",
      "Epoch [81/100], Step [43200/6235], Loss: 0.0249\n",
      "Epoch [81/100], Step [43300/6235], Loss: 3.6535\n",
      "Epoch [81/100], Step [43400/6235], Loss: 3.5680\n",
      "Epoch [81/100], Step [43500/6235], Loss: 12.6887\n",
      "Epoch [81/100], Step [43600/6235], Loss: 1.0095\n",
      "Epoch [81/100], Step [43700/6235], Loss: 35.3433\n",
      "Epoch [81/100], Step [43800/6235], Loss: 0.3925\n",
      "Epoch [81/100], Step [43900/6235], Loss: 4.3144\n",
      "Epoch [81/100], Step [44000/6235], Loss: 58.5484\n",
      "Epoch [81/100], Step [44100/6235], Loss: 0.9977\n",
      "Epoch [81/100], Step [44200/6235], Loss: 4.9129\n",
      "Epoch [81/100], Step [44300/6235], Loss: 16.2597\n",
      "Epoch [81/100], Step [44400/6235], Loss: 0.9354\n",
      "Epoch [81/100], Step [44500/6235], Loss: 4.5044\n",
      "Epoch [81/100], Step [44600/6235], Loss: 14.0378\n",
      "Epoch [81/100], Step [44700/6235], Loss: 7.6330\n",
      "Epoch [81/100], Step [44800/6235], Loss: 0.5262\n",
      "Epoch [81/100], Step [44900/6235], Loss: 10.7350\n",
      "Epoch [81/100], Step [45000/6235], Loss: 5.8067\n",
      "Epoch [81/100], Step [45100/6235], Loss: 46.7859\n",
      "Epoch [81/100], Step [45200/6235], Loss: 1.7438\n",
      "Epoch [81/100], Step [45300/6235], Loss: 25.3580\n",
      "Epoch [81/100], Step [45400/6235], Loss: 9.0021\n",
      "Epoch [81/100], Step [45500/6235], Loss: 3.1462\n",
      "Epoch [81/100], Step [45600/6235], Loss: 1.5614\n",
      "Epoch [81/100], Step [45700/6235], Loss: 118.6685\n",
      "Epoch [81/100], Step [45800/6235], Loss: 280.5228\n",
      "Epoch [81/100], Step [45900/6235], Loss: 13.0263\n",
      "Epoch [81/100], Step [46000/6235], Loss: 0.4298\n",
      "Epoch [81/100], Step [46100/6235], Loss: 17.5600\n",
      "Epoch [81/100], Step [46200/6235], Loss: 90.8981\n",
      "Epoch [81/100], Step [46300/6235], Loss: 12.0669\n",
      "Epoch [81/100], Step [46400/6235], Loss: 16.7779\n",
      "Epoch [81/100], Step [46500/6235], Loss: 88.9327\n",
      "Epoch [81/100], Step [46600/6235], Loss: 21.2992\n",
      "Epoch [81/100], Step [46700/6235], Loss: 5.2038\n",
      "Epoch [81/100], Step [46800/6235], Loss: 28.6142\n",
      "Epoch [81/100], Step [46900/6235], Loss: 15.2633\n",
      "Epoch [81/100], Step [47000/6235], Loss: 0.5350\n",
      "Epoch [81/100], Step [47100/6235], Loss: 131.2790\n",
      "Epoch [81/100], Step [47200/6235], Loss: 24.4401\n",
      "Epoch [81/100], Step [47300/6235], Loss: 8.1518\n",
      "Epoch [81/100], Step [47400/6235], Loss: 333.6340\n",
      "Epoch [81/100], Step [47500/6235], Loss: 28.3715\n",
      "Epoch [81/100], Step [47600/6235], Loss: 16.4657\n",
      "Epoch [81/100], Step [47700/6235], Loss: 31.6597\n",
      "Epoch [81/100], Step [47800/6235], Loss: 35.9568\n",
      "Epoch [81/100], Step [47900/6235], Loss: 12.3639\n",
      "Epoch [81/100], Step [48000/6235], Loss: 6.2997\n",
      "Epoch [81/100], Step [48100/6235], Loss: 10.7090\n",
      "Epoch [81/100], Step [48200/6235], Loss: 140.9980\n",
      "Epoch [81/100], Step [48300/6235], Loss: 647.8505\n",
      "Epoch [81/100], Step [48400/6235], Loss: 3.7175\n",
      "Epoch [81/100], Step [48500/6235], Loss: 42.7272\n",
      "Epoch [81/100], Step [48600/6235], Loss: 34.7387\n",
      "Epoch [81/100], Step [48700/6235], Loss: 13.5680\n",
      "Epoch [81/100], Step [48800/6235], Loss: 727.3257\n",
      "Epoch [81/100], Step [48900/6235], Loss: 780.4777\n",
      "Epoch [81/100], Step [49000/6235], Loss: 67.7475\n",
      "Epoch [81/100], Step [49100/6235], Loss: 1059.6439\n",
      "Epoch [81/100], Step [49200/6235], Loss: 1287.7332\n",
      "Epoch [81/100], Step [49300/6235], Loss: 759.9462\n",
      "Epoch [81/100], Step [49400/6235], Loss: 16.4083\n",
      "Epoch [81/100], Step [49500/6235], Loss: 35.4561\n",
      "Epoch [81/100], Step [49600/6235], Loss: 677.8506\n",
      "Epoch [81/100], Step [49700/6235], Loss: 1567.6301\n",
      "Epoch [81/100], Step [49800/6235], Loss: 356.1645\n",
      "Epoch [82/100], Step [100/6235], Loss: 16.2946\n",
      "Epoch [82/100], Step [200/6235], Loss: 0.1183\n",
      "Epoch [82/100], Step [300/6235], Loss: 0.0010\n",
      "Epoch [82/100], Step [400/6235], Loss: 0.0010\n",
      "Epoch [82/100], Step [500/6235], Loss: 0.4648\n",
      "Epoch [82/100], Step [600/6235], Loss: 0.0291\n",
      "Epoch [82/100], Step [700/6235], Loss: 0.4481\n",
      "Epoch [82/100], Step [800/6235], Loss: 0.1232\n",
      "Epoch [82/100], Step [900/6235], Loss: 0.0213\n",
      "Epoch [82/100], Step [1000/6235], Loss: 0.0256\n",
      "Epoch [82/100], Step [1100/6235], Loss: 0.0109\n",
      "Epoch [82/100], Step [1200/6235], Loss: 0.1694\n",
      "Epoch [82/100], Step [1300/6235], Loss: 0.0364\n",
      "Epoch [82/100], Step [1400/6235], Loss: 0.0334\n",
      "Epoch [82/100], Step [1500/6235], Loss: 0.0056\n",
      "Epoch [82/100], Step [1600/6235], Loss: 0.2236\n",
      "Epoch [82/100], Step [1700/6235], Loss: 0.0132\n",
      "Epoch [82/100], Step [1800/6235], Loss: 0.1934\n",
      "Epoch [82/100], Step [1900/6235], Loss: 0.4922\n",
      "Epoch [82/100], Step [2000/6235], Loss: 2.2375\n",
      "Epoch [82/100], Step [2100/6235], Loss: 1.2041\n",
      "Epoch [82/100], Step [2200/6235], Loss: 9.2870\n",
      "Epoch [82/100], Step [2300/6235], Loss: 10.0366\n",
      "Epoch [82/100], Step [2400/6235], Loss: 2.8948\n",
      "Epoch [82/100], Step [2500/6235], Loss: 38.4891\n",
      "Epoch [82/100], Step [2600/6235], Loss: 11.4720\n",
      "Epoch [82/100], Step [2700/6235], Loss: 9.3627\n",
      "Epoch [82/100], Step [2800/6235], Loss: 108.7505\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Step [2900/6235], Loss: 7.8504\n",
      "Epoch [82/100], Step [3000/6235], Loss: 0.2549\n",
      "Epoch [82/100], Step [3100/6235], Loss: 70.4125\n",
      "Epoch [82/100], Step [3200/6235], Loss: 87.3139\n",
      "Epoch [82/100], Step [3300/6235], Loss: 3.0867\n",
      "Epoch [82/100], Step [3400/6235], Loss: 2.2347\n",
      "Epoch [82/100], Step [3500/6235], Loss: 29.5173\n",
      "Epoch [82/100], Step [3600/6235], Loss: 11.1364\n",
      "Epoch [82/100], Step [3700/6235], Loss: 0.4692\n",
      "Epoch [82/100], Step [3800/6235], Loss: 0.5177\n",
      "Epoch [82/100], Step [3900/6235], Loss: 1.6227\n",
      "Epoch [82/100], Step [4000/6235], Loss: 0.0426\n",
      "Epoch [82/100], Step [4100/6235], Loss: 5.3468\n",
      "Epoch [82/100], Step [4200/6235], Loss: 0.3821\n",
      "Epoch [82/100], Step [4300/6235], Loss: 8.3690\n",
      "Epoch [82/100], Step [4400/6235], Loss: 4.4478\n",
      "Epoch [82/100], Step [4500/6235], Loss: 45.4420\n",
      "Epoch [82/100], Step [4600/6235], Loss: 4.7385\n",
      "Epoch [82/100], Step [4700/6235], Loss: 0.7186\n",
      "Epoch [82/100], Step [4800/6235], Loss: 4.9572\n",
      "Epoch [82/100], Step [4900/6235], Loss: 0.0757\n",
      "Epoch [82/100], Step [5000/6235], Loss: 0.1220\n",
      "Epoch [82/100], Step [5100/6235], Loss: 2.5738\n",
      "Epoch [82/100], Step [5200/6235], Loss: 1.7535\n",
      "Epoch [82/100], Step [5300/6235], Loss: 36.8630\n",
      "Epoch [82/100], Step [5400/6235], Loss: 0.5314\n",
      "Epoch [82/100], Step [5500/6235], Loss: 0.3265\n",
      "Epoch [82/100], Step [5600/6235], Loss: 0.3762\n",
      "Epoch [82/100], Step [5700/6235], Loss: 1.2047\n",
      "Epoch [82/100], Step [5800/6235], Loss: 0.6375\n",
      "Epoch [82/100], Step [5900/6235], Loss: 0.1649\n",
      "Epoch [82/100], Step [6000/6235], Loss: 1.7361\n",
      "Epoch [82/100], Step [6100/6235], Loss: 0.2424\n",
      "Epoch [82/100], Step [6200/6235], Loss: 1.3017\n",
      "Epoch [82/100], Step [6300/6235], Loss: 1.9615\n",
      "Epoch [82/100], Step [6400/6235], Loss: 0.0258\n",
      "Epoch [82/100], Step [6500/6235], Loss: 0.4261\n",
      "Epoch [82/100], Step [6600/6235], Loss: 4.2721\n",
      "Epoch [82/100], Step [6700/6235], Loss: 1.8856\n",
      "Epoch [82/100], Step [6800/6235], Loss: 1.6944\n",
      "Epoch [82/100], Step [6900/6235], Loss: 2.1065\n",
      "Epoch [82/100], Step [7000/6235], Loss: 1.1532\n",
      "Epoch [82/100], Step [7100/6235], Loss: 0.2529\n",
      "Epoch [82/100], Step [7200/6235], Loss: 0.2339\n",
      "Epoch [82/100], Step [7300/6235], Loss: 0.1122\n",
      "Epoch [82/100], Step [7400/6235], Loss: 0.2384\n",
      "Epoch [82/100], Step [7500/6235], Loss: 0.8812\n",
      "Epoch [82/100], Step [7600/6235], Loss: 1.4041\n",
      "Epoch [82/100], Step [7700/6235], Loss: 19.5197\n",
      "Epoch [82/100], Step [7800/6235], Loss: 6.7275\n",
      "Epoch [82/100], Step [7900/6235], Loss: 1.6688\n",
      "Epoch [82/100], Step [8000/6235], Loss: 0.4458\n",
      "Epoch [82/100], Step [8100/6235], Loss: 4.5652\n",
      "Epoch [82/100], Step [8200/6235], Loss: 16.8186\n",
      "Epoch [82/100], Step [8300/6235], Loss: 55.6897\n",
      "Epoch [82/100], Step [8400/6235], Loss: 161.7416\n",
      "Epoch [82/100], Step [8500/6235], Loss: 6.8197\n",
      "Epoch [82/100], Step [8600/6235], Loss: 141.6323\n",
      "Epoch [82/100], Step [8700/6235], Loss: 91.6836\n",
      "Epoch [82/100], Step [8800/6235], Loss: 227.9716\n",
      "Epoch [82/100], Step [8900/6235], Loss: 210.8033\n",
      "Epoch [82/100], Step [9000/6235], Loss: 522.5577\n",
      "Epoch [82/100], Step [9100/6235], Loss: 2582.6582\n",
      "Epoch [82/100], Step [9200/6235], Loss: 5117.3159\n",
      "Epoch [82/100], Step [9300/6235], Loss: 2.4277\n",
      "Epoch [82/100], Step [9400/6235], Loss: 77.6492\n",
      "Epoch [82/100], Step [9500/6235], Loss: 2160.0710\n",
      "Epoch [82/100], Step [9600/6235], Loss: 1209.9723\n",
      "Epoch [82/100], Step [9700/6235], Loss: 0.7388\n",
      "Epoch [82/100], Step [9800/6235], Loss: 6447.3003\n",
      "Epoch [82/100], Step [9900/6235], Loss: 32.7984\n",
      "Epoch [82/100], Step [10000/6235], Loss: 115.7939\n",
      "Epoch [82/100], Step [10100/6235], Loss: 2.8571\n",
      "Epoch [82/100], Step [10200/6235], Loss: 1143.5052\n",
      "Epoch [82/100], Step [10300/6235], Loss: 31.8038\n",
      "Epoch [82/100], Step [10400/6235], Loss: 10.5730\n",
      "Epoch [82/100], Step [10500/6235], Loss: 129.2309\n",
      "Epoch [82/100], Step [10600/6235], Loss: 474.2730\n",
      "Epoch [82/100], Step [10700/6235], Loss: 37.8072\n",
      "Epoch [82/100], Step [10800/6235], Loss: 58.7661\n",
      "Epoch [82/100], Step [10900/6235], Loss: 125.5949\n",
      "Epoch [82/100], Step [11000/6235], Loss: 288.8467\n",
      "Epoch [82/100], Step [11100/6235], Loss: 12.2219\n",
      "Epoch [82/100], Step [11200/6235], Loss: 0.9121\n",
      "Epoch [82/100], Step [11300/6235], Loss: 97.5467\n",
      "Epoch [82/100], Step [11400/6235], Loss: 46.8122\n",
      "Epoch [82/100], Step [11500/6235], Loss: 12.5245\n",
      "Epoch [82/100], Step [11600/6235], Loss: 9.9816\n",
      "Epoch [82/100], Step [11700/6235], Loss: 56.1538\n",
      "Epoch [82/100], Step [11800/6235], Loss: 410.3284\n",
      "Epoch [82/100], Step [11900/6235], Loss: 123.8188\n",
      "Epoch [82/100], Step [12000/6235], Loss: 517.3195\n",
      "Epoch [82/100], Step [12100/6235], Loss: 217.8667\n",
      "Epoch [82/100], Step [12200/6235], Loss: 78.3412\n",
      "Epoch [82/100], Step [12300/6235], Loss: 11.0962\n",
      "Epoch [82/100], Step [12400/6235], Loss: 409.1872\n",
      "Epoch [82/100], Step [12500/6235], Loss: 27.2150\n",
      "Epoch [82/100], Step [12600/6235], Loss: 29.3825\n",
      "Epoch [82/100], Step [12700/6235], Loss: 6.3786\n",
      "Epoch [82/100], Step [12800/6235], Loss: 9.6557\n",
      "Epoch [82/100], Step [12900/6235], Loss: 33.0889\n",
      "Epoch [82/100], Step [13000/6235], Loss: 0.3914\n",
      "Epoch [82/100], Step [13100/6235], Loss: 64.4252\n",
      "Epoch [82/100], Step [13200/6235], Loss: 8.4843\n",
      "Epoch [82/100], Step [13300/6235], Loss: 30.7105\n",
      "Epoch [82/100], Step [13400/6235], Loss: 237.6044\n",
      "Epoch [82/100], Step [13500/6235], Loss: 2.9938\n",
      "Epoch [82/100], Step [13600/6235], Loss: 2.6310\n",
      "Epoch [82/100], Step [13700/6235], Loss: 66.1485\n",
      "Epoch [82/100], Step [13800/6235], Loss: 114.1671\n",
      "Epoch [82/100], Step [13900/6235], Loss: 45.2819\n",
      "Epoch [82/100], Step [14000/6235], Loss: 11.5061\n",
      "Epoch [82/100], Step [14100/6235], Loss: 33.7374\n",
      "Epoch [82/100], Step [14200/6235], Loss: 128.1750\n",
      "Epoch [82/100], Step [14300/6235], Loss: 25.5024\n",
      "Epoch [82/100], Step [14400/6235], Loss: 37.3306\n",
      "Epoch [82/100], Step [14500/6235], Loss: 32.7669\n",
      "Epoch [82/100], Step [14600/6235], Loss: 1.6138\n",
      "Epoch [82/100], Step [14700/6235], Loss: 30.9680\n",
      "Epoch [82/100], Step [14800/6235], Loss: 31.7005\n",
      "Epoch [82/100], Step [14900/6235], Loss: 0.6771\n",
      "Epoch [82/100], Step [15000/6235], Loss: 1.3632\n",
      "Epoch [82/100], Step [15100/6235], Loss: 0.5186\n",
      "Epoch [82/100], Step [15200/6235], Loss: 14.1729\n",
      "Epoch [82/100], Step [15300/6235], Loss: 26.5765\n",
      "Epoch [82/100], Step [15400/6235], Loss: 92.4286\n",
      "Epoch [82/100], Step [15500/6235], Loss: 15.5480\n",
      "Epoch [82/100], Step [15600/6235], Loss: 174.6215\n",
      "Epoch [82/100], Step [15700/6235], Loss: 56.6281\n",
      "Epoch [82/100], Step [15800/6235], Loss: 0.1668\n",
      "Epoch [82/100], Step [15900/6235], Loss: 0.2874\n",
      "Epoch [82/100], Step [16000/6235], Loss: 195.9185\n",
      "Epoch [82/100], Step [16100/6235], Loss: 7.0933\n",
      "Epoch [82/100], Step [16200/6235], Loss: 0.7641\n",
      "Epoch [82/100], Step [16300/6235], Loss: 9.4184\n",
      "Epoch [82/100], Step [16400/6235], Loss: 28.9337\n",
      "Epoch [82/100], Step [16500/6235], Loss: 139.3317\n",
      "Epoch [82/100], Step [16600/6235], Loss: 18.3882\n",
      "Epoch [82/100], Step [16700/6235], Loss: 0.7934\n",
      "Epoch [82/100], Step [16800/6235], Loss: 9.1508\n",
      "Epoch [82/100], Step [16900/6235], Loss: 0.1651\n",
      "Epoch [82/100], Step [17000/6235], Loss: 0.2264\n",
      "Epoch [82/100], Step [17100/6235], Loss: 0.1721\n",
      "Epoch [82/100], Step [17200/6235], Loss: 284.1389\n",
      "Epoch [82/100], Step [17300/6235], Loss: 38.5882\n",
      "Epoch [82/100], Step [17400/6235], Loss: 37.8122\n",
      "Epoch [82/100], Step [17500/6235], Loss: 0.8094\n",
      "Epoch [82/100], Step [17600/6235], Loss: 2.8660\n",
      "Epoch [82/100], Step [17700/6235], Loss: 38.3468\n",
      "Epoch [82/100], Step [17800/6235], Loss: 20.4592\n",
      "Epoch [82/100], Step [17900/6235], Loss: 5.7852\n",
      "Epoch [82/100], Step [18000/6235], Loss: 0.6500\n",
      "Epoch [82/100], Step [18100/6235], Loss: 12.1892\n",
      "Epoch [82/100], Step [18200/6235], Loss: 0.8492\n",
      "Epoch [82/100], Step [18300/6235], Loss: 6.0754\n",
      "Epoch [82/100], Step [18400/6235], Loss: 1.3821\n",
      "Epoch [82/100], Step [18500/6235], Loss: 11.2892\n",
      "Epoch [82/100], Step [18600/6235], Loss: 2.1769\n",
      "Epoch [82/100], Step [18700/6235], Loss: 0.3902\n",
      "Epoch [82/100], Step [18800/6235], Loss: 133.6950\n",
      "Epoch [82/100], Step [18900/6235], Loss: 52.3230\n",
      "Epoch [82/100], Step [19000/6235], Loss: 15.1523\n",
      "Epoch [82/100], Step [19100/6235], Loss: 7.9317\n",
      "Epoch [82/100], Step [19200/6235], Loss: 3.6674\n",
      "Epoch [82/100], Step [19300/6235], Loss: 6.7464\n",
      "Epoch [82/100], Step [19400/6235], Loss: 69.6472\n",
      "Epoch [82/100], Step [19500/6235], Loss: 175.3656\n",
      "Epoch [82/100], Step [19600/6235], Loss: 122.2092\n",
      "Epoch [82/100], Step [19700/6235], Loss: 21.6045\n",
      "Epoch [82/100], Step [19800/6235], Loss: 0.4738\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Step [19900/6235], Loss: 1.5187\n",
      "Epoch [82/100], Step [20000/6235], Loss: 102.2592\n",
      "Epoch [82/100], Step [20100/6235], Loss: 12.1519\n",
      "Epoch [82/100], Step [20200/6235], Loss: 0.8833\n",
      "Epoch [82/100], Step [20300/6235], Loss: 0.5474\n",
      "Epoch [82/100], Step [20400/6235], Loss: 29.7151\n",
      "Epoch [82/100], Step [20500/6235], Loss: 29.0119\n",
      "Epoch [82/100], Step [20600/6235], Loss: 14.5676\n",
      "Epoch [82/100], Step [20700/6235], Loss: 9.9610\n",
      "Epoch [82/100], Step [20800/6235], Loss: 0.8884\n",
      "Epoch [82/100], Step [20900/6235], Loss: 33.9094\n",
      "Epoch [82/100], Step [21000/6235], Loss: 16.2166\n",
      "Epoch [82/100], Step [21100/6235], Loss: 5.1154\n",
      "Epoch [82/100], Step [21200/6235], Loss: 0.1800\n",
      "Epoch [82/100], Step [21300/6235], Loss: 0.2030\n",
      "Epoch [82/100], Step [21400/6235], Loss: 5.9763\n",
      "Epoch [82/100], Step [21500/6235], Loss: 1.9203\n",
      "Epoch [82/100], Step [21600/6235], Loss: 32.9279\n",
      "Epoch [82/100], Step [21700/6235], Loss: 0.1888\n",
      "Epoch [82/100], Step [21800/6235], Loss: 1.0731\n",
      "Epoch [82/100], Step [21900/6235], Loss: 0.3670\n",
      "Epoch [82/100], Step [22000/6235], Loss: 3.3031\n",
      "Epoch [82/100], Step [22100/6235], Loss: 3.8733\n",
      "Epoch [82/100], Step [22200/6235], Loss: 7.7332\n",
      "Epoch [82/100], Step [22300/6235], Loss: 0.5064\n",
      "Epoch [82/100], Step [22400/6235], Loss: 0.1268\n",
      "Epoch [82/100], Step [22500/6235], Loss: 109.8044\n",
      "Epoch [82/100], Step [22600/6235], Loss: 14.9818\n",
      "Epoch [82/100], Step [22700/6235], Loss: 0.2007\n",
      "Epoch [82/100], Step [22800/6235], Loss: 10.3996\n",
      "Epoch [82/100], Step [22900/6235], Loss: 20.8197\n",
      "Epoch [82/100], Step [23000/6235], Loss: 17.3232\n",
      "Epoch [82/100], Step [23100/6235], Loss: 0.4029\n",
      "Epoch [82/100], Step [23200/6235], Loss: 18.8717\n",
      "Epoch [82/100], Step [23300/6235], Loss: 18.6874\n",
      "Epoch [82/100], Step [23400/6235], Loss: 0.7574\n",
      "Epoch [82/100], Step [23500/6235], Loss: 0.2607\n",
      "Epoch [82/100], Step [23600/6235], Loss: 109.0262\n",
      "Epoch [82/100], Step [23700/6235], Loss: 3.5781\n",
      "Epoch [82/100], Step [23800/6235], Loss: 1.0228\n",
      "Epoch [82/100], Step [23900/6235], Loss: 7.6553\n",
      "Epoch [82/100], Step [24000/6235], Loss: 0.2875\n",
      "Epoch [82/100], Step [24100/6235], Loss: 0.1891\n",
      "Epoch [82/100], Step [24200/6235], Loss: 51.5306\n",
      "Epoch [82/100], Step [24300/6235], Loss: 1.0861\n",
      "Epoch [82/100], Step [24400/6235], Loss: 3.4743\n",
      "Epoch [82/100], Step [24500/6235], Loss: 1.7133\n",
      "Epoch [82/100], Step [24600/6235], Loss: 0.1096\n",
      "Epoch [82/100], Step [24700/6235], Loss: 2.6923\n",
      "Epoch [82/100], Step [24800/6235], Loss: 0.1316\n",
      "Epoch [82/100], Step [24900/6235], Loss: 16.9606\n",
      "Epoch [82/100], Step [25000/6235], Loss: 19.8340\n",
      "Epoch [82/100], Step [25100/6235], Loss: 8.2167\n",
      "Epoch [82/100], Step [25200/6235], Loss: 1.3050\n",
      "Epoch [82/100], Step [25300/6235], Loss: 0.5864\n",
      "Epoch [82/100], Step [25400/6235], Loss: 9.0473\n",
      "Epoch [82/100], Step [25500/6235], Loss: 5.6956\n",
      "Epoch [82/100], Step [25600/6235], Loss: 2.2819\n",
      "Epoch [82/100], Step [25700/6235], Loss: 0.3577\n",
      "Epoch [82/100], Step [25800/6235], Loss: 0.1454\n",
      "Epoch [82/100], Step [25900/6235], Loss: 10.0726\n",
      "Epoch [82/100], Step [26000/6235], Loss: 0.8092\n",
      "Epoch [82/100], Step [26100/6235], Loss: 0.5029\n",
      "Epoch [82/100], Step [26200/6235], Loss: 0.2138\n",
      "Epoch [82/100], Step [26300/6235], Loss: 5.4440\n",
      "Epoch [82/100], Step [26400/6235], Loss: 0.1495\n",
      "Epoch [82/100], Step [26500/6235], Loss: 0.0990\n",
      "Epoch [82/100], Step [26600/6235], Loss: 2.5422\n",
      "Epoch [82/100], Step [26700/6235], Loss: 0.5322\n",
      "Epoch [82/100], Step [26800/6235], Loss: 0.3686\n",
      "Epoch [82/100], Step [26900/6235], Loss: 0.0112\n",
      "Epoch [82/100], Step [27000/6235], Loss: 13.5797\n",
      "Epoch [82/100], Step [27100/6235], Loss: 0.0942\n",
      "Epoch [82/100], Step [27200/6235], Loss: 0.0459\n",
      "Epoch [82/100], Step [27300/6235], Loss: 0.2293\n",
      "Epoch [82/100], Step [27400/6235], Loss: 0.8440\n",
      "Epoch [82/100], Step [27500/6235], Loss: 9.6732\n",
      "Epoch [82/100], Step [27600/6235], Loss: 1.3770\n",
      "Epoch [82/100], Step [27700/6235], Loss: 1.7689\n",
      "Epoch [82/100], Step [27800/6235], Loss: 0.5085\n",
      "Epoch [82/100], Step [27900/6235], Loss: 1.6311\n",
      "Epoch [82/100], Step [28000/6235], Loss: 142.9779\n",
      "Epoch [82/100], Step [28100/6235], Loss: 9.8246\n",
      "Epoch [82/100], Step [28200/6235], Loss: 42.2355\n",
      "Epoch [82/100], Step [28300/6235], Loss: 2.3835\n",
      "Epoch [82/100], Step [28400/6235], Loss: 26.0311\n",
      "Epoch [82/100], Step [28500/6235], Loss: 2.8704\n",
      "Epoch [82/100], Step [28600/6235], Loss: 0.0861\n",
      "Epoch [82/100], Step [28700/6235], Loss: 5.5536\n",
      "Epoch [82/100], Step [28800/6235], Loss: 0.5860\n",
      "Epoch [82/100], Step [28900/6235], Loss: 71.3575\n",
      "Epoch [82/100], Step [29000/6235], Loss: 12.0974\n",
      "Epoch [82/100], Step [29100/6235], Loss: 0.1613\n",
      "Epoch [82/100], Step [29200/6235], Loss: 0.9107\n",
      "Epoch [82/100], Step [29300/6235], Loss: 15.6035\n",
      "Epoch [82/100], Step [29400/6235], Loss: 0.1486\n",
      "Epoch [82/100], Step [29500/6235], Loss: 0.5593\n",
      "Epoch [82/100], Step [29600/6235], Loss: 0.3526\n",
      "Epoch [82/100], Step [29700/6235], Loss: 1.1968\n",
      "Epoch [82/100], Step [29800/6235], Loss: 1.6434\n",
      "Epoch [82/100], Step [29900/6235], Loss: 0.8549\n",
      "Epoch [82/100], Step [30000/6235], Loss: 5.4362\n",
      "Epoch [82/100], Step [30100/6235], Loss: 10.9117\n",
      "Epoch [82/100], Step [30200/6235], Loss: 0.8034\n",
      "Epoch [82/100], Step [30300/6235], Loss: 0.0148\n",
      "Epoch [82/100], Step [30400/6235], Loss: 0.8053\n",
      "Epoch [82/100], Step [30500/6235], Loss: 3.2005\n",
      "Epoch [82/100], Step [30600/6235], Loss: 1.5574\n",
      "Epoch [82/100], Step [30700/6235], Loss: 0.1977\n",
      "Epoch [82/100], Step [30800/6235], Loss: 0.4286\n",
      "Epoch [82/100], Step [30900/6235], Loss: 4.0267\n",
      "Epoch [82/100], Step [31000/6235], Loss: 0.0809\n",
      "Epoch [82/100], Step [31100/6235], Loss: 0.0362\n",
      "Epoch [82/100], Step [31200/6235], Loss: 5.9938\n",
      "Epoch [82/100], Step [31300/6235], Loss: 1.4140\n",
      "Epoch [82/100], Step [31400/6235], Loss: 11.8687\n",
      "Epoch [82/100], Step [31500/6235], Loss: 0.6307\n",
      "Epoch [82/100], Step [31600/6235], Loss: 11.0724\n",
      "Epoch [82/100], Step [31700/6235], Loss: 8.7530\n",
      "Epoch [82/100], Step [31800/6235], Loss: 1.1748\n",
      "Epoch [82/100], Step [31900/6235], Loss: 23.4823\n",
      "Epoch [82/100], Step [32000/6235], Loss: 53.0986\n",
      "Epoch [82/100], Step [32100/6235], Loss: 4.9425\n",
      "Epoch [82/100], Step [32200/6235], Loss: 42.5577\n",
      "Epoch [82/100], Step [32300/6235], Loss: 0.0713\n",
      "Epoch [82/100], Step [32400/6235], Loss: 0.3588\n",
      "Epoch [82/100], Step [32500/6235], Loss: 21.8987\n",
      "Epoch [82/100], Step [32600/6235], Loss: 0.8652\n",
      "Epoch [82/100], Step [32700/6235], Loss: 94.0558\n",
      "Epoch [82/100], Step [32800/6235], Loss: 23.3205\n",
      "Epoch [82/100], Step [32900/6235], Loss: 9.7532\n",
      "Epoch [82/100], Step [33000/6235], Loss: 0.4115\n",
      "Epoch [82/100], Step [33100/6235], Loss: 1.2029\n",
      "Epoch [82/100], Step [33200/6235], Loss: 1.1533\n",
      "Epoch [82/100], Step [33300/6235], Loss: 0.3159\n",
      "Epoch [82/100], Step [33400/6235], Loss: 139.7334\n",
      "Epoch [82/100], Step [33500/6235], Loss: 2.8659\n",
      "Epoch [82/100], Step [33600/6235], Loss: 5.0287\n",
      "Epoch [82/100], Step [33700/6235], Loss: 0.8527\n",
      "Epoch [82/100], Step [33800/6235], Loss: 2.5184\n",
      "Epoch [82/100], Step [33900/6235], Loss: 24.7319\n",
      "Epoch [82/100], Step [34000/6235], Loss: 0.0065\n",
      "Epoch [82/100], Step [34100/6235], Loss: 0.2616\n",
      "Epoch [82/100], Step [34200/6235], Loss: 2.0863\n",
      "Epoch [82/100], Step [34300/6235], Loss: 6.0278\n",
      "Epoch [82/100], Step [34400/6235], Loss: 0.2091\n",
      "Epoch [82/100], Step [34500/6235], Loss: 147.2072\n",
      "Epoch [82/100], Step [34600/6235], Loss: 0.3400\n",
      "Epoch [82/100], Step [34700/6235], Loss: 18.5980\n",
      "Epoch [82/100], Step [34800/6235], Loss: 12.4081\n",
      "Epoch [82/100], Step [34900/6235], Loss: 69.0352\n",
      "Epoch [82/100], Step [35000/6235], Loss: 0.9511\n",
      "Epoch [82/100], Step [35100/6235], Loss: 0.3970\n",
      "Epoch [82/100], Step [35200/6235], Loss: 0.2196\n",
      "Epoch [82/100], Step [35300/6235], Loss: 2.7633\n",
      "Epoch [82/100], Step [35400/6235], Loss: 0.4570\n",
      "Epoch [82/100], Step [35500/6235], Loss: 1.8117\n",
      "Epoch [82/100], Step [35600/6235], Loss: 0.7145\n",
      "Epoch [82/100], Step [35700/6235], Loss: 6.0732\n",
      "Epoch [82/100], Step [35800/6235], Loss: 0.2009\n",
      "Epoch [82/100], Step [35900/6235], Loss: 0.9306\n",
      "Epoch [82/100], Step [36000/6235], Loss: 0.3210\n",
      "Epoch [82/100], Step [36100/6235], Loss: 0.0924\n",
      "Epoch [82/100], Step [36200/6235], Loss: 10.1817\n",
      "Epoch [82/100], Step [36300/6235], Loss: 1.3138\n",
      "Epoch [82/100], Step [36400/6235], Loss: 2.2648\n",
      "Epoch [82/100], Step [36500/6235], Loss: 8.7446\n",
      "Epoch [82/100], Step [36600/6235], Loss: 0.1348\n",
      "Epoch [82/100], Step [36700/6235], Loss: 0.4005\n",
      "Epoch [82/100], Step [36800/6235], Loss: 12.0565\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [82/100], Step [36900/6235], Loss: 4.6655\n",
      "Epoch [82/100], Step [37000/6235], Loss: 0.5185\n",
      "Epoch [82/100], Step [37100/6235], Loss: 1.1775\n",
      "Epoch [82/100], Step [37200/6235], Loss: 0.0756\n",
      "Epoch [82/100], Step [37300/6235], Loss: 0.0412\n",
      "Epoch [82/100], Step [37400/6235], Loss: 0.2010\n",
      "Epoch [82/100], Step [37500/6235], Loss: 4.7097\n",
      "Epoch [82/100], Step [37600/6235], Loss: 11.7642\n",
      "Epoch [82/100], Step [37700/6235], Loss: 1.6729\n",
      "Epoch [82/100], Step [37800/6235], Loss: 4.8295\n",
      "Epoch [82/100], Step [37900/6235], Loss: 6.9846\n",
      "Epoch [82/100], Step [38000/6235], Loss: 0.4694\n",
      "Epoch [82/100], Step [38100/6235], Loss: 3.5131\n",
      "Epoch [82/100], Step [38200/6235], Loss: 2.2096\n",
      "Epoch [82/100], Step [38300/6235], Loss: 2.3907\n",
      "Epoch [82/100], Step [38400/6235], Loss: 0.1049\n",
      "Epoch [82/100], Step [38500/6235], Loss: 2.5162\n",
      "Epoch [82/100], Step [38600/6235], Loss: 0.1276\n",
      "Epoch [82/100], Step [38700/6235], Loss: 0.1154\n",
      "Epoch [82/100], Step [38800/6235], Loss: 0.2188\n",
      "Epoch [82/100], Step [38900/6235], Loss: 1.3664\n",
      "Epoch [82/100], Step [39000/6235], Loss: 13.4704\n",
      "Epoch [82/100], Step [39100/6235], Loss: 21.0674\n",
      "Epoch [82/100], Step [39200/6235], Loss: 0.2798\n",
      "Epoch [82/100], Step [39300/6235], Loss: 53.5805\n",
      "Epoch [82/100], Step [39400/6235], Loss: 87.3805\n",
      "Epoch [82/100], Step [39500/6235], Loss: 75.3833\n",
      "Epoch [82/100], Step [39600/6235], Loss: 4.6850\n",
      "Epoch [82/100], Step [39700/6235], Loss: 41.2772\n",
      "Epoch [82/100], Step [39800/6235], Loss: 23.7176\n",
      "Epoch [82/100], Step [39900/6235], Loss: 11.6458\n",
      "Epoch [82/100], Step [40000/6235], Loss: 3.3197\n",
      "Epoch [82/100], Step [40100/6235], Loss: 6.4184\n",
      "Epoch [82/100], Step [40200/6235], Loss: 16.3704\n",
      "Epoch [82/100], Step [40300/6235], Loss: 0.5733\n",
      "Epoch [82/100], Step [40400/6235], Loss: 0.8819\n",
      "Epoch [82/100], Step [40500/6235], Loss: 3.2780\n",
      "Epoch [82/100], Step [40600/6235], Loss: 0.3182\n",
      "Epoch [82/100], Step [40700/6235], Loss: 5.1635\n",
      "Epoch [82/100], Step [40800/6235], Loss: 1.4216\n",
      "Epoch [82/100], Step [40900/6235], Loss: 1.3876\n",
      "Epoch [82/100], Step [41000/6235], Loss: 39.1286\n",
      "Epoch [82/100], Step [41100/6235], Loss: 10.3244\n",
      "Epoch [82/100], Step [41200/6235], Loss: 14.9779\n",
      "Epoch [82/100], Step [41300/6235], Loss: 2.6629\n",
      "Epoch [82/100], Step [41400/6235], Loss: 0.4673\n",
      "Epoch [82/100], Step [41500/6235], Loss: 13.3913\n",
      "Epoch [82/100], Step [41600/6235], Loss: 2.5906\n",
      "Epoch [82/100], Step [41700/6235], Loss: 0.1353\n",
      "Epoch [82/100], Step [41800/6235], Loss: 0.5232\n",
      "Epoch [82/100], Step [41900/6235], Loss: 4.3106\n",
      "Epoch [82/100], Step [42000/6235], Loss: 4.2765\n",
      "Epoch [82/100], Step [42100/6235], Loss: 12.1839\n",
      "Epoch [82/100], Step [42200/6235], Loss: 61.2564\n",
      "Epoch [82/100], Step [42300/6235], Loss: 0.1816\n",
      "Epoch [82/100], Step [42400/6235], Loss: 3.1451\n",
      "Epoch [82/100], Step [42500/6235], Loss: 1.1838\n",
      "Epoch [82/100], Step [42600/6235], Loss: 0.4835\n",
      "Epoch [82/100], Step [42700/6235], Loss: 0.1710\n",
      "Epoch [82/100], Step [42800/6235], Loss: 16.1996\n",
      "Epoch [82/100], Step [42900/6235], Loss: 0.2204\n",
      "Epoch [82/100], Step [43000/6235], Loss: 0.4795\n",
      "Epoch [82/100], Step [43100/6235], Loss: 0.0520\n",
      "Epoch [82/100], Step [43200/6235], Loss: 0.1266\n",
      "Epoch [82/100], Step [43300/6235], Loss: 4.3642\n",
      "Epoch [82/100], Step [43400/6235], Loss: 4.3469\n",
      "Epoch [82/100], Step [43500/6235], Loss: 12.1056\n",
      "Epoch [82/100], Step [43600/6235], Loss: 1.2253\n",
      "Epoch [82/100], Step [43700/6235], Loss: 47.4337\n",
      "Epoch [82/100], Step [43800/6235], Loss: 0.3979\n",
      "Epoch [82/100], Step [43900/6235], Loss: 2.7179\n",
      "Epoch [82/100], Step [44000/6235], Loss: 96.7414\n",
      "Epoch [82/100], Step [44100/6235], Loss: 4.5772\n",
      "Epoch [82/100], Step [44200/6235], Loss: 1.5142\n",
      "Epoch [82/100], Step [44300/6235], Loss: 99.1973\n",
      "Epoch [82/100], Step [44400/6235], Loss: 0.7864\n",
      "Epoch [82/100], Step [44500/6235], Loss: 0.8069\n",
      "Epoch [82/100], Step [44600/6235], Loss: 15.7612\n",
      "Epoch [82/100], Step [44700/6235], Loss: 8.1311\n",
      "Epoch [82/100], Step [44800/6235], Loss: 5.8422\n",
      "Epoch [82/100], Step [44900/6235], Loss: 11.5955\n",
      "Epoch [82/100], Step [45000/6235], Loss: 5.9944\n",
      "Epoch [82/100], Step [45100/6235], Loss: 62.2796\n",
      "Epoch [82/100], Step [45200/6235], Loss: 4.4535\n",
      "Epoch [82/100], Step [45300/6235], Loss: 23.2373\n",
      "Epoch [82/100], Step [45400/6235], Loss: 5.8238\n",
      "Epoch [82/100], Step [45500/6235], Loss: 3.2881\n",
      "Epoch [82/100], Step [45600/6235], Loss: 1.2581\n",
      "Epoch [82/100], Step [45700/6235], Loss: 98.0403\n",
      "Epoch [82/100], Step [45800/6235], Loss: 471.1088\n",
      "Epoch [82/100], Step [45900/6235], Loss: 58.5770\n",
      "Epoch [82/100], Step [46000/6235], Loss: 26.7925\n",
      "Epoch [82/100], Step [46100/6235], Loss: 23.8324\n",
      "Epoch [82/100], Step [46200/6235], Loss: 18.4964\n",
      "Epoch [82/100], Step [46300/6235], Loss: 65.8381\n",
      "Epoch [82/100], Step [46400/6235], Loss: 11.9104\n",
      "Epoch [82/100], Step [46500/6235], Loss: 0.9897\n",
      "Epoch [82/100], Step [46600/6235], Loss: 9.9713\n",
      "Epoch [82/100], Step [46700/6235], Loss: 36.4054\n",
      "Epoch [82/100], Step [46800/6235], Loss: 1.8877\n",
      "Epoch [82/100], Step [46900/6235], Loss: 0.8841\n",
      "Epoch [82/100], Step [47000/6235], Loss: 8.2560\n",
      "Epoch [82/100], Step [47100/6235], Loss: 3.7517\n",
      "Epoch [82/100], Step [47200/6235], Loss: 18.1431\n",
      "Epoch [82/100], Step [47300/6235], Loss: 1.4362\n",
      "Epoch [82/100], Step [47400/6235], Loss: 21.3402\n",
      "Epoch [82/100], Step [47500/6235], Loss: 14.3343\n",
      "Epoch [82/100], Step [47600/6235], Loss: 4.6447\n",
      "Epoch [82/100], Step [47700/6235], Loss: 15.4019\n",
      "Epoch [82/100], Step [47800/6235], Loss: 10.2041\n",
      "Epoch [82/100], Step [47900/6235], Loss: 19.0919\n",
      "Epoch [82/100], Step [48000/6235], Loss: 94.5918\n",
      "Epoch [82/100], Step [48100/6235], Loss: 4.6353\n",
      "Epoch [82/100], Step [48200/6235], Loss: 5.7379\n",
      "Epoch [82/100], Step [48300/6235], Loss: 302.1100\n",
      "Epoch [82/100], Step [48400/6235], Loss: 17.8924\n",
      "Epoch [82/100], Step [48500/6235], Loss: 21.3612\n",
      "Epoch [82/100], Step [48600/6235], Loss: 156.1828\n",
      "Epoch [82/100], Step [48700/6235], Loss: 7.0958\n",
      "Epoch [82/100], Step [48800/6235], Loss: 253.8536\n",
      "Epoch [82/100], Step [48900/6235], Loss: 5.0219\n",
      "Epoch [82/100], Step [49000/6235], Loss: 273.6817\n",
      "Epoch [82/100], Step [49100/6235], Loss: 1375.2531\n",
      "Epoch [82/100], Step [49200/6235], Loss: 932.2684\n",
      "Epoch [82/100], Step [49300/6235], Loss: 1227.3312\n",
      "Epoch [82/100], Step [49400/6235], Loss: 35.9674\n",
      "Epoch [82/100], Step [49500/6235], Loss: 15.5870\n",
      "Epoch [82/100], Step [49600/6235], Loss: 2473.1572\n",
      "Epoch [82/100], Step [49700/6235], Loss: 1101.5393\n",
      "Epoch [82/100], Step [49800/6235], Loss: 261.0062\n",
      "Epoch [83/100], Step [100/6235], Loss: 0.2765\n",
      "Epoch [83/100], Step [200/6235], Loss: 0.1547\n",
      "Epoch [83/100], Step [300/6235], Loss: 0.0005\n",
      "Epoch [83/100], Step [400/6235], Loss: 0.0013\n",
      "Epoch [83/100], Step [500/6235], Loss: 0.0518\n",
      "Epoch [83/100], Step [600/6235], Loss: 0.0385\n",
      "Epoch [83/100], Step [700/6235], Loss: 0.5728\n",
      "Epoch [83/100], Step [800/6235], Loss: 0.0744\n",
      "Epoch [83/100], Step [900/6235], Loss: 0.0389\n",
      "Epoch [83/100], Step [1000/6235], Loss: 0.0241\n",
      "Epoch [83/100], Step [1100/6235], Loss: 0.0227\n",
      "Epoch [83/100], Step [1200/6235], Loss: 0.1734\n",
      "Epoch [83/100], Step [1300/6235], Loss: 0.0161\n",
      "Epoch [83/100], Step [1400/6235], Loss: 0.0463\n",
      "Epoch [83/100], Step [1500/6235], Loss: 0.0076\n",
      "Epoch [83/100], Step [1600/6235], Loss: 0.2301\n",
      "Epoch [83/100], Step [1700/6235], Loss: 0.0872\n",
      "Epoch [83/100], Step [1800/6235], Loss: 0.2474\n",
      "Epoch [83/100], Step [1900/6235], Loss: 0.3235\n",
      "Epoch [83/100], Step [2000/6235], Loss: 2.2965\n",
      "Epoch [83/100], Step [2100/6235], Loss: 4.0165\n",
      "Epoch [83/100], Step [2200/6235], Loss: 7.4146\n",
      "Epoch [83/100], Step [2300/6235], Loss: 2.3559\n",
      "Epoch [83/100], Step [2400/6235], Loss: 0.9620\n",
      "Epoch [83/100], Step [2500/6235], Loss: 40.5369\n",
      "Epoch [83/100], Step [2600/6235], Loss: 14.0822\n",
      "Epoch [83/100], Step [2700/6235], Loss: 7.8404\n",
      "Epoch [83/100], Step [2800/6235], Loss: 120.3919\n",
      "Epoch [83/100], Step [2900/6235], Loss: 16.0963\n",
      "Epoch [83/100], Step [3000/6235], Loss: 1.1842\n",
      "Epoch [83/100], Step [3100/6235], Loss: 63.5510\n",
      "Epoch [83/100], Step [3200/6235], Loss: 70.4241\n",
      "Epoch [83/100], Step [3300/6235], Loss: 9.1149\n",
      "Epoch [83/100], Step [3400/6235], Loss: 2.0815\n",
      "Epoch [83/100], Step [3500/6235], Loss: 39.6409\n",
      "Epoch [83/100], Step [3600/6235], Loss: 6.9254\n",
      "Epoch [83/100], Step [3700/6235], Loss: 0.0674\n",
      "Epoch [83/100], Step [3800/6235], Loss: 0.1154\n",
      "Epoch [83/100], Step [3900/6235], Loss: 0.2392\n",
      "Epoch [83/100], Step [4000/6235], Loss: 0.0571\n",
      "Epoch [83/100], Step [4100/6235], Loss: 7.9404\n",
      "Epoch [83/100], Step [4200/6235], Loss: 1.0321\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Step [4300/6235], Loss: 8.0346\n",
      "Epoch [83/100], Step [4400/6235], Loss: 2.1285\n",
      "Epoch [83/100], Step [4500/6235], Loss: 39.1412\n",
      "Epoch [83/100], Step [4600/6235], Loss: 1.7667\n",
      "Epoch [83/100], Step [4700/6235], Loss: 0.1607\n",
      "Epoch [83/100], Step [4800/6235], Loss: 10.4940\n",
      "Epoch [83/100], Step [4900/6235], Loss: 0.2140\n",
      "Epoch [83/100], Step [5000/6235], Loss: 0.0662\n",
      "Epoch [83/100], Step [5100/6235], Loss: 1.2115\n",
      "Epoch [83/100], Step [5200/6235], Loss: 0.6449\n",
      "Epoch [83/100], Step [5300/6235], Loss: 41.7341\n",
      "Epoch [83/100], Step [5400/6235], Loss: 1.4980\n",
      "Epoch [83/100], Step [5500/6235], Loss: 0.1294\n",
      "Epoch [83/100], Step [5600/6235], Loss: 0.2711\n",
      "Epoch [83/100], Step [5700/6235], Loss: 0.0091\n",
      "Epoch [83/100], Step [5800/6235], Loss: 0.1989\n",
      "Epoch [83/100], Step [5900/6235], Loss: 0.0497\n",
      "Epoch [83/100], Step [6000/6235], Loss: 2.8763\n",
      "Epoch [83/100], Step [6100/6235], Loss: 0.0431\n",
      "Epoch [83/100], Step [6200/6235], Loss: 3.0334\n",
      "Epoch [83/100], Step [6300/6235], Loss: 0.5081\n",
      "Epoch [83/100], Step [6400/6235], Loss: 0.0225\n",
      "Epoch [83/100], Step [6500/6235], Loss: 3.0100\n",
      "Epoch [83/100], Step [6600/6235], Loss: 6.5910\n",
      "Epoch [83/100], Step [6700/6235], Loss: 2.9895\n",
      "Epoch [83/100], Step [6800/6235], Loss: 0.6907\n",
      "Epoch [83/100], Step [6900/6235], Loss: 0.6324\n",
      "Epoch [83/100], Step [7000/6235], Loss: 0.0163\n",
      "Epoch [83/100], Step [7100/6235], Loss: 0.1672\n",
      "Epoch [83/100], Step [7200/6235], Loss: 0.2479\n",
      "Epoch [83/100], Step [7300/6235], Loss: 0.0491\n",
      "Epoch [83/100], Step [7400/6235], Loss: 0.1187\n",
      "Epoch [83/100], Step [7500/6235], Loss: 0.8255\n",
      "Epoch [83/100], Step [7600/6235], Loss: 2.5055\n",
      "Epoch [83/100], Step [7700/6235], Loss: 15.9884\n",
      "Epoch [83/100], Step [7800/6235], Loss: 1.6539\n",
      "Epoch [83/100], Step [7900/6235], Loss: 2.5898\n",
      "Epoch [83/100], Step [8000/6235], Loss: 0.1090\n",
      "Epoch [83/100], Step [8100/6235], Loss: 4.5696\n",
      "Epoch [83/100], Step [8200/6235], Loss: 12.5011\n",
      "Epoch [83/100], Step [8300/6235], Loss: 30.9698\n",
      "Epoch [83/100], Step [8400/6235], Loss: 289.0861\n",
      "Epoch [83/100], Step [8500/6235], Loss: 1.5778\n",
      "Epoch [83/100], Step [8600/6235], Loss: 97.4357\n",
      "Epoch [83/100], Step [8700/6235], Loss: 42.2710\n",
      "Epoch [83/100], Step [8800/6235], Loss: 837.2392\n",
      "Epoch [83/100], Step [8900/6235], Loss: 122.6921\n",
      "Epoch [83/100], Step [9000/6235], Loss: 679.2305\n",
      "Epoch [83/100], Step [9100/6235], Loss: 2178.5530\n",
      "Epoch [83/100], Step [9200/6235], Loss: 5122.1650\n",
      "Epoch [83/100], Step [9300/6235], Loss: 41.7026\n",
      "Epoch [83/100], Step [9400/6235], Loss: 80.4692\n",
      "Epoch [83/100], Step [9500/6235], Loss: 868.6859\n",
      "Epoch [83/100], Step [9600/6235], Loss: 546.7144\n",
      "Epoch [83/100], Step [9700/6235], Loss: 12.6911\n",
      "Epoch [83/100], Step [9800/6235], Loss: 131.4237\n",
      "Epoch [83/100], Step [9900/6235], Loss: 20.4768\n",
      "Epoch [83/100], Step [10000/6235], Loss: 87.0531\n",
      "Epoch [83/100], Step [10100/6235], Loss: 3.6674\n",
      "Epoch [83/100], Step [10200/6235], Loss: 545.0654\n",
      "Epoch [83/100], Step [10300/6235], Loss: 0.8274\n",
      "Epoch [83/100], Step [10400/6235], Loss: 10.3403\n",
      "Epoch [83/100], Step [10500/6235], Loss: 12.8716\n",
      "Epoch [83/100], Step [10600/6235], Loss: 166.9884\n",
      "Epoch [83/100], Step [10700/6235], Loss: 17.2536\n",
      "Epoch [83/100], Step [10800/6235], Loss: 113.3858\n",
      "Epoch [83/100], Step [10900/6235], Loss: 38.1362\n",
      "Epoch [83/100], Step [11000/6235], Loss: 296.4627\n",
      "Epoch [83/100], Step [11100/6235], Loss: 46.9588\n",
      "Epoch [83/100], Step [11200/6235], Loss: 14.7947\n",
      "Epoch [83/100], Step [11300/6235], Loss: 117.7186\n",
      "Epoch [83/100], Step [11400/6235], Loss: 0.9544\n",
      "Epoch [83/100], Step [11500/6235], Loss: 8.0885\n",
      "Epoch [83/100], Step [11600/6235], Loss: 6.1760\n",
      "Epoch [83/100], Step [11700/6235], Loss: 41.8246\n",
      "Epoch [83/100], Step [11800/6235], Loss: 6.5049\n",
      "Epoch [83/100], Step [11900/6235], Loss: 9.6029\n",
      "Epoch [83/100], Step [12000/6235], Loss: 499.1368\n",
      "Epoch [83/100], Step [12100/6235], Loss: 230.0128\n",
      "Epoch [83/100], Step [12200/6235], Loss: 1.3087\n",
      "Epoch [83/100], Step [12300/6235], Loss: 1.1784\n",
      "Epoch [83/100], Step [12400/6235], Loss: 122.4701\n",
      "Epoch [83/100], Step [12500/6235], Loss: 74.3427\n",
      "Epoch [83/100], Step [12600/6235], Loss: 4.3068\n",
      "Epoch [83/100], Step [12700/6235], Loss: 3.0888\n",
      "Epoch [83/100], Step [12800/6235], Loss: 10.3244\n",
      "Epoch [83/100], Step [12900/6235], Loss: 28.4335\n",
      "Epoch [83/100], Step [13000/6235], Loss: 0.1150\n",
      "Epoch [83/100], Step [13100/6235], Loss: 61.7729\n",
      "Epoch [83/100], Step [13200/6235], Loss: 8.2844\n",
      "Epoch [83/100], Step [13300/6235], Loss: 21.6250\n",
      "Epoch [83/100], Step [13400/6235], Loss: 200.7694\n",
      "Epoch [83/100], Step [13500/6235], Loss: 3.6810\n",
      "Epoch [83/100], Step [13600/6235], Loss: 1.4783\n",
      "Epoch [83/100], Step [13700/6235], Loss: 142.2815\n",
      "Epoch [83/100], Step [13800/6235], Loss: 82.6911\n",
      "Epoch [83/100], Step [13900/6235], Loss: 19.4375\n",
      "Epoch [83/100], Step [14000/6235], Loss: 7.5564\n",
      "Epoch [83/100], Step [14100/6235], Loss: 49.5922\n",
      "Epoch [83/100], Step [14200/6235], Loss: 10.8714\n",
      "Epoch [83/100], Step [14300/6235], Loss: 12.9005\n",
      "Epoch [83/100], Step [14400/6235], Loss: 32.7925\n",
      "Epoch [83/100], Step [14500/6235], Loss: 24.5176\n",
      "Epoch [83/100], Step [14600/6235], Loss: 3.1636\n",
      "Epoch [83/100], Step [14700/6235], Loss: 20.1615\n",
      "Epoch [83/100], Step [14800/6235], Loss: 26.0406\n",
      "Epoch [83/100], Step [14900/6235], Loss: 0.7948\n",
      "Epoch [83/100], Step [15000/6235], Loss: 0.9186\n",
      "Epoch [83/100], Step [15100/6235], Loss: 0.2782\n",
      "Epoch [83/100], Step [15200/6235], Loss: 28.0927\n",
      "Epoch [83/100], Step [15300/6235], Loss: 21.4805\n",
      "Epoch [83/100], Step [15400/6235], Loss: 17.4944\n",
      "Epoch [83/100], Step [15500/6235], Loss: 3.6211\n",
      "Epoch [83/100], Step [15600/6235], Loss: 271.3919\n",
      "Epoch [83/100], Step [15700/6235], Loss: 134.1145\n",
      "Epoch [83/100], Step [15800/6235], Loss: 7.9962\n",
      "Epoch [83/100], Step [15900/6235], Loss: 1.3294\n",
      "Epoch [83/100], Step [16000/6235], Loss: 40.2517\n",
      "Epoch [83/100], Step [16100/6235], Loss: 1.6446\n",
      "Epoch [83/100], Step [16200/6235], Loss: 0.3103\n",
      "Epoch [83/100], Step [16300/6235], Loss: 8.3497\n",
      "Epoch [83/100], Step [16400/6235], Loss: 19.5378\n",
      "Epoch [83/100], Step [16500/6235], Loss: 440.1183\n",
      "Epoch [83/100], Step [16600/6235], Loss: 40.7012\n",
      "Epoch [83/100], Step [16700/6235], Loss: 0.4688\n",
      "Epoch [83/100], Step [16800/6235], Loss: 10.4724\n",
      "Epoch [83/100], Step [16900/6235], Loss: 0.4364\n",
      "Epoch [83/100], Step [17000/6235], Loss: 0.1838\n",
      "Epoch [83/100], Step [17100/6235], Loss: 0.1600\n",
      "Epoch [83/100], Step [17200/6235], Loss: 245.2646\n",
      "Epoch [83/100], Step [17300/6235], Loss: 2.6926\n",
      "Epoch [83/100], Step [17400/6235], Loss: 30.7706\n",
      "Epoch [83/100], Step [17500/6235], Loss: 2.1930\n",
      "Epoch [83/100], Step [17600/6235], Loss: 2.6384\n",
      "Epoch [83/100], Step [17700/6235], Loss: 1.9408\n",
      "Epoch [83/100], Step [17800/6235], Loss: 21.4542\n",
      "Epoch [83/100], Step [17900/6235], Loss: 19.8956\n",
      "Epoch [83/100], Step [18000/6235], Loss: 2.5336\n",
      "Epoch [83/100], Step [18100/6235], Loss: 17.1565\n",
      "Epoch [83/100], Step [18200/6235], Loss: 0.8103\n",
      "Epoch [83/100], Step [18300/6235], Loss: 6.0486\n",
      "Epoch [83/100], Step [18400/6235], Loss: 4.6114\n",
      "Epoch [83/100], Step [18500/6235], Loss: 11.0830\n",
      "Epoch [83/100], Step [18600/6235], Loss: 1.1407\n",
      "Epoch [83/100], Step [18700/6235], Loss: 0.4444\n",
      "Epoch [83/100], Step [18800/6235], Loss: 135.3150\n",
      "Epoch [83/100], Step [18900/6235], Loss: 18.8365\n",
      "Epoch [83/100], Step [19000/6235], Loss: 9.6199\n",
      "Epoch [83/100], Step [19100/6235], Loss: 30.1137\n",
      "Epoch [83/100], Step [19200/6235], Loss: 1.8168\n",
      "Epoch [83/100], Step [19300/6235], Loss: 4.6507\n",
      "Epoch [83/100], Step [19400/6235], Loss: 201.4996\n",
      "Epoch [83/100], Step [19500/6235], Loss: 141.4046\n",
      "Epoch [83/100], Step [19600/6235], Loss: 86.2045\n",
      "Epoch [83/100], Step [19700/6235], Loss: 4.7287\n",
      "Epoch [83/100], Step [19800/6235], Loss: 3.5429\n",
      "Epoch [83/100], Step [19900/6235], Loss: 0.0635\n",
      "Epoch [83/100], Step [20000/6235], Loss: 68.2875\n",
      "Epoch [83/100], Step [20100/6235], Loss: 0.1161\n",
      "Epoch [83/100], Step [20200/6235], Loss: 8.0154\n",
      "Epoch [83/100], Step [20300/6235], Loss: 2.3591\n",
      "Epoch [83/100], Step [20400/6235], Loss: 19.6615\n",
      "Epoch [83/100], Step [20500/6235], Loss: 41.4325\n",
      "Epoch [83/100], Step [20600/6235], Loss: 129.6530\n",
      "Epoch [83/100], Step [20700/6235], Loss: 19.8674\n",
      "Epoch [83/100], Step [20800/6235], Loss: 1.2445\n",
      "Epoch [83/100], Step [20900/6235], Loss: 20.5531\n",
      "Epoch [83/100], Step [21000/6235], Loss: 20.1531\n",
      "Epoch [83/100], Step [21100/6235], Loss: 6.3183\n",
      "Epoch [83/100], Step [21200/6235], Loss: 0.2245\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Step [21300/6235], Loss: 0.2206\n",
      "Epoch [83/100], Step [21400/6235], Loss: 6.7871\n",
      "Epoch [83/100], Step [21500/6235], Loss: 0.2105\n",
      "Epoch [83/100], Step [21600/6235], Loss: 28.0547\n",
      "Epoch [83/100], Step [21700/6235], Loss: 0.3816\n",
      "Epoch [83/100], Step [21800/6235], Loss: 0.2427\n",
      "Epoch [83/100], Step [21900/6235], Loss: 0.8141\n",
      "Epoch [83/100], Step [22000/6235], Loss: 5.0814\n",
      "Epoch [83/100], Step [22100/6235], Loss: 2.1987\n",
      "Epoch [83/100], Step [22200/6235], Loss: 5.0490\n",
      "Epoch [83/100], Step [22300/6235], Loss: 0.3170\n",
      "Epoch [83/100], Step [22400/6235], Loss: 3.1879\n",
      "Epoch [83/100], Step [22500/6235], Loss: 169.5642\n",
      "Epoch [83/100], Step [22600/6235], Loss: 17.1858\n",
      "Epoch [83/100], Step [22700/6235], Loss: 2.7967\n",
      "Epoch [83/100], Step [22800/6235], Loss: 3.8202\n",
      "Epoch [83/100], Step [22900/6235], Loss: 2.5223\n",
      "Epoch [83/100], Step [23000/6235], Loss: 9.2908\n",
      "Epoch [83/100], Step [23100/6235], Loss: 8.3101\n",
      "Epoch [83/100], Step [23200/6235], Loss: 12.2176\n",
      "Epoch [83/100], Step [23300/6235], Loss: 19.0991\n",
      "Epoch [83/100], Step [23400/6235], Loss: 1.5116\n",
      "Epoch [83/100], Step [23500/6235], Loss: 0.1466\n",
      "Epoch [83/100], Step [23600/6235], Loss: 120.3800\n",
      "Epoch [83/100], Step [23700/6235], Loss: 4.4330\n",
      "Epoch [83/100], Step [23800/6235], Loss: 1.0643\n",
      "Epoch [83/100], Step [23900/6235], Loss: 6.3286\n",
      "Epoch [83/100], Step [24000/6235], Loss: 0.1651\n",
      "Epoch [83/100], Step [24100/6235], Loss: 0.2780\n",
      "Epoch [83/100], Step [24200/6235], Loss: 52.8107\n",
      "Epoch [83/100], Step [24300/6235], Loss: 1.4697\n",
      "Epoch [83/100], Step [24400/6235], Loss: 2.9417\n",
      "Epoch [83/100], Step [24500/6235], Loss: 1.2879\n",
      "Epoch [83/100], Step [24600/6235], Loss: 0.1176\n",
      "Epoch [83/100], Step [24700/6235], Loss: 0.2210\n",
      "Epoch [83/100], Step [24800/6235], Loss: 0.5140\n",
      "Epoch [83/100], Step [24900/6235], Loss: 0.8758\n",
      "Epoch [83/100], Step [25000/6235], Loss: 18.8018\n",
      "Epoch [83/100], Step [25100/6235], Loss: 8.0289\n",
      "Epoch [83/100], Step [25200/6235], Loss: 0.9158\n",
      "Epoch [83/100], Step [25300/6235], Loss: 0.5942\n",
      "Epoch [83/100], Step [25400/6235], Loss: 6.7533\n",
      "Epoch [83/100], Step [25500/6235], Loss: 6.9549\n",
      "Epoch [83/100], Step [25600/6235], Loss: 4.0881\n",
      "Epoch [83/100], Step [25700/6235], Loss: 0.3778\n",
      "Epoch [83/100], Step [25800/6235], Loss: 0.2203\n",
      "Epoch [83/100], Step [25900/6235], Loss: 9.3003\n",
      "Epoch [83/100], Step [26000/6235], Loss: 0.8113\n",
      "Epoch [83/100], Step [26100/6235], Loss: 0.5456\n",
      "Epoch [83/100], Step [26200/6235], Loss: 0.1097\n",
      "Epoch [83/100], Step [26300/6235], Loss: 4.7905\n",
      "Epoch [83/100], Step [26400/6235], Loss: 0.1007\n",
      "Epoch [83/100], Step [26500/6235], Loss: 0.0403\n",
      "Epoch [83/100], Step [26600/6235], Loss: 1.9509\n",
      "Epoch [83/100], Step [26700/6235], Loss: 0.4299\n",
      "Epoch [83/100], Step [26800/6235], Loss: 0.2405\n",
      "Epoch [83/100], Step [26900/6235], Loss: 0.0012\n",
      "Epoch [83/100], Step [27000/6235], Loss: 14.4624\n",
      "Epoch [83/100], Step [27100/6235], Loss: 0.0614\n",
      "Epoch [83/100], Step [27200/6235], Loss: 0.0305\n",
      "Epoch [83/100], Step [27300/6235], Loss: 0.2408\n",
      "Epoch [83/100], Step [27400/6235], Loss: 0.8013\n",
      "Epoch [83/100], Step [27500/6235], Loss: 17.9070\n",
      "Epoch [83/100], Step [27600/6235], Loss: 0.1370\n",
      "Epoch [83/100], Step [27700/6235], Loss: 1.0063\n",
      "Epoch [83/100], Step [27800/6235], Loss: 0.0550\n",
      "Epoch [83/100], Step [27900/6235], Loss: 0.8486\n",
      "Epoch [83/100], Step [28000/6235], Loss: 170.9216\n",
      "Epoch [83/100], Step [28100/6235], Loss: 0.5021\n",
      "Epoch [83/100], Step [28200/6235], Loss: 30.5608\n",
      "Epoch [83/100], Step [28300/6235], Loss: 2.0909\n",
      "Epoch [83/100], Step [28400/6235], Loss: 26.0605\n",
      "Epoch [83/100], Step [28500/6235], Loss: 4.4099\n",
      "Epoch [83/100], Step [28600/6235], Loss: 0.0816\n",
      "Epoch [83/100], Step [28700/6235], Loss: 5.5998\n",
      "Epoch [83/100], Step [28800/6235], Loss: 0.6034\n",
      "Epoch [83/100], Step [28900/6235], Loss: 71.4888\n",
      "Epoch [83/100], Step [29000/6235], Loss: 12.8332\n",
      "Epoch [83/100], Step [29100/6235], Loss: 0.1655\n",
      "Epoch [83/100], Step [29200/6235], Loss: 1.3243\n",
      "Epoch [83/100], Step [29300/6235], Loss: 15.5476\n",
      "Epoch [83/100], Step [29400/6235], Loss: 1.0254\n",
      "Epoch [83/100], Step [29500/6235], Loss: 1.8447\n",
      "Epoch [83/100], Step [29600/6235], Loss: 0.2411\n",
      "Epoch [83/100], Step [29700/6235], Loss: 1.7431\n",
      "Epoch [83/100], Step [29800/6235], Loss: 1.4433\n",
      "Epoch [83/100], Step [29900/6235], Loss: 1.3109\n",
      "Epoch [83/100], Step [30000/6235], Loss: 5.7131\n",
      "Epoch [83/100], Step [30100/6235], Loss: 11.2172\n",
      "Epoch [83/100], Step [30200/6235], Loss: 1.3112\n",
      "Epoch [83/100], Step [30300/6235], Loss: 0.0300\n",
      "Epoch [83/100], Step [30400/6235], Loss: 1.2699\n",
      "Epoch [83/100], Step [30500/6235], Loss: 3.0313\n",
      "Epoch [83/100], Step [30600/6235], Loss: 1.8591\n",
      "Epoch [83/100], Step [30700/6235], Loss: 0.8300\n",
      "Epoch [83/100], Step [30800/6235], Loss: 0.5451\n",
      "Epoch [83/100], Step [30900/6235], Loss: 3.5082\n",
      "Epoch [83/100], Step [31000/6235], Loss: 0.2304\n",
      "Epoch [83/100], Step [31100/6235], Loss: 0.0768\n",
      "Epoch [83/100], Step [31200/6235], Loss: 6.3178\n",
      "Epoch [83/100], Step [31300/6235], Loss: 2.9154\n",
      "Epoch [83/100], Step [31400/6235], Loss: 3.7982\n",
      "Epoch [83/100], Step [31500/6235], Loss: 0.7153\n",
      "Epoch [83/100], Step [31600/6235], Loss: 6.9945\n",
      "Epoch [83/100], Step [31700/6235], Loss: 12.9373\n",
      "Epoch [83/100], Step [31800/6235], Loss: 0.7361\n",
      "Epoch [83/100], Step [31900/6235], Loss: 32.6006\n",
      "Epoch [83/100], Step [32000/6235], Loss: 2.7218\n",
      "Epoch [83/100], Step [32100/6235], Loss: 3.6227\n",
      "Epoch [83/100], Step [32200/6235], Loss: 45.4670\n",
      "Epoch [83/100], Step [32300/6235], Loss: 0.3115\n",
      "Epoch [83/100], Step [32400/6235], Loss: 0.1407\n",
      "Epoch [83/100], Step [32500/6235], Loss: 19.2117\n",
      "Epoch [83/100], Step [32600/6235], Loss: 1.3011\n",
      "Epoch [83/100], Step [32700/6235], Loss: 88.9125\n",
      "Epoch [83/100], Step [32800/6235], Loss: 1.1429\n",
      "Epoch [83/100], Step [32900/6235], Loss: 15.6779\n",
      "Epoch [83/100], Step [33000/6235], Loss: 0.5294\n",
      "Epoch [83/100], Step [33100/6235], Loss: 1.3350\n",
      "Epoch [83/100], Step [33200/6235], Loss: 1.3145\n",
      "Epoch [83/100], Step [33300/6235], Loss: 0.7430\n",
      "Epoch [83/100], Step [33400/6235], Loss: 22.4485\n",
      "Epoch [83/100], Step [33500/6235], Loss: 0.3536\n",
      "Epoch [83/100], Step [33600/6235], Loss: 9.1623\n",
      "Epoch [83/100], Step [33700/6235], Loss: 13.9788\n",
      "Epoch [83/100], Step [33800/6235], Loss: 1.8821\n",
      "Epoch [83/100], Step [33900/6235], Loss: 28.9082\n",
      "Epoch [83/100], Step [34000/6235], Loss: 0.0209\n",
      "Epoch [83/100], Step [34100/6235], Loss: 0.4165\n",
      "Epoch [83/100], Step [34200/6235], Loss: 3.2813\n",
      "Epoch [83/100], Step [34300/6235], Loss: 5.1365\n",
      "Epoch [83/100], Step [34400/6235], Loss: 0.2178\n",
      "Epoch [83/100], Step [34500/6235], Loss: 39.3511\n",
      "Epoch [83/100], Step [34600/6235], Loss: 0.3371\n",
      "Epoch [83/100], Step [34700/6235], Loss: 60.6540\n",
      "Epoch [83/100], Step [34800/6235], Loss: 14.5516\n",
      "Epoch [83/100], Step [34900/6235], Loss: 43.8215\n",
      "Epoch [83/100], Step [35000/6235], Loss: 1.2946\n",
      "Epoch [83/100], Step [35100/6235], Loss: 1.2853\n",
      "Epoch [83/100], Step [35200/6235], Loss: 0.2584\n",
      "Epoch [83/100], Step [35300/6235], Loss: 2.1291\n",
      "Epoch [83/100], Step [35400/6235], Loss: 0.4637\n",
      "Epoch [83/100], Step [35500/6235], Loss: 2.0854\n",
      "Epoch [83/100], Step [35600/6235], Loss: 1.5465\n",
      "Epoch [83/100], Step [35700/6235], Loss: 6.3486\n",
      "Epoch [83/100], Step [35800/6235], Loss: 0.3865\n",
      "Epoch [83/100], Step [35900/6235], Loss: 0.5395\n",
      "Epoch [83/100], Step [36000/6235], Loss: 0.0891\n",
      "Epoch [83/100], Step [36100/6235], Loss: 0.0461\n",
      "Epoch [83/100], Step [36200/6235], Loss: 22.9936\n",
      "Epoch [83/100], Step [36300/6235], Loss: 0.4144\n",
      "Epoch [83/100], Step [36400/6235], Loss: 2.7316\n",
      "Epoch [83/100], Step [36500/6235], Loss: 8.8060\n",
      "Epoch [83/100], Step [36600/6235], Loss: 0.1281\n",
      "Epoch [83/100], Step [36700/6235], Loss: 0.3808\n",
      "Epoch [83/100], Step [36800/6235], Loss: 12.6174\n",
      "Epoch [83/100], Step [36900/6235], Loss: 10.4256\n",
      "Epoch [83/100], Step [37000/6235], Loss: 0.5262\n",
      "Epoch [83/100], Step [37100/6235], Loss: 1.1090\n",
      "Epoch [83/100], Step [37200/6235], Loss: 0.0777\n",
      "Epoch [83/100], Step [37300/6235], Loss: 0.0462\n",
      "Epoch [83/100], Step [37400/6235], Loss: 0.2002\n",
      "Epoch [83/100], Step [37500/6235], Loss: 4.3912\n",
      "Epoch [83/100], Step [37600/6235], Loss: 11.6459\n",
      "Epoch [83/100], Step [37700/6235], Loss: 1.3971\n",
      "Epoch [83/100], Step [37800/6235], Loss: 5.5122\n",
      "Epoch [83/100], Step [37900/6235], Loss: 6.0319\n",
      "Epoch [83/100], Step [38000/6235], Loss: 0.6253\n",
      "Epoch [83/100], Step [38100/6235], Loss: 3.9426\n",
      "Epoch [83/100], Step [38200/6235], Loss: 2.3537\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [83/100], Step [38300/6235], Loss: 0.8578\n",
      "Epoch [83/100], Step [38400/6235], Loss: 0.1322\n",
      "Epoch [83/100], Step [38500/6235], Loss: 2.7204\n",
      "Epoch [83/100], Step [38600/6235], Loss: 0.1440\n",
      "Epoch [83/100], Step [38700/6235], Loss: 0.0597\n",
      "Epoch [83/100], Step [38800/6235], Loss: 0.2366\n",
      "Epoch [83/100], Step [38900/6235], Loss: 1.7736\n",
      "Epoch [83/100], Step [39000/6235], Loss: 17.5516\n",
      "Epoch [83/100], Step [39100/6235], Loss: 18.7411\n",
      "Epoch [83/100], Step [39200/6235], Loss: 0.3408\n",
      "Epoch [83/100], Step [39300/6235], Loss: 61.3250\n",
      "Epoch [83/100], Step [39400/6235], Loss: 257.7451\n",
      "Epoch [83/100], Step [39500/6235], Loss: 65.0827\n",
      "Epoch [83/100], Step [39600/6235], Loss: 17.9220\n",
      "Epoch [83/100], Step [39700/6235], Loss: 376.7168\n",
      "Epoch [83/100], Step [39800/6235], Loss: 84.6720\n",
      "Epoch [83/100], Step [39900/6235], Loss: 5.2154\n",
      "Epoch [83/100], Step [40000/6235], Loss: 1.7178\n",
      "Epoch [83/100], Step [40100/6235], Loss: 12.6954\n",
      "Epoch [83/100], Step [40200/6235], Loss: 8.1454\n",
      "Epoch [83/100], Step [40300/6235], Loss: 0.3455\n",
      "Epoch [83/100], Step [40400/6235], Loss: 0.1401\n",
      "Epoch [83/100], Step [40500/6235], Loss: 3.1401\n",
      "Epoch [83/100], Step [40600/6235], Loss: 0.3088\n",
      "Epoch [83/100], Step [40700/6235], Loss: 5.9786\n",
      "Epoch [83/100], Step [40800/6235], Loss: 0.7712\n",
      "Epoch [83/100], Step [40900/6235], Loss: 1.2299\n",
      "Epoch [83/100], Step [41000/6235], Loss: 43.3116\n",
      "Epoch [83/100], Step [41100/6235], Loss: 36.5807\n",
      "Epoch [83/100], Step [41200/6235], Loss: 4.0827\n",
      "Epoch [83/100], Step [41300/6235], Loss: 4.1146\n",
      "Epoch [83/100], Step [41400/6235], Loss: 0.7649\n",
      "Epoch [83/100], Step [41500/6235], Loss: 1.0646\n",
      "Epoch [83/100], Step [41600/6235], Loss: 0.5411\n",
      "Epoch [83/100], Step [41700/6235], Loss: 1.7989\n",
      "Epoch [83/100], Step [41800/6235], Loss: 3.9664\n",
      "Epoch [83/100], Step [41900/6235], Loss: 4.6634\n",
      "Epoch [83/100], Step [42000/6235], Loss: 4.6701\n",
      "Epoch [83/100], Step [42100/6235], Loss: 10.8675\n",
      "Epoch [83/100], Step [42200/6235], Loss: 37.0280\n",
      "Epoch [83/100], Step [42300/6235], Loss: 0.4032\n",
      "Epoch [83/100], Step [42400/6235], Loss: 3.0979\n",
      "Epoch [83/100], Step [42500/6235], Loss: 0.7418\n",
      "Epoch [83/100], Step [42600/6235], Loss: 2.1671\n",
      "Epoch [83/100], Step [42700/6235], Loss: 0.6066\n",
      "Epoch [83/100], Step [42800/6235], Loss: 16.0542\n",
      "Epoch [83/100], Step [42900/6235], Loss: 0.2566\n",
      "Epoch [83/100], Step [43000/6235], Loss: 0.3781\n",
      "Epoch [83/100], Step [43100/6235], Loss: 0.0474\n",
      "Epoch [83/100], Step [43200/6235], Loss: 0.2089\n",
      "Epoch [83/100], Step [43300/6235], Loss: 4.8207\n",
      "Epoch [83/100], Step [43400/6235], Loss: 5.1553\n",
      "Epoch [83/100], Step [43500/6235], Loss: 11.3432\n",
      "Epoch [83/100], Step [43600/6235], Loss: 1.7912\n",
      "Epoch [83/100], Step [43700/6235], Loss: 51.0775\n",
      "Epoch [83/100], Step [43800/6235], Loss: 0.2801\n",
      "Epoch [83/100], Step [43900/6235], Loss: 3.2067\n",
      "Epoch [83/100], Step [44000/6235], Loss: 53.5398\n",
      "Epoch [83/100], Step [44100/6235], Loss: 2.9488\n",
      "Epoch [83/100], Step [44200/6235], Loss: 3.0136\n",
      "Epoch [83/100], Step [44300/6235], Loss: 95.6452\n",
      "Epoch [83/100], Step [44400/6235], Loss: 0.9474\n",
      "Epoch [83/100], Step [44500/6235], Loss: 0.2896\n",
      "Epoch [83/100], Step [44600/6235], Loss: 21.1495\n",
      "Epoch [83/100], Step [44700/6235], Loss: 0.7324\n",
      "Epoch [83/100], Step [44800/6235], Loss: 3.5014\n",
      "Epoch [83/100], Step [44900/6235], Loss: 10.5072\n",
      "Epoch [83/100], Step [45000/6235], Loss: 6.0711\n",
      "Epoch [83/100], Step [45100/6235], Loss: 53.5282\n",
      "Epoch [83/100], Step [45200/6235], Loss: 5.1232\n",
      "Epoch [83/100], Step [45300/6235], Loss: 26.0892\n",
      "Epoch [83/100], Step [45400/6235], Loss: 12.1816\n",
      "Epoch [83/100], Step [45500/6235], Loss: 1.8026\n",
      "Epoch [83/100], Step [45600/6235], Loss: 0.2696\n",
      "Epoch [83/100], Step [45700/6235], Loss: 65.8638\n",
      "Epoch [83/100], Step [45800/6235], Loss: 325.9102\n",
      "Epoch [83/100], Step [45900/6235], Loss: 48.2922\n",
      "Epoch [83/100], Step [46000/6235], Loss: 0.8155\n",
      "Epoch [83/100], Step [46100/6235], Loss: 31.3345\n",
      "Epoch [83/100], Step [46200/6235], Loss: 5.2315\n",
      "Epoch [83/100], Step [46300/6235], Loss: 23.5005\n",
      "Epoch [83/100], Step [46400/6235], Loss: 10.4338\n",
      "Epoch [83/100], Step [46500/6235], Loss: 3.8125\n",
      "Epoch [83/100], Step [46600/6235], Loss: 14.5272\n",
      "Epoch [83/100], Step [46700/6235], Loss: 8.2727\n",
      "Epoch [83/100], Step [46800/6235], Loss: 10.4865\n",
      "Epoch [83/100], Step [46900/6235], Loss: 5.5848\n",
      "Epoch [83/100], Step [47000/6235], Loss: 5.0905\n",
      "Epoch [83/100], Step [47100/6235], Loss: 5.7485\n",
      "Epoch [83/100], Step [47200/6235], Loss: 35.5841\n",
      "Epoch [83/100], Step [47300/6235], Loss: 1.1183\n",
      "Epoch [83/100], Step [47400/6235], Loss: 47.0560\n",
      "Epoch [83/100], Step [47500/6235], Loss: 32.2775\n",
      "Epoch [83/100], Step [47600/6235], Loss: 5.0366\n",
      "Epoch [83/100], Step [47700/6235], Loss: 9.7542\n",
      "Epoch [83/100], Step [47800/6235], Loss: 7.3568\n",
      "Epoch [83/100], Step [47900/6235], Loss: 17.6032\n",
      "Epoch [83/100], Step [48000/6235], Loss: 43.1927\n",
      "Epoch [83/100], Step [48100/6235], Loss: 5.2407\n",
      "Epoch [83/100], Step [48200/6235], Loss: 63.9226\n",
      "Epoch [83/100], Step [48300/6235], Loss: 337.2046\n",
      "Epoch [83/100], Step [48400/6235], Loss: 29.6911\n",
      "Epoch [83/100], Step [48500/6235], Loss: 19.9772\n",
      "Epoch [83/100], Step [48600/6235], Loss: 165.6449\n",
      "Epoch [83/100], Step [48700/6235], Loss: 24.1338\n",
      "Epoch [83/100], Step [48800/6235], Loss: 475.9957\n",
      "Epoch [83/100], Step [48900/6235], Loss: 505.4645\n",
      "Epoch [83/100], Step [49000/6235], Loss: 232.2196\n",
      "Epoch [83/100], Step [49100/6235], Loss: 1964.3015\n",
      "Epoch [83/100], Step [49200/6235], Loss: 646.8240\n",
      "Epoch [83/100], Step [49300/6235], Loss: 1258.2722\n",
      "Epoch [83/100], Step [49400/6235], Loss: 70.2445\n",
      "Epoch [83/100], Step [49500/6235], Loss: 13.5171\n",
      "Epoch [83/100], Step [49600/6235], Loss: 32.3104\n",
      "Epoch [83/100], Step [49700/6235], Loss: 4950.6611\n",
      "Epoch [83/100], Step [49800/6235], Loss: 823.1943\n",
      "Epoch [84/100], Step [100/6235], Loss: 41.9939\n",
      "Epoch [84/100], Step [200/6235], Loss: 0.4331\n",
      "Epoch [84/100], Step [300/6235], Loss: 0.0122\n",
      "Epoch [84/100], Step [400/6235], Loss: 0.0058\n",
      "Epoch [84/100], Step [500/6235], Loss: 3.5348\n",
      "Epoch [84/100], Step [600/6235], Loss: 0.0238\n",
      "Epoch [84/100], Step [700/6235], Loss: 0.6248\n",
      "Epoch [84/100], Step [800/6235], Loss: 0.1013\n",
      "Epoch [84/100], Step [900/6235], Loss: 0.1220\n",
      "Epoch [84/100], Step [1000/6235], Loss: 0.0350\n",
      "Epoch [84/100], Step [1100/6235], Loss: 0.2002\n",
      "Epoch [84/100], Step [1200/6235], Loss: 0.1729\n",
      "Epoch [84/100], Step [1300/6235], Loss: 0.0267\n",
      "Epoch [84/100], Step [1400/6235], Loss: 0.4317\n",
      "Epoch [84/100], Step [1500/6235], Loss: 0.0109\n",
      "Epoch [84/100], Step [1600/6235], Loss: 0.2422\n",
      "Epoch [84/100], Step [1700/6235], Loss: 0.1677\n",
      "Epoch [84/100], Step [1800/6235], Loss: 0.2562\n",
      "Epoch [84/100], Step [1900/6235], Loss: 0.2865\n",
      "Epoch [84/100], Step [2000/6235], Loss: 2.2838\n",
      "Epoch [84/100], Step [2100/6235], Loss: 1.9214\n",
      "Epoch [84/100], Step [2200/6235], Loss: 6.4172\n",
      "Epoch [84/100], Step [2300/6235], Loss: 1.2177\n",
      "Epoch [84/100], Step [2400/6235], Loss: 0.8953\n",
      "Epoch [84/100], Step [2500/6235], Loss: 26.3503\n",
      "Epoch [84/100], Step [2600/6235], Loss: 13.5087\n",
      "Epoch [84/100], Step [2700/6235], Loss: 4.8062\n",
      "Epoch [84/100], Step [2800/6235], Loss: 71.6163\n",
      "Epoch [84/100], Step [2900/6235], Loss: 18.6033\n",
      "Epoch [84/100], Step [3000/6235], Loss: 1.2854\n",
      "Epoch [84/100], Step [3100/6235], Loss: 65.4888\n",
      "Epoch [84/100], Step [3200/6235], Loss: 52.0536\n",
      "Epoch [84/100], Step [3300/6235], Loss: 10.9850\n",
      "Epoch [84/100], Step [3400/6235], Loss: 2.6119\n",
      "Epoch [84/100], Step [3500/6235], Loss: 48.5774\n",
      "Epoch [84/100], Step [3600/6235], Loss: 2.7945\n",
      "Epoch [84/100], Step [3700/6235], Loss: 0.0256\n",
      "Epoch [84/100], Step [3800/6235], Loss: 0.0024\n",
      "Epoch [84/100], Step [3900/6235], Loss: 0.0212\n",
      "Epoch [84/100], Step [4000/6235], Loss: 0.0786\n",
      "Epoch [84/100], Step [4100/6235], Loss: 9.2035\n",
      "Epoch [84/100], Step [4200/6235], Loss: 2.5563\n",
      "Epoch [84/100], Step [4300/6235], Loss: 5.2428\n",
      "Epoch [84/100], Step [4400/6235], Loss: 0.8166\n",
      "Epoch [84/100], Step [4500/6235], Loss: 36.3809\n",
      "Epoch [84/100], Step [4600/6235], Loss: 0.6167\n",
      "Epoch [84/100], Step [4700/6235], Loss: 0.4424\n",
      "Epoch [84/100], Step [4800/6235], Loss: 8.9625\n",
      "Epoch [84/100], Step [4900/6235], Loss: 0.2770\n",
      "Epoch [84/100], Step [5000/6235], Loss: 0.1013\n",
      "Epoch [84/100], Step [5100/6235], Loss: 0.5263\n",
      "Epoch [84/100], Step [5200/6235], Loss: 2.2990\n",
      "Epoch [84/100], Step [5300/6235], Loss: 32.8202\n",
      "Epoch [84/100], Step [5400/6235], Loss: 0.0165\n",
      "Epoch [84/100], Step [5500/6235], Loss: 0.0055\n",
      "Epoch [84/100], Step [5600/6235], Loss: 0.2217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Step [5700/6235], Loss: 0.1567\n",
      "Epoch [84/100], Step [5800/6235], Loss: 0.2564\n",
      "Epoch [84/100], Step [5900/6235], Loss: 0.1978\n",
      "Epoch [84/100], Step [6000/6235], Loss: 0.4423\n",
      "Epoch [84/100], Step [6100/6235], Loss: 0.0429\n",
      "Epoch [84/100], Step [6200/6235], Loss: 4.9388\n",
      "Epoch [84/100], Step [6300/6235], Loss: 0.0675\n",
      "Epoch [84/100], Step [6400/6235], Loss: 0.1065\n",
      "Epoch [84/100], Step [6500/6235], Loss: 4.5010\n",
      "Epoch [84/100], Step [6600/6235], Loss: 6.7631\n",
      "Epoch [84/100], Step [6700/6235], Loss: 1.4380\n",
      "Epoch [84/100], Step [6800/6235], Loss: 0.4458\n",
      "Epoch [84/100], Step [6900/6235], Loss: 0.7023\n",
      "Epoch [84/100], Step [7000/6235], Loss: 0.0110\n",
      "Epoch [84/100], Step [7100/6235], Loss: 0.3176\n",
      "Epoch [84/100], Step [7200/6235], Loss: 0.2786\n",
      "Epoch [84/100], Step [7300/6235], Loss: 1.5287\n",
      "Epoch [84/100], Step [7400/6235], Loss: 0.0198\n",
      "Epoch [84/100], Step [7500/6235], Loss: 0.2201\n",
      "Epoch [84/100], Step [7600/6235], Loss: 5.4516\n",
      "Epoch [84/100], Step [7700/6235], Loss: 9.0964\n",
      "Epoch [84/100], Step [7800/6235], Loss: 1.3119\n",
      "Epoch [84/100], Step [7900/6235], Loss: 0.5518\n",
      "Epoch [84/100], Step [8000/6235], Loss: 0.1799\n",
      "Epoch [84/100], Step [8100/6235], Loss: 2.3854\n",
      "Epoch [84/100], Step [8200/6235], Loss: 9.9918\n",
      "Epoch [84/100], Step [8300/6235], Loss: 18.4649\n",
      "Epoch [84/100], Step [8400/6235], Loss: 449.7236\n",
      "Epoch [84/100], Step [8500/6235], Loss: 2.0697\n",
      "Epoch [84/100], Step [8600/6235], Loss: 28.1834\n",
      "Epoch [84/100], Step [8700/6235], Loss: 18.8340\n",
      "Epoch [84/100], Step [8800/6235], Loss: 945.3647\n",
      "Epoch [84/100], Step [8900/6235], Loss: 82.8104\n",
      "Epoch [84/100], Step [9000/6235], Loss: 480.8783\n",
      "Epoch [84/100], Step [9100/6235], Loss: 2068.5881\n",
      "Epoch [84/100], Step [9200/6235], Loss: 3256.2959\n",
      "Epoch [84/100], Step [9300/6235], Loss: 4.9642\n",
      "Epoch [84/100], Step [9400/6235], Loss: 321.4845\n",
      "Epoch [84/100], Step [9500/6235], Loss: 1202.0635\n",
      "Epoch [84/100], Step [9600/6235], Loss: 270.1020\n",
      "Epoch [84/100], Step [9700/6235], Loss: 7.8122\n",
      "Epoch [84/100], Step [9800/6235], Loss: 5470.8555\n",
      "Epoch [84/100], Step [9900/6235], Loss: 12.8514\n",
      "Epoch [84/100], Step [10000/6235], Loss: 12.9711\n",
      "Epoch [84/100], Step [10100/6235], Loss: 1.1407\n",
      "Epoch [84/100], Step [10200/6235], Loss: 1167.0618\n",
      "Epoch [84/100], Step [10300/6235], Loss: 27.6260\n",
      "Epoch [84/100], Step [10400/6235], Loss: 10.5957\n",
      "Epoch [84/100], Step [10500/6235], Loss: 29.9685\n",
      "Epoch [84/100], Step [10600/6235], Loss: 138.9021\n",
      "Epoch [84/100], Step [10700/6235], Loss: 8.8306\n",
      "Epoch [84/100], Step [10800/6235], Loss: 118.9155\n",
      "Epoch [84/100], Step [10900/6235], Loss: 102.4628\n",
      "Epoch [84/100], Step [11000/6235], Loss: 286.4430\n",
      "Epoch [84/100], Step [11100/6235], Loss: 27.1581\n",
      "Epoch [84/100], Step [11200/6235], Loss: 2.5130\n",
      "Epoch [84/100], Step [11300/6235], Loss: 97.2863\n",
      "Epoch [84/100], Step [11400/6235], Loss: 36.6322\n",
      "Epoch [84/100], Step [11500/6235], Loss: 12.9886\n",
      "Epoch [84/100], Step [11600/6235], Loss: 8.6691\n",
      "Epoch [84/100], Step [11700/6235], Loss: 54.3875\n",
      "Epoch [84/100], Step [11800/6235], Loss: 3.4399\n",
      "Epoch [84/100], Step [11900/6235], Loss: 4.7313\n",
      "Epoch [84/100], Step [12000/6235], Loss: 643.4932\n",
      "Epoch [84/100], Step [12100/6235], Loss: 239.7779\n",
      "Epoch [84/100], Step [12200/6235], Loss: 42.0765\n",
      "Epoch [84/100], Step [12300/6235], Loss: 18.5165\n",
      "Epoch [84/100], Step [12400/6235], Loss: 533.8325\n",
      "Epoch [84/100], Step [12500/6235], Loss: 52.0552\n",
      "Epoch [84/100], Step [12600/6235], Loss: 12.9097\n",
      "Epoch [84/100], Step [12700/6235], Loss: 3.6484\n",
      "Epoch [84/100], Step [12800/6235], Loss: 16.9110\n",
      "Epoch [84/100], Step [12900/6235], Loss: 30.9384\n",
      "Epoch [84/100], Step [13000/6235], Loss: 0.0470\n",
      "Epoch [84/100], Step [13100/6235], Loss: 61.8657\n",
      "Epoch [84/100], Step [13200/6235], Loss: 8.0639\n",
      "Epoch [84/100], Step [13300/6235], Loss: 20.0315\n",
      "Epoch [84/100], Step [13400/6235], Loss: 209.1252\n",
      "Epoch [84/100], Step [13500/6235], Loss: 11.5340\n",
      "Epoch [84/100], Step [13600/6235], Loss: 3.1390\n",
      "Epoch [84/100], Step [13700/6235], Loss: 129.9062\n",
      "Epoch [84/100], Step [13800/6235], Loss: 115.4896\n",
      "Epoch [84/100], Step [13900/6235], Loss: 46.7232\n",
      "Epoch [84/100], Step [14000/6235], Loss: 11.8946\n",
      "Epoch [84/100], Step [14100/6235], Loss: 16.6552\n",
      "Epoch [84/100], Step [14200/6235], Loss: 41.4636\n",
      "Epoch [84/100], Step [14300/6235], Loss: 0.1708\n",
      "Epoch [84/100], Step [14400/6235], Loss: 29.9806\n",
      "Epoch [84/100], Step [14500/6235], Loss: 30.6179\n",
      "Epoch [84/100], Step [14600/6235], Loss: 2.4924\n",
      "Epoch [84/100], Step [14700/6235], Loss: 27.0839\n",
      "Epoch [84/100], Step [14800/6235], Loss: 31.0425\n",
      "Epoch [84/100], Step [14900/6235], Loss: 0.6756\n",
      "Epoch [84/100], Step [15000/6235], Loss: 1.1868\n",
      "Epoch [84/100], Step [15100/6235], Loss: 0.3884\n",
      "Epoch [84/100], Step [15200/6235], Loss: 40.8590\n",
      "Epoch [84/100], Step [15300/6235], Loss: 1.1321\n",
      "Epoch [84/100], Step [15400/6235], Loss: 85.4830\n",
      "Epoch [84/100], Step [15500/6235], Loss: 16.9595\n",
      "Epoch [84/100], Step [15600/6235], Loss: 184.4125\n",
      "Epoch [84/100], Step [15700/6235], Loss: 142.0159\n",
      "Epoch [84/100], Step [15800/6235], Loss: 0.3272\n",
      "Epoch [84/100], Step [15900/6235], Loss: 2.9576\n",
      "Epoch [84/100], Step [16000/6235], Loss: 67.3149\n",
      "Epoch [84/100], Step [16100/6235], Loss: 3.9578\n",
      "Epoch [84/100], Step [16200/6235], Loss: 0.4567\n",
      "Epoch [84/100], Step [16300/6235], Loss: 8.6366\n",
      "Epoch [84/100], Step [16400/6235], Loss: 24.1221\n",
      "Epoch [84/100], Step [16500/6235], Loss: 184.7299\n",
      "Epoch [84/100], Step [16600/6235], Loss: 29.2263\n",
      "Epoch [84/100], Step [16700/6235], Loss: 0.6124\n",
      "Epoch [84/100], Step [16800/6235], Loss: 9.8178\n",
      "Epoch [84/100], Step [16900/6235], Loss: 0.2381\n",
      "Epoch [84/100], Step [17000/6235], Loss: 0.2255\n",
      "Epoch [84/100], Step [17100/6235], Loss: 0.1343\n",
      "Epoch [84/100], Step [17200/6235], Loss: 260.8844\n",
      "Epoch [84/100], Step [17300/6235], Loss: 1.2148\n",
      "Epoch [84/100], Step [17400/6235], Loss: 37.2808\n",
      "Epoch [84/100], Step [17500/6235], Loss: 1.6035\n",
      "Epoch [84/100], Step [17600/6235], Loss: 2.5820\n",
      "Epoch [84/100], Step [17700/6235], Loss: 0.3488\n",
      "Epoch [84/100], Step [17800/6235], Loss: 39.0549\n",
      "Epoch [84/100], Step [17900/6235], Loss: 8.2190\n",
      "Epoch [84/100], Step [18000/6235], Loss: 7.9738\n",
      "Epoch [84/100], Step [18100/6235], Loss: 19.0041\n",
      "Epoch [84/100], Step [18200/6235], Loss: 0.7644\n",
      "Epoch [84/100], Step [18300/6235], Loss: 5.9068\n",
      "Epoch [84/100], Step [18400/6235], Loss: 5.0949\n",
      "Epoch [84/100], Step [18500/6235], Loss: 12.3810\n",
      "Epoch [84/100], Step [18600/6235], Loss: 0.9026\n",
      "Epoch [84/100], Step [18700/6235], Loss: 0.4267\n",
      "Epoch [84/100], Step [18800/6235], Loss: 133.6359\n",
      "Epoch [84/100], Step [18900/6235], Loss: 27.3617\n",
      "Epoch [84/100], Step [19000/6235], Loss: 7.7575\n",
      "Epoch [84/100], Step [19100/6235], Loss: 6.4101\n",
      "Epoch [84/100], Step [19200/6235], Loss: 2.5287\n",
      "Epoch [84/100], Step [19300/6235], Loss: 7.7593\n",
      "Epoch [84/100], Step [19400/6235], Loss: 232.9005\n",
      "Epoch [84/100], Step [19500/6235], Loss: 173.8375\n",
      "Epoch [84/100], Step [19600/6235], Loss: 121.4680\n",
      "Epoch [84/100], Step [19700/6235], Loss: 32.3409\n",
      "Epoch [84/100], Step [19800/6235], Loss: 1.2064\n",
      "Epoch [84/100], Step [19900/6235], Loss: 1.4798\n",
      "Epoch [84/100], Step [20000/6235], Loss: 104.3532\n",
      "Epoch [84/100], Step [20100/6235], Loss: 11.3237\n",
      "Epoch [84/100], Step [20200/6235], Loss: 2.1214\n",
      "Epoch [84/100], Step [20300/6235], Loss: 0.3843\n",
      "Epoch [84/100], Step [20400/6235], Loss: 30.1265\n",
      "Epoch [84/100], Step [20500/6235], Loss: 27.8982\n",
      "Epoch [84/100], Step [20600/6235], Loss: 9.3876\n",
      "Epoch [84/100], Step [20700/6235], Loss: 14.2350\n",
      "Epoch [84/100], Step [20800/6235], Loss: 5.4096\n",
      "Epoch [84/100], Step [20900/6235], Loss: 19.2824\n",
      "Epoch [84/100], Step [21000/6235], Loss: 24.4198\n",
      "Epoch [84/100], Step [21100/6235], Loss: 0.7193\n",
      "Epoch [84/100], Step [21200/6235], Loss: 0.1358\n",
      "Epoch [84/100], Step [21300/6235], Loss: 0.1547\n",
      "Epoch [84/100], Step [21400/6235], Loss: 4.7353\n",
      "Epoch [84/100], Step [21500/6235], Loss: 1.5403\n",
      "Epoch [84/100], Step [21600/6235], Loss: 32.8675\n",
      "Epoch [84/100], Step [21700/6235], Loss: 0.2068\n",
      "Epoch [84/100], Step [21800/6235], Loss: 20.0744\n",
      "Epoch [84/100], Step [21900/6235], Loss: 0.0028\n",
      "Epoch [84/100], Step [22000/6235], Loss: 2.0221\n",
      "Epoch [84/100], Step [22100/6235], Loss: 4.9498\n",
      "Epoch [84/100], Step [22200/6235], Loss: 12.1297\n",
      "Epoch [84/100], Step [22300/6235], Loss: 0.7607\n",
      "Epoch [84/100], Step [22400/6235], Loss: 6.6836\n",
      "Epoch [84/100], Step [22500/6235], Loss: 71.7223\n",
      "Epoch [84/100], Step [22600/6235], Loss: 18.3882\n",
      "Epoch [84/100], Step [22700/6235], Loss: 0.1389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Step [22800/6235], Loss: 11.2904\n",
      "Epoch [84/100], Step [22900/6235], Loss: 19.9310\n",
      "Epoch [84/100], Step [23000/6235], Loss: 12.6170\n",
      "Epoch [84/100], Step [23100/6235], Loss: 7.3766\n",
      "Epoch [84/100], Step [23200/6235], Loss: 10.1221\n",
      "Epoch [84/100], Step [23300/6235], Loss: 18.4661\n",
      "Epoch [84/100], Step [23400/6235], Loss: 0.8443\n",
      "Epoch [84/100], Step [23500/6235], Loss: 0.2471\n",
      "Epoch [84/100], Step [23600/6235], Loss: 103.0787\n",
      "Epoch [84/100], Step [23700/6235], Loss: 5.7279\n",
      "Epoch [84/100], Step [23800/6235], Loss: 1.0337\n",
      "Epoch [84/100], Step [23900/6235], Loss: 7.7570\n",
      "Epoch [84/100], Step [24000/6235], Loss: 0.3289\n",
      "Epoch [84/100], Step [24100/6235], Loss: 0.3530\n",
      "Epoch [84/100], Step [24200/6235], Loss: 2.7428\n",
      "Epoch [84/100], Step [24300/6235], Loss: 1.5223\n",
      "Epoch [84/100], Step [24400/6235], Loss: 4.8500\n",
      "Epoch [84/100], Step [24500/6235], Loss: 2.6035\n",
      "Epoch [84/100], Step [24600/6235], Loss: 0.1573\n",
      "Epoch [84/100], Step [24700/6235], Loss: 0.9586\n",
      "Epoch [84/100], Step [24800/6235], Loss: 0.1010\n",
      "Epoch [84/100], Step [24900/6235], Loss: 0.1187\n",
      "Epoch [84/100], Step [25000/6235], Loss: 20.2594\n",
      "Epoch [84/100], Step [25100/6235], Loss: 8.5999\n",
      "Epoch [84/100], Step [25200/6235], Loss: 1.7334\n",
      "Epoch [84/100], Step [25300/6235], Loss: 0.7709\n",
      "Epoch [84/100], Step [25400/6235], Loss: 9.6873\n",
      "Epoch [84/100], Step [25500/6235], Loss: 5.6285\n",
      "Epoch [84/100], Step [25600/6235], Loss: 2.3437\n",
      "Epoch [84/100], Step [25700/6235], Loss: 0.3539\n",
      "Epoch [84/100], Step [25800/6235], Loss: 0.1584\n",
      "Epoch [84/100], Step [25900/6235], Loss: 10.0898\n",
      "Epoch [84/100], Step [26000/6235], Loss: 4.3331\n",
      "Epoch [84/100], Step [26100/6235], Loss: 0.4727\n",
      "Epoch [84/100], Step [26200/6235], Loss: 0.0433\n",
      "Epoch [84/100], Step [26300/6235], Loss: 4.9692\n",
      "Epoch [84/100], Step [26400/6235], Loss: 0.1820\n",
      "Epoch [84/100], Step [26500/6235], Loss: 0.2326\n",
      "Epoch [84/100], Step [26600/6235], Loss: 3.2014\n",
      "Epoch [84/100], Step [26700/6235], Loss: 0.6577\n",
      "Epoch [84/100], Step [26800/6235], Loss: 0.6313\n",
      "Epoch [84/100], Step [26900/6235], Loss: 0.0432\n",
      "Epoch [84/100], Step [27000/6235], Loss: 12.5755\n",
      "Epoch [84/100], Step [27100/6235], Loss: 0.1579\n",
      "Epoch [84/100], Step [27200/6235], Loss: 0.0648\n",
      "Epoch [84/100], Step [27300/6235], Loss: 0.1949\n",
      "Epoch [84/100], Step [27400/6235], Loss: 0.9228\n",
      "Epoch [84/100], Step [27500/6235], Loss: 16.9976\n",
      "Epoch [84/100], Step [27600/6235], Loss: 1.1085\n",
      "Epoch [84/100], Step [27700/6235], Loss: 1.5930\n",
      "Epoch [84/100], Step [27800/6235], Loss: 6.0904\n",
      "Epoch [84/100], Step [27900/6235], Loss: 0.6331\n",
      "Epoch [84/100], Step [28000/6235], Loss: 106.9628\n",
      "Epoch [84/100], Step [28100/6235], Loss: 1.8704\n",
      "Epoch [84/100], Step [28200/6235], Loss: 31.9240\n",
      "Epoch [84/100], Step [28300/6235], Loss: 3.4726\n",
      "Epoch [84/100], Step [28400/6235], Loss: 24.3333\n",
      "Epoch [84/100], Step [28500/6235], Loss: 2.7420\n",
      "Epoch [84/100], Step [28600/6235], Loss: 0.5205\n",
      "Epoch [84/100], Step [28700/6235], Loss: 4.4791\n",
      "Epoch [84/100], Step [28800/6235], Loss: 0.3775\n",
      "Epoch [84/100], Step [28900/6235], Loss: 70.4551\n",
      "Epoch [84/100], Step [29000/6235], Loss: 6.9707\n",
      "Epoch [84/100], Step [29100/6235], Loss: 0.0319\n",
      "Epoch [84/100], Step [29200/6235], Loss: 0.0772\n",
      "Epoch [84/100], Step [29300/6235], Loss: 14.8792\n",
      "Epoch [84/100], Step [29400/6235], Loss: 0.1039\n",
      "Epoch [84/100], Step [29500/6235], Loss: 7.4562\n",
      "Epoch [84/100], Step [29600/6235], Loss: 0.2953\n",
      "Epoch [84/100], Step [29700/6235], Loss: 0.4609\n",
      "Epoch [84/100], Step [29800/6235], Loss: 1.7155\n",
      "Epoch [84/100], Step [29900/6235], Loss: 0.2427\n",
      "Epoch [84/100], Step [30000/6235], Loss: 3.4102\n",
      "Epoch [84/100], Step [30100/6235], Loss: 0.4731\n",
      "Epoch [84/100], Step [30200/6235], Loss: 0.0910\n",
      "Epoch [84/100], Step [30300/6235], Loss: 0.7418\n",
      "Epoch [84/100], Step [30400/6235], Loss: 0.2200\n",
      "Epoch [84/100], Step [30500/6235], Loss: 1.9697\n",
      "Epoch [84/100], Step [30600/6235], Loss: 0.5340\n",
      "Epoch [84/100], Step [30700/6235], Loss: 0.1539\n",
      "Epoch [84/100], Step [30800/6235], Loss: 0.2365\n",
      "Epoch [84/100], Step [30900/6235], Loss: 2.6825\n",
      "Epoch [84/100], Step [31000/6235], Loss: 0.0441\n",
      "Epoch [84/100], Step [31100/6235], Loss: 0.0855\n",
      "Epoch [84/100], Step [31200/6235], Loss: 5.5947\n",
      "Epoch [84/100], Step [31300/6235], Loss: 4.8639\n",
      "Epoch [84/100], Step [31400/6235], Loss: 7.9277\n",
      "Epoch [84/100], Step [31500/6235], Loss: 0.0703\n",
      "Epoch [84/100], Step [31600/6235], Loss: 0.6039\n",
      "Epoch [84/100], Step [31700/6235], Loss: 29.5940\n",
      "Epoch [84/100], Step [31800/6235], Loss: 2.2059\n",
      "Epoch [84/100], Step [31900/6235], Loss: 1325.9202\n",
      "Epoch [84/100], Step [32000/6235], Loss: 86.1337\n",
      "Epoch [84/100], Step [32100/6235], Loss: 4.6556\n",
      "Epoch [84/100], Step [32200/6235], Loss: 43.8010\n",
      "Epoch [84/100], Step [32300/6235], Loss: 0.1997\n",
      "Epoch [84/100], Step [32400/6235], Loss: 0.1529\n",
      "Epoch [84/100], Step [32500/6235], Loss: 21.6369\n",
      "Epoch [84/100], Step [32600/6235], Loss: 1.0777\n",
      "Epoch [84/100], Step [32700/6235], Loss: 55.7563\n",
      "Epoch [84/100], Step [32800/6235], Loss: 8.7563\n",
      "Epoch [84/100], Step [32900/6235], Loss: 14.6496\n",
      "Epoch [84/100], Step [33000/6235], Loss: 0.2364\n",
      "Epoch [84/100], Step [33100/6235], Loss: 0.9369\n",
      "Epoch [84/100], Step [33200/6235], Loss: 1.0977\n",
      "Epoch [84/100], Step [33300/6235], Loss: 0.5961\n",
      "Epoch [84/100], Step [33400/6235], Loss: 106.1876\n",
      "Epoch [84/100], Step [33500/6235], Loss: 1.4456\n",
      "Epoch [84/100], Step [33600/6235], Loss: 1.3495\n",
      "Epoch [84/100], Step [33700/6235], Loss: 2.8814\n",
      "Epoch [84/100], Step [33800/6235], Loss: 2.6438\n",
      "Epoch [84/100], Step [33900/6235], Loss: 23.3580\n",
      "Epoch [84/100], Step [34000/6235], Loss: 0.0735\n",
      "Epoch [84/100], Step [34100/6235], Loss: 0.1037\n",
      "Epoch [84/100], Step [34200/6235], Loss: 1.6329\n",
      "Epoch [84/100], Step [34300/6235], Loss: 7.0807\n",
      "Epoch [84/100], Step [34400/6235], Loss: 0.0552\n",
      "Epoch [84/100], Step [34500/6235], Loss: 54.6019\n",
      "Epoch [84/100], Step [34600/6235], Loss: 0.7302\n",
      "Epoch [84/100], Step [34700/6235], Loss: 20.5341\n",
      "Epoch [84/100], Step [34800/6235], Loss: 13.7803\n",
      "Epoch [84/100], Step [34900/6235], Loss: 46.7980\n",
      "Epoch [84/100], Step [35000/6235], Loss: 0.9138\n",
      "Epoch [84/100], Step [35100/6235], Loss: 0.9489\n",
      "Epoch [84/100], Step [35200/6235], Loss: 0.6090\n",
      "Epoch [84/100], Step [35300/6235], Loss: 1.1171\n",
      "Epoch [84/100], Step [35400/6235], Loss: 0.6281\n",
      "Epoch [84/100], Step [35500/6235], Loss: 2.5700\n",
      "Epoch [84/100], Step [35600/6235], Loss: 2.6051\n",
      "Epoch [84/100], Step [35700/6235], Loss: 5.8167\n",
      "Epoch [84/100], Step [35800/6235], Loss: 0.3543\n",
      "Epoch [84/100], Step [35900/6235], Loss: 0.9312\n",
      "Epoch [84/100], Step [36000/6235], Loss: 0.2461\n",
      "Epoch [84/100], Step [36100/6235], Loss: 0.0310\n",
      "Epoch [84/100], Step [36200/6235], Loss: 19.8643\n",
      "Epoch [84/100], Step [36300/6235], Loss: 0.8604\n",
      "Epoch [84/100], Step [36400/6235], Loss: 1.7935\n",
      "Epoch [84/100], Step [36500/6235], Loss: 9.4270\n",
      "Epoch [84/100], Step [36600/6235], Loss: 0.1367\n",
      "Epoch [84/100], Step [36700/6235], Loss: 0.2122\n",
      "Epoch [84/100], Step [36800/6235], Loss: 16.7562\n",
      "Epoch [84/100], Step [36900/6235], Loss: 5.6363\n",
      "Epoch [84/100], Step [37000/6235], Loss: 0.1970\n",
      "Epoch [84/100], Step [37100/6235], Loss: 0.7828\n",
      "Epoch [84/100], Step [37200/6235], Loss: 0.0782\n",
      "Epoch [84/100], Step [37300/6235], Loss: 0.0791\n",
      "Epoch [84/100], Step [37400/6235], Loss: 0.2016\n",
      "Epoch [84/100], Step [37500/6235], Loss: 3.7910\n",
      "Epoch [84/100], Step [37600/6235], Loss: 11.3459\n",
      "Epoch [84/100], Step [37700/6235], Loss: 0.9873\n",
      "Epoch [84/100], Step [37800/6235], Loss: 6.0127\n",
      "Epoch [84/100], Step [37900/6235], Loss: 8.0233\n",
      "Epoch [84/100], Step [38000/6235], Loss: 0.4185\n",
      "Epoch [84/100], Step [38100/6235], Loss: 2.6487\n",
      "Epoch [84/100], Step [38200/6235], Loss: 2.0400\n",
      "Epoch [84/100], Step [38300/6235], Loss: 0.4041\n",
      "Epoch [84/100], Step [38400/6235], Loss: 0.1551\n",
      "Epoch [84/100], Step [38500/6235], Loss: 2.8853\n",
      "Epoch [84/100], Step [38600/6235], Loss: 0.0849\n",
      "Epoch [84/100], Step [38700/6235], Loss: 0.0891\n",
      "Epoch [84/100], Step [38800/6235], Loss: 0.2748\n",
      "Epoch [84/100], Step [38900/6235], Loss: 5.9268\n",
      "Epoch [84/100], Step [39000/6235], Loss: 6.2231\n",
      "Epoch [84/100], Step [39100/6235], Loss: 15.7606\n",
      "Epoch [84/100], Step [39200/6235], Loss: 0.5563\n",
      "Epoch [84/100], Step [39300/6235], Loss: 58.2026\n",
      "Epoch [84/100], Step [39400/6235], Loss: 24.6718\n",
      "Epoch [84/100], Step [39500/6235], Loss: 59.5526\n",
      "Epoch [84/100], Step [39600/6235], Loss: 14.2765\n",
      "Epoch [84/100], Step [39700/6235], Loss: 234.9342\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [84/100], Step [39800/6235], Loss: 189.0417\n",
      "Epoch [84/100], Step [39900/6235], Loss: 0.1967\n",
      "Epoch [84/100], Step [40000/6235], Loss: 3.1579\n",
      "Epoch [84/100], Step [40100/6235], Loss: 9.5240\n",
      "Epoch [84/100], Step [40200/6235], Loss: 14.1890\n",
      "Epoch [84/100], Step [40300/6235], Loss: 0.2588\n",
      "Epoch [84/100], Step [40400/6235], Loss: 0.2427\n",
      "Epoch [84/100], Step [40500/6235], Loss: 3.1952\n",
      "Epoch [84/100], Step [40600/6235], Loss: 0.2909\n",
      "Epoch [84/100], Step [40700/6235], Loss: 5.4760\n",
      "Epoch [84/100], Step [40800/6235], Loss: 1.2659\n",
      "Epoch [84/100], Step [40900/6235], Loss: 1.3638\n",
      "Epoch [84/100], Step [41000/6235], Loss: 38.0368\n",
      "Epoch [84/100], Step [41100/6235], Loss: 7.2251\n",
      "Epoch [84/100], Step [41200/6235], Loss: 7.1642\n",
      "Epoch [84/100], Step [41300/6235], Loss: 2.6814\n",
      "Epoch [84/100], Step [41400/6235], Loss: 0.0188\n",
      "Epoch [84/100], Step [41500/6235], Loss: 2.7802\n",
      "Epoch [84/100], Step [41600/6235], Loss: 0.3194\n",
      "Epoch [84/100], Step [41700/6235], Loss: 0.3695\n",
      "Epoch [84/100], Step [41800/6235], Loss: 2.3604\n",
      "Epoch [84/100], Step [41900/6235], Loss: 4.7989\n",
      "Epoch [84/100], Step [42000/6235], Loss: 4.7020\n",
      "Epoch [84/100], Step [42100/6235], Loss: 11.3408\n",
      "Epoch [84/100], Step [42200/6235], Loss: 26.0143\n",
      "Epoch [84/100], Step [42300/6235], Loss: 1.2785\n",
      "Epoch [84/100], Step [42400/6235], Loss: 2.3833\n",
      "Epoch [84/100], Step [42500/6235], Loss: 3.1310\n",
      "Epoch [84/100], Step [42600/6235], Loss: 0.5622\n",
      "Epoch [84/100], Step [42700/6235], Loss: 0.2597\n",
      "Epoch [84/100], Step [42800/6235], Loss: 10.2692\n",
      "Epoch [84/100], Step [42900/6235], Loss: 1.7558\n",
      "Epoch [84/100], Step [43000/6235], Loss: 0.1738\n",
      "Epoch [84/100], Step [43100/6235], Loss: 0.0345\n",
      "Epoch [84/100], Step [43200/6235], Loss: 0.7795\n",
      "Epoch [84/100], Step [43300/6235], Loss: 7.2412\n",
      "Epoch [84/100], Step [43400/6235], Loss: 11.1093\n",
      "Epoch [84/100], Step [43500/6235], Loss: 9.7312\n",
      "Epoch [84/100], Step [43600/6235], Loss: 7.0271\n",
      "Epoch [84/100], Step [43700/6235], Loss: 40.4557\n",
      "Epoch [84/100], Step [43800/6235], Loss: 0.4571\n",
      "Epoch [84/100], Step [43900/6235], Loss: 0.9308\n",
      "Epoch [84/100], Step [44000/6235], Loss: 28.6508\n",
      "Epoch [84/100], Step [44100/6235], Loss: 2.6330\n",
      "Epoch [84/100], Step [44200/6235], Loss: 2.0596\n",
      "Epoch [84/100], Step [44300/6235], Loss: 16.9444\n",
      "Epoch [84/100], Step [44400/6235], Loss: 4.1036\n",
      "Epoch [84/100], Step [44500/6235], Loss: 0.4761\n",
      "Epoch [84/100], Step [44600/6235], Loss: 20.2547\n",
      "Epoch [84/100], Step [44700/6235], Loss: 6.1569\n",
      "Epoch [84/100], Step [44800/6235], Loss: 5.5499\n",
      "Epoch [84/100], Step [44900/6235], Loss: 12.2104\n",
      "Epoch [84/100], Step [45000/6235], Loss: 6.4418\n",
      "Epoch [84/100], Step [45100/6235], Loss: 41.1810\n",
      "Epoch [84/100], Step [45200/6235], Loss: 2.0338\n",
      "Epoch [84/100], Step [45300/6235], Loss: 25.4411\n",
      "Epoch [84/100], Step [45400/6235], Loss: 11.9706\n",
      "Epoch [84/100], Step [45500/6235], Loss: 3.0236\n",
      "Epoch [84/100], Step [45600/6235], Loss: 1.0397\n",
      "Epoch [84/100], Step [45700/6235], Loss: 111.2279\n",
      "Epoch [84/100], Step [45800/6235], Loss: 223.3467\n",
      "Epoch [84/100], Step [45900/6235], Loss: 17.8424\n",
      "Epoch [84/100], Step [46000/6235], Loss: 8.8312\n",
      "Epoch [84/100], Step [46100/6235], Loss: 136.9754\n",
      "Epoch [84/100], Step [46200/6235], Loss: 124.5289\n",
      "Epoch [84/100], Step [46300/6235], Loss: 103.2466\n",
      "Epoch [84/100], Step [46400/6235], Loss: 8.1877\n",
      "Epoch [84/100], Step [46500/6235], Loss: 214.7578\n",
      "Epoch [84/100], Step [46600/6235], Loss: 8.1400\n",
      "Epoch [84/100], Step [46700/6235], Loss: 34.5260\n",
      "Epoch [84/100], Step [46800/6235], Loss: 21.6870\n",
      "Epoch [84/100], Step [46900/6235], Loss: 2.2361\n",
      "Epoch [84/100], Step [47000/6235], Loss: 7.5054\n",
      "Epoch [84/100], Step [47100/6235], Loss: 2.9766\n",
      "Epoch [84/100], Step [47200/6235], Loss: 101.1174\n",
      "Epoch [84/100], Step [47300/6235], Loss: 1.0227\n",
      "Epoch [84/100], Step [47400/6235], Loss: 395.7078\n",
      "Epoch [84/100], Step [47500/6235], Loss: 6.2017\n",
      "Epoch [84/100], Step [47600/6235], Loss: 3.1625\n",
      "Epoch [84/100], Step [47700/6235], Loss: 10.8627\n",
      "Epoch [84/100], Step [47800/6235], Loss: 10.0478\n",
      "Epoch [84/100], Step [47900/6235], Loss: 17.7655\n",
      "Epoch [84/100], Step [48000/6235], Loss: 83.9585\n",
      "Epoch [84/100], Step [48100/6235], Loss: 50.3450\n",
      "Epoch [84/100], Step [48200/6235], Loss: 169.9417\n",
      "Epoch [84/100], Step [48300/6235], Loss: 580.1131\n",
      "Epoch [84/100], Step [48400/6235], Loss: 8.8389\n",
      "Epoch [84/100], Step [48500/6235], Loss: 46.5801\n",
      "Epoch [84/100], Step [48600/6235], Loss: 70.3245\n",
      "Epoch [84/100], Step [48700/6235], Loss: 3.9787\n",
      "Epoch [84/100], Step [48800/6235], Loss: 202.6149\n",
      "Epoch [84/100], Step [48900/6235], Loss: 560.2786\n",
      "Epoch [84/100], Step [49000/6235], Loss: 264.1777\n",
      "Epoch [84/100], Step [49100/6235], Loss: 2824.3757\n",
      "Epoch [84/100], Step [49200/6235], Loss: 783.9106\n",
      "Epoch [84/100], Step [49300/6235], Loss: 975.6645\n",
      "Epoch [84/100], Step [49400/6235], Loss: 121.1575\n",
      "Epoch [84/100], Step [49500/6235], Loss: 28.6298\n",
      "Epoch [84/100], Step [49600/6235], Loss: 2570.9072\n",
      "Epoch [84/100], Step [49700/6235], Loss: 2824.2212\n",
      "Epoch [84/100], Step [49800/6235], Loss: 462.5302\n",
      "Epoch [85/100], Step [100/6235], Loss: 5.7171\n",
      "Epoch [85/100], Step [200/6235], Loss: 0.1747\n",
      "Epoch [85/100], Step [300/6235], Loss: 0.0062\n",
      "Epoch [85/100], Step [400/6235], Loss: 0.0017\n",
      "Epoch [85/100], Step [500/6235], Loss: 2.6279\n",
      "Epoch [85/100], Step [600/6235], Loss: 0.0398\n",
      "Epoch [85/100], Step [700/6235], Loss: 0.6235\n",
      "Epoch [85/100], Step [800/6235], Loss: 0.0713\n",
      "Epoch [85/100], Step [900/6235], Loss: 0.0535\n",
      "Epoch [85/100], Step [1000/6235], Loss: 0.0283\n",
      "Epoch [85/100], Step [1100/6235], Loss: 0.0635\n",
      "Epoch [85/100], Step [1200/6235], Loss: 0.1716\n",
      "Epoch [85/100], Step [1300/6235], Loss: 0.0123\n",
      "Epoch [85/100], Step [1400/6235], Loss: 0.0820\n",
      "Epoch [85/100], Step [1500/6235], Loss: 0.0071\n",
      "Epoch [85/100], Step [1600/6235], Loss: 0.2328\n",
      "Epoch [85/100], Step [1700/6235], Loss: 0.0830\n",
      "Epoch [85/100], Step [1800/6235], Loss: 0.2274\n",
      "Epoch [85/100], Step [1900/6235], Loss: 0.2847\n",
      "Epoch [85/100], Step [2000/6235], Loss: 2.2618\n",
      "Epoch [85/100], Step [2100/6235], Loss: 2.9618\n",
      "Epoch [85/100], Step [2200/6235], Loss: 6.6604\n",
      "Epoch [85/100], Step [2300/6235], Loss: 1.0985\n",
      "Epoch [85/100], Step [2400/6235], Loss: 0.8512\n",
      "Epoch [85/100], Step [2500/6235], Loss: 29.6106\n",
      "Epoch [85/100], Step [2600/6235], Loss: 13.0848\n",
      "Epoch [85/100], Step [2700/6235], Loss: 4.9284\n",
      "Epoch [85/100], Step [2800/6235], Loss: 81.1738\n",
      "Epoch [85/100], Step [2900/6235], Loss: 17.1294\n",
      "Epoch [85/100], Step [3000/6235], Loss: 1.3075\n",
      "Epoch [85/100], Step [3100/6235], Loss: 64.0678\n",
      "Epoch [85/100], Step [3200/6235], Loss: 67.4335\n",
      "Epoch [85/100], Step [3300/6235], Loss: 9.6936\n",
      "Epoch [85/100], Step [3400/6235], Loss: 2.0701\n",
      "Epoch [85/100], Step [3500/6235], Loss: 41.5948\n",
      "Epoch [85/100], Step [3600/6235], Loss: 6.3021\n",
      "Epoch [85/100], Step [3700/6235], Loss: 0.0691\n",
      "Epoch [85/100], Step [3800/6235], Loss: 0.0961\n",
      "Epoch [85/100], Step [3900/6235], Loss: 0.2052\n",
      "Epoch [85/100], Step [4000/6235], Loss: 0.0706\n",
      "Epoch [85/100], Step [4100/6235], Loss: 8.1483\n",
      "Epoch [85/100], Step [4200/6235], Loss: 1.1833\n",
      "Epoch [85/100], Step [4300/6235], Loss: 8.0670\n",
      "Epoch [85/100], Step [4400/6235], Loss: 1.9598\n",
      "Epoch [85/100], Step [4500/6235], Loss: 39.5827\n",
      "Epoch [85/100], Step [4600/6235], Loss: 2.7241\n",
      "Epoch [85/100], Step [4700/6235], Loss: 0.0693\n",
      "Epoch [85/100], Step [4800/6235], Loss: 10.7975\n",
      "Epoch [85/100], Step [4900/6235], Loss: 0.2973\n",
      "Epoch [85/100], Step [5000/6235], Loss: 0.0836\n",
      "Epoch [85/100], Step [5100/6235], Loss: 0.6286\n",
      "Epoch [85/100], Step [5200/6235], Loss: 1.4268\n",
      "Epoch [85/100], Step [5300/6235], Loss: 41.3562\n",
      "Epoch [85/100], Step [5400/6235], Loss: 1.9959\n",
      "Epoch [85/100], Step [5500/6235], Loss: 0.1348\n",
      "Epoch [85/100], Step [5600/6235], Loss: 0.3247\n",
      "Epoch [85/100], Step [5700/6235], Loss: 0.0392\n",
      "Epoch [85/100], Step [5800/6235], Loss: 0.3358\n",
      "Epoch [85/100], Step [5900/6235], Loss: 0.0965\n",
      "Epoch [85/100], Step [6000/6235], Loss: 2.7923\n",
      "Epoch [85/100], Step [6100/6235], Loss: 0.1527\n",
      "Epoch [85/100], Step [6200/6235], Loss: 2.9919\n",
      "Epoch [85/100], Step [6300/6235], Loss: 0.4698\n",
      "Epoch [85/100], Step [6400/6235], Loss: 0.0270\n",
      "Epoch [85/100], Step [6500/6235], Loss: 3.0223\n",
      "Epoch [85/100], Step [6600/6235], Loss: 9.2512\n",
      "Epoch [85/100], Step [6700/6235], Loss: 2.9354\n",
      "Epoch [85/100], Step [6800/6235], Loss: 0.3627\n",
      "Epoch [85/100], Step [6900/6235], Loss: 0.1509\n",
      "Epoch [85/100], Step [7000/6235], Loss: 0.0501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Step [7100/6235], Loss: 0.1509\n",
      "Epoch [85/100], Step [7200/6235], Loss: 0.1242\n",
      "Epoch [85/100], Step [7300/6235], Loss: 0.3059\n",
      "Epoch [85/100], Step [7400/6235], Loss: 0.2013\n",
      "Epoch [85/100], Step [7500/6235], Loss: 0.9595\n",
      "Epoch [85/100], Step [7600/6235], Loss: 0.0730\n",
      "Epoch [85/100], Step [7700/6235], Loss: 18.9985\n",
      "Epoch [85/100], Step [7800/6235], Loss: 4.1244\n",
      "Epoch [85/100], Step [7900/6235], Loss: 2.4657\n",
      "Epoch [85/100], Step [8000/6235], Loss: 0.1872\n",
      "Epoch [85/100], Step [8100/6235], Loss: 4.6859\n",
      "Epoch [85/100], Step [8200/6235], Loss: 15.0686\n",
      "Epoch [85/100], Step [8300/6235], Loss: 52.7882\n",
      "Epoch [85/100], Step [8400/6235], Loss: 216.2491\n",
      "Epoch [85/100], Step [8500/6235], Loss: 1.6230\n",
      "Epoch [85/100], Step [8600/6235], Loss: 150.6361\n",
      "Epoch [85/100], Step [8700/6235], Loss: 73.9875\n",
      "Epoch [85/100], Step [8800/6235], Loss: 444.3263\n",
      "Epoch [85/100], Step [8900/6235], Loss: 286.4128\n",
      "Epoch [85/100], Step [9000/6235], Loss: 235.3441\n",
      "Epoch [85/100], Step [9100/6235], Loss: 3089.8132\n",
      "Epoch [85/100], Step [9200/6235], Loss: 6106.7139\n",
      "Epoch [85/100], Step [9300/6235], Loss: 9.2846\n",
      "Epoch [85/100], Step [9400/6235], Loss: 89.2367\n",
      "Epoch [85/100], Step [9500/6235], Loss: 2598.5164\n",
      "Epoch [85/100], Step [9600/6235], Loss: 767.9321\n",
      "Epoch [85/100], Step [9700/6235], Loss: 2.3775\n",
      "Epoch [85/100], Step [9800/6235], Loss: 6186.2012\n",
      "Epoch [85/100], Step [9900/6235], Loss: 45.8441\n",
      "Epoch [85/100], Step [10000/6235], Loss: 226.3131\n",
      "Epoch [85/100], Step [10100/6235], Loss: 3.7342\n",
      "Epoch [85/100], Step [10200/6235], Loss: 533.3420\n",
      "Epoch [85/100], Step [10300/6235], Loss: 25.4533\n",
      "Epoch [85/100], Step [10400/6235], Loss: 7.9903\n",
      "Epoch [85/100], Step [10500/6235], Loss: 18.2741\n",
      "Epoch [85/100], Step [10600/6235], Loss: 16.6904\n",
      "Epoch [85/100], Step [10700/6235], Loss: 11.8045\n",
      "Epoch [85/100], Step [10800/6235], Loss: 103.9472\n",
      "Epoch [85/100], Step [10900/6235], Loss: 44.1851\n",
      "Epoch [85/100], Step [11000/6235], Loss: 299.7058\n",
      "Epoch [85/100], Step [11100/6235], Loss: 47.8069\n",
      "Epoch [85/100], Step [11200/6235], Loss: 11.7280\n",
      "Epoch [85/100], Step [11300/6235], Loss: 111.0588\n",
      "Epoch [85/100], Step [11400/6235], Loss: 9.6986\n",
      "Epoch [85/100], Step [11500/6235], Loss: 10.1638\n",
      "Epoch [85/100], Step [11600/6235], Loss: 7.5875\n",
      "Epoch [85/100], Step [11700/6235], Loss: 45.9175\n",
      "Epoch [85/100], Step [11800/6235], Loss: 413.6803\n",
      "Epoch [85/100], Step [11900/6235], Loss: 6.3762\n",
      "Epoch [85/100], Step [12000/6235], Loss: 692.4706\n",
      "Epoch [85/100], Step [12100/6235], Loss: 253.6956\n",
      "Epoch [85/100], Step [12200/6235], Loss: 12.2962\n",
      "Epoch [85/100], Step [12300/6235], Loss: 9.3293\n",
      "Epoch [85/100], Step [12400/6235], Loss: 182.3913\n",
      "Epoch [85/100], Step [12500/6235], Loss: 31.3540\n",
      "Epoch [85/100], Step [12600/6235], Loss: 33.3743\n",
      "Epoch [85/100], Step [12700/6235], Loss: 7.3970\n",
      "Epoch [85/100], Step [12800/6235], Loss: 6.5435\n",
      "Epoch [85/100], Step [12900/6235], Loss: 36.4980\n",
      "Epoch [85/100], Step [13000/6235], Loss: 0.2323\n",
      "Epoch [85/100], Step [13100/6235], Loss: 64.8498\n",
      "Epoch [85/100], Step [13200/6235], Loss: 8.7141\n",
      "Epoch [85/100], Step [13300/6235], Loss: 35.4144\n",
      "Epoch [85/100], Step [13400/6235], Loss: 239.1849\n",
      "Epoch [85/100], Step [13500/6235], Loss: 9.0488\n",
      "Epoch [85/100], Step [13600/6235], Loss: 23.5800\n",
      "Epoch [85/100], Step [13700/6235], Loss: 34.0979\n",
      "Epoch [85/100], Step [13800/6235], Loss: 126.2010\n",
      "Epoch [85/100], Step [13900/6235], Loss: 55.3191\n",
      "Epoch [85/100], Step [14000/6235], Loss: 16.0069\n",
      "Epoch [85/100], Step [14100/6235], Loss: 26.7774\n",
      "Epoch [85/100], Step [14200/6235], Loss: 114.7825\n",
      "Epoch [85/100], Step [14300/6235], Loss: 50.2812\n",
      "Epoch [85/100], Step [14400/6235], Loss: 38.8361\n",
      "Epoch [85/100], Step [14500/6235], Loss: 35.4318\n",
      "Epoch [85/100], Step [14600/6235], Loss: 0.8844\n",
      "Epoch [85/100], Step [14700/6235], Loss: 34.7827\n",
      "Epoch [85/100], Step [14800/6235], Loss: 32.8514\n",
      "Epoch [85/100], Step [14900/6235], Loss: 0.6910\n",
      "Epoch [85/100], Step [15000/6235], Loss: 1.4612\n",
      "Epoch [85/100], Step [15100/6235], Loss: 0.5506\n",
      "Epoch [85/100], Step [15200/6235], Loss: 6.9657\n",
      "Epoch [85/100], Step [15300/6235], Loss: 42.2755\n",
      "Epoch [85/100], Step [15400/6235], Loss: 69.5190\n",
      "Epoch [85/100], Step [15500/6235], Loss: 13.5060\n",
      "Epoch [85/100], Step [15600/6235], Loss: 160.9901\n",
      "Epoch [85/100], Step [15700/6235], Loss: 73.8654\n",
      "Epoch [85/100], Step [15800/6235], Loss: 8.5009\n",
      "Epoch [85/100], Step [15900/6235], Loss: 0.2757\n",
      "Epoch [85/100], Step [16000/6235], Loss: 180.3197\n",
      "Epoch [85/100], Step [16100/6235], Loss: 3.4778\n",
      "Epoch [85/100], Step [16200/6235], Loss: 0.8793\n",
      "Epoch [85/100], Step [16300/6235], Loss: 9.0786\n",
      "Epoch [85/100], Step [16400/6235], Loss: 25.0335\n",
      "Epoch [85/100], Step [16500/6235], Loss: 462.1095\n",
      "Epoch [85/100], Step [16600/6235], Loss: 14.3180\n",
      "Epoch [85/100], Step [16700/6235], Loss: 0.4342\n",
      "Epoch [85/100], Step [16800/6235], Loss: 12.5158\n",
      "Epoch [85/100], Step [16900/6235], Loss: 0.2846\n",
      "Epoch [85/100], Step [17000/6235], Loss: 0.2876\n",
      "Epoch [85/100], Step [17100/6235], Loss: 0.0999\n",
      "Epoch [85/100], Step [17200/6235], Loss: 272.9477\n",
      "Epoch [85/100], Step [17300/6235], Loss: 13.5720\n",
      "Epoch [85/100], Step [17400/6235], Loss: 35.9080\n",
      "Epoch [85/100], Step [17500/6235], Loss: 0.7744\n",
      "Epoch [85/100], Step [17600/6235], Loss: 2.6923\n",
      "Epoch [85/100], Step [17700/6235], Loss: 56.4972\n",
      "Epoch [85/100], Step [17800/6235], Loss: 26.5226\n",
      "Epoch [85/100], Step [17900/6235], Loss: 24.0662\n",
      "Epoch [85/100], Step [18000/6235], Loss: 1.7868\n",
      "Epoch [85/100], Step [18100/6235], Loss: 16.1462\n",
      "Epoch [85/100], Step [18200/6235], Loss: 0.5908\n",
      "Epoch [85/100], Step [18300/6235], Loss: 5.1996\n",
      "Epoch [85/100], Step [18400/6235], Loss: 5.3145\n",
      "Epoch [85/100], Step [18500/6235], Loss: 20.5269\n",
      "Epoch [85/100], Step [18600/6235], Loss: 1.1504\n",
      "Epoch [85/100], Step [18700/6235], Loss: 0.4242\n",
      "Epoch [85/100], Step [18800/6235], Loss: 119.1865\n",
      "Epoch [85/100], Step [18900/6235], Loss: 36.9896\n",
      "Epoch [85/100], Step [19000/6235], Loss: 7.4020\n",
      "Epoch [85/100], Step [19100/6235], Loss: 44.0331\n",
      "Epoch [85/100], Step [19200/6235], Loss: 0.7825\n",
      "Epoch [85/100], Step [19300/6235], Loss: 6.6486\n",
      "Epoch [85/100], Step [19400/6235], Loss: 140.5789\n",
      "Epoch [85/100], Step [19500/6235], Loss: 108.5017\n",
      "Epoch [85/100], Step [19600/6235], Loss: 96.9975\n",
      "Epoch [85/100], Step [19700/6235], Loss: 4.2029\n",
      "Epoch [85/100], Step [19800/6235], Loss: 2.7672\n",
      "Epoch [85/100], Step [19900/6235], Loss: 0.1268\n",
      "Epoch [85/100], Step [20000/6235], Loss: 66.7059\n",
      "Epoch [85/100], Step [20100/6235], Loss: 1.9513\n",
      "Epoch [85/100], Step [20200/6235], Loss: 9.2791\n",
      "Epoch [85/100], Step [20300/6235], Loss: 2.1726\n",
      "Epoch [85/100], Step [20400/6235], Loss: 13.1258\n",
      "Epoch [85/100], Step [20500/6235], Loss: 50.9878\n",
      "Epoch [85/100], Step [20600/6235], Loss: 141.9241\n",
      "Epoch [85/100], Step [20700/6235], Loss: 19.5406\n",
      "Epoch [85/100], Step [20800/6235], Loss: 7.2811\n",
      "Epoch [85/100], Step [20900/6235], Loss: 5.0853\n",
      "Epoch [85/100], Step [21000/6235], Loss: 24.4202\n",
      "Epoch [85/100], Step [21100/6235], Loss: 6.5494\n",
      "Epoch [85/100], Step [21200/6235], Loss: 0.3624\n",
      "Epoch [85/100], Step [21300/6235], Loss: 0.1657\n",
      "Epoch [85/100], Step [21400/6235], Loss: 5.6533\n",
      "Epoch [85/100], Step [21500/6235], Loss: 5.2809\n",
      "Epoch [85/100], Step [21600/6235], Loss: 6.6623\n",
      "Epoch [85/100], Step [21700/6235], Loss: 0.1432\n",
      "Epoch [85/100], Step [21800/6235], Loss: 4.6529\n",
      "Epoch [85/100], Step [21900/6235], Loss: 1.4496\n",
      "Epoch [85/100], Step [22000/6235], Loss: 7.3387\n",
      "Epoch [85/100], Step [22100/6235], Loss: 0.7802\n",
      "Epoch [85/100], Step [22200/6235], Loss: 5.2743\n",
      "Epoch [85/100], Step [22300/6235], Loss: 1.1411\n",
      "Epoch [85/100], Step [22400/6235], Loss: 14.5917\n",
      "Epoch [85/100], Step [22500/6235], Loss: 141.4193\n",
      "Epoch [85/100], Step [22600/6235], Loss: 31.1902\n",
      "Epoch [85/100], Step [22700/6235], Loss: 2.0827\n",
      "Epoch [85/100], Step [22800/6235], Loss: 6.4938\n",
      "Epoch [85/100], Step [22900/6235], Loss: 2.6825\n",
      "Epoch [85/100], Step [23000/6235], Loss: 15.9511\n",
      "Epoch [85/100], Step [23100/6235], Loss: 7.4425\n",
      "Epoch [85/100], Step [23200/6235], Loss: 8.3837\n",
      "Epoch [85/100], Step [23300/6235], Loss: 19.7013\n",
      "Epoch [85/100], Step [23400/6235], Loss: 1.7459\n",
      "Epoch [85/100], Step [23500/6235], Loss: 0.1065\n",
      "Epoch [85/100], Step [23600/6235], Loss: 125.5632\n",
      "Epoch [85/100], Step [23700/6235], Loss: 2.2167\n",
      "Epoch [85/100], Step [23800/6235], Loss: 1.0022\n",
      "Epoch [85/100], Step [23900/6235], Loss: 5.1731\n",
      "Epoch [85/100], Step [24000/6235], Loss: 0.3864\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Step [24100/6235], Loss: 0.5425\n",
      "Epoch [85/100], Step [24200/6235], Loss: 41.8175\n",
      "Epoch [85/100], Step [24300/6235], Loss: 0.9048\n",
      "Epoch [85/100], Step [24400/6235], Loss: 2.0504\n",
      "Epoch [85/100], Step [24500/6235], Loss: 0.5705\n",
      "Epoch [85/100], Step [24600/6235], Loss: 0.1966\n",
      "Epoch [85/100], Step [24700/6235], Loss: 1.0488\n",
      "Epoch [85/100], Step [24800/6235], Loss: 0.2294\n",
      "Epoch [85/100], Step [24900/6235], Loss: 12.4770\n",
      "Epoch [85/100], Step [25000/6235], Loss: 13.3061\n",
      "Epoch [85/100], Step [25100/6235], Loss: 6.3241\n",
      "Epoch [85/100], Step [25200/6235], Loss: 0.3698\n",
      "Epoch [85/100], Step [25300/6235], Loss: 0.7131\n",
      "Epoch [85/100], Step [25400/6235], Loss: 9.7300\n",
      "Epoch [85/100], Step [25500/6235], Loss: 8.1361\n",
      "Epoch [85/100], Step [25600/6235], Loss: 5.7450\n",
      "Epoch [85/100], Step [25700/6235], Loss: 0.2655\n",
      "Epoch [85/100], Step [25800/6235], Loss: 0.0782\n",
      "Epoch [85/100], Step [25900/6235], Loss: 7.1058\n",
      "Epoch [85/100], Step [26000/6235], Loss: 1.8612\n",
      "Epoch [85/100], Step [26100/6235], Loss: 0.0322\n",
      "Epoch [85/100], Step [26200/6235], Loss: 1.2594\n",
      "Epoch [85/100], Step [26300/6235], Loss: 3.3971\n",
      "Epoch [85/100], Step [26400/6235], Loss: 0.1601\n",
      "Epoch [85/100], Step [26500/6235], Loss: 0.0133\n",
      "Epoch [85/100], Step [26600/6235], Loss: 0.9534\n",
      "Epoch [85/100], Step [26700/6235], Loss: 0.2714\n",
      "Epoch [85/100], Step [26800/6235], Loss: 0.1315\n",
      "Epoch [85/100], Step [26900/6235], Loss: 0.0121\n",
      "Epoch [85/100], Step [27000/6235], Loss: 15.8014\n",
      "Epoch [85/100], Step [27100/6235], Loss: 0.0486\n",
      "Epoch [85/100], Step [27200/6235], Loss: 0.0161\n",
      "Epoch [85/100], Step [27300/6235], Loss: 0.1535\n",
      "Epoch [85/100], Step [27400/6235], Loss: 0.7129\n",
      "Epoch [85/100], Step [27500/6235], Loss: 7.5647\n",
      "Epoch [85/100], Step [27600/6235], Loss: 0.9399\n",
      "Epoch [85/100], Step [27700/6235], Loss: 1.3803\n",
      "Epoch [85/100], Step [27800/6235], Loss: 7.1261\n",
      "Epoch [85/100], Step [27900/6235], Loss: 0.8606\n",
      "Epoch [85/100], Step [28000/6235], Loss: 75.9356\n",
      "Epoch [85/100], Step [28100/6235], Loss: 3.2645\n",
      "Epoch [85/100], Step [28200/6235], Loss: 31.0703\n",
      "Epoch [85/100], Step [28300/6235], Loss: 2.7345\n",
      "Epoch [85/100], Step [28400/6235], Loss: 28.3585\n",
      "Epoch [85/100], Step [28500/6235], Loss: 4.4539\n",
      "Epoch [85/100], Step [28600/6235], Loss: 0.3041\n",
      "Epoch [85/100], Step [28700/6235], Loss: 4.9594\n",
      "Epoch [85/100], Step [28800/6235], Loss: 0.6502\n",
      "Epoch [85/100], Step [28900/6235], Loss: 64.2571\n",
      "Epoch [85/100], Step [29000/6235], Loss: 13.2537\n",
      "Epoch [85/100], Step [29100/6235], Loss: 0.3833\n",
      "Epoch [85/100], Step [29200/6235], Loss: 2.8481\n",
      "Epoch [85/100], Step [29300/6235], Loss: 0.0188\n",
      "Epoch [85/100], Step [29400/6235], Loss: 0.8702\n",
      "Epoch [85/100], Step [29500/6235], Loss: 3.4658\n",
      "Epoch [85/100], Step [29600/6235], Loss: 0.0189\n",
      "Epoch [85/100], Step [29700/6235], Loss: 2.1246\n",
      "Epoch [85/100], Step [29800/6235], Loss: 1.2587\n",
      "Epoch [85/100], Step [29900/6235], Loss: 1.5140\n",
      "Epoch [85/100], Step [30000/6235], Loss: 7.2409\n",
      "Epoch [85/100], Step [30100/6235], Loss: 10.6323\n",
      "Epoch [85/100], Step [30200/6235], Loss: 1.5977\n",
      "Epoch [85/100], Step [30300/6235], Loss: 0.0651\n",
      "Epoch [85/100], Step [30400/6235], Loss: 1.6734\n",
      "Epoch [85/100], Step [30500/6235], Loss: 2.3533\n",
      "Epoch [85/100], Step [30600/6235], Loss: 1.8137\n",
      "Epoch [85/100], Step [30700/6235], Loss: 1.4499\n",
      "Epoch [85/100], Step [30800/6235], Loss: 0.5654\n",
      "Epoch [85/100], Step [30900/6235], Loss: 2.8447\n",
      "Epoch [85/100], Step [31000/6235], Loss: 0.3192\n",
      "Epoch [85/100], Step [31100/6235], Loss: 0.0859\n",
      "Epoch [85/100], Step [31200/6235], Loss: 5.0643\n",
      "Epoch [85/100], Step [31300/6235], Loss: 1.1827\n",
      "Epoch [85/100], Step [31400/6235], Loss: 5.7495\n",
      "Epoch [85/100], Step [31500/6235], Loss: 0.6742\n",
      "Epoch [85/100], Step [31600/6235], Loss: 4.2876\n",
      "Epoch [85/100], Step [31700/6235], Loss: 26.6642\n",
      "Epoch [85/100], Step [31800/6235], Loss: 0.1507\n",
      "Epoch [85/100], Step [31900/6235], Loss: 352.9925\n",
      "Epoch [85/100], Step [32000/6235], Loss: 10.0201\n",
      "Epoch [85/100], Step [32100/6235], Loss: 8.3312\n",
      "Epoch [85/100], Step [32200/6235], Loss: 97.4239\n",
      "Epoch [85/100], Step [32300/6235], Loss: 1.5939\n",
      "Epoch [85/100], Step [32400/6235], Loss: 1.4038\n",
      "Epoch [85/100], Step [32500/6235], Loss: 18.2872\n",
      "Epoch [85/100], Step [32600/6235], Loss: 0.5986\n",
      "Epoch [85/100], Step [32700/6235], Loss: 93.1238\n",
      "Epoch [85/100], Step [32800/6235], Loss: 0.6714\n",
      "Epoch [85/100], Step [32900/6235], Loss: 0.5695\n",
      "Epoch [85/100], Step [33000/6235], Loss: 0.3005\n",
      "Epoch [85/100], Step [33100/6235], Loss: 0.8840\n",
      "Epoch [85/100], Step [33200/6235], Loss: 1.2434\n",
      "Epoch [85/100], Step [33300/6235], Loss: 0.3288\n",
      "Epoch [85/100], Step [33400/6235], Loss: 156.9850\n",
      "Epoch [85/100], Step [33500/6235], Loss: 0.6754\n",
      "Epoch [85/100], Step [33600/6235], Loss: 3.1262\n",
      "Epoch [85/100], Step [33700/6235], Loss: 1.6535\n",
      "Epoch [85/100], Step [33800/6235], Loss: 0.6200\n",
      "Epoch [85/100], Step [33900/6235], Loss: 25.5062\n",
      "Epoch [85/100], Step [34000/6235], Loss: 0.0075\n",
      "Epoch [85/100], Step [34100/6235], Loss: 0.2778\n",
      "Epoch [85/100], Step [34200/6235], Loss: 2.2887\n",
      "Epoch [85/100], Step [34300/6235], Loss: 6.8836\n",
      "Epoch [85/100], Step [34400/6235], Loss: 0.1738\n",
      "Epoch [85/100], Step [34500/6235], Loss: 43.5894\n",
      "Epoch [85/100], Step [34600/6235], Loss: 0.8148\n",
      "Epoch [85/100], Step [34700/6235], Loss: 10.5008\n",
      "Epoch [85/100], Step [34800/6235], Loss: 14.3250\n",
      "Epoch [85/100], Step [34900/6235], Loss: 68.7364\n",
      "Epoch [85/100], Step [35000/6235], Loss: 0.4106\n",
      "Epoch [85/100], Step [35100/6235], Loss: 0.7665\n",
      "Epoch [85/100], Step [35200/6235], Loss: 0.3314\n",
      "Epoch [85/100], Step [35300/6235], Loss: 2.9542\n",
      "Epoch [85/100], Step [35400/6235], Loss: 0.4329\n",
      "Epoch [85/100], Step [35500/6235], Loss: 1.6377\n",
      "Epoch [85/100], Step [35600/6235], Loss: 0.9616\n",
      "Epoch [85/100], Step [35700/6235], Loss: 6.5303\n",
      "Epoch [85/100], Step [35800/6235], Loss: 0.4134\n",
      "Epoch [85/100], Step [35900/6235], Loss: 1.2982\n",
      "Epoch [85/100], Step [36000/6235], Loss: 0.1942\n",
      "Epoch [85/100], Step [36100/6235], Loss: 0.0486\n",
      "Epoch [85/100], Step [36200/6235], Loss: 8.4411\n",
      "Epoch [85/100], Step [36300/6235], Loss: 0.2678\n",
      "Epoch [85/100], Step [36400/6235], Loss: 2.5989\n",
      "Epoch [85/100], Step [36500/6235], Loss: 8.7766\n",
      "Epoch [85/100], Step [36600/6235], Loss: 0.1275\n",
      "Epoch [85/100], Step [36700/6235], Loss: 0.3831\n",
      "Epoch [85/100], Step [36800/6235], Loss: 13.0129\n",
      "Epoch [85/100], Step [36900/6235], Loss: 8.7431\n",
      "Epoch [85/100], Step [37000/6235], Loss: 0.4874\n",
      "Epoch [85/100], Step [37100/6235], Loss: 1.1072\n",
      "Epoch [85/100], Step [37200/6235], Loss: 0.0770\n",
      "Epoch [85/100], Step [37300/6235], Loss: 0.0507\n",
      "Epoch [85/100], Step [37400/6235], Loss: 0.2025\n",
      "Epoch [85/100], Step [37500/6235], Loss: 4.1551\n",
      "Epoch [85/100], Step [37600/6235], Loss: 11.5244\n",
      "Epoch [85/100], Step [37700/6235], Loss: 1.0927\n",
      "Epoch [85/100], Step [37800/6235], Loss: 6.9522\n",
      "Epoch [85/100], Step [37900/6235], Loss: 6.3679\n",
      "Epoch [85/100], Step [38000/6235], Loss: 0.4655\n",
      "Epoch [85/100], Step [38100/6235], Loss: 2.5586\n",
      "Epoch [85/100], Step [38200/6235], Loss: 2.2338\n",
      "Epoch [85/100], Step [38300/6235], Loss: 0.7671\n",
      "Epoch [85/100], Step [38400/6235], Loss: 0.1432\n",
      "Epoch [85/100], Step [38500/6235], Loss: 3.2927\n",
      "Epoch [85/100], Step [38600/6235], Loss: 0.0772\n",
      "Epoch [85/100], Step [38700/6235], Loss: 0.0782\n",
      "Epoch [85/100], Step [38800/6235], Loss: 0.3139\n",
      "Epoch [85/100], Step [38900/6235], Loss: 8.3705\n",
      "Epoch [85/100], Step [39000/6235], Loss: 8.3052\n",
      "Epoch [85/100], Step [39100/6235], Loss: 11.2973\n",
      "Epoch [85/100], Step [39200/6235], Loss: 8.2614\n",
      "Epoch [85/100], Step [39300/6235], Loss: 1.0023\n",
      "Epoch [85/100], Step [39400/6235], Loss: 47.4332\n",
      "Epoch [85/100], Step [39500/6235], Loss: 305.8951\n",
      "Epoch [85/100], Step [39600/6235], Loss: 7.4306\n",
      "Epoch [85/100], Step [39700/6235], Loss: 70.6135\n",
      "Epoch [85/100], Step [39800/6235], Loss: 132.9099\n",
      "Epoch [85/100], Step [39900/6235], Loss: 26.5466\n",
      "Epoch [85/100], Step [40000/6235], Loss: 1.5123\n",
      "Epoch [85/100], Step [40100/6235], Loss: 1.0383\n",
      "Epoch [85/100], Step [40200/6235], Loss: 59.1680\n",
      "Epoch [85/100], Step [40300/6235], Loss: 1.1217\n",
      "Epoch [85/100], Step [40400/6235], Loss: 0.4506\n",
      "Epoch [85/100], Step [40500/6235], Loss: 5.3625\n",
      "Epoch [85/100], Step [40600/6235], Loss: 0.2814\n",
      "Epoch [85/100], Step [40700/6235], Loss: 2.8446\n",
      "Epoch [85/100], Step [40800/6235], Loss: 2.7898\n",
      "Epoch [85/100], Step [40900/6235], Loss: 0.7028\n",
      "Epoch [85/100], Step [41000/6235], Loss: 29.9501\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [85/100], Step [41100/6235], Loss: 28.1517\n",
      "Epoch [85/100], Step [41200/6235], Loss: 42.9746\n",
      "Epoch [85/100], Step [41300/6235], Loss: 4.7980\n",
      "Epoch [85/100], Step [41400/6235], Loss: 1.9302\n",
      "Epoch [85/100], Step [41500/6235], Loss: 34.2967\n",
      "Epoch [85/100], Step [41600/6235], Loss: 3.0239\n",
      "Epoch [85/100], Step [41700/6235], Loss: 0.0942\n",
      "Epoch [85/100], Step [41800/6235], Loss: 0.4126\n",
      "Epoch [85/100], Step [41900/6235], Loss: 3.5620\n",
      "Epoch [85/100], Step [42000/6235], Loss: 3.7977\n",
      "Epoch [85/100], Step [42100/6235], Loss: 12.2961\n",
      "Epoch [85/100], Step [42200/6235], Loss: 65.7670\n",
      "Epoch [85/100], Step [42300/6235], Loss: 0.3264\n",
      "Epoch [85/100], Step [42400/6235], Loss: 2.9706\n",
      "Epoch [85/100], Step [42500/6235], Loss: 1.6745\n",
      "Epoch [85/100], Step [42600/6235], Loss: 0.4826\n",
      "Epoch [85/100], Step [42700/6235], Loss: 0.1838\n",
      "Epoch [85/100], Step [42800/6235], Loss: 13.4350\n",
      "Epoch [85/100], Step [42900/6235], Loss: 0.1007\n",
      "Epoch [85/100], Step [43000/6235], Loss: 0.5603\n",
      "Epoch [85/100], Step [43100/6235], Loss: 0.0769\n",
      "Epoch [85/100], Step [43200/6235], Loss: 0.0242\n",
      "Epoch [85/100], Step [43300/6235], Loss: 3.7803\n",
      "Epoch [85/100], Step [43400/6235], Loss: 3.7736\n",
      "Epoch [85/100], Step [43500/6235], Loss: 12.6205\n",
      "Epoch [85/100], Step [43600/6235], Loss: 1.1438\n",
      "Epoch [85/100], Step [43700/6235], Loss: 37.3611\n",
      "Epoch [85/100], Step [43800/6235], Loss: 0.2336\n",
      "Epoch [85/100], Step [43900/6235], Loss: 5.3758\n",
      "Epoch [85/100], Step [44000/6235], Loss: 67.6735\n",
      "Epoch [85/100], Step [44100/6235], Loss: 1.1984\n",
      "Epoch [85/100], Step [44200/6235], Loss: 3.4051\n",
      "Epoch [85/100], Step [44300/6235], Loss: 175.7189\n",
      "Epoch [85/100], Step [44400/6235], Loss: 0.5041\n",
      "Epoch [85/100], Step [44500/6235], Loss: 1.3752\n",
      "Epoch [85/100], Step [44600/6235], Loss: 0.8417\n",
      "Epoch [85/100], Step [44700/6235], Loss: 11.0791\n",
      "Epoch [85/100], Step [44800/6235], Loss: 0.2049\n",
      "Epoch [85/100], Step [44900/6235], Loss: 5.4498\n",
      "Epoch [85/100], Step [45000/6235], Loss: 6.2327\n",
      "Epoch [85/100], Step [45100/6235], Loss: 66.3735\n",
      "Epoch [85/100], Step [45200/6235], Loss: 3.7878\n",
      "Epoch [85/100], Step [45300/6235], Loss: 20.9016\n",
      "Epoch [85/100], Step [45400/6235], Loss: 8.1261\n",
      "Epoch [85/100], Step [45500/6235], Loss: 1.9429\n",
      "Epoch [85/100], Step [45600/6235], Loss: 1.3083\n",
      "Epoch [85/100], Step [45700/6235], Loss: 98.8830\n",
      "Epoch [85/100], Step [45800/6235], Loss: 235.7735\n",
      "Epoch [85/100], Step [45900/6235], Loss: 3.3991\n",
      "Epoch [85/100], Step [46000/6235], Loss: 1.1192\n",
      "Epoch [85/100], Step [46100/6235], Loss: 40.3100\n",
      "Epoch [85/100], Step [46200/6235], Loss: 29.4915\n",
      "Epoch [85/100], Step [46300/6235], Loss: 22.2277\n",
      "Epoch [85/100], Step [46400/6235], Loss: 17.9051\n",
      "Epoch [85/100], Step [46500/6235], Loss: 236.1915\n",
      "Epoch [85/100], Step [46600/6235], Loss: 7.5520\n",
      "Epoch [85/100], Step [46700/6235], Loss: 26.2472\n",
      "Epoch [85/100], Step [46800/6235], Loss: 36.7302\n",
      "Epoch [85/100], Step [46900/6235], Loss: 16.1883\n",
      "Epoch [85/100], Step [47000/6235], Loss: 0.4936\n",
      "Epoch [85/100], Step [47100/6235], Loss: 149.0987\n",
      "Epoch [85/100], Step [47200/6235], Loss: 8.5841\n",
      "Epoch [85/100], Step [47300/6235], Loss: 3.0567\n",
      "Epoch [85/100], Step [47400/6235], Loss: 280.6041\n",
      "Epoch [85/100], Step [47500/6235], Loss: 34.7263\n",
      "Epoch [85/100], Step [47600/6235], Loss: 15.3156\n",
      "Epoch [85/100], Step [47700/6235], Loss: 22.0140\n",
      "Epoch [85/100], Step [47800/6235], Loss: 63.8524\n",
      "Epoch [85/100], Step [47900/6235], Loss: 0.7826\n",
      "Epoch [85/100], Step [48000/6235], Loss: 76.7910\n",
      "Epoch [85/100], Step [48100/6235], Loss: 66.0394\n",
      "Epoch [85/100], Step [48200/6235], Loss: 252.7141\n",
      "Epoch [85/100], Step [48300/6235], Loss: 820.9814\n",
      "Epoch [85/100], Step [48400/6235], Loss: 3.5091\n",
      "Epoch [85/100], Step [48500/6235], Loss: 12.8823\n",
      "Epoch [85/100], Step [48600/6235], Loss: 16.8103\n",
      "Epoch [85/100], Step [48700/6235], Loss: 45.1099\n",
      "Epoch [85/100], Step [48800/6235], Loss: 182.7766\n",
      "Epoch [85/100], Step [48900/6235], Loss: 949.8120\n",
      "Epoch [85/100], Step [49000/6235], Loss: 149.8190\n",
      "Epoch [85/100], Step [49100/6235], Loss: 3158.5957\n",
      "Epoch [85/100], Step [49200/6235], Loss: 1222.6581\n",
      "Epoch [85/100], Step [49300/6235], Loss: 1057.5087\n",
      "Epoch [85/100], Step [49400/6235], Loss: 122.2188\n",
      "Epoch [85/100], Step [49500/6235], Loss: 27.9975\n",
      "Epoch [85/100], Step [49600/6235], Loss: 151.3011\n",
      "Epoch [85/100], Step [49700/6235], Loss: 4588.0327\n",
      "Epoch [85/100], Step [49800/6235], Loss: 4702.9766\n",
      "Epoch [86/100], Step [100/6235], Loss: 35.8666\n",
      "Epoch [86/100], Step [200/6235], Loss: 0.6102\n",
      "Epoch [86/100], Step [300/6235], Loss: 0.1826\n",
      "Epoch [86/100], Step [400/6235], Loss: 0.0328\n",
      "Epoch [86/100], Step [500/6235], Loss: 41.8701\n",
      "Epoch [86/100], Step [600/6235], Loss: 0.1235\n",
      "Epoch [86/100], Step [700/6235], Loss: 1.0672\n",
      "Epoch [86/100], Step [800/6235], Loss: 0.1158\n",
      "Epoch [86/100], Step [900/6235], Loss: 0.5176\n",
      "Epoch [86/100], Step [1000/6235], Loss: 0.0569\n",
      "Epoch [86/100], Step [1100/6235], Loss: 0.3002\n",
      "Epoch [86/100], Step [1200/6235], Loss: 0.1754\n",
      "Epoch [86/100], Step [1300/6235], Loss: 0.0210\n",
      "Epoch [86/100], Step [1400/6235], Loss: 0.2408\n",
      "Epoch [86/100], Step [1500/6235], Loss: 0.0082\n",
      "Epoch [86/100], Step [1600/6235], Loss: 0.2403\n",
      "Epoch [86/100], Step [1700/6235], Loss: 0.0994\n",
      "Epoch [86/100], Step [1800/6235], Loss: 0.2387\n",
      "Epoch [86/100], Step [1900/6235], Loss: 0.2952\n",
      "Epoch [86/100], Step [2000/6235], Loss: 2.3137\n",
      "Epoch [86/100], Step [2100/6235], Loss: 2.5622\n",
      "Epoch [86/100], Step [2200/6235], Loss: 6.1552\n",
      "Epoch [86/100], Step [2300/6235], Loss: 0.9401\n",
      "Epoch [86/100], Step [2400/6235], Loss: 0.5139\n",
      "Epoch [86/100], Step [2500/6235], Loss: 20.7892\n",
      "Epoch [86/100], Step [2600/6235], Loss: 13.8011\n",
      "Epoch [86/100], Step [2700/6235], Loss: 12.0479\n",
      "Epoch [86/100], Step [2800/6235], Loss: 75.4579\n",
      "Epoch [86/100], Step [2900/6235], Loss: 18.8534\n",
      "Epoch [86/100], Step [3000/6235], Loss: 1.3800\n",
      "Epoch [86/100], Step [3100/6235], Loss: 63.3033\n",
      "Epoch [86/100], Step [3200/6235], Loss: 41.9827\n",
      "Epoch [86/100], Step [3300/6235], Loss: 10.1324\n",
      "Epoch [86/100], Step [3400/6235], Loss: 3.9659\n",
      "Epoch [86/100], Step [3500/6235], Loss: 53.5183\n",
      "Epoch [86/100], Step [3600/6235], Loss: 1.5577\n",
      "Epoch [86/100], Step [3700/6235], Loss: 0.0971\n",
      "Epoch [86/100], Step [3800/6235], Loss: 0.0437\n",
      "Epoch [86/100], Step [3900/6235], Loss: 0.0695\n",
      "Epoch [86/100], Step [4000/6235], Loss: 0.1550\n",
      "Epoch [86/100], Step [4100/6235], Loss: 9.8372\n",
      "Epoch [86/100], Step [4200/6235], Loss: 3.4987\n",
      "Epoch [86/100], Step [4300/6235], Loss: 5.6073\n",
      "Epoch [86/100], Step [4400/6235], Loss: 0.5942\n",
      "Epoch [86/100], Step [4500/6235], Loss: 39.0057\n",
      "Epoch [86/100], Step [4600/6235], Loss: 1.2723\n",
      "Epoch [86/100], Step [4700/6235], Loss: 0.2436\n",
      "Epoch [86/100], Step [4800/6235], Loss: 8.1195\n",
      "Epoch [86/100], Step [4900/6235], Loss: 0.8272\n",
      "Epoch [86/100], Step [5000/6235], Loss: 0.0391\n",
      "Epoch [86/100], Step [5100/6235], Loss: 0.8601\n",
      "Epoch [86/100], Step [5200/6235], Loss: 2.6385\n",
      "Epoch [86/100], Step [5300/6235], Loss: 30.6961\n",
      "Epoch [86/100], Step [5400/6235], Loss: 0.0905\n",
      "Epoch [86/100], Step [5500/6235], Loss: 0.0231\n",
      "Epoch [86/100], Step [5600/6235], Loss: 0.3606\n",
      "Epoch [86/100], Step [5700/6235], Loss: 0.1629\n",
      "Epoch [86/100], Step [5800/6235], Loss: 0.2869\n",
      "Epoch [86/100], Step [5900/6235], Loss: 0.2581\n",
      "Epoch [86/100], Step [6000/6235], Loss: 0.2617\n",
      "Epoch [86/100], Step [6100/6235], Loss: 0.1030\n",
      "Epoch [86/100], Step [6200/6235], Loss: 5.8131\n",
      "Epoch [86/100], Step [6300/6235], Loss: 0.0912\n",
      "Epoch [86/100], Step [6400/6235], Loss: 0.0241\n",
      "Epoch [86/100], Step [6500/6235], Loss: 2.7251\n",
      "Epoch [86/100], Step [6600/6235], Loss: 5.9288\n",
      "Epoch [86/100], Step [6700/6235], Loss: 1.1253\n",
      "Epoch [86/100], Step [6800/6235], Loss: 0.4346\n",
      "Epoch [86/100], Step [6900/6235], Loss: 0.6616\n",
      "Epoch [86/100], Step [7000/6235], Loss: 0.0873\n",
      "Epoch [86/100], Step [7100/6235], Loss: 0.4419\n",
      "Epoch [86/100], Step [7200/6235], Loss: 0.2519\n",
      "Epoch [86/100], Step [7300/6235], Loss: 0.5979\n",
      "Epoch [86/100], Step [7400/6235], Loss: 0.0792\n",
      "Epoch [86/100], Step [7500/6235], Loss: 0.7759\n",
      "Epoch [86/100], Step [7600/6235], Loss: 4.7688\n",
      "Epoch [86/100], Step [7700/6235], Loss: 10.1941\n",
      "Epoch [86/100], Step [7800/6235], Loss: 1.5048\n",
      "Epoch [86/100], Step [7900/6235], Loss: 6.6968\n",
      "Epoch [86/100], Step [8000/6235], Loss: 0.1401\n",
      "Epoch [86/100], Step [8100/6235], Loss: 2.0279\n",
      "Epoch [86/100], Step [8200/6235], Loss: 9.8295\n",
      "Epoch [86/100], Step [8300/6235], Loss: 18.9025\n",
      "Epoch [86/100], Step [8400/6235], Loss: 611.1233\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Step [8500/6235], Loss: 4.3443\n",
      "Epoch [86/100], Step [8600/6235], Loss: 50.7566\n",
      "Epoch [86/100], Step [8700/6235], Loss: 24.7292\n",
      "Epoch [86/100], Step [8800/6235], Loss: 503.4585\n",
      "Epoch [86/100], Step [8900/6235], Loss: 365.5565\n",
      "Epoch [86/100], Step [9000/6235], Loss: 570.4034\n",
      "Epoch [86/100], Step [9100/6235], Loss: 1319.9689\n",
      "Epoch [86/100], Step [9200/6235], Loss: 2948.3171\n",
      "Epoch [86/100], Step [9300/6235], Loss: 26.2235\n",
      "Epoch [86/100], Step [9400/6235], Loss: 429.0768\n",
      "Epoch [86/100], Step [9500/6235], Loss: 283.6878\n",
      "Epoch [86/100], Step [9600/6235], Loss: 1520.1675\n",
      "Epoch [86/100], Step [9700/6235], Loss: 5.3438\n",
      "Epoch [86/100], Step [9800/6235], Loss: 230.0697\n",
      "Epoch [86/100], Step [9900/6235], Loss: 28.5789\n",
      "Epoch [86/100], Step [10000/6235], Loss: 153.3790\n",
      "Epoch [86/100], Step [10100/6235], Loss: 3.4308\n",
      "Epoch [86/100], Step [10200/6235], Loss: 1210.9545\n",
      "Epoch [86/100], Step [10300/6235], Loss: 7.1869\n",
      "Epoch [86/100], Step [10400/6235], Loss: 9.8012\n",
      "Epoch [86/100], Step [10500/6235], Loss: 299.1767\n",
      "Epoch [86/100], Step [10600/6235], Loss: 902.5730\n",
      "Epoch [86/100], Step [10700/6235], Loss: 63.5161\n",
      "Epoch [86/100], Step [10800/6235], Loss: 5.9465\n",
      "Epoch [86/100], Step [10900/6235], Loss: 153.1860\n",
      "Epoch [86/100], Step [11000/6235], Loss: 293.0644\n",
      "Epoch [86/100], Step [11100/6235], Loss: 4.5763\n",
      "Epoch [86/100], Step [11200/6235], Loss: 1.0938\n",
      "Epoch [86/100], Step [11300/6235], Loss: 108.7329\n",
      "Epoch [86/100], Step [11400/6235], Loss: 42.2696\n",
      "Epoch [86/100], Step [11500/6235], Loss: 11.6500\n",
      "Epoch [86/100], Step [11600/6235], Loss: 9.2237\n",
      "Epoch [86/100], Step [11700/6235], Loss: 58.5523\n",
      "Epoch [86/100], Step [11800/6235], Loss: 241.9976\n",
      "Epoch [86/100], Step [11900/6235], Loss: 52.4673\n",
      "Epoch [86/100], Step [12000/6235], Loss: 692.4516\n",
      "Epoch [86/100], Step [12100/6235], Loss: 257.5076\n",
      "Epoch [86/100], Step [12200/6235], Loss: 16.5802\n",
      "Epoch [86/100], Step [12300/6235], Loss: 2.3173\n",
      "Epoch [86/100], Step [12400/6235], Loss: 114.9216\n",
      "Epoch [86/100], Step [12500/6235], Loss: 77.0660\n",
      "Epoch [86/100], Step [12600/6235], Loss: 5.6264\n",
      "Epoch [86/100], Step [12700/6235], Loss: 5.9593\n",
      "Epoch [86/100], Step [12800/6235], Loss: 8.7561\n",
      "Epoch [86/100], Step [12900/6235], Loss: 29.4889\n",
      "Epoch [86/100], Step [13000/6235], Loss: 0.0725\n",
      "Epoch [86/100], Step [13100/6235], Loss: 62.0430\n",
      "Epoch [86/100], Step [13200/6235], Loss: 8.2308\n",
      "Epoch [86/100], Step [13300/6235], Loss: 23.0654\n",
      "Epoch [86/100], Step [13400/6235], Loss: 208.0898\n",
      "Epoch [86/100], Step [13500/6235], Loss: 3.9341\n",
      "Epoch [86/100], Step [13600/6235], Loss: 5.0649\n",
      "Epoch [86/100], Step [13700/6235], Loss: 57.5260\n",
      "Epoch [86/100], Step [13800/6235], Loss: 113.8275\n",
      "Epoch [86/100], Step [13900/6235], Loss: 53.9759\n",
      "Epoch [86/100], Step [14000/6235], Loss: 14.1251\n",
      "Epoch [86/100], Step [14100/6235], Loss: 39.1870\n",
      "Epoch [86/100], Step [14200/6235], Loss: 116.9279\n",
      "Epoch [86/100], Step [14300/6235], Loss: 37.6156\n",
      "Epoch [86/100], Step [14400/6235], Loss: 37.6962\n",
      "Epoch [86/100], Step [14500/6235], Loss: 35.3191\n",
      "Epoch [86/100], Step [14600/6235], Loss: 0.8803\n",
      "Epoch [86/100], Step [14700/6235], Loss: 36.2183\n",
      "Epoch [86/100], Step [14800/6235], Loss: 33.3641\n",
      "Epoch [86/100], Step [14900/6235], Loss: 0.6625\n",
      "Epoch [86/100], Step [15000/6235], Loss: 1.4953\n",
      "Epoch [86/100], Step [15100/6235], Loss: 0.5560\n",
      "Epoch [86/100], Step [15200/6235], Loss: 12.7004\n",
      "Epoch [86/100], Step [15300/6235], Loss: 27.4583\n",
      "Epoch [86/100], Step [15400/6235], Loss: 88.1333\n",
      "Epoch [86/100], Step [15500/6235], Loss: 16.5287\n",
      "Epoch [86/100], Step [15600/6235], Loss: 190.7878\n",
      "Epoch [86/100], Step [15700/6235], Loss: 124.4094\n",
      "Epoch [86/100], Step [15800/6235], Loss: 0.2143\n",
      "Epoch [86/100], Step [15900/6235], Loss: 2.9969\n",
      "Epoch [86/100], Step [16000/6235], Loss: 188.7721\n",
      "Epoch [86/100], Step [16100/6235], Loss: 0.3025\n",
      "Epoch [86/100], Step [16200/6235], Loss: 0.2760\n",
      "Epoch [86/100], Step [16300/6235], Loss: 8.9326\n",
      "Epoch [86/100], Step [16400/6235], Loss: 21.2306\n",
      "Epoch [86/100], Step [16500/6235], Loss: 510.0197\n",
      "Epoch [86/100], Step [16600/6235], Loss: 27.4846\n",
      "Epoch [86/100], Step [16700/6235], Loss: 0.5370\n",
      "Epoch [86/100], Step [16800/6235], Loss: 10.3311\n",
      "Epoch [86/100], Step [16900/6235], Loss: 0.2973\n",
      "Epoch [86/100], Step [17000/6235], Loss: 0.1989\n",
      "Epoch [86/100], Step [17100/6235], Loss: 0.0874\n",
      "Epoch [86/100], Step [17200/6235], Loss: 259.0319\n",
      "Epoch [86/100], Step [17300/6235], Loss: 16.6178\n",
      "Epoch [86/100], Step [17400/6235], Loss: 53.2526\n",
      "Epoch [86/100], Step [17500/6235], Loss: 1.3886\n",
      "Epoch [86/100], Step [17600/6235], Loss: 2.5635\n",
      "Epoch [86/100], Step [17700/6235], Loss: 33.1182\n",
      "Epoch [86/100], Step [17800/6235], Loss: 18.7356\n",
      "Epoch [86/100], Step [17900/6235], Loss: 6.3964\n",
      "Epoch [86/100], Step [18000/6235], Loss: 16.3242\n",
      "Epoch [86/100], Step [18100/6235], Loss: 15.3912\n",
      "Epoch [86/100], Step [18200/6235], Loss: 0.5983\n",
      "Epoch [86/100], Step [18300/6235], Loss: 3.1058\n",
      "Epoch [86/100], Step [18400/6235], Loss: 0.9083\n",
      "Epoch [86/100], Step [18500/6235], Loss: 18.9022\n",
      "Epoch [86/100], Step [18600/6235], Loss: 2.3552\n",
      "Epoch [86/100], Step [18700/6235], Loss: 0.5289\n",
      "Epoch [86/100], Step [18800/6235], Loss: 86.2975\n",
      "Epoch [86/100], Step [18900/6235], Loss: 62.9729\n",
      "Epoch [86/100], Step [19000/6235], Loss: 3.1119\n",
      "Epoch [86/100], Step [19100/6235], Loss: 8.5359\n",
      "Epoch [86/100], Step [19200/6235], Loss: 4.3337\n",
      "Epoch [86/100], Step [19300/6235], Loss: 9.6695\n",
      "Epoch [86/100], Step [19400/6235], Loss: 118.8603\n",
      "Epoch [86/100], Step [19500/6235], Loss: 162.2518\n",
      "Epoch [86/100], Step [19600/6235], Loss: 127.1434\n",
      "Epoch [86/100], Step [19700/6235], Loss: 3.8185\n",
      "Epoch [86/100], Step [19800/6235], Loss: 0.7731\n",
      "Epoch [86/100], Step [19900/6235], Loss: 0.9662\n",
      "Epoch [86/100], Step [20000/6235], Loss: 94.5654\n",
      "Epoch [86/100], Step [20100/6235], Loss: 5.7037\n",
      "Epoch [86/100], Step [20200/6235], Loss: 3.4843\n",
      "Epoch [86/100], Step [20300/6235], Loss: 0.9382\n",
      "Epoch [86/100], Step [20400/6235], Loss: 26.2945\n",
      "Epoch [86/100], Step [20500/6235], Loss: 33.9428\n",
      "Epoch [86/100], Step [20600/6235], Loss: 38.6887\n",
      "Epoch [86/100], Step [20700/6235], Loss: 0.2919\n",
      "Epoch [86/100], Step [20800/6235], Loss: 6.3626\n",
      "Epoch [86/100], Step [20900/6235], Loss: 1.5536\n",
      "Epoch [86/100], Step [21000/6235], Loss: 14.2430\n",
      "Epoch [86/100], Step [21100/6235], Loss: 6.7551\n",
      "Epoch [86/100], Step [21200/6235], Loss: 0.3317\n",
      "Epoch [86/100], Step [21300/6235], Loss: 0.1135\n",
      "Epoch [86/100], Step [21400/6235], Loss: 4.5120\n",
      "Epoch [86/100], Step [21500/6235], Loss: 3.4131\n",
      "Epoch [86/100], Step [21600/6235], Loss: 21.9735\n",
      "Epoch [86/100], Step [21700/6235], Loss: 0.4044\n",
      "Epoch [86/100], Step [21800/6235], Loss: 5.6739\n",
      "Epoch [86/100], Step [21900/6235], Loss: 1.6892\n",
      "Epoch [86/100], Step [22000/6235], Loss: 9.2155\n",
      "Epoch [86/100], Step [22100/6235], Loss: 0.1806\n",
      "Epoch [86/100], Step [22200/6235], Loss: 5.1475\n",
      "Epoch [86/100], Step [22300/6235], Loss: 0.3383\n",
      "Epoch [86/100], Step [22400/6235], Loss: 9.7696\n",
      "Epoch [86/100], Step [22500/6235], Loss: 158.4178\n",
      "Epoch [86/100], Step [22600/6235], Loss: 15.4384\n",
      "Epoch [86/100], Step [22700/6235], Loss: 0.9347\n",
      "Epoch [86/100], Step [22800/6235], Loss: 10.5672\n",
      "Epoch [86/100], Step [22900/6235], Loss: 11.5982\n",
      "Epoch [86/100], Step [23000/6235], Loss: 6.7208\n",
      "Epoch [86/100], Step [23100/6235], Loss: 5.2764\n",
      "Epoch [86/100], Step [23200/6235], Loss: 5.3121\n",
      "Epoch [86/100], Step [23300/6235], Loss: 20.0326\n",
      "Epoch [86/100], Step [23400/6235], Loss: 2.4983\n",
      "Epoch [86/100], Step [23500/6235], Loss: 0.0458\n",
      "Epoch [86/100], Step [23600/6235], Loss: 135.2928\n",
      "Epoch [86/100], Step [23700/6235], Loss: 4.3779\n",
      "Epoch [86/100], Step [23800/6235], Loss: 0.7241\n",
      "Epoch [86/100], Step [23900/6235], Loss: 1.5382\n",
      "Epoch [86/100], Step [24000/6235], Loss: 1.9263\n",
      "Epoch [86/100], Step [24100/6235], Loss: 2.3775\n",
      "Epoch [86/100], Step [24200/6235], Loss: 42.7118\n",
      "Epoch [86/100], Step [24300/6235], Loss: 0.6351\n",
      "Epoch [86/100], Step [24400/6235], Loss: 0.6876\n",
      "Epoch [86/100], Step [24500/6235], Loss: 0.6817\n",
      "Epoch [86/100], Step [24600/6235], Loss: 0.2478\n",
      "Epoch [86/100], Step [24700/6235], Loss: 0.1320\n",
      "Epoch [86/100], Step [24800/6235], Loss: 0.4903\n",
      "Epoch [86/100], Step [24900/6235], Loss: 8.2928\n",
      "Epoch [86/100], Step [25000/6235], Loss: 6.5980\n",
      "Epoch [86/100], Step [25100/6235], Loss: 8.5951\n",
      "Epoch [86/100], Step [25200/6235], Loss: 0.1003\n",
      "Epoch [86/100], Step [25300/6235], Loss: 2.5437\n",
      "Epoch [86/100], Step [25400/6235], Loss: 6.5761\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Step [25500/6235], Loss: 8.1378\n",
      "Epoch [86/100], Step [25600/6235], Loss: 8.5492\n",
      "Epoch [86/100], Step [25700/6235], Loss: 0.1469\n",
      "Epoch [86/100], Step [25800/6235], Loss: 2.0143\n",
      "Epoch [86/100], Step [25900/6235], Loss: 2.1736\n",
      "Epoch [86/100], Step [26000/6235], Loss: 0.1860\n",
      "Epoch [86/100], Step [26100/6235], Loss: 0.3049\n",
      "Epoch [86/100], Step [26200/6235], Loss: 0.9424\n",
      "Epoch [86/100], Step [26300/6235], Loss: 0.2026\n",
      "Epoch [86/100], Step [26400/6235], Loss: 1.8550\n",
      "Epoch [86/100], Step [26500/6235], Loss: 0.0159\n",
      "Epoch [86/100], Step [26600/6235], Loss: 0.1231\n",
      "Epoch [86/100], Step [26700/6235], Loss: 0.0312\n",
      "Epoch [86/100], Step [26800/6235], Loss: 0.0812\n",
      "Epoch [86/100], Step [26900/6235], Loss: 0.1721\n",
      "Epoch [86/100], Step [27000/6235], Loss: 13.8630\n",
      "Epoch [86/100], Step [27100/6235], Loss: 0.1303\n",
      "Epoch [86/100], Step [27200/6235], Loss: 0.1487\n",
      "Epoch [86/100], Step [27300/6235], Loss: 0.0201\n",
      "Epoch [86/100], Step [27400/6235], Loss: 0.3433\n",
      "Epoch [86/100], Step [27500/6235], Loss: 0.4427\n",
      "Epoch [86/100], Step [27600/6235], Loss: 0.2231\n",
      "Epoch [86/100], Step [27700/6235], Loss: 0.8987\n",
      "Epoch [86/100], Step [27800/6235], Loss: 2.7530\n",
      "Epoch [86/100], Step [27900/6235], Loss: 0.1834\n",
      "Epoch [86/100], Step [28000/6235], Loss: 168.8811\n",
      "Epoch [86/100], Step [28100/6235], Loss: 11.0604\n",
      "Epoch [86/100], Step [28200/6235], Loss: 27.4213\n",
      "Epoch [86/100], Step [28300/6235], Loss: 0.5755\n",
      "Epoch [86/100], Step [28400/6235], Loss: 21.6950\n",
      "Epoch [86/100], Step [28500/6235], Loss: 2.2613\n",
      "Epoch [86/100], Step [28600/6235], Loss: 0.7681\n",
      "Epoch [86/100], Step [28700/6235], Loss: 2.5746\n",
      "Epoch [86/100], Step [28800/6235], Loss: 0.6807\n",
      "Epoch [86/100], Step [28900/6235], Loss: 35.3784\n",
      "Epoch [86/100], Step [29000/6235], Loss: 3.1219\n",
      "Epoch [86/100], Step [29100/6235], Loss: 0.2974\n",
      "Epoch [86/100], Step [29200/6235], Loss: 6.0256\n",
      "Epoch [86/100], Step [29300/6235], Loss: 0.2202\n",
      "Epoch [86/100], Step [29400/6235], Loss: 0.8994\n",
      "Epoch [86/100], Step [29500/6235], Loss: 2.5204\n",
      "Epoch [86/100], Step [29600/6235], Loss: 0.4437\n",
      "Epoch [86/100], Step [29700/6235], Loss: 0.9782\n",
      "Epoch [86/100], Step [29800/6235], Loss: 0.3224\n",
      "Epoch [86/100], Step [29900/6235], Loss: 4.5725\n",
      "Epoch [86/100], Step [30000/6235], Loss: 4.2258\n",
      "Epoch [86/100], Step [30100/6235], Loss: 8.6059\n",
      "Epoch [86/100], Step [30200/6235], Loss: 1.0985\n",
      "Epoch [86/100], Step [30300/6235], Loss: 0.1693\n",
      "Epoch [86/100], Step [30400/6235], Loss: 4.3501\n",
      "Epoch [86/100], Step [30500/6235], Loss: 0.7658\n",
      "Epoch [86/100], Step [30600/6235], Loss: 1.4043\n",
      "Epoch [86/100], Step [30700/6235], Loss: 3.1106\n",
      "Epoch [86/100], Step [30800/6235], Loss: 0.4233\n",
      "Epoch [86/100], Step [30900/6235], Loss: 0.8746\n",
      "Epoch [86/100], Step [31000/6235], Loss: 0.1540\n",
      "Epoch [86/100], Step [31100/6235], Loss: 1.3105\n",
      "Epoch [86/100], Step [31200/6235], Loss: 8.1026\n",
      "Epoch [86/100], Step [31300/6235], Loss: 2.1123\n",
      "Epoch [86/100], Step [31400/6235], Loss: 7.4593\n",
      "Epoch [86/100], Step [31500/6235], Loss: 0.9043\n",
      "Epoch [86/100], Step [31600/6235], Loss: 7.0283\n",
      "Epoch [86/100], Step [31700/6235], Loss: 48.2629\n",
      "Epoch [86/100], Step [31800/6235], Loss: 0.7394\n",
      "Epoch [86/100], Step [31900/6235], Loss: 44.7992\n",
      "Epoch [86/100], Step [32000/6235], Loss: 54.8250\n",
      "Epoch [86/100], Step [32100/6235], Loss: 8.5520\n",
      "Epoch [86/100], Step [32200/6235], Loss: 3.1439\n",
      "Epoch [86/100], Step [32300/6235], Loss: 7.9818\n",
      "Epoch [86/100], Step [32400/6235], Loss: 1.2458\n",
      "Epoch [86/100], Step [32500/6235], Loss: 1.3274\n",
      "Epoch [86/100], Step [32600/6235], Loss: 0.3424\n",
      "Epoch [86/100], Step [32700/6235], Loss: 48.5962\n",
      "Epoch [86/100], Step [32800/6235], Loss: 1.5315\n",
      "Epoch [86/100], Step [32900/6235], Loss: 6.7879\n",
      "Epoch [86/100], Step [33000/6235], Loss: 0.3676\n",
      "Epoch [86/100], Step [33100/6235], Loss: 0.8503\n",
      "Epoch [86/100], Step [33200/6235], Loss: 1.2726\n",
      "Epoch [86/100], Step [33300/6235], Loss: 0.2251\n",
      "Epoch [86/100], Step [33400/6235], Loss: 126.9091\n",
      "Epoch [86/100], Step [33500/6235], Loss: 2.0428\n",
      "Epoch [86/100], Step [33600/6235], Loss: 5.8821\n",
      "Epoch [86/100], Step [33700/6235], Loss: 6.2796\n",
      "Epoch [86/100], Step [33800/6235], Loss: 1.3958\n",
      "Epoch [86/100], Step [33900/6235], Loss: 27.8856\n",
      "Epoch [86/100], Step [34000/6235], Loss: 0.0105\n",
      "Epoch [86/100], Step [34100/6235], Loss: 0.2864\n",
      "Epoch [86/100], Step [34200/6235], Loss: 2.5422\n",
      "Epoch [86/100], Step [34300/6235], Loss: 6.6266\n",
      "Epoch [86/100], Step [34400/6235], Loss: 0.1184\n",
      "Epoch [86/100], Step [34500/6235], Loss: 94.2111\n",
      "Epoch [86/100], Step [34600/6235], Loss: 2.2790\n",
      "Epoch [86/100], Step [34700/6235], Loss: 27.6252\n",
      "Epoch [86/100], Step [34800/6235], Loss: 14.0982\n",
      "Epoch [86/100], Step [34900/6235], Loss: 29.6196\n",
      "Epoch [86/100], Step [35000/6235], Loss: 2.4658\n",
      "Epoch [86/100], Step [35100/6235], Loss: 4.2609\n",
      "Epoch [86/100], Step [35200/6235], Loss: 2.4634\n",
      "Epoch [86/100], Step [35300/6235], Loss: 0.0468\n",
      "Epoch [86/100], Step [35400/6235], Loss: 0.7884\n",
      "Epoch [86/100], Step [35500/6235], Loss: 2.5139\n",
      "Epoch [86/100], Step [35600/6235], Loss: 1.2261\n",
      "Epoch [86/100], Step [35700/6235], Loss: 5.2611\n",
      "Epoch [86/100], Step [35800/6235], Loss: 0.1723\n",
      "Epoch [86/100], Step [35900/6235], Loss: 0.8197\n",
      "Epoch [86/100], Step [36000/6235], Loss: 0.6035\n",
      "Epoch [86/100], Step [36100/6235], Loss: 0.0341\n",
      "Epoch [86/100], Step [36200/6235], Loss: 12.5119\n",
      "Epoch [86/100], Step [36300/6235], Loss: 0.4121\n",
      "Epoch [86/100], Step [36400/6235], Loss: 2.1393\n",
      "Epoch [86/100], Step [36500/6235], Loss: 9.2789\n",
      "Epoch [86/100], Step [36600/6235], Loss: 0.1265\n",
      "Epoch [86/100], Step [36700/6235], Loss: 0.2035\n",
      "Epoch [86/100], Step [36800/6235], Loss: 17.2692\n",
      "Epoch [86/100], Step [36900/6235], Loss: 4.3654\n",
      "Epoch [86/100], Step [37000/6235], Loss: 0.1898\n",
      "Epoch [86/100], Step [37100/6235], Loss: 0.7184\n",
      "Epoch [86/100], Step [37200/6235], Loss: 0.0744\n",
      "Epoch [86/100], Step [37300/6235], Loss: 0.0840\n",
      "Epoch [86/100], Step [37400/6235], Loss: 0.2049\n",
      "Epoch [86/100], Step [37500/6235], Loss: 3.2116\n",
      "Epoch [86/100], Step [37600/6235], Loss: 10.6300\n",
      "Epoch [86/100], Step [37700/6235], Loss: 0.6055\n",
      "Epoch [86/100], Step [37800/6235], Loss: 7.6312\n",
      "Epoch [86/100], Step [37900/6235], Loss: 7.5832\n",
      "Epoch [86/100], Step [38000/6235], Loss: 0.2332\n",
      "Epoch [86/100], Step [38100/6235], Loss: 2.5618\n",
      "Epoch [86/100], Step [38200/6235], Loss: 2.6163\n",
      "Epoch [86/100], Step [38300/6235], Loss: 1.3447\n",
      "Epoch [86/100], Step [38400/6235], Loss: 0.2003\n",
      "Epoch [86/100], Step [38500/6235], Loss: 3.7849\n",
      "Epoch [86/100], Step [38600/6235], Loss: 0.3476\n",
      "Epoch [86/100], Step [38700/6235], Loss: 0.3354\n",
      "Epoch [86/100], Step [38800/6235], Loss: 0.4625\n",
      "Epoch [86/100], Step [38900/6235], Loss: 9.7223\n",
      "Epoch [86/100], Step [39000/6235], Loss: 5.4747\n",
      "Epoch [86/100], Step [39100/6235], Loss: 9.9767\n",
      "Epoch [86/100], Step [39200/6235], Loss: 2.3230\n",
      "Epoch [86/100], Step [39300/6235], Loss: 31.4687\n",
      "Epoch [86/100], Step [39400/6235], Loss: 410.4716\n",
      "Epoch [86/100], Step [39500/6235], Loss: 201.3549\n",
      "Epoch [86/100], Step [39600/6235], Loss: 5.9597\n",
      "Epoch [86/100], Step [39700/6235], Loss: 960.8123\n",
      "Epoch [86/100], Step [39800/6235], Loss: 154.6569\n",
      "Epoch [86/100], Step [39900/6235], Loss: 55.0284\n",
      "Epoch [86/100], Step [40000/6235], Loss: 0.6711\n",
      "Epoch [86/100], Step [40100/6235], Loss: 2.7130\n",
      "Epoch [86/100], Step [40200/6235], Loss: 56.5133\n",
      "Epoch [86/100], Step [40300/6235], Loss: 0.9771\n",
      "Epoch [86/100], Step [40400/6235], Loss: 1.8456\n",
      "Epoch [86/100], Step [40500/6235], Loss: 4.9016\n",
      "Epoch [86/100], Step [40600/6235], Loss: 0.3871\n",
      "Epoch [86/100], Step [40700/6235], Loss: 3.0023\n",
      "Epoch [86/100], Step [40800/6235], Loss: 2.8184\n",
      "Epoch [86/100], Step [40900/6235], Loss: 0.6556\n",
      "Epoch [86/100], Step [41000/6235], Loss: 31.6930\n",
      "Epoch [86/100], Step [41100/6235], Loss: 34.6371\n",
      "Epoch [86/100], Step [41200/6235], Loss: 56.3480\n",
      "Epoch [86/100], Step [41300/6235], Loss: 6.0358\n",
      "Epoch [86/100], Step [41400/6235], Loss: 4.6032\n",
      "Epoch [86/100], Step [41500/6235], Loss: 35.8683\n",
      "Epoch [86/100], Step [41600/6235], Loss: 0.8942\n",
      "Epoch [86/100], Step [41700/6235], Loss: 0.1579\n",
      "Epoch [86/100], Step [41800/6235], Loss: 0.2372\n",
      "Epoch [86/100], Step [41900/6235], Loss: 4.2118\n",
      "Epoch [86/100], Step [42000/6235], Loss: 3.3052\n",
      "Epoch [86/100], Step [42100/6235], Loss: 12.0912\n",
      "Epoch [86/100], Step [42200/6235], Loss: 40.4290\n",
      "Epoch [86/100], Step [42300/6235], Loss: 0.5826\n",
      "Epoch [86/100], Step [42400/6235], Loss: 1.3877\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [86/100], Step [42500/6235], Loss: 1.6252\n",
      "Epoch [86/100], Step [42600/6235], Loss: 1.7333\n",
      "Epoch [86/100], Step [42700/6235], Loss: 0.6653\n",
      "Epoch [86/100], Step [42800/6235], Loss: 15.2804\n",
      "Epoch [86/100], Step [42900/6235], Loss: 0.2285\n",
      "Epoch [86/100], Step [43000/6235], Loss: 0.7549\n",
      "Epoch [86/100], Step [43100/6235], Loss: 0.1109\n",
      "Epoch [86/100], Step [43200/6235], Loss: 0.1158\n",
      "Epoch [86/100], Step [43300/6235], Loss: 3.5794\n",
      "Epoch [86/100], Step [43400/6235], Loss: 5.7251\n",
      "Epoch [86/100], Step [43500/6235], Loss: 12.1965\n",
      "Epoch [86/100], Step [43600/6235], Loss: 2.1790\n",
      "Epoch [86/100], Step [43700/6235], Loss: 40.9519\n",
      "Epoch [86/100], Step [43800/6235], Loss: 0.3160\n",
      "Epoch [86/100], Step [43900/6235], Loss: 3.8028\n",
      "Epoch [86/100], Step [44000/6235], Loss: 19.8839\n",
      "Epoch [86/100], Step [44100/6235], Loss: 1.3016\n",
      "Epoch [86/100], Step [44200/6235], Loss: 1.3773\n",
      "Epoch [86/100], Step [44300/6235], Loss: 175.8747\n",
      "Epoch [86/100], Step [44400/6235], Loss: 0.9291\n",
      "Epoch [86/100], Step [44500/6235], Loss: 1.3557\n",
      "Epoch [86/100], Step [44600/6235], Loss: 1.3461\n",
      "Epoch [86/100], Step [44700/6235], Loss: 3.3567\n",
      "Epoch [86/100], Step [44800/6235], Loss: 0.8751\n",
      "Epoch [86/100], Step [44900/6235], Loss: 4.6546\n",
      "Epoch [86/100], Step [45000/6235], Loss: 6.3860\n",
      "Epoch [86/100], Step [45100/6235], Loss: 54.6873\n",
      "Epoch [86/100], Step [45200/6235], Loss: 7.2380\n",
      "Epoch [86/100], Step [45300/6235], Loss: 23.2839\n",
      "Epoch [86/100], Step [45400/6235], Loss: 9.9515\n",
      "Epoch [86/100], Step [45500/6235], Loss: 1.8992\n",
      "Epoch [86/100], Step [45600/6235], Loss: 1.6867\n",
      "Epoch [86/100], Step [45700/6235], Loss: 9.7217\n",
      "Epoch [86/100], Step [45800/6235], Loss: 331.1302\n",
      "Epoch [86/100], Step [45900/6235], Loss: 93.3668\n",
      "Epoch [86/100], Step [46000/6235], Loss: 3.3465\n",
      "Epoch [86/100], Step [46100/6235], Loss: 17.5252\n",
      "Epoch [86/100], Step [46200/6235], Loss: 7.8042\n",
      "Epoch [86/100], Step [46300/6235], Loss: 67.7009\n",
      "Epoch [86/100], Step [46400/6235], Loss: 5.5588\n",
      "Epoch [86/100], Step [46500/6235], Loss: 134.7756\n",
      "Epoch [86/100], Step [46600/6235], Loss: 17.8856\n",
      "Epoch [86/100], Step [46700/6235], Loss: 16.1104\n",
      "Epoch [86/100], Step [46800/6235], Loss: 34.9829\n",
      "Epoch [86/100], Step [46900/6235], Loss: 16.9972\n",
      "Epoch [86/100], Step [47000/6235], Loss: 1.0664\n",
      "Epoch [86/100], Step [47100/6235], Loss: 87.1641\n",
      "Epoch [86/100], Step [47200/6235], Loss: 70.4636\n",
      "Epoch [86/100], Step [47300/6235], Loss: 10.8973\n",
      "Epoch [86/100], Step [47400/6235], Loss: 553.9995\n",
      "Epoch [86/100], Step [47500/6235], Loss: 8.9739\n",
      "Epoch [86/100], Step [47600/6235], Loss: 11.8299\n",
      "Epoch [86/100], Step [47700/6235], Loss: 17.5726\n",
      "Epoch [86/100], Step [47800/6235], Loss: 24.4054\n",
      "Epoch [86/100], Step [47900/6235], Loss: 15.2145\n",
      "Epoch [86/100], Step [48000/6235], Loss: 26.3621\n",
      "Epoch [86/100], Step [48100/6235], Loss: 9.1433\n",
      "Epoch [86/100], Step [48200/6235], Loss: 73.0240\n",
      "Epoch [86/100], Step [48300/6235], Loss: 706.3523\n",
      "Epoch [86/100], Step [48400/6235], Loss: 2.8212\n",
      "Epoch [86/100], Step [48500/6235], Loss: 36.4344\n",
      "Epoch [86/100], Step [48600/6235], Loss: 30.2286\n",
      "Epoch [86/100], Step [48700/6235], Loss: 16.5526\n",
      "Epoch [86/100], Step [48800/6235], Loss: 564.0096\n",
      "Epoch [86/100], Step [48900/6235], Loss: 130.6838\n",
      "Epoch [86/100], Step [49000/6235], Loss: 221.5428\n",
      "Epoch [86/100], Step [49100/6235], Loss: 1303.5981\n",
      "Epoch [86/100], Step [49200/6235], Loss: 885.9733\n",
      "Epoch [86/100], Step [49300/6235], Loss: 1054.6038\n",
      "Epoch [86/100], Step [49400/6235], Loss: 34.6639\n",
      "Epoch [86/100], Step [49500/6235], Loss: 22.2771\n",
      "Epoch [86/100], Step [49600/6235], Loss: 129.0125\n",
      "Epoch [86/100], Step [49700/6235], Loss: 4070.7834\n",
      "Epoch [86/100], Step [49800/6235], Loss: 62.9548\n",
      "Epoch [87/100], Step [100/6235], Loss: 9.3502\n",
      "Epoch [87/100], Step [200/6235], Loss: 0.1297\n",
      "Epoch [87/100], Step [300/6235], Loss: 0.0286\n",
      "Epoch [87/100], Step [400/6235], Loss: 0.0165\n",
      "Epoch [87/100], Step [500/6235], Loss: 15.2548\n",
      "Epoch [87/100], Step [600/6235], Loss: 0.0347\n",
      "Epoch [87/100], Step [700/6235], Loss: 0.5205\n",
      "Epoch [87/100], Step [800/6235], Loss: 0.1220\n",
      "Epoch [87/100], Step [900/6235], Loss: 0.0665\n",
      "Epoch [87/100], Step [1000/6235], Loss: 0.0319\n",
      "Epoch [87/100], Step [1100/6235], Loss: 0.0664\n",
      "Epoch [87/100], Step [1200/6235], Loss: 0.1766\n",
      "Epoch [87/100], Step [1300/6235], Loss: 0.0295\n",
      "Epoch [87/100], Step [1400/6235], Loss: 0.0477\n",
      "Epoch [87/100], Step [1500/6235], Loss: 0.0053\n",
      "Epoch [87/100], Step [1600/6235], Loss: 0.2254\n",
      "Epoch [87/100], Step [1700/6235], Loss: 0.0129\n",
      "Epoch [87/100], Step [1800/6235], Loss: 0.1975\n",
      "Epoch [87/100], Step [1900/6235], Loss: 0.4627\n",
      "Epoch [87/100], Step [2000/6235], Loss: 2.1984\n",
      "Epoch [87/100], Step [2100/6235], Loss: 1.9419\n",
      "Epoch [87/100], Step [2200/6235], Loss: 8.5998\n",
      "Epoch [87/100], Step [2300/6235], Loss: 7.4242\n",
      "Epoch [87/100], Step [2400/6235], Loss: 1.9732\n",
      "Epoch [87/100], Step [2500/6235], Loss: 36.0638\n",
      "Epoch [87/100], Step [2600/6235], Loss: 12.4045\n",
      "Epoch [87/100], Step [2700/6235], Loss: 10.0296\n",
      "Epoch [87/100], Step [2800/6235], Loss: 237.1892\n",
      "Epoch [87/100], Step [2900/6235], Loss: 12.7374\n",
      "Epoch [87/100], Step [3000/6235], Loss: 0.7274\n",
      "Epoch [87/100], Step [3100/6235], Loss: 67.1352\n",
      "Epoch [87/100], Step [3200/6235], Loss: 77.8342\n",
      "Epoch [87/100], Step [3300/6235], Loss: 7.5536\n",
      "Epoch [87/100], Step [3400/6235], Loss: 1.9882\n",
      "Epoch [87/100], Step [3500/6235], Loss: 38.2088\n",
      "Epoch [87/100], Step [3600/6235], Loss: 8.5865\n",
      "Epoch [87/100], Step [3700/6235], Loss: 0.0785\n",
      "Epoch [87/100], Step [3800/6235], Loss: 0.2419\n",
      "Epoch [87/100], Step [3900/6235], Loss: 0.7816\n",
      "Epoch [87/100], Step [4000/6235], Loss: 0.0370\n",
      "Epoch [87/100], Step [4100/6235], Loss: 7.2911\n",
      "Epoch [87/100], Step [4200/6235], Loss: 0.6206\n",
      "Epoch [87/100], Step [4300/6235], Loss: 8.4114\n",
      "Epoch [87/100], Step [4400/6235], Loss: 3.0933\n",
      "Epoch [87/100], Step [4500/6235], Loss: 39.5227\n",
      "Epoch [87/100], Step [4600/6235], Loss: 2.8125\n",
      "Epoch [87/100], Step [4700/6235], Loss: 0.1304\n",
      "Epoch [87/100], Step [4800/6235], Loss: 9.9882\n",
      "Epoch [87/100], Step [4900/6235], Loss: 0.2362\n",
      "Epoch [87/100], Step [5000/6235], Loss: 0.0427\n",
      "Epoch [87/100], Step [5100/6235], Loss: 2.0090\n",
      "Epoch [87/100], Step [5200/6235], Loss: 1.0928\n",
      "Epoch [87/100], Step [5300/6235], Loss: 42.8082\n",
      "Epoch [87/100], Step [5400/6235], Loss: 1.3999\n",
      "Epoch [87/100], Step [5500/6235], Loss: 0.0728\n",
      "Epoch [87/100], Step [5600/6235], Loss: 0.2983\n",
      "Epoch [87/100], Step [5700/6235], Loss: 0.1041\n",
      "Epoch [87/100], Step [5800/6235], Loss: 0.2245\n",
      "Epoch [87/100], Step [5900/6235], Loss: 0.1324\n",
      "Epoch [87/100], Step [6000/6235], Loss: 3.2331\n",
      "Epoch [87/100], Step [6100/6235], Loss: 0.0486\n",
      "Epoch [87/100], Step [6200/6235], Loss: 2.5038\n",
      "Epoch [87/100], Step [6300/6235], Loss: 1.2644\n",
      "Epoch [87/100], Step [6400/6235], Loss: 0.0610\n",
      "Epoch [87/100], Step [6500/6235], Loss: 2.5667\n",
      "Epoch [87/100], Step [6600/6235], Loss: 6.6049\n",
      "Epoch [87/100], Step [6700/6235], Loss: 3.1582\n",
      "Epoch [87/100], Step [6800/6235], Loss: 0.2474\n",
      "Epoch [87/100], Step [6900/6235], Loss: 0.1229\n",
      "Epoch [87/100], Step [7000/6235], Loss: 0.0300\n",
      "Epoch [87/100], Step [7100/6235], Loss: 0.2340\n",
      "Epoch [87/100], Step [7200/6235], Loss: 0.0700\n",
      "Epoch [87/100], Step [7300/6235], Loss: 0.4513\n",
      "Epoch [87/100], Step [7400/6235], Loss: 0.0478\n",
      "Epoch [87/100], Step [7500/6235], Loss: 0.9521\n",
      "Epoch [87/100], Step [7600/6235], Loss: 4.9607\n",
      "Epoch [87/100], Step [7700/6235], Loss: 11.4247\n",
      "Epoch [87/100], Step [7800/6235], Loss: 1.6254\n",
      "Epoch [87/100], Step [7900/6235], Loss: 0.8474\n",
      "Epoch [87/100], Step [8000/6235], Loss: 0.2252\n",
      "Epoch [87/100], Step [8100/6235], Loss: 3.9438\n",
      "Epoch [87/100], Step [8200/6235], Loss: 11.0944\n",
      "Epoch [87/100], Step [8300/6235], Loss: 13.9761\n",
      "Epoch [87/100], Step [8400/6235], Loss: 500.8312\n",
      "Epoch [87/100], Step [8500/6235], Loss: 2.3594\n",
      "Epoch [87/100], Step [8600/6235], Loss: 29.1732\n",
      "Epoch [87/100], Step [8700/6235], Loss: 22.1739\n",
      "Epoch [87/100], Step [8800/6235], Loss: 513.5959\n",
      "Epoch [87/100], Step [8900/6235], Loss: 215.4628\n",
      "Epoch [87/100], Step [9000/6235], Loss: 558.1949\n",
      "Epoch [87/100], Step [9100/6235], Loss: 978.5997\n",
      "Epoch [87/100], Step [9200/6235], Loss: 2142.6113\n",
      "Epoch [87/100], Step [9300/6235], Loss: 138.6737\n",
      "Epoch [87/100], Step [9400/6235], Loss: 22.5107\n",
      "Epoch [87/100], Step [9500/6235], Loss: 335.2295\n",
      "Epoch [87/100], Step [9600/6235], Loss: 1251.1051\n",
      "Epoch [87/100], Step [9700/6235], Loss: 6.4416\n",
      "Epoch [87/100], Step [9800/6235], Loss: 1746.2596\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Step [9900/6235], Loss: 46.1866\n",
      "Epoch [87/100], Step [10000/6235], Loss: 77.0525\n",
      "Epoch [87/100], Step [10100/6235], Loss: 2.8624\n",
      "Epoch [87/100], Step [10200/6235], Loss: 1182.7760\n",
      "Epoch [87/100], Step [10300/6235], Loss: 20.7828\n",
      "Epoch [87/100], Step [10400/6235], Loss: 11.0587\n",
      "Epoch [87/100], Step [10500/6235], Loss: 148.9891\n",
      "Epoch [87/100], Step [10600/6235], Loss: 278.4976\n",
      "Epoch [87/100], Step [10700/6235], Loss: 24.6715\n",
      "Epoch [87/100], Step [10800/6235], Loss: 78.7481\n",
      "Epoch [87/100], Step [10900/6235], Loss: 139.8961\n",
      "Epoch [87/100], Step [11000/6235], Loss: 273.6583\n",
      "Epoch [87/100], Step [11100/6235], Loss: 5.0335\n",
      "Epoch [87/100], Step [11200/6235], Loss: 0.8526\n",
      "Epoch [87/100], Step [11300/6235], Loss: 109.0519\n",
      "Epoch [87/100], Step [11400/6235], Loss: 72.4289\n",
      "Epoch [87/100], Step [11500/6235], Loss: 11.7093\n",
      "Epoch [87/100], Step [11600/6235], Loss: 9.0582\n",
      "Epoch [87/100], Step [11700/6235], Loss: 64.9654\n",
      "Epoch [87/100], Step [11800/6235], Loss: 395.2797\n",
      "Epoch [87/100], Step [11900/6235], Loss: 46.5499\n",
      "Epoch [87/100], Step [12000/6235], Loss: 646.1350\n",
      "Epoch [87/100], Step [12100/6235], Loss: 340.3065\n",
      "Epoch [87/100], Step [12200/6235], Loss: 21.0778\n",
      "Epoch [87/100], Step [12300/6235], Loss: 1.0038\n",
      "Epoch [87/100], Step [12400/6235], Loss: 162.8000\n",
      "Epoch [87/100], Step [12500/6235], Loss: 49.2606\n",
      "Epoch [87/100], Step [12600/6235], Loss: 11.5020\n",
      "Epoch [87/100], Step [12700/6235], Loss: 9.4801\n",
      "Epoch [87/100], Step [12800/6235], Loss: 9.6658\n",
      "Epoch [87/100], Step [12900/6235], Loss: 33.3001\n",
      "Epoch [87/100], Step [13000/6235], Loss: 0.2294\n",
      "Epoch [87/100], Step [13100/6235], Loss: 63.3751\n",
      "Epoch [87/100], Step [13200/6235], Loss: 7.5936\n",
      "Epoch [87/100], Step [13300/6235], Loss: 23.1521\n",
      "Epoch [87/100], Step [13400/6235], Loss: 222.0958\n",
      "Epoch [87/100], Step [13500/6235], Loss: 4.8400\n",
      "Epoch [87/100], Step [13600/6235], Loss: 1.6798\n",
      "Epoch [87/100], Step [13700/6235], Loss: 108.7258\n",
      "Epoch [87/100], Step [13800/6235], Loss: 95.5197\n",
      "Epoch [87/100], Step [13900/6235], Loss: 35.4464\n",
      "Epoch [87/100], Step [14000/6235], Loss: 10.1745\n",
      "Epoch [87/100], Step [14100/6235], Loss: 45.2527\n",
      "Epoch [87/100], Step [14200/6235], Loss: 17.1278\n",
      "Epoch [87/100], Step [14300/6235], Loss: 7.0686\n",
      "Epoch [87/100], Step [14400/6235], Loss: 33.2024\n",
      "Epoch [87/100], Step [14500/6235], Loss: 24.3069\n",
      "Epoch [87/100], Step [14600/6235], Loss: 2.8674\n",
      "Epoch [87/100], Step [14700/6235], Loss: 23.3508\n",
      "Epoch [87/100], Step [14800/6235], Loss: 28.2416\n",
      "Epoch [87/100], Step [14900/6235], Loss: 0.7479\n",
      "Epoch [87/100], Step [15000/6235], Loss: 1.0657\n",
      "Epoch [87/100], Step [15100/6235], Loss: 0.3448\n",
      "Epoch [87/100], Step [15200/6235], Loss: 24.9028\n",
      "Epoch [87/100], Step [15300/6235], Loss: 38.5860\n",
      "Epoch [87/100], Step [15400/6235], Loss: 75.6796\n",
      "Epoch [87/100], Step [15500/6235], Loss: 17.1387\n",
      "Epoch [87/100], Step [15600/6235], Loss: 188.3243\n",
      "Epoch [87/100], Step [15700/6235], Loss: 170.2055\n",
      "Epoch [87/100], Step [15800/6235], Loss: 0.2045\n",
      "Epoch [87/100], Step [15900/6235], Loss: 2.3524\n",
      "Epoch [87/100], Step [16000/6235], Loss: 208.9632\n",
      "Epoch [87/100], Step [16100/6235], Loss: 2.9514\n",
      "Epoch [87/100], Step [16200/6235], Loss: 0.2802\n",
      "Epoch [87/100], Step [16300/6235], Loss: 9.1997\n",
      "Epoch [87/100], Step [16400/6235], Loss: 26.6973\n",
      "Epoch [87/100], Step [16500/6235], Loss: 145.6221\n",
      "Epoch [87/100], Step [16600/6235], Loss: 15.6151\n",
      "Epoch [87/100], Step [16700/6235], Loss: 0.7015\n",
      "Epoch [87/100], Step [16800/6235], Loss: 9.1750\n",
      "Epoch [87/100], Step [16900/6235], Loss: 0.2567\n",
      "Epoch [87/100], Step [17000/6235], Loss: 0.2179\n",
      "Epoch [87/100], Step [17100/6235], Loss: 0.1658\n",
      "Epoch [87/100], Step [17200/6235], Loss: 277.5955\n",
      "Epoch [87/100], Step [17300/6235], Loss: 37.4060\n",
      "Epoch [87/100], Step [17400/6235], Loss: 56.5394\n",
      "Epoch [87/100], Step [17500/6235], Loss: 0.9085\n",
      "Epoch [87/100], Step [17600/6235], Loss: 2.7109\n",
      "Epoch [87/100], Step [17700/6235], Loss: 57.7547\n",
      "Epoch [87/100], Step [17800/6235], Loss: 22.3513\n",
      "Epoch [87/100], Step [17900/6235], Loss: 8.4385\n",
      "Epoch [87/100], Step [18000/6235], Loss: 22.5913\n",
      "Epoch [87/100], Step [18100/6235], Loss: 18.8737\n",
      "Epoch [87/100], Step [18200/6235], Loss: 0.7701\n",
      "Epoch [87/100], Step [18300/6235], Loss: 6.4860\n",
      "Epoch [87/100], Step [18400/6235], Loss: 4.6476\n",
      "Epoch [87/100], Step [18500/6235], Loss: 13.2272\n",
      "Epoch [87/100], Step [18600/6235], Loss: 1.6174\n",
      "Epoch [87/100], Step [18700/6235], Loss: 0.4553\n",
      "Epoch [87/100], Step [18800/6235], Loss: 26.0518\n",
      "Epoch [87/100], Step [18900/6235], Loss: 49.2074\n",
      "Epoch [87/100], Step [19000/6235], Loss: 4.7516\n",
      "Epoch [87/100], Step [19100/6235], Loss: 30.8577\n",
      "Epoch [87/100], Step [19200/6235], Loss: 2.6093\n",
      "Epoch [87/100], Step [19300/6235], Loss: 0.1992\n",
      "Epoch [87/100], Step [19400/6235], Loss: 70.5242\n",
      "Epoch [87/100], Step [19500/6235], Loss: 89.8309\n",
      "Epoch [87/100], Step [19600/6235], Loss: 84.3940\n",
      "Epoch [87/100], Step [19700/6235], Loss: 9.4477\n",
      "Epoch [87/100], Step [19800/6235], Loss: 3.1231\n",
      "Epoch [87/100], Step [19900/6235], Loss: 0.1446\n",
      "Epoch [87/100], Step [20000/6235], Loss: 67.3434\n",
      "Epoch [87/100], Step [20100/6235], Loss: 0.0381\n",
      "Epoch [87/100], Step [20200/6235], Loss: 5.9376\n",
      "Epoch [87/100], Step [20300/6235], Loss: 2.4593\n",
      "Epoch [87/100], Step [20400/6235], Loss: 20.3475\n",
      "Epoch [87/100], Step [20500/6235], Loss: 40.9288\n",
      "Epoch [87/100], Step [20600/6235], Loss: 20.8015\n",
      "Epoch [87/100], Step [20700/6235], Loss: 4.5743\n",
      "Epoch [87/100], Step [20800/6235], Loss: 3.5695\n",
      "Epoch [87/100], Step [20900/6235], Loss: 42.9498\n",
      "Epoch [87/100], Step [21000/6235], Loss: 16.0833\n",
      "Epoch [87/100], Step [21100/6235], Loss: 3.6704\n",
      "Epoch [87/100], Step [21200/6235], Loss: 0.1561\n",
      "Epoch [87/100], Step [21300/6235], Loss: 0.1654\n",
      "Epoch [87/100], Step [21400/6235], Loss: 5.8195\n",
      "Epoch [87/100], Step [21500/6235], Loss: 0.8019\n",
      "Epoch [87/100], Step [21600/6235], Loss: 31.7600\n",
      "Epoch [87/100], Step [21700/6235], Loss: 0.2354\n",
      "Epoch [87/100], Step [21800/6235], Loss: 0.2186\n",
      "Epoch [87/100], Step [21900/6235], Loss: 0.1924\n",
      "Epoch [87/100], Step [22000/6235], Loss: 2.7201\n",
      "Epoch [87/100], Step [22100/6235], Loss: 4.3758\n",
      "Epoch [87/100], Step [22200/6235], Loss: 7.2318\n",
      "Epoch [87/100], Step [22300/6235], Loss: 0.3446\n",
      "Epoch [87/100], Step [22400/6235], Loss: 0.7092\n",
      "Epoch [87/100], Step [22500/6235], Loss: 122.1983\n",
      "Epoch [87/100], Step [22600/6235], Loss: 20.6869\n",
      "Epoch [87/100], Step [22700/6235], Loss: 2.2939\n",
      "Epoch [87/100], Step [22800/6235], Loss: 11.2631\n",
      "Epoch [87/100], Step [22900/6235], Loss: 12.1297\n",
      "Epoch [87/100], Step [23000/6235], Loss: 16.2868\n",
      "Epoch [87/100], Step [23100/6235], Loss: 0.6697\n",
      "Epoch [87/100], Step [23200/6235], Loss: 37.2778\n",
      "Epoch [87/100], Step [23300/6235], Loss: 15.7220\n",
      "Epoch [87/100], Step [23400/6235], Loss: 0.2289\n",
      "Epoch [87/100], Step [23500/6235], Loss: 0.3333\n",
      "Epoch [87/100], Step [23600/6235], Loss: 88.5195\n",
      "Epoch [87/100], Step [23700/6235], Loss: 4.8745\n",
      "Epoch [87/100], Step [23800/6235], Loss: 0.6075\n",
      "Epoch [87/100], Step [23900/6235], Loss: 7.9571\n",
      "Epoch [87/100], Step [24000/6235], Loss: 0.9734\n",
      "Epoch [87/100], Step [24100/6235], Loss: 1.2404\n",
      "Epoch [87/100], Step [24200/6235], Loss: 6.6518\n",
      "Epoch [87/100], Step [24300/6235], Loss: 1.5582\n",
      "Epoch [87/100], Step [24400/6235], Loss: 4.6901\n",
      "Epoch [87/100], Step [24500/6235], Loss: 2.6893\n",
      "Epoch [87/100], Step [24600/6235], Loss: 0.1291\n",
      "Epoch [87/100], Step [24700/6235], Loss: 3.8013\n",
      "Epoch [87/100], Step [24800/6235], Loss: 0.0671\n",
      "Epoch [87/100], Step [24900/6235], Loss: 7.6689\n",
      "Epoch [87/100], Step [25000/6235], Loss: 19.6710\n",
      "Epoch [87/100], Step [25100/6235], Loss: 7.5891\n",
      "Epoch [87/100], Step [25200/6235], Loss: 1.9872\n",
      "Epoch [87/100], Step [25300/6235], Loss: 0.9036\n",
      "Epoch [87/100], Step [25400/6235], Loss: 10.1389\n",
      "Epoch [87/100], Step [25500/6235], Loss: 3.9151\n",
      "Epoch [87/100], Step [25600/6235], Loss: 1.3483\n",
      "Epoch [87/100], Step [25700/6235], Loss: 0.2136\n",
      "Epoch [87/100], Step [25800/6235], Loss: 0.1463\n",
      "Epoch [87/100], Step [25900/6235], Loss: 10.3918\n",
      "Epoch [87/100], Step [26000/6235], Loss: 1.7124\n",
      "Epoch [87/100], Step [26100/6235], Loss: 0.3351\n",
      "Epoch [87/100], Step [26200/6235], Loss: 0.0730\n",
      "Epoch [87/100], Step [26300/6235], Loss: 4.5070\n",
      "Epoch [87/100], Step [26400/6235], Loss: 0.1845\n",
      "Epoch [87/100], Step [26500/6235], Loss: 0.3465\n",
      "Epoch [87/100], Step [26600/6235], Loss: 4.0129\n",
      "Epoch [87/100], Step [26700/6235], Loss: 0.7875\n",
      "Epoch [87/100], Step [26800/6235], Loss: 0.9470\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Step [26900/6235], Loss: 0.0869\n",
      "Epoch [87/100], Step [27000/6235], Loss: 11.1872\n",
      "Epoch [87/100], Step [27100/6235], Loss: 0.3137\n",
      "Epoch [87/100], Step [27200/6235], Loss: 0.1195\n",
      "Epoch [87/100], Step [27300/6235], Loss: 0.1359\n",
      "Epoch [87/100], Step [27400/6235], Loss: 1.0216\n",
      "Epoch [87/100], Step [27500/6235], Loss: 11.6364\n",
      "Epoch [87/100], Step [27600/6235], Loss: 0.4422\n",
      "Epoch [87/100], Step [27700/6235], Loss: 1.5078\n",
      "Epoch [87/100], Step [27800/6235], Loss: 0.3589\n",
      "Epoch [87/100], Step [27900/6235], Loss: 0.1495\n",
      "Epoch [87/100], Step [28000/6235], Loss: 161.9106\n",
      "Epoch [87/100], Step [28100/6235], Loss: 1.7628\n",
      "Epoch [87/100], Step [28200/6235], Loss: 30.0844\n",
      "Epoch [87/100], Step [28300/6235], Loss: 3.6394\n",
      "Epoch [87/100], Step [28400/6235], Loss: 25.0644\n",
      "Epoch [87/100], Step [28500/6235], Loss: 1.9003\n",
      "Epoch [87/100], Step [28600/6235], Loss: 0.3842\n",
      "Epoch [87/100], Step [28700/6235], Loss: 4.6984\n",
      "Epoch [87/100], Step [28800/6235], Loss: 0.4144\n",
      "Epoch [87/100], Step [28900/6235], Loss: 72.3672\n",
      "Epoch [87/100], Step [29000/6235], Loss: 10.5980\n",
      "Epoch [87/100], Step [29100/6235], Loss: 0.0251\n",
      "Epoch [87/100], Step [29200/6235], Loss: 0.0350\n",
      "Epoch [87/100], Step [29300/6235], Loss: 9.9666\n",
      "Epoch [87/100], Step [29400/6235], Loss: 0.2801\n",
      "Epoch [87/100], Step [29500/6235], Loss: 4.8454\n",
      "Epoch [87/100], Step [29600/6235], Loss: 0.5608\n",
      "Epoch [87/100], Step [29700/6235], Loss: 0.2592\n",
      "Epoch [87/100], Step [29800/6235], Loss: 1.6716\n",
      "Epoch [87/100], Step [29900/6235], Loss: 0.3100\n",
      "Epoch [87/100], Step [30000/6235], Loss: 6.2449\n",
      "Epoch [87/100], Step [30100/6235], Loss: 9.4399\n",
      "Epoch [87/100], Step [30200/6235], Loss: 0.0414\n",
      "Epoch [87/100], Step [30300/6235], Loss: 0.6149\n",
      "Epoch [87/100], Step [30400/6235], Loss: 0.1617\n",
      "Epoch [87/100], Step [30500/6235], Loss: 1.8601\n",
      "Epoch [87/100], Step [30600/6235], Loss: 0.4938\n",
      "Epoch [87/100], Step [30700/6235], Loss: 0.1780\n",
      "Epoch [87/100], Step [30800/6235], Loss: 0.2318\n",
      "Epoch [87/100], Step [30900/6235], Loss: 2.7928\n",
      "Epoch [87/100], Step [31000/6235], Loss: 0.0406\n",
      "Epoch [87/100], Step [31100/6235], Loss: 0.0508\n",
      "Epoch [87/100], Step [31200/6235], Loss: 7.5792\n",
      "Epoch [87/100], Step [31300/6235], Loss: 2.0972\n",
      "Epoch [87/100], Step [31400/6235], Loss: 1.6210\n",
      "Epoch [87/100], Step [31500/6235], Loss: 0.6594\n",
      "Epoch [87/100], Step [31600/6235], Loss: 5.5876\n",
      "Epoch [87/100], Step [31700/6235], Loss: 2.4065\n",
      "Epoch [87/100], Step [31800/6235], Loss: 1.6411\n",
      "Epoch [87/100], Step [31900/6235], Loss: 45.1762\n",
      "Epoch [87/100], Step [32000/6235], Loss: 70.7256\n",
      "Epoch [87/100], Step [32100/6235], Loss: 4.2784\n",
      "Epoch [87/100], Step [32200/6235], Loss: 66.9430\n",
      "Epoch [87/100], Step [32300/6235], Loss: 0.1517\n",
      "Epoch [87/100], Step [32400/6235], Loss: 0.4045\n",
      "Epoch [87/100], Step [32500/6235], Loss: 22.2502\n",
      "Epoch [87/100], Step [32600/6235], Loss: 0.9083\n",
      "Epoch [87/100], Step [32700/6235], Loss: 87.3450\n",
      "Epoch [87/100], Step [32800/6235], Loss: 18.8845\n",
      "Epoch [87/100], Step [32900/6235], Loss: 4.9321\n",
      "Epoch [87/100], Step [33000/6235], Loss: 0.2949\n",
      "Epoch [87/100], Step [33100/6235], Loss: 0.8180\n",
      "Epoch [87/100], Step [33200/6235], Loss: 1.2696\n",
      "Epoch [87/100], Step [33300/6235], Loss: 9.7158\n",
      "Epoch [87/100], Step [33400/6235], Loss: 39.4128\n",
      "Epoch [87/100], Step [33500/6235], Loss: 0.5773\n",
      "Epoch [87/100], Step [33600/6235], Loss: 3.7614\n",
      "Epoch [87/100], Step [33700/6235], Loss: 7.6628\n",
      "Epoch [87/100], Step [33800/6235], Loss: 0.8335\n",
      "Epoch [87/100], Step [33900/6235], Loss: 27.5278\n",
      "Epoch [87/100], Step [34000/6235], Loss: 0.0172\n",
      "Epoch [87/100], Step [34100/6235], Loss: 0.3601\n",
      "Epoch [87/100], Step [34200/6235], Loss: 2.6910\n",
      "Epoch [87/100], Step [34300/6235], Loss: 5.4524\n",
      "Epoch [87/100], Step [34400/6235], Loss: 0.2068\n",
      "Epoch [87/100], Step [34500/6235], Loss: 69.6813\n",
      "Epoch [87/100], Step [34600/6235], Loss: 0.1626\n",
      "Epoch [87/100], Step [34700/6235], Loss: 9.8749\n",
      "Epoch [87/100], Step [34800/6235], Loss: 15.2571\n",
      "Epoch [87/100], Step [34900/6235], Loss: 68.5536\n",
      "Epoch [87/100], Step [35000/6235], Loss: 0.5851\n",
      "Epoch [87/100], Step [35100/6235], Loss: 0.5369\n",
      "Epoch [87/100], Step [35200/6235], Loss: 0.2194\n",
      "Epoch [87/100], Step [35300/6235], Loss: 2.7035\n",
      "Epoch [87/100], Step [35400/6235], Loss: 0.4152\n",
      "Epoch [87/100], Step [35500/6235], Loss: 1.8695\n",
      "Epoch [87/100], Step [35600/6235], Loss: 1.9714\n",
      "Epoch [87/100], Step [35700/6235], Loss: 5.9233\n",
      "Epoch [87/100], Step [35800/6235], Loss: 7.7855\n",
      "Epoch [87/100], Step [35900/6235], Loss: 0.3450\n",
      "Epoch [87/100], Step [36000/6235], Loss: 0.1629\n",
      "Epoch [87/100], Step [36100/6235], Loss: 0.0597\n",
      "Epoch [87/100], Step [36200/6235], Loss: 12.0872\n",
      "Epoch [87/100], Step [36300/6235], Loss: 1.5543\n",
      "Epoch [87/100], Step [36400/6235], Loss: 2.5388\n",
      "Epoch [87/100], Step [36500/6235], Loss: 8.8697\n",
      "Epoch [87/100], Step [36600/6235], Loss: 0.1321\n",
      "Epoch [87/100], Step [36700/6235], Loss: 0.3827\n",
      "Epoch [87/100], Step [36800/6235], Loss: 12.6575\n",
      "Epoch [87/100], Step [36900/6235], Loss: 6.6418\n",
      "Epoch [87/100], Step [37000/6235], Loss: 0.3881\n",
      "Epoch [87/100], Step [37100/6235], Loss: 1.0896\n",
      "Epoch [87/100], Step [37200/6235], Loss: 0.0823\n",
      "Epoch [87/100], Step [37300/6235], Loss: 0.0491\n",
      "Epoch [87/100], Step [37400/6235], Loss: 0.2021\n",
      "Epoch [87/100], Step [37500/6235], Loss: 4.4662\n",
      "Epoch [87/100], Step [37600/6235], Loss: 11.7101\n",
      "Epoch [87/100], Step [37700/6235], Loss: 1.4256\n",
      "Epoch [87/100], Step [37800/6235], Loss: 6.0637\n",
      "Epoch [87/100], Step [37900/6235], Loss: 6.4996\n",
      "Epoch [87/100], Step [38000/6235], Loss: 0.1046\n",
      "Epoch [87/100], Step [38100/6235], Loss: 2.4179\n",
      "Epoch [87/100], Step [38200/6235], Loss: 2.0933\n",
      "Epoch [87/100], Step [38300/6235], Loss: 0.6218\n",
      "Epoch [87/100], Step [38400/6235], Loss: 0.1251\n",
      "Epoch [87/100], Step [38500/6235], Loss: 2.4857\n",
      "Epoch [87/100], Step [38600/6235], Loss: 0.1787\n",
      "Epoch [87/100], Step [38700/6235], Loss: 0.1170\n",
      "Epoch [87/100], Step [38800/6235], Loss: 0.2010\n",
      "Epoch [87/100], Step [38900/6235], Loss: 0.9506\n",
      "Epoch [87/100], Step [39000/6235], Loss: 16.0906\n",
      "Epoch [87/100], Step [39100/6235], Loss: 7.9075\n",
      "Epoch [87/100], Step [39200/6235], Loss: 6.0734\n",
      "Epoch [87/100], Step [39300/6235], Loss: 6.1263\n",
      "Epoch [87/100], Step [39400/6235], Loss: 30.0148\n",
      "Epoch [87/100], Step [39500/6235], Loss: 69.5764\n",
      "Epoch [87/100], Step [39600/6235], Loss: 1.2989\n",
      "Epoch [87/100], Step [39700/6235], Loss: 85.5400\n",
      "Epoch [87/100], Step [39800/6235], Loss: 108.7785\n",
      "Epoch [87/100], Step [39900/6235], Loss: 30.4167\n",
      "Epoch [87/100], Step [40000/6235], Loss: 0.8923\n",
      "Epoch [87/100], Step [40100/6235], Loss: 3.7170\n",
      "Epoch [87/100], Step [40200/6235], Loss: 25.0467\n",
      "Epoch [87/100], Step [40300/6235], Loss: 0.5969\n",
      "Epoch [87/100], Step [40400/6235], Loss: 0.0520\n",
      "Epoch [87/100], Step [40500/6235], Loss: 3.7671\n",
      "Epoch [87/100], Step [40600/6235], Loss: 0.3985\n",
      "Epoch [87/100], Step [40700/6235], Loss: 4.0712\n",
      "Epoch [87/100], Step [40800/6235], Loss: 2.0981\n",
      "Epoch [87/100], Step [40900/6235], Loss: 1.3672\n",
      "Epoch [87/100], Step [41000/6235], Loss: 35.3163\n",
      "Epoch [87/100], Step [41100/6235], Loss: 18.4077\n",
      "Epoch [87/100], Step [41200/6235], Loss: 11.7957\n",
      "Epoch [87/100], Step [41300/6235], Loss: 0.1539\n",
      "Epoch [87/100], Step [41400/6235], Loss: 0.1112\n",
      "Epoch [87/100], Step [41500/6235], Loss: 24.1890\n",
      "Epoch [87/100], Step [41600/6235], Loss: 3.9244\n",
      "Epoch [87/100], Step [41700/6235], Loss: 0.1230\n",
      "Epoch [87/100], Step [41800/6235], Loss: 0.4709\n",
      "Epoch [87/100], Step [41900/6235], Loss: 3.9538\n",
      "Epoch [87/100], Step [42000/6235], Loss: 3.9085\n",
      "Epoch [87/100], Step [42100/6235], Loss: 12.2373\n",
      "Epoch [87/100], Step [42200/6235], Loss: 62.2604\n",
      "Epoch [87/100], Step [42300/6235], Loss: 0.1481\n",
      "Epoch [87/100], Step [42400/6235], Loss: 2.6074\n",
      "Epoch [87/100], Step [42500/6235], Loss: 1.5493\n",
      "Epoch [87/100], Step [42600/6235], Loss: 0.6030\n",
      "Epoch [87/100], Step [42700/6235], Loss: 0.2885\n",
      "Epoch [87/100], Step [42800/6235], Loss: 16.3447\n",
      "Epoch [87/100], Step [42900/6235], Loss: 0.0927\n",
      "Epoch [87/100], Step [43000/6235], Loss: 0.5338\n",
      "Epoch [87/100], Step [43100/6235], Loss: 0.0705\n",
      "Epoch [87/100], Step [43200/6235], Loss: 0.0618\n",
      "Epoch [87/100], Step [43300/6235], Loss: 4.0772\n",
      "Epoch [87/100], Step [43400/6235], Loss: 3.9826\n",
      "Epoch [87/100], Step [43500/6235], Loss: 12.3908\n",
      "Epoch [87/100], Step [43600/6235], Loss: 1.1494\n",
      "Epoch [87/100], Step [43700/6235], Loss: 44.7480\n",
      "Epoch [87/100], Step [43800/6235], Loss: 0.4823\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [87/100], Step [43900/6235], Loss: 4.7159\n",
      "Epoch [87/100], Step [44000/6235], Loss: 88.2635\n",
      "Epoch [87/100], Step [44100/6235], Loss: 0.6567\n",
      "Epoch [87/100], Step [44200/6235], Loss: 3.0368\n",
      "Epoch [87/100], Step [44300/6235], Loss: 56.3093\n",
      "Epoch [87/100], Step [44400/6235], Loss: 2.5718\n",
      "Epoch [87/100], Step [44500/6235], Loss: 1.2117\n",
      "Epoch [87/100], Step [44600/6235], Loss: 11.8086\n",
      "Epoch [87/100], Step [44700/6235], Loss: 9.4488\n",
      "Epoch [87/100], Step [44800/6235], Loss: 1.9250\n",
      "Epoch [87/100], Step [44900/6235], Loss: 11.3236\n",
      "Epoch [87/100], Step [45000/6235], Loss: 5.9139\n",
      "Epoch [87/100], Step [45100/6235], Loss: 44.4384\n",
      "Epoch [87/100], Step [45200/6235], Loss: 2.3805\n",
      "Epoch [87/100], Step [45300/6235], Loss: 23.8277\n",
      "Epoch [87/100], Step [45400/6235], Loss: 4.0225\n",
      "Epoch [87/100], Step [45500/6235], Loss: 3.2262\n",
      "Epoch [87/100], Step [45600/6235], Loss: 1.4531\n",
      "Epoch [87/100], Step [45700/6235], Loss: 127.1444\n",
      "Epoch [87/100], Step [45800/6235], Loss: 399.4332\n",
      "Epoch [87/100], Step [45900/6235], Loss: 18.2207\n",
      "Epoch [87/100], Step [46000/6235], Loss: 29.9954\n",
      "Epoch [87/100], Step [46100/6235], Loss: 29.7855\n",
      "Epoch [87/100], Step [46200/6235], Loss: 60.3781\n",
      "Epoch [87/100], Step [46300/6235], Loss: 129.7437\n",
      "Epoch [87/100], Step [46400/6235], Loss: 9.6426\n",
      "Epoch [87/100], Step [46500/6235], Loss: 67.7530\n",
      "Epoch [87/100], Step [46600/6235], Loss: 8.6464\n",
      "Epoch [87/100], Step [46700/6235], Loss: 31.1523\n",
      "Epoch [87/100], Step [46800/6235], Loss: 1.4757\n",
      "Epoch [87/100], Step [46900/6235], Loss: 0.9902\n",
      "Epoch [87/100], Step [47000/6235], Loss: 8.1185\n",
      "Epoch [87/100], Step [47100/6235], Loss: 1.9158\n",
      "Epoch [87/100], Step [47200/6235], Loss: 25.2877\n",
      "Epoch [87/100], Step [47300/6235], Loss: 1.2204\n",
      "Epoch [87/100], Step [47400/6235], Loss: 26.0671\n",
      "Epoch [87/100], Step [47500/6235], Loss: 8.5213\n",
      "Epoch [87/100], Step [47600/6235], Loss: 2.9412\n",
      "Epoch [87/100], Step [47700/6235], Loss: 9.0346\n",
      "Epoch [87/100], Step [47800/6235], Loss: 9.4297\n",
      "Epoch [87/100], Step [47900/6235], Loss: 18.2880\n",
      "Epoch [87/100], Step [48000/6235], Loss: 82.7875\n",
      "Epoch [87/100], Step [48100/6235], Loss: 4.7855\n",
      "Epoch [87/100], Step [48200/6235], Loss: 7.4009\n",
      "Epoch [87/100], Step [48300/6235], Loss: 345.3531\n",
      "Epoch [87/100], Step [48400/6235], Loss: 17.8270\n",
      "Epoch [87/100], Step [48500/6235], Loss: 21.6842\n",
      "Epoch [87/100], Step [48600/6235], Loss: 151.6875\n",
      "Epoch [87/100], Step [48700/6235], Loss: 5.9092\n",
      "Epoch [87/100], Step [48800/6235], Loss: 306.1211\n",
      "Epoch [87/100], Step [48900/6235], Loss: 43.4740\n",
      "Epoch [87/100], Step [49000/6235], Loss: 268.9203\n",
      "Epoch [87/100], Step [49100/6235], Loss: 1478.1045\n",
      "Epoch [87/100], Step [49200/6235], Loss: 1085.8519\n",
      "Epoch [87/100], Step [49300/6235], Loss: 1158.1449\n",
      "Epoch [87/100], Step [49400/6235], Loss: 4.3882\n",
      "Epoch [87/100], Step [49500/6235], Loss: 14.6429\n",
      "Epoch [87/100], Step [49600/6235], Loss: 680.7892\n",
      "Epoch [87/100], Step [49700/6235], Loss: 4175.4185\n",
      "Epoch [87/100], Step [49800/6235], Loss: 324.3886\n",
      "Epoch [88/100], Step [100/6235], Loss: 35.4901\n",
      "Epoch [88/100], Step [200/6235], Loss: 0.3078\n",
      "Epoch [88/100], Step [300/6235], Loss: 0.0220\n",
      "Epoch [88/100], Step [400/6235], Loss: 0.0139\n",
      "Epoch [88/100], Step [500/6235], Loss: 2.7403\n",
      "Epoch [88/100], Step [600/6235], Loss: 0.0489\n",
      "Epoch [88/100], Step [700/6235], Loss: 0.2564\n",
      "Epoch [88/100], Step [800/6235], Loss: 0.0826\n",
      "Epoch [88/100], Step [900/6235], Loss: 0.0257\n",
      "Epoch [88/100], Step [1000/6235], Loss: 0.0352\n",
      "Epoch [88/100], Step [1100/6235], Loss: 0.4174\n",
      "Epoch [88/100], Step [1200/6235], Loss: 0.1474\n",
      "Epoch [88/100], Step [1300/6235], Loss: 0.0558\n",
      "Epoch [88/100], Step [1400/6235], Loss: 0.6701\n",
      "Epoch [88/100], Step [1500/6235], Loss: 0.0049\n",
      "Epoch [88/100], Step [1600/6235], Loss: 0.2067\n",
      "Epoch [88/100], Step [1700/6235], Loss: 0.0740\n",
      "Epoch [88/100], Step [1800/6235], Loss: 0.2297\n",
      "Epoch [88/100], Step [1900/6235], Loss: 0.8685\n",
      "Epoch [88/100], Step [2000/6235], Loss: 2.3155\n",
      "Epoch [88/100], Step [2100/6235], Loss: 1.0633\n",
      "Epoch [88/100], Step [2200/6235], Loss: 11.1329\n",
      "Epoch [88/100], Step [2300/6235], Loss: 22.8705\n",
      "Epoch [88/100], Step [2400/6235], Loss: 11.7652\n",
      "Epoch [88/100], Step [2500/6235], Loss: 40.0676\n",
      "Epoch [88/100], Step [2600/6235], Loss: 8.4324\n",
      "Epoch [88/100], Step [2700/6235], Loss: 23.0561\n",
      "Epoch [88/100], Step [2800/6235], Loss: 158.2563\n",
      "Epoch [88/100], Step [2900/6235], Loss: 7.6511\n",
      "Epoch [88/100], Step [3000/6235], Loss: 0.0519\n",
      "Epoch [88/100], Step [3100/6235], Loss: 72.5127\n",
      "Epoch [88/100], Step [3200/6235], Loss: 86.2168\n",
      "Epoch [88/100], Step [3300/6235], Loss: 3.5306\n",
      "Epoch [88/100], Step [3400/6235], Loss: 2.0379\n",
      "Epoch [88/100], Step [3500/6235], Loss: 27.2428\n",
      "Epoch [88/100], Step [3600/6235], Loss: 10.3261\n",
      "Epoch [88/100], Step [3700/6235], Loss: 0.3438\n",
      "Epoch [88/100], Step [3800/6235], Loss: 0.4793\n",
      "Epoch [88/100], Step [3900/6235], Loss: 1.4968\n",
      "Epoch [88/100], Step [4000/6235], Loss: 0.0342\n",
      "Epoch [88/100], Step [4100/6235], Loss: 5.5929\n",
      "Epoch [88/100], Step [4200/6235], Loss: 0.2755\n",
      "Epoch [88/100], Step [4300/6235], Loss: 8.3645\n",
      "Epoch [88/100], Step [4400/6235], Loss: 4.4378\n",
      "Epoch [88/100], Step [4500/6235], Loss: 44.2401\n",
      "Epoch [88/100], Step [4600/6235], Loss: 5.5465\n",
      "Epoch [88/100], Step [4700/6235], Loss: 0.5288\n",
      "Epoch [88/100], Step [4800/6235], Loss: 6.5297\n",
      "Epoch [88/100], Step [4900/6235], Loss: 0.0745\n",
      "Epoch [88/100], Step [5000/6235], Loss: 0.0599\n",
      "Epoch [88/100], Step [5100/6235], Loss: 2.7773\n",
      "Epoch [88/100], Step [5200/6235], Loss: 0.5658\n",
      "Epoch [88/100], Step [5300/6235], Loss: 38.4892\n",
      "Epoch [88/100], Step [5400/6235], Loss: 1.2075\n",
      "Epoch [88/100], Step [5500/6235], Loss: 0.0853\n",
      "Epoch [88/100], Step [5600/6235], Loss: 0.3871\n",
      "Epoch [88/100], Step [5700/6235], Loss: 0.6033\n",
      "Epoch [88/100], Step [5800/6235], Loss: 0.2926\n",
      "Epoch [88/100], Step [5900/6235], Loss: 0.1504\n",
      "Epoch [88/100], Step [6000/6235], Loss: 2.4401\n",
      "Epoch [88/100], Step [6100/6235], Loss: 0.1799\n",
      "Epoch [88/100], Step [6200/6235], Loss: 1.8309\n",
      "Epoch [88/100], Step [6300/6235], Loss: 1.8239\n",
      "Epoch [88/100], Step [6400/6235], Loss: 0.0050\n",
      "Epoch [88/100], Step [6500/6235], Loss: 1.3686\n",
      "Epoch [88/100], Step [6600/6235], Loss: 3.2119\n",
      "Epoch [88/100], Step [6700/6235], Loss: 3.1343\n",
      "Epoch [88/100], Step [6800/6235], Loss: 0.1041\n",
      "Epoch [88/100], Step [6900/6235], Loss: 1.0282\n",
      "Epoch [88/100], Step [7000/6235], Loss: 0.3461\n",
      "Epoch [88/100], Step [7100/6235], Loss: 0.2467\n",
      "Epoch [88/100], Step [7200/6235], Loss: 0.1290\n",
      "Epoch [88/100], Step [7300/6235], Loss: 1.7527\n",
      "Epoch [88/100], Step [7400/6235], Loss: 0.0044\n",
      "Epoch [88/100], Step [7500/6235], Loss: 1.0601\n",
      "Epoch [88/100], Step [7600/6235], Loss: 5.1306\n",
      "Epoch [88/100], Step [7700/6235], Loss: 8.6385\n",
      "Epoch [88/100], Step [7800/6235], Loss: 1.1501\n",
      "Epoch [88/100], Step [7900/6235], Loss: 0.7482\n",
      "Epoch [88/100], Step [8000/6235], Loss: 0.1479\n",
      "Epoch [88/100], Step [8100/6235], Loss: 3.3126\n",
      "Epoch [88/100], Step [8200/6235], Loss: 10.5914\n",
      "Epoch [88/100], Step [8300/6235], Loss: 21.7340\n",
      "Epoch [88/100], Step [8400/6235], Loss: 334.1259\n",
      "Epoch [88/100], Step [8500/6235], Loss: 3.7972\n",
      "Epoch [88/100], Step [8600/6235], Loss: 29.8481\n",
      "Epoch [88/100], Step [8700/6235], Loss: 30.9959\n",
      "Epoch [88/100], Step [8800/6235], Loss: 667.2391\n",
      "Epoch [88/100], Step [8900/6235], Loss: 100.9534\n",
      "Epoch [88/100], Step [9000/6235], Loss: 634.3906\n",
      "Epoch [88/100], Step [9100/6235], Loss: 3032.3425\n",
      "Epoch [88/100], Step [9200/6235], Loss: 4673.2896\n",
      "Epoch [88/100], Step [9300/6235], Loss: 67.3622\n",
      "Epoch [88/100], Step [9400/6235], Loss: 13.7516\n",
      "Epoch [88/100], Step [9500/6235], Loss: 336.7522\n",
      "Epoch [88/100], Step [9600/6235], Loss: 1162.4022\n",
      "Epoch [88/100], Step [9700/6235], Loss: 8.6097\n",
      "Epoch [88/100], Step [9800/6235], Loss: 1610.5327\n",
      "Epoch [88/100], Step [9900/6235], Loss: 12.5501\n",
      "Epoch [88/100], Step [10000/6235], Loss: 91.4041\n",
      "Epoch [88/100], Step [10100/6235], Loss: 2.6039\n",
      "Epoch [88/100], Step [10200/6235], Loss: 1169.2230\n",
      "Epoch [88/100], Step [10300/6235], Loss: 23.7106\n",
      "Epoch [88/100], Step [10400/6235], Loss: 9.6331\n",
      "Epoch [88/100], Step [10500/6235], Loss: 192.4502\n",
      "Epoch [88/100], Step [10600/6235], Loss: 740.8929\n",
      "Epoch [88/100], Step [10700/6235], Loss: 44.4255\n",
      "Epoch [88/100], Step [10800/6235], Loss: 43.0593\n",
      "Epoch [88/100], Step [10900/6235], Loss: 125.5401\n",
      "Epoch [88/100], Step [11000/6235], Loss: 292.4254\n",
      "Epoch [88/100], Step [11100/6235], Loss: 13.1243\n",
      "Epoch [88/100], Step [11200/6235], Loss: 0.9753\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Step [11300/6235], Loss: 96.2720\n",
      "Epoch [88/100], Step [11400/6235], Loss: 37.1521\n",
      "Epoch [88/100], Step [11500/6235], Loss: 11.6664\n",
      "Epoch [88/100], Step [11600/6235], Loss: 8.9014\n",
      "Epoch [88/100], Step [11700/6235], Loss: 53.2000\n",
      "Epoch [88/100], Step [11800/6235], Loss: 404.2869\n",
      "Epoch [88/100], Step [11900/6235], Loss: 379.6418\n",
      "Epoch [88/100], Step [12000/6235], Loss: 657.1872\n",
      "Epoch [88/100], Step [12100/6235], Loss: 275.3315\n",
      "Epoch [88/100], Step [12200/6235], Loss: 72.8751\n",
      "Epoch [88/100], Step [12300/6235], Loss: 13.7869\n",
      "Epoch [88/100], Step [12400/6235], Loss: 417.6133\n",
      "Epoch [88/100], Step [12500/6235], Loss: 161.8837\n",
      "Epoch [88/100], Step [12600/6235], Loss: 0.8073\n",
      "Epoch [88/100], Step [12700/6235], Loss: 7.0952\n",
      "Epoch [88/100], Step [12800/6235], Loss: 9.8908\n",
      "Epoch [88/100], Step [12900/6235], Loss: 31.8775\n",
      "Epoch [88/100], Step [13000/6235], Loss: 0.1112\n",
      "Epoch [88/100], Step [13100/6235], Loss: 62.1243\n",
      "Epoch [88/100], Step [13200/6235], Loss: 8.0128\n",
      "Epoch [88/100], Step [13300/6235], Loss: 18.8685\n",
      "Epoch [88/100], Step [13400/6235], Loss: 197.9841\n",
      "Epoch [88/100], Step [13500/6235], Loss: 3.7787\n",
      "Epoch [88/100], Step [13600/6235], Loss: 14.3648\n",
      "Epoch [88/100], Step [13700/6235], Loss: 201.4383\n",
      "Epoch [88/100], Step [13800/6235], Loss: 72.7389\n",
      "Epoch [88/100], Step [13900/6235], Loss: 3.5217\n",
      "Epoch [88/100], Step [14000/6235], Loss: 1.8820\n",
      "Epoch [88/100], Step [14100/6235], Loss: 67.3504\n",
      "Epoch [88/100], Step [14200/6235], Loss: 0.9296\n",
      "Epoch [88/100], Step [14300/6235], Loss: 2.2085\n",
      "Epoch [88/100], Step [14400/6235], Loss: 29.6186\n",
      "Epoch [88/100], Step [14500/6235], Loss: 22.1943\n",
      "Epoch [88/100], Step [14600/6235], Loss: 3.2777\n",
      "Epoch [88/100], Step [14700/6235], Loss: 13.4633\n",
      "Epoch [88/100], Step [14800/6235], Loss: 20.5172\n",
      "Epoch [88/100], Step [14900/6235], Loss: 0.8629\n",
      "Epoch [88/100], Step [15000/6235], Loss: 0.4928\n",
      "Epoch [88/100], Step [15100/6235], Loss: 0.0996\n",
      "Epoch [88/100], Step [15200/6235], Loss: 39.6522\n",
      "Epoch [88/100], Step [15300/6235], Loss: 36.0569\n",
      "Epoch [88/100], Step [15400/6235], Loss: 64.5679\n",
      "Epoch [88/100], Step [15500/6235], Loss: 17.1137\n",
      "Epoch [88/100], Step [15600/6235], Loss: 186.9268\n",
      "Epoch [88/100], Step [15700/6235], Loss: 85.8919\n",
      "Epoch [88/100], Step [15800/6235], Loss: 2.5543\n",
      "Epoch [88/100], Step [15900/6235], Loss: 1.6934\n",
      "Epoch [88/100], Step [16000/6235], Loss: 205.1389\n",
      "Epoch [88/100], Step [16100/6235], Loss: 2.4619\n",
      "Epoch [88/100], Step [16200/6235], Loss: 0.5034\n",
      "Epoch [88/100], Step [16300/6235], Loss: 9.1005\n",
      "Epoch [88/100], Step [16400/6235], Loss: 23.8572\n",
      "Epoch [88/100], Step [16500/6235], Loss: 450.8799\n",
      "Epoch [88/100], Step [16600/6235], Loss: 22.5532\n",
      "Epoch [88/100], Step [16700/6235], Loss: 0.2978\n",
      "Epoch [88/100], Step [16800/6235], Loss: 14.6301\n",
      "Epoch [88/100], Step [16900/6235], Loss: 0.1980\n",
      "Epoch [88/100], Step [17000/6235], Loss: 0.2750\n",
      "Epoch [88/100], Step [17100/6235], Loss: 0.1595\n",
      "Epoch [88/100], Step [17200/6235], Loss: 274.2042\n",
      "Epoch [88/100], Step [17300/6235], Loss: 21.7081\n",
      "Epoch [88/100], Step [17400/6235], Loss: 32.0368\n",
      "Epoch [88/100], Step [17500/6235], Loss: 1.5675\n",
      "Epoch [88/100], Step [17600/6235], Loss: 2.7223\n",
      "Epoch [88/100], Step [17700/6235], Loss: 1.1815\n",
      "Epoch [88/100], Step [17800/6235], Loss: 24.4676\n",
      "Epoch [88/100], Step [17900/6235], Loss: 2.6352\n",
      "Epoch [88/100], Step [18000/6235], Loss: 15.0413\n",
      "Epoch [88/100], Step [18100/6235], Loss: 18.4044\n",
      "Epoch [88/100], Step [18200/6235], Loss: 0.7018\n",
      "Epoch [88/100], Step [18300/6235], Loss: 4.5340\n",
      "Epoch [88/100], Step [18400/6235], Loss: 3.1560\n",
      "Epoch [88/100], Step [18500/6235], Loss: 12.4563\n",
      "Epoch [88/100], Step [18600/6235], Loss: 2.0650\n",
      "Epoch [88/100], Step [18700/6235], Loss: 0.3855\n",
      "Epoch [88/100], Step [18800/6235], Loss: 145.4544\n",
      "Epoch [88/100], Step [18900/6235], Loss: 71.8563\n",
      "Epoch [88/100], Step [19000/6235], Loss: 12.1032\n",
      "Epoch [88/100], Step [19100/6235], Loss: 8.1116\n",
      "Epoch [88/100], Step [19200/6235], Loss: 3.5240\n",
      "Epoch [88/100], Step [19300/6235], Loss: 7.4072\n",
      "Epoch [88/100], Step [19400/6235], Loss: 273.1631\n",
      "Epoch [88/100], Step [19500/6235], Loss: 157.7007\n",
      "Epoch [88/100], Step [19600/6235], Loss: 119.7949\n",
      "Epoch [88/100], Step [19700/6235], Loss: 19.7603\n",
      "Epoch [88/100], Step [19800/6235], Loss: 0.6072\n",
      "Epoch [88/100], Step [19900/6235], Loss: 1.5504\n",
      "Epoch [88/100], Step [20000/6235], Loss: 98.8975\n",
      "Epoch [88/100], Step [20100/6235], Loss: 10.1579\n",
      "Epoch [88/100], Step [20200/6235], Loss: 2.9886\n",
      "Epoch [88/100], Step [20300/6235], Loss: 0.5028\n",
      "Epoch [88/100], Step [20400/6235], Loss: 29.9359\n",
      "Epoch [88/100], Step [20500/6235], Loss: 27.7955\n",
      "Epoch [88/100], Step [20600/6235], Loss: 14.4819\n",
      "Epoch [88/100], Step [20700/6235], Loss: 34.3756\n",
      "Epoch [88/100], Step [20800/6235], Loss: 5.3100\n",
      "Epoch [88/100], Step [20900/6235], Loss: 34.3536\n",
      "Epoch [88/100], Step [21000/6235], Loss: 15.2372\n",
      "Epoch [88/100], Step [21100/6235], Loss: 4.8630\n",
      "Epoch [88/100], Step [21200/6235], Loss: 0.1896\n",
      "Epoch [88/100], Step [21300/6235], Loss: 0.1908\n",
      "Epoch [88/100], Step [21400/6235], Loss: 6.1667\n",
      "Epoch [88/100], Step [21500/6235], Loss: 0.8218\n",
      "Epoch [88/100], Step [21600/6235], Loss: 31.2271\n",
      "Epoch [88/100], Step [21700/6235], Loss: 0.2073\n",
      "Epoch [88/100], Step [21800/6235], Loss: 0.9579\n",
      "Epoch [88/100], Step [21900/6235], Loss: 0.3852\n",
      "Epoch [88/100], Step [22000/6235], Loss: 3.2862\n",
      "Epoch [88/100], Step [22100/6235], Loss: 3.8407\n",
      "Epoch [88/100], Step [22200/6235], Loss: 6.7350\n",
      "Epoch [88/100], Step [22300/6235], Loss: 0.2324\n",
      "Epoch [88/100], Step [22400/6235], Loss: 4.1312\n",
      "Epoch [88/100], Step [22500/6235], Loss: 187.3100\n",
      "Epoch [88/100], Step [22600/6235], Loss: 18.9344\n",
      "Epoch [88/100], Step [22700/6235], Loss: 2.2000\n",
      "Epoch [88/100], Step [22800/6235], Loss: 2.9997\n",
      "Epoch [88/100], Step [22900/6235], Loss: 2.6026\n",
      "Epoch [88/100], Step [23000/6235], Loss: 17.7406\n",
      "Epoch [88/100], Step [23100/6235], Loss: 6.6657\n",
      "Epoch [88/100], Step [23200/6235], Loss: 12.2588\n",
      "Epoch [88/100], Step [23300/6235], Loss: 18.4808\n",
      "Epoch [88/100], Step [23400/6235], Loss: 0.8495\n",
      "Epoch [88/100], Step [23500/6235], Loss: 0.2496\n",
      "Epoch [88/100], Step [23600/6235], Loss: 107.1287\n",
      "Epoch [88/100], Step [23700/6235], Loss: 3.1791\n",
      "Epoch [88/100], Step [23800/6235], Loss: 0.9886\n",
      "Epoch [88/100], Step [23900/6235], Loss: 7.8225\n",
      "Epoch [88/100], Step [24000/6235], Loss: 0.5909\n",
      "Epoch [88/100], Step [24100/6235], Loss: 0.6106\n",
      "Epoch [88/100], Step [24200/6235], Loss: 50.7968\n",
      "Epoch [88/100], Step [24300/6235], Loss: 1.1176\n",
      "Epoch [88/100], Step [24400/6235], Loss: 4.1284\n",
      "Epoch [88/100], Step [24500/6235], Loss: 2.1972\n",
      "Epoch [88/100], Step [24600/6235], Loss: 0.1209\n",
      "Epoch [88/100], Step [24700/6235], Loss: 3.0604\n",
      "Epoch [88/100], Step [24800/6235], Loss: 0.0810\n",
      "Epoch [88/100], Step [24900/6235], Loss: 4.3688\n",
      "Epoch [88/100], Step [25000/6235], Loss: 18.9459\n",
      "Epoch [88/100], Step [25100/6235], Loss: 8.3876\n",
      "Epoch [88/100], Step [25200/6235], Loss: 1.7635\n",
      "Epoch [88/100], Step [25300/6235], Loss: 0.7301\n",
      "Epoch [88/100], Step [25400/6235], Loss: 9.6576\n",
      "Epoch [88/100], Step [25500/6235], Loss: 5.0918\n",
      "Epoch [88/100], Step [25600/6235], Loss: 2.2196\n",
      "Epoch [88/100], Step [25700/6235], Loss: 0.3038\n",
      "Epoch [88/100], Step [25800/6235], Loss: 0.1548\n",
      "Epoch [88/100], Step [25900/6235], Loss: 10.3288\n",
      "Epoch [88/100], Step [26000/6235], Loss: 4.1572\n",
      "Epoch [88/100], Step [26100/6235], Loss: 0.4945\n",
      "Epoch [88/100], Step [26200/6235], Loss: 0.0441\n",
      "Epoch [88/100], Step [26300/6235], Loss: 4.7297\n",
      "Epoch [88/100], Step [26400/6235], Loss: 0.1695\n",
      "Epoch [88/100], Step [26500/6235], Loss: 0.2156\n",
      "Epoch [88/100], Step [26600/6235], Loss: 3.3252\n",
      "Epoch [88/100], Step [26700/6235], Loss: 0.6679\n",
      "Epoch [88/100], Step [26800/6235], Loss: 0.6547\n",
      "Epoch [88/100], Step [26900/6235], Loss: 0.0447\n",
      "Epoch [88/100], Step [27000/6235], Loss: 12.2969\n",
      "Epoch [88/100], Step [27100/6235], Loss: 0.1961\n",
      "Epoch [88/100], Step [27200/6235], Loss: 0.0765\n",
      "Epoch [88/100], Step [27300/6235], Loss: 0.1855\n",
      "Epoch [88/100], Step [27400/6235], Loss: 0.9355\n",
      "Epoch [88/100], Step [27500/6235], Loss: 17.6190\n",
      "Epoch [88/100], Step [27600/6235], Loss: 0.6413\n",
      "Epoch [88/100], Step [27700/6235], Loss: 1.3635\n",
      "Epoch [88/100], Step [27800/6235], Loss: 0.0922\n",
      "Epoch [88/100], Step [27900/6235], Loss: 0.3540\n",
      "Epoch [88/100], Step [28000/6235], Loss: 143.3460\n",
      "Epoch [88/100], Step [28100/6235], Loss: 1.4886\n",
      "Epoch [88/100], Step [28200/6235], Loss: 32.6554\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Step [28300/6235], Loss: 3.5328\n",
      "Epoch [88/100], Step [28400/6235], Loss: 23.3986\n",
      "Epoch [88/100], Step [28500/6235], Loss: 3.7837\n",
      "Epoch [88/100], Step [28600/6235], Loss: 0.3371\n",
      "Epoch [88/100], Step [28700/6235], Loss: 4.8538\n",
      "Epoch [88/100], Step [28800/6235], Loss: 0.4301\n",
      "Epoch [88/100], Step [28900/6235], Loss: 72.9221\n",
      "Epoch [88/100], Step [29000/6235], Loss: 7.3501\n",
      "Epoch [88/100], Step [29100/6235], Loss: 0.0109\n",
      "Epoch [88/100], Step [29200/6235], Loss: 0.0988\n",
      "Epoch [88/100], Step [29300/6235], Loss: 0.1417\n",
      "Epoch [88/100], Step [29400/6235], Loss: 0.9226\n",
      "Epoch [88/100], Step [29500/6235], Loss: 7.8886\n",
      "Epoch [88/100], Step [29600/6235], Loss: 0.7275\n",
      "Epoch [88/100], Step [29700/6235], Loss: 0.3644\n",
      "Epoch [88/100], Step [29800/6235], Loss: 1.7099\n",
      "Epoch [88/100], Step [29900/6235], Loss: 0.4517\n",
      "Epoch [88/100], Step [30000/6235], Loss: 5.6811\n",
      "Epoch [88/100], Step [30100/6235], Loss: 9.1012\n",
      "Epoch [88/100], Step [30200/6235], Loss: 0.0709\n",
      "Epoch [88/100], Step [30300/6235], Loss: 0.5277\n",
      "Epoch [88/100], Step [30400/6235], Loss: 0.1965\n",
      "Epoch [88/100], Step [30500/6235], Loss: 2.0205\n",
      "Epoch [88/100], Step [30600/6235], Loss: 0.5666\n",
      "Epoch [88/100], Step [30700/6235], Loss: 0.1451\n",
      "Epoch [88/100], Step [30800/6235], Loss: 0.2466\n",
      "Epoch [88/100], Step [30900/6235], Loss: 3.0623\n",
      "Epoch [88/100], Step [31000/6235], Loss: 0.0348\n",
      "Epoch [88/100], Step [31100/6235], Loss: 0.0678\n",
      "Epoch [88/100], Step [31200/6235], Loss: 5.7568\n",
      "Epoch [88/100], Step [31300/6235], Loss: 1.7314\n",
      "Epoch [88/100], Step [31400/6235], Loss: 0.5729\n",
      "Epoch [88/100], Step [31500/6235], Loss: 0.6157\n",
      "Epoch [88/100], Step [31600/6235], Loss: 1.9009\n",
      "Epoch [88/100], Step [31700/6235], Loss: 4.9515\n",
      "Epoch [88/100], Step [31800/6235], Loss: 1.7595\n",
      "Epoch [88/100], Step [31900/6235], Loss: 1175.8936\n",
      "Epoch [88/100], Step [32000/6235], Loss: 19.1127\n",
      "Epoch [88/100], Step [32100/6235], Loss: 2.2672\n",
      "Epoch [88/100], Step [32200/6235], Loss: 83.7534\n",
      "Epoch [88/100], Step [32300/6235], Loss: 0.6429\n",
      "Epoch [88/100], Step [32400/6235], Loss: 1.0303\n",
      "Epoch [88/100], Step [32500/6235], Loss: 17.8162\n",
      "Epoch [88/100], Step [32600/6235], Loss: 0.5911\n",
      "Epoch [88/100], Step [32700/6235], Loss: 105.7299\n",
      "Epoch [88/100], Step [32800/6235], Loss: 0.3133\n",
      "Epoch [88/100], Step [32900/6235], Loss: 1.7072\n",
      "Epoch [88/100], Step [33000/6235], Loss: 0.2605\n",
      "Epoch [88/100], Step [33100/6235], Loss: 0.8054\n",
      "Epoch [88/100], Step [33200/6235], Loss: 1.1062\n",
      "Epoch [88/100], Step [33300/6235], Loss: 0.4902\n",
      "Epoch [88/100], Step [33400/6235], Loss: 156.6211\n",
      "Epoch [88/100], Step [33500/6235], Loss: 0.2979\n",
      "Epoch [88/100], Step [33600/6235], Loss: 5.7820\n",
      "Epoch [88/100], Step [33700/6235], Loss: 1.7564\n",
      "Epoch [88/100], Step [33800/6235], Loss: 0.7108\n",
      "Epoch [88/100], Step [33900/6235], Loss: 28.1076\n",
      "Epoch [88/100], Step [34000/6235], Loss: 0.0254\n",
      "Epoch [88/100], Step [34100/6235], Loss: 0.3865\n",
      "Epoch [88/100], Step [34200/6235], Loss: 2.3239\n",
      "Epoch [88/100], Step [34300/6235], Loss: 5.3543\n",
      "Epoch [88/100], Step [34400/6235], Loss: 0.2165\n",
      "Epoch [88/100], Step [34500/6235], Loss: 55.6625\n",
      "Epoch [88/100], Step [34600/6235], Loss: 0.1297\n",
      "Epoch [88/100], Step [34700/6235], Loss: 26.3369\n",
      "Epoch [88/100], Step [34800/6235], Loss: 8.3541\n",
      "Epoch [88/100], Step [34900/6235], Loss: 64.1892\n",
      "Epoch [88/100], Step [35000/6235], Loss: 0.2739\n",
      "Epoch [88/100], Step [35100/6235], Loss: 0.5875\n",
      "Epoch [88/100], Step [35200/6235], Loss: 0.1963\n",
      "Epoch [88/100], Step [35300/6235], Loss: 2.6455\n",
      "Epoch [88/100], Step [35400/6235], Loss: 0.4148\n",
      "Epoch [88/100], Step [35500/6235], Loss: 1.9130\n",
      "Epoch [88/100], Step [35600/6235], Loss: 0.9036\n",
      "Epoch [88/100], Step [35700/6235], Loss: 6.1296\n",
      "Epoch [88/100], Step [35800/6235], Loss: 0.8046\n",
      "Epoch [88/100], Step [35900/6235], Loss: 0.4498\n",
      "Epoch [88/100], Step [36000/6235], Loss: 0.2995\n",
      "Epoch [88/100], Step [36100/6235], Loss: 0.0185\n",
      "Epoch [88/100], Step [36200/6235], Loss: 14.3835\n",
      "Epoch [88/100], Step [36300/6235], Loss: 1.0830\n",
      "Epoch [88/100], Step [36400/6235], Loss: 2.6006\n",
      "Epoch [88/100], Step [36500/6235], Loss: 8.7845\n",
      "Epoch [88/100], Step [36600/6235], Loss: 0.1252\n",
      "Epoch [88/100], Step [36700/6235], Loss: 0.3806\n",
      "Epoch [88/100], Step [36800/6235], Loss: 12.0809\n",
      "Epoch [88/100], Step [36900/6235], Loss: 6.6882\n",
      "Epoch [88/100], Step [37000/6235], Loss: 0.5511\n",
      "Epoch [88/100], Step [37100/6235], Loss: 1.2102\n",
      "Epoch [88/100], Step [37200/6235], Loss: 0.0765\n",
      "Epoch [88/100], Step [37300/6235], Loss: 0.0447\n",
      "Epoch [88/100], Step [37400/6235], Loss: 0.2007\n",
      "Epoch [88/100], Step [37500/6235], Loss: 4.4826\n",
      "Epoch [88/100], Step [37600/6235], Loss: 11.7200\n",
      "Epoch [88/100], Step [37700/6235], Loss: 1.3240\n",
      "Epoch [88/100], Step [37800/6235], Loss: 7.0253\n",
      "Epoch [88/100], Step [37900/6235], Loss: 7.0128\n",
      "Epoch [88/100], Step [38000/6235], Loss: 0.5439\n",
      "Epoch [88/100], Step [38100/6235], Loss: 3.4946\n",
      "Epoch [88/100], Step [38200/6235], Loss: 1.6322\n",
      "Epoch [88/100], Step [38300/6235], Loss: 0.0896\n",
      "Epoch [88/100], Step [38400/6235], Loss: 0.1041\n",
      "Epoch [88/100], Step [38500/6235], Loss: 2.5121\n",
      "Epoch [88/100], Step [38600/6235], Loss: 0.1715\n",
      "Epoch [88/100], Step [38700/6235], Loss: 0.1145\n",
      "Epoch [88/100], Step [38800/6235], Loss: 0.2084\n",
      "Epoch [88/100], Step [38900/6235], Loss: 6.7284\n",
      "Epoch [88/100], Step [39000/6235], Loss: 4.9752\n",
      "Epoch [88/100], Step [39100/6235], Loss: 12.6333\n",
      "Epoch [88/100], Step [39200/6235], Loss: 0.5556\n",
      "Epoch [88/100], Step [39300/6235], Loss: 32.8314\n",
      "Epoch [88/100], Step [39400/6235], Loss: 171.2701\n",
      "Epoch [88/100], Step [39500/6235], Loss: 241.1335\n",
      "Epoch [88/100], Step [39600/6235], Loss: 12.3820\n",
      "Epoch [88/100], Step [39700/6235], Loss: 51.6747\n",
      "Epoch [88/100], Step [39800/6235], Loss: 137.5113\n",
      "Epoch [88/100], Step [39900/6235], Loss: 18.4586\n",
      "Epoch [88/100], Step [40000/6235], Loss: 1.4391\n",
      "Epoch [88/100], Step [40100/6235], Loss: 6.9717\n",
      "Epoch [88/100], Step [40200/6235], Loss: 14.9574\n",
      "Epoch [88/100], Step [40300/6235], Loss: 1.7681\n",
      "Epoch [88/100], Step [40400/6235], Loss: 0.1158\n",
      "Epoch [88/100], Step [40500/6235], Loss: 3.4799\n",
      "Epoch [88/100], Step [40600/6235], Loss: 0.3096\n",
      "Epoch [88/100], Step [40700/6235], Loss: 5.0292\n",
      "Epoch [88/100], Step [40800/6235], Loss: 1.4935\n",
      "Epoch [88/100], Step [40900/6235], Loss: 1.3913\n",
      "Epoch [88/100], Step [41000/6235], Loss: 37.4052\n",
      "Epoch [88/100], Step [41100/6235], Loss: 8.1472\n",
      "Epoch [88/100], Step [41200/6235], Loss: 31.6301\n",
      "Epoch [88/100], Step [41300/6235], Loss: 0.3793\n",
      "Epoch [88/100], Step [41400/6235], Loss: 1.3176\n",
      "Epoch [88/100], Step [41500/6235], Loss: 14.5909\n",
      "Epoch [88/100], Step [41600/6235], Loss: 1.5750\n",
      "Epoch [88/100], Step [41700/6235], Loss: 0.1426\n",
      "Epoch [88/100], Step [41800/6235], Loss: 0.6617\n",
      "Epoch [88/100], Step [41900/6235], Loss: 4.6643\n",
      "Epoch [88/100], Step [42000/6235], Loss: 4.5462\n",
      "Epoch [88/100], Step [42100/6235], Loss: 12.0909\n",
      "Epoch [88/100], Step [42200/6235], Loss: 62.4509\n",
      "Epoch [88/100], Step [42300/6235], Loss: 0.2158\n",
      "Epoch [88/100], Step [42400/6235], Loss: 3.7629\n",
      "Epoch [88/100], Step [42500/6235], Loss: 1.4094\n",
      "Epoch [88/100], Step [42600/6235], Loss: 1.8455\n",
      "Epoch [88/100], Step [42700/6235], Loss: 0.7224\n",
      "Epoch [88/100], Step [42800/6235], Loss: 15.7258\n",
      "Epoch [88/100], Step [42900/6235], Loss: 0.2008\n",
      "Epoch [88/100], Step [43000/6235], Loss: 0.4523\n",
      "Epoch [88/100], Step [43100/6235], Loss: 0.0600\n",
      "Epoch [88/100], Step [43200/6235], Loss: 0.1124\n",
      "Epoch [88/100], Step [43300/6235], Loss: 4.2058\n",
      "Epoch [88/100], Step [43400/6235], Loss: 3.9271\n",
      "Epoch [88/100], Step [43500/6235], Loss: 12.3632\n",
      "Epoch [88/100], Step [43600/6235], Loss: 1.0603\n",
      "Epoch [88/100], Step [43700/6235], Loss: 44.3597\n",
      "Epoch [88/100], Step [43800/6235], Loss: 0.2269\n",
      "Epoch [88/100], Step [43900/6235], Loss: 3.2300\n",
      "Epoch [88/100], Step [44000/6235], Loss: 39.0860\n",
      "Epoch [88/100], Step [44100/6235], Loss: 0.9163\n",
      "Epoch [88/100], Step [44200/6235], Loss: 1.2984\n",
      "Epoch [88/100], Step [44300/6235], Loss: 76.8927\n",
      "Epoch [88/100], Step [44400/6235], Loss: 0.8574\n",
      "Epoch [88/100], Step [44500/6235], Loss: 6.6356\n",
      "Epoch [88/100], Step [44600/6235], Loss: 1.2863\n",
      "Epoch [88/100], Step [44700/6235], Loss: 2.1778\n",
      "Epoch [88/100], Step [44800/6235], Loss: 5.1487\n",
      "Epoch [88/100], Step [44900/6235], Loss: 10.8564\n",
      "Epoch [88/100], Step [45000/6235], Loss: 5.8601\n",
      "Epoch [88/100], Step [45100/6235], Loss: 57.1576\n",
      "Epoch [88/100], Step [45200/6235], Loss: 4.8191\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [88/100], Step [45300/6235], Loss: 22.9975\n",
      "Epoch [88/100], Step [45400/6235], Loss: 7.6273\n",
      "Epoch [88/100], Step [45500/6235], Loss: 3.3080\n",
      "Epoch [88/100], Step [45600/6235], Loss: 1.3966\n",
      "Epoch [88/100], Step [45700/6235], Loss: 114.2261\n",
      "Epoch [88/100], Step [45800/6235], Loss: 300.5519\n",
      "Epoch [88/100], Step [45900/6235], Loss: 72.1338\n",
      "Epoch [88/100], Step [46000/6235], Loss: 5.5504\n",
      "Epoch [88/100], Step [46100/6235], Loss: 12.7448\n",
      "Epoch [88/100], Step [46200/6235], Loss: 7.9289\n",
      "Epoch [88/100], Step [46300/6235], Loss: 67.5321\n",
      "Epoch [88/100], Step [46400/6235], Loss: 17.0555\n",
      "Epoch [88/100], Step [46500/6235], Loss: 325.5300\n",
      "Epoch [88/100], Step [46600/6235], Loss: 9.1176\n",
      "Epoch [88/100], Step [46700/6235], Loss: 36.8224\n",
      "Epoch [88/100], Step [46800/6235], Loss: 5.4121\n",
      "Epoch [88/100], Step [46900/6235], Loss: 1.8002\n",
      "Epoch [88/100], Step [47000/6235], Loss: 7.4588\n",
      "Epoch [88/100], Step [47100/6235], Loss: 2.2217\n",
      "Epoch [88/100], Step [47200/6235], Loss: 72.8860\n",
      "Epoch [88/100], Step [47300/6235], Loss: 0.7618\n",
      "Epoch [88/100], Step [47400/6235], Loss: 300.4414\n",
      "Epoch [88/100], Step [47500/6235], Loss: 5.6782\n",
      "Epoch [88/100], Step [47600/6235], Loss: 10.6924\n",
      "Epoch [88/100], Step [47700/6235], Loss: 56.4001\n",
      "Epoch [88/100], Step [47800/6235], Loss: 18.6301\n",
      "Epoch [88/100], Step [47900/6235], Loss: 4.7041\n",
      "Epoch [88/100], Step [48000/6235], Loss: 148.5213\n",
      "Epoch [88/100], Step [48100/6235], Loss: 68.2665\n",
      "Epoch [88/100], Step [48200/6235], Loss: 17.0545\n",
      "Epoch [88/100], Step [48300/6235], Loss: 1010.1149\n",
      "Epoch [88/100], Step [48400/6235], Loss: 3.4025\n",
      "Epoch [88/100], Step [48500/6235], Loss: 13.0711\n",
      "Epoch [88/100], Step [48600/6235], Loss: 20.7460\n",
      "Epoch [88/100], Step [48700/6235], Loss: 44.4224\n",
      "Epoch [88/100], Step [48800/6235], Loss: 732.8808\n",
      "Epoch [88/100], Step [48900/6235], Loss: 202.0396\n",
      "Epoch [88/100], Step [49000/6235], Loss: 265.2175\n",
      "Epoch [88/100], Step [49100/6235], Loss: 450.3072\n",
      "Epoch [88/100], Step [49200/6235], Loss: 933.3084\n",
      "Epoch [88/100], Step [49300/6235], Loss: 1055.4773\n",
      "Epoch [88/100], Step [49400/6235], Loss: 90.0085\n",
      "Epoch [88/100], Step [49500/6235], Loss: 30.5403\n",
      "Epoch [88/100], Step [49600/6235], Loss: 50.8129\n",
      "Epoch [88/100], Step [49700/6235], Loss: 555.3170\n",
      "Epoch [88/100], Step [49800/6235], Loss: 1943.6638\n",
      "Epoch [89/100], Step [100/6235], Loss: 10.9106\n",
      "Epoch [89/100], Step [200/6235], Loss: 0.1647\n",
      "Epoch [89/100], Step [300/6235], Loss: 0.0034\n",
      "Epoch [89/100], Step [400/6235], Loss: 0.0007\n",
      "Epoch [89/100], Step [500/6235], Loss: 0.9849\n",
      "Epoch [89/100], Step [600/6235], Loss: 0.0206\n",
      "Epoch [89/100], Step [700/6235], Loss: 0.5436\n",
      "Epoch [89/100], Step [800/6235], Loss: 0.0881\n",
      "Epoch [89/100], Step [900/6235], Loss: 0.0359\n",
      "Epoch [89/100], Step [1000/6235], Loss: 0.0273\n",
      "Epoch [89/100], Step [1100/6235], Loss: 0.0198\n",
      "Epoch [89/100], Step [1200/6235], Loss: 0.1778\n",
      "Epoch [89/100], Step [1300/6235], Loss: 0.0209\n",
      "Epoch [89/100], Step [1400/6235], Loss: 0.0378\n",
      "Epoch [89/100], Step [1500/6235], Loss: 0.0064\n",
      "Epoch [89/100], Step [1600/6235], Loss: 0.2298\n",
      "Epoch [89/100], Step [1700/6235], Loss: 0.0385\n",
      "Epoch [89/100], Step [1800/6235], Loss: 0.2050\n",
      "Epoch [89/100], Step [1900/6235], Loss: 0.3356\n",
      "Epoch [89/100], Step [2000/6235], Loss: 2.2442\n",
      "Epoch [89/100], Step [2100/6235], Loss: 1.7342\n",
      "Epoch [89/100], Step [2200/6235], Loss: 7.6272\n",
      "Epoch [89/100], Step [2300/6235], Loss: 3.7459\n",
      "Epoch [89/100], Step [2400/6235], Loss: 1.1466\n",
      "Epoch [89/100], Step [2500/6235], Loss: 33.6133\n",
      "Epoch [89/100], Step [2600/6235], Loss: 13.2200\n",
      "Epoch [89/100], Step [2700/6235], Loss: 9.4119\n",
      "Epoch [89/100], Step [2800/6235], Loss: 116.5154\n",
      "Epoch [89/100], Step [2900/6235], Loss: 15.8027\n",
      "Epoch [89/100], Step [3000/6235], Loss: 1.1301\n",
      "Epoch [89/100], Step [3100/6235], Loss: 64.6190\n",
      "Epoch [89/100], Step [3200/6235], Loss: 70.8606\n",
      "Epoch [89/100], Step [3300/6235], Loss: 8.8128\n",
      "Epoch [89/100], Step [3400/6235], Loss: 2.0459\n",
      "Epoch [89/100], Step [3500/6235], Loss: 40.6492\n",
      "Epoch [89/100], Step [3600/6235], Loss: 6.9436\n",
      "Epoch [89/100], Step [3700/6235], Loss: 0.0423\n",
      "Epoch [89/100], Step [3800/6235], Loss: 0.1206\n",
      "Epoch [89/100], Step [3900/6235], Loss: 0.3193\n",
      "Epoch [89/100], Step [4000/6235], Loss: 0.0453\n",
      "Epoch [89/100], Step [4100/6235], Loss: 7.9468\n",
      "Epoch [89/100], Step [4200/6235], Loss: 0.9080\n",
      "Epoch [89/100], Step [4300/6235], Loss: 7.6573\n",
      "Epoch [89/100], Step [4400/6235], Loss: 2.1877\n",
      "Epoch [89/100], Step [4500/6235], Loss: 38.9261\n",
      "Epoch [89/100], Step [4600/6235], Loss: 0.9309\n",
      "Epoch [89/100], Step [4700/6235], Loss: 0.0532\n",
      "Epoch [89/100], Step [4800/6235], Loss: 10.6719\n",
      "Epoch [89/100], Step [4900/6235], Loss: 0.2422\n",
      "Epoch [89/100], Step [5000/6235], Loss: 0.0761\n",
      "Epoch [89/100], Step [5100/6235], Loss: 0.7662\n",
      "Epoch [89/100], Step [5200/6235], Loss: 1.5730\n",
      "Epoch [89/100], Step [5300/6235], Loss: 42.5603\n",
      "Epoch [89/100], Step [5400/6235], Loss: 1.3195\n",
      "Epoch [89/100], Step [5500/6235], Loss: 0.2148\n",
      "Epoch [89/100], Step [5600/6235], Loss: 0.3014\n",
      "Epoch [89/100], Step [5700/6235], Loss: 0.0287\n",
      "Epoch [89/100], Step [5800/6235], Loss: 0.2331\n",
      "Epoch [89/100], Step [5900/6235], Loss: 0.0361\n",
      "Epoch [89/100], Step [6000/6235], Loss: 2.8482\n",
      "Epoch [89/100], Step [6100/6235], Loss: 0.0029\n",
      "Epoch [89/100], Step [6200/6235], Loss: 3.0059\n",
      "Epoch [89/100], Step [6300/6235], Loss: 0.5295\n",
      "Epoch [89/100], Step [6400/6235], Loss: 0.0766\n",
      "Epoch [89/100], Step [6500/6235], Loss: 3.7010\n",
      "Epoch [89/100], Step [6600/6235], Loss: 10.0091\n",
      "Epoch [89/100], Step [6700/6235], Loss: 2.8008\n",
      "Epoch [89/100], Step [6800/6235], Loss: 0.2785\n",
      "Epoch [89/100], Step [6900/6235], Loss: 0.0834\n",
      "Epoch [89/100], Step [7000/6235], Loss: 0.0154\n",
      "Epoch [89/100], Step [7100/6235], Loss: 0.1286\n",
      "Epoch [89/100], Step [7200/6235], Loss: 0.1755\n",
      "Epoch [89/100], Step [7300/6235], Loss: 0.3823\n",
      "Epoch [89/100], Step [7400/6235], Loss: 0.0716\n",
      "Epoch [89/100], Step [7500/6235], Loss: 0.8152\n",
      "Epoch [89/100], Step [7600/6235], Loss: 3.5653\n",
      "Epoch [89/100], Step [7700/6235], Loss: 12.2869\n",
      "Epoch [89/100], Step [7800/6235], Loss: 1.2024\n",
      "Epoch [89/100], Step [7900/6235], Loss: 1.0547\n",
      "Epoch [89/100], Step [8000/6235], Loss: 0.3139\n",
      "Epoch [89/100], Step [8100/6235], Loss: 3.9655\n",
      "Epoch [89/100], Step [8200/6235], Loss: 11.0943\n",
      "Epoch [89/100], Step [8300/6235], Loss: 24.0853\n",
      "Epoch [89/100], Step [8400/6235], Loss: 390.4208\n",
      "Epoch [89/100], Step [8500/6235], Loss: 4.0090\n",
      "Epoch [89/100], Step [8600/6235], Loss: 19.6661\n",
      "Epoch [89/100], Step [8700/6235], Loss: 23.3064\n",
      "Epoch [89/100], Step [8800/6235], Loss: 738.0533\n",
      "Epoch [89/100], Step [8900/6235], Loss: 55.2210\n",
      "Epoch [89/100], Step [9000/6235], Loss: 622.7712\n",
      "Epoch [89/100], Step [9100/6235], Loss: 1923.1215\n",
      "Epoch [89/100], Step [9200/6235], Loss: 4221.2456\n",
      "Epoch [89/100], Step [9300/6235], Loss: 12.4113\n",
      "Epoch [89/100], Step [9400/6235], Loss: 15.5321\n",
      "Epoch [89/100], Step [9500/6235], Loss: 2022.4907\n",
      "Epoch [89/100], Step [9600/6235], Loss: 960.2905\n",
      "Epoch [89/100], Step [9700/6235], Loss: 0.7287\n",
      "Epoch [89/100], Step [9800/6235], Loss: 731.9409\n",
      "Epoch [89/100], Step [9900/6235], Loss: 25.9746\n",
      "Epoch [89/100], Step [10000/6235], Loss: 9.8881\n",
      "Epoch [89/100], Step [10100/6235], Loss: 1.7189\n",
      "Epoch [89/100], Step [10200/6235], Loss: 1186.0732\n",
      "Epoch [89/100], Step [10300/6235], Loss: 11.2641\n",
      "Epoch [89/100], Step [10400/6235], Loss: 10.1177\n",
      "Epoch [89/100], Step [10500/6235], Loss: 216.0773\n",
      "Epoch [89/100], Step [10600/6235], Loss: 576.6376\n",
      "Epoch [89/100], Step [10700/6235], Loss: 51.7581\n",
      "Epoch [89/100], Step [10800/6235], Loss: 29.6117\n",
      "Epoch [89/100], Step [10900/6235], Loss: 133.5365\n",
      "Epoch [89/100], Step [11000/6235], Loss: 281.4930\n",
      "Epoch [89/100], Step [11100/6235], Loss: 7.7771\n",
      "Epoch [89/100], Step [11200/6235], Loss: 0.4410\n",
      "Epoch [89/100], Step [11300/6235], Loss: 103.7315\n",
      "Epoch [89/100], Step [11400/6235], Loss: 71.9861\n",
      "Epoch [89/100], Step [11500/6235], Loss: 11.9708\n",
      "Epoch [89/100], Step [11600/6235], Loss: 10.0043\n",
      "Epoch [89/100], Step [11700/6235], Loss: 63.5603\n",
      "Epoch [89/100], Step [11800/6235], Loss: 394.1994\n",
      "Epoch [89/100], Step [11900/6235], Loss: 10.2625\n",
      "Epoch [89/100], Step [12000/6235], Loss: 698.7729\n",
      "Epoch [89/100], Step [12100/6235], Loss: 286.5005\n",
      "Epoch [89/100], Step [12200/6235], Loss: 22.5644\n",
      "Epoch [89/100], Step [12300/6235], Loss: 1.1039\n",
      "Epoch [89/100], Step [12400/6235], Loss: 101.5284\n",
      "Epoch [89/100], Step [12500/6235], Loss: 125.7751\n",
      "Epoch [89/100], Step [12600/6235], Loss: 0.6217\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Step [12700/6235], Loss: 5.6112\n",
      "Epoch [89/100], Step [12800/6235], Loss: 9.8866\n",
      "Epoch [89/100], Step [12900/6235], Loss: 29.4949\n",
      "Epoch [89/100], Step [13000/6235], Loss: 0.0725\n",
      "Epoch [89/100], Step [13100/6235], Loss: 61.7498\n",
      "Epoch [89/100], Step [13200/6235], Loss: 7.9990\n",
      "Epoch [89/100], Step [13300/6235], Loss: 17.6257\n",
      "Epoch [89/100], Step [13400/6235], Loss: 192.9265\n",
      "Epoch [89/100], Step [13500/6235], Loss: 4.4136\n",
      "Epoch [89/100], Step [13600/6235], Loss: 8.3056\n",
      "Epoch [89/100], Step [13700/6235], Loss: 173.8687\n",
      "Epoch [89/100], Step [13800/6235], Loss: 74.8348\n",
      "Epoch [89/100], Step [13900/6235], Loss: 6.3681\n",
      "Epoch [89/100], Step [14000/6235], Loss: 6.7858\n",
      "Epoch [89/100], Step [14100/6235], Loss: 54.8798\n",
      "Epoch [89/100], Step [14200/6235], Loss: 6.2832\n",
      "Epoch [89/100], Step [14300/6235], Loss: 1.8341\n",
      "Epoch [89/100], Step [14400/6235], Loss: 33.7369\n",
      "Epoch [89/100], Step [14500/6235], Loss: 22.8407\n",
      "Epoch [89/100], Step [14600/6235], Loss: 2.7550\n",
      "Epoch [89/100], Step [14700/6235], Loss: 24.3203\n",
      "Epoch [89/100], Step [14800/6235], Loss: 28.6983\n",
      "Epoch [89/100], Step [14900/6235], Loss: 0.7220\n",
      "Epoch [89/100], Step [15000/6235], Loss: 1.1324\n",
      "Epoch [89/100], Step [15100/6235], Loss: 0.3879\n",
      "Epoch [89/100], Step [15200/6235], Loss: 23.2974\n",
      "Epoch [89/100], Step [15300/6235], Loss: 25.4987\n",
      "Epoch [89/100], Step [15400/6235], Loss: 91.8783\n",
      "Epoch [89/100], Step [15500/6235], Loss: 16.0597\n",
      "Epoch [89/100], Step [15600/6235], Loss: 179.4581\n",
      "Epoch [89/100], Step [15700/6235], Loss: 78.0973\n",
      "Epoch [89/100], Step [15800/6235], Loss: 10.5388\n",
      "Epoch [89/100], Step [15900/6235], Loss: 0.3312\n",
      "Epoch [89/100], Step [16000/6235], Loss: 93.2213\n",
      "Epoch [89/100], Step [16100/6235], Loss: 0.8288\n",
      "Epoch [89/100], Step [16200/6235], Loss: 0.2492\n",
      "Epoch [89/100], Step [16300/6235], Loss: 8.6153\n",
      "Epoch [89/100], Step [16400/6235], Loss: 21.4435\n",
      "Epoch [89/100], Step [16500/6235], Loss: 314.2213\n",
      "Epoch [89/100], Step [16600/6235], Loss: 50.8295\n",
      "Epoch [89/100], Step [16700/6235], Loss: 0.3178\n",
      "Epoch [89/100], Step [16800/6235], Loss: 12.0237\n",
      "Epoch [89/100], Step [16900/6235], Loss: 0.3418\n",
      "Epoch [89/100], Step [17000/6235], Loss: 0.1934\n",
      "Epoch [89/100], Step [17100/6235], Loss: 0.1824\n",
      "Epoch [89/100], Step [17200/6235], Loss: 252.6080\n",
      "Epoch [89/100], Step [17300/6235], Loss: 1.4076\n",
      "Epoch [89/100], Step [17400/6235], Loss: 33.4489\n",
      "Epoch [89/100], Step [17500/6235], Loss: 1.0857\n",
      "Epoch [89/100], Step [17600/6235], Loss: 2.6085\n",
      "Epoch [89/100], Step [17700/6235], Loss: 71.5927\n",
      "Epoch [89/100], Step [17800/6235], Loss: 25.8040\n",
      "Epoch [89/100], Step [17900/6235], Loss: 10.2076\n",
      "Epoch [89/100], Step [18000/6235], Loss: 7.4697\n",
      "Epoch [89/100], Step [18100/6235], Loss: 16.2663\n",
      "Epoch [89/100], Step [18200/6235], Loss: 0.4798\n",
      "Epoch [89/100], Step [18300/6235], Loss: 4.2432\n",
      "Epoch [89/100], Step [18400/6235], Loss: 2.8364\n",
      "Epoch [89/100], Step [18500/6235], Loss: 5.6404\n",
      "Epoch [89/100], Step [18600/6235], Loss: 2.1121\n",
      "Epoch [89/100], Step [18700/6235], Loss: 0.4562\n",
      "Epoch [89/100], Step [18800/6235], Loss: 112.4676\n",
      "Epoch [89/100], Step [18900/6235], Loss: 45.6276\n",
      "Epoch [89/100], Step [19000/6235], Loss: 2.3962\n",
      "Epoch [89/100], Step [19100/6235], Loss: 32.9022\n",
      "Epoch [89/100], Step [19200/6235], Loss: 1.8990\n",
      "Epoch [89/100], Step [19300/6235], Loss: 13.0215\n",
      "Epoch [89/100], Step [19400/6235], Loss: 259.6870\n",
      "Epoch [89/100], Step [19500/6235], Loss: 77.7307\n",
      "Epoch [89/100], Step [19600/6235], Loss: 106.5691\n",
      "Epoch [89/100], Step [19700/6235], Loss: 12.4512\n",
      "Epoch [89/100], Step [19800/6235], Loss: 2.1689\n",
      "Epoch [89/100], Step [19900/6235], Loss: 0.1188\n",
      "Epoch [89/100], Step [20000/6235], Loss: 66.4044\n",
      "Epoch [89/100], Step [20100/6235], Loss: 1.4548\n",
      "Epoch [89/100], Step [20200/6235], Loss: 3.4226\n",
      "Epoch [89/100], Step [20300/6235], Loss: 2.2777\n",
      "Epoch [89/100], Step [20400/6235], Loss: 13.9334\n",
      "Epoch [89/100], Step [20500/6235], Loss: 50.3761\n",
      "Epoch [89/100], Step [20600/6235], Loss: 104.3177\n",
      "Epoch [89/100], Step [20700/6235], Loss: 23.6612\n",
      "Epoch [89/100], Step [20800/6235], Loss: 0.2777\n",
      "Epoch [89/100], Step [20900/6235], Loss: 14.6291\n",
      "Epoch [89/100], Step [21000/6235], Loss: 14.4363\n",
      "Epoch [89/100], Step [21100/6235], Loss: 6.5319\n",
      "Epoch [89/100], Step [21200/6235], Loss: 0.3074\n",
      "Epoch [89/100], Step [21300/6235], Loss: 0.1392\n",
      "Epoch [89/100], Step [21400/6235], Loss: 5.4152\n",
      "Epoch [89/100], Step [21500/6235], Loss: 2.3198\n",
      "Epoch [89/100], Step [21600/6235], Loss: 17.2691\n",
      "Epoch [89/100], Step [21700/6235], Loss: 0.1563\n",
      "Epoch [89/100], Step [21800/6235], Loss: 5.0107\n",
      "Epoch [89/100], Step [21900/6235], Loss: 1.4295\n",
      "Epoch [89/100], Step [22000/6235], Loss: 7.4597\n",
      "Epoch [89/100], Step [22100/6235], Loss: 0.7483\n",
      "Epoch [89/100], Step [22200/6235], Loss: 5.0165\n",
      "Epoch [89/100], Step [22300/6235], Loss: 0.7637\n",
      "Epoch [89/100], Step [22400/6235], Loss: 9.3119\n",
      "Epoch [89/100], Step [22500/6235], Loss: 182.5744\n",
      "Epoch [89/100], Step [22600/6235], Loss: 23.7222\n",
      "Epoch [89/100], Step [22700/6235], Loss: 3.0423\n",
      "Epoch [89/100], Step [22800/6235], Loss: 5.7449\n",
      "Epoch [89/100], Step [22900/6235], Loss: 5.4382\n",
      "Epoch [89/100], Step [23000/6235], Loss: 4.0877\n",
      "Epoch [89/100], Step [23100/6235], Loss: 4.6386\n",
      "Epoch [89/100], Step [23200/6235], Loss: 6.8389\n",
      "Epoch [89/100], Step [23300/6235], Loss: 19.2530\n",
      "Epoch [89/100], Step [23400/6235], Loss: 1.8634\n",
      "Epoch [89/100], Step [23500/6235], Loss: 0.0909\n",
      "Epoch [89/100], Step [23600/6235], Loss: 128.5594\n",
      "Epoch [89/100], Step [23700/6235], Loss: 3.9324\n",
      "Epoch [89/100], Step [23800/6235], Loss: 0.9872\n",
      "Epoch [89/100], Step [23900/6235], Loss: 4.8453\n",
      "Epoch [89/100], Step [24000/6235], Loss: 0.4492\n",
      "Epoch [89/100], Step [24100/6235], Loss: 0.9675\n",
      "Epoch [89/100], Step [24200/6235], Loss: 41.9857\n",
      "Epoch [89/100], Step [24300/6235], Loss: 1.3118\n",
      "Epoch [89/100], Step [24400/6235], Loss: 1.8419\n",
      "Epoch [89/100], Step [24500/6235], Loss: 0.2995\n",
      "Epoch [89/100], Step [24600/6235], Loss: 0.0719\n",
      "Epoch [89/100], Step [24700/6235], Loss: 0.0609\n",
      "Epoch [89/100], Step [24800/6235], Loss: 0.0970\n",
      "Epoch [89/100], Step [24900/6235], Loss: 13.5824\n",
      "Epoch [89/100], Step [25000/6235], Loss: 13.3599\n",
      "Epoch [89/100], Step [25100/6235], Loss: 6.2990\n",
      "Epoch [89/100], Step [25200/6235], Loss: 0.2013\n",
      "Epoch [89/100], Step [25300/6235], Loss: 0.8275\n",
      "Epoch [89/100], Step [25400/6235], Loss: 10.1556\n",
      "Epoch [89/100], Step [25500/6235], Loss: 8.3376\n",
      "Epoch [89/100], Step [25600/6235], Loss: 6.1155\n",
      "Epoch [89/100], Step [25700/6235], Loss: 0.2689\n",
      "Epoch [89/100], Step [25800/6235], Loss: 0.0694\n",
      "Epoch [89/100], Step [25900/6235], Loss: 7.1229\n",
      "Epoch [89/100], Step [26000/6235], Loss: 3.8884\n",
      "Epoch [89/100], Step [26100/6235], Loss: 0.0290\n",
      "Epoch [89/100], Step [26200/6235], Loss: 1.3792\n",
      "Epoch [89/100], Step [26300/6235], Loss: 1.9253\n",
      "Epoch [89/100], Step [26400/6235], Loss: 0.3497\n",
      "Epoch [89/100], Step [26500/6235], Loss: 0.0361\n",
      "Epoch [89/100], Step [26600/6235], Loss: 0.5413\n",
      "Epoch [89/100], Step [26700/6235], Loss: 0.1917\n",
      "Epoch [89/100], Step [26800/6235], Loss: 0.1083\n",
      "Epoch [89/100], Step [26900/6235], Loss: 0.0371\n",
      "Epoch [89/100], Step [27000/6235], Loss: 16.1922\n",
      "Epoch [89/100], Step [27100/6235], Loss: 0.0602\n",
      "Epoch [89/100], Step [27200/6235], Loss: 0.0111\n",
      "Epoch [89/100], Step [27300/6235], Loss: 0.0849\n",
      "Epoch [89/100], Step [27400/6235], Loss: 0.6520\n",
      "Epoch [89/100], Step [27500/6235], Loss: 2.2589\n",
      "Epoch [89/100], Step [27600/6235], Loss: 1.1878\n",
      "Epoch [89/100], Step [27700/6235], Loss: 1.0264\n",
      "Epoch [89/100], Step [27800/6235], Loss: 5.1880\n",
      "Epoch [89/100], Step [27900/6235], Loss: 0.5054\n",
      "Epoch [89/100], Step [28000/6235], Loss: 144.1090\n",
      "Epoch [89/100], Step [28100/6235], Loss: 3.8636\n",
      "Epoch [89/100], Step [28200/6235], Loss: 44.4306\n",
      "Epoch [89/100], Step [28300/6235], Loss: 1.4160\n",
      "Epoch [89/100], Step [28400/6235], Loss: 25.0087\n",
      "Epoch [89/100], Step [28500/6235], Loss: 3.5698\n",
      "Epoch [89/100], Step [28600/6235], Loss: 0.8328\n",
      "Epoch [89/100], Step [28700/6235], Loss: 3.7175\n",
      "Epoch [89/100], Step [28800/6235], Loss: 0.6542\n",
      "Epoch [89/100], Step [28900/6235], Loss: 52.4133\n",
      "Epoch [89/100], Step [29000/6235], Loss: 13.9690\n",
      "Epoch [89/100], Step [29100/6235], Loss: 0.4027\n",
      "Epoch [89/100], Step [29200/6235], Loss: 4.7672\n",
      "Epoch [89/100], Step [29300/6235], Loss: 7.8227\n",
      "Epoch [89/100], Step [29400/6235], Loss: 0.0971\n",
      "Epoch [89/100], Step [29500/6235], Loss: 2.2980\n",
      "Epoch [89/100], Step [29600/6235], Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Step [29700/6235], Loss: 2.6658\n",
      "Epoch [89/100], Step [29800/6235], Loss: 0.8252\n",
      "Epoch [89/100], Step [29900/6235], Loss: 0.2623\n",
      "Epoch [89/100], Step [30000/6235], Loss: 6.3915\n",
      "Epoch [89/100], Step [30100/6235], Loss: 7.4872\n",
      "Epoch [89/100], Step [30200/6235], Loss: 1.8811\n",
      "Epoch [89/100], Step [30300/6235], Loss: 0.0664\n",
      "Epoch [89/100], Step [30400/6235], Loss: 2.3045\n",
      "Epoch [89/100], Step [30500/6235], Loss: 0.7563\n",
      "Epoch [89/100], Step [30600/6235], Loss: 1.3196\n",
      "Epoch [89/100], Step [30700/6235], Loss: 2.3923\n",
      "Epoch [89/100], Step [30800/6235], Loss: 0.5194\n",
      "Epoch [89/100], Step [30900/6235], Loss: 1.6800\n",
      "Epoch [89/100], Step [31000/6235], Loss: 0.3252\n",
      "Epoch [89/100], Step [31100/6235], Loss: 0.3876\n",
      "Epoch [89/100], Step [31200/6235], Loss: 6.0680\n",
      "Epoch [89/100], Step [31300/6235], Loss: 1.1450\n",
      "Epoch [89/100], Step [31400/6235], Loss: 1.1456\n",
      "Epoch [89/100], Step [31500/6235], Loss: 0.7166\n",
      "Epoch [89/100], Step [31600/6235], Loss: 3.7079\n",
      "Epoch [89/100], Step [31700/6235], Loss: 7.1069\n",
      "Epoch [89/100], Step [31800/6235], Loss: 0.2003\n",
      "Epoch [89/100], Step [31900/6235], Loss: 62.8679\n",
      "Epoch [89/100], Step [32000/6235], Loss: 75.2896\n",
      "Epoch [89/100], Step [32100/6235], Loss: 1.1233\n",
      "Epoch [89/100], Step [32200/6235], Loss: 125.0832\n",
      "Epoch [89/100], Step [32300/6235], Loss: 0.8098\n",
      "Epoch [89/100], Step [32400/6235], Loss: 1.3908\n",
      "Epoch [89/100], Step [32500/6235], Loss: 15.1308\n",
      "Epoch [89/100], Step [32600/6235], Loss: 0.5066\n",
      "Epoch [89/100], Step [32700/6235], Loss: 153.0312\n",
      "Epoch [89/100], Step [32800/6235], Loss: 4.3656\n",
      "Epoch [89/100], Step [32900/6235], Loss: 4.9595\n",
      "Epoch [89/100], Step [33000/6235], Loss: 0.5908\n",
      "Epoch [89/100], Step [33100/6235], Loss: 0.8057\n",
      "Epoch [89/100], Step [33200/6235], Loss: 1.5951\n",
      "Epoch [89/100], Step [33300/6235], Loss: 1.6983\n",
      "Epoch [89/100], Step [33400/6235], Loss: 145.4326\n",
      "Epoch [89/100], Step [33500/6235], Loss: 2.4036\n",
      "Epoch [89/100], Step [33600/6235], Loss: 9.4960\n",
      "Epoch [89/100], Step [33700/6235], Loss: 12.5536\n",
      "Epoch [89/100], Step [33800/6235], Loss: 0.5875\n",
      "Epoch [89/100], Step [33900/6235], Loss: 28.8988\n",
      "Epoch [89/100], Step [34000/6235], Loss: 0.1059\n",
      "Epoch [89/100], Step [34100/6235], Loss: 0.6941\n",
      "Epoch [89/100], Step [34200/6235], Loss: 2.3701\n",
      "Epoch [89/100], Step [34300/6235], Loss: 2.9543\n",
      "Epoch [89/100], Step [34400/6235], Loss: 0.1365\n",
      "Epoch [89/100], Step [34500/6235], Loss: 21.4799\n",
      "Epoch [89/100], Step [34600/6235], Loss: 1.5037\n",
      "Epoch [89/100], Step [34700/6235], Loss: 11.5408\n",
      "Epoch [89/100], Step [34800/6235], Loss: 14.4892\n",
      "Epoch [89/100], Step [34900/6235], Loss: 70.2265\n",
      "Epoch [89/100], Step [35000/6235], Loss: 0.2918\n",
      "Epoch [89/100], Step [35100/6235], Loss: 1.0646\n",
      "Epoch [89/100], Step [35200/6235], Loss: 0.4922\n",
      "Epoch [89/100], Step [35300/6235], Loss: 3.0765\n",
      "Epoch [89/100], Step [35400/6235], Loss: 0.5736\n",
      "Epoch [89/100], Step [35500/6235], Loss: 0.6653\n",
      "Epoch [89/100], Step [35600/6235], Loss: 1.6846\n",
      "Epoch [89/100], Step [35700/6235], Loss: 4.2917\n",
      "Epoch [89/100], Step [35800/6235], Loss: 1.6325\n",
      "Epoch [89/100], Step [35900/6235], Loss: 0.1631\n",
      "Epoch [89/100], Step [36000/6235], Loss: 0.0280\n",
      "Epoch [89/100], Step [36100/6235], Loss: 0.0145\n",
      "Epoch [89/100], Step [36200/6235], Loss: 7.9109\n",
      "Epoch [89/100], Step [36300/6235], Loss: 0.1022\n",
      "Epoch [89/100], Step [36400/6235], Loss: 3.0665\n",
      "Epoch [89/100], Step [36500/6235], Loss: 7.9420\n",
      "Epoch [89/100], Step [36600/6235], Loss: 0.1006\n",
      "Epoch [89/100], Step [36700/6235], Loss: 0.5548\n",
      "Epoch [89/100], Step [36800/6235], Loss: 7.6049\n",
      "Epoch [89/100], Step [36900/6235], Loss: 9.4148\n",
      "Epoch [89/100], Step [37000/6235], Loss: 0.8201\n",
      "Epoch [89/100], Step [37100/6235], Loss: 1.6219\n",
      "Epoch [89/100], Step [37200/6235], Loss: 0.0569\n",
      "Epoch [89/100], Step [37300/6235], Loss: 0.0315\n",
      "Epoch [89/100], Step [37400/6235], Loss: 0.1873\n",
      "Epoch [89/100], Step [37500/6235], Loss: 5.4102\n",
      "Epoch [89/100], Step [37600/6235], Loss: 12.0080\n",
      "Epoch [89/100], Step [37700/6235], Loss: 1.1719\n",
      "Epoch [89/100], Step [37800/6235], Loss: 7.4764\n",
      "Epoch [89/100], Step [37900/6235], Loss: 4.2459\n",
      "Epoch [89/100], Step [38000/6235], Loss: 0.9438\n",
      "Epoch [89/100], Step [38100/6235], Loss: 4.4122\n",
      "Epoch [89/100], Step [38200/6235], Loss: 2.1238\n",
      "Epoch [89/100], Step [38300/6235], Loss: 1.6753\n",
      "Epoch [89/100], Step [38400/6235], Loss: 0.0596\n",
      "Epoch [89/100], Step [38500/6235], Loss: 2.1608\n",
      "Epoch [89/100], Step [38600/6235], Loss: 0.2800\n",
      "Epoch [89/100], Step [38700/6235], Loss: 0.2245\n",
      "Epoch [89/100], Step [38800/6235], Loss: 0.1999\n",
      "Epoch [89/100], Step [38900/6235], Loss: 0.8485\n",
      "Epoch [89/100], Step [39000/6235], Loss: 7.6763\n",
      "Epoch [89/100], Step [39100/6235], Loss: 16.7534\n",
      "Epoch [89/100], Step [39200/6235], Loss: 0.2669\n",
      "Epoch [89/100], Step [39300/6235], Loss: 23.7816\n",
      "Epoch [89/100], Step [39400/6235], Loss: 89.6978\n",
      "Epoch [89/100], Step [39500/6235], Loss: 49.2764\n",
      "Epoch [89/100], Step [39600/6235], Loss: 2.8246\n",
      "Epoch [89/100], Step [39700/6235], Loss: 972.4453\n",
      "Epoch [89/100], Step [39800/6235], Loss: 234.9687\n",
      "Epoch [89/100], Step [39900/6235], Loss: 10.1226\n",
      "Epoch [89/100], Step [40000/6235], Loss: 2.0969\n",
      "Epoch [89/100], Step [40100/6235], Loss: 5.6918\n",
      "Epoch [89/100], Step [40200/6235], Loss: 18.3498\n",
      "Epoch [89/100], Step [40300/6235], Loss: 0.2776\n",
      "Epoch [89/100], Step [40400/6235], Loss: 0.5851\n",
      "Epoch [89/100], Step [40500/6235], Loss: 3.3169\n",
      "Epoch [89/100], Step [40600/6235], Loss: 0.2640\n",
      "Epoch [89/100], Step [40700/6235], Loss: 4.9985\n",
      "Epoch [89/100], Step [40800/6235], Loss: 1.3964\n",
      "Epoch [89/100], Step [40900/6235], Loss: 1.3887\n",
      "Epoch [89/100], Step [41000/6235], Loss: 38.4394\n",
      "Epoch [89/100], Step [41100/6235], Loss: 34.8308\n",
      "Epoch [89/100], Step [41200/6235], Loss: 2.9145\n",
      "Epoch [89/100], Step [41300/6235], Loss: 3.1383\n",
      "Epoch [89/100], Step [41400/6235], Loss: 0.6284\n",
      "Epoch [89/100], Step [41500/6235], Loss: 0.6451\n",
      "Epoch [89/100], Step [41600/6235], Loss: 0.6818\n",
      "Epoch [89/100], Step [41700/6235], Loss: 4.3718\n",
      "Epoch [89/100], Step [41800/6235], Loss: 1.2533\n",
      "Epoch [89/100], Step [41900/6235], Loss: 4.1615\n",
      "Epoch [89/100], Step [42000/6235], Loss: 3.3578\n",
      "Epoch [89/100], Step [42100/6235], Loss: 7.9182\n",
      "Epoch [89/100], Step [42200/6235], Loss: 2.0190\n",
      "Epoch [89/100], Step [42300/6235], Loss: 1.3673\n",
      "Epoch [89/100], Step [42400/6235], Loss: 0.4270\n",
      "Epoch [89/100], Step [42500/6235], Loss: 5.5693\n",
      "Epoch [89/100], Step [42600/6235], Loss: 0.5695\n",
      "Epoch [89/100], Step [42700/6235], Loss: 0.2690\n",
      "Epoch [89/100], Step [42800/6235], Loss: 2.9704\n",
      "Epoch [89/100], Step [42900/6235], Loss: 3.8689\n",
      "Epoch [89/100], Step [43000/6235], Loss: 0.2285\n",
      "Epoch [89/100], Step [43100/6235], Loss: 0.5098\n",
      "Epoch [89/100], Step [43200/6235], Loss: 1.0006\n",
      "Epoch [89/100], Step [43300/6235], Loss: 8.9821\n",
      "Epoch [89/100], Step [43400/6235], Loss: 10.2380\n",
      "Epoch [89/100], Step [43500/6235], Loss: 9.4207\n",
      "Epoch [89/100], Step [43600/6235], Loss: 17.3358\n",
      "Epoch [89/100], Step [43700/6235], Loss: 43.7699\n",
      "Epoch [89/100], Step [43800/6235], Loss: 0.6365\n",
      "Epoch [89/100], Step [43900/6235], Loss: 1.1033\n",
      "Epoch [89/100], Step [44000/6235], Loss: 26.8856\n",
      "Epoch [89/100], Step [44100/6235], Loss: 0.1593\n",
      "Epoch [89/100], Step [44200/6235], Loss: 19.1390\n",
      "Epoch [89/100], Step [44300/6235], Loss: 1.7830\n",
      "Epoch [89/100], Step [44400/6235], Loss: 0.7284\n",
      "Epoch [89/100], Step [44500/6235], Loss: 3.1881\n",
      "Epoch [89/100], Step [44600/6235], Loss: 15.0721\n",
      "Epoch [89/100], Step [44700/6235], Loss: 2.5818\n",
      "Epoch [89/100], Step [44800/6235], Loss: 2.8177\n",
      "Epoch [89/100], Step [44900/6235], Loss: 6.9117\n",
      "Epoch [89/100], Step [45000/6235], Loss: 5.1588\n",
      "Epoch [89/100], Step [45100/6235], Loss: 11.0360\n",
      "Epoch [89/100], Step [45200/6235], Loss: 0.9969\n",
      "Epoch [89/100], Step [45300/6235], Loss: 25.7815\n",
      "Epoch [89/100], Step [45400/6235], Loss: 12.4583\n",
      "Epoch [89/100], Step [45500/6235], Loss: 1.0157\n",
      "Epoch [89/100], Step [45600/6235], Loss: 0.5108\n",
      "Epoch [89/100], Step [45700/6235], Loss: 132.3248\n",
      "Epoch [89/100], Step [45800/6235], Loss: 452.2492\n",
      "Epoch [89/100], Step [45900/6235], Loss: 25.1831\n",
      "Epoch [89/100], Step [46000/6235], Loss: 2.0360\n",
      "Epoch [89/100], Step [46100/6235], Loss: 66.8365\n",
      "Epoch [89/100], Step [46200/6235], Loss: 144.4084\n",
      "Epoch [89/100], Step [46300/6235], Loss: 39.3629\n",
      "Epoch [89/100], Step [46400/6235], Loss: 14.3816\n",
      "Epoch [89/100], Step [46500/6235], Loss: 140.4700\n",
      "Epoch [89/100], Step [46600/6235], Loss: 16.8133\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [89/100], Step [46700/6235], Loss: 7.6636\n",
      "Epoch [89/100], Step [46800/6235], Loss: 30.5006\n",
      "Epoch [89/100], Step [46900/6235], Loss: 5.2627\n",
      "Epoch [89/100], Step [47000/6235], Loss: 6.2264\n",
      "Epoch [89/100], Step [47100/6235], Loss: 2.1912\n",
      "Epoch [89/100], Step [47200/6235], Loss: 40.3548\n",
      "Epoch [89/100], Step [47300/6235], Loss: 1.2134\n",
      "Epoch [89/100], Step [47400/6235], Loss: 227.0433\n",
      "Epoch [89/100], Step [47500/6235], Loss: 8.3545\n",
      "Epoch [89/100], Step [47600/6235], Loss: 0.3626\n",
      "Epoch [89/100], Step [47700/6235], Loss: 5.2416\n",
      "Epoch [89/100], Step [47800/6235], Loss: 1.1267\n",
      "Epoch [89/100], Step [47900/6235], Loss: 15.7365\n",
      "Epoch [89/100], Step [48000/6235], Loss: 93.8213\n",
      "Epoch [89/100], Step [48100/6235], Loss: 8.7697\n",
      "Epoch [89/100], Step [48200/6235], Loss: 52.4035\n",
      "Epoch [89/100], Step [48300/6235], Loss: 1178.6041\n",
      "Epoch [89/100], Step [48400/6235], Loss: 11.8110\n",
      "Epoch [89/100], Step [48500/6235], Loss: 7.5473\n",
      "Epoch [89/100], Step [48600/6235], Loss: 35.1446\n",
      "Epoch [89/100], Step [48700/6235], Loss: 2.1898\n",
      "Epoch [89/100], Step [48800/6235], Loss: 1346.2839\n",
      "Epoch [89/100], Step [48900/6235], Loss: 126.2280\n",
      "Epoch [89/100], Step [49000/6235], Loss: 245.6078\n",
      "Epoch [89/100], Step [49100/6235], Loss: 1016.5496\n",
      "Epoch [89/100], Step [49200/6235], Loss: 217.8975\n",
      "Epoch [89/100], Step [49300/6235], Loss: 461.7422\n",
      "Epoch [89/100], Step [49400/6235], Loss: 1.9349\n",
      "Epoch [89/100], Step [49500/6235], Loss: 23.3503\n",
      "Epoch [89/100], Step [49600/6235], Loss: 692.4002\n",
      "Epoch [89/100], Step [49700/6235], Loss: 5761.0674\n",
      "Epoch [89/100], Step [49800/6235], Loss: 2438.2319\n",
      "Epoch [90/100], Step [100/6235], Loss: 8.6000\n",
      "Epoch [90/100], Step [200/6235], Loss: 0.2281\n",
      "Epoch [90/100], Step [300/6235], Loss: 0.1288\n",
      "Epoch [90/100], Step [400/6235], Loss: 0.0501\n",
      "Epoch [90/100], Step [500/6235], Loss: 6.8108\n",
      "Epoch [90/100], Step [600/6235], Loss: 0.0343\n",
      "Epoch [90/100], Step [700/6235], Loss: 0.5964\n",
      "Epoch [90/100], Step [800/6235], Loss: 0.0839\n",
      "Epoch [90/100], Step [900/6235], Loss: 0.0592\n",
      "Epoch [90/100], Step [1000/6235], Loss: 0.0450\n",
      "Epoch [90/100], Step [1100/6235], Loss: 0.5813\n",
      "Epoch [90/100], Step [1200/6235], Loss: 0.1920\n",
      "Epoch [90/100], Step [1300/6235], Loss: 0.0257\n",
      "Epoch [90/100], Step [1400/6235], Loss: 1.0988\n",
      "Epoch [90/100], Step [1500/6235], Loss: 0.0120\n",
      "Epoch [90/100], Step [1600/6235], Loss: 0.2582\n",
      "Epoch [90/100], Step [1700/6235], Loss: 0.2394\n",
      "Epoch [90/100], Step [1800/6235], Loss: 0.2684\n",
      "Epoch [90/100], Step [1900/6235], Loss: 0.3416\n",
      "Epoch [90/100], Step [2000/6235], Loss: 2.6037\n",
      "Epoch [90/100], Step [2100/6235], Loss: 1.9512\n",
      "Epoch [90/100], Step [2200/6235], Loss: 7.2538\n",
      "Epoch [90/100], Step [2300/6235], Loss: 2.0040\n",
      "Epoch [90/100], Step [2400/6235], Loss: 1.3436\n",
      "Epoch [90/100], Step [2500/6235], Loss: 40.3493\n",
      "Epoch [90/100], Step [2600/6235], Loss: 13.3730\n",
      "Epoch [90/100], Step [2700/6235], Loss: 5.5094\n",
      "Epoch [90/100], Step [2800/6235], Loss: 191.0712\n",
      "Epoch [90/100], Step [2900/6235], Loss: 18.8567\n",
      "Epoch [90/100], Step [3000/6235], Loss: 1.4164\n",
      "Epoch [90/100], Step [3100/6235], Loss: 64.3435\n",
      "Epoch [90/100], Step [3200/6235], Loss: 46.2630\n",
      "Epoch [90/100], Step [3300/6235], Loss: 10.8646\n",
      "Epoch [90/100], Step [3400/6235], Loss: 3.1881\n",
      "Epoch [90/100], Step [3500/6235], Loss: 50.6033\n",
      "Epoch [90/100], Step [3600/6235], Loss: 1.8466\n",
      "Epoch [90/100], Step [3700/6235], Loss: 0.0288\n",
      "Epoch [90/100], Step [3800/6235], Loss: 0.0288\n",
      "Epoch [90/100], Step [3900/6235], Loss: 0.0460\n",
      "Epoch [90/100], Step [4000/6235], Loss: 0.1222\n",
      "Epoch [90/100], Step [4100/6235], Loss: 9.6313\n",
      "Epoch [90/100], Step [4200/6235], Loss: 3.1263\n",
      "Epoch [90/100], Step [4300/6235], Loss: 5.7846\n",
      "Epoch [90/100], Step [4400/6235], Loss: 0.6777\n",
      "Epoch [90/100], Step [4500/6235], Loss: 43.3553\n",
      "Epoch [90/100], Step [4600/6235], Loss: 4.2600\n",
      "Epoch [90/100], Step [4700/6235], Loss: 0.2059\n",
      "Epoch [90/100], Step [4800/6235], Loss: 8.4657\n",
      "Epoch [90/100], Step [4900/6235], Loss: 0.6713\n",
      "Epoch [90/100], Step [5000/6235], Loss: 0.0233\n",
      "Epoch [90/100], Step [5100/6235], Loss: 0.3858\n",
      "Epoch [90/100], Step [5200/6235], Loss: 3.0761\n",
      "Epoch [90/100], Step [5300/6235], Loss: 30.1458\n",
      "Epoch [90/100], Step [5400/6235], Loss: 0.2215\n",
      "Epoch [90/100], Step [5500/6235], Loss: 0.0611\n",
      "Epoch [90/100], Step [5600/6235], Loss: 0.3471\n",
      "Epoch [90/100], Step [5700/6235], Loss: 0.2269\n",
      "Epoch [90/100], Step [5800/6235], Loss: 0.1938\n",
      "Epoch [90/100], Step [5900/6235], Loss: 0.2293\n",
      "Epoch [90/100], Step [6000/6235], Loss: 0.4376\n",
      "Epoch [90/100], Step [6100/6235], Loss: 0.1318\n",
      "Epoch [90/100], Step [6200/6235], Loss: 5.5021\n",
      "Epoch [90/100], Step [6300/6235], Loss: 0.0785\n",
      "Epoch [90/100], Step [6400/6235], Loss: 0.0379\n",
      "Epoch [90/100], Step [6500/6235], Loss: 2.9461\n",
      "Epoch [90/100], Step [6600/6235], Loss: 17.6684\n",
      "Epoch [90/100], Step [6700/6235], Loss: 1.0560\n",
      "Epoch [90/100], Step [6800/6235], Loss: 3.0865\n",
      "Epoch [90/100], Step [6900/6235], Loss: 0.9542\n",
      "Epoch [90/100], Step [7000/6235], Loss: 0.1340\n",
      "Epoch [90/100], Step [7100/6235], Loss: 0.5060\n",
      "Epoch [90/100], Step [7200/6235], Loss: 0.1405\n",
      "Epoch [90/100], Step [7300/6235], Loss: 1.7007\n",
      "Epoch [90/100], Step [7400/6235], Loss: 0.1755\n",
      "Epoch [90/100], Step [7500/6235], Loss: 0.0734\n",
      "Epoch [90/100], Step [7600/6235], Loss: 2.9988\n",
      "Epoch [90/100], Step [7700/6235], Loss: 15.3636\n",
      "Epoch [90/100], Step [7800/6235], Loss: 1.7130\n",
      "Epoch [90/100], Step [7900/6235], Loss: 0.5377\n",
      "Epoch [90/100], Step [8000/6235], Loss: 0.3285\n",
      "Epoch [90/100], Step [8100/6235], Loss: 1.9004\n",
      "Epoch [90/100], Step [8200/6235], Loss: 10.5912\n",
      "Epoch [90/100], Step [8300/6235], Loss: 12.1938\n",
      "Epoch [90/100], Step [8400/6235], Loss: 600.4476\n",
      "Epoch [90/100], Step [8500/6235], Loss: 4.3647\n",
      "Epoch [90/100], Step [8600/6235], Loss: 46.6594\n",
      "Epoch [90/100], Step [8700/6235], Loss: 21.0866\n",
      "Epoch [90/100], Step [8800/6235], Loss: 335.1853\n",
      "Epoch [90/100], Step [8900/6235], Loss: 471.3205\n",
      "Epoch [90/100], Step [9000/6235], Loss: 190.9131\n",
      "Epoch [90/100], Step [9100/6235], Loss: 2492.9556\n",
      "Epoch [90/100], Step [9200/6235], Loss: 3107.0955\n",
      "Epoch [90/100], Step [9300/6235], Loss: 14.1896\n",
      "Epoch [90/100], Step [9400/6235], Loss: 165.4673\n",
      "Epoch [90/100], Step [9500/6235], Loss: 2396.7520\n",
      "Epoch [90/100], Step [9600/6235], Loss: 732.5337\n",
      "Epoch [90/100], Step [9700/6235], Loss: 6.1897\n",
      "Epoch [90/100], Step [9800/6235], Loss: 6537.0640\n",
      "Epoch [90/100], Step [9900/6235], Loss: 122.7458\n",
      "Epoch [90/100], Step [10000/6235], Loss: 471.4992\n",
      "Epoch [90/100], Step [10100/6235], Loss: 3.7047\n",
      "Epoch [90/100], Step [10200/6235], Loss: 588.3363\n",
      "Epoch [90/100], Step [10300/6235], Loss: 48.1905\n",
      "Epoch [90/100], Step [10400/6235], Loss: 8.0707\n",
      "Epoch [90/100], Step [10500/6235], Loss: 36.2113\n",
      "Epoch [90/100], Step [10600/6235], Loss: 92.9230\n",
      "Epoch [90/100], Step [10700/6235], Loss: 9.5251\n",
      "Epoch [90/100], Step [10800/6235], Loss: 112.3917\n",
      "Epoch [90/100], Step [10900/6235], Loss: 58.5009\n",
      "Epoch [90/100], Step [11000/6235], Loss: 299.0528\n",
      "Epoch [90/100], Step [11100/6235], Loss: 45.2331\n",
      "Epoch [90/100], Step [11200/6235], Loss: 7.8100\n",
      "Epoch [90/100], Step [11300/6235], Loss: 99.8617\n",
      "Epoch [90/100], Step [11400/6235], Loss: 25.1858\n",
      "Epoch [90/100], Step [11500/6235], Loss: 11.5381\n",
      "Epoch [90/100], Step [11600/6235], Loss: 8.5418\n",
      "Epoch [90/100], Step [11700/6235], Loss: 50.4376\n",
      "Epoch [90/100], Step [11800/6235], Loss: 396.6585\n",
      "Epoch [90/100], Step [11900/6235], Loss: 67.7588\n",
      "Epoch [90/100], Step [12000/6235], Loss: 597.1147\n",
      "Epoch [90/100], Step [12100/6235], Loss: 202.7956\n",
      "Epoch [90/100], Step [12200/6235], Loss: 182.7442\n",
      "Epoch [90/100], Step [12300/6235], Loss: 52.1845\n",
      "Epoch [90/100], Step [12400/6235], Loss: 541.5452\n",
      "Epoch [90/100], Step [12500/6235], Loss: 22.1521\n",
      "Epoch [90/100], Step [12600/6235], Loss: 63.6434\n",
      "Epoch [90/100], Step [12700/6235], Loss: 3.2465\n",
      "Epoch [90/100], Step [12800/6235], Loss: 5.1974\n",
      "Epoch [90/100], Step [12900/6235], Loss: 35.1381\n",
      "Epoch [90/100], Step [13000/6235], Loss: 0.2154\n",
      "Epoch [90/100], Step [13100/6235], Loss: 64.8993\n",
      "Epoch [90/100], Step [13200/6235], Loss: 10.1825\n",
      "Epoch [90/100], Step [13300/6235], Loss: 48.9810\n",
      "Epoch [90/100], Step [13400/6235], Loss: 245.1156\n",
      "Epoch [90/100], Step [13500/6235], Loss: 4.6125\n",
      "Epoch [90/100], Step [13600/6235], Loss: 14.1199\n",
      "Epoch [90/100], Step [13700/6235], Loss: 1.2723\n",
      "Epoch [90/100], Step [13800/6235], Loss: 172.0362\n",
      "Epoch [90/100], Step [13900/6235], Loss: 51.7629\n",
      "Epoch [90/100], Step [14000/6235], Loss: 8.0557\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Step [14100/6235], Loss: 11.0724\n",
      "Epoch [90/100], Step [14200/6235], Loss: 47.4162\n",
      "Epoch [90/100], Step [14300/6235], Loss: 9.7191\n",
      "Epoch [90/100], Step [14400/6235], Loss: 39.3538\n",
      "Epoch [90/100], Step [14500/6235], Loss: 37.9054\n",
      "Epoch [90/100], Step [14600/6235], Loss: 0.1565\n",
      "Epoch [90/100], Step [14700/6235], Loss: 45.6081\n",
      "Epoch [90/100], Step [14800/6235], Loss: 31.6939\n",
      "Epoch [90/100], Step [14900/6235], Loss: 1.0891\n",
      "Epoch [90/100], Step [15000/6235], Loss: 2.2803\n",
      "Epoch [90/100], Step [15100/6235], Loss: 0.3890\n",
      "Epoch [90/100], Step [15200/6235], Loss: 2.0134\n",
      "Epoch [90/100], Step [15300/6235], Loss: 40.3545\n",
      "Epoch [90/100], Step [15400/6235], Loss: 44.6491\n",
      "Epoch [90/100], Step [15500/6235], Loss: 10.5481\n",
      "Epoch [90/100], Step [15600/6235], Loss: 145.3050\n",
      "Epoch [90/100], Step [15700/6235], Loss: 13.3353\n",
      "Epoch [90/100], Step [15800/6235], Loss: 9.9128\n",
      "Epoch [90/100], Step [15900/6235], Loss: 0.3722\n",
      "Epoch [90/100], Step [16000/6235], Loss: 36.5904\n",
      "Epoch [90/100], Step [16100/6235], Loss: 11.8988\n",
      "Epoch [90/100], Step [16200/6235], Loss: 0.3769\n",
      "Epoch [90/100], Step [16300/6235], Loss: 9.5605\n",
      "Epoch [90/100], Step [16400/6235], Loss: 25.4853\n",
      "Epoch [90/100], Step [16500/6235], Loss: 587.5485\n",
      "Epoch [90/100], Step [16600/6235], Loss: 9.4720\n",
      "Epoch [90/100], Step [16700/6235], Loss: 0.5157\n",
      "Epoch [90/100], Step [16800/6235], Loss: 11.7870\n",
      "Epoch [90/100], Step [16900/6235], Loss: 0.0848\n",
      "Epoch [90/100], Step [17000/6235], Loss: 0.2256\n",
      "Epoch [90/100], Step [17100/6235], Loss: 0.2858\n",
      "Epoch [90/100], Step [17200/6235], Loss: 293.8116\n",
      "Epoch [90/100], Step [17300/6235], Loss: 46.0879\n",
      "Epoch [90/100], Step [17400/6235], Loss: 35.1332\n",
      "Epoch [90/100], Step [17500/6235], Loss: 0.5628\n",
      "Epoch [90/100], Step [17600/6235], Loss: 2.9822\n",
      "Epoch [90/100], Step [17700/6235], Loss: 90.8673\n",
      "Epoch [90/100], Step [17800/6235], Loss: 21.7210\n",
      "Epoch [90/100], Step [17900/6235], Loss: 6.1771\n",
      "Epoch [90/100], Step [18000/6235], Loss: 0.5774\n",
      "Epoch [90/100], Step [18100/6235], Loss: 15.7906\n",
      "Epoch [90/100], Step [18200/6235], Loss: 0.6092\n",
      "Epoch [90/100], Step [18300/6235], Loss: 3.7795\n",
      "Epoch [90/100], Step [18400/6235], Loss: 1.3378\n",
      "Epoch [90/100], Step [18500/6235], Loss: 18.0678\n",
      "Epoch [90/100], Step [18600/6235], Loss: 2.9773\n",
      "Epoch [90/100], Step [18700/6235], Loss: 0.7512\n",
      "Epoch [90/100], Step [18800/6235], Loss: 112.0405\n",
      "Epoch [90/100], Step [18900/6235], Loss: 40.9282\n",
      "Epoch [90/100], Step [19000/6235], Loss: 7.0875\n",
      "Epoch [90/100], Step [19100/6235], Loss: 11.6790\n",
      "Epoch [90/100], Step [19200/6235], Loss: 2.3197\n",
      "Epoch [90/100], Step [19300/6235], Loss: 10.3634\n",
      "Epoch [90/100], Step [19400/6235], Loss: 32.6055\n",
      "Epoch [90/100], Step [19500/6235], Loss: 71.8804\n",
      "Epoch [90/100], Step [19600/6235], Loss: 107.7636\n",
      "Epoch [90/100], Step [19700/6235], Loss: 8.0673\n",
      "Epoch [90/100], Step [19800/6235], Loss: 3.6080\n",
      "Epoch [90/100], Step [19900/6235], Loss: 0.0930\n",
      "Epoch [90/100], Step [20000/6235], Loss: 66.4666\n",
      "Epoch [90/100], Step [20100/6235], Loss: 3.0853\n",
      "Epoch [90/100], Step [20200/6235], Loss: 6.7129\n",
      "Epoch [90/100], Step [20300/6235], Loss: 1.1507\n",
      "Epoch [90/100], Step [20400/6235], Loss: 9.9426\n",
      "Epoch [90/100], Step [20500/6235], Loss: 53.5351\n",
      "Epoch [90/100], Step [20600/6235], Loss: 81.7093\n",
      "Epoch [90/100], Step [20700/6235], Loss: 31.0066\n",
      "Epoch [90/100], Step [20800/6235], Loss: 0.2681\n",
      "Epoch [90/100], Step [20900/6235], Loss: 28.0733\n",
      "Epoch [90/100], Step [21000/6235], Loss: 14.8767\n",
      "Epoch [90/100], Step [21100/6235], Loss: 6.5599\n",
      "Epoch [90/100], Step [21200/6235], Loss: 0.2823\n",
      "Epoch [90/100], Step [21300/6235], Loss: 0.1993\n",
      "Epoch [90/100], Step [21400/6235], Loss: 5.4329\n",
      "Epoch [90/100], Step [21500/6235], Loss: 2.7995\n",
      "Epoch [90/100], Step [21600/6235], Loss: 21.0206\n",
      "Epoch [90/100], Step [21700/6235], Loss: 0.1771\n",
      "Epoch [90/100], Step [21800/6235], Loss: 0.3853\n",
      "Epoch [90/100], Step [21900/6235], Loss: 1.6322\n",
      "Epoch [90/100], Step [22000/6235], Loss: 8.2317\n",
      "Epoch [90/100], Step [22100/6235], Loss: 0.3224\n",
      "Epoch [90/100], Step [22200/6235], Loss: 1.6620\n",
      "Epoch [90/100], Step [22300/6235], Loss: 4.9917\n",
      "Epoch [90/100], Step [22400/6235], Loss: 18.1406\n",
      "Epoch [90/100], Step [22500/6235], Loss: 61.2266\n",
      "Epoch [90/100], Step [22600/6235], Loss: 25.2345\n",
      "Epoch [90/100], Step [22700/6235], Loss: 0.5388\n",
      "Epoch [90/100], Step [22800/6235], Loss: 10.6211\n",
      "Epoch [90/100], Step [22900/6235], Loss: 20.0369\n",
      "Epoch [90/100], Step [23000/6235], Loss: 11.2287\n",
      "Epoch [90/100], Step [23100/6235], Loss: 5.1298\n",
      "Epoch [90/100], Step [23200/6235], Loss: 14.5973\n",
      "Epoch [90/100], Step [23300/6235], Loss: 18.6401\n",
      "Epoch [90/100], Step [23400/6235], Loss: 2.3314\n",
      "Epoch [90/100], Step [23500/6235], Loss: 0.0589\n",
      "Epoch [90/100], Step [23600/6235], Loss: 125.2824\n",
      "Epoch [90/100], Step [23700/6235], Loss: 5.6743\n",
      "Epoch [90/100], Step [23800/6235], Loss: 1.2184\n",
      "Epoch [90/100], Step [23900/6235], Loss: 4.0378\n",
      "Epoch [90/100], Step [24000/6235], Loss: 0.1559\n",
      "Epoch [90/100], Step [24100/6235], Loss: 0.9038\n",
      "Epoch [90/100], Step [24200/6235], Loss: 31.1237\n",
      "Epoch [90/100], Step [24300/6235], Loss: 0.9950\n",
      "Epoch [90/100], Step [24400/6235], Loss: 3.2753\n",
      "Epoch [90/100], Step [24500/6235], Loss: 1.2948\n",
      "Epoch [90/100], Step [24600/6235], Loss: 0.1405\n",
      "Epoch [90/100], Step [24700/6235], Loss: 3.4081\n",
      "Epoch [90/100], Step [24800/6235], Loss: 0.2752\n",
      "Epoch [90/100], Step [24900/6235], Loss: 13.0342\n",
      "Epoch [90/100], Step [25000/6235], Loss: 15.3381\n",
      "Epoch [90/100], Step [25100/6235], Loss: 7.3756\n",
      "Epoch [90/100], Step [25200/6235], Loss: 0.8130\n",
      "Epoch [90/100], Step [25300/6235], Loss: 0.5803\n",
      "Epoch [90/100], Step [25400/6235], Loss: 9.6696\n",
      "Epoch [90/100], Step [25500/6235], Loss: 8.0608\n",
      "Epoch [90/100], Step [25600/6235], Loss: 5.3686\n",
      "Epoch [90/100], Step [25700/6235], Loss: 0.2684\n",
      "Epoch [90/100], Step [25800/6235], Loss: 0.0896\n",
      "Epoch [90/100], Step [25900/6235], Loss: 7.1208\n",
      "Epoch [90/100], Step [26000/6235], Loss: 0.4844\n",
      "Epoch [90/100], Step [26100/6235], Loss: 0.4398\n",
      "Epoch [90/100], Step [26200/6235], Loss: 0.3330\n",
      "Epoch [90/100], Step [26300/6235], Loss: 4.9520\n",
      "Epoch [90/100], Step [26400/6235], Loss: 0.0880\n",
      "Epoch [90/100], Step [26500/6235], Loss: 0.0142\n",
      "Epoch [90/100], Step [26600/6235], Loss: 1.4843\n",
      "Epoch [90/100], Step [26700/6235], Loss: 0.3732\n",
      "Epoch [90/100], Step [26800/6235], Loss: 0.1779\n",
      "Epoch [90/100], Step [26900/6235], Loss: 0.0005\n",
      "Epoch [90/100], Step [27000/6235], Loss: 15.1084\n",
      "Epoch [90/100], Step [27100/6235], Loss: 0.0444\n",
      "Epoch [90/100], Step [27200/6235], Loss: 0.0224\n",
      "Epoch [90/100], Step [27300/6235], Loss: 0.2125\n",
      "Epoch [90/100], Step [27400/6235], Loss: 0.7734\n",
      "Epoch [90/100], Step [27500/6235], Loss: 17.0875\n",
      "Epoch [90/100], Step [27600/6235], Loss: 0.7623\n",
      "Epoch [90/100], Step [27700/6235], Loss: 1.5232\n",
      "Epoch [90/100], Step [27800/6235], Loss: 1.6237\n",
      "Epoch [90/100], Step [27900/6235], Loss: 0.8646\n",
      "Epoch [90/100], Step [28000/6235], Loss: 162.9509\n",
      "Epoch [90/100], Step [28100/6235], Loss: 4.0641\n",
      "Epoch [90/100], Step [28200/6235], Loss: 28.2756\n",
      "Epoch [90/100], Step [28300/6235], Loss: 3.2445\n",
      "Epoch [90/100], Step [28400/6235], Loss: 25.9003\n",
      "Epoch [90/100], Step [28500/6235], Loss: 4.0774\n",
      "Epoch [90/100], Step [28600/6235], Loss: 0.1167\n",
      "Epoch [90/100], Step [28700/6235], Loss: 5.1689\n",
      "Epoch [90/100], Step [28800/6235], Loss: 0.5121\n",
      "Epoch [90/100], Step [28900/6235], Loss: 71.1313\n",
      "Epoch [90/100], Step [29000/6235], Loss: 7.8454\n",
      "Epoch [90/100], Step [29100/6235], Loss: 0.1314\n",
      "Epoch [90/100], Step [29200/6235], Loss: 0.6592\n",
      "Epoch [90/100], Step [29300/6235], Loss: 16.6287\n",
      "Epoch [90/100], Step [29400/6235], Loss: 0.0982\n",
      "Epoch [90/100], Step [29500/6235], Loss: 3.8407\n",
      "Epoch [90/100], Step [29600/6235], Loss: 0.1062\n",
      "Epoch [90/100], Step [29700/6235], Loss: 0.4454\n",
      "Epoch [90/100], Step [29800/6235], Loss: 1.7352\n",
      "Epoch [90/100], Step [29900/6235], Loss: 0.2343\n",
      "Epoch [90/100], Step [30000/6235], Loss: 8.3629\n",
      "Epoch [90/100], Step [30100/6235], Loss: 1.8274\n",
      "Epoch [90/100], Step [30200/6235], Loss: 0.4567\n",
      "Epoch [90/100], Step [30300/6235], Loss: 0.3410\n",
      "Epoch [90/100], Step [30400/6235], Loss: 0.5633\n",
      "Epoch [90/100], Step [30500/6235], Loss: 2.9518\n",
      "Epoch [90/100], Step [30600/6235], Loss: 1.2078\n",
      "Epoch [90/100], Step [30700/6235], Loss: 0.0312\n",
      "Epoch [90/100], Step [30800/6235], Loss: 0.3519\n",
      "Epoch [90/100], Step [30900/6235], Loss: 3.7023\n",
      "Epoch [90/100], Step [31000/6235], Loss: 0.0168\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Step [31100/6235], Loss: 0.0527\n",
      "Epoch [90/100], Step [31200/6235], Loss: 7.3168\n",
      "Epoch [90/100], Step [31300/6235], Loss: 3.2025\n",
      "Epoch [90/100], Step [31400/6235], Loss: 3.1151\n",
      "Epoch [90/100], Step [31500/6235], Loss: 0.5121\n",
      "Epoch [90/100], Step [31600/6235], Loss: 14.8089\n",
      "Epoch [90/100], Step [31700/6235], Loss: 2.3346\n",
      "Epoch [90/100], Step [31800/6235], Loss: 1.1130\n",
      "Epoch [90/100], Step [31900/6235], Loss: 671.1387\n",
      "Epoch [90/100], Step [32000/6235], Loss: 36.9557\n",
      "Epoch [90/100], Step [32100/6235], Loss: 0.4860\n",
      "Epoch [90/100], Step [32200/6235], Loss: 130.5809\n",
      "Epoch [90/100], Step [32300/6235], Loss: 1.3662\n",
      "Epoch [90/100], Step [32400/6235], Loss: 1.3083\n",
      "Epoch [90/100], Step [32500/6235], Loss: 17.1353\n",
      "Epoch [90/100], Step [32600/6235], Loss: 0.5758\n",
      "Epoch [90/100], Step [32700/6235], Loss: 70.3552\n",
      "Epoch [90/100], Step [32800/6235], Loss: 2.6799\n",
      "Epoch [90/100], Step [32900/6235], Loss: 4.2860\n",
      "Epoch [90/100], Step [33000/6235], Loss: 0.4686\n",
      "Epoch [90/100], Step [33100/6235], Loss: 1.1484\n",
      "Epoch [90/100], Step [33200/6235], Loss: 1.7290\n",
      "Epoch [90/100], Step [33300/6235], Loss: 0.2118\n",
      "Epoch [90/100], Step [33400/6235], Loss: 62.5275\n",
      "Epoch [90/100], Step [33500/6235], Loss: 1.1236\n",
      "Epoch [90/100], Step [33600/6235], Loss: 9.3406\n",
      "Epoch [90/100], Step [33700/6235], Loss: 14.6273\n",
      "Epoch [90/100], Step [33800/6235], Loss: 0.4548\n",
      "Epoch [90/100], Step [33900/6235], Loss: 28.8879\n",
      "Epoch [90/100], Step [34000/6235], Loss: 0.0456\n",
      "Epoch [90/100], Step [34100/6235], Loss: 0.4406\n",
      "Epoch [90/100], Step [34200/6235], Loss: 2.8580\n",
      "Epoch [90/100], Step [34300/6235], Loss: 4.6984\n",
      "Epoch [90/100], Step [34400/6235], Loss: 0.2662\n",
      "Epoch [90/100], Step [34500/6235], Loss: 39.8272\n",
      "Epoch [90/100], Step [34600/6235], Loss: 0.2465\n",
      "Epoch [90/100], Step [34700/6235], Loss: 16.3655\n",
      "Epoch [90/100], Step [34800/6235], Loss: 7.7610\n",
      "Epoch [90/100], Step [34900/6235], Loss: 61.0132\n",
      "Epoch [90/100], Step [35000/6235], Loss: 0.1416\n",
      "Epoch [90/100], Step [35100/6235], Loss: 0.5748\n",
      "Epoch [90/100], Step [35200/6235], Loss: 0.1331\n",
      "Epoch [90/100], Step [35300/6235], Loss: 2.5703\n",
      "Epoch [90/100], Step [35400/6235], Loss: 0.4618\n",
      "Epoch [90/100], Step [35500/6235], Loss: 2.0463\n",
      "Epoch [90/100], Step [35600/6235], Loss: 0.3345\n",
      "Epoch [90/100], Step [35700/6235], Loss: 6.1052\n",
      "Epoch [90/100], Step [35800/6235], Loss: 0.1591\n",
      "Epoch [90/100], Step [35900/6235], Loss: 0.1733\n",
      "Epoch [90/100], Step [36000/6235], Loss: 0.0907\n",
      "Epoch [90/100], Step [36100/6235], Loss: 0.0254\n",
      "Epoch [90/100], Step [36200/6235], Loss: 20.4553\n",
      "Epoch [90/100], Step [36300/6235], Loss: 1.0086\n",
      "Epoch [90/100], Step [36400/6235], Loss: 2.6157\n",
      "Epoch [90/100], Step [36500/6235], Loss: 8.7449\n",
      "Epoch [90/100], Step [36600/6235], Loss: 0.1276\n",
      "Epoch [90/100], Step [36700/6235], Loss: 0.4570\n",
      "Epoch [90/100], Step [36800/6235], Loss: 11.5251\n",
      "Epoch [90/100], Step [36900/6235], Loss: 5.1458\n",
      "Epoch [90/100], Step [37000/6235], Loss: 0.5731\n",
      "Epoch [90/100], Step [37100/6235], Loss: 1.1570\n",
      "Epoch [90/100], Step [37200/6235], Loss: 0.0843\n",
      "Epoch [90/100], Step [37300/6235], Loss: 0.0409\n",
      "Epoch [90/100], Step [37400/6235], Loss: 0.1996\n",
      "Epoch [90/100], Step [37500/6235], Loss: 4.7981\n",
      "Epoch [90/100], Step [37600/6235], Loss: 11.8037\n",
      "Epoch [90/100], Step [37700/6235], Loss: 1.6405\n",
      "Epoch [90/100], Step [37800/6235], Loss: 5.1615\n",
      "Epoch [90/100], Step [37900/6235], Loss: 6.2155\n",
      "Epoch [90/100], Step [38000/6235], Loss: 0.7005\n",
      "Epoch [90/100], Step [38100/6235], Loss: 4.4877\n",
      "Epoch [90/100], Step [38200/6235], Loss: 2.4976\n",
      "Epoch [90/100], Step [38300/6235], Loss: 0.5862\n",
      "Epoch [90/100], Step [38400/6235], Loss: 0.0871\n",
      "Epoch [90/100], Step [38500/6235], Loss: 2.3278\n",
      "Epoch [90/100], Step [38600/6235], Loss: 0.2234\n",
      "Epoch [90/100], Step [38700/6235], Loss: 0.0527\n",
      "Epoch [90/100], Step [38800/6235], Loss: 0.1953\n",
      "Epoch [90/100], Step [38900/6235], Loss: 0.5374\n",
      "Epoch [90/100], Step [39000/6235], Loss: 17.1982\n",
      "Epoch [90/100], Step [39100/6235], Loss: 18.0937\n",
      "Epoch [90/100], Step [39200/6235], Loss: 0.2246\n",
      "Epoch [90/100], Step [39300/6235], Loss: 35.3266\n",
      "Epoch [90/100], Step [39400/6235], Loss: 224.5981\n",
      "Epoch [90/100], Step [39500/6235], Loss: 7.6125\n",
      "Epoch [90/100], Step [39600/6235], Loss: 3.4884\n",
      "Epoch [90/100], Step [39700/6235], Loss: 7.0621\n",
      "Epoch [90/100], Step [39800/6235], Loss: 84.0134\n",
      "Epoch [90/100], Step [39900/6235], Loss: 3.5074\n",
      "Epoch [90/100], Step [40000/6235], Loss: 14.1531\n",
      "Epoch [90/100], Step [40100/6235], Loss: 16.4052\n",
      "Epoch [90/100], Step [40200/6235], Loss: 5.7912\n",
      "Epoch [90/100], Step [40300/6235], Loss: 0.7944\n",
      "Epoch [90/100], Step [40400/6235], Loss: 1.0546\n",
      "Epoch [90/100], Step [40500/6235], Loss: 2.8644\n",
      "Epoch [90/100], Step [40600/6235], Loss: 0.2117\n",
      "Epoch [90/100], Step [40700/6235], Loss: 6.7059\n",
      "Epoch [90/100], Step [40800/6235], Loss: 0.4959\n",
      "Epoch [90/100], Step [40900/6235], Loss: 0.9484\n",
      "Epoch [90/100], Step [41000/6235], Loss: 45.6349\n",
      "Epoch [90/100], Step [41100/6235], Loss: 26.3488\n",
      "Epoch [90/100], Step [41200/6235], Loss: 5.4386\n",
      "Epoch [90/100], Step [41300/6235], Loss: 2.5480\n",
      "Epoch [90/100], Step [41400/6235], Loss: 0.3021\n",
      "Epoch [90/100], Step [41500/6235], Loss: 1.0158\n",
      "Epoch [90/100], Step [41600/6235], Loss: 0.1196\n",
      "Epoch [90/100], Step [41700/6235], Loss: 0.2406\n",
      "Epoch [90/100], Step [41800/6235], Loss: 1.6115\n",
      "Epoch [90/100], Step [41900/6235], Loss: 4.6855\n",
      "Epoch [90/100], Step [42000/6235], Loss: 3.6289\n",
      "Epoch [90/100], Step [42100/6235], Loss: 8.5848\n",
      "Epoch [90/100], Step [42200/6235], Loss: 18.5655\n",
      "Epoch [90/100], Step [42300/6235], Loss: 0.6662\n",
      "Epoch [90/100], Step [42400/6235], Loss: 1.4108\n",
      "Epoch [90/100], Step [42500/6235], Loss: 2.2468\n",
      "Epoch [90/100], Step [42600/6235], Loss: 0.4661\n",
      "Epoch [90/100], Step [42700/6235], Loss: 0.1488\n",
      "Epoch [90/100], Step [42800/6235], Loss: 2.2995\n",
      "Epoch [90/100], Step [42900/6235], Loss: 3.8024\n",
      "Epoch [90/100], Step [43000/6235], Loss: 0.2403\n",
      "Epoch [90/100], Step [43100/6235], Loss: 0.4335\n",
      "Epoch [90/100], Step [43200/6235], Loss: 1.0280\n",
      "Epoch [90/100], Step [43300/6235], Loss: 8.6751\n",
      "Epoch [90/100], Step [43400/6235], Loss: 11.6655\n",
      "Epoch [90/100], Step [43500/6235], Loss: 9.5447\n",
      "Epoch [90/100], Step [43600/6235], Loss: 11.6809\n",
      "Epoch [90/100], Step [43700/6235], Loss: 46.4325\n",
      "Epoch [90/100], Step [43800/6235], Loss: 0.3232\n",
      "Epoch [90/100], Step [43900/6235], Loss: 1.1623\n",
      "Epoch [90/100], Step [44000/6235], Loss: 62.4583\n",
      "Epoch [90/100], Step [44100/6235], Loss: 5.9775\n",
      "Epoch [90/100], Step [44200/6235], Loss: 4.0376\n",
      "Epoch [90/100], Step [44300/6235], Loss: 1.8806\n",
      "Epoch [90/100], Step [44400/6235], Loss: 0.5618\n",
      "Epoch [90/100], Step [44500/6235], Loss: 0.5699\n",
      "Epoch [90/100], Step [44600/6235], Loss: 22.5228\n",
      "Epoch [90/100], Step [44700/6235], Loss: 1.2937\n",
      "Epoch [90/100], Step [44800/6235], Loss: 4.1150\n",
      "Epoch [90/100], Step [44900/6235], Loss: 11.9065\n",
      "Epoch [90/100], Step [45000/6235], Loss: 6.4492\n",
      "Epoch [90/100], Step [45100/6235], Loss: 27.7435\n",
      "Epoch [90/100], Step [45200/6235], Loss: 0.5848\n",
      "Epoch [90/100], Step [45300/6235], Loss: 24.7811\n",
      "Epoch [90/100], Step [45400/6235], Loss: 12.0403\n",
      "Epoch [90/100], Step [45500/6235], Loss: 3.1701\n",
      "Epoch [90/100], Step [45600/6235], Loss: 0.8713\n",
      "Epoch [90/100], Step [45700/6235], Loss: 132.1706\n",
      "Epoch [90/100], Step [45800/6235], Loss: 199.9508\n",
      "Epoch [90/100], Step [45900/6235], Loss: 37.7444\n",
      "Epoch [90/100], Step [46000/6235], Loss: 19.4958\n",
      "Epoch [90/100], Step [46100/6235], Loss: 78.8606\n",
      "Epoch [90/100], Step [46200/6235], Loss: 30.6239\n",
      "Epoch [90/100], Step [46300/6235], Loss: 22.4317\n",
      "Epoch [90/100], Step [46400/6235], Loss: 10.8761\n",
      "Epoch [90/100], Step [46500/6235], Loss: 24.3850\n",
      "Epoch [90/100], Step [46600/6235], Loss: 11.3164\n",
      "Epoch [90/100], Step [46700/6235], Loss: 1.9289\n",
      "Epoch [90/100], Step [46800/6235], Loss: 83.7512\n",
      "Epoch [90/100], Step [46900/6235], Loss: 34.7510\n",
      "Epoch [90/100], Step [47000/6235], Loss: 2.1571\n",
      "Epoch [90/100], Step [47100/6235], Loss: 162.5764\n",
      "Epoch [90/100], Step [47200/6235], Loss: 6.9643\n",
      "Epoch [90/100], Step [47300/6235], Loss: 3.2116\n",
      "Epoch [90/100], Step [47400/6235], Loss: 292.5510\n",
      "Epoch [90/100], Step [47500/6235], Loss: 1.2120\n",
      "Epoch [90/100], Step [47600/6235], Loss: 3.2296\n",
      "Epoch [90/100], Step [47700/6235], Loss: 45.8469\n",
      "Epoch [90/100], Step [47800/6235], Loss: 64.8464\n",
      "Epoch [90/100], Step [47900/6235], Loss: 24.4541\n",
      "Epoch [90/100], Step [48000/6235], Loss: 72.2439\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [90/100], Step [48100/6235], Loss: 62.7029\n",
      "Epoch [90/100], Step [48200/6235], Loss: 155.1683\n",
      "Epoch [90/100], Step [48300/6235], Loss: 894.3740\n",
      "Epoch [90/100], Step [48400/6235], Loss: 8.7650\n",
      "Epoch [90/100], Step [48500/6235], Loss: 13.1968\n",
      "Epoch [90/100], Step [48600/6235], Loss: 21.2573\n",
      "Epoch [90/100], Step [48700/6235], Loss: 43.8190\n",
      "Epoch [90/100], Step [48800/6235], Loss: 310.1041\n",
      "Epoch [90/100], Step [48900/6235], Loss: 604.5702\n",
      "Epoch [90/100], Step [49000/6235], Loss: 257.1771\n",
      "Epoch [90/100], Step [49100/6235], Loss: 1385.9812\n",
      "Epoch [90/100], Step [49200/6235], Loss: 790.7460\n",
      "Epoch [90/100], Step [49300/6235], Loss: 956.2900\n",
      "Epoch [90/100], Step [49400/6235], Loss: 3.7016\n",
      "Epoch [90/100], Step [49500/6235], Loss: 27.2969\n",
      "Epoch [90/100], Step [49600/6235], Loss: 1074.1857\n",
      "Epoch [90/100], Step [49700/6235], Loss: 151.0087\n",
      "Epoch [90/100], Step [49800/6235], Loss: 96.4515\n",
      "Epoch [91/100], Step [100/6235], Loss: 39.8276\n",
      "Epoch [91/100], Step [200/6235], Loss: 0.3436\n",
      "Epoch [91/100], Step [300/6235], Loss: 0.0804\n",
      "Epoch [91/100], Step [400/6235], Loss: 0.0225\n",
      "Epoch [91/100], Step [500/6235], Loss: 18.1125\n",
      "Epoch [91/100], Step [600/6235], Loss: 0.1074\n",
      "Epoch [91/100], Step [700/6235], Loss: 0.2982\n",
      "Epoch [91/100], Step [800/6235], Loss: 0.0095\n",
      "Epoch [91/100], Step [900/6235], Loss: 0.0508\n",
      "Epoch [91/100], Step [1000/6235], Loss: 0.0368\n",
      "Epoch [91/100], Step [1100/6235], Loss: 0.9371\n",
      "Epoch [91/100], Step [1200/6235], Loss: 0.1107\n",
      "Epoch [91/100], Step [1300/6235], Loss: 0.0178\n",
      "Epoch [91/100], Step [1400/6235], Loss: 0.7263\n",
      "Epoch [91/100], Step [1500/6235], Loss: 0.0013\n",
      "Epoch [91/100], Step [1600/6235], Loss: 0.2789\n",
      "Epoch [91/100], Step [1700/6235], Loss: 0.1009\n",
      "Epoch [91/100], Step [1800/6235], Loss: 0.3532\n",
      "Epoch [91/100], Step [1900/6235], Loss: 0.0959\n",
      "Epoch [91/100], Step [2000/6235], Loss: 2.0911\n",
      "Epoch [91/100], Step [2100/6235], Loss: 2.4983\n",
      "Epoch [91/100], Step [2200/6235], Loss: 1.6190\n",
      "Epoch [91/100], Step [2300/6235], Loss: 0.8144\n",
      "Epoch [91/100], Step [2400/6235], Loss: 20.5780\n",
      "Epoch [91/100], Step [2500/6235], Loss: 12.5145\n",
      "Epoch [91/100], Step [2600/6235], Loss: 10.7270\n",
      "Epoch [91/100], Step [2700/6235], Loss: 22.9226\n",
      "Epoch [91/100], Step [2800/6235], Loss: 67.5527\n",
      "Epoch [91/100], Step [2900/6235], Loss: 9.5154\n",
      "Epoch [91/100], Step [3000/6235], Loss: 7.2373\n",
      "Epoch [91/100], Step [3100/6235], Loss: 102.0763\n",
      "Epoch [91/100], Step [3200/6235], Loss: 2.1630\n",
      "Epoch [91/100], Step [3300/6235], Loss: 1.7270\n",
      "Epoch [91/100], Step [3400/6235], Loss: 6.3187\n",
      "Epoch [91/100], Step [3500/6235], Loss: 84.0193\n",
      "Epoch [91/100], Step [3600/6235], Loss: 5.0581\n",
      "Epoch [91/100], Step [3700/6235], Loss: 0.6252\n",
      "Epoch [91/100], Step [3800/6235], Loss: 0.4612\n",
      "Epoch [91/100], Step [3900/6235], Loss: 0.7658\n",
      "Epoch [91/100], Step [4000/6235], Loss: 0.8316\n",
      "Epoch [91/100], Step [4100/6235], Loss: 4.5059\n",
      "Epoch [91/100], Step [4200/6235], Loss: 0.1066\n",
      "Epoch [91/100], Step [4300/6235], Loss: 1.6530\n",
      "Epoch [91/100], Step [4400/6235], Loss: 0.0722\n",
      "Epoch [91/100], Step [4500/6235], Loss: 66.2821\n",
      "Epoch [91/100], Step [4600/6235], Loss: 22.4514\n",
      "Epoch [91/100], Step [4700/6235], Loss: 3.7969\n",
      "Epoch [91/100], Step [4800/6235], Loss: 1.8914\n",
      "Epoch [91/100], Step [4900/6235], Loss: 1.0394\n",
      "Epoch [91/100], Step [5000/6235], Loss: 0.7986\n",
      "Epoch [91/100], Step [5100/6235], Loss: 11.9875\n",
      "Epoch [91/100], Step [5200/6235], Loss: 0.5713\n",
      "Epoch [91/100], Step [5300/6235], Loss: 13.6842\n",
      "Epoch [91/100], Step [5400/6235], Loss: 1.6139\n",
      "Epoch [91/100], Step [5500/6235], Loss: 0.4237\n",
      "Epoch [91/100], Step [5600/6235], Loss: 0.7260\n",
      "Epoch [91/100], Step [5700/6235], Loss: 0.8094\n",
      "Epoch [91/100], Step [5800/6235], Loss: 1.1479\n",
      "Epoch [91/100], Step [5900/6235], Loss: 0.0239\n",
      "Epoch [91/100], Step [6000/6235], Loss: 0.3704\n",
      "Epoch [91/100], Step [6100/6235], Loss: 0.0465\n",
      "Epoch [91/100], Step [6200/6235], Loss: 4.1556\n",
      "Epoch [91/100], Step [6300/6235], Loss: 0.3060\n",
      "Epoch [91/100], Step [6400/6235], Loss: 0.0076\n",
      "Epoch [91/100], Step [6500/6235], Loss: 1.0489\n",
      "Epoch [91/100], Step [6600/6235], Loss: 5.0776\n",
      "Epoch [91/100], Step [6700/6235], Loss: 2.1609\n",
      "Epoch [91/100], Step [6800/6235], Loss: 0.3538\n",
      "Epoch [91/100], Step [6900/6235], Loss: 0.4359\n",
      "Epoch [91/100], Step [7000/6235], Loss: 0.0266\n",
      "Epoch [91/100], Step [7100/6235], Loss: 0.0528\n",
      "Epoch [91/100], Step [7200/6235], Loss: 0.2464\n",
      "Epoch [91/100], Step [7300/6235], Loss: 1.5184\n",
      "Epoch [91/100], Step [7400/6235], Loss: 0.1331\n",
      "Epoch [91/100], Step [7500/6235], Loss: 0.7150\n",
      "Epoch [91/100], Step [7600/6235], Loss: 2.6371\n",
      "Epoch [91/100], Step [7700/6235], Loss: 3.4349\n",
      "Epoch [91/100], Step [7800/6235], Loss: 4.1180\n",
      "Epoch [91/100], Step [7900/6235], Loss: 8.9894\n",
      "Epoch [91/100], Step [8000/6235], Loss: 0.6326\n",
      "Epoch [91/100], Step [8100/6235], Loss: 0.1274\n",
      "Epoch [91/100], Step [8200/6235], Loss: 10.8452\n",
      "Epoch [91/100], Step [8300/6235], Loss: 12.4956\n",
      "Epoch [91/100], Step [8400/6235], Loss: 648.7017\n",
      "Epoch [91/100], Step [8500/6235], Loss: 17.5126\n",
      "Epoch [91/100], Step [8600/6235], Loss: 29.5687\n",
      "Epoch [91/100], Step [8700/6235], Loss: 19.6314\n",
      "Epoch [91/100], Step [8800/6235], Loss: 1318.1018\n",
      "Epoch [91/100], Step [8900/6235], Loss: 217.1435\n",
      "Epoch [91/100], Step [9000/6235], Loss: 648.3550\n",
      "Epoch [91/100], Step [9100/6235], Loss: 1857.4829\n",
      "Epoch [91/100], Step [9200/6235], Loss: 2812.1582\n",
      "Epoch [91/100], Step [9300/6235], Loss: 103.2108\n",
      "Epoch [91/100], Step [9400/6235], Loss: 127.0916\n",
      "Epoch [91/100], Step [9500/6235], Loss: 1376.2725\n",
      "Epoch [91/100], Step [9600/6235], Loss: 804.4064\n",
      "Epoch [91/100], Step [9700/6235], Loss: 9.4501\n",
      "Epoch [91/100], Step [9800/6235], Loss: 3769.4604\n",
      "Epoch [91/100], Step [9900/6235], Loss: 285.6660\n",
      "Epoch [91/100], Step [10000/6235], Loss: 600.8783\n",
      "Epoch [91/100], Step [10100/6235], Loss: 4.3775\n",
      "Epoch [91/100], Step [10200/6235], Loss: 475.1801\n",
      "Epoch [91/100], Step [10300/6235], Loss: 16.4500\n",
      "Epoch [91/100], Step [10400/6235], Loss: 9.2409\n",
      "Epoch [91/100], Step [10500/6235], Loss: 4.1284\n",
      "Epoch [91/100], Step [10600/6235], Loss: 7.8419\n",
      "Epoch [91/100], Step [10700/6235], Loss: 16.4179\n",
      "Epoch [91/100], Step [10800/6235], Loss: 64.2822\n",
      "Epoch [91/100], Step [10900/6235], Loss: 7.1197\n",
      "Epoch [91/100], Step [11000/6235], Loss: 297.7405\n",
      "Epoch [91/100], Step [11100/6235], Loss: 44.2197\n",
      "Epoch [91/100], Step [11200/6235], Loss: 26.0578\n",
      "Epoch [91/100], Step [11300/6235], Loss: 130.9628\n",
      "Epoch [91/100], Step [11400/6235], Loss: 8.1366\n",
      "Epoch [91/100], Step [11500/6235], Loss: 8.7409\n",
      "Epoch [91/100], Step [11600/6235], Loss: 5.6408\n",
      "Epoch [91/100], Step [11700/6235], Loss: 46.0681\n",
      "Epoch [91/100], Step [11800/6235], Loss: 398.7775\n",
      "Epoch [91/100], Step [11900/6235], Loss: 375.0325\n",
      "Epoch [91/100], Step [12000/6235], Loss: 314.4697\n",
      "Epoch [91/100], Step [12100/6235], Loss: 183.2382\n",
      "Epoch [91/100], Step [12200/6235], Loss: 220.9989\n",
      "Epoch [91/100], Step [12300/6235], Loss: 59.6642\n",
      "Epoch [91/100], Step [12400/6235], Loss: 82.3133\n",
      "Epoch [91/100], Step [12500/6235], Loss: 13.3999\n",
      "Epoch [91/100], Step [12600/6235], Loss: 80.3256\n",
      "Epoch [91/100], Step [12700/6235], Loss: 0.5656\n",
      "Epoch [91/100], Step [12800/6235], Loss: 6.6988\n",
      "Epoch [91/100], Step [12900/6235], Loss: 35.8573\n",
      "Epoch [91/100], Step [13000/6235], Loss: 0.2646\n",
      "Epoch [91/100], Step [13100/6235], Loss: 65.4698\n",
      "Epoch [91/100], Step [13200/6235], Loss: 9.4831\n",
      "Epoch [91/100], Step [13300/6235], Loss: 36.9481\n",
      "Epoch [91/100], Step [13400/6235], Loss: 245.4692\n",
      "Epoch [91/100], Step [13500/6235], Loss: 5.8837\n",
      "Epoch [91/100], Step [13600/6235], Loss: 19.8831\n",
      "Epoch [91/100], Step [13700/6235], Loss: 0.5735\n",
      "Epoch [91/100], Step [13800/6235], Loss: 171.5544\n",
      "Epoch [91/100], Step [13900/6235], Loss: 57.8429\n",
      "Epoch [91/100], Step [14000/6235], Loss: 9.6451\n",
      "Epoch [91/100], Step [14100/6235], Loss: 32.1468\n",
      "Epoch [91/100], Step [14200/6235], Loss: 112.0386\n",
      "Epoch [91/100], Step [14300/6235], Loss: 41.7804\n",
      "Epoch [91/100], Step [14400/6235], Loss: 39.0301\n",
      "Epoch [91/100], Step [14500/6235], Loss: 54.2317\n",
      "Epoch [91/100], Step [14600/6235], Loss: 0.0796\n",
      "Epoch [91/100], Step [14700/6235], Loss: 45.0469\n",
      "Epoch [91/100], Step [14800/6235], Loss: 32.4058\n",
      "Epoch [91/100], Step [14900/6235], Loss: 0.9374\n",
      "Epoch [91/100], Step [15000/6235], Loss: 2.0698\n",
      "Epoch [91/100], Step [15100/6235], Loss: 0.4462\n",
      "Epoch [91/100], Step [15200/6235], Loss: 4.6852\n",
      "Epoch [91/100], Step [15300/6235], Loss: 39.2629\n",
      "Epoch [91/100], Step [15400/6235], Loss: 27.3964\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Step [15500/6235], Loss: 10.2892\n",
      "Epoch [91/100], Step [15600/6235], Loss: 151.2043\n",
      "Epoch [91/100], Step [15700/6235], Loss: 16.1352\n",
      "Epoch [91/100], Step [15800/6235], Loss: 9.8094\n",
      "Epoch [91/100], Step [15900/6235], Loss: 0.7321\n",
      "Epoch [91/100], Step [16000/6235], Loss: 47.5322\n",
      "Epoch [91/100], Step [16100/6235], Loss: 1.8358\n",
      "Epoch [91/100], Step [16200/6235], Loss: 0.3440\n",
      "Epoch [91/100], Step [16300/6235], Loss: 8.9597\n",
      "Epoch [91/100], Step [16400/6235], Loss: 26.9766\n",
      "Epoch [91/100], Step [16500/6235], Loss: 129.5184\n",
      "Epoch [91/100], Step [16600/6235], Loss: 8.3206\n",
      "Epoch [91/100], Step [16700/6235], Loss: 0.6452\n",
      "Epoch [91/100], Step [16800/6235], Loss: 11.2872\n",
      "Epoch [91/100], Step [16900/6235], Loss: 0.1506\n",
      "Epoch [91/100], Step [17000/6235], Loss: 0.2103\n",
      "Epoch [91/100], Step [17100/6235], Loss: 0.2065\n",
      "Epoch [91/100], Step [17200/6235], Loss: 277.3835\n",
      "Epoch [91/100], Step [17300/6235], Loss: 10.4352\n",
      "Epoch [91/100], Step [17400/6235], Loss: 31.7459\n",
      "Epoch [91/100], Step [17500/6235], Loss: 1.3075\n",
      "Epoch [91/100], Step [17600/6235], Loss: 2.8061\n",
      "Epoch [91/100], Step [17700/6235], Loss: 1.2862\n",
      "Epoch [91/100], Step [17800/6235], Loss: 34.4736\n",
      "Epoch [91/100], Step [17900/6235], Loss: 4.6572\n",
      "Epoch [91/100], Step [18000/6235], Loss: 21.5320\n",
      "Epoch [91/100], Step [18100/6235], Loss: 15.1834\n",
      "Epoch [91/100], Step [18200/6235], Loss: 0.5220\n",
      "Epoch [91/100], Step [18300/6235], Loss: 3.4637\n",
      "Epoch [91/100], Step [18400/6235], Loss: 3.3430\n",
      "Epoch [91/100], Step [18500/6235], Loss: 26.1586\n",
      "Epoch [91/100], Step [18600/6235], Loss: 1.9870\n",
      "Epoch [91/100], Step [18700/6235], Loss: 0.5325\n",
      "Epoch [91/100], Step [18800/6235], Loss: 169.3905\n",
      "Epoch [91/100], Step [18900/6235], Loss: 10.5805\n",
      "Epoch [91/100], Step [19000/6235], Loss: 4.0587\n",
      "Epoch [91/100], Step [19100/6235], Loss: 27.4848\n",
      "Epoch [91/100], Step [19200/6235], Loss: 2.5802\n",
      "Epoch [91/100], Step [19300/6235], Loss: 2.1924\n",
      "Epoch [91/100], Step [19400/6235], Loss: 223.2032\n",
      "Epoch [91/100], Step [19500/6235], Loss: 103.8709\n",
      "Epoch [91/100], Step [19600/6235], Loss: 33.4324\n",
      "Epoch [91/100], Step [19700/6235], Loss: 4.0916\n",
      "Epoch [91/100], Step [19800/6235], Loss: 6.2451\n",
      "Epoch [91/100], Step [19900/6235], Loss: 0.0841\n",
      "Epoch [91/100], Step [20000/6235], Loss: 66.3087\n",
      "Epoch [91/100], Step [20100/6235], Loss: 2.4215\n",
      "Epoch [91/100], Step [20200/6235], Loss: 0.6275\n",
      "Epoch [91/100], Step [20300/6235], Loss: 1.3418\n",
      "Epoch [91/100], Step [20400/6235], Loss: 13.1982\n",
      "Epoch [91/100], Step [20500/6235], Loss: 49.5078\n",
      "Epoch [91/100], Step [20600/6235], Loss: 70.1578\n",
      "Epoch [91/100], Step [20700/6235], Loss: 13.4914\n",
      "Epoch [91/100], Step [20800/6235], Loss: 5.1429\n",
      "Epoch [91/100], Step [20900/6235], Loss: 26.5757\n",
      "Epoch [91/100], Step [21000/6235], Loss: 13.9809\n",
      "Epoch [91/100], Step [21100/6235], Loss: 5.9055\n",
      "Epoch [91/100], Step [21200/6235], Loss: 0.2104\n",
      "Epoch [91/100], Step [21300/6235], Loss: 0.2192\n",
      "Epoch [91/100], Step [21400/6235], Loss: 5.9346\n",
      "Epoch [91/100], Step [21500/6235], Loss: 1.5760\n",
      "Epoch [91/100], Step [21600/6235], Loss: 32.4812\n",
      "Epoch [91/100], Step [21700/6235], Loss: 0.3290\n",
      "Epoch [91/100], Step [21800/6235], Loss: 2.5740\n",
      "Epoch [91/100], Step [21900/6235], Loss: 1.4224\n",
      "Epoch [91/100], Step [22000/6235], Loss: 7.6219\n",
      "Epoch [91/100], Step [22100/6235], Loss: 0.5022\n",
      "Epoch [91/100], Step [22200/6235], Loss: 2.1717\n",
      "Epoch [91/100], Step [22300/6235], Loss: 1.1011\n",
      "Epoch [91/100], Step [22400/6235], Loss: 11.0459\n",
      "Epoch [91/100], Step [22500/6235], Loss: 118.3731\n",
      "Epoch [91/100], Step [22600/6235], Loss: 25.8013\n",
      "Epoch [91/100], Step [22700/6235], Loss: 1.8566\n",
      "Epoch [91/100], Step [22800/6235], Loss: 10.7719\n",
      "Epoch [91/100], Step [22900/6235], Loss: 21.7043\n",
      "Epoch [91/100], Step [23000/6235], Loss: 7.4904\n",
      "Epoch [91/100], Step [23100/6235], Loss: 5.4441\n",
      "Epoch [91/100], Step [23200/6235], Loss: 10.2823\n",
      "Epoch [91/100], Step [23300/6235], Loss: 19.4232\n",
      "Epoch [91/100], Step [23400/6235], Loss: 2.2848\n",
      "Epoch [91/100], Step [23500/6235], Loss: 0.0385\n",
      "Epoch [91/100], Step [23600/6235], Loss: 124.5803\n",
      "Epoch [91/100], Step [23700/6235], Loss: 2.8488\n",
      "Epoch [91/100], Step [23800/6235], Loss: 0.9879\n",
      "Epoch [91/100], Step [23900/6235], Loss: 4.8949\n",
      "Epoch [91/100], Step [24000/6235], Loss: 0.1197\n",
      "Epoch [91/100], Step [24100/6235], Loss: 1.2269\n",
      "Epoch [91/100], Step [24200/6235], Loss: 37.1882\n",
      "Epoch [91/100], Step [24300/6235], Loss: 1.2208\n",
      "Epoch [91/100], Step [24400/6235], Loss: 4.2760\n",
      "Epoch [91/100], Step [24500/6235], Loss: 1.9707\n",
      "Epoch [91/100], Step [24600/6235], Loss: 0.1010\n",
      "Epoch [91/100], Step [24700/6235], Loss: 4.0443\n",
      "Epoch [91/100], Step [24800/6235], Loss: 0.1311\n",
      "Epoch [91/100], Step [24900/6235], Loss: 14.7745\n",
      "Epoch [91/100], Step [25000/6235], Loss: 18.4701\n",
      "Epoch [91/100], Step [25100/6235], Loss: 9.0645\n",
      "Epoch [91/100], Step [25200/6235], Loss: 1.2752\n",
      "Epoch [91/100], Step [25300/6235], Loss: 0.5860\n",
      "Epoch [91/100], Step [25400/6235], Loss: 9.3619\n",
      "Epoch [91/100], Step [25500/6235], Loss: 7.3281\n",
      "Epoch [91/100], Step [25600/6235], Loss: 3.4349\n",
      "Epoch [91/100], Step [25700/6235], Loss: 0.3292\n",
      "Epoch [91/100], Step [25800/6235], Loss: 0.1018\n",
      "Epoch [91/100], Step [25900/6235], Loss: 7.8356\n",
      "Epoch [91/100], Step [26000/6235], Loss: 1.2294\n",
      "Epoch [91/100], Step [26100/6235], Loss: 0.1146\n",
      "Epoch [91/100], Step [26200/6235], Loss: 0.2240\n",
      "Epoch [91/100], Step [26300/6235], Loss: 5.1600\n",
      "Epoch [91/100], Step [26400/6235], Loss: 0.1446\n",
      "Epoch [91/100], Step [26500/6235], Loss: 0.0780\n",
      "Epoch [91/100], Step [26600/6235], Loss: 2.1054\n",
      "Epoch [91/100], Step [26700/6235], Loss: 0.4682\n",
      "Epoch [91/100], Step [26800/6235], Loss: 0.2807\n",
      "Epoch [91/100], Step [26900/6235], Loss: 0.0044\n",
      "Epoch [91/100], Step [27000/6235], Loss: 14.3842\n",
      "Epoch [91/100], Step [27100/6235], Loss: 0.0573\n",
      "Epoch [91/100], Step [27200/6235], Loss: 0.0281\n",
      "Epoch [91/100], Step [27300/6235], Loss: 0.2374\n",
      "Epoch [91/100], Step [27400/6235], Loss: 0.8150\n",
      "Epoch [91/100], Step [27500/6235], Loss: 28.3265\n",
      "Epoch [91/100], Step [27600/6235], Loss: 1.0898\n",
      "Epoch [91/100], Step [27700/6235], Loss: 1.3837\n",
      "Epoch [91/100], Step [27800/6235], Loss: 0.0315\n",
      "Epoch [91/100], Step [27900/6235], Loss: 1.1335\n",
      "Epoch [91/100], Step [28000/6235], Loss: 166.4824\n",
      "Epoch [91/100], Step [28100/6235], Loss: 2.6711\n",
      "Epoch [91/100], Step [28200/6235], Loss: 35.8983\n",
      "Epoch [91/100], Step [28300/6235], Loss: 2.9196\n",
      "Epoch [91/100], Step [28400/6235], Loss: 22.5048\n",
      "Epoch [91/100], Step [28500/6235], Loss: 3.8303\n",
      "Epoch [91/100], Step [28600/6235], Loss: 0.3461\n",
      "Epoch [91/100], Step [28700/6235], Loss: 4.7242\n",
      "Epoch [91/100], Step [28800/6235], Loss: 0.4379\n",
      "Epoch [91/100], Step [28900/6235], Loss: 71.4177\n",
      "Epoch [91/100], Step [29000/6235], Loss: 10.0268\n",
      "Epoch [91/100], Step [29100/6235], Loss: 0.0581\n",
      "Epoch [91/100], Step [29200/6235], Loss: 0.4635\n",
      "Epoch [91/100], Step [29300/6235], Loss: 12.3654\n",
      "Epoch [91/100], Step [29400/6235], Loss: 0.5400\n",
      "Epoch [91/100], Step [29500/6235], Loss: 6.6709\n",
      "Epoch [91/100], Step [29600/6235], Loss: 0.3842\n",
      "Epoch [91/100], Step [29700/6235], Loss: 0.5468\n",
      "Epoch [91/100], Step [29800/6235], Loss: 1.7311\n",
      "Epoch [91/100], Step [29900/6235], Loss: 0.4481\n",
      "Epoch [91/100], Step [30000/6235], Loss: 6.9257\n",
      "Epoch [91/100], Step [30100/6235], Loss: 11.7386\n",
      "Epoch [91/100], Step [30200/6235], Loss: 0.3950\n",
      "Epoch [91/100], Step [30300/6235], Loss: 0.3071\n",
      "Epoch [91/100], Step [30400/6235], Loss: 0.4532\n",
      "Epoch [91/100], Step [30500/6235], Loss: 2.6377\n",
      "Epoch [91/100], Step [30600/6235], Loss: 0.9395\n",
      "Epoch [91/100], Step [30700/6235], Loss: 0.0199\n",
      "Epoch [91/100], Step [30800/6235], Loss: 0.3075\n",
      "Epoch [91/100], Step [30900/6235], Loss: 3.3703\n",
      "Epoch [91/100], Step [31000/6235], Loss: 0.0132\n",
      "Epoch [91/100], Step [31100/6235], Loss: 0.0900\n",
      "Epoch [91/100], Step [31200/6235], Loss: 5.4687\n",
      "Epoch [91/100], Step [31300/6235], Loss: 2.1206\n",
      "Epoch [91/100], Step [31400/6235], Loss: 3.4484\n",
      "Epoch [91/100], Step [31500/6235], Loss: 0.4846\n",
      "Epoch [91/100], Step [31600/6235], Loss: 0.2301\n",
      "Epoch [91/100], Step [31700/6235], Loss: 1.5648\n",
      "Epoch [91/100], Step [31800/6235], Loss: 1.1845\n",
      "Epoch [91/100], Step [31900/6235], Loss: 122.7586\n",
      "Epoch [91/100], Step [32000/6235], Loss: 3.2038\n",
      "Epoch [91/100], Step [32100/6235], Loss: 4.4632\n",
      "Epoch [91/100], Step [32200/6235], Loss: 0.4661\n",
      "Epoch [91/100], Step [32300/6235], Loss: 1.5303\n",
      "Epoch [91/100], Step [32400/6235], Loss: 0.6219\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Step [32500/6235], Loss: 16.2696\n",
      "Epoch [91/100], Step [32600/6235], Loss: 1.4950\n",
      "Epoch [91/100], Step [32700/6235], Loss: 99.9113\n",
      "Epoch [91/100], Step [32800/6235], Loss: 5.0708\n",
      "Epoch [91/100], Step [32900/6235], Loss: 11.7766\n",
      "Epoch [91/100], Step [33000/6235], Loss: 0.1425\n",
      "Epoch [91/100], Step [33100/6235], Loss: 0.8141\n",
      "Epoch [91/100], Step [33200/6235], Loss: 1.7920\n",
      "Epoch [91/100], Step [33300/6235], Loss: 1.2998\n",
      "Epoch [91/100], Step [33400/6235], Loss: 14.1263\n",
      "Epoch [91/100], Step [33500/6235], Loss: 1.3487\n",
      "Epoch [91/100], Step [33600/6235], Loss: 5.1581\n",
      "Epoch [91/100], Step [33700/6235], Loss: 7.8688\n",
      "Epoch [91/100], Step [33800/6235], Loss: 2.0458\n",
      "Epoch [91/100], Step [33900/6235], Loss: 27.1006\n",
      "Epoch [91/100], Step [34000/6235], Loss: 0.0281\n",
      "Epoch [91/100], Step [34100/6235], Loss: 0.2202\n",
      "Epoch [91/100], Step [34200/6235], Loss: 2.8312\n",
      "Epoch [91/100], Step [34300/6235], Loss: 6.4275\n",
      "Epoch [91/100], Step [34400/6235], Loss: 0.0580\n",
      "Epoch [91/100], Step [34500/6235], Loss: 157.7960\n",
      "Epoch [91/100], Step [34600/6235], Loss: 0.5974\n",
      "Epoch [91/100], Step [34700/6235], Loss: 25.8588\n",
      "Epoch [91/100], Step [34800/6235], Loss: 11.1127\n",
      "Epoch [91/100], Step [34900/6235], Loss: 66.8425\n",
      "Epoch [91/100], Step [35000/6235], Loss: 0.9829\n",
      "Epoch [91/100], Step [35100/6235], Loss: 0.4823\n",
      "Epoch [91/100], Step [35200/6235], Loss: 0.6468\n",
      "Epoch [91/100], Step [35300/6235], Loss: 1.2874\n",
      "Epoch [91/100], Step [35400/6235], Loss: 0.6848\n",
      "Epoch [91/100], Step [35500/6235], Loss: 2.6540\n",
      "Epoch [91/100], Step [35600/6235], Loss: 2.5618\n",
      "Epoch [91/100], Step [35700/6235], Loss: 6.0802\n",
      "Epoch [91/100], Step [35800/6235], Loss: 0.3368\n",
      "Epoch [91/100], Step [35900/6235], Loss: 0.3231\n",
      "Epoch [91/100], Step [36000/6235], Loss: 0.5698\n",
      "Epoch [91/100], Step [36100/6235], Loss: 0.0229\n",
      "Epoch [91/100], Step [36200/6235], Loss: 19.9349\n",
      "Epoch [91/100], Step [36300/6235], Loss: 0.1276\n",
      "Epoch [91/100], Step [36400/6235], Loss: 1.9310\n",
      "Epoch [91/100], Step [36500/6235], Loss: 9.3239\n",
      "Epoch [91/100], Step [36600/6235], Loss: 0.1280\n",
      "Epoch [91/100], Step [36700/6235], Loss: 0.2438\n",
      "Epoch [91/100], Step [36800/6235], Loss: 16.1256\n",
      "Epoch [91/100], Step [36900/6235], Loss: 7.0699\n",
      "Epoch [91/100], Step [37000/6235], Loss: 0.2472\n",
      "Epoch [91/100], Step [37100/6235], Loss: 0.8575\n",
      "Epoch [91/100], Step [37200/6235], Loss: 0.0789\n",
      "Epoch [91/100], Step [37300/6235], Loss: 0.0764\n",
      "Epoch [91/100], Step [37400/6235], Loss: 0.2054\n",
      "Epoch [91/100], Step [37500/6235], Loss: 3.9368\n",
      "Epoch [91/100], Step [37600/6235], Loss: 11.4545\n",
      "Epoch [91/100], Step [37700/6235], Loss: 1.2694\n",
      "Epoch [91/100], Step [37800/6235], Loss: 5.7158\n",
      "Epoch [91/100], Step [37900/6235], Loss: 8.0436\n",
      "Epoch [91/100], Step [38000/6235], Loss: 0.4979\n",
      "Epoch [91/100], Step [38100/6235], Loss: 3.1526\n",
      "Epoch [91/100], Step [38200/6235], Loss: 1.5842\n",
      "Epoch [91/100], Step [38300/6235], Loss: 0.1305\n",
      "Epoch [91/100], Step [38400/6235], Loss: 0.1317\n",
      "Epoch [91/100], Step [38500/6235], Loss: 2.8126\n",
      "Epoch [91/100], Step [38600/6235], Loss: 0.1083\n",
      "Epoch [91/100], Step [38700/6235], Loss: 0.0718\n",
      "Epoch [91/100], Step [38800/6235], Loss: 0.2555\n",
      "Epoch [91/100], Step [38900/6235], Loss: 20.8529\n",
      "Epoch [91/100], Step [39000/6235], Loss: 5.9561\n",
      "Epoch [91/100], Step [39100/6235], Loss: 17.7864\n",
      "Epoch [91/100], Step [39200/6235], Loss: 0.4318\n",
      "Epoch [91/100], Step [39300/6235], Loss: 4.4087\n",
      "Epoch [91/100], Step [39400/6235], Loss: 259.8954\n",
      "Epoch [91/100], Step [39500/6235], Loss: 10.0313\n",
      "Epoch [91/100], Step [39600/6235], Loss: 28.5027\n",
      "Epoch [91/100], Step [39700/6235], Loss: 103.0440\n",
      "Epoch [91/100], Step [39800/6235], Loss: 218.9263\n",
      "Epoch [91/100], Step [39900/6235], Loss: 7.4292\n",
      "Epoch [91/100], Step [40000/6235], Loss: 6.6497\n",
      "Epoch [91/100], Step [40100/6235], Loss: 12.2543\n",
      "Epoch [91/100], Step [40200/6235], Loss: 8.1781\n",
      "Epoch [91/100], Step [40300/6235], Loss: 1.4127\n",
      "Epoch [91/100], Step [40400/6235], Loss: 0.3837\n",
      "Epoch [91/100], Step [40500/6235], Loss: 2.9322\n",
      "Epoch [91/100], Step [40600/6235], Loss: 0.2378\n",
      "Epoch [91/100], Step [40700/6235], Loss: 6.4422\n",
      "Epoch [91/100], Step [40800/6235], Loss: 0.5354\n",
      "Epoch [91/100], Step [40900/6235], Loss: 1.0089\n",
      "Epoch [91/100], Step [41000/6235], Loss: 46.9081\n",
      "Epoch [91/100], Step [41100/6235], Loss: 15.7215\n",
      "Epoch [91/100], Step [41200/6235], Loss: 3.9844\n",
      "Epoch [91/100], Step [41300/6235], Loss: 2.8171\n",
      "Epoch [91/100], Step [41400/6235], Loss: 1.7732\n",
      "Epoch [91/100], Step [41500/6235], Loss: 0.5201\n",
      "Epoch [91/100], Step [41600/6235], Loss: 0.3040\n",
      "Epoch [91/100], Step [41700/6235], Loss: 1.0458\n",
      "Epoch [91/100], Step [41800/6235], Loss: 3.0193\n",
      "Epoch [91/100], Step [41900/6235], Loss: 4.4962\n",
      "Epoch [91/100], Step [42000/6235], Loss: 4.0633\n",
      "Epoch [91/100], Step [42100/6235], Loss: 9.1527\n",
      "Epoch [91/100], Step [42200/6235], Loss: 25.2172\n",
      "Epoch [91/100], Step [42300/6235], Loss: 0.9971\n",
      "Epoch [91/100], Step [42400/6235], Loss: 2.3858\n",
      "Epoch [91/100], Step [42500/6235], Loss: 1.8783\n",
      "Epoch [91/100], Step [42600/6235], Loss: 0.6870\n",
      "Epoch [91/100], Step [42700/6235], Loss: 0.3430\n",
      "Epoch [91/100], Step [42800/6235], Loss: 2.8396\n",
      "Epoch [91/100], Step [42900/6235], Loss: 3.4655\n",
      "Epoch [91/100], Step [43000/6235], Loss: 0.2459\n",
      "Epoch [91/100], Step [43100/6235], Loss: 0.2566\n",
      "Epoch [91/100], Step [43200/6235], Loss: 1.0768\n",
      "Epoch [91/100], Step [43300/6235], Loss: 8.5585\n",
      "Epoch [91/100], Step [43400/6235], Loss: 10.8137\n",
      "Epoch [91/100], Step [43500/6235], Loss: 9.4188\n",
      "Epoch [91/100], Step [43600/6235], Loss: 14.6781\n",
      "Epoch [91/100], Step [43700/6235], Loss: 39.5922\n",
      "Epoch [91/100], Step [43800/6235], Loss: 0.2410\n",
      "Epoch [91/100], Step [43900/6235], Loss: 1.2899\n",
      "Epoch [91/100], Step [44000/6235], Loss: 64.5445\n",
      "Epoch [91/100], Step [44100/6235], Loss: 5.0701\n",
      "Epoch [91/100], Step [44200/6235], Loss: 5.9494\n",
      "Epoch [91/100], Step [44300/6235], Loss: 9.0047\n",
      "Epoch [91/100], Step [44400/6235], Loss: 0.7999\n",
      "Epoch [91/100], Step [44500/6235], Loss: 1.5494\n",
      "Epoch [91/100], Step [44600/6235], Loss: 12.2252\n",
      "Epoch [91/100], Step [44700/6235], Loss: 2.7151\n",
      "Epoch [91/100], Step [44800/6235], Loss: 5.3872\n",
      "Epoch [91/100], Step [44900/6235], Loss: 6.7387\n",
      "Epoch [91/100], Step [45000/6235], Loss: 5.1826\n",
      "Epoch [91/100], Step [45100/6235], Loss: 12.0619\n",
      "Epoch [91/100], Step [45200/6235], Loss: 0.6489\n",
      "Epoch [91/100], Step [45300/6235], Loss: 27.5954\n",
      "Epoch [91/100], Step [45400/6235], Loss: 13.4394\n",
      "Epoch [91/100], Step [45500/6235], Loss: 1.5072\n",
      "Epoch [91/100], Step [45600/6235], Loss: 0.4746\n",
      "Epoch [91/100], Step [45700/6235], Loss: 89.0703\n",
      "Epoch [91/100], Step [45800/6235], Loss: 313.4073\n",
      "Epoch [91/100], Step [45900/6235], Loss: 0.8221\n",
      "Epoch [91/100], Step [46000/6235], Loss: 8.9824\n",
      "Epoch [91/100], Step [46100/6235], Loss: 14.7101\n",
      "Epoch [91/100], Step [46200/6235], Loss: 63.6321\n",
      "Epoch [91/100], Step [46300/6235], Loss: 43.1518\n",
      "Epoch [91/100], Step [46400/6235], Loss: 1.4946\n",
      "Epoch [91/100], Step [46500/6235], Loss: 32.5230\n",
      "Epoch [91/100], Step [46600/6235], Loss: 7.8759\n",
      "Epoch [91/100], Step [46700/6235], Loss: 50.6022\n",
      "Epoch [91/100], Step [46800/6235], Loss: 1.7423\n",
      "Epoch [91/100], Step [46900/6235], Loss: 106.3782\n",
      "Epoch [91/100], Step [47000/6235], Loss: 0.5780\n",
      "Epoch [91/100], Step [47100/6235], Loss: 148.0369\n",
      "Epoch [91/100], Step [47200/6235], Loss: 5.1726\n",
      "Epoch [91/100], Step [47300/6235], Loss: 10.7678\n",
      "Epoch [91/100], Step [47400/6235], Loss: 358.9474\n",
      "Epoch [91/100], Step [47500/6235], Loss: 9.1349\n",
      "Epoch [91/100], Step [47600/6235], Loss: 2.7829\n",
      "Epoch [91/100], Step [47700/6235], Loss: 11.6615\n",
      "Epoch [91/100], Step [47800/6235], Loss: 62.7153\n",
      "Epoch [91/100], Step [47900/6235], Loss: 4.2336\n",
      "Epoch [91/100], Step [48000/6235], Loss: 6.7656\n",
      "Epoch [91/100], Step [48100/6235], Loss: 18.0883\n",
      "Epoch [91/100], Step [48200/6235], Loss: 156.7475\n",
      "Epoch [91/100], Step [48300/6235], Loss: 785.7707\n",
      "Epoch [91/100], Step [48400/6235], Loss: 2.3999\n",
      "Epoch [91/100], Step [48500/6235], Loss: 20.0083\n",
      "Epoch [91/100], Step [48600/6235], Loss: 15.0360\n",
      "Epoch [91/100], Step [48700/6235], Loss: 32.4182\n",
      "Epoch [91/100], Step [48800/6235], Loss: 421.1927\n",
      "Epoch [91/100], Step [48900/6235], Loss: 603.5984\n",
      "Epoch [91/100], Step [49000/6235], Loss: 148.4314\n",
      "Epoch [91/100], Step [49100/6235], Loss: 2346.3127\n",
      "Epoch [91/100], Step [49200/6235], Loss: 1124.7997\n",
      "Epoch [91/100], Step [49300/6235], Loss: 951.6027\n",
      "Epoch [91/100], Step [49400/6235], Loss: 29.6373\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [91/100], Step [49500/6235], Loss: 33.7573\n",
      "Epoch [91/100], Step [49600/6235], Loss: 280.9089\n",
      "Epoch [91/100], Step [49700/6235], Loss: 1488.8444\n",
      "Epoch [91/100], Step [49800/6235], Loss: 286.8208\n",
      "Epoch [92/100], Step [100/6235], Loss: 16.0209\n",
      "Epoch [92/100], Step [200/6235], Loss: 0.3670\n",
      "Epoch [92/100], Step [300/6235], Loss: 0.0447\n",
      "Epoch [92/100], Step [400/6235], Loss: 0.0172\n",
      "Epoch [92/100], Step [500/6235], Loss: 1.4676\n",
      "Epoch [92/100], Step [600/6235], Loss: 0.0246\n",
      "Epoch [92/100], Step [700/6235], Loss: 0.6119\n",
      "Epoch [92/100], Step [800/6235], Loss: 0.0400\n",
      "Epoch [92/100], Step [900/6235], Loss: 0.0728\n",
      "Epoch [92/100], Step [1000/6235], Loss: 0.0246\n",
      "Epoch [92/100], Step [1100/6235], Loss: 0.1618\n",
      "Epoch [92/100], Step [1200/6235], Loss: 0.1658\n",
      "Epoch [92/100], Step [1300/6235], Loss: 0.0076\n",
      "Epoch [92/100], Step [1400/6235], Loss: 0.1904\n",
      "Epoch [92/100], Step [1500/6235], Loss: 0.0089\n",
      "Epoch [92/100], Step [1600/6235], Loss: 0.2374\n",
      "Epoch [92/100], Step [1700/6235], Loss: 0.1641\n",
      "Epoch [92/100], Step [1800/6235], Loss: 0.2569\n",
      "Epoch [92/100], Step [1900/6235], Loss: 0.2671\n",
      "Epoch [92/100], Step [2000/6235], Loss: 2.2915\n",
      "Epoch [92/100], Step [2100/6235], Loss: 3.0754\n",
      "Epoch [92/100], Step [2200/6235], Loss: 5.7832\n",
      "Epoch [92/100], Step [2300/6235], Loss: 0.4685\n",
      "Epoch [92/100], Step [2400/6235], Loss: 2.1206\n",
      "Epoch [92/100], Step [2500/6235], Loss: 25.8773\n",
      "Epoch [92/100], Step [2600/6235], Loss: 13.6462\n",
      "Epoch [92/100], Step [2700/6235], Loss: 5.4462\n",
      "Epoch [92/100], Step [2800/6235], Loss: 133.7377\n",
      "Epoch [92/100], Step [2900/6235], Loss: 15.0071\n",
      "Epoch [92/100], Step [3000/6235], Loss: 0.2804\n",
      "Epoch [92/100], Step [3100/6235], Loss: 72.5104\n",
      "Epoch [92/100], Step [3200/6235], Loss: 33.7397\n",
      "Epoch [92/100], Step [3300/6235], Loss: 8.5326\n",
      "Epoch [92/100], Step [3400/6235], Loss: 4.9695\n",
      "Epoch [92/100], Step [3500/6235], Loss: 56.7738\n",
      "Epoch [92/100], Step [3600/6235], Loss: 0.4225\n",
      "Epoch [92/100], Step [3700/6235], Loss: 0.0828\n",
      "Epoch [92/100], Step [3800/6235], Loss: 0.0989\n",
      "Epoch [92/100], Step [3900/6235], Loss: 0.2403\n",
      "Epoch [92/100], Step [4000/6235], Loss: 0.1477\n",
      "Epoch [92/100], Step [4100/6235], Loss: 9.9667\n",
      "Epoch [92/100], Step [4200/6235], Loss: 5.0181\n",
      "Epoch [92/100], Step [4300/6235], Loss: 4.8864\n",
      "Epoch [92/100], Step [4400/6235], Loss: 0.4296\n",
      "Epoch [92/100], Step [4500/6235], Loss: 42.3379\n",
      "Epoch [92/100], Step [4600/6235], Loss: 3.5978\n",
      "Epoch [92/100], Step [4700/6235], Loss: 0.0545\n",
      "Epoch [92/100], Step [4800/6235], Loss: 5.5410\n",
      "Epoch [92/100], Step [4900/6235], Loss: 3.3111\n",
      "Epoch [92/100], Step [5000/6235], Loss: 0.1025\n",
      "Epoch [92/100], Step [5100/6235], Loss: 0.7434\n",
      "Epoch [92/100], Step [5200/6235], Loss: 5.9541\n",
      "Epoch [92/100], Step [5300/6235], Loss: 17.1836\n",
      "Epoch [92/100], Step [5400/6235], Loss: 6.7859\n",
      "Epoch [92/100], Step [5500/6235], Loss: 0.0989\n",
      "Epoch [92/100], Step [5600/6235], Loss: 0.2848\n",
      "Epoch [92/100], Step [5700/6235], Loss: 0.1647\n",
      "Epoch [92/100], Step [5800/6235], Loss: 0.1795\n",
      "Epoch [92/100], Step [5900/6235], Loss: 0.0746\n",
      "Epoch [92/100], Step [6000/6235], Loss: 0.5821\n",
      "Epoch [92/100], Step [6100/6235], Loss: 0.0433\n",
      "Epoch [92/100], Step [6200/6235], Loss: 7.3375\n",
      "Epoch [92/100], Step [6300/6235], Loss: 0.8716\n",
      "Epoch [92/100], Step [6400/6235], Loss: 0.0377\n",
      "Epoch [92/100], Step [6500/6235], Loss: 0.6300\n",
      "Epoch [92/100], Step [6600/6235], Loss: 8.9682\n",
      "Epoch [92/100], Step [6700/6235], Loss: 1.2306\n",
      "Epoch [92/100], Step [6800/6235], Loss: 0.5655\n",
      "Epoch [92/100], Step [6900/6235], Loss: 0.3733\n",
      "Epoch [92/100], Step [7000/6235], Loss: 0.3424\n",
      "Epoch [92/100], Step [7100/6235], Loss: 0.2161\n",
      "Epoch [92/100], Step [7200/6235], Loss: 0.0840\n",
      "Epoch [92/100], Step [7300/6235], Loss: 0.0549\n",
      "Epoch [92/100], Step [7400/6235], Loss: 0.1969\n",
      "Epoch [92/100], Step [7500/6235], Loss: 0.1764\n",
      "Epoch [92/100], Step [7600/6235], Loss: 1.5387\n",
      "Epoch [92/100], Step [7700/6235], Loss: 15.5006\n",
      "Epoch [92/100], Step [7800/6235], Loss: 1.2577\n",
      "Epoch [92/100], Step [7900/6235], Loss: 2.2755\n",
      "Epoch [92/100], Step [8000/6235], Loss: 0.2215\n",
      "Epoch [92/100], Step [8100/6235], Loss: 1.2595\n",
      "Epoch [92/100], Step [8200/6235], Loss: 10.2173\n",
      "Epoch [92/100], Step [8300/6235], Loss: 15.4792\n",
      "Epoch [92/100], Step [8400/6235], Loss: 627.3258\n",
      "Epoch [92/100], Step [8500/6235], Loss: 14.6727\n",
      "Epoch [92/100], Step [8600/6235], Loss: 25.1999\n",
      "Epoch [92/100], Step [8700/6235], Loss: 22.8626\n",
      "Epoch [92/100], Step [8800/6235], Loss: 857.6346\n",
      "Epoch [92/100], Step [8900/6235], Loss: 326.4545\n",
      "Epoch [92/100], Step [9000/6235], Loss: 406.1038\n",
      "Epoch [92/100], Step [9100/6235], Loss: 1927.4802\n",
      "Epoch [92/100], Step [9200/6235], Loss: 2905.7737\n",
      "Epoch [92/100], Step [9300/6235], Loss: 37.6195\n",
      "Epoch [92/100], Step [9400/6235], Loss: 129.0550\n",
      "Epoch [92/100], Step [9500/6235], Loss: 2654.2710\n",
      "Epoch [92/100], Step [9600/6235], Loss: 968.3040\n",
      "Epoch [92/100], Step [9700/6235], Loss: 0.4331\n",
      "Epoch [92/100], Step [9800/6235], Loss: 3926.9158\n",
      "Epoch [92/100], Step [9900/6235], Loss: 121.1299\n",
      "Epoch [92/100], Step [10000/6235], Loss: 375.3972\n",
      "Epoch [92/100], Step [10100/6235], Loss: 1.6986\n",
      "Epoch [92/100], Step [10200/6235], Loss: 485.7616\n",
      "Epoch [92/100], Step [10300/6235], Loss: 24.9959\n",
      "Epoch [92/100], Step [10400/6235], Loss: 7.9727\n",
      "Epoch [92/100], Step [10500/6235], Loss: 9.6075\n",
      "Epoch [92/100], Step [10600/6235], Loss: 8.8285\n",
      "Epoch [92/100], Step [10700/6235], Loss: 11.2003\n",
      "Epoch [92/100], Step [10800/6235], Loss: 92.8523\n",
      "Epoch [92/100], Step [10900/6235], Loss: 47.9450\n",
      "Epoch [92/100], Step [11000/6235], Loss: 299.3465\n",
      "Epoch [92/100], Step [11100/6235], Loss: 46.6670\n",
      "Epoch [92/100], Step [11200/6235], Loss: 8.3012\n",
      "Epoch [92/100], Step [11300/6235], Loss: 100.3293\n",
      "Epoch [92/100], Step [11400/6235], Loss: 16.8391\n",
      "Epoch [92/100], Step [11500/6235], Loss: 10.7009\n",
      "Epoch [92/100], Step [11600/6235], Loss: 7.4610\n",
      "Epoch [92/100], Step [11700/6235], Loss: 46.9950\n",
      "Epoch [92/100], Step [11800/6235], Loss: 414.7640\n",
      "Epoch [92/100], Step [11900/6235], Loss: 209.8048\n",
      "Epoch [92/100], Step [12000/6235], Loss: 352.9158\n",
      "Epoch [92/100], Step [12100/6235], Loss: 223.8892\n",
      "Epoch [92/100], Step [12200/6235], Loss: 51.5647\n",
      "Epoch [92/100], Step [12300/6235], Loss: 16.9621\n",
      "Epoch [92/100], Step [12400/6235], Loss: 225.7231\n",
      "Epoch [92/100], Step [12500/6235], Loss: 6.7432\n",
      "Epoch [92/100], Step [12600/6235], Loss: 74.5487\n",
      "Epoch [92/100], Step [12700/6235], Loss: 4.1464\n",
      "Epoch [92/100], Step [12800/6235], Loss: 5.6531\n",
      "Epoch [92/100], Step [12900/6235], Loss: 33.6336\n",
      "Epoch [92/100], Step [13000/6235], Loss: 0.1987\n",
      "Epoch [92/100], Step [13100/6235], Loss: 63.8321\n",
      "Epoch [92/100], Step [13200/6235], Loss: 9.1021\n",
      "Epoch [92/100], Step [13300/6235], Loss: 40.0984\n",
      "Epoch [92/100], Step [13400/6235], Loss: 237.0065\n",
      "Epoch [92/100], Step [13500/6235], Loss: 1.2076\n",
      "Epoch [92/100], Step [13600/6235], Loss: 2.8227\n",
      "Epoch [92/100], Step [13700/6235], Loss: 4.9248\n",
      "Epoch [92/100], Step [13800/6235], Loss: 171.1929\n",
      "Epoch [92/100], Step [13900/6235], Loss: 54.9986\n",
      "Epoch [92/100], Step [14000/6235], Loss: 13.1958\n",
      "Epoch [92/100], Step [14100/6235], Loss: 17.2178\n",
      "Epoch [92/100], Step [14200/6235], Loss: 46.0814\n",
      "Epoch [92/100], Step [14300/6235], Loss: 10.5568\n",
      "Epoch [92/100], Step [14400/6235], Loss: 38.9692\n",
      "Epoch [92/100], Step [14500/6235], Loss: 37.9832\n",
      "Epoch [92/100], Step [14600/6235], Loss: 0.0844\n",
      "Epoch [92/100], Step [14700/6235], Loss: 44.7943\n",
      "Epoch [92/100], Step [14800/6235], Loss: 32.5739\n",
      "Epoch [92/100], Step [14900/6235], Loss: 0.8795\n",
      "Epoch [92/100], Step [15000/6235], Loss: 2.0075\n",
      "Epoch [92/100], Step [15100/6235], Loss: 0.4627\n",
      "Epoch [92/100], Step [15200/6235], Loss: 9.7725\n",
      "Epoch [92/100], Step [15300/6235], Loss: 19.6140\n",
      "Epoch [92/100], Step [15400/6235], Loss: 73.9032\n",
      "Epoch [92/100], Step [15500/6235], Loss: 16.7469\n",
      "Epoch [92/100], Step [15600/6235], Loss: 164.9755\n",
      "Epoch [92/100], Step [15700/6235], Loss: 100.8099\n",
      "Epoch [92/100], Step [15800/6235], Loss: 0.2612\n",
      "Epoch [92/100], Step [15900/6235], Loss: 2.0583\n",
      "Epoch [92/100], Step [16000/6235], Loss: 150.9651\n",
      "Epoch [92/100], Step [16100/6235], Loss: 0.8720\n",
      "Epoch [92/100], Step [16200/6235], Loss: 1.0442\n",
      "Epoch [92/100], Step [16300/6235], Loss: 8.4306\n",
      "Epoch [92/100], Step [16400/6235], Loss: 25.0143\n",
      "Epoch [92/100], Step [16500/6235], Loss: 175.8912\n",
      "Epoch [92/100], Step [16600/6235], Loss: 8.9218\n",
      "Epoch [92/100], Step [16700/6235], Loss: 0.6221\n",
      "Epoch [92/100], Step [16800/6235], Loss: 10.2046\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Step [16900/6235], Loss: 0.1765\n",
      "Epoch [92/100], Step [17000/6235], Loss: 0.2090\n",
      "Epoch [92/100], Step [17100/6235], Loss: 0.1357\n",
      "Epoch [92/100], Step [17200/6235], Loss: 265.6967\n",
      "Epoch [92/100], Step [17300/6235], Loss: 57.0573\n",
      "Epoch [92/100], Step [17400/6235], Loss: 55.4425\n",
      "Epoch [92/100], Step [17500/6235], Loss: 1.6534\n",
      "Epoch [92/100], Step [17600/6235], Loss: 2.5418\n",
      "Epoch [92/100], Step [17700/6235], Loss: 8.3026\n",
      "Epoch [92/100], Step [17800/6235], Loss: 32.2389\n",
      "Epoch [92/100], Step [17900/6235], Loss: 1.7178\n",
      "Epoch [92/100], Step [18000/6235], Loss: 10.4088\n",
      "Epoch [92/100], Step [18100/6235], Loss: 17.3434\n",
      "Epoch [92/100], Step [18200/6235], Loss: 0.7679\n",
      "Epoch [92/100], Step [18300/6235], Loss: 5.0424\n",
      "Epoch [92/100], Step [18400/6235], Loss: 5.3138\n",
      "Epoch [92/100], Step [18500/6235], Loss: 19.9879\n",
      "Epoch [92/100], Step [18600/6235], Loss: 1.0692\n",
      "Epoch [92/100], Step [18700/6235], Loss: 0.5198\n",
      "Epoch [92/100], Step [18800/6235], Loss: 153.7299\n",
      "Epoch [92/100], Step [18900/6235], Loss: 11.8378\n",
      "Epoch [92/100], Step [19000/6235], Loss: 8.2384\n",
      "Epoch [92/100], Step [19100/6235], Loss: 8.6450\n",
      "Epoch [92/100], Step [19200/6235], Loss: 2.2668\n",
      "Epoch [92/100], Step [19300/6235], Loss: 4.5793\n",
      "Epoch [92/100], Step [19400/6235], Loss: 143.4874\n",
      "Epoch [92/100], Step [19500/6235], Loss: 229.4090\n",
      "Epoch [92/100], Step [19600/6235], Loss: 147.6761\n",
      "Epoch [92/100], Step [19700/6235], Loss: 15.0935\n",
      "Epoch [92/100], Step [19800/6235], Loss: 7.9507\n",
      "Epoch [92/100], Step [19900/6235], Loss: 0.1254\n",
      "Epoch [92/100], Step [20000/6235], Loss: 77.6353\n",
      "Epoch [92/100], Step [20100/6235], Loss: 11.8385\n",
      "Epoch [92/100], Step [20200/6235], Loss: 0.5413\n",
      "Epoch [92/100], Step [20300/6235], Loss: 0.1759\n",
      "Epoch [92/100], Step [20400/6235], Loss: 36.1844\n",
      "Epoch [92/100], Step [20500/6235], Loss: 24.9023\n",
      "Epoch [92/100], Step [20600/6235], Loss: 3.1137\n",
      "Epoch [92/100], Step [20700/6235], Loss: 4.4457\n",
      "Epoch [92/100], Step [20800/6235], Loss: 0.1843\n",
      "Epoch [92/100], Step [20900/6235], Loss: 25.0275\n",
      "Epoch [92/100], Step [21000/6235], Loss: 16.8833\n",
      "Epoch [92/100], Step [21100/6235], Loss: 3.5292\n",
      "Epoch [92/100], Step [21200/6235], Loss: 0.1937\n",
      "Epoch [92/100], Step [21300/6235], Loss: 0.1865\n",
      "Epoch [92/100], Step [21400/6235], Loss: 6.3464\n",
      "Epoch [92/100], Step [21500/6235], Loss: 1.8828\n",
      "Epoch [92/100], Step [21600/6235], Loss: 31.6156\n",
      "Epoch [92/100], Step [21700/6235], Loss: 0.1478\n",
      "Epoch [92/100], Step [21800/6235], Loss: 0.2397\n",
      "Epoch [92/100], Step [21900/6235], Loss: 1.0843\n",
      "Epoch [92/100], Step [22000/6235], Loss: 6.3846\n",
      "Epoch [92/100], Step [22100/6235], Loss: 1.0352\n",
      "Epoch [92/100], Step [22200/6235], Loss: 1.8124\n",
      "Epoch [92/100], Step [22300/6235], Loss: 4.8701\n",
      "Epoch [92/100], Step [22400/6235], Loss: 9.3846\n",
      "Epoch [92/100], Step [22500/6235], Loss: 62.5720\n",
      "Epoch [92/100], Step [22600/6235], Loss: 20.9712\n",
      "Epoch [92/100], Step [22700/6235], Loss: 0.3607\n",
      "Epoch [92/100], Step [22800/6235], Loss: 4.8387\n",
      "Epoch [92/100], Step [22900/6235], Loss: 2.1289\n",
      "Epoch [92/100], Step [23000/6235], Loss: 11.6085\n",
      "Epoch [92/100], Step [23100/6235], Loss: 6.3334\n",
      "Epoch [92/100], Step [23200/6235], Loss: 20.3105\n",
      "Epoch [92/100], Step [23300/6235], Loss: 19.5413\n",
      "Epoch [92/100], Step [23400/6235], Loss: 1.9635\n",
      "Epoch [92/100], Step [23500/6235], Loss: 0.0816\n",
      "Epoch [92/100], Step [23600/6235], Loss: 117.0889\n",
      "Epoch [92/100], Step [23700/6235], Loss: 2.3828\n",
      "Epoch [92/100], Step [23800/6235], Loss: 1.0123\n",
      "Epoch [92/100], Step [23900/6235], Loss: 6.4614\n",
      "Epoch [92/100], Step [24000/6235], Loss: 0.2419\n",
      "Epoch [92/100], Step [24100/6235], Loss: 1.2607\n",
      "Epoch [92/100], Step [24200/6235], Loss: 5.2270\n",
      "Epoch [92/100], Step [24300/6235], Loss: 1.3168\n",
      "Epoch [92/100], Step [24400/6235], Loss: 4.9455\n",
      "Epoch [92/100], Step [24500/6235], Loss: 2.5813\n",
      "Epoch [92/100], Step [24600/6235], Loss: 0.1764\n",
      "Epoch [92/100], Step [24700/6235], Loss: 2.5538\n",
      "Epoch [92/100], Step [24800/6235], Loss: 0.0669\n",
      "Epoch [92/100], Step [24900/6235], Loss: 7.1667\n",
      "Epoch [92/100], Step [25000/6235], Loss: 15.7051\n",
      "Epoch [92/100], Step [25100/6235], Loss: 7.3119\n",
      "Epoch [92/100], Step [25200/6235], Loss: 1.6349\n",
      "Epoch [92/100], Step [25300/6235], Loss: 0.6843\n",
      "Epoch [92/100], Step [25400/6235], Loss: 9.7820\n",
      "Epoch [92/100], Step [25500/6235], Loss: 6.3296\n",
      "Epoch [92/100], Step [25600/6235], Loss: 3.0512\n",
      "Epoch [92/100], Step [25700/6235], Loss: 0.3505\n",
      "Epoch [92/100], Step [25800/6235], Loss: 0.1793\n",
      "Epoch [92/100], Step [25900/6235], Loss: 9.1330\n",
      "Epoch [92/100], Step [26000/6235], Loss: 1.0588\n",
      "Epoch [92/100], Step [26100/6235], Loss: 0.2745\n",
      "Epoch [92/100], Step [26200/6235], Loss: 0.5741\n",
      "Epoch [92/100], Step [26300/6235], Loss: 4.6937\n",
      "Epoch [92/100], Step [26400/6235], Loss: 0.1575\n",
      "Epoch [92/100], Step [26500/6235], Loss: 0.1257\n",
      "Epoch [92/100], Step [26600/6235], Loss: 2.5519\n",
      "Epoch [92/100], Step [26700/6235], Loss: 0.5539\n",
      "Epoch [92/100], Step [26800/6235], Loss: 0.5171\n",
      "Epoch [92/100], Step [26900/6235], Loss: 0.0201\n",
      "Epoch [92/100], Step [27000/6235], Loss: 13.6038\n",
      "Epoch [92/100], Step [27100/6235], Loss: 0.0898\n",
      "Epoch [92/100], Step [27200/6235], Loss: 0.0407\n",
      "Epoch [92/100], Step [27300/6235], Loss: 0.2354\n",
      "Epoch [92/100], Step [27400/6235], Loss: 0.8796\n",
      "Epoch [92/100], Step [27500/6235], Loss: 21.4115\n",
      "Epoch [92/100], Step [27600/6235], Loss: 0.3230\n",
      "Epoch [92/100], Step [27700/6235], Loss: 0.3293\n",
      "Epoch [92/100], Step [27800/6235], Loss: 6.5584\n",
      "Epoch [92/100], Step [27900/6235], Loss: 1.3386\n",
      "Epoch [92/100], Step [28000/6235], Loss: 175.7396\n",
      "Epoch [92/100], Step [28100/6235], Loss: 6.2260\n",
      "Epoch [92/100], Step [28200/6235], Loss: 37.3842\n",
      "Epoch [92/100], Step [28300/6235], Loss: 3.5884\n",
      "Epoch [92/100], Step [28400/6235], Loss: 23.4875\n",
      "Epoch [92/100], Step [28500/6235], Loss: 1.2562\n",
      "Epoch [92/100], Step [28600/6235], Loss: 0.7820\n",
      "Epoch [92/100], Step [28700/6235], Loss: 4.3230\n",
      "Epoch [92/100], Step [28800/6235], Loss: 0.3225\n",
      "Epoch [92/100], Step [28900/6235], Loss: 61.1277\n",
      "Epoch [92/100], Step [29000/6235], Loss: 0.0520\n",
      "Epoch [92/100], Step [29100/6235], Loss: 0.1952\n",
      "Epoch [92/100], Step [29200/6235], Loss: 0.0721\n",
      "Epoch [92/100], Step [29300/6235], Loss: 9.1210\n",
      "Epoch [92/100], Step [29400/6235], Loss: 0.1718\n",
      "Epoch [92/100], Step [29500/6235], Loss: 4.5470\n",
      "Epoch [92/100], Step [29600/6235], Loss: 2.0895\n",
      "Epoch [92/100], Step [29700/6235], Loss: 0.0915\n",
      "Epoch [92/100], Step [29800/6235], Loss: 1.6473\n",
      "Epoch [92/100], Step [29900/6235], Loss: 0.0185\n",
      "Epoch [92/100], Step [30000/6235], Loss: 8.2519\n",
      "Epoch [92/100], Step [30100/6235], Loss: 0.9648\n",
      "Epoch [92/100], Step [30200/6235], Loss: 0.1037\n",
      "Epoch [92/100], Step [30300/6235], Loss: 0.9703\n",
      "Epoch [92/100], Step [30400/6235], Loss: 0.1895\n",
      "Epoch [92/100], Step [30500/6235], Loss: 1.8069\n",
      "Epoch [92/100], Step [30600/6235], Loss: 0.4480\n",
      "Epoch [92/100], Step [30700/6235], Loss: 0.2035\n",
      "Epoch [92/100], Step [30800/6235], Loss: 0.2296\n",
      "Epoch [92/100], Step [30900/6235], Loss: 2.3108\n",
      "Epoch [92/100], Step [31000/6235], Loss: 0.0669\n",
      "Epoch [92/100], Step [31100/6235], Loss: 0.0985\n",
      "Epoch [92/100], Step [31200/6235], Loss: 7.2189\n",
      "Epoch [92/100], Step [31300/6235], Loss: 1.9063\n",
      "Epoch [92/100], Step [31400/6235], Loss: 0.5302\n",
      "Epoch [92/100], Step [31500/6235], Loss: 0.4135\n",
      "Epoch [92/100], Step [31600/6235], Loss: 2.0613\n",
      "Epoch [92/100], Step [31700/6235], Loss: 11.5697\n",
      "Epoch [92/100], Step [31800/6235], Loss: 2.3913\n",
      "Epoch [92/100], Step [31900/6235], Loss: 287.2212\n",
      "Epoch [92/100], Step [32000/6235], Loss: 14.1214\n",
      "Epoch [92/100], Step [32100/6235], Loss: 4.3514\n",
      "Epoch [92/100], Step [32200/6235], Loss: 54.1217\n",
      "Epoch [92/100], Step [32300/6235], Loss: 1.3026\n",
      "Epoch [92/100], Step [32400/6235], Loss: 0.6340\n",
      "Epoch [92/100], Step [32500/6235], Loss: 21.3796\n",
      "Epoch [92/100], Step [32600/6235], Loss: 0.7733\n",
      "Epoch [92/100], Step [32700/6235], Loss: 55.2714\n",
      "Epoch [92/100], Step [32800/6235], Loss: 0.4671\n",
      "Epoch [92/100], Step [32900/6235], Loss: 7.7373\n",
      "Epoch [92/100], Step [33000/6235], Loss: 0.3499\n",
      "Epoch [92/100], Step [33100/6235], Loss: 1.1619\n",
      "Epoch [92/100], Step [33200/6235], Loss: 1.2950\n",
      "Epoch [92/100], Step [33300/6235], Loss: 0.7184\n",
      "Epoch [92/100], Step [33400/6235], Loss: 143.5141\n",
      "Epoch [92/100], Step [33500/6235], Loss: 2.1820\n",
      "Epoch [92/100], Step [33600/6235], Loss: 6.8366\n",
      "Epoch [92/100], Step [33700/6235], Loss: 11.0991\n",
      "Epoch [92/100], Step [33800/6235], Loss: 1.4583\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [92/100], Step [33900/6235], Loss: 24.0019\n",
      "Epoch [92/100], Step [34000/6235], Loss: 0.0300\n",
      "Epoch [92/100], Step [34100/6235], Loss: 0.1906\n",
      "Epoch [92/100], Step [34200/6235], Loss: 2.6532\n",
      "Epoch [92/100], Step [34300/6235], Loss: 6.5281\n",
      "Epoch [92/100], Step [34400/6235], Loss: 0.0860\n",
      "Epoch [92/100], Step [34500/6235], Loss: 51.8796\n",
      "Epoch [92/100], Step [34600/6235], Loss: 0.1929\n",
      "Epoch [92/100], Step [34700/6235], Loss: 14.6796\n",
      "Epoch [92/100], Step [34800/6235], Loss: 16.1564\n",
      "Epoch [92/100], Step [34900/6235], Loss: 66.9198\n",
      "Epoch [92/100], Step [35000/6235], Loss: 0.1180\n",
      "Epoch [92/100], Step [35100/6235], Loss: 0.4957\n",
      "Epoch [92/100], Step [35200/6235], Loss: 0.2908\n",
      "Epoch [92/100], Step [35300/6235], Loss: 1.4765\n",
      "Epoch [92/100], Step [35400/6235], Loss: 0.5572\n",
      "Epoch [92/100], Step [35500/6235], Loss: 2.5319\n",
      "Epoch [92/100], Step [35600/6235], Loss: 1.5780\n",
      "Epoch [92/100], Step [35700/6235], Loss: 6.4260\n",
      "Epoch [92/100], Step [35800/6235], Loss: 0.1724\n",
      "Epoch [92/100], Step [35900/6235], Loss: 0.2073\n",
      "Epoch [92/100], Step [36000/6235], Loss: 1.3647\n",
      "Epoch [92/100], Step [36100/6235], Loss: 0.0324\n",
      "Epoch [92/100], Step [36200/6235], Loss: 20.2878\n",
      "Epoch [92/100], Step [36300/6235], Loss: 0.4854\n",
      "Epoch [92/100], Step [36400/6235], Loss: 1.7672\n",
      "Epoch [92/100], Step [36500/6235], Loss: 9.2167\n",
      "Epoch [92/100], Step [36600/6235], Loss: 0.1334\n",
      "Epoch [92/100], Step [36700/6235], Loss: 0.2366\n",
      "Epoch [92/100], Step [36800/6235], Loss: 16.1679\n",
      "Epoch [92/100], Step [36900/6235], Loss: 5.5372\n",
      "Epoch [92/100], Step [37000/6235], Loss: 0.2592\n",
      "Epoch [92/100], Step [37100/6235], Loss: 0.8651\n",
      "Epoch [92/100], Step [37200/6235], Loss: 0.0781\n",
      "Epoch [92/100], Step [37300/6235], Loss: 0.0753\n",
      "Epoch [92/100], Step [37400/6235], Loss: 0.2020\n",
      "Epoch [92/100], Step [37500/6235], Loss: 3.9098\n",
      "Epoch [92/100], Step [37600/6235], Loss: 11.4258\n",
      "Epoch [92/100], Step [37700/6235], Loss: 1.2625\n",
      "Epoch [92/100], Step [37800/6235], Loss: 5.7924\n",
      "Epoch [92/100], Step [37900/6235], Loss: 6.6713\n",
      "Epoch [92/100], Step [38000/6235], Loss: 0.4091\n",
      "Epoch [92/100], Step [38100/6235], Loss: 3.3028\n",
      "Epoch [92/100], Step [38200/6235], Loss: 2.1324\n",
      "Epoch [92/100], Step [38300/6235], Loss: 0.8281\n",
      "Epoch [92/100], Step [38400/6235], Loss: 0.1448\n",
      "Epoch [92/100], Step [38500/6235], Loss: 2.8825\n",
      "Epoch [92/100], Step [38600/6235], Loss: 0.1944\n",
      "Epoch [92/100], Step [38700/6235], Loss: 0.3645\n",
      "Epoch [92/100], Step [38800/6235], Loss: 0.3041\n",
      "Epoch [92/100], Step [38900/6235], Loss: 26.5068\n",
      "Epoch [92/100], Step [39000/6235], Loss: 10.6588\n",
      "Epoch [92/100], Step [39100/6235], Loss: 1.9765\n",
      "Epoch [92/100], Step [39200/6235], Loss: 2.6973\n",
      "Epoch [92/100], Step [39300/6235], Loss: 55.2089\n",
      "Epoch [92/100], Step [39400/6235], Loss: 76.2123\n",
      "Epoch [92/100], Step [39500/6235], Loss: 371.2962\n",
      "Epoch [92/100], Step [39600/6235], Loss: 48.9768\n",
      "Epoch [92/100], Step [39700/6235], Loss: 48.0845\n",
      "Epoch [92/100], Step [39800/6235], Loss: 156.5238\n",
      "Epoch [92/100], Step [39900/6235], Loss: 10.6260\n",
      "Epoch [92/100], Step [40000/6235], Loss: 2.4311\n",
      "Epoch [92/100], Step [40100/6235], Loss: 11.7648\n",
      "Epoch [92/100], Step [40200/6235], Loss: 8.8038\n",
      "Epoch [92/100], Step [40300/6235], Loss: 0.6439\n",
      "Epoch [92/100], Step [40400/6235], Loss: 0.4498\n",
      "Epoch [92/100], Step [40500/6235], Loss: 2.9952\n",
      "Epoch [92/100], Step [40600/6235], Loss: 0.2575\n",
      "Epoch [92/100], Step [40700/6235], Loss: 6.4320\n",
      "Epoch [92/100], Step [40800/6235], Loss: 0.5673\n",
      "Epoch [92/100], Step [40900/6235], Loss: 1.0230\n",
      "Epoch [92/100], Step [41000/6235], Loss: 45.9834\n",
      "Epoch [92/100], Step [41100/6235], Loss: 3.5442\n",
      "Epoch [92/100], Step [41200/6235], Loss: 30.5473\n",
      "Epoch [92/100], Step [41300/6235], Loss: 0.2639\n",
      "Epoch [92/100], Step [41400/6235], Loss: 1.3919\n",
      "Epoch [92/100], Step [41500/6235], Loss: 3.9741\n",
      "Epoch [92/100], Step [41600/6235], Loss: 0.1560\n",
      "Epoch [92/100], Step [41700/6235], Loss: 0.0767\n",
      "Epoch [92/100], Step [41800/6235], Loss: 1.0901\n",
      "Epoch [92/100], Step [41900/6235], Loss: 4.7116\n",
      "Epoch [92/100], Step [42000/6235], Loss: 3.5785\n",
      "Epoch [92/100], Step [42100/6235], Loss: 8.4495\n",
      "Epoch [92/100], Step [42200/6235], Loss: 46.8436\n",
      "Epoch [92/100], Step [42300/6235], Loss: 0.6319\n",
      "Epoch [92/100], Step [42400/6235], Loss: 3.1087\n",
      "Epoch [92/100], Step [42500/6235], Loss: 1.6213\n",
      "Epoch [92/100], Step [42600/6235], Loss: 0.5366\n",
      "Epoch [92/100], Step [42700/6235], Loss: 1.0692\n",
      "Epoch [92/100], Step [42800/6235], Loss: 0.4653\n",
      "Epoch [92/100], Step [42900/6235], Loss: 4.0801\n",
      "Epoch [92/100], Step [43000/6235], Loss: 0.2288\n",
      "Epoch [92/100], Step [43100/6235], Loss: 1.1226\n",
      "Epoch [92/100], Step [43200/6235], Loss: 0.7100\n",
      "Epoch [92/100], Step [43300/6235], Loss: 9.4781\n",
      "Epoch [92/100], Step [43400/6235], Loss: 6.0900\n",
      "Epoch [92/100], Step [43500/6235], Loss: 9.3561\n",
      "Epoch [92/100], Step [43600/6235], Loss: 22.9431\n",
      "Epoch [92/100], Step [43700/6235], Loss: 38.4990\n",
      "Epoch [92/100], Step [43800/6235], Loss: 0.9022\n",
      "Epoch [92/100], Step [43900/6235], Loss: 1.4726\n",
      "Epoch [92/100], Step [44000/6235], Loss: 60.6154\n",
      "Epoch [92/100], Step [44100/6235], Loss: 4.5945\n",
      "Epoch [92/100], Step [44200/6235], Loss: 2.5507\n",
      "Epoch [92/100], Step [44300/6235], Loss: 5.6371\n",
      "Epoch [92/100], Step [44400/6235], Loss: 0.5149\n",
      "Epoch [92/100], Step [44500/6235], Loss: 3.0456\n",
      "Epoch [92/100], Step [44600/6235], Loss: 13.5863\n",
      "Epoch [92/100], Step [44700/6235], Loss: 38.5338\n",
      "Epoch [92/100], Step [44800/6235], Loss: 1.9244\n",
      "Epoch [92/100], Step [44900/6235], Loss: 11.5907\n",
      "Epoch [92/100], Step [45000/6235], Loss: 5.6565\n",
      "Epoch [92/100], Step [45100/6235], Loss: 47.3044\n",
      "Epoch [92/100], Step [45200/6235], Loss: 0.6063\n",
      "Epoch [92/100], Step [45300/6235], Loss: 25.2326\n",
      "Epoch [92/100], Step [45400/6235], Loss: 11.5593\n",
      "Epoch [92/100], Step [45500/6235], Loss: 2.7104\n",
      "Epoch [92/100], Step [45600/6235], Loss: 0.7589\n",
      "Epoch [92/100], Step [45700/6235], Loss: 57.4669\n",
      "Epoch [92/100], Step [45800/6235], Loss: 212.2516\n",
      "Epoch [92/100], Step [45900/6235], Loss: 3.7608\n",
      "Epoch [92/100], Step [46000/6235], Loss: 84.8287\n",
      "Epoch [92/100], Step [46100/6235], Loss: 137.9781\n",
      "Epoch [92/100], Step [46200/6235], Loss: 22.7760\n",
      "Epoch [92/100], Step [46300/6235], Loss: 7.8999\n",
      "Epoch [92/100], Step [46400/6235], Loss: 17.4635\n",
      "Epoch [92/100], Step [46500/6235], Loss: 9.2135\n",
      "Epoch [92/100], Step [46600/6235], Loss: 9.9964\n",
      "Epoch [92/100], Step [46700/6235], Loss: 27.0534\n",
      "Epoch [92/100], Step [46800/6235], Loss: 22.9103\n",
      "Epoch [92/100], Step [46900/6235], Loss: 1.6263\n",
      "Epoch [92/100], Step [47000/6235], Loss: 8.0388\n",
      "Epoch [92/100], Step [47100/6235], Loss: 0.5730\n",
      "Epoch [92/100], Step [47200/6235], Loss: 86.8016\n",
      "Epoch [92/100], Step [47300/6235], Loss: 0.8698\n",
      "Epoch [92/100], Step [47400/6235], Loss: 221.3818\n",
      "Epoch [92/100], Step [47500/6235], Loss: 5.3183\n",
      "Epoch [92/100], Step [47600/6235], Loss: 2.7737\n",
      "Epoch [92/100], Step [47700/6235], Loss: 15.2014\n",
      "Epoch [92/100], Step [47800/6235], Loss: 12.6836\n",
      "Epoch [92/100], Step [47900/6235], Loss: 19.3183\n",
      "Epoch [92/100], Step [48000/6235], Loss: 18.4312\n",
      "Epoch [92/100], Step [48100/6235], Loss: 9.7224\n",
      "Epoch [92/100], Step [48200/6235], Loss: 173.5943\n",
      "Epoch [92/100], Step [48300/6235], Loss: 659.5760\n",
      "Epoch [92/100], Step [48400/6235], Loss: 5.7528\n",
      "Epoch [92/100], Step [48500/6235], Loss: 44.8174\n",
      "Epoch [92/100], Step [48600/6235], Loss: 66.5358\n",
      "Epoch [92/100], Step [48700/6235], Loss: 3.7710\n",
      "Epoch [92/100], Step [48800/6235], Loss: 726.8433\n",
      "Epoch [92/100], Step [48900/6235], Loss: 215.2334\n",
      "Epoch [92/100], Step [49000/6235], Loss: 154.2879\n",
      "Epoch [92/100], Step [49100/6235], Loss: 3398.7297\n",
      "Epoch [92/100], Step [49200/6235], Loss: 98.5822\n",
      "Epoch [92/100], Step [49300/6235], Loss: 927.9196\n",
      "Epoch [92/100], Step [49400/6235], Loss: 41.2774\n",
      "Epoch [92/100], Step [49500/6235], Loss: 25.2479\n",
      "Epoch [92/100], Step [49600/6235], Loss: 216.2918\n",
      "Epoch [92/100], Step [49700/6235], Loss: 12553.0723\n",
      "Epoch [92/100], Step [49800/6235], Loss: 3750.9067\n",
      "Epoch [93/100], Step [100/6235], Loss: 35.9944\n",
      "Epoch [93/100], Step [200/6235], Loss: 0.1355\n",
      "Epoch [93/100], Step [300/6235], Loss: 0.0034\n",
      "Epoch [93/100], Step [400/6235], Loss: 0.0022\n",
      "Epoch [93/100], Step [500/6235], Loss: 0.0807\n",
      "Epoch [93/100], Step [600/6235], Loss: 0.0284\n",
      "Epoch [93/100], Step [700/6235], Loss: 0.3255\n",
      "Epoch [93/100], Step [800/6235], Loss: 0.1167\n",
      "Epoch [93/100], Step [900/6235], Loss: 0.0243\n",
      "Epoch [93/100], Step [1000/6235], Loss: 0.0246\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Step [1100/6235], Loss: 0.0078\n",
      "Epoch [93/100], Step [1200/6235], Loss: 0.1582\n",
      "Epoch [93/100], Step [1300/6235], Loss: 0.0541\n",
      "Epoch [93/100], Step [1400/6235], Loss: 0.0369\n",
      "Epoch [93/100], Step [1500/6235], Loss: 0.0046\n",
      "Epoch [93/100], Step [1600/6235], Loss: 0.2153\n",
      "Epoch [93/100], Step [1700/6235], Loss: 0.0134\n",
      "Epoch [93/100], Step [1800/6235], Loss: 0.1894\n",
      "Epoch [93/100], Step [1900/6235], Loss: 0.7378\n",
      "Epoch [93/100], Step [2000/6235], Loss: 2.1727\n",
      "Epoch [93/100], Step [2100/6235], Loss: 0.7388\n",
      "Epoch [93/100], Step [2200/6235], Loss: 10.8885\n",
      "Epoch [93/100], Step [2300/6235], Loss: 19.2957\n",
      "Epoch [93/100], Step [2400/6235], Loss: 9.8568\n",
      "Epoch [93/100], Step [2500/6235], Loss: 35.4840\n",
      "Epoch [93/100], Step [2600/6235], Loss: 8.5031\n",
      "Epoch [93/100], Step [2700/6235], Loss: 25.9958\n",
      "Epoch [93/100], Step [2800/6235], Loss: 63.0037\n",
      "Epoch [93/100], Step [2900/6235], Loss: 6.3594\n",
      "Epoch [93/100], Step [3000/6235], Loss: 1.2562\n",
      "Epoch [93/100], Step [3100/6235], Loss: 59.7977\n",
      "Epoch [93/100], Step [3200/6235], Loss: 81.5685\n",
      "Epoch [93/100], Step [3300/6235], Loss: 0.8423\n",
      "Epoch [93/100], Step [3400/6235], Loss: 3.1472\n",
      "Epoch [93/100], Step [3500/6235], Loss: 29.4435\n",
      "Epoch [93/100], Step [3600/6235], Loss: 10.3839\n",
      "Epoch [93/100], Step [3700/6235], Loss: 1.2372\n",
      "Epoch [93/100], Step [3800/6235], Loss: 0.5733\n",
      "Epoch [93/100], Step [3900/6235], Loss: 1.4355\n",
      "Epoch [93/100], Step [4000/6235], Loss: 0.1256\n",
      "Epoch [93/100], Step [4100/6235], Loss: 4.1958\n",
      "Epoch [93/100], Step [4200/6235], Loss: 0.3932\n",
      "Epoch [93/100], Step [4300/6235], Loss: 9.1522\n",
      "Epoch [93/100], Step [4400/6235], Loss: 3.4328\n",
      "Epoch [93/100], Step [4500/6235], Loss: 57.6732\n",
      "Epoch [93/100], Step [4600/6235], Loss: 9.3406\n",
      "Epoch [93/100], Step [4700/6235], Loss: 1.5102\n",
      "Epoch [93/100], Step [4800/6235], Loss: 0.6803\n",
      "Epoch [93/100], Step [4900/6235], Loss: 0.1000\n",
      "Epoch [93/100], Step [5000/6235], Loss: 0.3944\n",
      "Epoch [93/100], Step [5100/6235], Loss: 1.7539\n",
      "Epoch [93/100], Step [5200/6235], Loss: 1.7325\n",
      "Epoch [93/100], Step [5300/6235], Loss: 32.0296\n",
      "Epoch [93/100], Step [5400/6235], Loss: 0.2865\n",
      "Epoch [93/100], Step [5500/6235], Loss: 0.2133\n",
      "Epoch [93/100], Step [5600/6235], Loss: 0.3845\n",
      "Epoch [93/100], Step [5700/6235], Loss: 1.9884\n",
      "Epoch [93/100], Step [5800/6235], Loss: 1.3037\n",
      "Epoch [93/100], Step [5900/6235], Loss: 0.1198\n",
      "Epoch [93/100], Step [6000/6235], Loss: 0.6580\n",
      "Epoch [93/100], Step [6100/6235], Loss: 0.0590\n",
      "Epoch [93/100], Step [6200/6235], Loss: 0.5731\n",
      "Epoch [93/100], Step [6300/6235], Loss: 0.8205\n",
      "Epoch [93/100], Step [6400/6235], Loss: 0.0579\n",
      "Epoch [93/100], Step [6500/6235], Loss: 0.9135\n",
      "Epoch [93/100], Step [6600/6235], Loss: 1.4416\n",
      "Epoch [93/100], Step [6700/6235], Loss: 0.7239\n",
      "Epoch [93/100], Step [6800/6235], Loss: 0.9633\n",
      "Epoch [93/100], Step [6900/6235], Loss: 3.3610\n",
      "Epoch [93/100], Step [7000/6235], Loss: 0.5313\n",
      "Epoch [93/100], Step [7100/6235], Loss: 0.3422\n",
      "Epoch [93/100], Step [7200/6235], Loss: 0.3644\n",
      "Epoch [93/100], Step [7300/6235], Loss: 0.0828\n",
      "Epoch [93/100], Step [7400/6235], Loss: 0.3260\n",
      "Epoch [93/100], Step [7500/6235], Loss: 0.6100\n",
      "Epoch [93/100], Step [7600/6235], Loss: 13.7419\n",
      "Epoch [93/100], Step [7700/6235], Loss: 17.3934\n",
      "Epoch [93/100], Step [7800/6235], Loss: 14.0003\n",
      "Epoch [93/100], Step [7900/6235], Loss: 4.8619\n",
      "Epoch [93/100], Step [8000/6235], Loss: 0.5069\n",
      "Epoch [93/100], Step [8100/6235], Loss: 4.2269\n",
      "Epoch [93/100], Step [8200/6235], Loss: 19.9656\n",
      "Epoch [93/100], Step [8300/6235], Loss: 64.9674\n",
      "Epoch [93/100], Step [8400/6235], Loss: 63.1050\n",
      "Epoch [93/100], Step [8500/6235], Loss: 53.4999\n",
      "Epoch [93/100], Step [8600/6235], Loss: 57.0377\n",
      "Epoch [93/100], Step [8700/6235], Loss: 99.5366\n",
      "Epoch [93/100], Step [8800/6235], Loss: 520.1313\n",
      "Epoch [93/100], Step [8900/6235], Loss: 4.0775\n",
      "Epoch [93/100], Step [9000/6235], Loss: 675.9855\n",
      "Epoch [93/100], Step [9100/6235], Loss: 1525.8088\n",
      "Epoch [93/100], Step [9200/6235], Loss: 5815.8271\n",
      "Epoch [93/100], Step [9300/6235], Loss: 108.4735\n",
      "Epoch [93/100], Step [9400/6235], Loss: 104.0945\n",
      "Epoch [93/100], Step [9500/6235], Loss: 2226.9260\n",
      "Epoch [93/100], Step [9600/6235], Loss: 694.7695\n",
      "Epoch [93/100], Step [9700/6235], Loss: 5.6989\n",
      "Epoch [93/100], Step [9800/6235], Loss: 1653.0911\n",
      "Epoch [93/100], Step [9900/6235], Loss: 130.2074\n",
      "Epoch [93/100], Step [10000/6235], Loss: 352.3250\n",
      "Epoch [93/100], Step [10100/6235], Loss: 3.4759\n",
      "Epoch [93/100], Step [10200/6235], Loss: 446.5838\n",
      "Epoch [93/100], Step [10300/6235], Loss: 4.3233\n",
      "Epoch [93/100], Step [10400/6235], Loss: 9.2802\n",
      "Epoch [93/100], Step [10500/6235], Loss: 1.8370\n",
      "Epoch [93/100], Step [10600/6235], Loss: 22.1957\n",
      "Epoch [93/100], Step [10700/6235], Loss: 18.2670\n",
      "Epoch [93/100], Step [10800/6235], Loss: 44.6197\n",
      "Epoch [93/100], Step [10900/6235], Loss: 7.9299\n",
      "Epoch [93/100], Step [11000/6235], Loss: 300.3568\n",
      "Epoch [93/100], Step [11100/6235], Loss: 48.8338\n",
      "Epoch [93/100], Step [11200/6235], Loss: 18.5256\n",
      "Epoch [93/100], Step [11300/6235], Loss: 114.7701\n",
      "Epoch [93/100], Step [11400/6235], Loss: 3.6649\n",
      "Epoch [93/100], Step [11500/6235], Loss: 8.6919\n",
      "Epoch [93/100], Step [11600/6235], Loss: 6.0113\n",
      "Epoch [93/100], Step [11700/6235], Loss: 41.4095\n",
      "Epoch [93/100], Step [11800/6235], Loss: 425.6642\n",
      "Epoch [93/100], Step [11900/6235], Loss: 363.7628\n",
      "Epoch [93/100], Step [12000/6235], Loss: 202.3889\n",
      "Epoch [93/100], Step [12100/6235], Loss: 194.1901\n",
      "Epoch [93/100], Step [12200/6235], Loss: 179.7082\n",
      "Epoch [93/100], Step [12300/6235], Loss: 42.0261\n",
      "Epoch [93/100], Step [12400/6235], Loss: 168.5491\n",
      "Epoch [93/100], Step [12500/6235], Loss: 12.5499\n",
      "Epoch [93/100], Step [12600/6235], Loss: 79.8806\n",
      "Epoch [93/100], Step [12700/6235], Loss: 1.4474\n",
      "Epoch [93/100], Step [12800/6235], Loss: 5.8286\n",
      "Epoch [93/100], Step [12900/6235], Loss: 30.4367\n",
      "Epoch [93/100], Step [13000/6235], Loss: 0.2307\n",
      "Epoch [93/100], Step [13100/6235], Loss: 63.5065\n",
      "Epoch [93/100], Step [13200/6235], Loss: 9.5738\n",
      "Epoch [93/100], Step [13300/6235], Loss: 39.8822\n",
      "Epoch [93/100], Step [13400/6235], Loss: 240.8105\n",
      "Epoch [93/100], Step [13500/6235], Loss: 3.4656\n",
      "Epoch [93/100], Step [13600/6235], Loss: 11.2913\n",
      "Epoch [93/100], Step [13700/6235], Loss: 0.4323\n",
      "Epoch [93/100], Step [13800/6235], Loss: 171.7183\n",
      "Epoch [93/100], Step [13900/6235], Loss: 58.9139\n",
      "Epoch [93/100], Step [14000/6235], Loss: 14.5629\n",
      "Epoch [93/100], Step [14100/6235], Loss: 33.6837\n",
      "Epoch [93/100], Step [14200/6235], Loss: 71.2220\n",
      "Epoch [93/100], Step [14300/6235], Loss: 14.8844\n",
      "Epoch [93/100], Step [14400/6235], Loss: 39.1184\n",
      "Epoch [93/100], Step [14500/6235], Loss: 53.6270\n",
      "Epoch [93/100], Step [14600/6235], Loss: 0.1036\n",
      "Epoch [93/100], Step [14700/6235], Loss: 45.3555\n",
      "Epoch [93/100], Step [14800/6235], Loss: 32.0646\n",
      "Epoch [93/100], Step [14900/6235], Loss: 1.0025\n",
      "Epoch [93/100], Step [15000/6235], Loss: 2.1529\n",
      "Epoch [93/100], Step [15100/6235], Loss: 0.4271\n",
      "Epoch [93/100], Step [15200/6235], Loss: 3.9950\n",
      "Epoch [93/100], Step [15300/6235], Loss: 37.5602\n",
      "Epoch [93/100], Step [15400/6235], Loss: 40.0234\n",
      "Epoch [93/100], Step [15500/6235], Loss: 10.8386\n",
      "Epoch [93/100], Step [15600/6235], Loss: 162.3445\n",
      "Epoch [93/100], Step [15700/6235], Loss: 17.4383\n",
      "Epoch [93/100], Step [15800/6235], Loss: 1.0284\n",
      "Epoch [93/100], Step [15900/6235], Loss: 1.8045\n",
      "Epoch [93/100], Step [16000/6235], Loss: 90.0317\n",
      "Epoch [93/100], Step [16100/6235], Loss: 7.5017\n",
      "Epoch [93/100], Step [16200/6235], Loss: 0.5520\n",
      "Epoch [93/100], Step [16300/6235], Loss: 8.1955\n",
      "Epoch [93/100], Step [16400/6235], Loss: 22.9059\n",
      "Epoch [93/100], Step [16500/6235], Loss: 130.8858\n",
      "Epoch [93/100], Step [16600/6235], Loss: 17.1746\n",
      "Epoch [93/100], Step [16700/6235], Loss: 0.5316\n",
      "Epoch [93/100], Step [16800/6235], Loss: 11.1069\n",
      "Epoch [93/100], Step [16900/6235], Loss: 0.2903\n",
      "Epoch [93/100], Step [17000/6235], Loss: 0.1960\n",
      "Epoch [93/100], Step [17100/6235], Loss: 0.1230\n",
      "Epoch [93/100], Step [17200/6235], Loss: 257.0785\n",
      "Epoch [93/100], Step [17300/6235], Loss: 25.6156\n",
      "Epoch [93/100], Step [17400/6235], Loss: 39.7294\n",
      "Epoch [93/100], Step [17500/6235], Loss: 2.0317\n",
      "Epoch [93/100], Step [17600/6235], Loss: 2.4990\n",
      "Epoch [93/100], Step [17700/6235], Loss: 33.2367\n",
      "Epoch [93/100], Step [17800/6235], Loss: 36.6812\n",
      "Epoch [93/100], Step [17900/6235], Loss: 5.0686\n",
      "Epoch [93/100], Step [18000/6235], Loss: 0.9830\n",
      "Epoch [93/100], Step [18100/6235], Loss: 12.1706\n",
      "Epoch [93/100], Step [18200/6235], Loss: 0.7666\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Step [18300/6235], Loss: 5.4708\n",
      "Epoch [93/100], Step [18400/6235], Loss: 5.5580\n",
      "Epoch [93/100], Step [18500/6235], Loss: 19.1883\n",
      "Epoch [93/100], Step [18600/6235], Loss: 0.8571\n",
      "Epoch [93/100], Step [18700/6235], Loss: 0.4092\n",
      "Epoch [93/100], Step [18800/6235], Loss: 104.9888\n",
      "Epoch [93/100], Step [18900/6235], Loss: 33.8825\n",
      "Epoch [93/100], Step [19000/6235], Loss: 1.5316\n",
      "Epoch [93/100], Step [19100/6235], Loss: 43.8233\n",
      "Epoch [93/100], Step [19200/6235], Loss: 1.8775\n",
      "Epoch [93/100], Step [19300/6235], Loss: 15.6396\n",
      "Epoch [93/100], Step [19400/6235], Loss: 226.0523\n",
      "Epoch [93/100], Step [19500/6235], Loss: 94.9893\n",
      "Epoch [93/100], Step [19600/6235], Loss: 82.4781\n",
      "Epoch [93/100], Step [19700/6235], Loss: 8.1205\n",
      "Epoch [93/100], Step [19800/6235], Loss: 2.7158\n",
      "Epoch [93/100], Step [19900/6235], Loss: 0.1249\n",
      "Epoch [93/100], Step [20000/6235], Loss: 64.8255\n",
      "Epoch [93/100], Step [20100/6235], Loss: 0.9700\n",
      "Epoch [93/100], Step [20200/6235], Loss: 5.2648\n",
      "Epoch [93/100], Step [20300/6235], Loss: 1.8398\n",
      "Epoch [93/100], Step [20400/6235], Loss: 18.4642\n",
      "Epoch [93/100], Step [20500/6235], Loss: 41.9425\n",
      "Epoch [93/100], Step [20600/6235], Loss: 52.4772\n",
      "Epoch [93/100], Step [20700/6235], Loss: 5.3680\n",
      "Epoch [93/100], Step [20800/6235], Loss: 55.6337\n",
      "Epoch [93/100], Step [20900/6235], Loss: 14.8961\n",
      "Epoch [93/100], Step [21000/6235], Loss: 17.1204\n",
      "Epoch [93/100], Step [21100/6235], Loss: 0.3597\n",
      "Epoch [93/100], Step [21200/6235], Loss: 0.1087\n",
      "Epoch [93/100], Step [21300/6235], Loss: 0.1672\n",
      "Epoch [93/100], Step [21400/6235], Loss: 5.6036\n",
      "Epoch [93/100], Step [21500/6235], Loss: 0.6382\n",
      "Epoch [93/100], Step [21600/6235], Loss: 29.2826\n",
      "Epoch [93/100], Step [21700/6235], Loss: 0.2228\n",
      "Epoch [93/100], Step [21800/6235], Loss: 24.7782\n",
      "Epoch [93/100], Step [21900/6235], Loss: 0.7441\n",
      "Epoch [93/100], Step [22000/6235], Loss: 5.6626\n",
      "Epoch [93/100], Step [22100/6235], Loss: 1.4556\n",
      "Epoch [93/100], Step [22200/6235], Loss: 2.0673\n",
      "Epoch [93/100], Step [22300/6235], Loss: 0.7147\n",
      "Epoch [93/100], Step [22400/6235], Loss: 5.7033\n",
      "Epoch [93/100], Step [22500/6235], Loss: 120.8132\n",
      "Epoch [93/100], Step [22600/6235], Loss: 19.1898\n",
      "Epoch [93/100], Step [22700/6235], Loss: 0.8598\n",
      "Epoch [93/100], Step [22800/6235], Loss: 10.8250\n",
      "Epoch [93/100], Step [22900/6235], Loss: 11.4188\n",
      "Epoch [93/100], Step [23000/6235], Loss: 21.4806\n",
      "Epoch [93/100], Step [23100/6235], Loss: 8.1742\n",
      "Epoch [93/100], Step [23200/6235], Loss: 9.2072\n",
      "Epoch [93/100], Step [23300/6235], Loss: 16.6333\n",
      "Epoch [93/100], Step [23400/6235], Loss: 2.0372\n",
      "Epoch [93/100], Step [23500/6235], Loss: 0.0508\n",
      "Epoch [93/100], Step [23600/6235], Loss: 119.4106\n",
      "Epoch [93/100], Step [23700/6235], Loss: 2.7822\n",
      "Epoch [93/100], Step [23800/6235], Loss: 1.0209\n",
      "Epoch [93/100], Step [23900/6235], Loss: 6.5355\n",
      "Epoch [93/100], Step [24000/6235], Loss: 0.1060\n",
      "Epoch [93/100], Step [24100/6235], Loss: 0.8664\n",
      "Epoch [93/100], Step [24200/6235], Loss: 22.2909\n",
      "Epoch [93/100], Step [24300/6235], Loss: 1.3620\n",
      "Epoch [93/100], Step [24400/6235], Loss: 4.9049\n",
      "Epoch [93/100], Step [24500/6235], Loss: 2.5018\n",
      "Epoch [93/100], Step [24600/6235], Loss: 0.1791\n",
      "Epoch [93/100], Step [24700/6235], Loss: 6.3920\n",
      "Epoch [93/100], Step [24800/6235], Loss: 0.0740\n",
      "Epoch [93/100], Step [24900/6235], Loss: 0.7918\n",
      "Epoch [93/100], Step [25000/6235], Loss: 11.1349\n",
      "Epoch [93/100], Step [25100/6235], Loss: 9.0884\n",
      "Epoch [93/100], Step [25200/6235], Loss: 1.5418\n",
      "Epoch [93/100], Step [25300/6235], Loss: 0.6508\n",
      "Epoch [93/100], Step [25400/6235], Loss: 9.6621\n",
      "Epoch [93/100], Step [25500/6235], Loss: 7.0507\n",
      "Epoch [93/100], Step [25600/6235], Loss: 3.5888\n",
      "Epoch [93/100], Step [25700/6235], Loss: 0.3408\n",
      "Epoch [93/100], Step [25800/6235], Loss: 0.1680\n",
      "Epoch [93/100], Step [25900/6235], Loss: 9.0068\n",
      "Epoch [93/100], Step [26000/6235], Loss: 0.2302\n",
      "Epoch [93/100], Step [26100/6235], Loss: 0.1024\n",
      "Epoch [93/100], Step [26200/6235], Loss: 0.2336\n",
      "Epoch [93/100], Step [26300/6235], Loss: 4.6811\n",
      "Epoch [93/100], Step [26400/6235], Loss: 0.1752\n",
      "Epoch [93/100], Step [26500/6235], Loss: 0.1766\n",
      "Epoch [93/100], Step [26600/6235], Loss: 2.8803\n",
      "Epoch [93/100], Step [26700/6235], Loss: 0.6098\n",
      "Epoch [93/100], Step [26800/6235], Loss: 0.5792\n",
      "Epoch [93/100], Step [26900/6235], Loss: 0.0330\n",
      "Epoch [93/100], Step [27000/6235], Loss: 13.1421\n",
      "Epoch [93/100], Step [27100/6235], Loss: 0.1100\n",
      "Epoch [93/100], Step [27200/6235], Loss: 0.0449\n",
      "Epoch [93/100], Step [27300/6235], Loss: 0.2238\n",
      "Epoch [93/100], Step [27400/6235], Loss: 0.8988\n",
      "Epoch [93/100], Step [27500/6235], Loss: 28.5737\n",
      "Epoch [93/100], Step [27600/6235], Loss: 1.1870\n",
      "Epoch [93/100], Step [27700/6235], Loss: 0.0079\n",
      "Epoch [93/100], Step [27800/6235], Loss: 8.1239\n",
      "Epoch [93/100], Step [27900/6235], Loss: 1.3276\n",
      "Epoch [93/100], Step [28000/6235], Loss: 173.5715\n",
      "Epoch [93/100], Step [28100/6235], Loss: 3.8547\n",
      "Epoch [93/100], Step [28200/6235], Loss: 31.5492\n",
      "Epoch [93/100], Step [28300/6235], Loss: 4.0072\n",
      "Epoch [93/100], Step [28400/6235], Loss: 21.0351\n",
      "Epoch [93/100], Step [28500/6235], Loss: 1.1211\n",
      "Epoch [93/100], Step [28600/6235], Loss: 0.6934\n",
      "Epoch [93/100], Step [28700/6235], Loss: 4.2981\n",
      "Epoch [93/100], Step [28800/6235], Loss: 0.3199\n",
      "Epoch [93/100], Step [28900/6235], Loss: 65.9535\n",
      "Epoch [93/100], Step [29000/6235], Loss: 9.0852\n",
      "Epoch [93/100], Step [29100/6235], Loss: 0.2325\n",
      "Epoch [93/100], Step [29200/6235], Loss: 0.0870\n",
      "Epoch [93/100], Step [29300/6235], Loss: 3.8266\n",
      "Epoch [93/100], Step [29400/6235], Loss: 0.2006\n",
      "Epoch [93/100], Step [29500/6235], Loss: 3.5291\n",
      "Epoch [93/100], Step [29600/6235], Loss: 0.4489\n",
      "Epoch [93/100], Step [29700/6235], Loss: 0.1190\n",
      "Epoch [93/100], Step [29800/6235], Loss: 1.6362\n",
      "Epoch [93/100], Step [29900/6235], Loss: 0.0815\n",
      "Epoch [93/100], Step [30000/6235], Loss: 6.9497\n",
      "Epoch [93/100], Step [30100/6235], Loss: 0.1334\n",
      "Epoch [93/100], Step [30200/6235], Loss: 0.0497\n",
      "Epoch [93/100], Step [30300/6235], Loss: 0.8127\n",
      "Epoch [93/100], Step [30400/6235], Loss: 0.1452\n",
      "Epoch [93/100], Step [30500/6235], Loss: 1.5035\n",
      "Epoch [93/100], Step [30600/6235], Loss: 0.2834\n",
      "Epoch [93/100], Step [30700/6235], Loss: 0.3051\n",
      "Epoch [93/100], Step [30800/6235], Loss: 0.2051\n",
      "Epoch [93/100], Step [30900/6235], Loss: 2.2580\n",
      "Epoch [93/100], Step [31000/6235], Loss: 0.0826\n",
      "Epoch [93/100], Step [31100/6235], Loss: 0.1022\n",
      "Epoch [93/100], Step [31200/6235], Loss: 5.9443\n",
      "Epoch [93/100], Step [31300/6235], Loss: 2.0564\n",
      "Epoch [93/100], Step [31400/6235], Loss: 0.8208\n",
      "Epoch [93/100], Step [31500/6235], Loss: 0.4432\n",
      "Epoch [93/100], Step [31600/6235], Loss: 2.0758\n",
      "Epoch [93/100], Step [31700/6235], Loss: 1.9175\n",
      "Epoch [93/100], Step [31800/6235], Loss: 2.1058\n",
      "Epoch [93/100], Step [31900/6235], Loss: 45.2511\n",
      "Epoch [93/100], Step [32000/6235], Loss: 0.1077\n",
      "Epoch [93/100], Step [32100/6235], Loss: 4.0824\n",
      "Epoch [93/100], Step [32200/6235], Loss: 94.9773\n",
      "Epoch [93/100], Step [32300/6235], Loss: 0.4401\n",
      "Epoch [93/100], Step [32400/6235], Loss: 0.1237\n",
      "Epoch [93/100], Step [32500/6235], Loss: 21.1458\n",
      "Epoch [93/100], Step [32600/6235], Loss: 1.1503\n",
      "Epoch [93/100], Step [32700/6235], Loss: 65.0307\n",
      "Epoch [93/100], Step [32800/6235], Loss: 2.7224\n",
      "Epoch [93/100], Step [32900/6235], Loss: 12.0030\n",
      "Epoch [93/100], Step [33000/6235], Loss: 0.1881\n",
      "Epoch [93/100], Step [33100/6235], Loss: 0.9374\n",
      "Epoch [93/100], Step [33200/6235], Loss: 1.6951\n",
      "Epoch [93/100], Step [33300/6235], Loss: 7.2022\n",
      "Epoch [93/100], Step [33400/6235], Loss: 122.6253\n",
      "Epoch [93/100], Step [33500/6235], Loss: 2.8300\n",
      "Epoch [93/100], Step [33600/6235], Loss: 0.1729\n",
      "Epoch [93/100], Step [33700/6235], Loss: 2.6673\n",
      "Epoch [93/100], Step [33800/6235], Loss: 1.4670\n",
      "Epoch [93/100], Step [33900/6235], Loss: 23.6588\n",
      "Epoch [93/100], Step [34000/6235], Loss: 0.0875\n",
      "Epoch [93/100], Step [34100/6235], Loss: 0.0663\n",
      "Epoch [93/100], Step [34200/6235], Loss: 2.6753\n",
      "Epoch [93/100], Step [34300/6235], Loss: 7.6181\n",
      "Epoch [93/100], Step [34400/6235], Loss: 0.4317\n",
      "Epoch [93/100], Step [34500/6235], Loss: 78.4980\n",
      "Epoch [93/100], Step [34600/6235], Loss: 2.5513\n",
      "Epoch [93/100], Step [34700/6235], Loss: 14.6768\n",
      "Epoch [93/100], Step [34800/6235], Loss: 12.8753\n",
      "Epoch [93/100], Step [34900/6235], Loss: 37.4699\n",
      "Epoch [93/100], Step [35000/6235], Loss: 1.5301\n",
      "Epoch [93/100], Step [35100/6235], Loss: 1.8518\n",
      "Epoch [93/100], Step [35200/6235], Loss: 2.6422\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [93/100], Step [35300/6235], Loss: 0.0129\n",
      "Epoch [93/100], Step [35400/6235], Loss: 0.9758\n",
      "Epoch [93/100], Step [35500/6235], Loss: 2.1247\n",
      "Epoch [93/100], Step [35600/6235], Loss: 3.0831\n",
      "Epoch [93/100], Step [35700/6235], Loss: 6.0539\n",
      "Epoch [93/100], Step [35800/6235], Loss: 1.1544\n",
      "Epoch [93/100], Step [35900/6235], Loss: 0.3090\n",
      "Epoch [93/100], Step [36000/6235], Loss: 0.8059\n",
      "Epoch [93/100], Step [36100/6235], Loss: 0.0490\n",
      "Epoch [93/100], Step [36200/6235], Loss: 17.5873\n",
      "Epoch [93/100], Step [36300/6235], Loss: 0.1191\n",
      "Epoch [93/100], Step [36400/6235], Loss: 0.4925\n",
      "Epoch [93/100], Step [36500/6235], Loss: 9.9247\n",
      "Epoch [93/100], Step [36600/6235], Loss: 0.0460\n",
      "Epoch [93/100], Step [36700/6235], Loss: 0.1312\n",
      "Epoch [93/100], Step [36800/6235], Loss: 27.6537\n",
      "Epoch [93/100], Step [36900/6235], Loss: 3.6407\n",
      "Epoch [93/100], Step [37000/6235], Loss: 0.0380\n",
      "Epoch [93/100], Step [37100/6235], Loss: 0.1299\n",
      "Epoch [93/100], Step [37200/6235], Loss: 0.0359\n",
      "Epoch [93/100], Step [37300/6235], Loss: 0.2928\n",
      "Epoch [93/100], Step [37400/6235], Loss: 0.1983\n",
      "Epoch [93/100], Step [37500/6235], Loss: 2.6817\n",
      "Epoch [93/100], Step [37600/6235], Loss: 10.0794\n",
      "Epoch [93/100], Step [37700/6235], Loss: 0.1838\n",
      "Epoch [93/100], Step [37800/6235], Loss: 9.0990\n",
      "Epoch [93/100], Step [37900/6235], Loss: 7.5040\n",
      "Epoch [93/100], Step [38000/6235], Loss: 0.2221\n",
      "Epoch [93/100], Step [38100/6235], Loss: 2.3678\n",
      "Epoch [93/100], Step [38200/6235], Loss: 1.4720\n",
      "Epoch [93/100], Step [38300/6235], Loss: 0.8344\n",
      "Epoch [93/100], Step [38400/6235], Loss: 0.1481\n",
      "Epoch [93/100], Step [38500/6235], Loss: 4.0780\n",
      "Epoch [93/100], Step [38600/6235], Loss: 0.5660\n",
      "Epoch [93/100], Step [38700/6235], Loss: 0.3316\n",
      "Epoch [93/100], Step [38800/6235], Loss: 0.4898\n",
      "Epoch [93/100], Step [38900/6235], Loss: 22.1914\n",
      "Epoch [93/100], Step [39000/6235], Loss: 9.8995\n",
      "Epoch [93/100], Step [39100/6235], Loss: 6.6855\n",
      "Epoch [93/100], Step [39200/6235], Loss: 0.6196\n",
      "Epoch [93/100], Step [39300/6235], Loss: 35.0541\n",
      "Epoch [93/100], Step [39400/6235], Loss: 279.3191\n",
      "Epoch [93/100], Step [39500/6235], Loss: 249.2338\n",
      "Epoch [93/100], Step [39600/6235], Loss: 4.3653\n",
      "Epoch [93/100], Step [39700/6235], Loss: 312.4657\n",
      "Epoch [93/100], Step [39800/6235], Loss: 102.0816\n",
      "Epoch [93/100], Step [39900/6235], Loss: 12.9206\n",
      "Epoch [93/100], Step [40000/6235], Loss: 5.4642\n",
      "Epoch [93/100], Step [40100/6235], Loss: 4.1553\n",
      "Epoch [93/100], Step [40200/6235], Loss: 23.5701\n",
      "Epoch [93/100], Step [40300/6235], Loss: 0.8789\n",
      "Epoch [93/100], Step [40400/6235], Loss: 0.7173\n",
      "Epoch [93/100], Step [40500/6235], Loss: 3.7266\n",
      "Epoch [93/100], Step [40600/6235], Loss: 0.4314\n",
      "Epoch [93/100], Step [40700/6235], Loss: 4.0988\n",
      "Epoch [93/100], Step [40800/6235], Loss: 2.1017\n",
      "Epoch [93/100], Step [40900/6235], Loss: 1.3673\n",
      "Epoch [93/100], Step [41000/6235], Loss: 36.3099\n",
      "Epoch [93/100], Step [41100/6235], Loss: 51.3853\n",
      "Epoch [93/100], Step [41200/6235], Loss: 31.3908\n",
      "Epoch [93/100], Step [41300/6235], Loss: 6.5000\n",
      "Epoch [93/100], Step [41400/6235], Loss: 3.2982\n",
      "Epoch [93/100], Step [41500/6235], Loss: 1.6398\n",
      "Epoch [93/100], Step [41600/6235], Loss: 0.1697\n",
      "Epoch [93/100], Step [41700/6235], Loss: 2.9098\n",
      "Epoch [93/100], Step [41800/6235], Loss: 4.4342\n",
      "Epoch [93/100], Step [41900/6235], Loss: 4.3482\n",
      "Epoch [93/100], Step [42000/6235], Loss: 4.4191\n",
      "Epoch [93/100], Step [42100/6235], Loss: 10.0731\n",
      "Epoch [93/100], Step [42200/6235], Loss: 29.6713\n",
      "Epoch [93/100], Step [42300/6235], Loss: 1.0627\n",
      "Epoch [93/100], Step [42400/6235], Loss: 2.8518\n",
      "Epoch [93/100], Step [42500/6235], Loss: 0.6101\n",
      "Epoch [93/100], Step [42600/6235], Loss: 1.4402\n",
      "Epoch [93/100], Step [42700/6235], Loss: 0.2964\n",
      "Epoch [93/100], Step [42800/6235], Loss: 16.0550\n",
      "Epoch [93/100], Step [42900/6235], Loss: 0.2685\n",
      "Epoch [93/100], Step [43000/6235], Loss: 0.4256\n",
      "Epoch [93/100], Step [43100/6235], Loss: 0.0539\n",
      "Epoch [93/100], Step [43200/6235], Loss: 0.1554\n",
      "Epoch [93/100], Step [43300/6235], Loss: 4.5189\n",
      "Epoch [93/100], Step [43400/6235], Loss: 4.5791\n",
      "Epoch [93/100], Step [43500/6235], Loss: 11.7517\n",
      "Epoch [93/100], Step [43600/6235], Loss: 1.2806\n",
      "Epoch [93/100], Step [43700/6235], Loss: 48.9562\n",
      "Epoch [93/100], Step [43800/6235], Loss: 0.2650\n",
      "Epoch [93/100], Step [43900/6235], Loss: 2.2364\n",
      "Epoch [93/100], Step [44000/6235], Loss: 66.5659\n",
      "Epoch [93/100], Step [44100/6235], Loss: 5.7814\n",
      "Epoch [93/100], Step [44200/6235], Loss: 2.7638\n",
      "Epoch [93/100], Step [44300/6235], Loss: 55.8039\n",
      "Epoch [93/100], Step [44400/6235], Loss: 1.4655\n",
      "Epoch [93/100], Step [44500/6235], Loss: 0.1640\n",
      "Epoch [93/100], Step [44600/6235], Loss: 17.4267\n",
      "Epoch [93/100], Step [44700/6235], Loss: 24.2808\n",
      "Epoch [93/100], Step [44800/6235], Loss: 3.8424\n",
      "Epoch [93/100], Step [44900/6235], Loss: 12.1190\n",
      "Epoch [93/100], Step [45000/6235], Loss: 6.1500\n",
      "Epoch [93/100], Step [45100/6235], Loss: 51.1322\n",
      "Epoch [93/100], Step [45200/6235], Loss: 12.5145\n",
      "Epoch [93/100], Step [45300/6235], Loss: 24.6639\n",
      "Epoch [93/100], Step [45400/6235], Loss: 9.7580\n",
      "Epoch [93/100], Step [45500/6235], Loss: 3.2453\n",
      "Epoch [93/100], Step [45600/6235], Loss: 1.1048\n",
      "Epoch [93/100], Step [45700/6235], Loss: 102.2740\n",
      "Epoch [93/100], Step [45800/6235], Loss: 261.0757\n",
      "Epoch [93/100], Step [45900/6235], Loss: 9.5783\n",
      "Epoch [93/100], Step [46000/6235], Loss: 25.6946\n",
      "Epoch [93/100], Step [46100/6235], Loss: 21.2826\n",
      "Epoch [93/100], Step [46200/6235], Loss: 107.0820\n",
      "Epoch [93/100], Step [46300/6235], Loss: 58.8727\n",
      "Epoch [93/100], Step [46400/6235], Loss: 17.4467\n",
      "Epoch [93/100], Step [46500/6235], Loss: 3.6554\n",
      "Epoch [93/100], Step [46600/6235], Loss: 8.6401\n",
      "Epoch [93/100], Step [46700/6235], Loss: 15.4308\n",
      "Epoch [93/100], Step [46800/6235], Loss: 1.0376\n",
      "Epoch [93/100], Step [46900/6235], Loss: 1.4678\n",
      "Epoch [93/100], Step [47000/6235], Loss: 7.6988\n",
      "Epoch [93/100], Step [47100/6235], Loss: 0.7231\n",
      "Epoch [93/100], Step [47200/6235], Loss: 33.0766\n",
      "Epoch [93/100], Step [47300/6235], Loss: 1.0697\n",
      "Epoch [93/100], Step [47400/6235], Loss: 49.4639\n",
      "Epoch [93/100], Step [47500/6235], Loss: 27.6944\n",
      "Epoch [93/100], Step [47600/6235], Loss: 3.0662\n",
      "Epoch [93/100], Step [47700/6235], Loss: 7.8590\n",
      "Epoch [93/100], Step [47800/6235], Loss: 8.0967\n",
      "Epoch [93/100], Step [47900/6235], Loss: 16.7866\n",
      "Epoch [93/100], Step [48000/6235], Loss: 2.6384\n",
      "Epoch [93/100], Step [48100/6235], Loss: 4.2186\n",
      "Epoch [93/100], Step [48200/6235], Loss: 7.6874\n",
      "Epoch [93/100], Step [48300/6235], Loss: 283.9724\n",
      "Epoch [93/100], Step [48400/6235], Loss: 19.7050\n",
      "Epoch [93/100], Step [48500/6235], Loss: 19.1065\n",
      "Epoch [93/100], Step [48600/6235], Loss: 160.8916\n",
      "Epoch [93/100], Step [48700/6235], Loss: 11.7122\n",
      "Epoch [93/100], Step [48800/6235], Loss: 392.1130\n",
      "Epoch [93/100], Step [48900/6235], Loss: 298.4976\n",
      "Epoch [93/100], Step [49000/6235], Loss: 286.5259\n",
      "Epoch [93/100], Step [49100/6235], Loss: 1132.1121\n",
      "Epoch [93/100], Step [49200/6235], Loss: 710.3665\n",
      "Epoch [93/100], Step [49300/6235], Loss: 1188.4163\n",
      "Epoch [93/100], Step [49400/6235], Loss: 36.5541\n",
      "Epoch [93/100], Step [49500/6235], Loss: 18.1706\n",
      "Epoch [93/100], Step [49600/6235], Loss: 96.3186\n",
      "Epoch [93/100], Step [49700/6235], Loss: 9319.8604\n",
      "Epoch [93/100], Step [49800/6235], Loss: 1234.7576\n",
      "Epoch [94/100], Step [100/6235], Loss: 46.5491\n",
      "Epoch [94/100], Step [200/6235], Loss: 0.3343\n",
      "Epoch [94/100], Step [300/6235], Loss: 0.0585\n",
      "Epoch [94/100], Step [400/6235], Loss: 0.0177\n",
      "Epoch [94/100], Step [500/6235], Loss: 0.2916\n",
      "Epoch [94/100], Step [600/6235], Loss: 0.0516\n",
      "Epoch [94/100], Step [700/6235], Loss: 0.8190\n",
      "Epoch [94/100], Step [800/6235], Loss: 0.0760\n",
      "Epoch [94/100], Step [900/6235], Loss: 0.0659\n",
      "Epoch [94/100], Step [1000/6235], Loss: 0.0316\n",
      "Epoch [94/100], Step [1100/6235], Loss: 0.0770\n",
      "Epoch [94/100], Step [1200/6235], Loss: 0.2203\n",
      "Epoch [94/100], Step [1300/6235], Loss: 0.0109\n",
      "Epoch [94/100], Step [1400/6235], Loss: 0.0604\n",
      "Epoch [94/100], Step [1500/6235], Loss: 0.0210\n",
      "Epoch [94/100], Step [1600/6235], Loss: 0.2420\n",
      "Epoch [94/100], Step [1700/6235], Loss: 0.1382\n",
      "Epoch [94/100], Step [1800/6235], Loss: 0.2935\n",
      "Epoch [94/100], Step [1900/6235], Loss: 0.2842\n",
      "Epoch [94/100], Step [2000/6235], Loss: 2.2735\n",
      "Epoch [94/100], Step [2100/6235], Loss: 1.9529\n",
      "Epoch [94/100], Step [2200/6235], Loss: 6.0390\n",
      "Epoch [94/100], Step [2300/6235], Loss: 0.3401\n",
      "Epoch [94/100], Step [2400/6235], Loss: 0.7869\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Step [2500/6235], Loss: 26.3221\n",
      "Epoch [94/100], Step [2600/6235], Loss: 13.5331\n",
      "Epoch [94/100], Step [2700/6235], Loss: 5.1615\n",
      "Epoch [94/100], Step [2800/6235], Loss: 76.4324\n",
      "Epoch [94/100], Step [2900/6235], Loss: 17.9059\n",
      "Epoch [94/100], Step [3000/6235], Loss: 1.3564\n",
      "Epoch [94/100], Step [3100/6235], Loss: 64.8252\n",
      "Epoch [94/100], Step [3200/6235], Loss: 65.3376\n",
      "Epoch [94/100], Step [3300/6235], Loss: 10.0417\n",
      "Epoch [94/100], Step [3400/6235], Loss: 1.8468\n",
      "Epoch [94/100], Step [3500/6235], Loss: 43.1488\n",
      "Epoch [94/100], Step [3600/6235], Loss: 5.9771\n",
      "Epoch [94/100], Step [3700/6235], Loss: 0.0252\n",
      "Epoch [94/100], Step [3800/6235], Loss: 0.0536\n",
      "Epoch [94/100], Step [3900/6235], Loss: 0.1283\n",
      "Epoch [94/100], Step [4000/6235], Loss: 0.0497\n",
      "Epoch [94/100], Step [4100/6235], Loss: 8.2612\n",
      "Epoch [94/100], Step [4200/6235], Loss: 1.2097\n",
      "Epoch [94/100], Step [4300/6235], Loss: 6.7014\n",
      "Epoch [94/100], Step [4400/6235], Loss: 1.7310\n",
      "Epoch [94/100], Step [4500/6235], Loss: 40.1870\n",
      "Epoch [94/100], Step [4600/6235], Loss: 0.5596\n",
      "Epoch [94/100], Step [4700/6235], Loss: 0.1844\n",
      "Epoch [94/100], Step [4800/6235], Loss: 10.7434\n",
      "Epoch [94/100], Step [4900/6235], Loss: 0.2318\n",
      "Epoch [94/100], Step [5000/6235], Loss: 0.1023\n",
      "Epoch [94/100], Step [5100/6235], Loss: 0.6192\n",
      "Epoch [94/100], Step [5200/6235], Loss: 1.0295\n",
      "Epoch [94/100], Step [5300/6235], Loss: 41.0374\n",
      "Epoch [94/100], Step [5400/6235], Loss: 1.5960\n",
      "Epoch [94/100], Step [5500/6235], Loss: 0.1086\n",
      "Epoch [94/100], Step [5600/6235], Loss: 0.3094\n",
      "Epoch [94/100], Step [5700/6235], Loss: 0.0503\n",
      "Epoch [94/100], Step [5800/6235], Loss: 0.2828\n",
      "Epoch [94/100], Step [5900/6235], Loss: 0.1162\n",
      "Epoch [94/100], Step [6000/6235], Loss: 3.4727\n",
      "Epoch [94/100], Step [6100/6235], Loss: 0.0447\n",
      "Epoch [94/100], Step [6200/6235], Loss: 3.2885\n",
      "Epoch [94/100], Step [6300/6235], Loss: 0.6241\n",
      "Epoch [94/100], Step [6400/6235], Loss: 0.0557\n",
      "Epoch [94/100], Step [6500/6235], Loss: 5.6972\n",
      "Epoch [94/100], Step [6600/6235], Loss: 7.8182\n",
      "Epoch [94/100], Step [6700/6235], Loss: 2.8831\n",
      "Epoch [94/100], Step [6800/6235], Loss: 0.3603\n",
      "Epoch [94/100], Step [6900/6235], Loss: 0.2795\n",
      "Epoch [94/100], Step [7000/6235], Loss: 0.0219\n",
      "Epoch [94/100], Step [7100/6235], Loss: 0.1865\n",
      "Epoch [94/100], Step [7200/6235], Loss: 0.2495\n",
      "Epoch [94/100], Step [7300/6235], Loss: 5.3616\n",
      "Epoch [94/100], Step [7400/6235], Loss: 0.2274\n",
      "Epoch [94/100], Step [7500/6235], Loss: 0.1876\n",
      "Epoch [94/100], Step [7600/6235], Loss: 0.5958\n",
      "Epoch [94/100], Step [7700/6235], Loss: 20.0352\n",
      "Epoch [94/100], Step [7800/6235], Loss: 6.2426\n",
      "Epoch [94/100], Step [7900/6235], Loss: 2.5781\n",
      "Epoch [94/100], Step [8000/6235], Loss: 0.2781\n",
      "Epoch [94/100], Step [8100/6235], Loss: 4.5419\n",
      "Epoch [94/100], Step [8200/6235], Loss: 17.3583\n",
      "Epoch [94/100], Step [8300/6235], Loss: 61.6476\n",
      "Epoch [94/100], Step [8400/6235], Loss: 103.5181\n",
      "Epoch [94/100], Step [8500/6235], Loss: 24.9854\n",
      "Epoch [94/100], Step [8600/6235], Loss: 88.0824\n",
      "Epoch [94/100], Step [8700/6235], Loss: 104.7509\n",
      "Epoch [94/100], Step [8800/6235], Loss: 491.7968\n",
      "Epoch [94/100], Step [8900/6235], Loss: 1.6317\n",
      "Epoch [94/100], Step [9000/6235], Loss: 376.4251\n",
      "Epoch [94/100], Step [9100/6235], Loss: 1626.1622\n",
      "Epoch [94/100], Step [9200/6235], Loss: 4624.1816\n",
      "Epoch [94/100], Step [9300/6235], Loss: 9.0627\n",
      "Epoch [94/100], Step [9400/6235], Loss: 104.9294\n",
      "Epoch [94/100], Step [9500/6235], Loss: 918.5975\n",
      "Epoch [94/100], Step [9600/6235], Loss: 801.2776\n",
      "Epoch [94/100], Step [9700/6235], Loss: 2.0443\n",
      "Epoch [94/100], Step [9800/6235], Loss: 78.9977\n",
      "Epoch [94/100], Step [9900/6235], Loss: 32.2547\n",
      "Epoch [94/100], Step [10000/6235], Loss: 600.6785\n",
      "Epoch [94/100], Step [10100/6235], Loss: 69.6822\n",
      "Epoch [94/100], Step [10200/6235], Loss: 580.6795\n",
      "Epoch [94/100], Step [10300/6235], Loss: 2.6609\n",
      "Epoch [94/100], Step [10400/6235], Loss: 11.3402\n",
      "Epoch [94/100], Step [10500/6235], Loss: 138.3180\n",
      "Epoch [94/100], Step [10600/6235], Loss: 753.0164\n",
      "Epoch [94/100], Step [10700/6235], Loss: 34.0705\n",
      "Epoch [94/100], Step [10800/6235], Loss: 39.4207\n",
      "Epoch [94/100], Step [10900/6235], Loss: 157.8145\n",
      "Epoch [94/100], Step [11000/6235], Loss: 293.1546\n",
      "Epoch [94/100], Step [11100/6235], Loss: 8.9297\n",
      "Epoch [94/100], Step [11200/6235], Loss: 1.0074\n",
      "Epoch [94/100], Step [11300/6235], Loss: 101.5887\n",
      "Epoch [94/100], Step [11400/6235], Loss: 51.3967\n",
      "Epoch [94/100], Step [11500/6235], Loss: 9.8261\n",
      "Epoch [94/100], Step [11600/6235], Loss: 8.7991\n",
      "Epoch [94/100], Step [11700/6235], Loss: 55.8165\n",
      "Epoch [94/100], Step [11800/6235], Loss: 22.6288\n",
      "Epoch [94/100], Step [11900/6235], Loss: 16.8740\n",
      "Epoch [94/100], Step [12000/6235], Loss: 580.5647\n",
      "Epoch [94/100], Step [12100/6235], Loss: 310.1419\n",
      "Epoch [94/100], Step [12200/6235], Loss: 41.6292\n",
      "Epoch [94/100], Step [12300/6235], Loss: 2.1399\n",
      "Epoch [94/100], Step [12400/6235], Loss: 404.1415\n",
      "Epoch [94/100], Step [12500/6235], Loss: 258.4250\n",
      "Epoch [94/100], Step [12600/6235], Loss: 8.8384\n",
      "Epoch [94/100], Step [12700/6235], Loss: 1.7736\n",
      "Epoch [94/100], Step [12800/6235], Loss: 19.0920\n",
      "Epoch [94/100], Step [12900/6235], Loss: 28.7568\n",
      "Epoch [94/100], Step [13000/6235], Loss: 0.2092\n",
      "Epoch [94/100], Step [13100/6235], Loss: 61.8867\n",
      "Epoch [94/100], Step [13200/6235], Loss: 11.5465\n",
      "Epoch [94/100], Step [13300/6235], Loss: 19.1268\n",
      "Epoch [94/100], Step [13400/6235], Loss: 137.2050\n",
      "Epoch [94/100], Step [13500/6235], Loss: 0.9358\n",
      "Epoch [94/100], Step [13600/6235], Loss: 28.5216\n",
      "Epoch [94/100], Step [13700/6235], Loss: 199.3468\n",
      "Epoch [94/100], Step [13800/6235], Loss: 89.1918\n",
      "Epoch [94/100], Step [13900/6235], Loss: 13.0726\n",
      "Epoch [94/100], Step [14000/6235], Loss: 0.4120\n",
      "Epoch [94/100], Step [14100/6235], Loss: 72.3968\n",
      "Epoch [94/100], Step [14200/6235], Loss: 2.3524\n",
      "Epoch [94/100], Step [14300/6235], Loss: 12.5765\n",
      "Epoch [94/100], Step [14400/6235], Loss: 20.0124\n",
      "Epoch [94/100], Step [14500/6235], Loss: 16.0908\n",
      "Epoch [94/100], Step [14600/6235], Loss: 2.2098\n",
      "Epoch [94/100], Step [14700/6235], Loss: 10.1946\n",
      "Epoch [94/100], Step [14800/6235], Loss: 15.9651\n",
      "Epoch [94/100], Step [14900/6235], Loss: 0.6725\n",
      "Epoch [94/100], Step [15000/6235], Loss: 0.2253\n",
      "Epoch [94/100], Step [15100/6235], Loss: 0.0378\n",
      "Epoch [94/100], Step [15200/6235], Loss: 61.5282\n",
      "Epoch [94/100], Step [15300/6235], Loss: 2.3291\n",
      "Epoch [94/100], Step [15400/6235], Loss: 92.4223\n",
      "Epoch [94/100], Step [15500/6235], Loss: 5.4086\n",
      "Epoch [94/100], Step [15600/6235], Loss: 211.0328\n",
      "Epoch [94/100], Step [15700/6235], Loss: 67.1767\n",
      "Epoch [94/100], Step [15800/6235], Loss: 7.1179\n",
      "Epoch [94/100], Step [15900/6235], Loss: 1.4688\n",
      "Epoch [94/100], Step [16000/6235], Loss: 67.5427\n",
      "Epoch [94/100], Step [16100/6235], Loss: 3.0626\n",
      "Epoch [94/100], Step [16200/6235], Loss: 0.3353\n",
      "Epoch [94/100], Step [16300/6235], Loss: 8.4386\n",
      "Epoch [94/100], Step [16400/6235], Loss: 21.0730\n",
      "Epoch [94/100], Step [16500/6235], Loss: 397.8427\n",
      "Epoch [94/100], Step [16600/6235], Loss: 37.1191\n",
      "Epoch [94/100], Step [16700/6235], Loss: 0.3560\n",
      "Epoch [94/100], Step [16800/6235], Loss: 13.5519\n",
      "Epoch [94/100], Step [16900/6235], Loss: 0.2732\n",
      "Epoch [94/100], Step [17000/6235], Loss: 0.2269\n",
      "Epoch [94/100], Step [17100/6235], Loss: 0.1325\n",
      "Epoch [94/100], Step [17200/6235], Loss: 250.6942\n",
      "Epoch [94/100], Step [17300/6235], Loss: 1.1459\n",
      "Epoch [94/100], Step [17400/6235], Loss: 40.5327\n",
      "Epoch [94/100], Step [17500/6235], Loss: 4.0378\n",
      "Epoch [94/100], Step [17600/6235], Loss: 2.6261\n",
      "Epoch [94/100], Step [17700/6235], Loss: 28.1623\n",
      "Epoch [94/100], Step [17800/6235], Loss: 28.0522\n",
      "Epoch [94/100], Step [17900/6235], Loss: 33.5095\n",
      "Epoch [94/100], Step [18000/6235], Loss: 3.4441\n",
      "Epoch [94/100], Step [18100/6235], Loss: 18.6308\n",
      "Epoch [94/100], Step [18200/6235], Loss: 0.5854\n",
      "Epoch [94/100], Step [18300/6235], Loss: 5.1326\n",
      "Epoch [94/100], Step [18400/6235], Loss: 5.2256\n",
      "Epoch [94/100], Step [18500/6235], Loss: 17.8555\n",
      "Epoch [94/100], Step [18600/6235], Loss: 0.8682\n",
      "Epoch [94/100], Step [18700/6235], Loss: 0.3914\n",
      "Epoch [94/100], Step [18800/6235], Loss: 118.3174\n",
      "Epoch [94/100], Step [18900/6235], Loss: 35.8340\n",
      "Epoch [94/100], Step [19000/6235], Loss: 4.4629\n",
      "Epoch [94/100], Step [19100/6235], Loss: 38.9466\n",
      "Epoch [94/100], Step [19200/6235], Loss: 0.9699\n",
      "Epoch [94/100], Step [19300/6235], Loss: 2.9234\n",
      "Epoch [94/100], Step [19400/6235], Loss: 191.2623\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Step [19500/6235], Loss: 140.0341\n",
      "Epoch [94/100], Step [19600/6235], Loss: 57.6828\n",
      "Epoch [94/100], Step [19700/6235], Loss: 6.7815\n",
      "Epoch [94/100], Step [19800/6235], Loss: 1.6619\n",
      "Epoch [94/100], Step [19900/6235], Loss: 0.1005\n",
      "Epoch [94/100], Step [20000/6235], Loss: 66.3382\n",
      "Epoch [94/100], Step [20100/6235], Loss: 1.0989\n",
      "Epoch [94/100], Step [20200/6235], Loss: 4.6046\n",
      "Epoch [94/100], Step [20300/6235], Loss: 2.3601\n",
      "Epoch [94/100], Step [20400/6235], Loss: 15.2392\n",
      "Epoch [94/100], Step [20500/6235], Loss: 48.2169\n",
      "Epoch [94/100], Step [20600/6235], Loss: 112.5809\n",
      "Epoch [94/100], Step [20700/6235], Loss: 2.6842\n",
      "Epoch [94/100], Step [20800/6235], Loss: 5.1001\n",
      "Epoch [94/100], Step [20900/6235], Loss: 2.3951\n",
      "Epoch [94/100], Step [21000/6235], Loss: 15.5125\n",
      "Epoch [94/100], Step [21100/6235], Loss: 6.6177\n",
      "Epoch [94/100], Step [21200/6235], Loss: 0.2784\n",
      "Epoch [94/100], Step [21300/6235], Loss: 0.1854\n",
      "Epoch [94/100], Step [21400/6235], Loss: 6.3096\n",
      "Epoch [94/100], Step [21500/6235], Loss: 2.7694\n",
      "Epoch [94/100], Step [21600/6235], Loss: 24.7902\n",
      "Epoch [94/100], Step [21700/6235], Loss: 0.2730\n",
      "Epoch [94/100], Step [21800/6235], Loss: 3.7434\n",
      "Epoch [94/100], Step [21900/6235], Loss: 1.2067\n",
      "Epoch [94/100], Step [22000/6235], Loss: 6.2157\n",
      "Epoch [94/100], Step [22100/6235], Loss: 1.4329\n",
      "Epoch [94/100], Step [22200/6235], Loss: 7.6010\n",
      "Epoch [94/100], Step [22300/6235], Loss: 0.5339\n",
      "Epoch [94/100], Step [22400/6235], Loss: 7.3232\n",
      "Epoch [94/100], Step [22500/6235], Loss: 181.6143\n",
      "Epoch [94/100], Step [22600/6235], Loss: 17.4875\n",
      "Epoch [94/100], Step [22700/6235], Loss: 2.4802\n",
      "Epoch [94/100], Step [22800/6235], Loss: 4.5497\n",
      "Epoch [94/100], Step [22900/6235], Loss: 1.4857\n",
      "Epoch [94/100], Step [23000/6235], Loss: 4.3724\n",
      "Epoch [94/100], Step [23100/6235], Loss: 8.6741\n",
      "Epoch [94/100], Step [23200/6235], Loss: 10.4695\n",
      "Epoch [94/100], Step [23300/6235], Loss: 19.3385\n",
      "Epoch [94/100], Step [23400/6235], Loss: 1.6221\n",
      "Epoch [94/100], Step [23500/6235], Loss: 0.1475\n",
      "Epoch [94/100], Step [23600/6235], Loss: 122.0110\n",
      "Epoch [94/100], Step [23700/6235], Loss: 5.3848\n",
      "Epoch [94/100], Step [23800/6235], Loss: 1.0649\n",
      "Epoch [94/100], Step [23900/6235], Loss: 5.8732\n",
      "Epoch [94/100], Step [24000/6235], Loss: 0.2804\n",
      "Epoch [94/100], Step [24100/6235], Loss: 0.2952\n",
      "Epoch [94/100], Step [24200/6235], Loss: 39.4044\n",
      "Epoch [94/100], Step [24300/6235], Loss: 0.9293\n",
      "Epoch [94/100], Step [24400/6235], Loss: 2.0711\n",
      "Epoch [94/100], Step [24500/6235], Loss: 0.6882\n",
      "Epoch [94/100], Step [24600/6235], Loss: 0.2130\n",
      "Epoch [94/100], Step [24700/6235], Loss: 0.2194\n",
      "Epoch [94/100], Step [24800/6235], Loss: 0.2318\n",
      "Epoch [94/100], Step [24900/6235], Loss: 10.9520\n",
      "Epoch [94/100], Step [25000/6235], Loss: 15.1496\n",
      "Epoch [94/100], Step [25100/6235], Loss: 6.5913\n",
      "Epoch [94/100], Step [25200/6235], Loss: 0.5247\n",
      "Epoch [94/100], Step [25300/6235], Loss: 0.6358\n",
      "Epoch [94/100], Step [25400/6235], Loss: 6.1504\n",
      "Epoch [94/100], Step [25500/6235], Loss: 7.5203\n",
      "Epoch [94/100], Step [25600/6235], Loss: 4.7134\n",
      "Epoch [94/100], Step [25700/6235], Loss: 0.3532\n",
      "Epoch [94/100], Step [25800/6235], Loss: 0.1699\n",
      "Epoch [94/100], Step [25900/6235], Loss: 8.5452\n",
      "Epoch [94/100], Step [26000/6235], Loss: 1.3834\n",
      "Epoch [94/100], Step [26100/6235], Loss: 0.6205\n",
      "Epoch [94/100], Step [26200/6235], Loss: 0.8592\n",
      "Epoch [94/100], Step [26300/6235], Loss: 3.8940\n",
      "Epoch [94/100], Step [26400/6235], Loss: 0.1004\n",
      "Epoch [94/100], Step [26500/6235], Loss: 0.0163\n",
      "Epoch [94/100], Step [26600/6235], Loss: 1.4872\n",
      "Epoch [94/100], Step [26700/6235], Loss: 0.3540\n",
      "Epoch [94/100], Step [26800/6235], Loss: 0.1548\n",
      "Epoch [94/100], Step [26900/6235], Loss: 0.0015\n",
      "Epoch [94/100], Step [27000/6235], Loss: 15.1092\n",
      "Epoch [94/100], Step [27100/6235], Loss: 0.0488\n",
      "Epoch [94/100], Step [27200/6235], Loss: 0.0238\n",
      "Epoch [94/100], Step [27300/6235], Loss: 0.2177\n",
      "Epoch [94/100], Step [27400/6235], Loss: 0.7634\n",
      "Epoch [94/100], Step [27500/6235], Loss: 10.1143\n",
      "Epoch [94/100], Step [27600/6235], Loss: 1.1051\n",
      "Epoch [94/100], Step [27700/6235], Loss: 0.8480\n",
      "Epoch [94/100], Step [27800/6235], Loss: 5.6278\n",
      "Epoch [94/100], Step [27900/6235], Loss: 3.0707\n",
      "Epoch [94/100], Step [28000/6235], Loss: 173.8808\n",
      "Epoch [94/100], Step [28100/6235], Loss: 3.2352\n",
      "Epoch [94/100], Step [28200/6235], Loss: 35.3484\n",
      "Epoch [94/100], Step [28300/6235], Loss: 2.6014\n",
      "Epoch [94/100], Step [28400/6235], Loss: 24.8174\n",
      "Epoch [94/100], Step [28500/6235], Loss: 4.4986\n",
      "Epoch [94/100], Step [28600/6235], Loss: 0.2238\n",
      "Epoch [94/100], Step [28700/6235], Loss: 5.2205\n",
      "Epoch [94/100], Step [28800/6235], Loss: 0.6580\n",
      "Epoch [94/100], Step [28900/6235], Loss: 66.7781\n",
      "Epoch [94/100], Step [29000/6235], Loss: 9.9437\n",
      "Epoch [94/100], Step [29100/6235], Loss: 0.4074\n",
      "Epoch [94/100], Step [29200/6235], Loss: 2.4072\n",
      "Epoch [94/100], Step [29300/6235], Loss: 9.4632\n",
      "Epoch [94/100], Step [29400/6235], Loss: 0.0956\n",
      "Epoch [94/100], Step [29500/6235], Loss: 1.2137\n",
      "Epoch [94/100], Step [29600/6235], Loss: 0.3108\n",
      "Epoch [94/100], Step [29700/6235], Loss: 1.9951\n",
      "Epoch [94/100], Step [29800/6235], Loss: 1.3452\n",
      "Epoch [94/100], Step [29900/6235], Loss: 1.4506\n",
      "Epoch [94/100], Step [30000/6235], Loss: 7.1845\n",
      "Epoch [94/100], Step [30100/6235], Loss: 10.5412\n",
      "Epoch [94/100], Step [30200/6235], Loss: 1.4715\n",
      "Epoch [94/100], Step [30300/6235], Loss: 0.0513\n",
      "Epoch [94/100], Step [30400/6235], Loss: 1.4871\n",
      "Epoch [94/100], Step [30500/6235], Loss: 2.7761\n",
      "Epoch [94/100], Step [30600/6235], Loss: 1.8632\n",
      "Epoch [94/100], Step [30700/6235], Loss: 1.1872\n",
      "Epoch [94/100], Step [30800/6235], Loss: 0.5620\n",
      "Epoch [94/100], Step [30900/6235], Loss: 3.0594\n",
      "Epoch [94/100], Step [31000/6235], Loss: 0.2951\n",
      "Epoch [94/100], Step [31100/6235], Loss: 0.0587\n",
      "Epoch [94/100], Step [31200/6235], Loss: 6.7023\n",
      "Epoch [94/100], Step [31300/6235], Loss: 1.3088\n",
      "Epoch [94/100], Step [31400/6235], Loss: 6.6535\n",
      "Epoch [94/100], Step [31500/6235], Loss: 0.6906\n",
      "Epoch [94/100], Step [31600/6235], Loss: 6.0771\n",
      "Epoch [94/100], Step [31700/6235], Loss: 24.1761\n",
      "Epoch [94/100], Step [31800/6235], Loss: 0.1521\n",
      "Epoch [94/100], Step [31900/6235], Loss: 16.9064\n",
      "Epoch [94/100], Step [32000/6235], Loss: 40.7692\n",
      "Epoch [94/100], Step [32100/6235], Loss: 1.8983\n",
      "Epoch [94/100], Step [32200/6235], Loss: 30.4113\n",
      "Epoch [94/100], Step [32300/6235], Loss: 0.1522\n",
      "Epoch [94/100], Step [32400/6235], Loss: 0.1783\n",
      "Epoch [94/100], Step [32500/6235], Loss: 20.6329\n",
      "Epoch [94/100], Step [32600/6235], Loss: 1.2270\n",
      "Epoch [94/100], Step [32700/6235], Loss: 65.7080\n",
      "Epoch [94/100], Step [32800/6235], Loss: 0.5683\n",
      "Epoch [94/100], Step [32900/6235], Loss: 4.1895\n",
      "Epoch [94/100], Step [33000/6235], Loss: 0.3599\n",
      "Epoch [94/100], Step [33100/6235], Loss: 0.7689\n",
      "Epoch [94/100], Step [33200/6235], Loss: 1.2806\n",
      "Epoch [94/100], Step [33300/6235], Loss: 1.3356\n",
      "Epoch [94/100], Step [33400/6235], Loss: 120.6850\n",
      "Epoch [94/100], Step [33500/6235], Loss: 2.3371\n",
      "Epoch [94/100], Step [33600/6235], Loss: 8.9244\n",
      "Epoch [94/100], Step [33700/6235], Loss: 13.8930\n",
      "Epoch [94/100], Step [33800/6235], Loss: 0.8189\n",
      "Epoch [94/100], Step [33900/6235], Loss: 28.8127\n",
      "Epoch [94/100], Step [34000/6235], Loss: 0.1032\n",
      "Epoch [94/100], Step [34100/6235], Loss: 0.6085\n",
      "Epoch [94/100], Step [34200/6235], Loss: 2.1739\n",
      "Epoch [94/100], Step [34300/6235], Loss: 3.6243\n",
      "Epoch [94/100], Step [34400/6235], Loss: 0.1851\n",
      "Epoch [94/100], Step [34500/6235], Loss: 14.7570\n",
      "Epoch [94/100], Step [34600/6235], Loss: 0.7504\n",
      "Epoch [94/100], Step [34700/6235], Loss: 26.3530\n",
      "Epoch [94/100], Step [34800/6235], Loss: 8.5611\n",
      "Epoch [94/100], Step [34900/6235], Loss: 65.5552\n",
      "Epoch [94/100], Step [35000/6235], Loss: 0.3093\n",
      "Epoch [94/100], Step [35100/6235], Loss: 0.7846\n",
      "Epoch [94/100], Step [35200/6235], Loss: 0.2905\n",
      "Epoch [94/100], Step [35300/6235], Loss: 3.0453\n",
      "Epoch [94/100], Step [35400/6235], Loss: 0.4330\n",
      "Epoch [94/100], Step [35500/6235], Loss: 0.9567\n",
      "Epoch [94/100], Step [35600/6235], Loss: 4.1418\n",
      "Epoch [94/100], Step [35700/6235], Loss: 4.8017\n",
      "Epoch [94/100], Step [35800/6235], Loss: 0.3980\n",
      "Epoch [94/100], Step [35900/6235], Loss: 3.8742\n",
      "Epoch [94/100], Step [36000/6235], Loss: 0.0663\n",
      "Epoch [94/100], Step [36100/6235], Loss: 0.0278\n",
      "Epoch [94/100], Step [36200/6235], Loss: 27.0832\n",
      "Epoch [94/100], Step [36300/6235], Loss: 0.1853\n",
      "Epoch [94/100], Step [36400/6235], Loss: 2.8821\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [94/100], Step [36500/6235], Loss: 8.0097\n",
      "Epoch [94/100], Step [36600/6235], Loss: 0.1152\n",
      "Epoch [94/100], Step [36700/6235], Loss: 0.5659\n",
      "Epoch [94/100], Step [36800/6235], Loss: 7.8997\n",
      "Epoch [94/100], Step [36900/6235], Loss: 12.1644\n",
      "Epoch [94/100], Step [37000/6235], Loss: 0.8055\n",
      "Epoch [94/100], Step [37100/6235], Loss: 1.5890\n",
      "Epoch [94/100], Step [37200/6235], Loss: 0.0594\n",
      "Epoch [94/100], Step [37300/6235], Loss: 0.0316\n",
      "Epoch [94/100], Step [37400/6235], Loss: 0.1913\n",
      "Epoch [94/100], Step [37500/6235], Loss: 5.7027\n",
      "Epoch [94/100], Step [37600/6235], Loss: 12.0565\n",
      "Epoch [94/100], Step [37700/6235], Loss: 2.0159\n",
      "Epoch [94/100], Step [37800/6235], Loss: 3.3426\n",
      "Epoch [94/100], Step [37900/6235], Loss: 6.9612\n",
      "Epoch [94/100], Step [38000/6235], Loss: 0.6302\n",
      "Epoch [94/100], Step [38100/6235], Loss: 4.4499\n",
      "Epoch [94/100], Step [38200/6235], Loss: 1.5074\n",
      "Epoch [94/100], Step [38300/6235], Loss: 0.6658\n",
      "Epoch [94/100], Step [38400/6235], Loss: 0.1201\n",
      "Epoch [94/100], Step [38500/6235], Loss: 2.2702\n",
      "Epoch [94/100], Step [38600/6235], Loss: 0.2088\n",
      "Epoch [94/100], Step [38700/6235], Loss: 0.0921\n",
      "Epoch [94/100], Step [38800/6235], Loss: 0.1817\n",
      "Epoch [94/100], Step [38900/6235], Loss: 0.6607\n",
      "Epoch [94/100], Step [39000/6235], Loss: 14.6883\n",
      "Epoch [94/100], Step [39100/6235], Loss: 20.8329\n",
      "Epoch [94/100], Step [39200/6235], Loss: 0.4582\n",
      "Epoch [94/100], Step [39300/6235], Loss: 86.8030\n",
      "Epoch [94/100], Step [39400/6235], Loss: 78.4453\n",
      "Epoch [94/100], Step [39500/6235], Loss: 368.5773\n",
      "Epoch [94/100], Step [39600/6235], Loss: 13.4534\n",
      "Epoch [94/100], Step [39700/6235], Loss: 73.9940\n",
      "Epoch [94/100], Step [39800/6235], Loss: 160.0091\n",
      "Epoch [94/100], Step [39900/6235], Loss: 16.2116\n",
      "Epoch [94/100], Step [40000/6235], Loss: 3.0143\n",
      "Epoch [94/100], Step [40100/6235], Loss: 10.3383\n",
      "Epoch [94/100], Step [40200/6235], Loss: 9.5370\n",
      "Epoch [94/100], Step [40300/6235], Loss: 2.5575\n",
      "Epoch [94/100], Step [40400/6235], Loss: 0.1329\n",
      "Epoch [94/100], Step [40500/6235], Loss: 3.0832\n",
      "Epoch [94/100], Step [40600/6235], Loss: 0.2771\n",
      "Epoch [94/100], Step [40700/6235], Loss: 6.2258\n",
      "Epoch [94/100], Step [40800/6235], Loss: 0.6042\n",
      "Epoch [94/100], Step [40900/6235], Loss: 1.1008\n",
      "Epoch [94/100], Step [41000/6235], Loss: 46.3955\n",
      "Epoch [94/100], Step [41100/6235], Loss: 3.6450\n",
      "Epoch [94/100], Step [41200/6235], Loss: 21.4810\n",
      "Epoch [94/100], Step [41300/6235], Loss: 2.9339\n",
      "Epoch [94/100], Step [41400/6235], Loss: 0.2722\n",
      "Epoch [94/100], Step [41500/6235], Loss: 10.7115\n",
      "Epoch [94/100], Step [41600/6235], Loss: 2.1171\n",
      "Epoch [94/100], Step [41700/6235], Loss: 0.1681\n",
      "Epoch [94/100], Step [41800/6235], Loss: 0.6064\n",
      "Epoch [94/100], Step [41900/6235], Loss: 4.2116\n",
      "Epoch [94/100], Step [42000/6235], Loss: 4.3447\n",
      "Epoch [94/100], Step [42100/6235], Loss: 12.0836\n",
      "Epoch [94/100], Step [42200/6235], Loss: 75.7021\n",
      "Epoch [94/100], Step [42300/6235], Loss: 0.1418\n",
      "Epoch [94/100], Step [42400/6235], Loss: 2.7810\n",
      "Epoch [94/100], Step [42500/6235], Loss: 1.3328\n",
      "Epoch [94/100], Step [42600/6235], Loss: 0.4755\n",
      "Epoch [94/100], Step [42700/6235], Loss: 0.1688\n",
      "Epoch [94/100], Step [42800/6235], Loss: 13.5386\n",
      "Epoch [94/100], Step [42900/6235], Loss: 0.5120\n",
      "Epoch [94/100], Step [43000/6235], Loss: 0.3150\n",
      "Epoch [94/100], Step [43100/6235], Loss: 0.0446\n",
      "Epoch [94/100], Step [43200/6235], Loss: 0.3694\n",
      "Epoch [94/100], Step [43300/6235], Loss: 5.2316\n",
      "Epoch [94/100], Step [43400/6235], Loss: 4.9424\n",
      "Epoch [94/100], Step [43500/6235], Loss: 11.4611\n",
      "Epoch [94/100], Step [43600/6235], Loss: 2.0402\n",
      "Epoch [94/100], Step [43700/6235], Loss: 49.6861\n",
      "Epoch [94/100], Step [43800/6235], Loss: 0.3097\n",
      "Epoch [94/100], Step [43900/6235], Loss: 4.6415\n",
      "Epoch [94/100], Step [44000/6235], Loss: 84.3450\n",
      "Epoch [94/100], Step [44100/6235], Loss: 1.3814\n",
      "Epoch [94/100], Step [44200/6235], Loss: 1.7877\n",
      "Epoch [94/100], Step [44300/6235], Loss: 30.6440\n",
      "Epoch [94/100], Step [44400/6235], Loss: 3.9071\n",
      "Epoch [94/100], Step [44500/6235], Loss: 1.1826\n",
      "Epoch [94/100], Step [44600/6235], Loss: 26.3183\n",
      "Epoch [94/100], Step [44700/6235], Loss: 5.9750\n",
      "Epoch [94/100], Step [44800/6235], Loss: 3.2561\n",
      "Epoch [94/100], Step [44900/6235], Loss: 10.9681\n",
      "Epoch [94/100], Step [45000/6235], Loss: 6.3725\n",
      "Epoch [94/100], Step [45100/6235], Loss: 76.2222\n",
      "Epoch [94/100], Step [45200/6235], Loss: 3.8201\n",
      "Epoch [94/100], Step [45300/6235], Loss: 25.0757\n",
      "Epoch [94/100], Step [45400/6235], Loss: 6.9120\n",
      "Epoch [94/100], Step [45500/6235], Loss: 1.9529\n",
      "Epoch [94/100], Step [45600/6235], Loss: 0.4336\n",
      "Epoch [94/100], Step [45700/6235], Loss: 88.5796\n",
      "Epoch [94/100], Step [45800/6235], Loss: 446.4567\n",
      "Epoch [94/100], Step [45900/6235], Loss: 47.6452\n",
      "Epoch [94/100], Step [46000/6235], Loss: 17.9727\n",
      "Epoch [94/100], Step [46100/6235], Loss: 14.1182\n",
      "Epoch [94/100], Step [46200/6235], Loss: 64.8538\n",
      "Epoch [94/100], Step [46300/6235], Loss: 1.6944\n",
      "Epoch [94/100], Step [46400/6235], Loss: 16.3302\n",
      "Epoch [94/100], Step [46500/6235], Loss: 9.7764\n",
      "Epoch [94/100], Step [46600/6235], Loss: 21.5946\n",
      "Epoch [94/100], Step [46700/6235], Loss: 26.4388\n",
      "Epoch [94/100], Step [46800/6235], Loss: 1.5541\n",
      "Epoch [94/100], Step [46900/6235], Loss: 4.6503\n",
      "Epoch [94/100], Step [47000/6235], Loss: 6.1876\n",
      "Epoch [94/100], Step [47100/6235], Loss: 0.8942\n",
      "Epoch [94/100], Step [47200/6235], Loss: 18.0289\n",
      "Epoch [94/100], Step [47300/6235], Loss: 1.1846\n",
      "Epoch [94/100], Step [47400/6235], Loss: 35.1781\n",
      "Epoch [94/100], Step [47500/6235], Loss: 7.2701\n",
      "Epoch [94/100], Step [47600/6235], Loss: 17.0419\n",
      "Epoch [94/100], Step [47700/6235], Loss: 32.2212\n",
      "Epoch [94/100], Step [47800/6235], Loss: 19.8318\n",
      "Epoch [94/100], Step [47900/6235], Loss: 20.0613\n",
      "Epoch [94/100], Step [48000/6235], Loss: 0.7866\n",
      "Epoch [94/100], Step [48100/6235], Loss: 4.3679\n",
      "Epoch [94/100], Step [48200/6235], Loss: 7.8158\n",
      "Epoch [94/100], Step [48300/6235], Loss: 391.8180\n",
      "Epoch [94/100], Step [48400/6235], Loss: 17.5281\n",
      "Epoch [94/100], Step [48500/6235], Loss: 29.9298\n",
      "Epoch [94/100], Step [48600/6235], Loss: 142.2437\n",
      "Epoch [94/100], Step [48700/6235], Loss: 2.7682\n",
      "Epoch [94/100], Step [48800/6235], Loss: 461.1241\n",
      "Epoch [94/100], Step [48900/6235], Loss: 275.2486\n",
      "Epoch [94/100], Step [49000/6235], Loss: 186.1900\n",
      "Epoch [94/100], Step [49100/6235], Loss: 1878.7272\n",
      "Epoch [94/100], Step [49200/6235], Loss: 623.8293\n",
      "Epoch [94/100], Step [49300/6235], Loss: 1220.5743\n",
      "Epoch [94/100], Step [49400/6235], Loss: 1.0447\n",
      "Epoch [94/100], Step [49500/6235], Loss: 16.1003\n",
      "Epoch [94/100], Step [49600/6235], Loss: 718.3325\n",
      "Epoch [94/100], Step [49700/6235], Loss: 761.8921\n",
      "Epoch [94/100], Step [49800/6235], Loss: 1500.8790\n",
      "Epoch [95/100], Step [100/6235], Loss: 12.9777\n",
      "Epoch [95/100], Step [200/6235], Loss: 1.2051\n",
      "Epoch [95/100], Step [300/6235], Loss: 0.0990\n",
      "Epoch [95/100], Step [400/6235], Loss: 0.0592\n",
      "Epoch [95/100], Step [500/6235], Loss: 92.0008\n",
      "Epoch [95/100], Step [600/6235], Loss: 0.4259\n",
      "Epoch [95/100], Step [700/6235], Loss: 1.8745\n",
      "Epoch [95/100], Step [800/6235], Loss: 0.2929\n",
      "Epoch [95/100], Step [900/6235], Loss: 1.0314\n",
      "Epoch [95/100], Step [1000/6235], Loss: 0.2965\n",
      "Epoch [95/100], Step [1100/6235], Loss: 2.5978\n",
      "Epoch [95/100], Step [1200/6235], Loss: 0.5696\n",
      "Epoch [95/100], Step [1300/6235], Loss: 0.2325\n",
      "Epoch [95/100], Step [1400/6235], Loss: 1.8592\n",
      "Epoch [95/100], Step [1500/6235], Loss: 0.0094\n",
      "Epoch [95/100], Step [1600/6235], Loss: 0.2938\n",
      "Epoch [95/100], Step [1700/6235], Loss: 0.0573\n",
      "Epoch [95/100], Step [1800/6235], Loss: 0.2048\n",
      "Epoch [95/100], Step [1900/6235], Loss: 0.5222\n",
      "Epoch [95/100], Step [2000/6235], Loss: 2.2308\n",
      "Epoch [95/100], Step [2100/6235], Loss: 2.4594\n",
      "Epoch [95/100], Step [2200/6235], Loss: 9.2309\n",
      "Epoch [95/100], Step [2300/6235], Loss: 12.3028\n",
      "Epoch [95/100], Step [2400/6235], Loss: 5.8057\n",
      "Epoch [95/100], Step [2500/6235], Loss: 40.8704\n",
      "Epoch [95/100], Step [2600/6235], Loss: 10.9771\n",
      "Epoch [95/100], Step [2700/6235], Loss: 13.3905\n",
      "Epoch [95/100], Step [2800/6235], Loss: 91.9473\n",
      "Epoch [95/100], Step [2900/6235], Loss: 7.2050\n",
      "Epoch [95/100], Step [3000/6235], Loss: 0.7230\n",
      "Epoch [95/100], Step [3100/6235], Loss: 64.2069\n",
      "Epoch [95/100], Step [3200/6235], Loss: 85.3689\n",
      "Epoch [95/100], Step [3300/6235], Loss: 2.1040\n",
      "Epoch [95/100], Step [3400/6235], Loss: 2.8869\n",
      "Epoch [95/100], Step [3500/6235], Loss: 29.9974\n",
      "Epoch [95/100], Step [3600/6235], Loss: 10.2176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Step [3700/6235], Loss: 0.9135\n",
      "Epoch [95/100], Step [3800/6235], Loss: 0.6042\n",
      "Epoch [95/100], Step [3900/6235], Loss: 1.7087\n",
      "Epoch [95/100], Step [4000/6235], Loss: 0.1188\n",
      "Epoch [95/100], Step [4100/6235], Loss: 4.8759\n",
      "Epoch [95/100], Step [4200/6235], Loss: 0.2821\n",
      "Epoch [95/100], Step [4300/6235], Loss: 9.9237\n",
      "Epoch [95/100], Step [4400/6235], Loss: 4.1829\n",
      "Epoch [95/100], Step [4500/6235], Loss: 53.2389\n",
      "Epoch [95/100], Step [4600/6235], Loss: 8.6078\n",
      "Epoch [95/100], Step [4700/6235], Loss: 1.2656\n",
      "Epoch [95/100], Step [4800/6235], Loss: 1.6015\n",
      "Epoch [95/100], Step [4900/6235], Loss: 0.0322\n",
      "Epoch [95/100], Step [5000/6235], Loss: 0.2752\n",
      "Epoch [95/100], Step [5100/6235], Loss: 2.5582\n",
      "Epoch [95/100], Step [5200/6235], Loss: 0.9810\n",
      "Epoch [95/100], Step [5300/6235], Loss: 32.9459\n",
      "Epoch [95/100], Step [5400/6235], Loss: 0.3115\n",
      "Epoch [95/100], Step [5500/6235], Loss: 0.3075\n",
      "Epoch [95/100], Step [5600/6235], Loss: 0.5327\n",
      "Epoch [95/100], Step [5700/6235], Loss: 2.0025\n",
      "Epoch [95/100], Step [5800/6235], Loss: 1.0280\n",
      "Epoch [95/100], Step [5900/6235], Loss: 0.0221\n",
      "Epoch [95/100], Step [6000/6235], Loss: 0.3304\n",
      "Epoch [95/100], Step [6100/6235], Loss: 0.3155\n",
      "Epoch [95/100], Step [6200/6235], Loss: 0.6194\n",
      "Epoch [95/100], Step [6300/6235], Loss: 1.0731\n",
      "Epoch [95/100], Step [6400/6235], Loss: 0.0882\n",
      "Epoch [95/100], Step [6500/6235], Loss: 0.8425\n",
      "Epoch [95/100], Step [6600/6235], Loss: 1.8964\n",
      "Epoch [95/100], Step [6700/6235], Loss: 0.6460\n",
      "Epoch [95/100], Step [6800/6235], Loss: 0.6934\n",
      "Epoch [95/100], Step [6900/6235], Loss: 3.3183\n",
      "Epoch [95/100], Step [7000/6235], Loss: 0.5638\n",
      "Epoch [95/100], Step [7100/6235], Loss: 0.3181\n",
      "Epoch [95/100], Step [7200/6235], Loss: 0.2292\n",
      "Epoch [95/100], Step [7300/6235], Loss: 1.8775\n",
      "Epoch [95/100], Step [7400/6235], Loss: 0.0780\n",
      "Epoch [95/100], Step [7500/6235], Loss: 2.7018\n",
      "Epoch [95/100], Step [7600/6235], Loss: 19.9041\n",
      "Epoch [95/100], Step [7700/6235], Loss: 6.0273\n",
      "Epoch [95/100], Step [7800/6235], Loss: 14.6541\n",
      "Epoch [95/100], Step [7900/6235], Loss: 12.9312\n",
      "Epoch [95/100], Step [8000/6235], Loss: 0.4802\n",
      "Epoch [95/100], Step [8100/6235], Loss: 3.5486\n",
      "Epoch [95/100], Step [8200/6235], Loss: 22.8681\n",
      "Epoch [95/100], Step [8300/6235], Loss: 65.0853\n",
      "Epoch [95/100], Step [8400/6235], Loss: 40.0143\n",
      "Epoch [95/100], Step [8500/6235], Loss: 77.4311\n",
      "Epoch [95/100], Step [8600/6235], Loss: 14.2321\n",
      "Epoch [95/100], Step [8700/6235], Loss: 89.6806\n",
      "Epoch [95/100], Step [8800/6235], Loss: 531.4367\n",
      "Epoch [95/100], Step [8900/6235], Loss: 167.8600\n",
      "Epoch [95/100], Step [9000/6235], Loss: 525.1785\n",
      "Epoch [95/100], Step [9100/6235], Loss: 2700.4590\n",
      "Epoch [95/100], Step [9200/6235], Loss: 5982.0083\n",
      "Epoch [95/100], Step [9300/6235], Loss: 130.5139\n",
      "Epoch [95/100], Step [9400/6235], Loss: 45.3401\n",
      "Epoch [95/100], Step [9500/6235], Loss: 1898.6201\n",
      "Epoch [95/100], Step [9600/6235], Loss: 581.9833\n",
      "Epoch [95/100], Step [9700/6235], Loss: 6.2702\n",
      "Epoch [95/100], Step [9800/6235], Loss: 2792.9495\n",
      "Epoch [95/100], Step [9900/6235], Loss: 24.0281\n",
      "Epoch [95/100], Step [10000/6235], Loss: 70.2071\n",
      "Epoch [95/100], Step [10100/6235], Loss: 3.1140\n",
      "Epoch [95/100], Step [10200/6235], Loss: 900.9258\n",
      "Epoch [95/100], Step [10300/6235], Loss: 37.0204\n",
      "Epoch [95/100], Step [10400/6235], Loss: 10.9926\n",
      "Epoch [95/100], Step [10500/6235], Loss: 6.8952\n",
      "Epoch [95/100], Step [10600/6235], Loss: 107.3023\n",
      "Epoch [95/100], Step [10700/6235], Loss: 15.8740\n",
      "Epoch [95/100], Step [10800/6235], Loss: 110.6701\n",
      "Epoch [95/100], Step [10900/6235], Loss: 109.4964\n",
      "Epoch [95/100], Step [11000/6235], Loss: 290.7152\n",
      "Epoch [95/100], Step [11100/6235], Loss: 22.9046\n",
      "Epoch [95/100], Step [11200/6235], Loss: 2.4399\n",
      "Epoch [95/100], Step [11300/6235], Loss: 99.4342\n",
      "Epoch [95/100], Step [11400/6235], Loss: 37.9936\n",
      "Epoch [95/100], Step [11500/6235], Loss: 11.8944\n",
      "Epoch [95/100], Step [11600/6235], Loss: 9.1382\n",
      "Epoch [95/100], Step [11700/6235], Loss: 53.4785\n",
      "Epoch [95/100], Step [11800/6235], Loss: 400.7932\n",
      "Epoch [95/100], Step [11900/6235], Loss: 27.3920\n",
      "Epoch [95/100], Step [12000/6235], Loss: 649.8682\n",
      "Epoch [95/100], Step [12100/6235], Loss: 289.5602\n",
      "Epoch [95/100], Step [12200/6235], Loss: 35.1186\n",
      "Epoch [95/100], Step [12300/6235], Loss: 1.0855\n",
      "Epoch [95/100], Step [12400/6235], Loss: 194.4848\n",
      "Epoch [95/100], Step [12500/6235], Loss: 149.6165\n",
      "Epoch [95/100], Step [12600/6235], Loss: 0.4268\n",
      "Epoch [95/100], Step [12700/6235], Loss: 5.3961\n",
      "Epoch [95/100], Step [12800/6235], Loss: 13.6527\n",
      "Epoch [95/100], Step [12900/6235], Loss: 29.0178\n",
      "Epoch [95/100], Step [13000/6235], Loss: 0.0678\n",
      "Epoch [95/100], Step [13100/6235], Loss: 61.6501\n",
      "Epoch [95/100], Step [13200/6235], Loss: 8.3376\n",
      "Epoch [95/100], Step [13300/6235], Loss: 17.9856\n",
      "Epoch [95/100], Step [13400/6235], Loss: 189.1426\n",
      "Epoch [95/100], Step [13500/6235], Loss: 5.0807\n",
      "Epoch [95/100], Step [13600/6235], Loss: 6.9115\n",
      "Epoch [95/100], Step [13700/6235], Loss: 168.8119\n",
      "Epoch [95/100], Step [13800/6235], Loss: 74.0089\n",
      "Epoch [95/100], Step [13900/6235], Loss: 10.1269\n",
      "Epoch [95/100], Step [14000/6235], Loss: 5.8821\n",
      "Epoch [95/100], Step [14100/6235], Loss: 65.6414\n",
      "Epoch [95/100], Step [14200/6235], Loss: 18.6146\n",
      "Epoch [95/100], Step [14300/6235], Loss: 3.6317\n",
      "Epoch [95/100], Step [14400/6235], Loss: 31.3678\n",
      "Epoch [95/100], Step [14500/6235], Loss: 22.6721\n",
      "Epoch [95/100], Step [14600/6235], Loss: 3.1270\n",
      "Epoch [95/100], Step [14700/6235], Loss: 19.5744\n",
      "Epoch [95/100], Step [14800/6235], Loss: 26.0335\n",
      "Epoch [95/100], Step [14900/6235], Loss: 0.8207\n",
      "Epoch [95/100], Step [15000/6235], Loss: 0.8728\n",
      "Epoch [95/100], Step [15100/6235], Loss: 0.2532\n",
      "Epoch [95/100], Step [15200/6235], Loss: 35.5709\n",
      "Epoch [95/100], Step [15300/6235], Loss: 13.3458\n",
      "Epoch [95/100], Step [15400/6235], Loss: 77.4320\n",
      "Epoch [95/100], Step [15500/6235], Loss: 12.5271\n",
      "Epoch [95/100], Step [15600/6235], Loss: 179.2061\n",
      "Epoch [95/100], Step [15700/6235], Loss: 91.5160\n",
      "Epoch [95/100], Step [15800/6235], Loss: 9.2705\n",
      "Epoch [95/100], Step [15900/6235], Loss: 0.3258\n",
      "Epoch [95/100], Step [16000/6235], Loss: 169.6897\n",
      "Epoch [95/100], Step [16100/6235], Loss: 1.3506\n",
      "Epoch [95/100], Step [16200/6235], Loss: 0.8914\n",
      "Epoch [95/100], Step [16300/6235], Loss: 9.0005\n",
      "Epoch [95/100], Step [16400/6235], Loss: 25.6764\n",
      "Epoch [95/100], Step [16500/6235], Loss: 254.8440\n",
      "Epoch [95/100], Step [16600/6235], Loss: 29.8259\n",
      "Epoch [95/100], Step [16700/6235], Loss: 0.2692\n",
      "Epoch [95/100], Step [16800/6235], Loss: 15.2673\n",
      "Epoch [95/100], Step [16900/6235], Loss: 0.3412\n",
      "Epoch [95/100], Step [17000/6235], Loss: 0.1700\n",
      "Epoch [95/100], Step [17100/6235], Loss: 0.0398\n",
      "Epoch [95/100], Step [17200/6235], Loss: 270.0997\n",
      "Epoch [95/100], Step [17300/6235], Loss: 2.5606\n",
      "Epoch [95/100], Step [17400/6235], Loss: 29.6938\n",
      "Epoch [95/100], Step [17500/6235], Loss: 0.8625\n",
      "Epoch [95/100], Step [17600/6235], Loss: 2.8529\n",
      "Epoch [95/100], Step [17700/6235], Loss: 1.4390\n",
      "Epoch [95/100], Step [17800/6235], Loss: 15.9099\n",
      "Epoch [95/100], Step [17900/6235], Loss: 4.7214\n",
      "Epoch [95/100], Step [18000/6235], Loss: 1.0248\n",
      "Epoch [95/100], Step [18100/6235], Loss: 15.6193\n",
      "Epoch [95/100], Step [18200/6235], Loss: 0.3306\n",
      "Epoch [95/100], Step [18300/6235], Loss: 2.0390\n",
      "Epoch [95/100], Step [18400/6235], Loss: 1.6680\n",
      "Epoch [95/100], Step [18500/6235], Loss: 21.4679\n",
      "Epoch [95/100], Step [18600/6235], Loss: 3.4139\n",
      "Epoch [95/100], Step [18700/6235], Loss: 0.6698\n",
      "Epoch [95/100], Step [18800/6235], Loss: 166.5603\n",
      "Epoch [95/100], Step [18900/6235], Loss: 12.9914\n",
      "Epoch [95/100], Step [19000/6235], Loss: 1.3053\n",
      "Epoch [95/100], Step [19100/6235], Loss: 46.2087\n",
      "Epoch [95/100], Step [19200/6235], Loss: 1.2991\n",
      "Epoch [95/100], Step [19300/6235], Loss: 6.0219\n",
      "Epoch [95/100], Step [19400/6235], Loss: 1.9861\n",
      "Epoch [95/100], Step [19500/6235], Loss: 42.7021\n",
      "Epoch [95/100], Step [19600/6235], Loss: 61.0134\n",
      "Epoch [95/100], Step [19700/6235], Loss: 2.4273\n",
      "Epoch [95/100], Step [19800/6235], Loss: 7.1257\n",
      "Epoch [95/100], Step [19900/6235], Loss: 0.1423\n",
      "Epoch [95/100], Step [20000/6235], Loss: 66.8761\n",
      "Epoch [95/100], Step [20100/6235], Loss: 3.6593\n",
      "Epoch [95/100], Step [20200/6235], Loss: 5.6779\n",
      "Epoch [95/100], Step [20300/6235], Loss: 1.3465\n",
      "Epoch [95/100], Step [20400/6235], Loss: 9.0337\n",
      "Epoch [95/100], Step [20500/6235], Loss: 55.9153\n",
      "Epoch [95/100], Step [20600/6235], Loss: 151.5515\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Step [20700/6235], Loss: 8.5162\n",
      "Epoch [95/100], Step [20800/6235], Loss: 2.0609\n",
      "Epoch [95/100], Step [20900/6235], Loss: 7.8126\n",
      "Epoch [95/100], Step [21000/6235], Loss: 20.1062\n",
      "Epoch [95/100], Step [21100/6235], Loss: 6.8282\n",
      "Epoch [95/100], Step [21200/6235], Loss: 0.3056\n",
      "Epoch [95/100], Step [21300/6235], Loss: 0.1098\n",
      "Epoch [95/100], Step [21400/6235], Loss: 4.8404\n",
      "Epoch [95/100], Step [21500/6235], Loss: 0.5863\n",
      "Epoch [95/100], Step [21600/6235], Loss: 30.0328\n",
      "Epoch [95/100], Step [21700/6235], Loss: 0.2866\n",
      "Epoch [95/100], Step [21800/6235], Loss: 3.2329\n",
      "Epoch [95/100], Step [21900/6235], Loss: 1.5977\n",
      "Epoch [95/100], Step [22000/6235], Loss: 8.2390\n",
      "Epoch [95/100], Step [22100/6235], Loss: 0.4304\n",
      "Epoch [95/100], Step [22200/6235], Loss: 4.6541\n",
      "Epoch [95/100], Step [22300/6235], Loss: 0.2343\n",
      "Epoch [95/100], Step [22400/6235], Loss: 5.9997\n",
      "Epoch [95/100], Step [22500/6235], Loss: 138.6491\n",
      "Epoch [95/100], Step [22600/6235], Loss: 0.8214\n",
      "Epoch [95/100], Step [22700/6235], Loss: 0.0720\n",
      "Epoch [95/100], Step [22800/6235], Loss: 7.7866\n",
      "Epoch [95/100], Step [22900/6235], Loss: 3.7283\n",
      "Epoch [95/100], Step [23000/6235], Loss: 14.0042\n",
      "Epoch [95/100], Step [23100/6235], Loss: 8.5029\n",
      "Epoch [95/100], Step [23200/6235], Loss: 8.8688\n",
      "Epoch [95/100], Step [23300/6235], Loss: 19.9772\n",
      "Epoch [95/100], Step [23400/6235], Loss: 1.9928\n",
      "Epoch [95/100], Step [23500/6235], Loss: 0.0808\n",
      "Epoch [95/100], Step [23600/6235], Loss: 127.9356\n",
      "Epoch [95/100], Step [23700/6235], Loss: 3.5799\n",
      "Epoch [95/100], Step [23800/6235], Loss: 0.9975\n",
      "Epoch [95/100], Step [23900/6235], Loss: 4.8385\n",
      "Epoch [95/100], Step [24000/6235], Loss: 0.4618\n",
      "Epoch [95/100], Step [24100/6235], Loss: 0.2595\n",
      "Epoch [95/100], Step [24200/6235], Loss: 0.1098\n",
      "Epoch [95/100], Step [24300/6235], Loss: 1.1358\n",
      "Epoch [95/100], Step [24400/6235], Loss: 2.1113\n",
      "Epoch [95/100], Step [24500/6235], Loss: 0.4359\n",
      "Epoch [95/100], Step [24600/6235], Loss: 0.0678\n",
      "Epoch [95/100], Step [24700/6235], Loss: 0.2513\n",
      "Epoch [95/100], Step [24800/6235], Loss: 0.4271\n",
      "Epoch [95/100], Step [24900/6235], Loss: 15.0146\n",
      "Epoch [95/100], Step [25000/6235], Loss: 19.0447\n",
      "Epoch [95/100], Step [25100/6235], Loss: 6.3405\n",
      "Epoch [95/100], Step [25200/6235], Loss: 0.1561\n",
      "Epoch [95/100], Step [25300/6235], Loss: 0.7654\n",
      "Epoch [95/100], Step [25400/6235], Loss: 6.6361\n",
      "Epoch [95/100], Step [25500/6235], Loss: 8.1904\n",
      "Epoch [95/100], Step [25600/6235], Loss: 5.8296\n",
      "Epoch [95/100], Step [25700/6235], Loss: 0.3136\n",
      "Epoch [95/100], Step [25800/6235], Loss: 0.0455\n",
      "Epoch [95/100], Step [25900/6235], Loss: 7.3399\n",
      "Epoch [95/100], Step [26000/6235], Loss: 3.2520\n",
      "Epoch [95/100], Step [26100/6235], Loss: 0.0271\n",
      "Epoch [95/100], Step [26200/6235], Loss: 1.2409\n",
      "Epoch [95/100], Step [26300/6235], Loss: 3.0166\n",
      "Epoch [95/100], Step [26400/6235], Loss: 0.1396\n",
      "Epoch [95/100], Step [26500/6235], Loss: 0.0111\n",
      "Epoch [95/100], Step [26600/6235], Loss: 1.0778\n",
      "Epoch [95/100], Step [26700/6235], Loss: 0.2931\n",
      "Epoch [95/100], Step [26800/6235], Loss: 0.1530\n",
      "Epoch [95/100], Step [26900/6235], Loss: 0.0088\n",
      "Epoch [95/100], Step [27000/6235], Loss: 15.6244\n",
      "Epoch [95/100], Step [27100/6235], Loss: 0.0429\n",
      "Epoch [95/100], Step [27200/6235], Loss: 0.0196\n",
      "Epoch [95/100], Step [27300/6235], Loss: 0.1766\n",
      "Epoch [95/100], Step [27400/6235], Loss: 0.7218\n",
      "Epoch [95/100], Step [27500/6235], Loss: 2.8424\n",
      "Epoch [95/100], Step [27600/6235], Loss: 1.0402\n",
      "Epoch [95/100], Step [27700/6235], Loss: 0.9718\n",
      "Epoch [95/100], Step [27800/6235], Loss: 5.2058\n",
      "Epoch [95/100], Step [27900/6235], Loss: 0.7047\n",
      "Epoch [95/100], Step [28000/6235], Loss: 101.7520\n",
      "Epoch [95/100], Step [28100/6235], Loss: 1.2280\n",
      "Epoch [95/100], Step [28200/6235], Loss: 27.4820\n",
      "Epoch [95/100], Step [28300/6235], Loss: 3.0545\n",
      "Epoch [95/100], Step [28400/6235], Loss: 21.2511\n",
      "Epoch [95/100], Step [28500/6235], Loss: 4.4839\n",
      "Epoch [95/100], Step [28600/6235], Loss: 0.6653\n",
      "Epoch [95/100], Step [28700/6235], Loss: 4.5978\n",
      "Epoch [95/100], Step [28800/6235], Loss: 0.6606\n",
      "Epoch [95/100], Step [28900/6235], Loss: 62.7233\n",
      "Epoch [95/100], Step [29000/6235], Loss: 7.2835\n",
      "Epoch [95/100], Step [29100/6235], Loss: 0.2723\n",
      "Epoch [95/100], Step [29200/6235], Loss: 3.0233\n",
      "Epoch [95/100], Step [29300/6235], Loss: 4.1029\n",
      "Epoch [95/100], Step [29400/6235], Loss: 1.3307\n",
      "Epoch [95/100], Step [29500/6235], Loss: 7.2177\n",
      "Epoch [95/100], Step [29600/6235], Loss: 0.7987\n",
      "Epoch [95/100], Step [29700/6235], Loss: 1.9544\n",
      "Epoch [95/100], Step [29800/6235], Loss: 1.3377\n",
      "Epoch [95/100], Step [29900/6235], Loss: 1.4525\n",
      "Epoch [95/100], Step [30000/6235], Loss: 5.2452\n",
      "Epoch [95/100], Step [30100/6235], Loss: 8.5031\n",
      "Epoch [95/100], Step [30200/6235], Loss: 1.5388\n",
      "Epoch [95/100], Step [30300/6235], Loss: 0.0586\n",
      "Epoch [95/100], Step [30400/6235], Loss: 1.5753\n",
      "Epoch [95/100], Step [30500/6235], Loss: 2.1657\n",
      "Epoch [95/100], Step [30600/6235], Loss: 1.8320\n",
      "Epoch [95/100], Step [30700/6235], Loss: 1.3701\n",
      "Epoch [95/100], Step [30800/6235], Loss: 0.5595\n",
      "Epoch [95/100], Step [30900/6235], Loss: 2.8233\n",
      "Epoch [95/100], Step [31000/6235], Loss: 0.3150\n",
      "Epoch [95/100], Step [31100/6235], Loss: 0.0689\n",
      "Epoch [95/100], Step [31200/6235], Loss: 5.4458\n",
      "Epoch [95/100], Step [31300/6235], Loss: 0.9597\n",
      "Epoch [95/100], Step [31400/6235], Loss: 0.2680\n",
      "Epoch [95/100], Step [31500/6235], Loss: 0.6883\n",
      "Epoch [95/100], Step [31600/6235], Loss: 6.8225\n",
      "Epoch [95/100], Step [31700/6235], Loss: 27.6857\n",
      "Epoch [95/100], Step [31800/6235], Loss: 1.3042\n",
      "Epoch [95/100], Step [31900/6235], Loss: 14.9824\n",
      "Epoch [95/100], Step [32000/6235], Loss: 44.7497\n",
      "Epoch [95/100], Step [32100/6235], Loss: 1.1126\n",
      "Epoch [95/100], Step [32200/6235], Loss: 64.0689\n",
      "Epoch [95/100], Step [32300/6235], Loss: 0.2051\n",
      "Epoch [95/100], Step [32400/6235], Loss: 0.6097\n",
      "Epoch [95/100], Step [32500/6235], Loss: 22.4735\n",
      "Epoch [95/100], Step [32600/6235], Loss: 0.8578\n",
      "Epoch [95/100], Step [32700/6235], Loss: 75.2716\n",
      "Epoch [95/100], Step [32800/6235], Loss: 14.1387\n",
      "Epoch [95/100], Step [32900/6235], Loss: 0.2359\n",
      "Epoch [95/100], Step [33000/6235], Loss: 0.2030\n",
      "Epoch [95/100], Step [33100/6235], Loss: 0.7132\n",
      "Epoch [95/100], Step [33200/6235], Loss: 1.1553\n",
      "Epoch [95/100], Step [33300/6235], Loss: 1.7793\n",
      "Epoch [95/100], Step [33400/6235], Loss: 142.6014\n",
      "Epoch [95/100], Step [33500/6235], Loss: 2.4047\n",
      "Epoch [95/100], Step [33600/6235], Loss: 9.1917\n",
      "Epoch [95/100], Step [33700/6235], Loss: 10.6595\n",
      "Epoch [95/100], Step [33800/6235], Loss: 0.5555\n",
      "Epoch [95/100], Step [33900/6235], Loss: 26.5858\n",
      "Epoch [95/100], Step [34000/6235], Loss: 0.1032\n",
      "Epoch [95/100], Step [34100/6235], Loss: 0.5788\n",
      "Epoch [95/100], Step [34200/6235], Loss: 2.3294\n",
      "Epoch [95/100], Step [34300/6235], Loss: 3.9753\n",
      "Epoch [95/100], Step [34400/6235], Loss: 0.2171\n",
      "Epoch [95/100], Step [34500/6235], Loss: 20.9709\n",
      "Epoch [95/100], Step [34600/6235], Loss: 0.2033\n",
      "Epoch [95/100], Step [34700/6235], Loss: 6.1906\n",
      "Epoch [95/100], Step [34800/6235], Loss: 8.3518\n",
      "Epoch [95/100], Step [34900/6235], Loss: 55.5093\n",
      "Epoch [95/100], Step [35000/6235], Loss: 0.4087\n",
      "Epoch [95/100], Step [35100/6235], Loss: 0.5462\n",
      "Epoch [95/100], Step [35200/6235], Loss: 0.1985\n",
      "Epoch [95/100], Step [35300/6235], Loss: 2.8134\n",
      "Epoch [95/100], Step [35400/6235], Loss: 0.4337\n",
      "Epoch [95/100], Step [35500/6235], Loss: 1.2695\n",
      "Epoch [95/100], Step [35600/6235], Loss: 1.2612\n",
      "Epoch [95/100], Step [35700/6235], Loss: 5.3565\n",
      "Epoch [95/100], Step [35800/6235], Loss: 0.3489\n",
      "Epoch [95/100], Step [35900/6235], Loss: 0.2558\n",
      "Epoch [95/100], Step [36000/6235], Loss: 0.0798\n",
      "Epoch [95/100], Step [36100/6235], Loss: 0.0286\n",
      "Epoch [95/100], Step [36200/6235], Loss: 25.4783\n",
      "Epoch [95/100], Step [36300/6235], Loss: 0.4002\n",
      "Epoch [95/100], Step [36400/6235], Loss: 2.9420\n",
      "Epoch [95/100], Step [36500/6235], Loss: 8.0429\n",
      "Epoch [95/100], Step [36600/6235], Loss: 0.1131\n",
      "Epoch [95/100], Step [36700/6235], Loss: 0.5572\n",
      "Epoch [95/100], Step [36800/6235], Loss: 8.1505\n",
      "Epoch [95/100], Step [36900/6235], Loss: 11.3385\n",
      "Epoch [95/100], Step [37000/6235], Loss: 0.7840\n",
      "Epoch [95/100], Step [37100/6235], Loss: 1.5929\n",
      "Epoch [95/100], Step [37200/6235], Loss: 0.0601\n",
      "Epoch [95/100], Step [37300/6235], Loss: 0.0308\n",
      "Epoch [95/100], Step [37400/6235], Loss: 0.1897\n",
      "Epoch [95/100], Step [37500/6235], Loss: 5.5005\n",
      "Epoch [95/100], Step [37600/6235], Loss: 12.0114\n",
      "Epoch [95/100], Step [37700/6235], Loss: 1.6354\n",
      "Epoch [95/100], Step [37800/6235], Loss: 7.6207\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [95/100], Step [37900/6235], Loss: 6.6674\n",
      "Epoch [95/100], Step [38000/6235], Loss: 0.7819\n",
      "Epoch [95/100], Step [38100/6235], Loss: 4.7208\n",
      "Epoch [95/100], Step [38200/6235], Loss: 2.1350\n",
      "Epoch [95/100], Step [38300/6235], Loss: 0.1083\n",
      "Epoch [95/100], Step [38400/6235], Loss: 0.0908\n",
      "Epoch [95/100], Step [38500/6235], Loss: 2.2040\n",
      "Epoch [95/100], Step [38600/6235], Loss: 0.2898\n",
      "Epoch [95/100], Step [38700/6235], Loss: 0.0996\n",
      "Epoch [95/100], Step [38800/6235], Loss: 0.1751\n",
      "Epoch [95/100], Step [38900/6235], Loss: 19.3001\n",
      "Epoch [95/100], Step [39000/6235], Loss: 3.9491\n",
      "Epoch [95/100], Step [39100/6235], Loss: 19.1845\n",
      "Epoch [95/100], Step [39200/6235], Loss: 0.3312\n",
      "Epoch [95/100], Step [39300/6235], Loss: 7.0904\n",
      "Epoch [95/100], Step [39400/6235], Loss: 220.6366\n",
      "Epoch [95/100], Step [39500/6235], Loss: 309.1104\n",
      "Epoch [95/100], Step [39600/6235], Loss: 29.3686\n",
      "Epoch [95/100], Step [39700/6235], Loss: 422.3391\n",
      "Epoch [95/100], Step [39800/6235], Loss: 86.9320\n",
      "Epoch [95/100], Step [39900/6235], Loss: 16.2202\n",
      "Epoch [95/100], Step [40000/6235], Loss: 1.4254\n",
      "Epoch [95/100], Step [40100/6235], Loss: 7.7748\n",
      "Epoch [95/100], Step [40200/6235], Loss: 12.6328\n",
      "Epoch [95/100], Step [40300/6235], Loss: 0.6580\n",
      "Epoch [95/100], Step [40400/6235], Loss: 0.1785\n",
      "Epoch [95/100], Step [40500/6235], Loss: 3.1598\n",
      "Epoch [95/100], Step [40600/6235], Loss: 0.2459\n",
      "Epoch [95/100], Step [40700/6235], Loss: 5.8463\n",
      "Epoch [95/100], Step [40800/6235], Loss: 0.8242\n",
      "Epoch [95/100], Step [40900/6235], Loss: 1.2500\n",
      "Epoch [95/100], Step [41000/6235], Loss: 43.3270\n",
      "Epoch [95/100], Step [41100/6235], Loss: 9.6117\n",
      "Epoch [95/100], Step [41200/6235], Loss: 3.5258\n",
      "Epoch [95/100], Step [41300/6235], Loss: 2.6372\n",
      "Epoch [95/100], Step [41400/6235], Loss: 2.6262\n",
      "Epoch [95/100], Step [41500/6235], Loss: 10.5408\n",
      "Epoch [95/100], Step [41600/6235], Loss: 2.8192\n",
      "Epoch [95/100], Step [41700/6235], Loss: 0.1490\n",
      "Epoch [95/100], Step [41800/6235], Loss: 0.5501\n",
      "Epoch [95/100], Step [41900/6235], Loss: 4.2768\n",
      "Epoch [95/100], Step [42000/6235], Loss: 4.2790\n",
      "Epoch [95/100], Step [42100/6235], Loss: 12.1794\n",
      "Epoch [95/100], Step [42200/6235], Loss: 74.7099\n",
      "Epoch [95/100], Step [42300/6235], Loss: 0.1176\n",
      "Epoch [95/100], Step [42400/6235], Loss: 3.4883\n",
      "Epoch [95/100], Step [42500/6235], Loss: 1.5587\n",
      "Epoch [95/100], Step [42600/6235], Loss: 0.5929\n",
      "Epoch [95/100], Step [42700/6235], Loss: 0.2975\n",
      "Epoch [95/100], Step [42800/6235], Loss: 15.2108\n",
      "Epoch [95/100], Step [42900/6235], Loss: 0.2796\n",
      "Epoch [95/100], Step [43000/6235], Loss: 0.4001\n",
      "Epoch [95/100], Step [43100/6235], Loss: 0.0602\n",
      "Epoch [95/100], Step [43200/6235], Loss: 0.1482\n",
      "Epoch [95/100], Step [43300/6235], Loss: 4.4284\n",
      "Epoch [95/100], Step [43400/6235], Loss: 4.3429\n",
      "Epoch [95/100], Step [43500/6235], Loss: 11.9970\n",
      "Epoch [95/100], Step [43600/6235], Loss: 1.3190\n",
      "Epoch [95/100], Step [43700/6235], Loss: 47.2404\n",
      "Epoch [95/100], Step [43800/6235], Loss: 0.2625\n",
      "Epoch [95/100], Step [43900/6235], Loss: 3.5037\n",
      "Epoch [95/100], Step [44000/6235], Loss: 59.0321\n",
      "Epoch [95/100], Step [44100/6235], Loss: 0.7863\n",
      "Epoch [95/100], Step [44200/6235], Loss: 4.8897\n",
      "Epoch [95/100], Step [44300/6235], Loss: 14.2953\n",
      "Epoch [95/100], Step [44400/6235], Loss: 4.5013\n",
      "Epoch [95/100], Step [44500/6235], Loss: 0.6417\n",
      "Epoch [95/100], Step [44600/6235], Loss: 22.4666\n",
      "Epoch [95/100], Step [44700/6235], Loss: 1.3621\n",
      "Epoch [95/100], Step [44800/6235], Loss: 5.5247\n",
      "Epoch [95/100], Step [44900/6235], Loss: 12.2307\n",
      "Epoch [95/100], Step [45000/6235], Loss: 6.2587\n",
      "Epoch [95/100], Step [45100/6235], Loss: 68.7760\n",
      "Epoch [95/100], Step [45200/6235], Loss: 8.2952\n",
      "Epoch [95/100], Step [45300/6235], Loss: 23.4924\n",
      "Epoch [95/100], Step [45400/6235], Loss: 3.8410\n",
      "Epoch [95/100], Step [45500/6235], Loss: 3.2142\n",
      "Epoch [95/100], Step [45600/6235], Loss: 1.1808\n",
      "Epoch [95/100], Step [45700/6235], Loss: 111.1503\n",
      "Epoch [95/100], Step [45800/6235], Loss: 446.7823\n",
      "Epoch [95/100], Step [45900/6235], Loss: 47.3364\n",
      "Epoch [95/100], Step [46000/6235], Loss: 29.2296\n",
      "Epoch [95/100], Step [46100/6235], Loss: 27.9225\n",
      "Epoch [95/100], Step [46200/6235], Loss: 4.1833\n",
      "Epoch [95/100], Step [46300/6235], Loss: 62.4458\n",
      "Epoch [95/100], Step [46400/6235], Loss: 5.3840\n",
      "Epoch [95/100], Step [46500/6235], Loss: 74.6111\n",
      "Epoch [95/100], Step [46600/6235], Loss: 24.3810\n",
      "Epoch [95/100], Step [46700/6235], Loss: 27.6580\n",
      "Epoch [95/100], Step [46800/6235], Loss: 13.3545\n",
      "Epoch [95/100], Step [46900/6235], Loss: 4.9579\n",
      "Epoch [95/100], Step [47000/6235], Loss: 5.5509\n",
      "Epoch [95/100], Step [47100/6235], Loss: 5.8140\n",
      "Epoch [95/100], Step [47200/6235], Loss: 75.2238\n",
      "Epoch [95/100], Step [47300/6235], Loss: 0.7305\n",
      "Epoch [95/100], Step [47400/6235], Loss: 194.9560\n",
      "Epoch [95/100], Step [47500/6235], Loss: 3.2991\n",
      "Epoch [95/100], Step [47600/6235], Loss: 1.7198\n",
      "Epoch [95/100], Step [47700/6235], Loss: 4.4268\n",
      "Epoch [95/100], Step [47800/6235], Loss: 3.7143\n",
      "Epoch [95/100], Step [47900/6235], Loss: 17.3084\n",
      "Epoch [95/100], Step [48000/6235], Loss: 98.9847\n",
      "Epoch [95/100], Step [48100/6235], Loss: 4.2920\n",
      "Epoch [95/100], Step [48200/6235], Loss: 11.9448\n",
      "Epoch [95/100], Step [48300/6235], Loss: 203.6185\n",
      "Epoch [95/100], Step [48400/6235], Loss: 22.0809\n",
      "Epoch [95/100], Step [48500/6235], Loss: 13.5277\n",
      "Epoch [95/100], Step [48600/6235], Loss: 163.5883\n",
      "Epoch [95/100], Step [48700/6235], Loss: 31.3757\n",
      "Epoch [95/100], Step [48800/6235], Loss: 490.9693\n",
      "Epoch [95/100], Step [48900/6235], Loss: 19.6451\n",
      "Epoch [95/100], Step [49000/6235], Loss: 274.0873\n",
      "Epoch [95/100], Step [49100/6235], Loss: 982.4903\n",
      "Epoch [95/100], Step [49200/6235], Loss: 816.1163\n",
      "Epoch [95/100], Step [49300/6235], Loss: 1230.6729\n",
      "Epoch [95/100], Step [49400/6235], Loss: 5.9921\n",
      "Epoch [95/100], Step [49500/6235], Loss: 13.2764\n",
      "Epoch [95/100], Step [49600/6235], Loss: 450.2460\n",
      "Epoch [95/100], Step [49700/6235], Loss: 7309.6318\n",
      "Epoch [95/100], Step [49800/6235], Loss: 901.0165\n",
      "Epoch [96/100], Step [100/6235], Loss: 7.6086\n",
      "Epoch [96/100], Step [200/6235], Loss: 0.1610\n",
      "Epoch [96/100], Step [300/6235], Loss: 0.0174\n",
      "Epoch [96/100], Step [400/6235], Loss: 0.0331\n",
      "Epoch [96/100], Step [500/6235], Loss: 36.7104\n",
      "Epoch [96/100], Step [600/6235], Loss: 0.0975\n",
      "Epoch [96/100], Step [700/6235], Loss: 0.3962\n",
      "Epoch [96/100], Step [800/6235], Loss: 0.1289\n",
      "Epoch [96/100], Step [900/6235], Loss: 0.3248\n",
      "Epoch [96/100], Step [1000/6235], Loss: 0.1628\n",
      "Epoch [96/100], Step [1100/6235], Loss: 1.2582\n",
      "Epoch [96/100], Step [1200/6235], Loss: 0.1612\n",
      "Epoch [96/100], Step [1300/6235], Loss: 0.3559\n",
      "Epoch [96/100], Step [1400/6235], Loss: 1.8444\n",
      "Epoch [96/100], Step [1500/6235], Loss: 0.0095\n",
      "Epoch [96/100], Step [1600/6235], Loss: 0.2086\n",
      "Epoch [96/100], Step [1700/6235], Loss: 0.1669\n",
      "Epoch [96/100], Step [1800/6235], Loss: 0.2439\n",
      "Epoch [96/100], Step [1900/6235], Loss: 0.8308\n",
      "Epoch [96/100], Step [2000/6235], Loss: 2.1874\n",
      "Epoch [96/100], Step [2100/6235], Loss: 2.2605\n",
      "Epoch [96/100], Step [2200/6235], Loss: 10.8839\n",
      "Epoch [96/100], Step [2300/6235], Loss: 21.0543\n",
      "Epoch [96/100], Step [2400/6235], Loss: 10.9080\n",
      "Epoch [96/100], Step [2500/6235], Loss: 37.2762\n",
      "Epoch [96/100], Step [2600/6235], Loss: 9.2721\n",
      "Epoch [96/100], Step [2700/6235], Loss: 16.9577\n",
      "Epoch [96/100], Step [2800/6235], Loss: 190.5068\n",
      "Epoch [96/100], Step [2900/6235], Loss: 7.3696\n",
      "Epoch [96/100], Step [3000/6235], Loss: 0.1537\n",
      "Epoch [96/100], Step [3100/6235], Loss: 70.5368\n",
      "Epoch [96/100], Step [3200/6235], Loss: 86.7199\n",
      "Epoch [96/100], Step [3300/6235], Loss: 3.7907\n",
      "Epoch [96/100], Step [3400/6235], Loss: 2.0832\n",
      "Epoch [96/100], Step [3500/6235], Loss: 28.3866\n",
      "Epoch [96/100], Step [3600/6235], Loss: 10.2898\n",
      "Epoch [96/100], Step [3700/6235], Loss: 0.4333\n",
      "Epoch [96/100], Step [3800/6235], Loss: 0.5151\n",
      "Epoch [96/100], Step [3900/6235], Loss: 1.6627\n",
      "Epoch [96/100], Step [4000/6235], Loss: 0.0399\n",
      "Epoch [96/100], Step [4100/6235], Loss: 5.6632\n",
      "Epoch [96/100], Step [4200/6235], Loss: 0.3053\n",
      "Epoch [96/100], Step [4300/6235], Loss: 9.6510\n",
      "Epoch [96/100], Step [4400/6235], Loss: 4.5264\n",
      "Epoch [96/100], Step [4500/6235], Loss: 58.3258\n",
      "Epoch [96/100], Step [4600/6235], Loss: 4.2991\n",
      "Epoch [96/100], Step [4700/6235], Loss: 0.6121\n",
      "Epoch [96/100], Step [4800/6235], Loss: 5.6767\n",
      "Epoch [96/100], Step [4900/6235], Loss: 0.0915\n",
      "Epoch [96/100], Step [5000/6235], Loss: 0.1810\n",
      "Epoch [96/100], Step [5100/6235], Loss: 4.2149\n",
      "Epoch [96/100], Step [5200/6235], Loss: 4.4007\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Step [5300/6235], Loss: 35.1382\n",
      "Epoch [96/100], Step [5400/6235], Loss: 4.6530\n",
      "Epoch [96/100], Step [5500/6235], Loss: 0.1221\n",
      "Epoch [96/100], Step [5600/6235], Loss: 0.3304\n",
      "Epoch [96/100], Step [5700/6235], Loss: 0.9550\n",
      "Epoch [96/100], Step [5800/6235], Loss: 0.3880\n",
      "Epoch [96/100], Step [5900/6235], Loss: 0.1428\n",
      "Epoch [96/100], Step [6000/6235], Loss: 2.0402\n",
      "Epoch [96/100], Step [6100/6235], Loss: 0.1945\n",
      "Epoch [96/100], Step [6200/6235], Loss: 1.6534\n",
      "Epoch [96/100], Step [6300/6235], Loss: 2.1253\n",
      "Epoch [96/100], Step [6400/6235], Loss: 0.0107\n",
      "Epoch [96/100], Step [6500/6235], Loss: 1.6615\n",
      "Epoch [96/100], Step [6600/6235], Loss: 6.8114\n",
      "Epoch [96/100], Step [6700/6235], Loss: 3.0213\n",
      "Epoch [96/100], Step [6800/6235], Loss: 0.1224\n",
      "Epoch [96/100], Step [6900/6235], Loss: 1.4171\n",
      "Epoch [96/100], Step [7000/6235], Loss: 0.4776\n",
      "Epoch [96/100], Step [7100/6235], Loss: 0.3353\n",
      "Epoch [96/100], Step [7200/6235], Loss: 0.0901\n",
      "Epoch [96/100], Step [7300/6235], Loss: 0.0592\n",
      "Epoch [96/100], Step [7400/6235], Loss: 0.1105\n",
      "Epoch [96/100], Step [7500/6235], Loss: 0.1224\n",
      "Epoch [96/100], Step [7600/6235], Loss: 4.4672\n",
      "Epoch [96/100], Step [7700/6235], Loss: 11.4718\n",
      "Epoch [96/100], Step [7800/6235], Loss: 1.9304\n",
      "Epoch [96/100], Step [7900/6235], Loss: 1.7134\n",
      "Epoch [96/100], Step [8000/6235], Loss: 0.2254\n",
      "Epoch [96/100], Step [8100/6235], Loss: 1.8913\n",
      "Epoch [96/100], Step [8200/6235], Loss: 10.5238\n",
      "Epoch [96/100], Step [8300/6235], Loss: 15.9177\n",
      "Epoch [96/100], Step [8400/6235], Loss: 602.6625\n",
      "Epoch [96/100], Step [8500/6235], Loss: 12.6894\n",
      "Epoch [96/100], Step [8600/6235], Loss: 23.6931\n",
      "Epoch [96/100], Step [8700/6235], Loss: 25.2888\n",
      "Epoch [96/100], Step [8800/6235], Loss: 519.5361\n",
      "Epoch [96/100], Step [8900/6235], Loss: 332.5994\n",
      "Epoch [96/100], Step [9000/6235], Loss: 477.2156\n",
      "Epoch [96/100], Step [9100/6235], Loss: 876.7300\n",
      "Epoch [96/100], Step [9200/6235], Loss: 2808.3491\n",
      "Epoch [96/100], Step [9300/6235], Loss: 178.3332\n",
      "Epoch [96/100], Step [9400/6235], Loss: 140.4606\n",
      "Epoch [96/100], Step [9500/6235], Loss: 1173.8311\n",
      "Epoch [96/100], Step [9600/6235], Loss: 1204.0183\n",
      "Epoch [96/100], Step [9700/6235], Loss: 1.9340\n",
      "Epoch [96/100], Step [9800/6235], Loss: 2134.4919\n",
      "Epoch [96/100], Step [9900/6235], Loss: 26.7259\n",
      "Epoch [96/100], Step [10000/6235], Loss: 54.7466\n",
      "Epoch [96/100], Step [10100/6235], Loss: 1.0675\n",
      "Epoch [96/100], Step [10200/6235], Loss: 1257.5826\n",
      "Epoch [96/100], Step [10300/6235], Loss: 27.8034\n",
      "Epoch [96/100], Step [10400/6235], Loss: 11.5991\n",
      "Epoch [96/100], Step [10500/6235], Loss: 195.6135\n",
      "Epoch [96/100], Step [10600/6235], Loss: 521.6099\n",
      "Epoch [96/100], Step [10700/6235], Loss: 39.7919\n",
      "Epoch [96/100], Step [10800/6235], Loss: 43.2467\n",
      "Epoch [96/100], Step [10900/6235], Loss: 136.7423\n",
      "Epoch [96/100], Step [11000/6235], Loss: 274.0922\n",
      "Epoch [96/100], Step [11100/6235], Loss: 10.5812\n",
      "Epoch [96/100], Step [11200/6235], Loss: 1.1530\n",
      "Epoch [96/100], Step [11300/6235], Loss: 120.8376\n",
      "Epoch [96/100], Step [11400/6235], Loss: 65.1123\n",
      "Epoch [96/100], Step [11500/6235], Loss: 11.4488\n",
      "Epoch [96/100], Step [11600/6235], Loss: 8.4533\n",
      "Epoch [96/100], Step [11700/6235], Loss: 63.3095\n",
      "Epoch [96/100], Step [11800/6235], Loss: 1.5877\n",
      "Epoch [96/100], Step [11900/6235], Loss: 40.2496\n",
      "Epoch [96/100], Step [12000/6235], Loss: 678.3963\n",
      "Epoch [96/100], Step [12100/6235], Loss: 231.5171\n",
      "Epoch [96/100], Step [12200/6235], Loss: 8.4612\n",
      "Epoch [96/100], Step [12300/6235], Loss: 2.5304\n",
      "Epoch [96/100], Step [12400/6235], Loss: 426.1913\n",
      "Epoch [96/100], Step [12500/6235], Loss: 52.9008\n",
      "Epoch [96/100], Step [12600/6235], Loss: 11.4772\n",
      "Epoch [96/100], Step [12700/6235], Loss: 4.4628\n",
      "Epoch [96/100], Step [12800/6235], Loss: 6.5539\n",
      "Epoch [96/100], Step [12900/6235], Loss: 35.1368\n",
      "Epoch [96/100], Step [13000/6235], Loss: 0.2653\n",
      "Epoch [96/100], Step [13100/6235], Loss: 63.9284\n",
      "Epoch [96/100], Step [13200/6235], Loss: 8.5713\n",
      "Epoch [96/100], Step [13300/6235], Loss: 32.2514\n",
      "Epoch [96/100], Step [13400/6235], Loss: 233.1342\n",
      "Epoch [96/100], Step [13500/6235], Loss: 0.8552\n",
      "Epoch [96/100], Step [13600/6235], Loss: 7.4315\n",
      "Epoch [96/100], Step [13700/6235], Loss: 159.7647\n",
      "Epoch [96/100], Step [13800/6235], Loss: 90.8223\n",
      "Epoch [96/100], Step [13900/6235], Loss: 21.5033\n",
      "Epoch [96/100], Step [14000/6235], Loss: 10.7334\n",
      "Epoch [96/100], Step [14100/6235], Loss: 38.3196\n",
      "Epoch [96/100], Step [14200/6235], Loss: 125.0359\n",
      "Epoch [96/100], Step [14300/6235], Loss: 40.3465\n",
      "Epoch [96/100], Step [14400/6235], Loss: 37.1971\n",
      "Epoch [96/100], Step [14500/6235], Loss: 27.9489\n",
      "Epoch [96/100], Step [14600/6235], Loss: 2.0777\n",
      "Epoch [96/100], Step [14700/6235], Loss: 27.8873\n",
      "Epoch [96/100], Step [14800/6235], Loss: 30.2900\n",
      "Epoch [96/100], Step [14900/6235], Loss: 0.7019\n",
      "Epoch [96/100], Step [15000/6235], Loss: 1.2500\n",
      "Epoch [96/100], Step [15100/6235], Loss: 0.4633\n",
      "Epoch [96/100], Step [15200/6235], Loss: 14.7178\n",
      "Epoch [96/100], Step [15300/6235], Loss: 40.2363\n",
      "Epoch [96/100], Step [15400/6235], Loss: 72.4890\n",
      "Epoch [96/100], Step [15500/6235], Loss: 16.8347\n",
      "Epoch [96/100], Step [15600/6235], Loss: 166.9007\n",
      "Epoch [96/100], Step [15700/6235], Loss: 80.1925\n",
      "Epoch [96/100], Step [15800/6235], Loss: 7.3329\n",
      "Epoch [96/100], Step [15900/6235], Loss: 0.5577\n",
      "Epoch [96/100], Step [16000/6235], Loss: 163.5418\n",
      "Epoch [96/100], Step [16100/6235], Loss: 3.5620\n",
      "Epoch [96/100], Step [16200/6235], Loss: 1.2531\n",
      "Epoch [96/100], Step [16300/6235], Loss: 8.6254\n",
      "Epoch [96/100], Step [16400/6235], Loss: 21.5074\n",
      "Epoch [96/100], Step [16500/6235], Loss: 566.8248\n",
      "Epoch [96/100], Step [16600/6235], Loss: 24.3911\n",
      "Epoch [96/100], Step [16700/6235], Loss: 0.6168\n",
      "Epoch [96/100], Step [16800/6235], Loss: 10.4174\n",
      "Epoch [96/100], Step [16900/6235], Loss: 0.2635\n",
      "Epoch [96/100], Step [17000/6235], Loss: 0.1942\n",
      "Epoch [96/100], Step [17100/6235], Loss: 0.0860\n",
      "Epoch [96/100], Step [17200/6235], Loss: 256.4867\n",
      "Epoch [96/100], Step [17300/6235], Loss: 2.0444\n",
      "Epoch [96/100], Step [17400/6235], Loss: 29.6773\n",
      "Epoch [96/100], Step [17500/6235], Loss: 1.4944\n",
      "Epoch [96/100], Step [17600/6235], Loss: 2.7111\n",
      "Epoch [96/100], Step [17700/6235], Loss: 0.5621\n",
      "Epoch [96/100], Step [17800/6235], Loss: 37.8307\n",
      "Epoch [96/100], Step [17900/6235], Loss: 10.8364\n",
      "Epoch [96/100], Step [18000/6235], Loss: 33.7154\n",
      "Epoch [96/100], Step [18100/6235], Loss: 16.8319\n",
      "Epoch [96/100], Step [18200/6235], Loss: 0.5301\n",
      "Epoch [96/100], Step [18300/6235], Loss: 3.3259\n",
      "Epoch [96/100], Step [18400/6235], Loss: 3.4354\n",
      "Epoch [96/100], Step [18500/6235], Loss: 22.4561\n",
      "Epoch [96/100], Step [18600/6235], Loss: 1.9562\n",
      "Epoch [96/100], Step [18700/6235], Loss: 0.5815\n",
      "Epoch [96/100], Step [18800/6235], Loss: 168.7150\n",
      "Epoch [96/100], Step [18900/6235], Loss: 0.7990\n",
      "Epoch [96/100], Step [19000/6235], Loss: 8.6585\n",
      "Epoch [96/100], Step [19100/6235], Loss: 1.5587\n",
      "Epoch [96/100], Step [19200/6235], Loss: 4.7153\n",
      "Epoch [96/100], Step [19300/6235], Loss: 8.2321\n",
      "Epoch [96/100], Step [19400/6235], Loss: 178.7063\n",
      "Epoch [96/100], Step [19500/6235], Loss: 157.8697\n",
      "Epoch [96/100], Step [19600/6235], Loss: 128.8265\n",
      "Epoch [96/100], Step [19700/6235], Loss: 7.5723\n",
      "Epoch [96/100], Step [19800/6235], Loss: 0.7678\n",
      "Epoch [96/100], Step [19900/6235], Loss: 1.5219\n",
      "Epoch [96/100], Step [20000/6235], Loss: 106.3772\n",
      "Epoch [96/100], Step [20100/6235], Loss: 14.7128\n",
      "Epoch [96/100], Step [20200/6235], Loss: 0.6302\n",
      "Epoch [96/100], Step [20300/6235], Loss: 0.4288\n",
      "Epoch [96/100], Step [20400/6235], Loss: 30.2978\n",
      "Epoch [96/100], Step [20500/6235], Loss: 27.9765\n",
      "Epoch [96/100], Step [20600/6235], Loss: 13.3315\n",
      "Epoch [96/100], Step [20700/6235], Loss: 11.0736\n",
      "Epoch [96/100], Step [20800/6235], Loss: 2.2423\n",
      "Epoch [96/100], Step [20900/6235], Loss: 39.7426\n",
      "Epoch [96/100], Step [21000/6235], Loss: 16.5613\n",
      "Epoch [96/100], Step [21100/6235], Loss: 5.8654\n",
      "Epoch [96/100], Step [21200/6235], Loss: 0.2039\n",
      "Epoch [96/100], Step [21300/6235], Loss: 0.2010\n",
      "Epoch [96/100], Step [21400/6235], Loss: 6.1075\n",
      "Epoch [96/100], Step [21500/6235], Loss: 3.2164\n",
      "Epoch [96/100], Step [21600/6235], Loss: 30.0606\n",
      "Epoch [96/100], Step [21700/6235], Loss: 0.3964\n",
      "Epoch [96/100], Step [21800/6235], Loss: 0.7933\n",
      "Epoch [96/100], Step [21900/6235], Loss: 0.2944\n",
      "Epoch [96/100], Step [22000/6235], Loss: 3.0167\n",
      "Epoch [96/100], Step [22100/6235], Loss: 4.1398\n",
      "Epoch [96/100], Step [22200/6235], Loss: 8.5100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Step [22300/6235], Loss: 0.3073\n",
      "Epoch [96/100], Step [22400/6235], Loss: 6.2990\n",
      "Epoch [96/100], Step [22500/6235], Loss: 137.8483\n",
      "Epoch [96/100], Step [22600/6235], Loss: 14.5484\n",
      "Epoch [96/100], Step [22700/6235], Loss: 0.1725\n",
      "Epoch [96/100], Step [22800/6235], Loss: 2.7755\n",
      "Epoch [96/100], Step [22900/6235], Loss: 4.6424\n",
      "Epoch [96/100], Step [23000/6235], Loss: 10.5062\n",
      "Epoch [96/100], Step [23100/6235], Loss: 8.3486\n",
      "Epoch [96/100], Step [23200/6235], Loss: 13.7989\n",
      "Epoch [96/100], Step [23300/6235], Loss: 10.7101\n",
      "Epoch [96/100], Step [23400/6235], Loss: 0.5007\n",
      "Epoch [96/100], Step [23500/6235], Loss: 0.2982\n",
      "Epoch [96/100], Step [23600/6235], Loss: 102.5445\n",
      "Epoch [96/100], Step [23700/6235], Loss: 5.6924\n",
      "Epoch [96/100], Step [23800/6235], Loss: 0.9087\n",
      "Epoch [96/100], Step [23900/6235], Loss: 7.9116\n",
      "Epoch [96/100], Step [24000/6235], Loss: 0.5770\n",
      "Epoch [96/100], Step [24100/6235], Loss: 1.4921\n",
      "Epoch [96/100], Step [24200/6235], Loss: 42.6109\n",
      "Epoch [96/100], Step [24300/6235], Loss: 2.9150\n",
      "Epoch [96/100], Step [24400/6235], Loss: 4.1776\n",
      "Epoch [96/100], Step [24500/6235], Loss: 2.4836\n",
      "Epoch [96/100], Step [24600/6235], Loss: 0.1391\n",
      "Epoch [96/100], Step [24700/6235], Loss: 0.0781\n",
      "Epoch [96/100], Step [24800/6235], Loss: 0.3155\n",
      "Epoch [96/100], Step [24900/6235], Loss: 15.4770\n",
      "Epoch [96/100], Step [25000/6235], Loss: 20.3113\n",
      "Epoch [96/100], Step [25100/6235], Loss: 7.6815\n",
      "Epoch [96/100], Step [25200/6235], Loss: 1.9000\n",
      "Epoch [96/100], Step [25300/6235], Loss: 0.7719\n",
      "Epoch [96/100], Step [25400/6235], Loss: 9.9486\n",
      "Epoch [96/100], Step [25500/6235], Loss: 4.1487\n",
      "Epoch [96/100], Step [25600/6235], Loss: 1.5908\n",
      "Epoch [96/100], Step [25700/6235], Loss: 0.2371\n",
      "Epoch [96/100], Step [25800/6235], Loss: 0.1654\n",
      "Epoch [96/100], Step [25900/6235], Loss: 10.4660\n",
      "Epoch [96/100], Step [26000/6235], Loss: 2.0553\n",
      "Epoch [96/100], Step [26100/6235], Loss: 0.3736\n",
      "Epoch [96/100], Step [26200/6235], Loss: 0.2560\n",
      "Epoch [96/100], Step [26300/6235], Loss: 4.5513\n",
      "Epoch [96/100], Step [26400/6235], Loss: 0.1783\n",
      "Epoch [96/100], Step [26500/6235], Loss: 0.2348\n",
      "Epoch [96/100], Step [26600/6235], Loss: 3.4743\n",
      "Epoch [96/100], Step [26700/6235], Loss: 0.6818\n",
      "Epoch [96/100], Step [26800/6235], Loss: 0.6626\n",
      "Epoch [96/100], Step [26900/6235], Loss: 0.0444\n",
      "Epoch [96/100], Step [27000/6235], Loss: 12.1236\n",
      "Epoch [96/100], Step [27100/6235], Loss: 0.2237\n",
      "Epoch [96/100], Step [27200/6235], Loss: 0.0863\n",
      "Epoch [96/100], Step [27300/6235], Loss: 0.1793\n",
      "Epoch [96/100], Step [27400/6235], Loss: 0.9342\n",
      "Epoch [96/100], Step [27500/6235], Loss: 15.0980\n",
      "Epoch [96/100], Step [27600/6235], Loss: 0.3301\n",
      "Epoch [96/100], Step [27700/6235], Loss: 1.3658\n",
      "Epoch [96/100], Step [27800/6235], Loss: 0.1671\n",
      "Epoch [96/100], Step [27900/6235], Loss: 0.6094\n",
      "Epoch [96/100], Step [28000/6235], Loss: 93.4009\n",
      "Epoch [96/100], Step [28100/6235], Loss: 8.4956\n",
      "Epoch [96/100], Step [28200/6235], Loss: 38.1741\n",
      "Epoch [96/100], Step [28300/6235], Loss: 3.1410\n",
      "Epoch [96/100], Step [28400/6235], Loss: 27.7537\n",
      "Epoch [96/100], Step [28500/6235], Loss: 4.6615\n",
      "Epoch [96/100], Step [28600/6235], Loss: 0.0698\n",
      "Epoch [96/100], Step [28700/6235], Loss: 5.4963\n",
      "Epoch [96/100], Step [28800/6235], Loss: 0.5504\n",
      "Epoch [96/100], Step [28900/6235], Loss: 74.5190\n",
      "Epoch [96/100], Step [29000/6235], Loss: 11.3079\n",
      "Epoch [96/100], Step [29100/6235], Loss: 0.0867\n",
      "Epoch [96/100], Step [29200/6235], Loss: 0.3583\n",
      "Epoch [96/100], Step [29300/6235], Loss: 17.3986\n",
      "Epoch [96/100], Step [29400/6235], Loss: 0.0550\n",
      "Epoch [96/100], Step [29500/6235], Loss: 8.1883\n",
      "Epoch [96/100], Step [29600/6235], Loss: 0.5376\n",
      "Epoch [96/100], Step [29700/6235], Loss: 0.8051\n",
      "Epoch [96/100], Step [29800/6235], Loss: 1.7048\n",
      "Epoch [96/100], Step [29900/6235], Loss: 0.8448\n",
      "Epoch [96/100], Step [30000/6235], Loss: 5.1514\n",
      "Epoch [96/100], Step [30100/6235], Loss: 11.3300\n",
      "Epoch [96/100], Step [30200/6235], Loss: 0.5890\n",
      "Epoch [96/100], Step [30300/6235], Loss: 0.0460\n",
      "Epoch [96/100], Step [30400/6235], Loss: 0.6309\n",
      "Epoch [96/100], Step [30500/6235], Loss: 3.1467\n",
      "Epoch [96/100], Step [30600/6235], Loss: 1.4374\n",
      "Epoch [96/100], Step [30700/6235], Loss: 0.1140\n",
      "Epoch [96/100], Step [30800/6235], Loss: 0.4052\n",
      "Epoch [96/100], Step [30900/6235], Loss: 3.9389\n",
      "Epoch [96/100], Step [31000/6235], Loss: 0.0666\n",
      "Epoch [96/100], Step [31100/6235], Loss: 0.0451\n",
      "Epoch [96/100], Step [31200/6235], Loss: 6.1111\n",
      "Epoch [96/100], Step [31300/6235], Loss: 1.1593\n",
      "Epoch [96/100], Step [31400/6235], Loss: 3.5160\n",
      "Epoch [96/100], Step [31500/6235], Loss: 0.6692\n",
      "Epoch [96/100], Step [31600/6235], Loss: 5.4692\n",
      "Epoch [96/100], Step [31700/6235], Loss: 20.1784\n",
      "Epoch [96/100], Step [31800/6235], Loss: 0.2744\n",
      "Epoch [96/100], Step [31900/6235], Loss: 604.6245\n",
      "Epoch [96/100], Step [32000/6235], Loss: 5.1971\n",
      "Epoch [96/100], Step [32100/6235], Loss: 0.2279\n",
      "Epoch [96/100], Step [32200/6235], Loss: 113.9399\n",
      "Epoch [96/100], Step [32300/6235], Loss: 1.8527\n",
      "Epoch [96/100], Step [32400/6235], Loss: 1.5527\n",
      "Epoch [96/100], Step [32500/6235], Loss: 13.0058\n",
      "Epoch [96/100], Step [32600/6235], Loss: 0.4463\n",
      "Epoch [96/100], Step [32700/6235], Loss: 141.0397\n",
      "Epoch [96/100], Step [32800/6235], Loss: 5.5858\n",
      "Epoch [96/100], Step [32900/6235], Loss: 0.5810\n",
      "Epoch [96/100], Step [33000/6235], Loss: 0.1928\n",
      "Epoch [96/100], Step [33100/6235], Loss: 0.5546\n",
      "Epoch [96/100], Step [33200/6235], Loss: 0.7330\n",
      "Epoch [96/100], Step [33300/6235], Loss: 0.5543\n",
      "Epoch [96/100], Step [33400/6235], Loss: 108.2434\n",
      "Epoch [96/100], Step [33500/6235], Loss: 2.2403\n",
      "Epoch [96/100], Step [33600/6235], Loss: 6.5296\n",
      "Epoch [96/100], Step [33700/6235], Loss: 5.0994\n",
      "Epoch [96/100], Step [33800/6235], Loss: 0.5954\n",
      "Epoch [96/100], Step [33900/6235], Loss: 28.2376\n",
      "Epoch [96/100], Step [34000/6235], Loss: 0.0877\n",
      "Epoch [96/100], Step [34100/6235], Loss: 0.5526\n",
      "Epoch [96/100], Step [34200/6235], Loss: 2.3341\n",
      "Epoch [96/100], Step [34300/6235], Loss: 4.1548\n",
      "Epoch [96/100], Step [34400/6235], Loss: 0.2270\n",
      "Epoch [96/100], Step [34500/6235], Loss: 18.2140\n",
      "Epoch [96/100], Step [34600/6235], Loss: 0.8038\n",
      "Epoch [96/100], Step [34700/6235], Loss: 21.2507\n",
      "Epoch [96/100], Step [34800/6235], Loss: 7.8794\n",
      "Epoch [96/100], Step [34900/6235], Loss: 63.1388\n",
      "Epoch [96/100], Step [35000/6235], Loss: 0.2417\n",
      "Epoch [96/100], Step [35100/6235], Loss: 0.6225\n",
      "Epoch [96/100], Step [35200/6235], Loss: 0.2310\n",
      "Epoch [96/100], Step [35300/6235], Loss: 2.9245\n",
      "Epoch [96/100], Step [35400/6235], Loss: 0.3985\n",
      "Epoch [96/100], Step [35500/6235], Loss: 1.3221\n",
      "Epoch [96/100], Step [35600/6235], Loss: 0.7203\n",
      "Epoch [96/100], Step [35700/6235], Loss: 6.7460\n",
      "Epoch [96/100], Step [35800/6235], Loss: 0.6707\n",
      "Epoch [96/100], Step [35900/6235], Loss: 1.0934\n",
      "Epoch [96/100], Step [36000/6235], Loss: 0.1233\n",
      "Epoch [96/100], Step [36100/6235], Loss: 0.0271\n",
      "Epoch [96/100], Step [36200/6235], Loss: 23.3247\n",
      "Epoch [96/100], Step [36300/6235], Loss: 0.2698\n",
      "Epoch [96/100], Step [36400/6235], Loss: 2.8250\n",
      "Epoch [96/100], Step [36500/6235], Loss: 8.2553\n",
      "Epoch [96/100], Step [36600/6235], Loss: 0.1519\n",
      "Epoch [96/100], Step [36700/6235], Loss: 0.5323\n",
      "Epoch [96/100], Step [36800/6235], Loss: 9.0338\n",
      "Epoch [96/100], Step [36900/6235], Loss: 10.3458\n",
      "Epoch [96/100], Step [37000/6235], Loss: 0.7244\n",
      "Epoch [96/100], Step [37100/6235], Loss: 1.4717\n",
      "Epoch [96/100], Step [37200/6235], Loss: 0.0703\n",
      "Epoch [96/100], Step [37300/6235], Loss: 0.0294\n",
      "Epoch [96/100], Step [37400/6235], Loss: 0.1953\n",
      "Epoch [96/100], Step [37500/6235], Loss: 5.3052\n",
      "Epoch [96/100], Step [37600/6235], Loss: 11.9576\n",
      "Epoch [96/100], Step [37700/6235], Loss: 1.7424\n",
      "Epoch [96/100], Step [37800/6235], Loss: 4.0951\n",
      "Epoch [96/100], Step [37900/6235], Loss: 8.2012\n",
      "Epoch [96/100], Step [38000/6235], Loss: 0.7292\n",
      "Epoch [96/100], Step [38100/6235], Loss: 3.4530\n",
      "Epoch [96/100], Step [38200/6235], Loss: 2.1623\n",
      "Epoch [96/100], Step [38300/6235], Loss: 0.6163\n",
      "Epoch [96/100], Step [38400/6235], Loss: 0.1055\n",
      "Epoch [96/100], Step [38500/6235], Loss: 2.3435\n",
      "Epoch [96/100], Step [38600/6235], Loss: 0.2054\n",
      "Epoch [96/100], Step [38700/6235], Loss: 0.1099\n",
      "Epoch [96/100], Step [38800/6235], Loss: 0.1801\n",
      "Epoch [96/100], Step [38900/6235], Loss: 2.2803\n",
      "Epoch [96/100], Step [39000/6235], Loss: 18.2881\n",
      "Epoch [96/100], Step [39100/6235], Loss: 11.1652\n",
      "Epoch [96/100], Step [39200/6235], Loss: 0.2794\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [96/100], Step [39300/6235], Loss: 80.0370\n",
      "Epoch [96/100], Step [39400/6235], Loss: 107.3613\n",
      "Epoch [96/100], Step [39500/6235], Loss: 442.9977\n",
      "Epoch [96/100], Step [39600/6235], Loss: 8.9547\n",
      "Epoch [96/100], Step [39700/6235], Loss: 77.4279\n",
      "Epoch [96/100], Step [39800/6235], Loss: 230.2755\n",
      "Epoch [96/100], Step [39900/6235], Loss: 3.0412\n",
      "Epoch [96/100], Step [40000/6235], Loss: 1.6302\n",
      "Epoch [96/100], Step [40100/6235], Loss: 5.0883\n",
      "Epoch [96/100], Step [40200/6235], Loss: 17.7451\n",
      "Epoch [96/100], Step [40300/6235], Loss: 2.9097\n",
      "Epoch [96/100], Step [40400/6235], Loss: 0.2534\n",
      "Epoch [96/100], Step [40500/6235], Loss: 3.4516\n",
      "Epoch [96/100], Step [40600/6235], Loss: 0.3197\n",
      "Epoch [96/100], Step [40700/6235], Loss: 5.1682\n",
      "Epoch [96/100], Step [40800/6235], Loss: 1.3324\n",
      "Epoch [96/100], Step [40900/6235], Loss: 1.3782\n",
      "Epoch [96/100], Step [41000/6235], Loss: 38.5851\n",
      "Epoch [96/100], Step [41100/6235], Loss: 18.2500\n",
      "Epoch [96/100], Step [41200/6235], Loss: 32.7470\n",
      "Epoch [96/100], Step [41300/6235], Loss: 0.3631\n",
      "Epoch [96/100], Step [41400/6235], Loss: 1.3989\n",
      "Epoch [96/100], Step [41500/6235], Loss: 6.4877\n",
      "Epoch [96/100], Step [41600/6235], Loss: 0.4469\n",
      "Epoch [96/100], Step [41700/6235], Loss: 0.0982\n",
      "Epoch [96/100], Step [41800/6235], Loss: 0.9694\n",
      "Epoch [96/100], Step [41900/6235], Loss: 4.9960\n",
      "Epoch [96/100], Step [42000/6235], Loss: 4.2674\n",
      "Epoch [96/100], Step [42100/6235], Loss: 10.0619\n",
      "Epoch [96/100], Step [42200/6235], Loss: 31.1725\n",
      "Epoch [96/100], Step [42300/6235], Loss: 0.9365\n",
      "Epoch [96/100], Step [42400/6235], Loss: 2.4243\n",
      "Epoch [96/100], Step [42500/6235], Loss: 2.6752\n",
      "Epoch [96/100], Step [42600/6235], Loss: 0.4534\n",
      "Epoch [96/100], Step [42700/6235], Loss: 0.3400\n",
      "Epoch [96/100], Step [42800/6235], Loss: 2.4626\n",
      "Epoch [96/100], Step [42900/6235], Loss: 3.7747\n",
      "Epoch [96/100], Step [43000/6235], Loss: 0.2462\n",
      "Epoch [96/100], Step [43100/6235], Loss: 0.4365\n",
      "Epoch [96/100], Step [43200/6235], Loss: 1.0264\n",
      "Epoch [96/100], Step [43300/6235], Loss: 8.7058\n",
      "Epoch [96/100], Step [43400/6235], Loss: 11.7889\n",
      "Epoch [96/100], Step [43500/6235], Loss: 9.4593\n",
      "Epoch [96/100], Step [43600/6235], Loss: 13.5774\n",
      "Epoch [96/100], Step [43700/6235], Loss: 45.4457\n",
      "Epoch [96/100], Step [43800/6235], Loss: 0.4237\n",
      "Epoch [96/100], Step [43900/6235], Loss: 1.4432\n",
      "Epoch [96/100], Step [44000/6235], Loss: 50.9344\n",
      "Epoch [96/100], Step [44100/6235], Loss: 3.3012\n",
      "Epoch [96/100], Step [44200/6235], Loss: 28.3655\n",
      "Epoch [96/100], Step [44300/6235], Loss: 21.3907\n",
      "Epoch [96/100], Step [44400/6235], Loss: 0.4314\n",
      "Epoch [96/100], Step [44500/6235], Loss: 4.2234\n",
      "Epoch [96/100], Step [44600/6235], Loss: 16.4001\n",
      "Epoch [96/100], Step [44700/6235], Loss: 5.3390\n",
      "Epoch [96/100], Step [44800/6235], Loss: 4.2410\n",
      "Epoch [96/100], Step [44900/6235], Loss: 11.8529\n",
      "Epoch [96/100], Step [45000/6235], Loss: 6.4249\n",
      "Epoch [96/100], Step [45100/6235], Loss: 42.0614\n",
      "Epoch [96/100], Step [45200/6235], Loss: 0.3779\n",
      "Epoch [96/100], Step [45300/6235], Loss: 25.2925\n",
      "Epoch [96/100], Step [45400/6235], Loss: 9.3776\n",
      "Epoch [96/100], Step [45500/6235], Loss: 2.7427\n",
      "Epoch [96/100], Step [45600/6235], Loss: 0.8444\n",
      "Epoch [96/100], Step [45700/6235], Loss: 79.0046\n",
      "Epoch [96/100], Step [45800/6235], Loss: 213.1027\n",
      "Epoch [96/100], Step [45900/6235], Loss: 6.2665\n",
      "Epoch [96/100], Step [46000/6235], Loss: 6.2362\n",
      "Epoch [96/100], Step [46100/6235], Loss: 26.6041\n",
      "Epoch [96/100], Step [46200/6235], Loss: 140.7726\n",
      "Epoch [96/100], Step [46300/6235], Loss: 21.2950\n",
      "Epoch [96/100], Step [46400/6235], Loss: 13.9759\n",
      "Epoch [96/100], Step [46500/6235], Loss: 24.1662\n",
      "Epoch [96/100], Step [46600/6235], Loss: 8.5699\n",
      "Epoch [96/100], Step [46700/6235], Loss: 40.3739\n",
      "Epoch [96/100], Step [46800/6235], Loss: 1.6770\n",
      "Epoch [96/100], Step [46900/6235], Loss: 0.6052\n",
      "Epoch [96/100], Step [47000/6235], Loss: 7.7506\n",
      "Epoch [96/100], Step [47100/6235], Loss: 24.3194\n",
      "Epoch [96/100], Step [47200/6235], Loss: 9.8969\n",
      "Epoch [96/100], Step [47300/6235], Loss: 0.0900\n",
      "Epoch [96/100], Step [47400/6235], Loss: 469.7072\n",
      "Epoch [96/100], Step [47500/6235], Loss: 32.0509\n",
      "Epoch [96/100], Step [47600/6235], Loss: 12.9796\n",
      "Epoch [96/100], Step [47700/6235], Loss: 24.4354\n",
      "Epoch [96/100], Step [47800/6235], Loss: 22.6084\n",
      "Epoch [96/100], Step [47900/6235], Loss: 16.3948\n",
      "Epoch [96/100], Step [48000/6235], Loss: 13.1156\n",
      "Epoch [96/100], Step [48100/6235], Loss: 5.9606\n",
      "Epoch [96/100], Step [48200/6235], Loss: 33.9271\n",
      "Epoch [96/100], Step [48300/6235], Loss: 427.1015\n",
      "Epoch [96/100], Step [48400/6235], Loss: 2.5158\n",
      "Epoch [96/100], Step [48500/6235], Loss: 41.9577\n",
      "Epoch [96/100], Step [48600/6235], Loss: 115.6878\n",
      "Epoch [96/100], Step [48700/6235], Loss: 0.4900\n",
      "Epoch [96/100], Step [48800/6235], Loss: 1264.6072\n",
      "Epoch [96/100], Step [48900/6235], Loss: 538.3096\n",
      "Epoch [96/100], Step [49000/6235], Loss: 10.4502\n",
      "Epoch [96/100], Step [49100/6235], Loss: 176.7391\n",
      "Epoch [96/100], Step [49200/6235], Loss: 691.5737\n",
      "Epoch [96/100], Step [49300/6235], Loss: 263.7496\n",
      "Epoch [96/100], Step [49400/6235], Loss: 4.4817\n",
      "Epoch [96/100], Step [49500/6235], Loss: 18.0069\n",
      "Epoch [96/100], Step [49600/6235], Loss: 346.9393\n",
      "Epoch [96/100], Step [49700/6235], Loss: 655.2283\n",
      "Epoch [96/100], Step [49800/6235], Loss: 621.8727\n",
      "Epoch [97/100], Step [100/6235], Loss: 0.4181\n",
      "Epoch [97/100], Step [200/6235], Loss: 0.0441\n",
      "Epoch [97/100], Step [300/6235], Loss: 0.0092\n",
      "Epoch [97/100], Step [400/6235], Loss: 0.0010\n",
      "Epoch [97/100], Step [500/6235], Loss: 0.5683\n",
      "Epoch [97/100], Step [600/6235], Loss: 0.0360\n",
      "Epoch [97/100], Step [700/6235], Loss: 0.1817\n",
      "Epoch [97/100], Step [800/6235], Loss: 0.0227\n",
      "Epoch [97/100], Step [900/6235], Loss: 0.0215\n",
      "Epoch [97/100], Step [1000/6235], Loss: 0.0209\n",
      "Epoch [97/100], Step [1100/6235], Loss: 0.0046\n",
      "Epoch [97/100], Step [1200/6235], Loss: 0.1133\n",
      "Epoch [97/100], Step [1300/6235], Loss: 0.0584\n",
      "Epoch [97/100], Step [1400/6235], Loss: 0.0315\n",
      "Epoch [97/100], Step [1500/6235], Loss: 0.0016\n",
      "Epoch [97/100], Step [1600/6235], Loss: 0.1991\n",
      "Epoch [97/100], Step [1700/6235], Loss: 0.0431\n",
      "Epoch [97/100], Step [1800/6235], Loss: 0.2547\n",
      "Epoch [97/100], Step [1900/6235], Loss: 0.7758\n",
      "Epoch [97/100], Step [2000/6235], Loss: 1.8087\n",
      "Epoch [97/100], Step [2100/6235], Loss: 0.4108\n",
      "Epoch [97/100], Step [2200/6235], Loss: 11.5743\n",
      "Epoch [97/100], Step [2300/6235], Loss: 27.8012\n",
      "Epoch [97/100], Step [2400/6235], Loss: 17.0444\n",
      "Epoch [97/100], Step [2500/6235], Loss: 30.7763\n",
      "Epoch [97/100], Step [2600/6235], Loss: 6.6314\n",
      "Epoch [97/100], Step [2700/6235], Loss: 36.9601\n",
      "Epoch [97/100], Step [2800/6235], Loss: 40.0836\n",
      "Epoch [97/100], Step [2900/6235], Loss: 6.4102\n",
      "Epoch [97/100], Step [3000/6235], Loss: 0.8376\n",
      "Epoch [97/100], Step [3100/6235], Loss: 52.3301\n",
      "Epoch [97/100], Step [3200/6235], Loss: 75.8554\n",
      "Epoch [97/100], Step [3300/6235], Loss: 0.4016\n",
      "Epoch [97/100], Step [3400/6235], Loss: 3.0126\n",
      "Epoch [97/100], Step [3500/6235], Loss: 33.7179\n",
      "Epoch [97/100], Step [3600/6235], Loss: 9.7587\n",
      "Epoch [97/100], Step [3700/6235], Loss: 1.4152\n",
      "Epoch [97/100], Step [3800/6235], Loss: 0.5554\n",
      "Epoch [97/100], Step [3900/6235], Loss: 0.9376\n",
      "Epoch [97/100], Step [4000/6235], Loss: 0.1213\n",
      "Epoch [97/100], Step [4100/6235], Loss: 3.6703\n",
      "Epoch [97/100], Step [4200/6235], Loss: 0.2075\n",
      "Epoch [97/100], Step [4300/6235], Loss: 9.6816\n",
      "Epoch [97/100], Step [4400/6235], Loss: 2.2056\n",
      "Epoch [97/100], Step [4500/6235], Loss: 64.4949\n",
      "Epoch [97/100], Step [4600/6235], Loss: 11.5124\n",
      "Epoch [97/100], Step [4700/6235], Loss: 2.1540\n",
      "Epoch [97/100], Step [4800/6235], Loss: 0.2443\n",
      "Epoch [97/100], Step [4900/6235], Loss: 0.1765\n",
      "Epoch [97/100], Step [5000/6235], Loss: 0.6663\n",
      "Epoch [97/100], Step [5100/6235], Loss: 0.8987\n",
      "Epoch [97/100], Step [5200/6235], Loss: 2.8466\n",
      "Epoch [97/100], Step [5300/6235], Loss: 31.9931\n",
      "Epoch [97/100], Step [5400/6235], Loss: 1.4928\n",
      "Epoch [97/100], Step [5500/6235], Loss: 0.1354\n",
      "Epoch [97/100], Step [5600/6235], Loss: 0.2176\n",
      "Epoch [97/100], Step [5700/6235], Loss: 1.5122\n",
      "Epoch [97/100], Step [5800/6235], Loss: 1.3614\n",
      "Epoch [97/100], Step [5900/6235], Loss: 0.2528\n",
      "Epoch [97/100], Step [6000/6235], Loss: 0.7453\n",
      "Epoch [97/100], Step [6100/6235], Loss: 0.0448\n",
      "Epoch [97/100], Step [6200/6235], Loss: 0.3754\n",
      "Epoch [97/100], Step [6300/6235], Loss: 0.3591\n",
      "Epoch [97/100], Step [6400/6235], Loss: 0.2233\n",
      "Epoch [97/100], Step [6500/6235], Loss: 2.1103\n",
      "Epoch [97/100], Step [6600/6235], Loss: 0.8792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Step [6700/6235], Loss: 0.6517\n",
      "Epoch [97/100], Step [6800/6235], Loss: 1.8702\n",
      "Epoch [97/100], Step [6900/6235], Loss: 3.0915\n",
      "Epoch [97/100], Step [7000/6235], Loss: 0.3498\n",
      "Epoch [97/100], Step [7100/6235], Loss: 0.3158\n",
      "Epoch [97/100], Step [7200/6235], Loss: 0.7468\n",
      "Epoch [97/100], Step [7300/6235], Loss: 0.1751\n",
      "Epoch [97/100], Step [7400/6235], Loss: 0.2646\n",
      "Epoch [97/100], Step [7500/6235], Loss: 1.2497\n",
      "Epoch [97/100], Step [7600/6235], Loss: 5.3693\n",
      "Epoch [97/100], Step [7700/6235], Loss: 19.0658\n",
      "Epoch [97/100], Step [7800/6235], Loss: 9.1423\n",
      "Epoch [97/100], Step [7900/6235], Loss: 1.3962\n",
      "Epoch [97/100], Step [8000/6235], Loss: 0.5133\n",
      "Epoch [97/100], Step [8100/6235], Loss: 4.6196\n",
      "Epoch [97/100], Step [8200/6235], Loss: 16.3456\n",
      "Epoch [97/100], Step [8300/6235], Loss: 52.0976\n",
      "Epoch [97/100], Step [8400/6235], Loss: 183.6885\n",
      "Epoch [97/100], Step [8500/6235], Loss: 1.0881\n",
      "Epoch [97/100], Step [8600/6235], Loss: 147.6009\n",
      "Epoch [97/100], Step [8700/6235], Loss: 60.3430\n",
      "Epoch [97/100], Step [8800/6235], Loss: 178.6322\n",
      "Epoch [97/100], Step [8900/6235], Loss: 364.8397\n",
      "Epoch [97/100], Step [9000/6235], Loss: 137.7775\n",
      "Epoch [97/100], Step [9100/6235], Loss: 2805.4878\n",
      "Epoch [97/100], Step [9200/6235], Loss: 4281.7334\n",
      "Epoch [97/100], Step [9300/6235], Loss: 5.9136\n",
      "Epoch [97/100], Step [9400/6235], Loss: 21.8372\n",
      "Epoch [97/100], Step [9500/6235], Loss: 1096.0471\n",
      "Epoch [97/100], Step [9600/6235], Loss: 1657.7028\n",
      "Epoch [97/100], Step [9700/6235], Loss: 2.0566\n",
      "Epoch [97/100], Step [9800/6235], Loss: 268.8295\n",
      "Epoch [97/100], Step [9900/6235], Loss: 18.8824\n",
      "Epoch [97/100], Step [10000/6235], Loss: 123.8242\n",
      "Epoch [97/100], Step [10100/6235], Loss: 2.2332\n",
      "Epoch [97/100], Step [10200/6235], Loss: 1394.9617\n",
      "Epoch [97/100], Step [10300/6235], Loss: 31.2389\n",
      "Epoch [97/100], Step [10400/6235], Loss: 10.5253\n",
      "Epoch [97/100], Step [10500/6235], Loss: 281.0234\n",
      "Epoch [97/100], Step [10600/6235], Loss: 943.5566\n",
      "Epoch [97/100], Step [10700/6235], Loss: 67.5610\n",
      "Epoch [97/100], Step [10800/6235], Loss: 4.8001\n",
      "Epoch [97/100], Step [10900/6235], Loss: 134.8263\n",
      "Epoch [97/100], Step [11000/6235], Loss: 290.3425\n",
      "Epoch [97/100], Step [11100/6235], Loss: 7.2603\n",
      "Epoch [97/100], Step [11200/6235], Loss: 0.3254\n",
      "Epoch [97/100], Step [11300/6235], Loss: 98.5891\n",
      "Epoch [97/100], Step [11400/6235], Loss: 36.0012\n",
      "Epoch [97/100], Step [11500/6235], Loss: 12.3662\n",
      "Epoch [97/100], Step [11600/6235], Loss: 9.9579\n",
      "Epoch [97/100], Step [11700/6235], Loss: 52.5281\n",
      "Epoch [97/100], Step [11800/6235], Loss: 424.3461\n",
      "Epoch [97/100], Step [11900/6235], Loss: 233.0892\n",
      "Epoch [97/100], Step [12000/6235], Loss: 290.7918\n",
      "Epoch [97/100], Step [12100/6235], Loss: 206.0910\n",
      "Epoch [97/100], Step [12200/6235], Loss: 56.5934\n",
      "Epoch [97/100], Step [12300/6235], Loss: 11.1302\n",
      "Epoch [97/100], Step [12400/6235], Loss: 97.0707\n",
      "Epoch [97/100], Step [12500/6235], Loss: 14.8698\n",
      "Epoch [97/100], Step [12600/6235], Loss: 48.5938\n",
      "Epoch [97/100], Step [12700/6235], Loss: 4.1089\n",
      "Epoch [97/100], Step [12800/6235], Loss: 4.4751\n",
      "Epoch [97/100], Step [12900/6235], Loss: 34.8347\n",
      "Epoch [97/100], Step [13000/6235], Loss: 0.2139\n",
      "Epoch [97/100], Step [13100/6235], Loss: 64.5699\n",
      "Epoch [97/100], Step [13200/6235], Loss: 9.5495\n",
      "Epoch [97/100], Step [13300/6235], Loss: 44.7648\n",
      "Epoch [97/100], Step [13400/6235], Loss: 241.5041\n",
      "Epoch [97/100], Step [13500/6235], Loss: 32.4082\n",
      "Epoch [97/100], Step [13600/6235], Loss: 32.3800\n",
      "Epoch [97/100], Step [13700/6235], Loss: 11.4187\n",
      "Epoch [97/100], Step [13800/6235], Loss: 147.3813\n",
      "Epoch [97/100], Step [13900/6235], Loss: 65.2041\n",
      "Epoch [97/100], Step [14000/6235], Loss: 17.5393\n",
      "Epoch [97/100], Step [14100/6235], Loss: 20.4234\n",
      "Epoch [97/100], Step [14200/6235], Loss: 123.1640\n",
      "Epoch [97/100], Step [14300/6235], Loss: 39.4741\n",
      "Epoch [97/100], Step [14400/6235], Loss: 38.8410\n",
      "Epoch [97/100], Step [14500/6235], Loss: 38.9284\n",
      "Epoch [97/100], Step [14600/6235], Loss: 0.5102\n",
      "Epoch [97/100], Step [14700/6235], Loss: 38.4648\n",
      "Epoch [97/100], Step [14800/6235], Loss: 33.7356\n",
      "Epoch [97/100], Step [14900/6235], Loss: 0.7080\n",
      "Epoch [97/100], Step [15000/6235], Loss: 1.5560\n",
      "Epoch [97/100], Step [15100/6235], Loss: 0.5526\n",
      "Epoch [97/100], Step [15200/6235], Loss: 6.3288\n",
      "Epoch [97/100], Step [15300/6235], Loss: 41.6548\n",
      "Epoch [97/100], Step [15400/6235], Loss: 80.3271\n",
      "Epoch [97/100], Step [15500/6235], Loss: 13.5309\n",
      "Epoch [97/100], Step [15600/6235], Loss: 167.0476\n",
      "Epoch [97/100], Step [15700/6235], Loss: 175.4626\n",
      "Epoch [97/100], Step [15800/6235], Loss: 1.9210\n",
      "Epoch [97/100], Step [15900/6235], Loss: 2.7074\n",
      "Epoch [97/100], Step [16000/6235], Loss: 101.2746\n",
      "Epoch [97/100], Step [16100/6235], Loss: 3.5777\n",
      "Epoch [97/100], Step [16200/6235], Loss: 0.8106\n",
      "Epoch [97/100], Step [16300/6235], Loss: 8.7335\n",
      "Epoch [97/100], Step [16400/6235], Loss: 26.2731\n",
      "Epoch [97/100], Step [16500/6235], Loss: 253.1147\n",
      "Epoch [97/100], Step [16600/6235], Loss: 13.2379\n",
      "Epoch [97/100], Step [16700/6235], Loss: 0.5593\n",
      "Epoch [97/100], Step [16800/6235], Loss: 9.4158\n",
      "Epoch [97/100], Step [16900/6235], Loss: 0.2217\n",
      "Epoch [97/100], Step [17000/6235], Loss: 0.2064\n",
      "Epoch [97/100], Step [17100/6235], Loss: 0.1487\n",
      "Epoch [97/100], Step [17200/6235], Loss: 268.4629\n",
      "Epoch [97/100], Step [17300/6235], Loss: 6.4811\n",
      "Epoch [97/100], Step [17400/6235], Loss: 44.5557\n",
      "Epoch [97/100], Step [17500/6235], Loss: 0.8277\n",
      "Epoch [97/100], Step [17600/6235], Loss: 2.6888\n",
      "Epoch [97/100], Step [17700/6235], Loss: 95.6894\n",
      "Epoch [97/100], Step [17800/6235], Loss: 21.9520\n",
      "Epoch [97/100], Step [17900/6235], Loss: 10.7374\n",
      "Epoch [97/100], Step [18000/6235], Loss: 1.4997\n",
      "Epoch [97/100], Step [18100/6235], Loss: 17.0329\n",
      "Epoch [97/100], Step [18200/6235], Loss: 0.5734\n",
      "Epoch [97/100], Step [18300/6235], Loss: 3.6565\n",
      "Epoch [97/100], Step [18400/6235], Loss: 0.5168\n",
      "Epoch [97/100], Step [18500/6235], Loss: 12.4956\n",
      "Epoch [97/100], Step [18600/6235], Loss: 1.6916\n",
      "Epoch [97/100], Step [18700/6235], Loss: 0.4990\n",
      "Epoch [97/100], Step [18800/6235], Loss: 126.7056\n",
      "Epoch [97/100], Step [18900/6235], Loss: 1.9385\n",
      "Epoch [97/100], Step [19000/6235], Loss: 5.2403\n",
      "Epoch [97/100], Step [19100/6235], Loss: 33.8558\n",
      "Epoch [97/100], Step [19200/6235], Loss: 2.1163\n",
      "Epoch [97/100], Step [19300/6235], Loss: 12.1870\n",
      "Epoch [97/100], Step [19400/6235], Loss: 212.2302\n",
      "Epoch [97/100], Step [19500/6235], Loss: 110.2910\n",
      "Epoch [97/100], Step [19600/6235], Loss: 107.0586\n",
      "Epoch [97/100], Step [19700/6235], Loss: 5.7634\n",
      "Epoch [97/100], Step [19800/6235], Loss: 3.3880\n",
      "Epoch [97/100], Step [19900/6235], Loss: 0.1795\n",
      "Epoch [97/100], Step [20000/6235], Loss: 66.5857\n",
      "Epoch [97/100], Step [20100/6235], Loss: 0.1502\n",
      "Epoch [97/100], Step [20200/6235], Loss: 6.5789\n",
      "Epoch [97/100], Step [20300/6235], Loss: 2.5652\n",
      "Epoch [97/100], Step [20400/6235], Loss: 18.6482\n",
      "Epoch [97/100], Step [20500/6235], Loss: 43.5177\n",
      "Epoch [97/100], Step [20600/6235], Loss: 36.5061\n",
      "Epoch [97/100], Step [20700/6235], Loss: 7.3655\n",
      "Epoch [97/100], Step [20800/6235], Loss: 54.1803\n",
      "Epoch [97/100], Step [20900/6235], Loss: 24.9421\n",
      "Epoch [97/100], Step [21000/6235], Loss: 16.8187\n",
      "Epoch [97/100], Step [21100/6235], Loss: 4.6793\n",
      "Epoch [97/100], Step [21200/6235], Loss: 0.1338\n",
      "Epoch [97/100], Step [21300/6235], Loss: 0.1827\n",
      "Epoch [97/100], Step [21400/6235], Loss: 5.9444\n",
      "Epoch [97/100], Step [21500/6235], Loss: 2.5376\n",
      "Epoch [97/100], Step [21600/6235], Loss: 32.5684\n",
      "Epoch [97/100], Step [21700/6235], Loss: 0.4020\n",
      "Epoch [97/100], Step [21800/6235], Loss: 0.2464\n",
      "Epoch [97/100], Step [21900/6235], Loss: 0.3188\n",
      "Epoch [97/100], Step [22000/6235], Loss: 3.3197\n",
      "Epoch [97/100], Step [22100/6235], Loss: 3.8081\n",
      "Epoch [97/100], Step [22200/6235], Loss: 11.0849\n",
      "Epoch [97/100], Step [22300/6235], Loss: 0.0780\n",
      "Epoch [97/100], Step [22400/6235], Loss: 3.8180\n",
      "Epoch [97/100], Step [22500/6235], Loss: 96.1401\n",
      "Epoch [97/100], Step [22600/6235], Loss: 9.4343\n",
      "Epoch [97/100], Step [22700/6235], Loss: 0.1887\n",
      "Epoch [97/100], Step [22800/6235], Loss: 2.6175\n",
      "Epoch [97/100], Step [22900/6235], Loss: 1.0504\n",
      "Epoch [97/100], Step [23000/6235], Loss: 23.4147\n",
      "Epoch [97/100], Step [23100/6235], Loss: 9.3149\n",
      "Epoch [97/100], Step [23200/6235], Loss: 24.9454\n",
      "Epoch [97/100], Step [23300/6235], Loss: 16.4559\n",
      "Epoch [97/100], Step [23400/6235], Loss: 0.4004\n",
      "Epoch [97/100], Step [23500/6235], Loss: 0.3205\n",
      "Epoch [97/100], Step [23600/6235], Loss: 96.9469\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Step [23700/6235], Loss: 6.9779\n",
      "Epoch [97/100], Step [23800/6235], Loss: 0.8048\n",
      "Epoch [97/100], Step [23900/6235], Loss: 7.8273\n",
      "Epoch [97/100], Step [24000/6235], Loss: 0.8453\n",
      "Epoch [97/100], Step [24100/6235], Loss: 1.2308\n",
      "Epoch [97/100], Step [24200/6235], Loss: 36.7233\n",
      "Epoch [97/100], Step [24300/6235], Loss: 1.5406\n",
      "Epoch [97/100], Step [24400/6235], Loss: 4.2467\n",
      "Epoch [97/100], Step [24500/6235], Loss: 2.3218\n",
      "Epoch [97/100], Step [24600/6235], Loss: 0.1400\n",
      "Epoch [97/100], Step [24700/6235], Loss: 0.1035\n",
      "Epoch [97/100], Step [24800/6235], Loss: 0.0781\n",
      "Epoch [97/100], Step [24900/6235], Loss: 13.0406\n",
      "Epoch [97/100], Step [25000/6235], Loss: 16.3808\n",
      "Epoch [97/100], Step [25100/6235], Loss: 8.0816\n",
      "Epoch [97/100], Step [25200/6235], Loss: 1.9106\n",
      "Epoch [97/100], Step [25300/6235], Loss: 0.7426\n",
      "Epoch [97/100], Step [25400/6235], Loss: 9.8924\n",
      "Epoch [97/100], Step [25500/6235], Loss: 4.2538\n",
      "Epoch [97/100], Step [25600/6235], Loss: 1.6455\n",
      "Epoch [97/100], Step [25700/6235], Loss: 0.2436\n",
      "Epoch [97/100], Step [25800/6235], Loss: 0.1535\n",
      "Epoch [97/100], Step [25900/6235], Loss: 10.5028\n",
      "Epoch [97/100], Step [26000/6235], Loss: 0.6403\n",
      "Epoch [97/100], Step [26100/6235], Loss: 0.4092\n",
      "Epoch [97/100], Step [26200/6235], Loss: 0.0171\n",
      "Epoch [97/100], Step [26300/6235], Loss: 4.4580\n",
      "Epoch [97/100], Step [26400/6235], Loss: 0.1782\n",
      "Epoch [97/100], Step [26500/6235], Loss: 0.2647\n",
      "Epoch [97/100], Step [26600/6235], Loss: 3.6864\n",
      "Epoch [97/100], Step [26700/6235], Loss: 0.7217\n",
      "Epoch [97/100], Step [26800/6235], Loss: 0.7730\n",
      "Epoch [97/100], Step [26900/6235], Loss: 0.0585\n",
      "Epoch [97/100], Step [27000/6235], Loss: 11.7345\n",
      "Epoch [97/100], Step [27100/6235], Loss: 0.2630\n",
      "Epoch [97/100], Step [27200/6235], Loss: 0.1013\n",
      "Epoch [97/100], Step [27300/6235], Loss: 0.1590\n",
      "Epoch [97/100], Step [27400/6235], Loss: 0.9653\n",
      "Epoch [97/100], Step [27500/6235], Loss: 24.0498\n",
      "Epoch [97/100], Step [27600/6235], Loss: 0.9683\n",
      "Epoch [97/100], Step [27700/6235], Loss: 1.5931\n",
      "Epoch [97/100], Step [27800/6235], Loss: 7.6414\n",
      "Epoch [97/100], Step [27900/6235], Loss: 1.0803\n",
      "Epoch [97/100], Step [28000/6235], Loss: 167.1933\n",
      "Epoch [97/100], Step [28100/6235], Loss: 1.8316\n",
      "Epoch [97/100], Step [28200/6235], Loss: 23.4412\n",
      "Epoch [97/100], Step [28300/6235], Loss: 3.1329\n",
      "Epoch [97/100], Step [28400/6235], Loss: 27.2736\n",
      "Epoch [97/100], Step [28500/6235], Loss: 4.8889\n",
      "Epoch [97/100], Step [28600/6235], Loss: 0.0442\n",
      "Epoch [97/100], Step [28700/6235], Loss: 5.4313\n",
      "Epoch [97/100], Step [28800/6235], Loss: 0.5546\n",
      "Epoch [97/100], Step [28900/6235], Loss: 74.3833\n",
      "Epoch [97/100], Step [29000/6235], Loss: 12.7588\n",
      "Epoch [97/100], Step [29100/6235], Loss: 0.0361\n",
      "Epoch [97/100], Step [29200/6235], Loss: 0.1974\n",
      "Epoch [97/100], Step [29300/6235], Loss: 1.8704\n",
      "Epoch [97/100], Step [29400/6235], Loss: 0.1310\n",
      "Epoch [97/100], Step [29500/6235], Loss: 1.8675\n",
      "Epoch [97/100], Step [29600/6235], Loss: 0.6996\n",
      "Epoch [97/100], Step [29700/6235], Loss: 0.3770\n",
      "Epoch [97/100], Step [29800/6235], Loss: 1.7248\n",
      "Epoch [97/100], Step [29900/6235], Loss: 0.6039\n",
      "Epoch [97/100], Step [30000/6235], Loss: 5.5613\n",
      "Epoch [97/100], Step [30100/6235], Loss: 8.3234\n",
      "Epoch [97/100], Step [30200/6235], Loss: 0.2011\n",
      "Epoch [97/100], Step [30300/6235], Loss: 0.2578\n",
      "Epoch [97/100], Step [30400/6235], Loss: 0.3385\n",
      "Epoch [97/100], Step [30500/6235], Loss: 2.7141\n",
      "Epoch [97/100], Step [30600/6235], Loss: 1.0350\n",
      "Epoch [97/100], Step [30700/6235], Loss: 0.0143\n",
      "Epoch [97/100], Step [30800/6235], Loss: 0.3229\n",
      "Epoch [97/100], Step [30900/6235], Loss: 3.8250\n",
      "Epoch [97/100], Step [31000/6235], Loss: 0.0238\n",
      "Epoch [97/100], Step [31100/6235], Loss: 0.0417\n",
      "Epoch [97/100], Step [31200/6235], Loss: 5.7557\n",
      "Epoch [97/100], Step [31300/6235], Loss: 1.6731\n",
      "Epoch [97/100], Step [31400/6235], Loss: 14.6774\n",
      "Epoch [97/100], Step [31500/6235], Loss: 0.6071\n",
      "Epoch [97/100], Step [31600/6235], Loss: 0.6959\n",
      "Epoch [97/100], Step [31700/6235], Loss: 9.8398\n",
      "Epoch [97/100], Step [31800/6235], Loss: 0.9640\n",
      "Epoch [97/100], Step [31900/6235], Loss: 1229.7871\n",
      "Epoch [97/100], Step [32000/6235], Loss: 19.4993\n",
      "Epoch [97/100], Step [32100/6235], Loss: 0.7232\n",
      "Epoch [97/100], Step [32200/6235], Loss: 132.6291\n",
      "Epoch [97/100], Step [32300/6235], Loss: 0.3428\n",
      "Epoch [97/100], Step [32400/6235], Loss: 1.2292\n",
      "Epoch [97/100], Step [32500/6235], Loss: 7.1874\n",
      "Epoch [97/100], Step [32600/6235], Loss: 0.2300\n",
      "Epoch [97/100], Step [32700/6235], Loss: 171.8952\n",
      "Epoch [97/100], Step [32800/6235], Loss: 7.7159\n",
      "Epoch [97/100], Step [32900/6235], Loss: 1.0054\n",
      "Epoch [97/100], Step [33000/6235], Loss: 0.1824\n",
      "Epoch [97/100], Step [33100/6235], Loss: 0.4958\n",
      "Epoch [97/100], Step [33200/6235], Loss: 1.5284\n",
      "Epoch [97/100], Step [33300/6235], Loss: 4.5261\n",
      "Epoch [97/100], Step [33400/6235], Loss: 0.2897\n",
      "Epoch [97/100], Step [33500/6235], Loss: 1.4540\n",
      "Epoch [97/100], Step [33600/6235], Loss: 8.9299\n",
      "Epoch [97/100], Step [33700/6235], Loss: 13.6162\n",
      "Epoch [97/100], Step [33800/6235], Loss: 1.3324\n",
      "Epoch [97/100], Step [33900/6235], Loss: 26.1966\n",
      "Epoch [97/100], Step [34000/6235], Loss: 0.0800\n",
      "Epoch [97/100], Step [34100/6235], Loss: 0.5180\n",
      "Epoch [97/100], Step [34200/6235], Loss: 2.3098\n",
      "Epoch [97/100], Step [34300/6235], Loss: 4.5899\n",
      "Epoch [97/100], Step [34400/6235], Loss: 0.2312\n",
      "Epoch [97/100], Step [34500/6235], Loss: 21.3366\n",
      "Epoch [97/100], Step [34600/6235], Loss: 1.7594\n",
      "Epoch [97/100], Step [34700/6235], Loss: 15.9883\n",
      "Epoch [97/100], Step [34800/6235], Loss: 14.1074\n",
      "Epoch [97/100], Step [34900/6235], Loss: 70.0779\n",
      "Epoch [97/100], Step [35000/6235], Loss: 0.2544\n",
      "Epoch [97/100], Step [35100/6235], Loss: 0.9934\n",
      "Epoch [97/100], Step [35200/6235], Loss: 0.3640\n",
      "Epoch [97/100], Step [35300/6235], Loss: 3.0461\n",
      "Epoch [97/100], Step [35400/6235], Loss: 0.4411\n",
      "Epoch [97/100], Step [35500/6235], Loss: 1.1273\n",
      "Epoch [97/100], Step [35600/6235], Loss: 1.5379\n",
      "Epoch [97/100], Step [35700/6235], Loss: 6.2226\n",
      "Epoch [97/100], Step [35800/6235], Loss: 2.1514\n",
      "Epoch [97/100], Step [35900/6235], Loss: 1.7344\n",
      "Epoch [97/100], Step [36000/6235], Loss: 0.0469\n",
      "Epoch [97/100], Step [36100/6235], Loss: 0.0251\n",
      "Epoch [97/100], Step [36200/6235], Loss: 20.5604\n",
      "Epoch [97/100], Step [36300/6235], Loss: 0.3983\n",
      "Epoch [97/100], Step [36400/6235], Loss: 2.6605\n",
      "Epoch [97/100], Step [36500/6235], Loss: 8.3357\n",
      "Epoch [97/100], Step [36600/6235], Loss: 0.1318\n",
      "Epoch [97/100], Step [36700/6235], Loss: 0.5145\n",
      "Epoch [97/100], Step [36800/6235], Loss: 9.6829\n",
      "Epoch [97/100], Step [36900/6235], Loss: 8.9846\n",
      "Epoch [97/100], Step [37000/6235], Loss: 0.7063\n",
      "Epoch [97/100], Step [37100/6235], Loss: 1.4254\n",
      "Epoch [97/100], Step [37200/6235], Loss: 0.0700\n",
      "Epoch [97/100], Step [37300/6235], Loss: 0.0320\n",
      "Epoch [97/100], Step [37400/6235], Loss: 0.1942\n",
      "Epoch [97/100], Step [37500/6235], Loss: 5.0219\n",
      "Epoch [97/100], Step [37600/6235], Loss: 11.8518\n",
      "Epoch [97/100], Step [37700/6235], Loss: 1.6011\n",
      "Epoch [97/100], Step [37800/6235], Loss: 5.2537\n",
      "Epoch [97/100], Step [37900/6235], Loss: 5.7591\n",
      "Epoch [97/100], Step [38000/6235], Loss: 0.6892\n",
      "Epoch [97/100], Step [38100/6235], Loss: 4.4350\n",
      "Epoch [97/100], Step [38200/6235], Loss: 2.4025\n",
      "Epoch [97/100], Step [38300/6235], Loss: 0.8029\n",
      "Epoch [97/100], Step [38400/6235], Loss: 0.1086\n",
      "Epoch [97/100], Step [38500/6235], Loss: 2.8713\n",
      "Epoch [97/100], Step [38600/6235], Loss: 0.1609\n",
      "Epoch [97/100], Step [38700/6235], Loss: 0.0423\n",
      "Epoch [97/100], Step [38800/6235], Loss: 0.2212\n",
      "Epoch [97/100], Step [38900/6235], Loss: 12.1003\n",
      "Epoch [97/100], Step [39000/6235], Loss: 19.3295\n",
      "Epoch [97/100], Step [39100/6235], Loss: 17.5321\n",
      "Epoch [97/100], Step [39200/6235], Loss: 0.6326\n",
      "Epoch [97/100], Step [39300/6235], Loss: 5.9041\n",
      "Epoch [97/100], Step [39400/6235], Loss: 216.2600\n",
      "Epoch [97/100], Step [39500/6235], Loss: 105.1613\n",
      "Epoch [97/100], Step [39600/6235], Loss: 2.8223\n",
      "Epoch [97/100], Step [39700/6235], Loss: 204.6656\n",
      "Epoch [97/100], Step [39800/6235], Loss: 64.2819\n",
      "Epoch [97/100], Step [39900/6235], Loss: 5.3220\n",
      "Epoch [97/100], Step [40000/6235], Loss: 4.4518\n",
      "Epoch [97/100], Step [40100/6235], Loss: 12.1017\n",
      "Epoch [97/100], Step [40200/6235], Loss: 9.7566\n",
      "Epoch [97/100], Step [40300/6235], Loss: 0.8358\n",
      "Epoch [97/100], Step [40400/6235], Loss: 0.6305\n",
      "Epoch [97/100], Step [40500/6235], Loss: 3.0989\n",
      "Epoch [97/100], Step [40600/6235], Loss: 0.2337\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [97/100], Step [40700/6235], Loss: 6.0101\n",
      "Epoch [97/100], Step [40800/6235], Loss: 0.6478\n",
      "Epoch [97/100], Step [40900/6235], Loss: 1.1949\n",
      "Epoch [97/100], Step [41000/6235], Loss: 44.2611\n",
      "Epoch [97/100], Step [41100/6235], Loss: 50.1697\n",
      "Epoch [97/100], Step [41200/6235], Loss: 35.8531\n",
      "Epoch [97/100], Step [41300/6235], Loss: 6.5320\n",
      "Epoch [97/100], Step [41400/6235], Loss: 3.0110\n",
      "Epoch [97/100], Step [41500/6235], Loss: 1.0842\n",
      "Epoch [97/100], Step [41600/6235], Loss: 0.2690\n",
      "Epoch [97/100], Step [41700/6235], Loss: 0.7464\n",
      "Epoch [97/100], Step [41800/6235], Loss: 2.7925\n",
      "Epoch [97/100], Step [41900/6235], Loss: 4.6465\n",
      "Epoch [97/100], Step [42000/6235], Loss: 4.3468\n",
      "Epoch [97/100], Step [42100/6235], Loss: 9.9470\n",
      "Epoch [97/100], Step [42200/6235], Loss: 30.7047\n",
      "Epoch [97/100], Step [42300/6235], Loss: 1.8398\n",
      "Epoch [97/100], Step [42400/6235], Loss: 5.8051\n",
      "Epoch [97/100], Step [42500/6235], Loss: 1.0341\n",
      "Epoch [97/100], Step [42600/6235], Loss: 1.4109\n",
      "Epoch [97/100], Step [42700/6235], Loss: 0.6844\n",
      "Epoch [97/100], Step [42800/6235], Loss: 9.3298\n",
      "Epoch [97/100], Step [42900/6235], Loss: 1.8135\n",
      "Epoch [97/100], Step [43000/6235], Loss: 0.1702\n",
      "Epoch [97/100], Step [43100/6235], Loss: 0.0331\n",
      "Epoch [97/100], Step [43200/6235], Loss: 0.8557\n",
      "Epoch [97/100], Step [43300/6235], Loss: 7.3057\n",
      "Epoch [97/100], Step [43400/6235], Loss: 10.2149\n",
      "Epoch [97/100], Step [43500/6235], Loss: 9.9167\n",
      "Epoch [97/100], Step [43600/6235], Loss: 6.1865\n",
      "Epoch [97/100], Step [43700/6235], Loss: 42.6933\n",
      "Epoch [97/100], Step [43800/6235], Loss: 0.5311\n",
      "Epoch [97/100], Step [43900/6235], Loss: 2.0443\n",
      "Epoch [97/100], Step [44000/6235], Loss: 54.9589\n",
      "Epoch [97/100], Step [44100/6235], Loss: 2.4817\n",
      "Epoch [97/100], Step [44200/6235], Loss: 5.0880\n",
      "Epoch [97/100], Step [44300/6235], Loss: 16.9634\n",
      "Epoch [97/100], Step [44400/6235], Loss: 0.8713\n",
      "Epoch [97/100], Step [44500/6235], Loss: 3.7424\n",
      "Epoch [97/100], Step [44600/6235], Loss: 21.1506\n",
      "Epoch [97/100], Step [44700/6235], Loss: 4.1714\n",
      "Epoch [97/100], Step [44800/6235], Loss: 0.9325\n",
      "Epoch [97/100], Step [44900/6235], Loss: 12.4515\n",
      "Epoch [97/100], Step [45000/6235], Loss: 6.4233\n",
      "Epoch [97/100], Step [45100/6235], Loss: 70.1978\n",
      "Epoch [97/100], Step [45200/6235], Loss: 8.6374\n",
      "Epoch [97/100], Step [45300/6235], Loss: 24.5446\n",
      "Epoch [97/100], Step [45400/6235], Loss: 10.4326\n",
      "Epoch [97/100], Step [45500/6235], Loss: 3.2819\n",
      "Epoch [97/100], Step [45600/6235], Loss: 1.4783\n",
      "Epoch [97/100], Step [45700/6235], Loss: 110.4172\n",
      "Epoch [97/100], Step [45800/6235], Loss: 254.1739\n",
      "Epoch [97/100], Step [45900/6235], Loss: 15.3026\n",
      "Epoch [97/100], Step [46000/6235], Loss: 46.5099\n",
      "Epoch [97/100], Step [46100/6235], Loss: 80.9250\n",
      "Epoch [97/100], Step [46200/6235], Loss: 125.9560\n",
      "Epoch [97/100], Step [46300/6235], Loss: 23.1653\n",
      "Epoch [97/100], Step [46400/6235], Loss: 2.6486\n",
      "Epoch [97/100], Step [46500/6235], Loss: 458.9172\n",
      "Epoch [97/100], Step [46600/6235], Loss: 9.2219\n",
      "Epoch [97/100], Step [46700/6235], Loss: 46.4383\n",
      "Epoch [97/100], Step [46800/6235], Loss: 2.0671\n",
      "Epoch [97/100], Step [46900/6235], Loss: 0.5413\n",
      "Epoch [97/100], Step [47000/6235], Loss: 7.8306\n",
      "Epoch [97/100], Step [47100/6235], Loss: 17.1169\n",
      "Epoch [97/100], Step [47200/6235], Loss: 10.2074\n",
      "Epoch [97/100], Step [47300/6235], Loss: 1.2541\n",
      "Epoch [97/100], Step [47400/6235], Loss: 21.8691\n",
      "Epoch [97/100], Step [47500/6235], Loss: 26.1394\n",
      "Epoch [97/100], Step [47600/6235], Loss: 14.2862\n",
      "Epoch [97/100], Step [47700/6235], Loss: 34.4599\n",
      "Epoch [97/100], Step [47800/6235], Loss: 27.5506\n",
      "Epoch [97/100], Step [47900/6235], Loss: 12.6917\n",
      "Epoch [97/100], Step [48000/6235], Loss: 28.1873\n",
      "Epoch [97/100], Step [48100/6235], Loss: 6.1196\n",
      "Epoch [97/100], Step [48200/6235], Loss: 95.5201\n",
      "Epoch [97/100], Step [48300/6235], Loss: 641.3490\n",
      "Epoch [97/100], Step [48400/6235], Loss: 12.5199\n",
      "Epoch [97/100], Step [48500/6235], Loss: 41.4953\n",
      "Epoch [97/100], Step [48600/6235], Loss: 86.4820\n",
      "Epoch [97/100], Step [48700/6235], Loss: 1.7516\n",
      "Epoch [97/100], Step [48800/6235], Loss: 163.3860\n",
      "Epoch [97/100], Step [48900/6235], Loss: 198.6472\n",
      "Epoch [97/100], Step [49000/6235], Loss: 264.3502\n",
      "Epoch [97/100], Step [49100/6235], Loss: 2262.4119\n",
      "Epoch [97/100], Step [49200/6235], Loss: 939.0768\n",
      "Epoch [97/100], Step [49300/6235], Loss: 1171.4728\n",
      "Epoch [97/100], Step [49400/6235], Loss: 26.7623\n",
      "Epoch [97/100], Step [49500/6235], Loss: 30.4409\n",
      "Epoch [97/100], Step [49600/6235], Loss: 571.5167\n",
      "Epoch [97/100], Step [49700/6235], Loss: 217.2129\n",
      "Epoch [97/100], Step [49800/6235], Loss: 457.9755\n",
      "Epoch [98/100], Step [100/6235], Loss: 1.9797\n",
      "Epoch [98/100], Step [200/6235], Loss: 0.1380\n",
      "Epoch [98/100], Step [300/6235], Loss: 0.0321\n",
      "Epoch [98/100], Step [400/6235], Loss: 0.0071\n",
      "Epoch [98/100], Step [500/6235], Loss: 13.0729\n",
      "Epoch [98/100], Step [600/6235], Loss: 0.0628\n",
      "Epoch [98/100], Step [700/6235], Loss: 0.6659\n",
      "Epoch [98/100], Step [800/6235], Loss: 0.1242\n",
      "Epoch [98/100], Step [900/6235], Loss: 0.0551\n",
      "Epoch [98/100], Step [1000/6235], Loss: 0.0354\n",
      "Epoch [98/100], Step [1100/6235], Loss: 0.0278\n",
      "Epoch [98/100], Step [1200/6235], Loss: 0.1735\n",
      "Epoch [98/100], Step [1300/6235], Loss: 0.0292\n",
      "Epoch [98/100], Step [1400/6235], Loss: 0.0380\n",
      "Epoch [98/100], Step [1500/6235], Loss: 0.0073\n",
      "Epoch [98/100], Step [1600/6235], Loss: 0.2275\n",
      "Epoch [98/100], Step [1700/6235], Loss: 0.0263\n",
      "Epoch [98/100], Step [1800/6235], Loss: 0.1992\n",
      "Epoch [98/100], Step [1900/6235], Loss: 0.4619\n",
      "Epoch [98/100], Step [2000/6235], Loss: 2.3004\n",
      "Epoch [98/100], Step [2100/6235], Loss: 1.5811\n",
      "Epoch [98/100], Step [2200/6235], Loss: 8.4258\n",
      "Epoch [98/100], Step [2300/6235], Loss: 6.8195\n",
      "Epoch [98/100], Step [2400/6235], Loss: 1.8659\n",
      "Epoch [98/100], Step [2500/6235], Loss: 35.3263\n",
      "Epoch [98/100], Step [2600/6235], Loss: 12.4085\n",
      "Epoch [98/100], Step [2700/6235], Loss: 9.0043\n",
      "Epoch [98/100], Step [2800/6235], Loss: 348.9727\n",
      "Epoch [98/100], Step [2900/6235], Loss: 9.9312\n",
      "Epoch [98/100], Step [3000/6235], Loss: 0.3993\n",
      "Epoch [98/100], Step [3100/6235], Loss: 68.0243\n",
      "Epoch [98/100], Step [3200/6235], Loss: 85.2274\n",
      "Epoch [98/100], Step [3300/6235], Loss: 4.9996\n",
      "Epoch [98/100], Step [3400/6235], Loss: 2.3420\n",
      "Epoch [98/100], Step [3500/6235], Loss: 31.9363\n",
      "Epoch [98/100], Step [3600/6235], Loss: 10.2634\n",
      "Epoch [98/100], Step [3700/6235], Loss: 0.3548\n",
      "Epoch [98/100], Step [3800/6235], Loss: 0.4389\n",
      "Epoch [98/100], Step [3900/6235], Loss: 1.4220\n",
      "Epoch [98/100], Step [4000/6235], Loss: 0.0358\n",
      "Epoch [98/100], Step [4100/6235], Loss: 6.1429\n",
      "Epoch [98/100], Step [4200/6235], Loss: 0.3779\n",
      "Epoch [98/100], Step [4300/6235], Loss: 9.3215\n",
      "Epoch [98/100], Step [4400/6235], Loss: 4.2830\n",
      "Epoch [98/100], Step [4500/6235], Loss: 43.9171\n",
      "Epoch [98/100], Step [4600/6235], Loss: 4.8856\n",
      "Epoch [98/100], Step [4700/6235], Loss: 0.6435\n",
      "Epoch [98/100], Step [4800/6235], Loss: 7.2478\n",
      "Epoch [98/100], Step [4900/6235], Loss: 0.1027\n",
      "Epoch [98/100], Step [5000/6235], Loss: 0.0743\n",
      "Epoch [98/100], Step [5100/6235], Loss: 2.9294\n",
      "Epoch [98/100], Step [5200/6235], Loss: 1.1529\n",
      "Epoch [98/100], Step [5300/6235], Loss: 38.1604\n",
      "Epoch [98/100], Step [5400/6235], Loss: 0.9636\n",
      "Epoch [98/100], Step [5500/6235], Loss: 0.1877\n",
      "Epoch [98/100], Step [5600/6235], Loss: 0.3500\n",
      "Epoch [98/100], Step [5700/6235], Loss: 0.6877\n",
      "Epoch [98/100], Step [5800/6235], Loss: 0.4498\n",
      "Epoch [98/100], Step [5900/6235], Loss: 0.1696\n",
      "Epoch [98/100], Step [6000/6235], Loss: 2.2273\n",
      "Epoch [98/100], Step [6100/6235], Loss: 0.2885\n",
      "Epoch [98/100], Step [6200/6235], Loss: 1.7272\n",
      "Epoch [98/100], Step [6300/6235], Loss: 2.1166\n",
      "Epoch [98/100], Step [6400/6235], Loss: 0.0259\n",
      "Epoch [98/100], Step [6500/6235], Loss: 1.0049\n",
      "Epoch [98/100], Step [6600/6235], Loss: 4.5162\n",
      "Epoch [98/100], Step [6700/6235], Loss: 2.7804\n",
      "Epoch [98/100], Step [6800/6235], Loss: 0.1495\n",
      "Epoch [98/100], Step [6900/6235], Loss: 1.1287\n",
      "Epoch [98/100], Step [7000/6235], Loss: 0.9563\n",
      "Epoch [98/100], Step [7100/6235], Loss: 0.1412\n",
      "Epoch [98/100], Step [7200/6235], Loss: 0.1636\n",
      "Epoch [98/100], Step [7300/6235], Loss: 0.1319\n",
      "Epoch [98/100], Step [7400/6235], Loss: 0.2632\n",
      "Epoch [98/100], Step [7500/6235], Loss: 1.0176\n",
      "Epoch [98/100], Step [7600/6235], Loss: 5.7183\n",
      "Epoch [98/100], Step [7700/6235], Loss: 19.9454\n",
      "Epoch [98/100], Step [7800/6235], Loss: 10.0837\n",
      "Epoch [98/100], Step [7900/6235], Loss: 4.4157\n",
      "Epoch [98/100], Step [8000/6235], Loss: 0.3352\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Step [8100/6235], Loss: 4.2736\n",
      "Epoch [98/100], Step [8200/6235], Loss: 19.1166\n",
      "Epoch [98/100], Step [8300/6235], Loss: 64.8070\n",
      "Epoch [98/100], Step [8400/6235], Loss: 100.5618\n",
      "Epoch [98/100], Step [8500/6235], Loss: 44.7057\n",
      "Epoch [98/100], Step [8600/6235], Loss: 81.7781\n",
      "Epoch [98/100], Step [8700/6235], Loss: 110.5998\n",
      "Epoch [98/100], Step [8800/6235], Loss: 555.4764\n",
      "Epoch [98/100], Step [8900/6235], Loss: 8.7405\n",
      "Epoch [98/100], Step [9000/6235], Loss: 670.6476\n",
      "Epoch [98/100], Step [9100/6235], Loss: 2997.6750\n",
      "Epoch [98/100], Step [9200/6235], Loss: 6468.4453\n",
      "Epoch [98/100], Step [9300/6235], Loss: 52.5751\n",
      "Epoch [98/100], Step [9400/6235], Loss: 33.6769\n",
      "Epoch [98/100], Step [9500/6235], Loss: 1927.6187\n",
      "Epoch [98/100], Step [9600/6235], Loss: 1024.1855\n",
      "Epoch [98/100], Step [9700/6235], Loss: 1.3182\n",
      "Epoch [98/100], Step [9800/6235], Loss: 4472.8066\n",
      "Epoch [98/100], Step [9900/6235], Loss: 175.5923\n",
      "Epoch [98/100], Step [10000/6235], Loss: 170.6744\n",
      "Epoch [98/100], Step [10100/6235], Loss: 2.5128\n",
      "Epoch [98/100], Step [10200/6235], Loss: 980.9191\n",
      "Epoch [98/100], Step [10300/6235], Loss: 33.9445\n",
      "Epoch [98/100], Step [10400/6235], Loss: 8.7402\n",
      "Epoch [98/100], Step [10500/6235], Loss: 9.7078\n",
      "Epoch [98/100], Step [10600/6235], Loss: 453.5902\n",
      "Epoch [98/100], Step [10700/6235], Loss: 22.2167\n",
      "Epoch [98/100], Step [10800/6235], Loss: 115.8938\n",
      "Epoch [98/100], Step [10900/6235], Loss: 103.1604\n",
      "Epoch [98/100], Step [11000/6235], Loss: 297.3272\n",
      "Epoch [98/100], Step [11100/6235], Loss: 27.3569\n",
      "Epoch [98/100], Step [11200/6235], Loss: 3.8789\n",
      "Epoch [98/100], Step [11300/6235], Loss: 99.0929\n",
      "Epoch [98/100], Step [11400/6235], Loss: 13.9631\n",
      "Epoch [98/100], Step [11500/6235], Loss: 10.8567\n",
      "Epoch [98/100], Step [11600/6235], Loss: 8.2529\n",
      "Epoch [98/100], Step [11700/6235], Loss: 45.2578\n",
      "Epoch [98/100], Step [11800/6235], Loss: 389.8663\n",
      "Epoch [98/100], Step [11900/6235], Loss: 29.6639\n",
      "Epoch [98/100], Step [12000/6235], Loss: 739.4187\n",
      "Epoch [98/100], Step [12100/6235], Loss: 247.0968\n",
      "Epoch [98/100], Step [12200/6235], Loss: 11.3505\n",
      "Epoch [98/100], Step [12300/6235], Loss: 2.0115\n",
      "Epoch [98/100], Step [12400/6235], Loss: 127.5271\n",
      "Epoch [98/100], Step [12500/6235], Loss: 34.8284\n",
      "Epoch [98/100], Step [12600/6235], Loss: 21.1963\n",
      "Epoch [98/100], Step [12700/6235], Loss: 9.2223\n",
      "Epoch [98/100], Step [12800/6235], Loss: 8.4816\n",
      "Epoch [98/100], Step [12900/6235], Loss: 33.4909\n",
      "Epoch [98/100], Step [13000/6235], Loss: 0.1266\n",
      "Epoch [98/100], Step [13100/6235], Loss: 64.1166\n",
      "Epoch [98/100], Step [13200/6235], Loss: 8.8255\n",
      "Epoch [98/100], Step [13300/6235], Loss: 35.2884\n",
      "Epoch [98/100], Step [13400/6235], Loss: 237.8886\n",
      "Epoch [98/100], Step [13500/6235], Loss: 1.9372\n",
      "Epoch [98/100], Step [13600/6235], Loss: 0.3041\n",
      "Epoch [98/100], Step [13700/6235], Loss: 53.8374\n",
      "Epoch [98/100], Step [13800/6235], Loss: 124.3791\n",
      "Epoch [98/100], Step [13900/6235], Loss: 50.7353\n",
      "Epoch [98/100], Step [14000/6235], Loss: 15.7872\n",
      "Epoch [98/100], Step [14100/6235], Loss: 28.3553\n",
      "Epoch [98/100], Step [14200/6235], Loss: 16.6449\n",
      "Epoch [98/100], Step [14300/6235], Loss: 35.1590\n",
      "Epoch [98/100], Step [14400/6235], Loss: 38.0835\n",
      "Epoch [98/100], Step [14500/6235], Loss: 29.5745\n",
      "Epoch [98/100], Step [14600/6235], Loss: 1.0811\n",
      "Epoch [98/100], Step [14700/6235], Loss: 34.4359\n",
      "Epoch [98/100], Step [14800/6235], Loss: 32.8867\n",
      "Epoch [98/100], Step [14900/6235], Loss: 0.6729\n",
      "Epoch [98/100], Step [15000/6235], Loss: 1.4573\n",
      "Epoch [98/100], Step [15100/6235], Loss: 0.5478\n",
      "Epoch [98/100], Step [15200/6235], Loss: 9.5171\n",
      "Epoch [98/100], Step [15300/6235], Loss: 33.0277\n",
      "Epoch [98/100], Step [15400/6235], Loss: 102.2915\n",
      "Epoch [98/100], Step [15500/6235], Loss: 14.0038\n",
      "Epoch [98/100], Step [15600/6235], Loss: 166.8219\n",
      "Epoch [98/100], Step [15700/6235], Loss: 147.0734\n",
      "Epoch [98/100], Step [15800/6235], Loss: 0.1543\n",
      "Epoch [98/100], Step [15900/6235], Loss: 2.5661\n",
      "Epoch [98/100], Step [16000/6235], Loss: 92.4306\n",
      "Epoch [98/100], Step [16100/6235], Loss: 1.4395\n",
      "Epoch [98/100], Step [16200/6235], Loss: 2.0120\n",
      "Epoch [98/100], Step [16300/6235], Loss: 8.7956\n",
      "Epoch [98/100], Step [16400/6235], Loss: 25.3177\n",
      "Epoch [98/100], Step [16500/6235], Loss: 167.0406\n",
      "Epoch [98/100], Step [16600/6235], Loss: 24.9394\n",
      "Epoch [98/100], Step [16700/6235], Loss: 0.5691\n",
      "Epoch [98/100], Step [16800/6235], Loss: 9.5512\n",
      "Epoch [98/100], Step [16900/6235], Loss: 0.2181\n",
      "Epoch [98/100], Step [17000/6235], Loss: 0.2053\n",
      "Epoch [98/100], Step [17100/6235], Loss: 0.1512\n",
      "Epoch [98/100], Step [17200/6235], Loss: 270.8743\n",
      "Epoch [98/100], Step [17300/6235], Loss: 75.3624\n",
      "Epoch [98/100], Step [17400/6235], Loss: 40.0708\n",
      "Epoch [98/100], Step [17500/6235], Loss: 0.8798\n",
      "Epoch [98/100], Step [17600/6235], Loss: 2.6349\n",
      "Epoch [98/100], Step [17700/6235], Loss: 149.7391\n",
      "Epoch [98/100], Step [17800/6235], Loss: 31.2526\n",
      "Epoch [98/100], Step [17900/6235], Loss: 9.3266\n",
      "Epoch [98/100], Step [18000/6235], Loss: 10.1087\n",
      "Epoch [98/100], Step [18100/6235], Loss: 16.7614\n",
      "Epoch [98/100], Step [18200/6235], Loss: 0.6887\n",
      "Epoch [98/100], Step [18300/6235], Loss: 6.0418\n",
      "Epoch [98/100], Step [18400/6235], Loss: 5.5318\n",
      "Epoch [98/100], Step [18500/6235], Loss: 14.3788\n",
      "Epoch [98/100], Step [18600/6235], Loss: 1.1724\n",
      "Epoch [98/100], Step [18700/6235], Loss: 0.4048\n",
      "Epoch [98/100], Step [18800/6235], Loss: 60.9819\n",
      "Epoch [98/100], Step [18900/6235], Loss: 17.2875\n",
      "Epoch [98/100], Step [19000/6235], Loss: 5.2645\n",
      "Epoch [98/100], Step [19100/6235], Loss: 0.7450\n",
      "Epoch [98/100], Step [19200/6235], Loss: 5.4311\n",
      "Epoch [98/100], Step [19300/6235], Loss: 2.3431\n",
      "Epoch [98/100], Step [19400/6235], Loss: 289.4958\n",
      "Epoch [98/100], Step [19500/6235], Loss: 127.2436\n",
      "Epoch [98/100], Step [19600/6235], Loss: 106.7192\n",
      "Epoch [98/100], Step [19700/6235], Loss: 4.9118\n",
      "Epoch [98/100], Step [19800/6235], Loss: 0.8963\n",
      "Epoch [98/100], Step [19900/6235], Loss: 1.0568\n",
      "Epoch [98/100], Step [20000/6235], Loss: 88.8938\n",
      "Epoch [98/100], Step [20100/6235], Loss: 5.6642\n",
      "Epoch [98/100], Step [20200/6235], Loss: 3.4329\n",
      "Epoch [98/100], Step [20300/6235], Loss: 1.0574\n",
      "Epoch [98/100], Step [20400/6235], Loss: 27.4204\n",
      "Epoch [98/100], Step [20500/6235], Loss: 31.1225\n",
      "Epoch [98/100], Step [20600/6235], Loss: 11.1400\n",
      "Epoch [98/100], Step [20700/6235], Loss: 5.1613\n",
      "Epoch [98/100], Step [20800/6235], Loss: 2.3155\n",
      "Epoch [98/100], Step [20900/6235], Loss: 45.2218\n",
      "Epoch [98/100], Step [21000/6235], Loss: 14.5236\n",
      "Epoch [98/100], Step [21100/6235], Loss: 5.4628\n",
      "Epoch [98/100], Step [21200/6235], Loss: 0.2303\n",
      "Epoch [98/100], Step [21300/6235], Loss: 0.2095\n",
      "Epoch [98/100], Step [21400/6235], Loss: 6.1311\n",
      "Epoch [98/100], Step [21500/6235], Loss: 0.4946\n",
      "Epoch [98/100], Step [21600/6235], Loss: 30.7034\n",
      "Epoch [98/100], Step [21700/6235], Loss: 0.2166\n",
      "Epoch [98/100], Step [21800/6235], Loss: 0.4103\n",
      "Epoch [98/100], Step [21900/6235], Loss: 0.4983\n",
      "Epoch [98/100], Step [22000/6235], Loss: 3.8781\n",
      "Epoch [98/100], Step [22100/6235], Loss: 3.2633\n",
      "Epoch [98/100], Step [22200/6235], Loss: 7.4315\n",
      "Epoch [98/100], Step [22300/6235], Loss: 0.4459\n",
      "Epoch [98/100], Step [22400/6235], Loss: 7.9335\n",
      "Epoch [98/100], Step [22500/6235], Loss: 91.9734\n",
      "Epoch [98/100], Step [22600/6235], Loss: 10.8120\n",
      "Epoch [98/100], Step [22700/6235], Loss: 0.9132\n",
      "Epoch [98/100], Step [22800/6235], Loss: 3.9687\n",
      "Epoch [98/100], Step [22900/6235], Loss: 2.8270\n",
      "Epoch [98/100], Step [23000/6235], Loss: 15.7849\n",
      "Epoch [98/100], Step [23100/6235], Loss: 0.6936\n",
      "Epoch [98/100], Step [23200/6235], Loss: 9.7075\n",
      "Epoch [98/100], Step [23300/6235], Loss: 18.7263\n",
      "Epoch [98/100], Step [23400/6235], Loss: 0.9606\n",
      "Epoch [98/100], Step [23500/6235], Loss: 0.2419\n",
      "Epoch [98/100], Step [23600/6235], Loss: 111.4432\n",
      "Epoch [98/100], Step [23700/6235], Loss: 2.7821\n",
      "Epoch [98/100], Step [23800/6235], Loss: 1.0533\n",
      "Epoch [98/100], Step [23900/6235], Loss: 7.5904\n",
      "Epoch [98/100], Step [24000/6235], Loss: 0.2598\n",
      "Epoch [98/100], Step [24100/6235], Loss: 0.2874\n",
      "Epoch [98/100], Step [24200/6235], Loss: 50.9134\n",
      "Epoch [98/100], Step [24300/6235], Loss: 1.1560\n",
      "Epoch [98/100], Step [24400/6235], Loss: 3.6174\n",
      "Epoch [98/100], Step [24500/6235], Loss: 1.8739\n",
      "Epoch [98/100], Step [24600/6235], Loss: 0.1141\n",
      "Epoch [98/100], Step [24700/6235], Loss: 2.5810\n",
      "Epoch [98/100], Step [24800/6235], Loss: 0.1419\n",
      "Epoch [98/100], Step [24900/6235], Loss: 10.8508\n",
      "Epoch [98/100], Step [25000/6235], Loss: 19.1715\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Step [25100/6235], Loss: 8.8737\n",
      "Epoch [98/100], Step [25200/6235], Loss: 1.5363\n",
      "Epoch [98/100], Step [25300/6235], Loss: 0.6103\n",
      "Epoch [98/100], Step [25400/6235], Loss: 9.6082\n",
      "Epoch [98/100], Step [25500/6235], Loss: 5.3869\n",
      "Epoch [98/100], Step [25600/6235], Loss: 2.4953\n",
      "Epoch [98/100], Step [25700/6235], Loss: 0.3414\n",
      "Epoch [98/100], Step [25800/6235], Loss: 0.1526\n",
      "Epoch [98/100], Step [25900/6235], Loss: 10.2761\n",
      "Epoch [98/100], Step [26000/6235], Loss: 0.5436\n",
      "Epoch [98/100], Step [26100/6235], Loss: 0.4943\n",
      "Epoch [98/100], Step [26200/6235], Loss: 0.0163\n",
      "Epoch [98/100], Step [26300/6235], Loss: 4.4721\n",
      "Epoch [98/100], Step [26400/6235], Loss: 0.1198\n",
      "Epoch [98/100], Step [26500/6235], Loss: 0.1300\n",
      "Epoch [98/100], Step [26600/6235], Loss: 2.8359\n",
      "Epoch [98/100], Step [26700/6235], Loss: 0.5789\n",
      "Epoch [98/100], Step [26800/6235], Loss: 0.4509\n",
      "Epoch [98/100], Step [26900/6235], Loss: 0.0192\n",
      "Epoch [98/100], Step [27000/6235], Loss: 13.1300\n",
      "Epoch [98/100], Step [27100/6235], Loss: 0.1295\n",
      "Epoch [98/100], Step [27200/6235], Loss: 0.0561\n",
      "Epoch [98/100], Step [27300/6235], Loss: 0.2161\n",
      "Epoch [98/100], Step [27400/6235], Loss: 0.8684\n",
      "Epoch [98/100], Step [27500/6235], Loss: 25.4482\n",
      "Epoch [98/100], Step [27600/6235], Loss: 1.0651\n",
      "Epoch [98/100], Step [27700/6235], Loss: 1.4055\n",
      "Epoch [98/100], Step [27800/6235], Loss: 0.2289\n",
      "Epoch [98/100], Step [27900/6235], Loss: 0.1443\n",
      "Epoch [98/100], Step [28000/6235], Loss: 113.3445\n",
      "Epoch [98/100], Step [28100/6235], Loss: 5.8904\n",
      "Epoch [98/100], Step [28200/6235], Loss: 35.6175\n",
      "Epoch [98/100], Step [28300/6235], Loss: 3.5757\n",
      "Epoch [98/100], Step [28400/6235], Loss: 27.0921\n",
      "Epoch [98/100], Step [28500/6235], Loss: 4.4798\n",
      "Epoch [98/100], Step [28600/6235], Loss: 0.0440\n",
      "Epoch [98/100], Step [28700/6235], Loss: 5.5218\n",
      "Epoch [98/100], Step [28800/6235], Loss: 0.5616\n",
      "Epoch [98/100], Step [28900/6235], Loss: 74.0420\n",
      "Epoch [98/100], Step [29000/6235], Loss: 11.7804\n",
      "Epoch [98/100], Step [29100/6235], Loss: 0.0897\n",
      "Epoch [98/100], Step [29200/6235], Loss: 0.5623\n",
      "Epoch [98/100], Step [29300/6235], Loss: 11.8598\n",
      "Epoch [98/100], Step [29400/6235], Loss: 0.3736\n",
      "Epoch [98/100], Step [29500/6235], Loss: 3.0267\n",
      "Epoch [98/100], Step [29600/6235], Loss: 0.8925\n",
      "Epoch [98/100], Step [29700/6235], Loss: 0.8121\n",
      "Epoch [98/100], Step [29800/6235], Loss: 1.7123\n",
      "Epoch [98/100], Step [29900/6235], Loss: 0.7924\n",
      "Epoch [98/100], Step [30000/6235], Loss: 5.4842\n",
      "Epoch [98/100], Step [30100/6235], Loss: 11.5559\n",
      "Epoch [98/100], Step [30200/6235], Loss: 0.6255\n",
      "Epoch [98/100], Step [30300/6235], Loss: 0.0395\n",
      "Epoch [98/100], Step [30400/6235], Loss: 0.6844\n",
      "Epoch [98/100], Step [30500/6235], Loss: 3.1709\n",
      "Epoch [98/100], Step [30600/6235], Loss: 1.4436\n",
      "Epoch [98/100], Step [30700/6235], Loss: 0.1344\n",
      "Epoch [98/100], Step [30800/6235], Loss: 0.4086\n",
      "Epoch [98/100], Step [30900/6235], Loss: 3.9382\n",
      "Epoch [98/100], Step [31000/6235], Loss: 0.0665\n",
      "Epoch [98/100], Step [31100/6235], Loss: 0.0391\n",
      "Epoch [98/100], Step [31200/6235], Loss: 6.0207\n",
      "Epoch [98/100], Step [31300/6235], Loss: 0.5408\n",
      "Epoch [98/100], Step [31400/6235], Loss: 4.0210\n",
      "Epoch [98/100], Step [31500/6235], Loss: 0.6918\n",
      "Epoch [98/100], Step [31600/6235], Loss: 8.9506\n",
      "Epoch [98/100], Step [31700/6235], Loss: 0.3972\n",
      "Epoch [98/100], Step [31800/6235], Loss: 1.0592\n",
      "Epoch [98/100], Step [31900/6235], Loss: 747.0041\n",
      "Epoch [98/100], Step [32000/6235], Loss: 21.3275\n",
      "Epoch [98/100], Step [32100/6235], Loss: 0.3623\n",
      "Epoch [98/100], Step [32200/6235], Loss: 104.3684\n",
      "Epoch [98/100], Step [32300/6235], Loss: 1.3510\n",
      "Epoch [98/100], Step [32400/6235], Loss: 1.5210\n",
      "Epoch [98/100], Step [32500/6235], Loss: 11.7483\n",
      "Epoch [98/100], Step [32600/6235], Loss: 0.3989\n",
      "Epoch [98/100], Step [32700/6235], Loss: 134.5656\n",
      "Epoch [98/100], Step [32800/6235], Loss: 6.3677\n",
      "Epoch [98/100], Step [32900/6235], Loss: 0.1453\n",
      "Epoch [98/100], Step [33000/6235], Loss: 0.1950\n",
      "Epoch [98/100], Step [33100/6235], Loss: 0.5005\n",
      "Epoch [98/100], Step [33200/6235], Loss: 1.0361\n",
      "Epoch [98/100], Step [33300/6235], Loss: 2.5652\n",
      "Epoch [98/100], Step [33400/6235], Loss: 19.4380\n",
      "Epoch [98/100], Step [33500/6235], Loss: 2.0620\n",
      "Epoch [98/100], Step [33600/6235], Loss: 6.7480\n",
      "Epoch [98/100], Step [33700/6235], Loss: 7.2507\n",
      "Epoch [98/100], Step [33800/6235], Loss: 1.6774\n",
      "Epoch [98/100], Step [33900/6235], Loss: 26.6233\n",
      "Epoch [98/100], Step [34000/6235], Loss: 0.0471\n",
      "Epoch [98/100], Step [34100/6235], Loss: 0.4470\n",
      "Epoch [98/100], Step [34200/6235], Loss: 2.3383\n",
      "Epoch [98/100], Step [34300/6235], Loss: 5.1056\n",
      "Epoch [98/100], Step [34400/6235], Loss: 0.2269\n",
      "Epoch [98/100], Step [34500/6235], Loss: 31.4640\n",
      "Epoch [98/100], Step [34600/6235], Loss: 0.8324\n",
      "Epoch [98/100], Step [34700/6235], Loss: 4.4021\n",
      "Epoch [98/100], Step [34800/6235], Loss: 14.0305\n",
      "Epoch [98/100], Step [34900/6235], Loss: 69.3754\n",
      "Epoch [98/100], Step [35000/6235], Loss: 0.1815\n",
      "Epoch [98/100], Step [35100/6235], Loss: 0.4645\n",
      "Epoch [98/100], Step [35200/6235], Loss: 0.3772\n",
      "Epoch [98/100], Step [35300/6235], Loss: 2.9020\n",
      "Epoch [98/100], Step [35400/6235], Loss: 0.4470\n",
      "Epoch [98/100], Step [35500/6235], Loss: 1.6266\n",
      "Epoch [98/100], Step [35600/6235], Loss: 0.4366\n",
      "Epoch [98/100], Step [35700/6235], Loss: 5.5886\n",
      "Epoch [98/100], Step [35800/6235], Loss: 0.1465\n",
      "Epoch [98/100], Step [35900/6235], Loss: 0.5072\n",
      "Epoch [98/100], Step [36000/6235], Loss: 0.2574\n",
      "Epoch [98/100], Step [36100/6235], Loss: 0.0230\n",
      "Epoch [98/100], Step [36200/6235], Loss: 20.1801\n",
      "Epoch [98/100], Step [36300/6235], Loss: 0.1317\n",
      "Epoch [98/100], Step [36400/6235], Loss: 2.6133\n",
      "Epoch [98/100], Step [36500/6235], Loss: 8.5512\n",
      "Epoch [98/100], Step [36600/6235], Loss: 0.1205\n",
      "Epoch [98/100], Step [36700/6235], Loss: 0.4629\n",
      "Epoch [98/100], Step [36800/6235], Loss: 10.9692\n",
      "Epoch [98/100], Step [36900/6235], Loss: 8.6511\n",
      "Epoch [98/100], Step [37000/6235], Loss: 0.5888\n",
      "Epoch [98/100], Step [37100/6235], Loss: 1.2812\n",
      "Epoch [98/100], Step [37200/6235], Loss: 0.0734\n",
      "Epoch [98/100], Step [37300/6235], Loss: 0.0413\n",
      "Epoch [98/100], Step [37400/6235], Loss: 0.2011\n",
      "Epoch [98/100], Step [37500/6235], Loss: 4.8073\n",
      "Epoch [98/100], Step [37600/6235], Loss: 11.8143\n",
      "Epoch [98/100], Step [37700/6235], Loss: 1.6291\n",
      "Epoch [98/100], Step [37800/6235], Loss: 4.9308\n",
      "Epoch [98/100], Step [37900/6235], Loss: 7.7626\n",
      "Epoch [98/100], Step [38000/6235], Loss: 0.4826\n",
      "Epoch [98/100], Step [38100/6235], Loss: 3.1780\n",
      "Epoch [98/100], Step [38200/6235], Loss: 1.7148\n",
      "Epoch [98/100], Step [38300/6235], Loss: 0.2318\n",
      "Epoch [98/100], Step [38400/6235], Loss: 0.1267\n",
      "Epoch [98/100], Step [38500/6235], Loss: 2.5723\n",
      "Epoch [98/100], Step [38600/6235], Loss: 0.1680\n",
      "Epoch [98/100], Step [38700/6235], Loss: 0.0460\n",
      "Epoch [98/100], Step [38800/6235], Loss: 0.2164\n",
      "Epoch [98/100], Step [38900/6235], Loss: 2.0285\n",
      "Epoch [98/100], Step [39000/6235], Loss: 15.3776\n",
      "Epoch [98/100], Step [39100/6235], Loss: 16.1071\n",
      "Epoch [98/100], Step [39200/6235], Loss: 0.8547\n",
      "Epoch [98/100], Step [39300/6235], Loss: 3.6949\n",
      "Epoch [98/100], Step [39400/6235], Loss: 93.3274\n",
      "Epoch [98/100], Step [39500/6235], Loss: 27.9080\n",
      "Epoch [98/100], Step [39600/6235], Loss: 9.4996\n",
      "Epoch [98/100], Step [39700/6235], Loss: 31.8540\n",
      "Epoch [98/100], Step [39800/6235], Loss: 85.9602\n",
      "Epoch [98/100], Step [39900/6235], Loss: 12.4441\n",
      "Epoch [98/100], Step [40000/6235], Loss: 1.5962\n",
      "Epoch [98/100], Step [40100/6235], Loss: 8.0073\n",
      "Epoch [98/100], Step [40200/6235], Loss: 15.2949\n",
      "Epoch [98/100], Step [40300/6235], Loss: 0.3943\n",
      "Epoch [98/100], Step [40400/6235], Loss: 0.4698\n",
      "Epoch [98/100], Step [40500/6235], Loss: 3.1981\n",
      "Epoch [98/100], Step [40600/6235], Loss: 0.2992\n",
      "Epoch [98/100], Step [40700/6235], Loss: 5.4601\n",
      "Epoch [98/100], Step [40800/6235], Loss: 1.0488\n",
      "Epoch [98/100], Step [40900/6235], Loss: 1.3354\n",
      "Epoch [98/100], Step [41000/6235], Loss: 42.2739\n",
      "Epoch [98/100], Step [41100/6235], Loss: 37.5990\n",
      "Epoch [98/100], Step [41200/6235], Loss: 17.5723\n",
      "Epoch [98/100], Step [41300/6235], Loss: 5.0666\n",
      "Epoch [98/100], Step [41400/6235], Loss: 0.6223\n",
      "Epoch [98/100], Step [41500/6235], Loss: 0.9131\n",
      "Epoch [98/100], Step [41600/6235], Loss: 0.1176\n",
      "Epoch [98/100], Step [41700/6235], Loss: 0.2700\n",
      "Epoch [98/100], Step [41800/6235], Loss: 1.9180\n",
      "Epoch [98/100], Step [41900/6235], Loss: 4.7674\n",
      "Epoch [98/100], Step [42000/6235], Loss: 4.0499\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [98/100], Step [42100/6235], Loss: 9.3694\n",
      "Epoch [98/100], Step [42200/6235], Loss: 24.2938\n",
      "Epoch [98/100], Step [42300/6235], Loss: 0.6929\n",
      "Epoch [98/100], Step [42400/6235], Loss: 3.2760\n",
      "Epoch [98/100], Step [42500/6235], Loss: 0.6003\n",
      "Epoch [98/100], Step [42600/6235], Loss: 1.0500\n",
      "Epoch [98/100], Step [42700/6235], Loss: 0.5236\n",
      "Epoch [98/100], Step [42800/6235], Loss: 5.7822\n",
      "Epoch [98/100], Step [42900/6235], Loss: 2.9943\n",
      "Epoch [98/100], Step [43000/6235], Loss: 0.1860\n",
      "Epoch [98/100], Step [43100/6235], Loss: 0.1657\n",
      "Epoch [98/100], Step [43200/6235], Loss: 1.0729\n",
      "Epoch [98/100], Step [43300/6235], Loss: 8.2527\n",
      "Epoch [98/100], Step [43400/6235], Loss: 11.4650\n",
      "Epoch [98/100], Step [43500/6235], Loss: 9.6544\n",
      "Epoch [98/100], Step [43600/6235], Loss: 9.0774\n",
      "Epoch [98/100], Step [43700/6235], Loss: 46.2914\n",
      "Epoch [98/100], Step [43800/6235], Loss: 0.4513\n",
      "Epoch [98/100], Step [43900/6235], Loss: 0.9997\n",
      "Epoch [98/100], Step [44000/6235], Loss: 51.6404\n",
      "Epoch [98/100], Step [44100/6235], Loss: 1.7869\n",
      "Epoch [98/100], Step [44200/6235], Loss: 3.1976\n",
      "Epoch [98/100], Step [44300/6235], Loss: 7.6994\n",
      "Epoch [98/100], Step [44400/6235], Loss: 0.8023\n",
      "Epoch [98/100], Step [44500/6235], Loss: 3.1320\n",
      "Epoch [98/100], Step [44600/6235], Loss: 23.1515\n",
      "Epoch [98/100], Step [44700/6235], Loss: 4.8706\n",
      "Epoch [98/100], Step [44800/6235], Loss: 4.8914\n",
      "Epoch [98/100], Step [44900/6235], Loss: 7.5384\n",
      "Epoch [98/100], Step [45000/6235], Loss: 6.4308\n",
      "Epoch [98/100], Step [45100/6235], Loss: 55.5707\n",
      "Epoch [98/100], Step [45200/6235], Loss: 2.2707\n",
      "Epoch [98/100], Step [45300/6235], Loss: 25.4802\n",
      "Epoch [98/100], Step [45400/6235], Loss: 9.2980\n",
      "Epoch [98/100], Step [45500/6235], Loss: 3.2795\n",
      "Epoch [98/100], Step [45600/6235], Loss: 1.1381\n",
      "Epoch [98/100], Step [45700/6235], Loss: 73.2308\n",
      "Epoch [98/100], Step [45800/6235], Loss: 280.9981\n",
      "Epoch [98/100], Step [45900/6235], Loss: 10.7967\n",
      "Epoch [98/100], Step [46000/6235], Loss: 137.3217\n",
      "Epoch [98/100], Step [46100/6235], Loss: 173.7297\n",
      "Epoch [98/100], Step [46200/6235], Loss: 5.8300\n",
      "Epoch [98/100], Step [46300/6235], Loss: 112.3857\n",
      "Epoch [98/100], Step [46400/6235], Loss: 17.9665\n",
      "Epoch [98/100], Step [46500/6235], Loss: 43.1378\n",
      "Epoch [98/100], Step [46600/6235], Loss: 18.0064\n",
      "Epoch [98/100], Step [46700/6235], Loss: 53.7317\n",
      "Epoch [98/100], Step [46800/6235], Loss: 22.9469\n",
      "Epoch [98/100], Step [46900/6235], Loss: 0.9123\n",
      "Epoch [98/100], Step [47000/6235], Loss: 8.1512\n",
      "Epoch [98/100], Step [47100/6235], Loss: 2.6892\n",
      "Epoch [98/100], Step [47200/6235], Loss: 102.7473\n",
      "Epoch [98/100], Step [47300/6235], Loss: 1.0849\n",
      "Epoch [98/100], Step [47400/6235], Loss: 357.8997\n",
      "Epoch [98/100], Step [47500/6235], Loss: 6.5508\n",
      "Epoch [98/100], Step [47600/6235], Loss: 16.6392\n",
      "Epoch [98/100], Step [47700/6235], Loss: 35.8791\n",
      "Epoch [98/100], Step [47800/6235], Loss: 28.7153\n",
      "Epoch [98/100], Step [47900/6235], Loss: 13.5935\n",
      "Epoch [98/100], Step [48000/6235], Loss: 6.4357\n",
      "Epoch [98/100], Step [48100/6235], Loss: 8.1267\n",
      "Epoch [98/100], Step [48200/6235], Loss: 135.0519\n",
      "Epoch [98/100], Step [48300/6235], Loss: 644.9165\n",
      "Epoch [98/100], Step [48400/6235], Loss: 4.8268\n",
      "Epoch [98/100], Step [48500/6235], Loss: 45.2563\n",
      "Epoch [98/100], Step [48600/6235], Loss: 45.2822\n",
      "Epoch [98/100], Step [48700/6235], Loss: 9.5824\n",
      "Epoch [98/100], Step [48800/6235], Loss: 790.7295\n",
      "Epoch [98/100], Step [48900/6235], Loss: 288.0455\n",
      "Epoch [98/100], Step [49000/6235], Loss: 194.9387\n",
      "Epoch [98/100], Step [49100/6235], Loss: 3364.9365\n",
      "Epoch [98/100], Step [49200/6235], Loss: 804.9671\n",
      "Epoch [98/100], Step [49300/6235], Loss: 1103.6902\n",
      "Epoch [98/100], Step [49400/6235], Loss: 88.9736\n",
      "Epoch [98/100], Step [49500/6235], Loss: 25.1146\n",
      "Epoch [98/100], Step [49600/6235], Loss: 136.2284\n",
      "Epoch [98/100], Step [49700/6235], Loss: 5129.2798\n",
      "Epoch [98/100], Step [49800/6235], Loss: 382.1195\n",
      "Epoch [99/100], Step [100/6235], Loss: 24.6310\n",
      "Epoch [99/100], Step [200/6235], Loss: 0.0336\n",
      "Epoch [99/100], Step [300/6235], Loss: 0.0679\n",
      "Epoch [99/100], Step [400/6235], Loss: 0.0185\n",
      "Epoch [99/100], Step [500/6235], Loss: 30.0237\n",
      "Epoch [99/100], Step [600/6235], Loss: 0.1547\n",
      "Epoch [99/100], Step [700/6235], Loss: 0.4516\n",
      "Epoch [99/100], Step [800/6235], Loss: 0.0928\n",
      "Epoch [99/100], Step [900/6235], Loss: 0.0704\n",
      "Epoch [99/100], Step [1000/6235], Loss: 0.0176\n",
      "Epoch [99/100], Step [1100/6235], Loss: 0.0675\n",
      "Epoch [99/100], Step [1200/6235], Loss: 0.0681\n",
      "Epoch [99/100], Step [1300/6235], Loss: 0.0471\n",
      "Epoch [99/100], Step [1400/6235], Loss: 0.0443\n",
      "Epoch [99/100], Step [1500/6235], Loss: 0.0015\n",
      "Epoch [99/100], Step [1600/6235], Loss: 0.1951\n",
      "Epoch [99/100], Step [1700/6235], Loss: 0.0263\n",
      "Epoch [99/100], Step [1800/6235], Loss: 0.3792\n",
      "Epoch [99/100], Step [1900/6235], Loss: 0.2550\n",
      "Epoch [99/100], Step [2000/6235], Loss: 1.1747\n",
      "Epoch [99/100], Step [2100/6235], Loss: 1.0521\n",
      "Epoch [99/100], Step [2200/6235], Loss: 10.5874\n",
      "Epoch [99/100], Step [2300/6235], Loss: 18.9284\n",
      "Epoch [99/100], Step [2400/6235], Loss: 12.9322\n",
      "Epoch [99/100], Step [2500/6235], Loss: 12.1756\n",
      "Epoch [99/100], Step [2600/6235], Loss: 3.0429\n",
      "Epoch [99/100], Step [2700/6235], Loss: 23.8922\n",
      "Epoch [99/100], Step [2800/6235], Loss: 562.9273\n",
      "Epoch [99/100], Step [2900/6235], Loss: 6.5045\n",
      "Epoch [99/100], Step [3000/6235], Loss: 0.5573\n",
      "Epoch [99/100], Step [3100/6235], Loss: 41.4550\n",
      "Epoch [99/100], Step [3200/6235], Loss: 59.0298\n",
      "Epoch [99/100], Step [3300/6235], Loss: 0.3913\n",
      "Epoch [99/100], Step [3400/6235], Loss: 2.5019\n",
      "Epoch [99/100], Step [3500/6235], Loss: 34.9292\n",
      "Epoch [99/100], Step [3600/6235], Loss: 10.8240\n",
      "Epoch [99/100], Step [3700/6235], Loss: 1.6910\n",
      "Epoch [99/100], Step [3800/6235], Loss: 0.4499\n",
      "Epoch [99/100], Step [3900/6235], Loss: 1.0836\n",
      "Epoch [99/100], Step [4000/6235], Loss: 0.1521\n",
      "Epoch [99/100], Step [4100/6235], Loss: 2.7405\n",
      "Epoch [99/100], Step [4200/6235], Loss: 0.3124\n",
      "Epoch [99/100], Step [4300/6235], Loss: 9.2648\n",
      "Epoch [99/100], Step [4400/6235], Loss: 0.2900\n",
      "Epoch [99/100], Step [4500/6235], Loss: 70.9116\n",
      "Epoch [99/100], Step [4600/6235], Loss: 17.2912\n",
      "Epoch [99/100], Step [4700/6235], Loss: 2.5310\n",
      "Epoch [99/100], Step [4800/6235], Loss: 2.6559\n",
      "Epoch [99/100], Step [4900/6235], Loss: 0.0830\n",
      "Epoch [99/100], Step [5000/6235], Loss: 1.0118\n",
      "Epoch [99/100], Step [5100/6235], Loss: 3.1188\n",
      "Epoch [99/100], Step [5200/6235], Loss: 4.2698\n",
      "Epoch [99/100], Step [5300/6235], Loss: 35.5482\n",
      "Epoch [99/100], Step [5400/6235], Loss: 2.1569\n",
      "Epoch [99/100], Step [5500/6235], Loss: 0.7077\n",
      "Epoch [99/100], Step [5600/6235], Loss: 0.2239\n",
      "Epoch [99/100], Step [5700/6235], Loss: 0.1044\n",
      "Epoch [99/100], Step [5800/6235], Loss: 1.1684\n",
      "Epoch [99/100], Step [5900/6235], Loss: 1.0721\n",
      "Epoch [99/100], Step [6000/6235], Loss: 0.5274\n",
      "Epoch [99/100], Step [6100/6235], Loss: 0.3884\n",
      "Epoch [99/100], Step [6200/6235], Loss: 0.2761\n",
      "Epoch [99/100], Step [6300/6235], Loss: 0.3160\n",
      "Epoch [99/100], Step [6400/6235], Loss: 0.1150\n",
      "Epoch [99/100], Step [6500/6235], Loss: 0.4306\n",
      "Epoch [99/100], Step [6600/6235], Loss: 28.7836\n",
      "Epoch [99/100], Step [6700/6235], Loss: 1.0016\n",
      "Epoch [99/100], Step [6800/6235], Loss: 0.3623\n",
      "Epoch [99/100], Step [6900/6235], Loss: 1.2403\n",
      "Epoch [99/100], Step [7000/6235], Loss: 0.0155\n",
      "Epoch [99/100], Step [7100/6235], Loss: 0.2540\n",
      "Epoch [99/100], Step [7200/6235], Loss: 1.1366\n",
      "Epoch [99/100], Step [7300/6235], Loss: 0.3115\n",
      "Epoch [99/100], Step [7400/6235], Loss: 0.0116\n",
      "Epoch [99/100], Step [7500/6235], Loss: 7.1036\n",
      "Epoch [99/100], Step [7600/6235], Loss: 3.6774\n",
      "Epoch [99/100], Step [7700/6235], Loss: 15.6042\n",
      "Epoch [99/100], Step [7800/6235], Loss: 5.1683\n",
      "Epoch [99/100], Step [7900/6235], Loss: 18.4693\n",
      "Epoch [99/100], Step [8000/6235], Loss: 0.3100\n",
      "Epoch [99/100], Step [8100/6235], Loss: 4.0483\n",
      "Epoch [99/100], Step [8200/6235], Loss: 20.2024\n",
      "Epoch [99/100], Step [8300/6235], Loss: 70.7912\n",
      "Epoch [99/100], Step [8400/6235], Loss: 85.2979\n",
      "Epoch [99/100], Step [8500/6235], Loss: 74.2218\n",
      "Epoch [99/100], Step [8600/6235], Loss: 47.0120\n",
      "Epoch [99/100], Step [8700/6235], Loss: 106.1318\n",
      "Epoch [99/100], Step [8800/6235], Loss: 168.6945\n",
      "Epoch [99/100], Step [8900/6235], Loss: 127.6363\n",
      "Epoch [99/100], Step [9000/6235], Loss: 543.3307\n",
      "Epoch [99/100], Step [9100/6235], Loss: 2749.3125\n",
      "Epoch [99/100], Step [9200/6235], Loss: 5598.0747\n",
      "Epoch [99/100], Step [9300/6235], Loss: 93.6275\n",
      "Epoch [99/100], Step [9400/6235], Loss: 84.0736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Step [9500/6235], Loss: 2183.7705\n",
      "Epoch [99/100], Step [9600/6235], Loss: 953.3749\n",
      "Epoch [99/100], Step [9700/6235], Loss: 1.8929\n",
      "Epoch [99/100], Step [9800/6235], Loss: 4404.9458\n",
      "Epoch [99/100], Step [9900/6235], Loss: 137.9596\n",
      "Epoch [99/100], Step [10000/6235], Loss: 380.3513\n",
      "Epoch [99/100], Step [10100/6235], Loss: 3.3970\n",
      "Epoch [99/100], Step [10200/6235], Loss: 492.4421\n",
      "Epoch [99/100], Step [10300/6235], Loss: 13.1139\n",
      "Epoch [99/100], Step [10400/6235], Loss: 9.0535\n",
      "Epoch [99/100], Step [10500/6235], Loss: 15.4542\n",
      "Epoch [99/100], Step [10600/6235], Loss: 39.0424\n",
      "Epoch [99/100], Step [10700/6235], Loss: 13.9978\n",
      "Epoch [99/100], Step [10800/6235], Loss: 95.9740\n",
      "Epoch [99/100], Step [10900/6235], Loss: 32.7691\n",
      "Epoch [99/100], Step [11000/6235], Loss: 299.2180\n",
      "Epoch [99/100], Step [11100/6235], Loss: 48.7721\n",
      "Epoch [99/100], Step [11200/6235], Loss: 14.9368\n",
      "Epoch [99/100], Step [11300/6235], Loss: 117.5220\n",
      "Epoch [99/100], Step [11400/6235], Loss: 7.4340\n",
      "Epoch [99/100], Step [11500/6235], Loss: 9.6511\n",
      "Epoch [99/100], Step [11600/6235], Loss: 6.7520\n",
      "Epoch [99/100], Step [11700/6235], Loss: 44.8182\n",
      "Epoch [99/100], Step [11800/6235], Loss: 418.0004\n",
      "Epoch [99/100], Step [11900/6235], Loss: 16.7192\n",
      "Epoch [99/100], Step [12000/6235], Loss: 655.6385\n",
      "Epoch [99/100], Step [12100/6235], Loss: 303.9018\n",
      "Epoch [99/100], Step [12200/6235], Loss: 212.6132\n",
      "Epoch [99/100], Step [12300/6235], Loss: 31.3156\n",
      "Epoch [99/100], Step [12400/6235], Loss: 71.1867\n",
      "Epoch [99/100], Step [12500/6235], Loss: 10.1633\n",
      "Epoch [99/100], Step [12600/6235], Loss: 56.9588\n",
      "Epoch [99/100], Step [12700/6235], Loss: 4.7388\n",
      "Epoch [99/100], Step [12800/6235], Loss: 4.9581\n",
      "Epoch [99/100], Step [12900/6235], Loss: 38.4164\n",
      "Epoch [99/100], Step [13000/6235], Loss: 0.4376\n",
      "Epoch [99/100], Step [13100/6235], Loss: 65.9938\n",
      "Epoch [99/100], Step [13200/6235], Loss: 10.1025\n",
      "Epoch [99/100], Step [13300/6235], Loss: 45.0950\n",
      "Epoch [99/100], Step [13400/6235], Loss: 246.4832\n",
      "Epoch [99/100], Step [13500/6235], Loss: 3.8555\n",
      "Epoch [99/100], Step [13600/6235], Loss: 17.4946\n",
      "Epoch [99/100], Step [13700/6235], Loss: 14.5296\n",
      "Epoch [99/100], Step [13800/6235], Loss: 145.2526\n",
      "Epoch [99/100], Step [13900/6235], Loss: 62.1783\n",
      "Epoch [99/100], Step [14000/6235], Loss: 17.5924\n",
      "Epoch [99/100], Step [14100/6235], Loss: 21.9294\n",
      "Epoch [99/100], Step [14200/6235], Loss: 123.2452\n",
      "Epoch [99/100], Step [14300/6235], Loss: 32.4681\n",
      "Epoch [99/100], Step [14400/6235], Loss: 39.1293\n",
      "Epoch [99/100], Step [14500/6235], Loss: 41.5112\n",
      "Epoch [99/100], Step [14600/6235], Loss: 0.3606\n",
      "Epoch [99/100], Step [14700/6235], Loss: 39.5117\n",
      "Epoch [99/100], Step [14800/6235], Loss: 33.8265\n",
      "Epoch [99/100], Step [14900/6235], Loss: 0.7619\n",
      "Epoch [99/100], Step [15000/6235], Loss: 1.6284\n",
      "Epoch [99/100], Step [15100/6235], Loss: 0.5482\n",
      "Epoch [99/100], Step [15200/6235], Loss: 3.5104\n",
      "Epoch [99/100], Step [15300/6235], Loss: 45.6275\n",
      "Epoch [99/100], Step [15400/6235], Loss: 64.6102\n",
      "Epoch [99/100], Step [15500/6235], Loss: 10.8766\n",
      "Epoch [99/100], Step [15600/6235], Loss: 47.9703\n",
      "Epoch [99/100], Step [15700/6235], Loss: 37.0762\n",
      "Epoch [99/100], Step [15800/6235], Loss: 9.9873\n",
      "Epoch [99/100], Step [15900/6235], Loss: 0.2463\n",
      "Epoch [99/100], Step [16000/6235], Loss: 112.5665\n",
      "Epoch [99/100], Step [16100/6235], Loss: 8.2259\n",
      "Epoch [99/100], Step [16200/6235], Loss: 1.3142\n",
      "Epoch [99/100], Step [16300/6235], Loss: 8.8948\n",
      "Epoch [99/100], Step [16400/6235], Loss: 25.4801\n",
      "Epoch [99/100], Step [16500/6235], Loss: 239.4719\n",
      "Epoch [99/100], Step [16600/6235], Loss: 5.8269\n",
      "Epoch [99/100], Step [16700/6235], Loss: 0.5178\n",
      "Epoch [99/100], Step [16800/6235], Loss: 10.3367\n",
      "Epoch [99/100], Step [16900/6235], Loss: 0.1752\n",
      "Epoch [99/100], Step [17000/6235], Loss: 0.2223\n",
      "Epoch [99/100], Step [17100/6235], Loss: 0.0529\n",
      "Epoch [99/100], Step [17200/6235], Loss: 272.5033\n",
      "Epoch [99/100], Step [17300/6235], Loss: 27.9916\n",
      "Epoch [99/100], Step [17400/6235], Loss: 36.9600\n",
      "Epoch [99/100], Step [17500/6235], Loss: 2.0745\n",
      "Epoch [99/100], Step [17600/6235], Loss: 2.6341\n",
      "Epoch [99/100], Step [17700/6235], Loss: 4.7170\n",
      "Epoch [99/100], Step [17800/6235], Loss: 26.3681\n",
      "Epoch [99/100], Step [17900/6235], Loss: 2.3449\n",
      "Epoch [99/100], Step [18000/6235], Loss: 7.7118\n",
      "Epoch [99/100], Step [18100/6235], Loss: 15.8605\n",
      "Epoch [99/100], Step [18200/6235], Loss: 0.9479\n",
      "Epoch [99/100], Step [18300/6235], Loss: 4.5256\n",
      "Epoch [99/100], Step [18400/6235], Loss: 1.6168\n",
      "Epoch [99/100], Step [18500/6235], Loss: 16.5727\n",
      "Epoch [99/100], Step [18600/6235], Loss: 2.1139\n",
      "Epoch [99/100], Step [18700/6235], Loss: 0.4624\n",
      "Epoch [99/100], Step [18800/6235], Loss: 73.7939\n",
      "Epoch [99/100], Step [18900/6235], Loss: 45.8160\n",
      "Epoch [99/100], Step [19000/6235], Loss: 0.3664\n",
      "Epoch [99/100], Step [19100/6235], Loss: 2.3462\n",
      "Epoch [99/100], Step [19200/6235], Loss: 5.5639\n",
      "Epoch [99/100], Step [19300/6235], Loss: 7.0778\n",
      "Epoch [99/100], Step [19400/6235], Loss: 298.6922\n",
      "Epoch [99/100], Step [19500/6235], Loss: 82.0256\n",
      "Epoch [99/100], Step [19600/6235], Loss: 94.2033\n",
      "Epoch [99/100], Step [19700/6235], Loss: 7.5889\n",
      "Epoch [99/100], Step [19800/6235], Loss: 2.9581\n",
      "Epoch [99/100], Step [19900/6235], Loss: 0.3319\n",
      "Epoch [99/100], Step [20000/6235], Loss: 72.5275\n",
      "Epoch [99/100], Step [20100/6235], Loss: 0.6455\n",
      "Epoch [99/100], Step [20200/6235], Loss: 7.1043\n",
      "Epoch [99/100], Step [20300/6235], Loss: 2.2272\n",
      "Epoch [99/100], Step [20400/6235], Loss: 21.6342\n",
      "Epoch [99/100], Step [20500/6235], Loss: 40.0435\n",
      "Epoch [99/100], Step [20600/6235], Loss: 25.7072\n",
      "Epoch [99/100], Step [20700/6235], Loss: 1.8807\n",
      "Epoch [99/100], Step [20800/6235], Loss: 45.7540\n",
      "Epoch [99/100], Step [20900/6235], Loss: 23.6963\n",
      "Epoch [99/100], Step [21000/6235], Loss: 14.9457\n",
      "Epoch [99/100], Step [21100/6235], Loss: 4.8731\n",
      "Epoch [99/100], Step [21200/6235], Loss: 0.1572\n",
      "Epoch [99/100], Step [21300/6235], Loss: 0.1901\n",
      "Epoch [99/100], Step [21400/6235], Loss: 5.9803\n",
      "Epoch [99/100], Step [21500/6235], Loss: 4.9743\n",
      "Epoch [99/100], Step [21600/6235], Loss: 20.6614\n",
      "Epoch [99/100], Step [21700/6235], Loss: 0.8655\n",
      "Epoch [99/100], Step [21800/6235], Loss: 0.3931\n",
      "Epoch [99/100], Step [21900/6235], Loss: 0.5381\n",
      "Epoch [99/100], Step [22000/6235], Loss: 4.8575\n",
      "Epoch [99/100], Step [22100/6235], Loss: 2.3065\n",
      "Epoch [99/100], Step [22200/6235], Loss: 5.4633\n",
      "Epoch [99/100], Step [22300/6235], Loss: 4.7532\n",
      "Epoch [99/100], Step [22400/6235], Loss: 3.7092\n",
      "Epoch [99/100], Step [22500/6235], Loss: 66.8216\n",
      "Epoch [99/100], Step [22600/6235], Loss: 18.5945\n",
      "Epoch [99/100], Step [22700/6235], Loss: 0.7067\n",
      "Epoch [99/100], Step [22800/6235], Loss: 3.9388\n",
      "Epoch [99/100], Step [22900/6235], Loss: 1.3509\n",
      "Epoch [99/100], Step [23000/6235], Loss: 4.7639\n",
      "Epoch [99/100], Step [23100/6235], Loss: 0.7525\n",
      "Epoch [99/100], Step [23200/6235], Loss: 12.9714\n",
      "Epoch [99/100], Step [23300/6235], Loss: 17.5535\n",
      "Epoch [99/100], Step [23400/6235], Loss: 1.3741\n",
      "Epoch [99/100], Step [23500/6235], Loss: 0.1663\n",
      "Epoch [99/100], Step [23600/6235], Loss: 116.2085\n",
      "Epoch [99/100], Step [23700/6235], Loss: 3.5612\n",
      "Epoch [99/100], Step [23800/6235], Loss: 1.1115\n",
      "Epoch [99/100], Step [23900/6235], Loss: 6.4874\n",
      "Epoch [99/100], Step [24000/6235], Loss: 0.1313\n",
      "Epoch [99/100], Step [24100/6235], Loss: 0.1029\n",
      "Epoch [99/100], Step [24200/6235], Loss: 31.1726\n",
      "Epoch [99/100], Step [24300/6235], Loss: 1.2479\n",
      "Epoch [99/100], Step [24400/6235], Loss: 3.7603\n",
      "Epoch [99/100], Step [24500/6235], Loss: 1.6541\n",
      "Epoch [99/100], Step [24600/6235], Loss: 0.1030\n",
      "Epoch [99/100], Step [24700/6235], Loss: 3.7943\n",
      "Epoch [99/100], Step [24800/6235], Loss: 0.1753\n",
      "Epoch [99/100], Step [24900/6235], Loss: 15.5569\n",
      "Epoch [99/100], Step [25000/6235], Loss: 15.5010\n",
      "Epoch [99/100], Step [25100/6235], Loss: 9.8547\n",
      "Epoch [99/100], Step [25200/6235], Loss: 1.3163\n",
      "Epoch [99/100], Step [25300/6235], Loss: 0.5529\n",
      "Epoch [99/100], Step [25400/6235], Loss: 9.5379\n",
      "Epoch [99/100], Step [25500/6235], Loss: 7.1460\n",
      "Epoch [99/100], Step [25600/6235], Loss: 3.7979\n",
      "Epoch [99/100], Step [25700/6235], Loss: 0.3667\n",
      "Epoch [99/100], Step [25800/6235], Loss: 0.1081\n",
      "Epoch [99/100], Step [25900/6235], Loss: 8.1745\n",
      "Epoch [99/100], Step [26000/6235], Loss: 2.4494\n",
      "Epoch [99/100], Step [26100/6235], Loss: 0.0351\n",
      "Epoch [99/100], Step [26200/6235], Loss: 0.9379\n",
      "Epoch [99/100], Step [26300/6235], Loss: 4.2891\n",
      "Epoch [99/100], Step [26400/6235], Loss: 0.0892\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Step [26500/6235], Loss: 0.0244\n",
      "Epoch [99/100], Step [26600/6235], Loss: 1.7249\n",
      "Epoch [99/100], Step [26700/6235], Loss: 0.4118\n",
      "Epoch [99/100], Step [26800/6235], Loss: 0.1923\n",
      "Epoch [99/100], Step [26900/6235], Loss: 0.0009\n",
      "Epoch [99/100], Step [27000/6235], Loss: 14.8068\n",
      "Epoch [99/100], Step [27100/6235], Loss: 0.0430\n",
      "Epoch [99/100], Step [27200/6235], Loss: 0.0258\n",
      "Epoch [99/100], Step [27300/6235], Loss: 0.2261\n",
      "Epoch [99/100], Step [27400/6235], Loss: 0.7885\n",
      "Epoch [99/100], Step [27500/6235], Loss: 14.8119\n",
      "Epoch [99/100], Step [27600/6235], Loss: 1.1617\n",
      "Epoch [99/100], Step [27700/6235], Loss: 1.8273\n",
      "Epoch [99/100], Step [27800/6235], Loss: 5.2011\n",
      "Epoch [99/100], Step [27900/6235], Loss: 1.4390\n",
      "Epoch [99/100], Step [28000/6235], Loss: 140.1893\n",
      "Epoch [99/100], Step [28100/6235], Loss: 1.6080\n",
      "Epoch [99/100], Step [28200/6235], Loss: 30.5634\n",
      "Epoch [99/100], Step [28300/6235], Loss: 2.6821\n",
      "Epoch [99/100], Step [28400/6235], Loss: 26.3530\n",
      "Epoch [99/100], Step [28500/6235], Loss: 4.2161\n",
      "Epoch [99/100], Step [28600/6235], Loss: 0.0829\n",
      "Epoch [99/100], Step [28700/6235], Loss: 5.5089\n",
      "Epoch [99/100], Step [28800/6235], Loss: 0.5618\n",
      "Epoch [99/100], Step [28900/6235], Loss: 72.4561\n",
      "Epoch [99/100], Step [29000/6235], Loss: 11.6710\n",
      "Epoch [99/100], Step [29100/6235], Loss: 0.1190\n",
      "Epoch [99/100], Step [29200/6235], Loss: 0.8480\n",
      "Epoch [99/100], Step [29300/6235], Loss: 5.7835\n",
      "Epoch [99/100], Step [29400/6235], Loss: 0.0460\n",
      "Epoch [99/100], Step [29500/6235], Loss: 0.7704\n",
      "Epoch [99/100], Step [29600/6235], Loss: 0.5227\n",
      "Epoch [99/100], Step [29700/6235], Loss: 1.0234\n",
      "Epoch [99/100], Step [29800/6235], Loss: 1.6886\n",
      "Epoch [99/100], Step [29900/6235], Loss: 0.6866\n",
      "Epoch [99/100], Step [30000/6235], Loss: 5.9048\n",
      "Epoch [99/100], Step [30100/6235], Loss: 11.4648\n",
      "Epoch [99/100], Step [30200/6235], Loss: 0.7097\n",
      "Epoch [99/100], Step [30300/6235], Loss: 0.0370\n",
      "Epoch [99/100], Step [30400/6235], Loss: 0.7147\n",
      "Epoch [99/100], Step [30500/6235], Loss: 3.1343\n",
      "Epoch [99/100], Step [30600/6235], Loss: 1.3925\n",
      "Epoch [99/100], Step [30700/6235], Loss: 0.0975\n",
      "Epoch [99/100], Step [30800/6235], Loss: 0.3959\n",
      "Epoch [99/100], Step [30900/6235], Loss: 3.9339\n",
      "Epoch [99/100], Step [31000/6235], Loss: 0.0442\n",
      "Epoch [99/100], Step [31100/6235], Loss: 0.0613\n",
      "Epoch [99/100], Step [31200/6235], Loss: 5.7880\n",
      "Epoch [99/100], Step [31300/6235], Loss: 5.8390\n",
      "Epoch [99/100], Step [31400/6235], Loss: 10.3134\n",
      "Epoch [99/100], Step [31500/6235], Loss: 0.5752\n",
      "Epoch [99/100], Step [31600/6235], Loss: 5.2949\n",
      "Epoch [99/100], Step [31700/6235], Loss: 5.5750\n",
      "Epoch [99/100], Step [31800/6235], Loss: 1.8751\n",
      "Epoch [99/100], Step [31900/6235], Loss: 1192.3141\n",
      "Epoch [99/100], Step [32000/6235], Loss: 97.8994\n",
      "Epoch [99/100], Step [32100/6235], Loss: 2.7925\n",
      "Epoch [99/100], Step [32200/6235], Loss: 86.9383\n",
      "Epoch [99/100], Step [32300/6235], Loss: 1.0779\n",
      "Epoch [99/100], Step [32400/6235], Loss: 1.1183\n",
      "Epoch [99/100], Step [32500/6235], Loss: 18.3906\n",
      "Epoch [99/100], Step [32600/6235], Loss: 0.6115\n",
      "Epoch [99/100], Step [32700/6235], Loss: 78.4898\n",
      "Epoch [99/100], Step [32800/6235], Loss: 0.4756\n",
      "Epoch [99/100], Step [32900/6235], Loss: 4.3880\n",
      "Epoch [99/100], Step [33000/6235], Loss: 0.4031\n",
      "Epoch [99/100], Step [33100/6235], Loss: 0.9373\n",
      "Epoch [99/100], Step [33200/6235], Loss: 1.6462\n",
      "Epoch [99/100], Step [33300/6235], Loss: 0.8452\n",
      "Epoch [99/100], Step [33400/6235], Loss: 31.0130\n",
      "Epoch [99/100], Step [33500/6235], Loss: 0.3310\n",
      "Epoch [99/100], Step [33600/6235], Loss: 9.5283\n",
      "Epoch [99/100], Step [33700/6235], Loss: 15.4755\n",
      "Epoch [99/100], Step [33800/6235], Loss: 0.6875\n",
      "Epoch [99/100], Step [33900/6235], Loss: 31.2469\n",
      "Epoch [99/100], Step [34000/6235], Loss: 0.0276\n",
      "Epoch [99/100], Step [34100/6235], Loss: 0.4099\n",
      "Epoch [99/100], Step [34200/6235], Loss: 2.7232\n",
      "Epoch [99/100], Step [34300/6235], Loss: 5.1653\n",
      "Epoch [99/100], Step [34400/6235], Loss: 0.2230\n",
      "Epoch [99/100], Step [34500/6235], Loss: 84.1011\n",
      "Epoch [99/100], Step [34600/6235], Loss: 0.1058\n",
      "Epoch [99/100], Step [34700/6235], Loss: 1.0366\n",
      "Epoch [99/100], Step [34800/6235], Loss: 11.9188\n",
      "Epoch [99/100], Step [34900/6235], Loss: 69.9090\n",
      "Epoch [99/100], Step [35000/6235], Loss: 0.6073\n",
      "Epoch [99/100], Step [35100/6235], Loss: 0.7090\n",
      "Epoch [99/100], Step [35200/6235], Loss: 0.2886\n",
      "Epoch [99/100], Step [35300/6235], Loss: 2.5188\n",
      "Epoch [99/100], Step [35400/6235], Loss: 0.4581\n",
      "Epoch [99/100], Step [35500/6235], Loss: 2.1596\n",
      "Epoch [99/100], Step [35600/6235], Loss: 1.9210\n",
      "Epoch [99/100], Step [35700/6235], Loss: 5.8515\n",
      "Epoch [99/100], Step [35800/6235], Loss: 0.2114\n",
      "Epoch [99/100], Step [35900/6235], Loss: 0.4055\n",
      "Epoch [99/100], Step [36000/6235], Loss: 0.4172\n",
      "Epoch [99/100], Step [36100/6235], Loss: 0.0577\n",
      "Epoch [99/100], Step [36200/6235], Loss: 11.5003\n",
      "Epoch [99/100], Step [36300/6235], Loss: 1.2639\n",
      "Epoch [99/100], Step [36400/6235], Loss: 2.1297\n",
      "Epoch [99/100], Step [36500/6235], Loss: 8.9879\n",
      "Epoch [99/100], Step [36600/6235], Loss: 0.1656\n",
      "Epoch [99/100], Step [36700/6235], Loss: 0.3977\n",
      "Epoch [99/100], Step [36800/6235], Loss: 13.0955\n",
      "Epoch [99/100], Step [36900/6235], Loss: 5.6376\n",
      "Epoch [99/100], Step [37000/6235], Loss: 0.4496\n",
      "Epoch [99/100], Step [37100/6235], Loss: 1.0205\n",
      "Epoch [99/100], Step [37200/6235], Loss: 0.0822\n",
      "Epoch [99/100], Step [37300/6235], Loss: 0.0489\n",
      "Epoch [99/100], Step [37400/6235], Loss: 0.2033\n",
      "Epoch [99/100], Step [37500/6235], Loss: 4.3669\n",
      "Epoch [99/100], Step [37600/6235], Loss: 11.6200\n",
      "Epoch [99/100], Step [37700/6235], Loss: 1.2951\n",
      "Epoch [99/100], Step [37800/6235], Loss: 6.1423\n",
      "Epoch [99/100], Step [37900/6235], Loss: 9.3395\n",
      "Epoch [99/100], Step [38000/6235], Loss: 0.4663\n",
      "Epoch [99/100], Step [38100/6235], Loss: 2.9994\n",
      "Epoch [99/100], Step [38200/6235], Loss: 1.9165\n",
      "Epoch [99/100], Step [38300/6235], Loss: 0.4043\n",
      "Epoch [99/100], Step [38400/6235], Loss: 0.1244\n",
      "Epoch [99/100], Step [38500/6235], Loss: 2.5156\n",
      "Epoch [99/100], Step [38600/6235], Loss: 0.1372\n",
      "Epoch [99/100], Step [38700/6235], Loss: 0.0411\n",
      "Epoch [99/100], Step [38800/6235], Loss: 0.2247\n",
      "Epoch [99/100], Step [38900/6235], Loss: 10.1683\n",
      "Epoch [99/100], Step [39000/6235], Loss: 4.2440\n",
      "Epoch [99/100], Step [39100/6235], Loss: 19.0145\n",
      "Epoch [99/100], Step [39200/6235], Loss: 0.5359\n",
      "Epoch [99/100], Step [39300/6235], Loss: 5.0537\n",
      "Epoch [99/100], Step [39400/6235], Loss: 162.4256\n",
      "Epoch [99/100], Step [39500/6235], Loss: 11.2028\n",
      "Epoch [99/100], Step [39600/6235], Loss: 19.0704\n",
      "Epoch [99/100], Step [39700/6235], Loss: 95.3954\n",
      "Epoch [99/100], Step [39800/6235], Loss: 120.3115\n",
      "Epoch [99/100], Step [39900/6235], Loss: 4.8802\n",
      "Epoch [99/100], Step [40000/6235], Loss: 6.1590\n",
      "Epoch [99/100], Step [40100/6235], Loss: 20.1957\n",
      "Epoch [99/100], Step [40200/6235], Loss: 1.3089\n",
      "Epoch [99/100], Step [40300/6235], Loss: 1.2235\n",
      "Epoch [99/100], Step [40400/6235], Loss: 1.5421\n",
      "Epoch [99/100], Step [40500/6235], Loss: 2.5879\n",
      "Epoch [99/100], Step [40600/6235], Loss: 0.2495\n",
      "Epoch [99/100], Step [40700/6235], Loss: 7.3591\n",
      "Epoch [99/100], Step [40800/6235], Loss: 0.9095\n",
      "Epoch [99/100], Step [40900/6235], Loss: 0.3901\n",
      "Epoch [99/100], Step [41000/6235], Loss: 48.0001\n",
      "Epoch [99/100], Step [41100/6235], Loss: 1.7376\n",
      "Epoch [99/100], Step [41200/6235], Loss: 14.7803\n",
      "Epoch [99/100], Step [41300/6235], Loss: 2.8109\n",
      "Epoch [99/100], Step [41400/6235], Loss: 0.2979\n",
      "Epoch [99/100], Step [41500/6235], Loss: 0.4832\n",
      "Epoch [99/100], Step [41600/6235], Loss: 0.2556\n",
      "Epoch [99/100], Step [41700/6235], Loss: 1.1053\n",
      "Epoch [99/100], Step [41800/6235], Loss: 2.8674\n",
      "Epoch [99/100], Step [41900/6235], Loss: 4.2314\n",
      "Epoch [99/100], Step [42000/6235], Loss: 3.4046\n",
      "Epoch [99/100], Step [42100/6235], Loss: 7.8753\n",
      "Epoch [99/100], Step [42200/6235], Loss: 19.3832\n",
      "Epoch [99/100], Step [42300/6235], Loss: 0.4613\n",
      "Epoch [99/100], Step [42400/6235], Loss: 2.4759\n",
      "Epoch [99/100], Step [42500/6235], Loss: 3.9501\n",
      "Epoch [99/100], Step [42600/6235], Loss: 0.5270\n",
      "Epoch [99/100], Step [42700/6235], Loss: 0.2439\n",
      "Epoch [99/100], Step [42800/6235], Loss: 1.1319\n",
      "Epoch [99/100], Step [42900/6235], Loss: 3.9032\n",
      "Epoch [99/100], Step [43000/6235], Loss: 0.2885\n",
      "Epoch [99/100], Step [43100/6235], Loss: 0.7104\n",
      "Epoch [99/100], Step [43200/6235], Loss: 0.9022\n",
      "Epoch [99/100], Step [43300/6235], Loss: 9.0301\n",
      "Epoch [99/100], Step [43400/6235], Loss: 10.1868\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [99/100], Step [43500/6235], Loss: 9.4152\n",
      "Epoch [99/100], Step [43600/6235], Loss: 17.4389\n",
      "Epoch [99/100], Step [43700/6235], Loss: 41.5929\n",
      "Epoch [99/100], Step [43800/6235], Loss: 0.5370\n",
      "Epoch [99/100], Step [43900/6235], Loss: 0.8489\n",
      "Epoch [99/100], Step [44000/6235], Loss: 57.3381\n",
      "Epoch [99/100], Step [44100/6235], Loss: 3.9791\n",
      "Epoch [99/100], Step [44200/6235], Loss: 1.3631\n",
      "Epoch [99/100], Step [44300/6235], Loss: 40.7043\n",
      "Epoch [99/100], Step [44400/6235], Loss: 0.8957\n",
      "Epoch [99/100], Step [44500/6235], Loss: 5.6215\n",
      "Epoch [99/100], Step [44600/6235], Loss: 10.9121\n",
      "Epoch [99/100], Step [44700/6235], Loss: 3.5857\n",
      "Epoch [99/100], Step [44800/6235], Loss: 2.6655\n",
      "Epoch [99/100], Step [44900/6235], Loss: 12.2769\n",
      "Epoch [99/100], Step [45000/6235], Loss: 6.4406\n",
      "Epoch [99/100], Step [45100/6235], Loss: 41.9192\n",
      "Epoch [99/100], Step [45200/6235], Loss: 0.8955\n",
      "Epoch [99/100], Step [45300/6235], Loss: 24.9487\n",
      "Epoch [99/100], Step [45400/6235], Loss: 11.3194\n",
      "Epoch [99/100], Step [45500/6235], Loss: 3.1834\n",
      "Epoch [99/100], Step [45600/6235], Loss: 1.0198\n",
      "Epoch [99/100], Step [45700/6235], Loss: 63.5606\n",
      "Epoch [99/100], Step [45800/6235], Loss: 209.6029\n",
      "Epoch [99/100], Step [45900/6235], Loss: 21.2667\n",
      "Epoch [99/100], Step [46000/6235], Loss: 250.1834\n",
      "Epoch [99/100], Step [46100/6235], Loss: 202.1557\n",
      "Epoch [99/100], Step [46200/6235], Loss: 79.7612\n",
      "Epoch [99/100], Step [46300/6235], Loss: 11.7516\n",
      "Epoch [99/100], Step [46400/6235], Loss: 4.1699\n",
      "Epoch [99/100], Step [46500/6235], Loss: 123.4791\n",
      "Epoch [99/100], Step [46600/6235], Loss: 15.1785\n",
      "Epoch [99/100], Step [46700/6235], Loss: 11.7722\n",
      "Epoch [99/100], Step [46800/6235], Loss: 28.5744\n",
      "Epoch [99/100], Step [46900/6235], Loss: 5.2576\n",
      "Epoch [99/100], Step [47000/6235], Loss: 6.1857\n",
      "Epoch [99/100], Step [47100/6235], Loss: 8.6709\n",
      "Epoch [99/100], Step [47200/6235], Loss: 106.7387\n",
      "Epoch [99/100], Step [47300/6235], Loss: 1.3196\n",
      "Epoch [99/100], Step [47400/6235], Loss: 428.0618\n",
      "Epoch [99/100], Step [47500/6235], Loss: 0.4261\n",
      "Epoch [99/100], Step [47600/6235], Loss: 1.2652\n",
      "Epoch [99/100], Step [47700/6235], Loss: 4.0353\n",
      "Epoch [99/100], Step [47800/6235], Loss: 2.4718\n",
      "Epoch [99/100], Step [47900/6235], Loss: 17.4641\n",
      "Epoch [99/100], Step [48000/6235], Loss: 6.4560\n",
      "Epoch [99/100], Step [48100/6235], Loss: 4.7893\n",
      "Epoch [99/100], Step [48200/6235], Loss: 74.1602\n",
      "Epoch [99/100], Step [48300/6235], Loss: 502.1638\n",
      "Epoch [99/100], Step [48400/6235], Loss: 6.5484\n",
      "Epoch [99/100], Step [48500/6235], Loss: 37.5020\n",
      "Epoch [99/100], Step [48600/6235], Loss: 118.8152\n",
      "Epoch [99/100], Step [48700/6235], Loss: 0.3663\n",
      "Epoch [99/100], Step [48800/6235], Loss: 150.1711\n",
      "Epoch [99/100], Step [48900/6235], Loss: 277.2966\n",
      "Epoch [99/100], Step [49000/6235], Loss: 249.2075\n",
      "Epoch [99/100], Step [49100/6235], Loss: 2693.7756\n",
      "Epoch [99/100], Step [49200/6235], Loss: 1241.1215\n",
      "Epoch [99/100], Step [49300/6235], Loss: 1112.7219\n",
      "Epoch [99/100], Step [49400/6235], Loss: 111.0475\n",
      "Epoch [99/100], Step [49500/6235], Loss: 12.5506\n",
      "Epoch [99/100], Step [49600/6235], Loss: 81.9429\n",
      "Epoch [99/100], Step [49700/6235], Loss: 93.8441\n",
      "Epoch [99/100], Step [49800/6235], Loss: 114.7716\n",
      "Epoch [100/100], Step [100/6235], Loss: 30.9598\n",
      "Epoch [100/100], Step [200/6235], Loss: 0.5992\n",
      "Epoch [100/100], Step [300/6235], Loss: 0.0807\n",
      "Epoch [100/100], Step [400/6235], Loss: 0.0519\n",
      "Epoch [100/100], Step [500/6235], Loss: 2.3612\n",
      "Epoch [100/100], Step [600/6235], Loss: 0.1824\n",
      "Epoch [100/100], Step [700/6235], Loss: 1.0442\n",
      "Epoch [100/100], Step [800/6235], Loss: 0.0309\n",
      "Epoch [100/100], Step [900/6235], Loss: 0.1030\n",
      "Epoch [100/100], Step [1000/6235], Loss: 0.0432\n",
      "Epoch [100/100], Step [1100/6235], Loss: 0.0739\n",
      "Epoch [100/100], Step [1200/6235], Loss: 0.2730\n",
      "Epoch [100/100], Step [1300/6235], Loss: 0.0054\n",
      "Epoch [100/100], Step [1400/6235], Loss: 0.1526\n",
      "Epoch [100/100], Step [1500/6235], Loss: 0.0178\n",
      "Epoch [100/100], Step [1600/6235], Loss: 0.2527\n",
      "Epoch [100/100], Step [1700/6235], Loss: 0.3021\n",
      "Epoch [100/100], Step [1800/6235], Loss: 0.4321\n",
      "Epoch [100/100], Step [1900/6235], Loss: 0.3171\n",
      "Epoch [100/100], Step [2000/6235], Loss: 2.3725\n",
      "Epoch [100/100], Step [2100/6235], Loss: 11.0784\n",
      "Epoch [100/100], Step [2200/6235], Loss: 4.7946\n",
      "Epoch [100/100], Step [2300/6235], Loss: 2.2630\n",
      "Epoch [100/100], Step [2400/6235], Loss: 5.3867\n",
      "Epoch [100/100], Step [2500/6235], Loss: 22.5690\n",
      "Epoch [100/100], Step [2600/6235], Loss: 16.1024\n",
      "Epoch [100/100], Step [2700/6235], Loss: 8.1827\n",
      "Epoch [100/100], Step [2800/6235], Loss: 98.0234\n",
      "Epoch [100/100], Step [2900/6235], Loss: 14.4548\n",
      "Epoch [100/100], Step [3000/6235], Loss: 1.2363\n",
      "Epoch [100/100], Step [3100/6235], Loss: 78.5911\n",
      "Epoch [100/100], Step [3200/6235], Loss: 31.5004\n",
      "Epoch [100/100], Step [3300/6235], Loss: 7.2642\n",
      "Epoch [100/100], Step [3400/6235], Loss: 5.2596\n",
      "Epoch [100/100], Step [3500/6235], Loss: 59.3387\n",
      "Epoch [100/100], Step [3600/6235], Loss: 0.5689\n",
      "Epoch [100/100], Step [3700/6235], Loss: 0.1543\n",
      "Epoch [100/100], Step [3800/6235], Loss: 0.1081\n",
      "Epoch [100/100], Step [3900/6235], Loss: 0.2710\n",
      "Epoch [100/100], Step [4000/6235], Loss: 0.1340\n",
      "Epoch [100/100], Step [4100/6235], Loss: 9.9162\n",
      "Epoch [100/100], Step [4200/6235], Loss: 5.1420\n",
      "Epoch [100/100], Step [4300/6235], Loss: 3.3715\n",
      "Epoch [100/100], Step [4400/6235], Loss: 0.3618\n",
      "Epoch [100/100], Step [4500/6235], Loss: 41.3621\n",
      "Epoch [100/100], Step [4600/6235], Loss: 3.5510\n",
      "Epoch [100/100], Step [4700/6235], Loss: 0.3261\n",
      "Epoch [100/100], Step [4800/6235], Loss: 5.1063\n",
      "Epoch [100/100], Step [4900/6235], Loss: 3.9140\n",
      "Epoch [100/100], Step [5000/6235], Loss: 0.2051\n",
      "Epoch [100/100], Step [5100/6235], Loss: 0.3330\n",
      "Epoch [100/100], Step [5200/6235], Loss: 5.5805\n",
      "Epoch [100/100], Step [5300/6235], Loss: 14.8847\n",
      "Epoch [100/100], Step [5400/6235], Loss: 2.6826\n",
      "Epoch [100/100], Step [5500/6235], Loss: 0.0670\n",
      "Epoch [100/100], Step [5600/6235], Loss: 0.2899\n",
      "Epoch [100/100], Step [5700/6235], Loss: 0.0720\n",
      "Epoch [100/100], Step [5800/6235], Loss: 0.1663\n",
      "Epoch [100/100], Step [5900/6235], Loss: 0.0701\n",
      "Epoch [100/100], Step [6000/6235], Loss: 0.9248\n",
      "Epoch [100/100], Step [6100/6235], Loss: 0.0521\n",
      "Epoch [100/100], Step [6200/6235], Loss: 7.7475\n",
      "Epoch [100/100], Step [6300/6235], Loss: 0.7618\n",
      "Epoch [100/100], Step [6400/6235], Loss: 0.0261\n",
      "Epoch [100/100], Step [6500/6235], Loss: 0.6164\n",
      "Epoch [100/100], Step [6600/6235], Loss: 12.9491\n",
      "Epoch [100/100], Step [6700/6235], Loss: 1.3237\n",
      "Epoch [100/100], Step [6800/6235], Loss: 0.6303\n",
      "Epoch [100/100], Step [6900/6235], Loss: 0.2875\n",
      "Epoch [100/100], Step [7000/6235], Loss: 0.2716\n",
      "Epoch [100/100], Step [7100/6235], Loss: 0.2237\n",
      "Epoch [100/100], Step [7200/6235], Loss: 0.1090\n",
      "Epoch [100/100], Step [7300/6235], Loss: 0.5415\n",
      "Epoch [100/100], Step [7400/6235], Loss: 0.1340\n",
      "Epoch [100/100], Step [7500/6235], Loss: 0.1676\n",
      "Epoch [100/100], Step [7600/6235], Loss: 3.5213\n",
      "Epoch [100/100], Step [7700/6235], Loss: 12.3621\n",
      "Epoch [100/100], Step [7800/6235], Loss: 1.1542\n",
      "Epoch [100/100], Step [7900/6235], Loss: 1.9274\n",
      "Epoch [100/100], Step [8000/6235], Loss: 0.3683\n",
      "Epoch [100/100], Step [8100/6235], Loss: 1.2210\n",
      "Epoch [100/100], Step [8200/6235], Loss: 9.8828\n",
      "Epoch [100/100], Step [8300/6235], Loss: 16.1858\n",
      "Epoch [100/100], Step [8400/6235], Loss: 545.6528\n",
      "Epoch [100/100], Step [8500/6235], Loss: 20.0215\n",
      "Epoch [100/100], Step [8600/6235], Loss: 34.7510\n",
      "Epoch [100/100], Step [8700/6235], Loss: 17.5373\n",
      "Epoch [100/100], Step [8800/6235], Loss: 611.0281\n",
      "Epoch [100/100], Step [8900/6235], Loss: 1.1631\n",
      "Epoch [100/100], Step [9000/6235], Loss: 554.5699\n",
      "Epoch [100/100], Step [9100/6235], Loss: 2374.1978\n",
      "Epoch [100/100], Step [9200/6235], Loss: 5032.6460\n",
      "Epoch [100/100], Step [9300/6235], Loss: 175.0458\n",
      "Epoch [100/100], Step [9400/6235], Loss: 76.2506\n",
      "Epoch [100/100], Step [9500/6235], Loss: 2205.3008\n",
      "Epoch [100/100], Step [9600/6235], Loss: 1191.7249\n",
      "Epoch [100/100], Step [9700/6235], Loss: 2.6329\n",
      "Epoch [100/100], Step [9800/6235], Loss: 3026.5576\n",
      "Epoch [100/100], Step [9900/6235], Loss: 47.0366\n",
      "Epoch [100/100], Step [10000/6235], Loss: 153.9786\n",
      "Epoch [100/100], Step [10100/6235], Loss: 2.8475\n",
      "Epoch [100/100], Step [10200/6235], Loss: 1002.4413\n",
      "Epoch [100/100], Step [10300/6235], Loss: 35.5424\n",
      "Epoch [100/100], Step [10400/6235], Loss: 8.6762\n",
      "Epoch [100/100], Step [10500/6235], Loss: 9.8124\n",
      "Epoch [100/100], Step [10600/6235], Loss: 335.8873\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Step [10700/6235], Loss: 14.5911\n",
      "Epoch [100/100], Step [10800/6235], Loss: 125.4945\n",
      "Epoch [100/100], Step [10900/6235], Loss: 92.3461\n",
      "Epoch [100/100], Step [11000/6235], Loss: 297.4350\n",
      "Epoch [100/100], Step [11100/6235], Loss: 32.8191\n",
      "Epoch [100/100], Step [11200/6235], Loss: 5.0202\n",
      "Epoch [100/100], Step [11300/6235], Loss: 102.2358\n",
      "Epoch [100/100], Step [11400/6235], Loss: 9.1585\n",
      "Epoch [100/100], Step [11500/6235], Loss: 10.2129\n",
      "Epoch [100/100], Step [11600/6235], Loss: 7.5374\n",
      "Epoch [100/100], Step [11700/6235], Loss: 43.9050\n",
      "Epoch [100/100], Step [11800/6235], Loss: 403.8616\n",
      "Epoch [100/100], Step [11900/6235], Loss: 22.1281\n",
      "Epoch [100/100], Step [12000/6235], Loss: 727.8201\n",
      "Epoch [100/100], Step [12100/6235], Loss: 251.9500\n",
      "Epoch [100/100], Step [12200/6235], Loss: 7.6459\n",
      "Epoch [100/100], Step [12300/6235], Loss: 0.8796\n",
      "Epoch [100/100], Step [12400/6235], Loss: 131.5971\n",
      "Epoch [100/100], Step [12500/6235], Loss: 49.1530\n",
      "Epoch [100/100], Step [12600/6235], Loss: 13.8684\n",
      "Epoch [100/100], Step [12700/6235], Loss: 8.1978\n",
      "Epoch [100/100], Step [12800/6235], Loss: 8.4003\n",
      "Epoch [100/100], Step [12900/6235], Loss: 33.2589\n",
      "Epoch [100/100], Step [13000/6235], Loss: 0.1740\n",
      "Epoch [100/100], Step [13100/6235], Loss: 62.8961\n",
      "Epoch [100/100], Step [13200/6235], Loss: 8.2947\n",
      "Epoch [100/100], Step [13300/6235], Loss: 30.0142\n",
      "Epoch [100/100], Step [13400/6235], Loss: 226.0405\n",
      "Epoch [100/100], Step [13500/6235], Loss: 19.7860\n",
      "Epoch [100/100], Step [13600/6235], Loss: 34.0851\n",
      "Epoch [100/100], Step [13700/6235], Loss: 3.4779\n",
      "Epoch [100/100], Step [13800/6235], Loss: 161.9750\n",
      "Epoch [100/100], Step [13900/6235], Loss: 62.5100\n",
      "Epoch [100/100], Step [14000/6235], Loss: 12.6664\n",
      "Epoch [100/100], Step [14100/6235], Loss: 20.3218\n",
      "Epoch [100/100], Step [14200/6235], Loss: 58.2520\n",
      "Epoch [100/100], Step [14300/6235], Loss: 24.5321\n",
      "Epoch [100/100], Step [14400/6235], Loss: 38.4204\n",
      "Epoch [100/100], Step [14500/6235], Loss: 38.1583\n",
      "Epoch [100/100], Step [14600/6235], Loss: 0.2178\n",
      "Epoch [100/100], Step [14700/6235], Loss: 42.6990\n",
      "Epoch [100/100], Step [14800/6235], Loss: 33.5013\n",
      "Epoch [100/100], Step [14900/6235], Loss: 0.7321\n",
      "Epoch [100/100], Step [15000/6235], Loss: 1.7401\n",
      "Epoch [100/100], Step [15100/6235], Loss: 0.5317\n",
      "Epoch [100/100], Step [15200/6235], Loss: 8.8383\n",
      "Epoch [100/100], Step [15300/6235], Loss: 40.3819\n",
      "Epoch [100/100], Step [15400/6235], Loss: 1.5190\n",
      "Epoch [100/100], Step [15500/6235], Loss: 13.1207\n",
      "Epoch [100/100], Step [15600/6235], Loss: 176.7414\n",
      "Epoch [100/100], Step [15700/6235], Loss: 49.9749\n",
      "Epoch [100/100], Step [15800/6235], Loss: 4.7457\n",
      "Epoch [100/100], Step [15900/6235], Loss: 1.1606\n",
      "Epoch [100/100], Step [16000/6235], Loss: 147.4563\n",
      "Epoch [100/100], Step [16100/6235], Loss: 1.2659\n",
      "Epoch [100/100], Step [16200/6235], Loss: 0.8242\n",
      "Epoch [100/100], Step [16300/6235], Loss: 8.1800\n",
      "Epoch [100/100], Step [16400/6235], Loss: 20.8080\n",
      "Epoch [100/100], Step [16500/6235], Loss: 147.8842\n",
      "Epoch [100/100], Step [16600/6235], Loss: 11.5986\n",
      "Epoch [100/100], Step [16700/6235], Loss: 0.3404\n",
      "Epoch [100/100], Step [16800/6235], Loss: 12.0486\n",
      "Epoch [100/100], Step [16900/6235], Loss: 0.4198\n",
      "Epoch [100/100], Step [17000/6235], Loss: 0.1725\n",
      "Epoch [100/100], Step [17100/6235], Loss: 0.1557\n",
      "Epoch [100/100], Step [17200/6235], Loss: 224.4632\n",
      "Epoch [100/100], Step [17300/6235], Loss: 6.1907\n",
      "Epoch [100/100], Step [17400/6235], Loss: 35.3837\n",
      "Epoch [100/100], Step [17500/6235], Loss: 6.1308\n",
      "Epoch [100/100], Step [17600/6235], Loss: 2.6146\n",
      "Epoch [100/100], Step [17700/6235], Loss: 3.0562\n",
      "Epoch [100/100], Step [17800/6235], Loss: 41.5607\n",
      "Epoch [100/100], Step [17900/6235], Loss: 3.5165\n",
      "Epoch [100/100], Step [18000/6235], Loss: 8.1206\n",
      "Epoch [100/100], Step [18100/6235], Loss: 16.5458\n",
      "Epoch [100/100], Step [18200/6235], Loss: 0.8752\n",
      "Epoch [100/100], Step [18300/6235], Loss: 5.8418\n",
      "Epoch [100/100], Step [18400/6235], Loss: 3.9339\n",
      "Epoch [100/100], Step [18500/6235], Loss: 9.9270\n",
      "Epoch [100/100], Step [18600/6235], Loss: 1.2500\n",
      "Epoch [100/100], Step [18700/6235], Loss: 0.4697\n",
      "Epoch [100/100], Step [18800/6235], Loss: 147.0918\n",
      "Epoch [100/100], Step [18900/6235], Loss: 3.5876\n",
      "Epoch [100/100], Step [19000/6235], Loss: 5.6649\n",
      "Epoch [100/100], Step [19100/6235], Loss: 6.3554\n",
      "Epoch [100/100], Step [19200/6235], Loss: 3.5730\n",
      "Epoch [100/100], Step [19300/6235], Loss: 4.6942\n",
      "Epoch [100/100], Step [19400/6235], Loss: 130.9599\n",
      "Epoch [100/100], Step [19500/6235], Loss: 219.8701\n",
      "Epoch [100/100], Step [19600/6235], Loss: 148.7816\n",
      "Epoch [100/100], Step [19700/6235], Loss: 23.8406\n",
      "Epoch [100/100], Step [19800/6235], Loss: 7.2292\n",
      "Epoch [100/100], Step [19900/6235], Loss: 0.1238\n",
      "Epoch [100/100], Step [20000/6235], Loss: 86.5991\n",
      "Epoch [100/100], Step [20100/6235], Loss: 12.7758\n",
      "Epoch [100/100], Step [20200/6235], Loss: 0.4117\n",
      "Epoch [100/100], Step [20300/6235], Loss: 0.1496\n",
      "Epoch [100/100], Step [20400/6235], Loss: 36.1649\n",
      "Epoch [100/100], Step [20500/6235], Loss: 24.2447\n",
      "Epoch [100/100], Step [20600/6235], Loss: 21.6207\n",
      "Epoch [100/100], Step [20700/6235], Loss: 2.0800\n",
      "Epoch [100/100], Step [20800/6235], Loss: 18.5504\n",
      "Epoch [100/100], Step [20900/6235], Loss: 50.5766\n",
      "Epoch [100/100], Step [21000/6235], Loss: 15.6174\n",
      "Epoch [100/100], Step [21100/6235], Loss: 2.3411\n",
      "Epoch [100/100], Step [21200/6235], Loss: 0.1699\n",
      "Epoch [100/100], Step [21300/6235], Loss: 0.1353\n",
      "Epoch [100/100], Step [21400/6235], Loss: 5.5226\n",
      "Epoch [100/100], Step [21500/6235], Loss: 2.6368\n",
      "Epoch [100/100], Step [21600/6235], Loss: 32.2954\n",
      "Epoch [100/100], Step [21700/6235], Loss: 0.2201\n",
      "Epoch [100/100], Step [21800/6235], Loss: 0.3303\n",
      "Epoch [100/100], Step [21900/6235], Loss: 0.3900\n",
      "Epoch [100/100], Step [22000/6235], Loss: 3.6865\n",
      "Epoch [100/100], Step [22100/6235], Loss: 3.3319\n",
      "Epoch [100/100], Step [22200/6235], Loss: 8.1075\n",
      "Epoch [100/100], Step [22300/6235], Loss: 3.4425\n",
      "Epoch [100/100], Step [22400/6235], Loss: 8.5443\n",
      "Epoch [100/100], Step [22500/6235], Loss: 110.2752\n",
      "Epoch [100/100], Step [22600/6235], Loss: 16.6390\n",
      "Epoch [100/100], Step [22700/6235], Loss: 0.8462\n",
      "Epoch [100/100], Step [22800/6235], Loss: 2.7126\n",
      "Epoch [100/100], Step [22900/6235], Loss: 2.3592\n",
      "Epoch [100/100], Step [23000/6235], Loss: 13.8018\n",
      "Epoch [100/100], Step [23100/6235], Loss: 8.0391\n",
      "Epoch [100/100], Step [23200/6235], Loss: 11.3502\n",
      "Epoch [100/100], Step [23300/6235], Loss: 19.1118\n",
      "Epoch [100/100], Step [23400/6235], Loss: 1.1485\n",
      "Epoch [100/100], Step [23500/6235], Loss: 0.2068\n",
      "Epoch [100/100], Step [23600/6235], Loss: 108.4303\n",
      "Epoch [100/100], Step [23700/6235], Loss: 3.2233\n",
      "Epoch [100/100], Step [23800/6235], Loss: 1.0310\n",
      "Epoch [100/100], Step [23900/6235], Loss: 7.6461\n",
      "Epoch [100/100], Step [24000/6235], Loss: 0.2198\n",
      "Epoch [100/100], Step [24100/6235], Loss: 0.2631\n",
      "Epoch [100/100], Step [24200/6235], Loss: 18.9004\n",
      "Epoch [100/100], Step [24300/6235], Loss: 2.7951\n",
      "Epoch [100/100], Step [24400/6235], Loss: 8.5796\n",
      "Epoch [100/100], Step [24500/6235], Loss: 2.6212\n",
      "Epoch [100/100], Step [24600/6235], Loss: 0.1388\n",
      "Epoch [100/100], Step [24700/6235], Loss: 5.4826\n",
      "Epoch [100/100], Step [24800/6235], Loss: 0.0835\n",
      "Epoch [100/100], Step [24900/6235], Loss: 1.5682\n",
      "Epoch [100/100], Step [25000/6235], Loss: 17.4950\n",
      "Epoch [100/100], Step [25100/6235], Loss: 8.3725\n",
      "Epoch [100/100], Step [25200/6235], Loss: 1.7826\n",
      "Epoch [100/100], Step [25300/6235], Loss: 0.7189\n",
      "Epoch [100/100], Step [25400/6235], Loss: 9.6036\n",
      "Epoch [100/100], Step [25500/6235], Loss: 5.9020\n",
      "Epoch [100/100], Step [25600/6235], Loss: 2.5322\n",
      "Epoch [100/100], Step [25700/6235], Loss: 0.3579\n",
      "Epoch [100/100], Step [25800/6235], Loss: 0.1547\n",
      "Epoch [100/100], Step [25900/6235], Loss: 9.9187\n",
      "Epoch [100/100], Step [26000/6235], Loss: 4.4476\n",
      "Epoch [100/100], Step [26100/6235], Loss: 0.4596\n",
      "Epoch [100/100], Step [26200/6235], Loss: 0.0312\n",
      "Epoch [100/100], Step [26300/6235], Loss: 4.7823\n",
      "Epoch [100/100], Step [26400/6235], Loss: 0.1600\n",
      "Epoch [100/100], Step [26500/6235], Loss: 0.1959\n",
      "Epoch [100/100], Step [26600/6235], Loss: 3.1143\n",
      "Epoch [100/100], Step [26700/6235], Loss: 0.6440\n",
      "Epoch [100/100], Step [26800/6235], Loss: 0.6334\n",
      "Epoch [100/100], Step [26900/6235], Loss: 0.0400\n",
      "Epoch [100/100], Step [27000/6235], Loss: 12.7654\n",
      "Epoch [100/100], Step [27100/6235], Loss: 0.1313\n",
      "Epoch [100/100], Step [27200/6235], Loss: 0.0584\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Step [27300/6235], Loss: 0.2036\n",
      "Epoch [100/100], Step [27400/6235], Loss: 0.9119\n",
      "Epoch [100/100], Step [27500/6235], Loss: 6.6536\n",
      "Epoch [100/100], Step [27600/6235], Loss: 0.2386\n",
      "Epoch [100/100], Step [27700/6235], Loss: 1.5364\n",
      "Epoch [100/100], Step [27800/6235], Loss: 0.0684\n",
      "Epoch [100/100], Step [27900/6235], Loss: 0.9433\n",
      "Epoch [100/100], Step [28000/6235], Loss: 95.1951\n",
      "Epoch [100/100], Step [28100/6235], Loss: 1.2609\n",
      "Epoch [100/100], Step [28200/6235], Loss: 36.0312\n",
      "Epoch [100/100], Step [28300/6235], Loss: 3.2436\n",
      "Epoch [100/100], Step [28400/6235], Loss: 22.1742\n",
      "Epoch [100/100], Step [28500/6235], Loss: 4.4594\n",
      "Epoch [100/100], Step [28600/6235], Loss: 0.5002\n",
      "Epoch [100/100], Step [28700/6235], Loss: 4.6380\n",
      "Epoch [100/100], Step [28800/6235], Loss: 0.3975\n",
      "Epoch [100/100], Step [28900/6235], Loss: 66.5097\n",
      "Epoch [100/100], Step [29000/6235], Loss: 9.9621\n",
      "Epoch [100/100], Step [29100/6235], Loss: 0.0265\n",
      "Epoch [100/100], Step [29200/6235], Loss: 0.3481\n",
      "Epoch [100/100], Step [29300/6235], Loss: 6.4035\n",
      "Epoch [100/100], Step [29400/6235], Loss: 0.1872\n",
      "Epoch [100/100], Step [29500/6235], Loss: 1.5466\n",
      "Epoch [100/100], Step [29600/6235], Loss: 0.1972\n",
      "Epoch [100/100], Step [29700/6235], Loss: 0.8030\n",
      "Epoch [100/100], Step [29800/6235], Loss: 1.7233\n",
      "Epoch [100/100], Step [29900/6235], Loss: 0.3641\n",
      "Epoch [100/100], Step [30000/6235], Loss: 7.9403\n",
      "Epoch [100/100], Step [30100/6235], Loss: 11.7894\n",
      "Epoch [100/100], Step [30200/6235], Loss: 0.3744\n",
      "Epoch [100/100], Step [30300/6235], Loss: 0.2110\n",
      "Epoch [100/100], Step [30400/6235], Loss: 0.4141\n",
      "Epoch [100/100], Step [30500/6235], Loss: 2.6068\n",
      "Epoch [100/100], Step [30600/6235], Loss: 0.8629\n",
      "Epoch [100/100], Step [30700/6235], Loss: 0.0385\n",
      "Epoch [100/100], Step [30800/6235], Loss: 0.2898\n",
      "Epoch [100/100], Step [30900/6235], Loss: 3.2471\n",
      "Epoch [100/100], Step [31000/6235], Loss: 0.0211\n",
      "Epoch [100/100], Step [31100/6235], Loss: 0.0862\n",
      "Epoch [100/100], Step [31200/6235], Loss: 5.3288\n",
      "Epoch [100/100], Step [31300/6235], Loss: 0.6228\n",
      "Epoch [100/100], Step [31400/6235], Loss: 7.1051\n",
      "Epoch [100/100], Step [31500/6235], Loss: 1.8630\n",
      "Epoch [100/100], Step [31600/6235], Loss: 4.3599\n",
      "Epoch [100/100], Step [31700/6235], Loss: 2.8807\n",
      "Epoch [100/100], Step [31800/6235], Loss: 3.1000\n",
      "Epoch [100/100], Step [31900/6235], Loss: 1447.9059\n",
      "Epoch [100/100], Step [32000/6235], Loss: 175.4453\n",
      "Epoch [100/100], Step [32100/6235], Loss: 1.7383\n",
      "Epoch [100/100], Step [32200/6235], Loss: 48.3611\n",
      "Epoch [100/100], Step [32300/6235], Loss: 0.3163\n",
      "Epoch [100/100], Step [32400/6235], Loss: 0.1754\n",
      "Epoch [100/100], Step [32500/6235], Loss: 21.9507\n",
      "Epoch [100/100], Step [32600/6235], Loss: 0.9347\n",
      "Epoch [100/100], Step [32700/6235], Loss: 55.3958\n",
      "Epoch [100/100], Step [32800/6235], Loss: 11.7984\n",
      "Epoch [100/100], Step [32900/6235], Loss: 14.9902\n",
      "Epoch [100/100], Step [33000/6235], Loss: 0.1664\n",
      "Epoch [100/100], Step [33100/6235], Loss: 1.2386\n",
      "Epoch [100/100], Step [33200/6235], Loss: 1.6324\n",
      "Epoch [100/100], Step [33300/6235], Loss: 0.1727\n",
      "Epoch [100/100], Step [33400/6235], Loss: 149.2537\n",
      "Epoch [100/100], Step [33500/6235], Loss: 2.1899\n",
      "Epoch [100/100], Step [33600/6235], Loss: 3.3892\n",
      "Epoch [100/100], Step [33700/6235], Loss: 1.5932\n",
      "Epoch [100/100], Step [33800/6235], Loss: 1.1027\n",
      "Epoch [100/100], Step [33900/6235], Loss: 23.2870\n",
      "Epoch [100/100], Step [34000/6235], Loss: 0.0788\n",
      "Epoch [100/100], Step [34100/6235], Loss: 0.0798\n",
      "Epoch [100/100], Step [34200/6235], Loss: 2.3165\n",
      "Epoch [100/100], Step [34300/6235], Loss: 7.6744\n",
      "Epoch [100/100], Step [34400/6235], Loss: 0.4973\n",
      "Epoch [100/100], Step [34500/6235], Loss: 101.5095\n",
      "Epoch [100/100], Step [34600/6235], Loss: 1.5080\n",
      "Epoch [100/100], Step [34700/6235], Loss: 4.4327\n",
      "Epoch [100/100], Step [34800/6235], Loss: 8.8130\n",
      "Epoch [100/100], Step [34900/6235], Loss: 66.2423\n",
      "Epoch [100/100], Step [35000/6235], Loss: 0.2976\n",
      "Epoch [100/100], Step [35100/6235], Loss: 1.7245\n",
      "Epoch [100/100], Step [35200/6235], Loss: 2.1116\n",
      "Epoch [100/100], Step [35300/6235], Loss: 0.1735\n",
      "Epoch [100/100], Step [35400/6235], Loss: 0.9455\n",
      "Epoch [100/100], Step [35500/6235], Loss: 2.2716\n",
      "Epoch [100/100], Step [35600/6235], Loss: 3.2852\n",
      "Epoch [100/100], Step [35700/6235], Loss: 5.4584\n",
      "Epoch [100/100], Step [35800/6235], Loss: 0.3039\n",
      "Epoch [100/100], Step [35900/6235], Loss: 0.1897\n",
      "Epoch [100/100], Step [36000/6235], Loss: 1.4171\n",
      "Epoch [100/100], Step [36100/6235], Loss: 0.1014\n",
      "Epoch [100/100], Step [36200/6235], Loss: 19.6551\n",
      "Epoch [100/100], Step [36300/6235], Loss: 0.1260\n",
      "Epoch [100/100], Step [36400/6235], Loss: 0.4888\n",
      "Epoch [100/100], Step [36500/6235], Loss: 9.8795\n",
      "Epoch [100/100], Step [36600/6235], Loss: 0.0299\n",
      "Epoch [100/100], Step [36700/6235], Loss: 0.1654\n",
      "Epoch [100/100], Step [36800/6235], Loss: 29.6818\n",
      "Epoch [100/100], Step [36900/6235], Loss: 4.0604\n",
      "Epoch [100/100], Step [37000/6235], Loss: 0.1083\n",
      "Epoch [100/100], Step [37100/6235], Loss: 0.0448\n",
      "Epoch [100/100], Step [37200/6235], Loss: 0.0254\n",
      "Epoch [100/100], Step [37300/6235], Loss: 0.3669\n",
      "Epoch [100/100], Step [37400/6235], Loss: 0.2047\n",
      "Epoch [100/100], Step [37500/6235], Loss: 2.6264\n",
      "Epoch [100/100], Step [37600/6235], Loss: 9.5130\n",
      "Epoch [100/100], Step [37700/6235], Loss: 0.0286\n",
      "Epoch [100/100], Step [37800/6235], Loss: 10.3899\n",
      "Epoch [100/100], Step [37900/6235], Loss: 6.9747\n",
      "Epoch [100/100], Step [38000/6235], Loss: 0.0660\n",
      "Epoch [100/100], Step [38100/6235], Loss: 3.7807\n",
      "Epoch [100/100], Step [38200/6235], Loss: 2.5420\n",
      "Epoch [100/100], Step [38300/6235], Loss: 0.0796\n",
      "Epoch [100/100], Step [38400/6235], Loss: 0.1154\n",
      "Epoch [100/100], Step [38500/6235], Loss: 5.1354\n",
      "Epoch [100/100], Step [38600/6235], Loss: 1.1070\n",
      "Epoch [100/100], Step [38700/6235], Loss: 0.3718\n",
      "Epoch [100/100], Step [38800/6235], Loss: 0.7138\n",
      "Epoch [100/100], Step [38900/6235], Loss: 35.9220\n",
      "Epoch [100/100], Step [39000/6235], Loss: 10.4403\n",
      "Epoch [100/100], Step [39100/6235], Loss: 12.2413\n",
      "Epoch [100/100], Step [39200/6235], Loss: 1.1260\n",
      "Epoch [100/100], Step [39300/6235], Loss: 2.5910\n",
      "Epoch [100/100], Step [39400/6235], Loss: 278.3898\n",
      "Epoch [100/100], Step [39500/6235], Loss: 26.8027\n",
      "Epoch [100/100], Step [39600/6235], Loss: 9.3423\n",
      "Epoch [100/100], Step [39700/6235], Loss: 201.0681\n",
      "Epoch [100/100], Step [39800/6235], Loss: 70.0889\n",
      "Epoch [100/100], Step [39900/6235], Loss: 9.3597\n",
      "Epoch [100/100], Step [40000/6235], Loss: 9.3907\n",
      "Epoch [100/100], Step [40100/6235], Loss: 5.3724\n",
      "Epoch [100/100], Step [40200/6235], Loss: 23.0176\n",
      "Epoch [100/100], Step [40300/6235], Loss: 0.7770\n",
      "Epoch [100/100], Step [40400/6235], Loss: 0.2546\n",
      "Epoch [100/100], Step [40500/6235], Loss: 3.7220\n",
      "Epoch [100/100], Step [40600/6235], Loss: 0.3832\n",
      "Epoch [100/100], Step [40700/6235], Loss: 4.0400\n",
      "Epoch [100/100], Step [40800/6235], Loss: 2.0258\n",
      "Epoch [100/100], Step [40900/6235], Loss: 1.3851\n",
      "Epoch [100/100], Step [41000/6235], Loss: 41.6186\n",
      "Epoch [100/100], Step [41100/6235], Loss: 48.8286\n",
      "Epoch [100/100], Step [41200/6235], Loss: 16.3806\n",
      "Epoch [100/100], Step [41300/6235], Loss: 0.8887\n",
      "Epoch [100/100], Step [41400/6235], Loss: 0.0125\n",
      "Epoch [100/100], Step [41500/6235], Loss: 28.1307\n",
      "Epoch [100/100], Step [41600/6235], Loss: 2.8503\n",
      "Epoch [100/100], Step [41700/6235], Loss: 0.1026\n",
      "Epoch [100/100], Step [41800/6235], Loss: 0.3856\n",
      "Epoch [100/100], Step [41900/6235], Loss: 3.8146\n",
      "Epoch [100/100], Step [42000/6235], Loss: 4.2552\n",
      "Epoch [100/100], Step [42100/6235], Loss: 12.2814\n",
      "Epoch [100/100], Step [42200/6235], Loss: 66.8127\n",
      "Epoch [100/100], Step [42300/6235], Loss: 0.1014\n",
      "Epoch [100/100], Step [42400/6235], Loss: 1.7839\n",
      "Epoch [100/100], Step [42500/6235], Loss: 1.0930\n",
      "Epoch [100/100], Step [42600/6235], Loss: 0.4288\n",
      "Epoch [100/100], Step [42700/6235], Loss: 0.1785\n",
      "Epoch [100/100], Step [42800/6235], Loss: 4.7758\n",
      "Epoch [100/100], Step [42900/6235], Loss: 4.5673\n",
      "Epoch [100/100], Step [43000/6235], Loss: 0.3928\n",
      "Epoch [100/100], Step [43100/6235], Loss: 0.0419\n",
      "Epoch [100/100], Step [43200/6235], Loss: 0.2377\n",
      "Epoch [100/100], Step [43300/6235], Loss: 4.5241\n",
      "Epoch [100/100], Step [43400/6235], Loss: 4.0070\n",
      "Epoch [100/100], Step [43500/6235], Loss: 12.3146\n",
      "Epoch [100/100], Step [43600/6235], Loss: 1.2883\n",
      "Epoch [100/100], Step [43700/6235], Loss: 44.8005\n",
      "Epoch [100/100], Step [43800/6235], Loss: 0.6243\n",
      "Epoch [100/100], Step [43900/6235], Loss: 3.8459\n",
      "Epoch [100/100], Step [44000/6235], Loss: 36.5204\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/100], Step [44100/6235], Loss: 0.0770\n",
      "Epoch [100/100], Step [44200/6235], Loss: 2.0970\n",
      "Epoch [100/100], Step [44300/6235], Loss: 66.1331\n",
      "Epoch [100/100], Step [44400/6235], Loss: 5.3494\n",
      "Epoch [100/100], Step [44500/6235], Loss: 0.3476\n",
      "Epoch [100/100], Step [44600/6235], Loss: 10.0070\n",
      "Epoch [100/100], Step [44700/6235], Loss: 3.7283\n",
      "Epoch [100/100], Step [44800/6235], Loss: 0.3471\n",
      "Epoch [100/100], Step [44900/6235], Loss: 11.2561\n",
      "Epoch [100/100], Step [45000/6235], Loss: 5.9675\n",
      "Epoch [100/100], Step [45100/6235], Loss: 56.3557\n",
      "Epoch [100/100], Step [45200/6235], Loss: 0.7338\n",
      "Epoch [100/100], Step [45300/6235], Loss: 25.3633\n",
      "Epoch [100/100], Step [45400/6235], Loss: 8.2486\n",
      "Epoch [100/100], Step [45500/6235], Loss: 3.1684\n",
      "Epoch [100/100], Step [45600/6235], Loss: 1.4602\n",
      "Epoch [100/100], Step [45700/6235], Loss: 75.9022\n",
      "Epoch [100/100], Step [45800/6235], Loss: 218.9457\n",
      "Epoch [100/100], Step [45900/6235], Loss: 13.2355\n",
      "Epoch [100/100], Step [46000/6235], Loss: 34.6347\n",
      "Epoch [100/100], Step [46100/6235], Loss: 44.4363\n",
      "Epoch [100/100], Step [46200/6235], Loss: 44.3420\n",
      "Epoch [100/100], Step [46300/6235], Loss: 8.2585\n",
      "Epoch [100/100], Step [46400/6235], Loss: 12.8711\n",
      "Epoch [100/100], Step [46500/6235], Loss: 360.0119\n",
      "Epoch [100/100], Step [46600/6235], Loss: 12.0446\n",
      "Epoch [100/100], Step [46700/6235], Loss: 40.9937\n",
      "Epoch [100/100], Step [46800/6235], Loss: 37.0452\n",
      "Epoch [100/100], Step [46900/6235], Loss: 13.4515\n",
      "Epoch [100/100], Step [47000/6235], Loss: 2.5226\n",
      "Epoch [100/100], Step [47100/6235], Loss: 67.1172\n",
      "Epoch [100/100], Step [47200/6235], Loss: 60.9949\n",
      "Epoch [100/100], Step [47300/6235], Loss: 11.5429\n",
      "Epoch [100/100], Step [47400/6235], Loss: 455.8917\n",
      "Epoch [100/100], Step [47500/6235], Loss: 4.9303\n",
      "Epoch [100/100], Step [47600/6235], Loss: 9.7486\n",
      "Epoch [100/100], Step [47700/6235], Loss: 23.0369\n",
      "Epoch [100/100], Step [47800/6235], Loss: 30.8616\n",
      "Epoch [100/100], Step [47900/6235], Loss: 10.9033\n",
      "Epoch [100/100], Step [48000/6235], Loss: 0.9968\n",
      "Epoch [100/100], Step [48100/6235], Loss: 14.1741\n",
      "Epoch [100/100], Step [48200/6235], Loss: 173.7258\n",
      "Epoch [100/100], Step [48300/6235], Loss: 747.4875\n",
      "Epoch [100/100], Step [48400/6235], Loss: 2.4002\n",
      "Epoch [100/100], Step [48500/6235], Loss: 36.1312\n",
      "Epoch [100/100], Step [48600/6235], Loss: 24.8227\n",
      "Epoch [100/100], Step [48700/6235], Loss: 20.3674\n",
      "Epoch [100/100], Step [48800/6235], Loss: 215.9346\n",
      "Epoch [100/100], Step [48900/6235], Loss: 112.9072\n",
      "Epoch [100/100], Step [49000/6235], Loss: 202.0871\n",
      "Epoch [100/100], Step [49100/6235], Loss: 599.7324\n",
      "Epoch [100/100], Step [49200/6235], Loss: 715.0166\n",
      "Epoch [100/100], Step [49300/6235], Loss: 1001.3436\n",
      "Epoch [100/100], Step [49400/6235], Loss: 30.6605\n",
      "Epoch [100/100], Step [49500/6235], Loss: 21.2137\n",
      "Epoch [100/100], Step [49600/6235], Loss: 53.9704\n",
      "Epoch [100/100], Step [49700/6235], Loss: 964.4534\n",
      "Epoch [100/100], Step [49800/6235], Loss: 536.1829\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and test data:\n",
    "table = pd.read_csv(\"bitcoin-historical-data/btceUSD_1-min_data_2012-01-01_to_2017-05-31.csv\")\n",
    "table = table.dropna()\n",
    "\n",
    "table = table.reset_index(drop=True)\n",
    "divider = np.random.rand(len(table)) < 0.8\n",
    "train_table = table[divider]\n",
    "test_table = table[~divider]\n",
    "\n",
    "train_data = train_table.as_matrix().astype('float')\n",
    "test_data = test_table.as_matrix().astype('float')\n",
    "\n",
    "# Loss function:\n",
    "criterion = nn.MSELoss()\n",
    "# Optimizer: (either use backpropagation or a variant of it to speed learning)\n",
    "optimizer = torch.optim.Adam(net.parameters(), lr=0.01)\n",
    "\n",
    "# epochs: how many iterations we want to train for \n",
    "num_epochs = 20\n",
    "# batch size : number of examples we want to use per training update \n",
    "batch_size = 500\n",
    "# number of splits: how many groups of batches we will use:\n",
    "num_batches = train_data.size // batch_size\n",
    "# split the data into batches \n",
    "batches =  np.array_split(train_data, num_batches)\n",
    "\n",
    "# Train the model:\n",
    "for epoch in range(num_epochs):\n",
    "    for i, batch in enumerate(batches):\n",
    "        # want all columns except last column for inputs. Convert it to pytorch's Variable \n",
    "        inputs = Variable(torch.from_numpy(batch[:,:-1]).float())\n",
    "        # last column - our price is the label \n",
    "        labels = Variable(torch.from_numpy(batch[:,-1]).float()) \n",
    "        \n",
    "        optimizer.zero_grad()  # zero the gradient buffer\n",
    "        outputs = net(inputs) # get the output of the network\n",
    "        \n",
    "        loss = criterion(outputs, labels) # compute the loss \n",
    "        loss.backward() # update the weights of the neural network\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0: # Print out our loss\n",
    "            print ('Epoch [%d/%d], Step [%d/%d], Loss: %.4f' \n",
    "                   %(epoch+1, num_epochs, i+1, len(train_data)//batch_size, loss.data[0]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have trained our neural network model on the 80% of the data, we can test it with the last 20% of the data, known as the testing data. If we want a model that can make better predictions, our goal is to make a model that generalizes well instead of only learning the weights that make it perform well on the training data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test our model:\n",
    "inputs = Variable(torch.from_numpy(test_data[:,:-1]).float())\n",
    "labels = Variable(torch.from_numpy(test_data[:,-1]).float()) \n",
    "# get the prediction\n",
    "prediction = net(inputs)\n",
    "# compare it to labels:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
